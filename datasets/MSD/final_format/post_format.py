# -*- coding: utf-8 -*-
import json
type1={'内科':
  0.311, '药理学': 0.088, '病理学': 0.078, '病理生理学': 0.062, '外科': 0.056, '微生物学':
  0.056, '儿科': 0.055, '放射科': 0.034, '妇产科': 0.031, '遗传学': 0.031, '精神病学': 0.022,
  '解剖学': 0.022, '皮肤性病科': 0.019, '眼科': 0.016, '医学免疫学': 0.015, '预防医学': 0.012,
  '生物化学': 0.012, '生理学': 0.011, '耳鼻咽喉头颈外科学': 0.011, '急诊医学': 0.011, '营养学': 0.01,
  '医学伦理学': 0.008, '康复医学': 0.004, '全科医学概论': 0.004, '职业卫生学': 0.004, '口腔科学':
  0.004, '环境卫生学': 0.003, '流行病学和循证医学': 0.003, '医学心理学': 0.003, '核医学': 0.001,
  '医学统计学': 0.001, '麻醉学': 0.001}
type2={'药理学@临床药理学': 0.108, '病理学@系统病理学':
  0.077, '内科@感染病学': 0.05, '微生物学@医学细菌学': 0.048, '内科@神经内科': 0.048, '儿科@新生儿科':
  0.046, '放射科@影像诊断': 0.044, '外科@普通外科': 0.04, '遗传学@人类遗传学': 0.04, '内科@心血管内科':
  0.037, '内科@消化内科': 0.031, '内科@风湿病学': 0.027, '内科@内分泌内科': 0.027, '内科@老年病学':
  0.025, '病理学@临床病理学': 0.023, '妇产科@产科': 0.023, '内科@肾脏内科': 0.023, '儿科@儿内科':
  0.021, '妇产科@妇科': 0.019, '内科@呼吸内科': 0.017, '微生物学@医学病毒学': 0.017, '内科@肿瘤学':
  0.017, '解剖学@系统解剖学': 0.017, '解剖学@局部解剖学': 0.017, '外科@骨科': 0.015, '内科@血液内科':
  0.015, '微生物学@人体寄生虫学': 0.012, '内科@传染病学': 0.012, '生物化学@分子生物化学': 0.01,
  '生理学@人体生理学': 0.01, '放射科@介入放射学': 0.008, '医学伦理学@医患沟通': 0.008, '遗传学@分子遗传学':
  0.008, '外科@胸心外科': 0.008, '微生物学@医学真菌学': 0.006, '妇产科@生殖医学': 0.006, '病理学@细胞病理学':
  0.006, '生理学@系统生理学': 0.004, '口腔科学@口腔外科': 0.004, '生物化学@细胞生物化学': 0.004, '妇产科':
  0.004, '皮肤性病科': 0.002, '外科@泌尿外科': 0.002, '急诊医学': 0.002, '外科@神经外科': 0.002,
  '病理学@分子病理学': 0.002, '儿科': 0.002, '儿科@儿童保健': 0.002, '儿科@儿外科': 0.002,
  '生物化学@临床生物化学': 0.002}

file="MSD"
save_file = f"../../../../full_data/{file}/{file}.jsonl"
fw = open(save_file, 'w',encoding="utf-8")


from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained("../../../basic_tools/tokenizer")
def tokenizer_lens(context):
    ids = tokenizer.encode(context)
    return len(ids)
sum_lens = 0
class_ratio_token= {'level1': {'外科': '11.846%', '皮肤性病科': '2.774%', '全科医学概论': '2.103%', '康复医学': '0.927%', '内科': '65.857%', '眼科': '4.402%', '微生物学': '15.588%', '病理生理学': '22.289%', '病理学': '22.306%', '环境卫生学': '1.61%', '妇产科': '11.267%', '预防医学': '4.486%', '药理学': '18.218%', '遗传学': '5.117%', '精神病学': '5.529%', '医学免疫学': '2.323%', '生理学': '3.821%', '耳鼻咽喉头颈外科学': '2.539%', '儿科': '12.731%', '流行病学和循证医学': '0.337%', '急诊医学': '1.922%', '职业卫生学': '1.126%', '解剖学': '3.801%', '放射科': '4.633%', '营养学': '0.829%', '生物化学': '2.397%', '医学伦理学': '1.593%', '口腔科学': '1.03%', '核医学': '0.185%', '麻醉学': '0.034%', '医学心理学': '0.64%'}, 'level2': {'外科@普通外科': '5.387%', '内科@老年病学': '5.251%', '内科@心血管内科': '6.792%', '内科@风湿病学': '3.846%', '微生物学@医学细菌学': '11.238%', '内科@感染病学': '9.314%', '内科@消化内科': '5.849%', '病理学@系统病理学': '14.597%', '药理学@临床药理学': '21.657%', '放射科@介入放射学': '2.544%', '医学伦理学@医患沟通': '2.261%', '妇产科@妇科': '2.205%', '内科@呼吸内科': '1.897%', '微生物学@医学病毒学': '3.505%', '儿科@新生儿科': '10.472%', '病理学@临床病理学': '5.346%', '内科@神经内科': '9.334%', '妇产科@产科': '5.212%', '遗传学@人类遗传学': '7.739%', '内科@肿瘤学': '5.767%', '生理学@系统生理学': '2.0%', '内科@肾脏内科': '3.581%', '微生物学@人体寄生虫学': '1.533%', '内科@传染病学': '2.606%', '皮肤性病科': '0.541%', '微生物学@医学真菌学': '0.944%', '放射科@影像诊断': '7.679%', '解剖学@系统解剖学': '2.415%', '内科@内分泌内科': '7.757%', '遗传学@分子遗传学': '1.202%', '外科@骨科': '2.47%', '儿科@儿内科': '6.711%', '外科@泌尿外科': '0.229%', '解剖学@局部解剖学': '3.256%', '急诊医学': '0.276%', '外科@胸心外科': '0.854%', '内科@血液内科': '2.66%', '外科@神经外科': '0.521%', '生物化学@分子生物化学': '1.544%', '病理学@分子病理学': '0.112%', '生理学@人体生理学': '1.53%', '妇产科@生殖医学': '3.596%', '儿科': '0.787%', '口腔科学@口腔外科': '0.452%', '生物化学@细胞生物化学': '0.823%', '病理学@细胞病理学': '1.092%', '儿科@儿童保健': '0.57%', '儿科@儿外科': '0.161%', '妇产科': '1.148%', '生物化学@临床生物化学': '0.22%'}, 'all_sample_tokens': 529551}
class_ratio_doc= {'level1': {'妇产科': '8.367%', '遗传学': '7.171%', '内科': '64.143%', '放射科': '6.375%', '精神病学': '5.976%', '皮肤性病科': '5.179%', '解剖学': '5.179%', '眼科': '4.781%', '医学免疫学': '3.586%', '耳鼻咽喉头颈外科学': '3.187%', '生理学': '2.39%', '生物化学': '2.39%', '病理学': '19.124%', '病理生理学': '14.343%', '药理学': '14.343%', '外科': '13.546%', '儿科': '13.147%', '微生物学': '10.359%', '急诊医学': '1.992%', '营养学': '1.992%', '预防医学': '1.594%', '医学伦理学': '1.594%', '职业卫生学': '1.195%', '康复医学': '0.797%', '全科医学概论': '0.797%', '口腔科学': '0.797%', '医学心理学': '0.797%', '流行病学和循证医学': '0.398%', '环境卫生学': '0.398%', '核医学': '0.398%'}, 'level2': {'内科@感染病学': '9.163%', '微生物学@医学细菌学': '9.163%', '内科@神经内科': '9.163%', '儿科@新生儿科': '8.765%', '外科@普通外科': '7.57%', '遗传学@人类遗传学': '7.57%', '放射科@影像诊断': '7.57%', '内科@心血管内科': '6.773%', '内科@消化内科': '5.976%', '内科@风湿病学': '5.179%', '内科@内分泌内科': '5.179%', '病理学@临床病理学': '4.382%', '内科@肾脏内科': '4.382%', '内科@老年病学': '3.984%', '妇产科@产科': '3.984%', '妇产科@妇科': '3.586%', '微生物学@医学病毒学': '3.187%', '内科@呼吸内科': '3.187%', '解剖学@系统解剖学': '3.187%', '儿科@儿内科': '3.187%', '解剖学@局部解剖学': '3.187%', '药理学@临床药理学': '20.717%', '内科@肿瘤学': '2.789%', '外科@骨科': '2.789%', '内科@血液内科': '2.789%', '内科@传染病学': '2.39%', '微生物学@人体寄生虫学': '2.39%', '病理学@系统病理学': '14.741%', '生物化学@分子生物化学': '1.992%', '医学伦理学@医患沟通': '1.594%', '放射科@介入放射学': '1.594%', '遗传学@分子遗传学': '1.594%', '生理学@人体生理学': '1.594%', '微生物学@医学真菌学': '1.195%', '外科@胸心外科': '1.195%', '病理学@细胞病理学': '1.195%', '生理学@系统生理学': '0.797%', '妇产科@生殖医学': '0.797%', '口腔科学@口腔外科': '0.797%', '妇产科': '0.797%', '皮肤性病科': '0.398%', '外科@泌尿外科': '0.398%', '急诊医学': '0.398%', '外科@神经外科': '0.398%', '病理学@分子病理学': '0.398%', '儿科': '0.398%', '儿科@儿童保健': '0.398%', '生物化学@细胞生物化学': '0.398%', '儿科@儿外科': '0.398%', '生物化学@临床生物化学': '0.398%'}}

with open(f"../../../../full_data/{file}/{file}_clean.jsonl", "r",encoding="utf-8") as fs:
    for item in fs.readlines():
        item = json.loads(item)
        context = item["text"]
        lens = tokenizer_lens(context)
        sum_lens += lens

with open(f"../../../../full_data/{file}/{file}_clean.jsonl", "r",encoding="utf-8") as fs:
    for item in fs.readlines():
        item = json.loads(item)
        item["tags"] = {
                "id": item["seq_id"],
                "clean_iters":2,
                "quality_score":"zh:90.4%;en:80.4%",
                "note:中文存在拼音替代汉字的情况，为计入不合格中；英文存在清洗后导致上下文关联性查的问题，暂无法清洗；另外英文存在部分句子语义重合度较高的问题，大概占有10%的样本，留待后期优化；"
                "class_ratio_doc": class_ratio_doc,
                "class_ratio_tokenize": class_ratio_token,
                "item_tokens": tokenizer_lens(item["text"]),
                "dataset_tokens": sum_lens,
                "bia_class": "诊疗指南"
        }

        item = json.dumps(item,ensure_ascii=False)
        fw.write(item+"\n")
