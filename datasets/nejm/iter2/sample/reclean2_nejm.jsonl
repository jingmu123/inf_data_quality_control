{"id": 2234552, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "21efe830-850d-449f-9d3f-bf3447f1dbe5", "title": "Drug Sensitivity of Currently Circulating Mpox Viruses", "text": "【0】Drug Sensitivity of Currently Circulating Mpox Viruses\nTo the Editor:\n--------------\n\n【1】As of November 10, 2022, the ongoing global monkeypox (recently renamed mpox) outbreak has resulted in 79,231 cases in 110 countries and 49 deaths, according to the Centers for Disease Control and Prevention. Approximately 10% of patients with mpox are hospitalized. \n\n【2】Tecovirimat (ST-246), cidofovir, and brincidofovir (CMX001) are the antiviral agents currently used for the treatment of mpox.  The currently circulating mpox viruses (MPXVs) have genomic alterations that were not observed previously and appear to affect virus biology, as indicated by the clinical and epidemiologic features seen with the viruses in the current outbreak, which are different from those seen in previous mpox outbreaks.  These alterations may also affect virus sensitivity to antiviral drugs.\n\n【3】We obtained MPXV isolates from 12 patients, who had no known relationship to one another, during the current outbreak to assess virus sensitivity to tecovirimat, cidofovir, and brincidofovir in commonly used cell-line models and primary cultures of pathologically relevant cell types (human foreskin fibroblasts \\[HFF\\] and human foreskin keratinocytes \\[HFK\\]) . All isolates reacted with primers that detect clade II (West African clade) and had mutational profiles that closely resembled that of a reference genome from the current worldwide outbreak (ON563414.2) , results that are consistent with previous findings.  However, the isolates and ON563414.2 harbored mutations in the viral DNA polymerase (gp57, the target of cidofovir and brincidofovir) and in F13L (gp45, the target of tecovirimat) that were not present in a reference genome (MT903344.1) before the current outbreak. These mutations have arisen without known selective pressure from antiviral medications.\n\n【4】Figure 1. Infection of Primary Human Cells with Mpox Virus (MPXV) Isolates Obtained from Patients during the Current Outbreak and Sensitivity to Antiviral Drugs.\n\n【5】Primary human foreskin fibroblasts (HFF) and human foreskin keratinocytes (HFK) were infected with MPXV isolates obtained from 12 patients with MPXV infection (multiplicity of infection, 0.01), and immunofluorescence staining was performed at 24 hours, 48 hours, and 72 hours after infection . Cell nuclei were stained with 4′,6-diamidine-2-phenylindole (DAPI). Dose–response curves and 50% inhibitory concentrations (IC <sub>50 </sub> ) were determined at 72 hours after infection .\n\n【6】All isolates replicated in both HFF and HFK cells, as indicated by immunofluorescence staining for orthopoxvirus  and the detection of virus DNA in cell supernatants . Pronounced cytopathogenic effects were seen in HFK cells but not in HFF cells.\n\n【7】Tecovirimat, cidofovir, and brincidofovir inhibited MPXV infection in a dose-dependent manner . The 50% inhibitory concentration (IC <sub>50 </sub> ) of the drugs ranged from 4 to 20 nmol for tecovirimat, from 5 to 32 μmol for cidofovir, and from 9 to 152 nmol for brincidofovir. IC <sub>50 </sub> values determined in continuous cell lines differed substantially from those in primary cultures, in particular for cidofovir and brincidofovir , findings that stress the importance of physiologically relevant models.\n\n【8】The IC <sub>50 </sub> values for tecovirimat, cidofovir, and brincidofovir (4000 nmol, 80 μmol, and 600 nmol, respectively) are within the range of therapeutic concentrations in plasma . The highest plasma concentration of tecovirimat after one dose was 200 to 1000 times as high as the IC <sub>50 </sub> values for the agent. The plasma concentrations of brincidofovir were 3.9 to 67.0 times as high as the IC <sub>50 </sub> values, and the plasma concentrations of cidofovir were 2.5 to 16.0 times as high as the IC <sub>50 </sub> values. Our data indicate that the currently circulating MPXVs are likely to remain sensitive to the available antiviral drugs.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-14 00:18:37", "grab_time": "2024-08-13 22:44:36"}
{"id": 2234551, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "7dc3bc7e-6c9a-4487-a66b-9896b75e6af6", "title": "Lymphocyte Stimulation Induced by Halothane in Patients with Hepatitis Following Exposure to Halothane", "text": "【0】Lymphocyte Stimulation Induced by Halothane in Patients with Hepatitis Following Exposure to Halothane\nAbstract\n--------\n\n【1】Stimulation of lymphocytes, as measured by incorporation of  H-thymidine into the deoxyribonucleic acid of lymphocytes, was observed in the presence of halothane in 10 of 15 patients with halothane hepatitis, but not in healthy controls, patients with hepatic disease or patients who were exposed to halothane but did not have liver damage. Lymphocytes of a patient with hepatic damage attributable to methoxyflurane were stimulated by methoxyflurane. Preliminary data indicate that sensitization is temporary. The plasma of the patients may contain a factor inhibiting lymphocyte stimulation. Australia antigen was not detected in the serums of the patients, but antimitochondrial antibodies seemed to correlate with lymphocyte stimulation.\n\n【2】Stimulation of lymphocytes in the presence of halothane is helpful in the differential diagnosis of viral and halothane hepatitis, and indicates that in some patients, the anesthetic may be a sensitizing agent with a pathogenetic role in the hepatic damage.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 16:42:40", "endTime": "2024/08/13 16:43:38", "cost": 58.535}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 00:43:39", "grab_time": "2024-08-13 00:42:40"}
{"id": 2234550, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "a3556148-4db0-4546-b933-d52e5d40f0bb", "title": "A Prospective Study of the Role of Cytomegalovirus in Post-Transfusion Mononucleosis", "text": "【0】A Prospective Study of the Role of Cytomegalovirus in Post-Transfusion Mononucleosis\nAbstract\n--------\n\n【1】After open-heart surgery post-transfusion mononucleosis developed in six patients who had had cytomegalovirus complement-fixing (CMV-CF) antibody before operation. Three of them showed an appreciable antibody rise during the episode of mononucleosis, and cytomegalovirus was isolated from the leukocytes of another two.\n\n【2】One donor to a patient with mononucleosis and cytomegalovirus in the blood had a rising CMV-CF antibody titer. This donor, it is suggested, may have been viremic at the time of donating blood and that he constituted an exogenous source of virus.\n\n【3】The cytomegalovirus in the blood of patients experiencing post-transfusion mononucleosis may be of endogenous as well as of exogenous derivation. It is questionable whether cytomegalovirus was responsible for the hematologic changes observed.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:39:02", "endTime": "2024/08/14 15:39:58", "cost": 55.998}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 23:39:58", "grab_time": "2024-08-13 23:39:02"}
{"id": 2234549, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "704ddde3-b44f-4779-95a2-3bc5b36bb4bc", "title": "Tangier Disease — One Explanation of Lipid Storage", "text": "【0】Tangier Disease — One Explanation of Lipid Storage\nAbstract\n--------\n\n【1】Normal high-density lipoproteins are absent from plasma in Tangier disease, and the disorder is characterized by accumulation of cholesteryl esters in several tissues, particularly those of the reticuloendothelial system. Electron microscopy of the abnormal high-density lipoproteins in the plasma of three patients with Tangier disease revealed large (68-nm), flattened, translucent particles in all cases. These particles were most abundant in the plasma of the splenectomized patient. Restriction of dietary fat eliminated or drastically reduced the numbers of these particles among the Tangier high-density lipoproteins. Thus abnormal products of chylomicron metabolism that appear to occur in plasma in this disorder may be targets for phagocytosis and may be at least one source of the cholesteryl esters that accumulate in reticuloendothelial tissues in Tangier disease.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:32:53", "endTime": "2024/08/14 15:34:56", "cost": 123.321}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 23:34:56", "grab_time": "2024-08-13 23:32:53"}
{"id": 2234548, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "757b5236-5382-44b4-bbf1-83ed94c78bc7", "title": "Excess of Ampicillin Rashes Associated with Allopurinol or Hyperuricemia", "text": "【0】Excess of Ampicillin Rashes Associated with Allopurinol or Hyperuricemia\nAbstract\n--------\n\n【1】In a comprehensive drug surveillance system, drug rashes were observed among 22.4 per cent of 67 hospitalized medical patients receiving allopurinol and ampicillin concomitantly, and among 7.5 per cent of 1257 patients receiving only ampicillin. The relative risk for allopurinol recipients, as compared with nonrecipients, was 3.0, with 95 per cent confidence limits of 1.8 and 4.6. Potentiation of ampicillin rashes by allopurinol (or hyperuricemia) seems a likely explanation, since only 2.1 per cent of 283 patients receiving allopurinol without ampicillin experienced drug rashes – a rate comparable with that observed among ampicillin nonrecipients in general. Data on uric acid levels were not available, and it is not clear whether the potentiation should be ascribed to allopurinol or to hyperuricemia.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:40:51", "endTime": "2024/08/14 14:41:00", "cost": 8.785}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 22:41:00", "grab_time": "2024-08-13 22:40:51"}
{"id": 2234547, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "9fa94319-166b-4c50-8f9e-a42ef4fefb48", "title": "Effectiveness of BNT162b2 Vaccine against Delta Variant in Adolescents", "text": "【0】Effectiveness of BNT162b2 Vaccine against Delta Variant in Adolescents\nTo the Editor:\n--------------\n\n【1】The B.1.617.2 (delta) variant of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has emerged as the dominant strain circulating in many regions worldwide. The BNT162b2 mRNA vaccine against coronavirus disease 2019 (Covid-19) was found to be effective in preventing infection with the delta variant in a recent observational study,  but other reports have suggested reduced vaccine effectiveness against this variant.  On May 10, 2021, the U.S. Food and Drug Administration approved the emergency use of BNT162b2 in adolescents 12 years of age or older on the basis of a clinical trial that had been conducted before the delta variant had become prevalent in the United States.  Additional evidence was needed regarding the effectiveness of the BNT162b2 vaccine among adolescents, particularly against the delta variant.\n\n【2】We sought to estimate the vaccine effectiveness of BNT162b2 against the delta variant among vaccinated adolescents for whom an unvaccinated match was found. We used data from Clalit Health Services, the largest health care organization in Israel, to conduct an observational cohort study involving adolescents between the ages of 12 and 18 years who had no prior SARS-CoV-2 infection noted in their electronic medical record and who had been vaccinated between June 8 and September 14, 2021. According to the sequencing of samples obtained from infected persons that was performed by the Israeli Ministry of Health during this period, the delta variant was responsible for more than 95% of new infections in the general population in Israel.\n\n【3】We used the same methods that were used in our previous studies of vaccine effectiveness, which were conducted in the same health care organization using the same database.   Vaccine effectiveness was defined as 1 minus the risk ratio, which was estimated over several follow-up periods for documented SARS-CoV-2 infection and symptomatic Covid-19. More severe outcomes related to Covid-19 are rare in this age group.\n\n【4】Table 1. Effectiveness of BNT162b2 Vaccine among Adolescents.\n\n【5】Of 184,905 vaccinated adolescents, 130,464 met the eligibility requirements, and 94,354 of these vaccine recipients were successfully matched with 94,354 unvaccinated controls . The eligible population was similar to the matched population with respect to several demographic and clinical characteristics . The frequency of polymerase-chain-reaction testing for SARS-CoV-2 was similar in the vaccinated and unvaccinated populations (9.4 and 9.9 tests per 100 persons per week, respectively). The median follow-up was 27 days after baseline, which was defined as the administration of the first dose among the vaccine recipients. Kaplan–Meier curves for SARS-CoV-2 infection in both the vaccinated and unvaccinated groups were similar during the initial days, after which the incidence began to rise more slowly in the vaccinated group .\n\n【6】The estimated vaccine effectiveness against documented SARS-CoV-2 infection was 59% (95% confidence interval \\[CI\\], 52 to 65) on days 14 through 20 after the first dose, 66% (95% CI, 59 to 72) on days 21 to 27 after the first dose, and 90% (95% CI, 88 to 92) on days 7 to 21 after the second dose. The estimated vaccine effectiveness against symptomatic Covid-19 was 57% (95% CI, 39 to 71) on days 14 to 20 after the first dose, 82% (95% CI, 73 to 91) on days 21 to 27 after the first dose, and 93% (95% CI, 88 to 97) on days 7 to 21 after the second dose.\n\n【7】In a recent randomized trial involving 1983 vaccinated adolescents between the ages of 12 and 15 years with no history of SARS-CoV-2 infection, investigators estimated that the vaccine effectiveness of two doses of BNT162b2 was 100% (95% CI, 75 to 100) against symptomatic infection by non-delta variants.  The present observational study provides substantially more precise estimates of vaccine effectiveness among adolescents between the ages of 12 and 18 years for both documented infection and symptomatic disease in a setting in which the delta variant was predominant. Our estimates of the effectiveness of two doses of the BNT162b2 vaccine against the delta variant among adolescents are similar to estimates of effectiveness against the alpha variant in the general population with the use of the same study design  and are similar to the estimate of 88% (95% CI, 85 to 90) against the delta variant in the general population in an observational study that used a different design. \n\n【8】Our results show that the BNT162b2 mRNA vaccine was highly effective in the first few weeks after vaccination against both documented infection and symptomatic Covid-19 with the delta variant among adolescents between the ages of 12 and 18 years.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-14 00:22:00", "grab_time": "2024-08-13 23:52:02"}
{"id": 2234546, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "2870fe3a-3ae1-4704-be42-a1a9ed6d8d4e", "title": "Asthma Caused by a Cathedral Wall", "text": "【0】Asthma Caused by a Cathedral Wall\nTo the Editor:\n--------------\n\n【1】The addition of egg to the paste used to protect stone buildings is an old custom, with origins in ancient Rome.  We describe a patient who had an episode of severe asthma and atopic dermatitis caused by the release of this hidden allergen during the cleaning and repairing of a cathedral wall from the 16th century.\n\n【2】A 20-year-old woman was hospitalized with atopic dermatitis involving 60 percent of her body surface and moderate asthma. Skin-prick tests were positive for grass pollen, cat dander, bird feathers, egg white, and egg yolk. A test for specific IgE antibodies to egg white was also positive (titer, >100 kU per liter). A double-blind, placebo-controlled ingestion challenge was positive: the ingestion of 100 mg of egg powder led to a decline in the forced expiratory volume in one second of more than 20 percent. After treatment and the institution of a diet free from egg products, the patient's symptoms improved. Fifteen months later, she had another asthma crisis related to the inhalation of dust arising from the restoration of an old cathedral situated opposite her house. Her specific IgE antibody titer to egg white was more than 1000 kU per liter.\n\n【3】Figure 1. Inhibition of the Cathedral-Wall Extract on Sodium Dodecyl Sulfate–Polyacrylamide-Gel Electrophoresis Immunoblotting.\n\n【4】Lane 1 shows the effect of the cathedral-wall extract on control serum (pooled serum from subjects without atopy); lane 2, a sample of the patient's serum; lane 3, a sample of the patient's serum that had previously been incubated with the cathedral-wall extract (positive control); lane 4, a sample of the patient's serum that had previously been incubated with egg-white extract; lane 5, a sample of the patient's serum that had previously been incubated with egg-yolk extract; lane 6, a sample of the patient's serum that had previously been incubated with an extract of birch pollen ( _Betula alba_ ) (negative control); and lane 7, molecular-mass markers.\n\n【5】Recently, Craig et al. described the persistence of milk proteins in prehistoric vessels.  This finding led us to speculate that some allergenic egg proteins are conserved in the patina of ancient walls. We obtained an extract of dust from the patina of the cathedral wall and analyzed the allergenic response to this extract of our patient and 19 controls (10 persons with asthma, 5 persons who were sensitized to egg, and 4 workers who had been restoring the cathedral). Our patient had a positive skin-prick test and positive results on conjunctival challenge with the cathedral-wall extract.  These tests were negative in the 10 controls with asthma and positive in the 5 controls with egg sensitization and in 1 of the workers. Specific IgE levels were positive with respect to the cathedral-wall extract (54 kU per liter), egg white, egg yolk, ovalbumin, ovomucoid, conalbumin, and lysozyme. An immunoblot inhibition assay  showed that egg-white and egg-yolk proteins completely inhibited binding of the patient's specific IgE to the cathedral-wall extract.\n\n【6】Our findings suggest that egg allergy is a possible etiologic agent in patients with asthma in whom symptoms develop after the inhalation of dust from old monuments and may be a cause of occupational asthma in people who restore old buildings.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-14 00:15:42", "grab_time": "2024-08-13 23:44:33"}
{"id": 2234545, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "00f7c36e-b5c1-4a38-a3ff-fc7a9c4c10a8", "title": "Human Herpesvirus 8 and Interstitial Pneumonitis in an HIV-Negative Patient", "text": "【0】Human Herpesvirus 8 and Interstitial Pneumonitis in an HIV-Negative Patient\nTo the Editor:\n--------------\n\n【1】A 67-year-old woman who was negative for the human immunodeficiency virus was seen because of low-grade fever, fatigue, night sweats, and weight loss, which had been present for several weeks. Computed tomographic scanning showed massive splenomegaly, mild hepatomegaly, enlargement of pericaval and inguinal lymph nodes, and diffuse, finely reticular interstitial infiltrates with multiple nodules (1 to 1.5 cm in diameter) throughout the lung fields and most prominent at the bases. The patient underwent splenectomy, and histologic examination revealed follicular hyperplasia in the spleen and lymph nodes. Liver biopsy showed biliary cirrhosis. Multiple open-lung biopsies were performed and revealed chronic interstitial pneumonitis with marked fibrosclerosis and a lymphohistiocytic and plasma-cell infiltrate. A bone marrow biopsy revealed areas of hypoplasia with scattered lymphoid nodules.\n\n【2】After splenectomy, the patient had intermittent fever (temperature, 38.5 to 39°C) that was not responsive to antibiotic therapy and a decrease in the absolute number of CD4+ T lymphocytes (to 200 per cubic millimeter). Routine serologic testing was positive only for antibodies against nuclear, early, and viral capsid antigens of the Epstein–Barr virus (EBV). No common pathogens could be documented by standard culture methods or examination of bronchoalveolar-lavage fluid. Prednisone therapy was initiated, and the fever rapidly resolved, with subjective improvement. After two months of corticosteroid treatment, the CD4+ count had increased and there was a reduction in the number of reticulonodular infiltrates on computed tomographic examination.\n\n【3】A clonal B-cell population and a clonal EBV genome were documented in the spleen by Southern blotting. No expression of latent membrane protein 1 could be detected, but sequencing analysis revealed specific point mutations of the latent-membrane-protein oncogene, which are frequently associated with EBV-related lymphoproliferative disorders.  Unexpectedly, human herpesvirus 8 sequences were detected in two lung nodules by the polymerase chain reaction  ; these tissues were negative for other common herpesvirus sequences. Human herpesvirus 8 was not detected in either the spleen or the peripheral-blood mononuclear cells of this patient, nor in six control lung samples without organ-specific abnormalities, obtained at autopsy. The amplified human herpesvirus 8 product was identical to the prototypical sequence identified in Kaposi's sarcoma, except for one isocoding base-pair substitution at position 100. \n\n【4】Interstitial pneumonitis may be associated with cytomegalovirus and human herpesvirus 6 in the presence of immunosuppression,  as well as with EBV in rare cases of chronic infectious mononucleosis. The murine gammaherpesvirus 68 infects the lungs in animal models.  We suggest that human herpesvirus 8, a newly identified gammaherpesvirus, should be considered in the differential diagnosis of viral agents associated with interstitial pneumonitis in humans.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 16:28:10", "endTime": "2024/08/13 16:28:56", "cost": 46.573}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 00:28:56", "grab_time": "2024-08-13 00:28:09"}
{"id": 2234544, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "45d70dc7-0ff4-4fc2-8596-805307ca6875", "title": "Genetic Linkage of the Marfan Syndrome, Ectopia Lentis, and Congenital Contractural Arachnodactyly to the Fibrillin Genes on Chromosomes 15 and 5", "text": "【0】Genetic Linkage of the Marfan Syndrome, Ectopia Lentis, and Congenital Contractural Arachnodactyly to the Fibrillin Genes on Chromosomes 15 and 5\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】The large glycoprotein fibrillin is a structural component of elastin-containing microfibrils found in many tissues. The Marfan syndrome has been linked to the fibrillin gene on chromosome 15, but congenital contractural arachnodactyly, which shares some of the physical features of the syndrome, has been linked to the fibrillin gene on chromosome 5.\n\n【3】Methods.\n--------\n\n【4】Using specific markers for the fibrillin genes, we performed genetic linkage analysis in 28 families with the Marfan syndrome and 8 families with four phenotypically related disorders — congenital contractural arachnodactyly (3 families), ectopia lentis (2), mitral-valve prolapse syndrome (2), and annuloaortic ectasia (1).\n\n【5】Results.\n--------\n\n【6】Genetic linkage was established between the Marfan syndrome and only the fibrillin gene on chromosome 15, with a maximum lod score of 25.6 (odds for linkage, 10 <sup>25.6 </sup> :1). Ectopia lentis was also linked to the fibrillin gene on chromosome 15, whereas congenital contractural arachnodactyly was linked to the fibrillin gene on chromosome 5. There was no linkage of mitral-valve prolapse to the fibrillin gene on chromosome 5; studies of chromosome 15 were not informative. Annuloaortic ectasia was not linked to either fibrillin gene.\n\n【7】Conclusions.\n------------\n\n【8】The Marfan syndrome appears to be caused by mutations in a single fibrillin gene on chromosome 15. Diagnosis of the Marfan syndrome by genetic linkage and analysis is now feasible in many families. \n\n【9】Introduction\n------------\n\n【10】THE Marfan syndrome is a common genetic disorder of connective tissue, with characteristic manifestations in the musculoskeletal, cardiovascular, and ocular systems.  Recently, two independent studies  <sup>, </sup>  linked the syndrome to a fibrillin gene localized on chromosome 15.  This finding agreed with those of previous immunohistochemical and genetic-linkage studies, which implicated fibrillin in the pathogenesis of the condition  and established chromosome 15 as the location of the gene for the Marfan syndrome.  <sup><a>6 </a></sup>  More important, one of these reports described the same missense mutation in two sporadic cases of the syndrome.  Lee et al.  further substantiated this causal relation, by showing genetic linkage between another fibrillin gene mapped to chromosome 5 and congenital contractural arachnodactyly, a disorder presenting with marfanoid habitus, flexion contractures, abnormal pinnae, muscular hypoplasia, and rarely, aortic-root dilatation.  <sup>, </sup>  Fibrillin, a large glycoprotein (350 kd), is one of the structural components of the elastin-associated microfibrils. These microfibrils have been detected in a wide variety of tissues, including the suspensory ligament, periosteum, and the aortic media.  <sup>, </sup> \n\n【11】These previous findings led to two important questions: Is more than one fibrillin gene implicated in causing the Marfan syndrome? And are the fibrillin genes genetically linked to other phenotypically related disorders, such as the mitral-valve prolapse syndrome, annuloaortic ectasia, and autosomal-dominant ectopia lentis? To address these two questions, we performed genetic-linkage analysis in a large number of families with the Marfan syndrome and other phenotypically related disorders.\n\n【12】Methods\n-------\n\n【13】Clinical Studies\n----------------\n\n【14】Members of 36 mutigenerational families underwent genotyping for markers specific for the fibrillin genes on chromosomes 15 and 5. The Marfan syndrome had been diagnosed clinically in 28 families, ectopia lentis in 2, congenital contractural arachnodactyly in 3, mitral-valve prolapse syndrome in 2, and annuloaortic ectasia in 1. The families were identified by and evaluated in several centers in North America, Europe, and South Africa. The clinical diagnosis was established according to widely accepted criteria. \n\n【15】DNA Markers\n-----------\n\n【16】Two informative markers have been identified — a (TAAAA)n for the fibrillin gene on chromosome 15 (fibrillin 15) and a (GT)n for the fibrillin gene on chromosome 5 (fibrillin 5)  (n denotes the number of repeats). Genomic DNA (0.5 μg) was amplified with the use of primers specific for fibrillin 15 and fibrillin 5. These primers have been described previously  ; those for fibrillin 15 are 5′-CCTGGCTACCATTCAACTCCC-3′ and 5′-GAGTACATAGAGTGTTTTAGGG-3′, and those for fibrillin 5 are 5′-AAGGTGTTCTTTGCATGTTCACC-3′ and 5′-GTAATGTGTTCTATCTAGTTCAACG-3′. Amplification was carried out under the following conditions: denaturing at 94°C for 90 seconds, annealing at 50°C (55°C for fibrillin 5) for 150 seconds, and elongation at 72°C for 60 seconds. One primer was phosphorylated in each reaction, with gamma\\[  P\\]ATP (activity, 6000 Ci per millimole) (New England Nuclear) and T4 polynucleotide kinase (Promega). One microliter of the denatured product of the polymerase chain reaction was subjected to electrophoresis in a 7 M urea—5 percent polyacrylamide gel. The gel was exposed on x-ray film at -70°C for autoradiography.\n\n【17】In addition, 5-μg samples of genomic DNA obtained from affected family members and their relatives were digested with the restriction endonuclease _Taq_ I. The DNA fragments were separated by agarose gel electrophoresis, transferred onto a nylon filter (Zeta-bind; Kuno), and hybridized overnight to a  P-labeled 1-kb fragment of fibrillin 15 complementary DNA derived from the MF-13 clone.  After washing, the filters were exposed on x-ray film at -70°C for autoradiography. A constant band (8 kb) and two variable bands (6 kb and 5 kb) were observed.\n\n【18】All genotypes were interpreted from the autoradiograms by two independent observers and recorded in a dedicated data-entry computer program (LARMAS). \n\n【19】Genetic Analysis\n----------------\n\n【20】Linkage analysis of each disorder and its fibrillin gene marker was performed with the LIPED and LINKAGE programs.  <sup>, </sup>  The programs calculate the odds of the observed pattern of inheritance for markers linked at hypothetical distances on the chromosome map and for unlinked, randomly assorting markers. An odds ratio of more than  in favor of linkage (expressed on a logarithmic scale as a lod score of more than 3) is considered a statistically significant demonstration of linkage in humans. On the other hand, an odds ratio of less than  (or a lod score of less than -2) is agreed to exclude linkage. Confidence intervals were obtained in the usual manner (by subtracting 1 from the maximal lod score).\n\n【21】A total of 439 genotypes were obtained for fibrillin 15—(TAAAA)n, 224 for fibrillin 15— _Taq_ I, and 402 for fibrillin 5—(GT)n. The Marfan syndrome and the other disorders were defined as having full penetrance and a gene frequency of 0.0001. Family members less than five years old were excluded from the analysis. The lod scores for linkage between the Marfan syndrome and each of the two fibrillin genes were used to estimate the proportion of families whose disorders were linked to either gene or both genes, and 95 percent confidence intervals were subsequently obtained. These calculations were made with the HOMOG program . \n\n【22】Results\n-------\n\n【23】Linkage Analysis for the Marfan Syndrome\n----------------------------------------\n\n【24】Table 1. Two-Point Lod Scores for Linkage between the Disease Loci and Fibrillin Genes on Chromosomes 15 and 5 (Fibrillin 15 and Fibrillin 5). Table 2.  Table 2. Phenotypic Features and Individual Lod Scores of 28 Families with the Marfan Syndrome.\\*\n\n【25】A maximal lod score of 25.6 (the Z value when the recombination fraction \\[θ\\] was 0.00) was derived from the genotyping of the 28 families with the Marfan syndrome by means of the fibrillin 15 markers . We did not observe any recombinants between the fibrillin 15 gene and the syndrome. Ten families were not informative for either marker . The lod scores obtained for each family when θ was 0.00 are shown in Table 2 . Pairwise linkage between the Marfan syndrome and the fibrillin 5 gene gave consistently negative lod scores. Four families were not informative for the fibrillin 5 gene marker.\n\n【26】The clinical phenotype of each family with the Marfan syndrome  reflected the presence of a particular manifestation in several affected members of the family. The clinical presentation ranged from the classic involvement of three systems in most families to primarily skeletal and cardiovascular manifestations in a group of four families (Families 24 through 27, Table 2 ) and musculoskeletal and ocular manifestations in one family (Family 28). It should be noted that the degree of severity of aortic disease varied greatly; aortic dissection was found in 60 percent of the families.\n\n【27】The Test of Admixture\n---------------------\n\n【28】Analysis of two-point lod scores for linkage between the Marfan syndrome and fibrillin 15 showed that all the families were linked with this gene (100 percent; lower 95 percent confidence limit, 80 percent). A similar type of analysis for fibrillin 5 showed that there was no linkage between this gene and the syndrome (estimated upper 95 percent confidence limit, 5 percent). These estimates reflect the small positive lod score obtained from analysis for fibrillin 5 in four families linked with fibrillin 15.\n\n【29】Linkage Analysis for Ectopia Lentis\n-----------------------------------\n\n【30】Figure 1. Results of Genotyping for Two Fibrillin Gene Markers on Chromosome 15 in a Family with Ectopia Lentis.\n\n【31】The phenotype cosegregates with allele 2 of both markers (boxed area), fibrillin 15—TAAAA and fibrillin 15— _Taq_ l. The bracketed alleles have been inferred.\n\n【32】Squares denote male subjects; circles, female subjects; symbols with diagonals, deceased subjects; solid symbols, affected subjects; and open symbols, unaffected subjects.\n\n【33】Two families with ectopia lentis underwent genotyping for fibrillin 15 and fibrillin 5. The results in one family are shown in Figure 1 . The phenotype of both families was characterized by the presence of bilateral ectopia lentis and iridodonesis in all affected members without any skeletal or aortic manifestations characteristic of the Marfan syndrome. Genotyping was performed in 17 members, and a maximal lod score of 3.0 (θ = 0.00; 95 percent confidence interval, 0.00 to >0.18) was obtained with the use of fibrillin 15 . Discordant segregation with fibrillin 5 markers was observed in one family; analysis in the other family was not informative.\n\n【34】Linkage Analysis for Congenital Contractural Arachnodactyly\n-----------------------------------------------------------\n\n【35】Table 3. Phenotypic Features and Individual Lod Scores in Three Families with Congenital Contractural Arachnodactyly.\n\n【36】Three families with congenital contractural arachnodactyly underwent genotyping. The clinical phenotype of each family is shown in Table 3 ; Family 2 has been described previously.  Affected members of all three families had the characteristic abnormalities of the pinnae. The flexion contractures of the small joints tended to improve with age. There was no evidence of cardiovascular involvement in any of the three families. The results of the ophthalmologic examination of the affected members of two families were normal. Sixty-three members underwent genotyping. Pairwise linkage between congenital contractural arachnodactyly and fibrillin 5 gave a maximum lod score of 6.2 (θ = 0.00; 95 percent confidence interval, 0.00 to >0.10), and no linkage with fibrillin 15 was observed in any of the three families .\n\n【37】Linkage Analysis for Mitral-Valve Prolapse Syndrome\n---------------------------------------------------\n\n【38】The clinical phenotype of one of the two families with mitral-valve prolapse syndrome was characterized by normal height and a decreased ratio (<2 SD) of the upper to the lower body segment, echocardiographic and clinical evidence of mitral-valve prolapse, myopia, pectus deformity, and scoliosis. The phenotype of the other family was very similar, and in addition arachnodactyly was present in all affected members. Twenty-two members underwent genotyping. Analysis of both families was uninformative for the fibrillin 15 markers, and both had no evidence of linkage with the fibrillin 5 markers .\n\n【39】Linkage Analysis for Annuloaortic Ectasia\n-----------------------------------------\n\n【40】The phenotype of the family with annuloaortic ectasia was characterized by aortic-root dilatation, dissecting aneurysms, and mild generalized hypermobility of the joints. Eight members from three generations underwent genotyping. No linkage was found with either the fibrillin 15 or the fibrillin 5 gene .\n\n【41】Discussion\n----------\n\n【42】Our data show that the Marfan syndrome is genetically linked to the fibrillin gene on chromosome 15, since the maximal lod score for the families we studied (Z = 25.6 when θ = 0.00) indicates that the odds of linkage are 10 <sup>25.6 </sup> :1. In the same group of families we found no linkage with the fibrillin gene on chromosome 5. These data indicate that the Marfan syndrome is probably caused by mutations within or very close to the chromosome 15 fibrillin gene. Genetic-linkage analysis could therefore be used for diagnosis at the molecular level both prenatally and postnatally.\n\n【43】We observed marked clinical variation within and between the families we studied. It is appropriate to speculate that a variety of fibrillin 15 gene mutations will be detected among patients with the Marfan syndrome. Given the severe morbidity associated with this condition and the frequently encountered difficulty of establishing the diagnosis at an early age, a correlation between its clinical and molecular features, if established, would make the detection of a particular mutation early in life a meaningful prognostic tool.\n\n【44】Our findings suggest a genetic linkage between ectopia lentis and fibrillin 15. This observation suggests the cause of a rare genetic trait and also sheds light on the pleiotropy associated with the Marfan syndrome. Little is known about the folding of the fibrillin protein and its interactions with other molecules in the extracellular matrix of different tissues.  <sup>, </sup>  <sup>, </sup>  It appears that a specific qualitative or quantitative change in fibrillin may affect primarily the morphology of the suspensory ligament of the lens but produce no other systemic manifestations characteristic of the Marfan syndrome. This situation may be similar to that involving another structural protein, Type I collagen, in which defects in two domains of the molecule have been found in patients with osteogenesis imperfecta  and Ehlers—Danlos syndrome Type VII. \n\n【45】The results of the present study expand our previous findings of genetic linkage between congenital contractural arachnodactyly and fibrillin 5, indicated by a maximal lod score of 6.2 (θ = 0.00). Congenital contractural arachnodactyly is a mild disorder whose clinical phenotype overlaps with that of the Marfan syndrome, of which it has been considered an allelic form. Our findings demonstrate that the two conditions are caused by mutations in two different but structurally related genes located on different chromosomes.\n\n【46】The identification of different fibrillin genes coding for at least two distinct proteins  <sup>, </sup>  raises questions about the relation between the structure and function of these proteins and others found in microfibrils. Furthermore, the described causal association of two distinct, albeit phenotypically overlapping disorders with two related proteins gives credence to the concept of a family of disorders in which each is associated with a distinct gene from a gene family. With this concept in mind, we studied two other phenotypically related disorders, mitral-valve prolapse syndrome  and annuloaortic ectasia.  <sup>, </sup>  We found that the latter was not linked with either the fibrillin 15 or the fibrillin 5 gene in the family we studied and that mitral-valve prolapse was not linked with fibrillin 5. In addition to the fibrillins, a number of structural proteins have been identified in microfibrils.  <sup>, </sup>  The genes coding for these proteins are appropriate candidates for the causes of some forms of mitral-valve prolapse and annuloaortic ectasia.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-14 00:19:34", "grab_time": "2024-08-13 23:12:31"}
{"id": 2234543, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "74a44440-8dd2-4cc9-9a44-54602389fbdc", "title": "Intracoronary Bone Marrow–Derived Progenitor Cells in Acute Myocardial Infarction", "text": "【0】Intracoronary Bone Marrow–Derived Progenitor Cells in Acute Myocardial Infarction\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Pilot trials suggest that the intracoronary administration of autologous progenitor cells may improve left ventricular function after acute myocardial infarction.\n\n【3】Methods\n-------\n\n【4】In a multicenter trial, we randomly assigned 204 patients with acute myocardial infarction to receive an intracoronary infusion of progenitor cells derived from bone marrow (BMC) or placebo medium into the infarct artery 3 to 7 days after successful reperfusion therapy.\n\n【5】Results\n-------\n\n【6】At 4 months, the absolute improvement in the global left ventricular ejection fraction (LVEF) was significantly greater in the BMC group than in the placebo group (mean \\[±SD\\] increase, 5.5±7.3% vs. 3.0±6.5%; P=0.01). Patients with a baseline LVEF at or below the median value of 48.9% derived the most benefit (absolute improvement in LVEF, 5.0%; 95% confidence interval, 2.0 to 8.1). At 1 year, intracoronary infusion of BMC was associated with a reduction in the prespecified combined clinical end point of death, recurrence of myocardial infarction, and any revascularization procedure (P=0.01).\n\n【7】Conclusions\n-----------\n\n【8】Intracoronary administration of BMC is associated with improved recovery of left ventricular contractile function in patients with acute myocardial infarction. Large-scale studies are warranted to examine the potential effects of progenitor-cell administration on morbidity and mortality. \n\n【9】Introduction\n------------\n\n【10】Prompt reperfusion of the infarct-related coronary artery has considerably improved the clinical outcome in patients with acute myocardial infarction.  Although contemporary reperfusion strategies using stent implantation and aggressive inhibition of platelet aggregation have been shown to increase myocardial salvage,  improvements in global left ventricular function are rather modest, despite the use of optimal reperfusion therapy.  Heart failure that develops after infarction remains a major cause of morbidity and mortality. \n\n【11】Experimental studies suggested that intravascular or intramyocardial administration of progenitor cells derived from bone marrow (BMC) or blood may contribute to functional regeneration of infarcted myocardium and enhance neovascularization of ischemic myocardium.  Moreover, clinical pilot studies demonstrated that intracoronary infusion of progenitor cells is feasible and may improve the recovery of left ventricular contractility in patients with acute myocardial infarction.  We therefore designed a double-blind, placebo-controlled, randomized multicenter trial — the Reinfusion of Enriched Progenitor Cells and Infarct Remodeling in Acute Myocardial Infarction (REPAIR-AMI) trial — to determine whether intracoronary infusion of enriched BMC is associated with improved global left ventricular function in patients with myocardial infarction treated with state-of-the-art methods.\n\n【12】Methods\n-------\n\n【13】Study Population and Protocol\n-----------------------------\n\n【14】We enrolled the first patient in the study on April 16, 2004, and the last 4-month angiographic follow-up was performed on October 31, 2005. The definition of primary and secondary end points, as well as the prespecified subgroup analyses, have been published previously.  In brief, patients 18 to 80 years of age were eligible for the study if they had had an acute ST-elevation myocardial infarction that had been successfully reperfused by means of stent implantation and had a substantial residual left ventricular regional wall-motion abnormality (as defined by an ejection fraction ≤45% according to a visual estimate). Written informed consent was obtained within 3 days after the reperfusion therapy if the patients no longer required intravenous pressor substances or mechanical hemodynamic support. The ethics review board at each participating center approved the protocol, and the study was conducted in accordance with the Declaration of Helsinki. A total of 16 centers in Germany and 1 in Switzerland participated in this investigator-initiated trial.\n\n【15】Figure 1. Enrollment and Outcomes.\n\n【16】LVEF denotes left ventricular ejection fraction, CRP C-reactive protein, and LV left ventricular.\n\n【17】All patients underwent bone marrow aspiration 3 to 6 days after receiving reperfusion therapy for acute myocardial infarction. The bone marrow aspirate was sent by courier to the central cell-processing laboratory (Institute for Transfusion Medicine, Frankfurt, Germany), where patients were randomly assigned to receive placebo medium or BMC, and the study medication was sent back to the centers. Temperature-registering isolation boxes were used for the shipment of bone marrow aspirates and the study medication to monitor the quality of the materials during transportation. Baseline left ventricular angiography was performed at the time of intracoronary infusion of study medication and was repeated in identical projections at 4 months of follow-up . All patients undergoing bone marrow aspiration underwent randomization, and clinical follow-up started at the time of bone marrow aspiration.\n\n【18】Cell Preparation and Administration\n-----------------------------------\n\n【19】A total of 50 ml of bone marrow was aspirated into heparin-treated syringes from the iliac crest with the use of local anesthesia. The bone marrow aspirate was shipped at room temperature together with 20 ml of venous blood used to produce patients' own serum to the central cell-processing laboratory. Progenitor cells were isolated and enriched with the use of Ficoll–Hypaque centrifugation procedures.  The cell suspension consisted of a heterogeneous cell population including hematopoietic, mesenchymal, and other progenitor cells, as well as mononuclear cells. The cells were suspended in 10 ml of X VIVO 10 medium (a serum-free medium containing pharmaceutical-grade human components, Cambrex), including 2 ml of the patient's own serum. The placebo medium consisted of the 10 ml of X VIVO 10 medium, including 2 ml of the patient's own serum (without BMC). Frequencies of BMC were assessed according to the guideline of the International Society of Hematotherapy and Graft Engineering. \n\n【20】After undergoing arterial puncture, all patients received 7500 to 10,000 U of heparin, and the first 85 patients received a bolus of abciximab (0.25 mg per kilogram of body weight). Cells were infused with the use of a stop-flow technique through an over-the-wire balloon catheter (Opensail, Guidant) positioned within the segment containing the stent, as described previously. \n\n【21】Left Ventricular Angiography\n----------------------------\n\n【22】Left ventricular angiograms were obtained in identical standard projections at the time of the baseline procedure (immediately before intracoronary cell infusion) and at 4 months. An experienced investigator in a central core laboratory who was unaware of the patient's treatment assignment quantitatively analyzed the left ventricular angiograms from individual patients with the use of CMS software , as previously described.  Left ventricular ejection fraction (LVEF) and left ventricular volumes were calculated with the use of the area–length method, and regional wall motion in the infarcted zone was determined with the use of the center-line chord method. \n\n【23】End Points\n----------\n\n【24】The primary end point was the absolute change in global LVEF from baseline to 4 months, as measured by quantitative left ventricular angiography.  Secondary end points included changes in left ventricular end-diastolic and end-systolic volume and changes in regional wall motion. Prespecified subgroup analyses were conducted to determine whether there was an interaction of the primary end point with baseline LVEF and the time to intracoronary-infusion therapy. Prespecified clinical end points included major adverse events (defined as death, recurrence of myocardial infarction, or any revascularization procedure) and rehospitalization for heart failure. Other clinical events or combined end points were assessed as a post hoc analysis. Only the first event for each patient was included in the analysis. As of June 16, 2006, 1-year clinical follow-up data were available for 168 patients.\n\n【25】Statistical Analysis\n--------------------\n\n【26】Continuous variables are presented as means ±SD (unless stated otherwise). Analysis-of-variance testing was used to compare the incidence of the primary end point — the change in LVEF — between the groups. For subgroup analyses, subgroup variables were entered as effects into the univariate analysis-of-variance model to determine whether there was an interaction with the treatment assignment. An analysis-of-variance model was used to adjust for effects, and an analysis-of-covariance model was used to adjust for covariates. To estimate the treatment effect, differences in least-square means and corresponding 95% confidence intervals (CIs) were calculated on the basis of the analysis-of-variance model. All other analyses were performed in a nonparametric paired fashion with the use of the Wilcoxon signed-rank test, if not stated otherwise. Nonparametric Mann–Whitney U and Kruskal–Wallis tests were used to compare continuous with categorical variables. Categorical variables were compared with the chi-square test or Fisher's exact test, as appropriate. Spearman's correlation coefficient was used to correlate continuous data. A P value of less than 0.05 was considered to indicate statistical significance. All reported P values are two-sided. Statistical analyses were performed with SPSS software .\n\n【27】Results\n-------\n\n【28】Enrollment and Baseline Characteristics\n---------------------------------------\n\n【29】Table 1. Baseline Characteristics of the Patients and Concomitant Therapy.\n\n【30】A total of 217 patients with an acute myocardial infarction successfully reperfused by means of stent implantation gave written informed consent to participate in the trial. Of these patients, 13 were excluded before undergoing bone marrow aspiration . Of the remaining 204 patients undergoing bone marrow aspiration, 103 were randomly assigned to receive an infusion of placebo medium and 101 to receive a BMC infusion into the infarct-related coronary artery. The two groups were well matched with respect to baseline characteristics and procedural characteristics of the reperfusion therapy and concomitant pharmacologic therapy during the study . The characteristics of the BMC are provided in the Supplementary Appendix .\n\n【31】Procedural Results of Intracoronary Infusion\n--------------------------------------------\n\n【32】After bone marrow aspiration, one patient withdrew consent and one patient was excluded owing to fever and an increase in the level of C-reactive protein. No patient had bleeding complications or hematoma formation at the bone marrow puncture site. Intracoronary infusion was successful in all patients in the BMC group. In the placebo group, intracoronary infusion was not performed in three patients: in one the guidewire could not be advanced into the infarct-related artery, one had an air embolism during initial angiography before the guidewire could be advanced, and one had angiographic evidence of a thrombus in a non–infarct-related artery.\n\n【33】Quantitative Variables of Left Ventricular Function\n---------------------------------------------------\n\n【34】Baseline measurements of left ventricular function and volumes did not differ significantly between the two groups . At 4 months, paired left ventricular angiograms with adequate contrast opacification for quantitative analysis were available for 95 patients in the BMC group and 92 patients in the placebo group. Paired left ventricular angiograms were not available for the two patients in each group who died, five patients (three in the placebo group and two in the BMC group) who declined to undergo angiography at follow-up, three patients who missed one angiographic session (two patients in the placebo group and one patient in the BMC group), and one patient with left ventricular thrombus in the placebo group. In addition, in one patient in each group, poor contrast opacification precluded quantitative analysis of the left ventricular angiogram .\n\n【35】Table 2. Quantitative Measures of Left Ventricular Function.\n\n【36】Global LVEF increased from a mean of 46.9±10.4% at baseline to 49.9±13.0% at 4 months in the placebo group. In the BMC group, global LVEF increased from 48.3±9.2% to 53.8±10.2% . At 4 months, LVEF was significantly higher in the BMC group than in the placebo group (P=0.02). The absolute increase in LVEF was significantly greater in the BMC group than in the placebo group (2.5%; 95% CI, 0.5 to 4.5; P=0.01).\n\n【37】Figure 2. Effect of BMC Therapy as Compared with Placebo on the Primary End Point of the Absolute Change in the Global LVEF from Baseline to 4 Months.\n\n【38】The primary end point is shown before and after adjustment for effects according to analysis of variance (ANOVA) or analysis of covariance (ANCOVA). The large diamonds show the absolute change in LVEF, and the small diamonds show the 95% CI.\n\n【39】In order to document that the primary end point of the study was not affected by the subtle, nonsignificant differences in both baseline variables and clinical end points during follow-up between the two groups, we reanalyzed the data after adjustment for a variety of effects or covariates . None of the adjustments altered the primary finding that intracoronary administration of BMC was associated with a significantly greater increase in global LVEF than was placebo.\n\n【40】Selective analysis of the infarcted zone revealed a significantly greater improvement in regional contractility in the BMC group than in the placebo group . End-diastolic volumes slightly increased in both groups . In contrast, left ventricular end-systolic volumes remained constant in the BMC group but increased in the placebo group. The absolute change in left ventricular end-systolic volumes differed significantly between the two groups .\n\n【41】Interaction between Change in LVEF and Both Baseline LVEF and Time to Infusion\n------------------------------------------------------------------------------\n\n【42】Figure 3. Interaction between Baseline LVEF and the Absolute Change in LVEF  and between the Timing of Intracoronary Infusion of BMC or Placebo after Reperfusion Therapy and the Absolute Change in LVEF .\n\n【43】In Panel A, the P value for interaction was determined by analysis of variance. In both panels, the upper and lower edges of each box plot indicate the 25th and 75th percentiles, the “whiskers” the 10th and 90th percentiles, the solid horizontal line the median, and the dotted line the mean. All outliers are shown as individual data points. In Panel B, the P value for interaction was calculated with the use of a general linear model. The solid line in Panel B shows the regression curve for the BMC group, and the dotted line shows the regression curve for the placebo group\n\n【44】There was a significant inverse relation between baseline LVEF and the absolute change in LVEF at 4 months in the BMC group (r=−0.21, P=0.04) but not in the placebo group (r=+0.11, P=0.31). When the total patient population was dichotomized according to the median value of LVEF at baseline, there was a significant interaction between the treatment effect of the BMC infusion and the baseline LVEF (P=0.02). Among patients with a baseline LVEF at or below the median value (48.9%), patients in the BMC group had an absolute increase in LVEF that was three times that in the placebo group : 7.5±7.1% as compared with 2.5±7.7% (absolute difference, 5.0%; 95% CI, 2.0 to 8.1). Among patients with a baseline LVEF above the median, the absolute difference between groups was 0.3% (95% CI, −2.2 to 2.8), with an absolute improvement in LVEF in the placebo group of 3.7±4.6%, as compared with 4.0±7.1% in the BMC group.\n\n【45】Correlating the absolute changes in LVEF at 4 months with the time from reperfusion therapy to intracoronary infusion of BMC or placebo medium revealed a significant interaction, with a progressive increase in BMC-associated recovery of contractile function as the interval between reperfusion therapy and BMC infusion increased (P=0.01) . In fact, the beneficial effects of BMC infusion on the recovery of contractile function were confined to patients who were treated more than 4 days after infarct reperfusion. BMC infusion on day 5 or later was associated with an absolute increase in LVEF of 5.1% (95% CI, 1.7 to 8.5; absolute improvement in LVEF, 1.9±7.6% in the placebo group vs. 7.0±7.7% in the BMC group; P=0.004), whereas no benefit was observed in patients treated up to day 4 after reperfusion (treatment-associated increase in LVEF, 0.6%; 95% CI, −1.8 to 3.0; absolute improvement in LVEF, 3.9±5.4% in the placebo group vs. 4.5±6.8% in the BMC group; P=0.62). The interaction between the BMC treatment effect and the timing of the procedure (≤4 days vs. ≥5 days) was significant (P=0.03) and remained significant when baseline LVEF was also entered into the model as a covariate (P=0.04).\n\n【46】Clinical Outcomes\n-----------------\n\n【47】Table 3. Clinical Events during Follow-up.\n\n【48】Table 3 summarizes the adverse clinical events during hospitalization for acute myocardial infarction, at 4 months, and at 1 year (data were available for 168 patients as of June 16, 2006). The occurrence of the individual major adverse cardiac events of death, recurrence of myocardial infarction, and rehospitalization for heart failure did not differ significantly between the two groups during follow-up. However, the incidence of the prespecified combined clinical end point of death, recurrence of myocardial infarction, and coronary revascularization was significantly lower in the BMC group than in the placebo group . Likewise, the post hoc combined clinical end point of death, recurrence of myocardial infarction, and rehospitalization for heart failure occurred less frequently in the BMC group than in the placebo group.\n\n【49】Discussion\n----------\n\n【50】The principal finding of our study is that intracoronary administration of BMC is associated with a significant increase in the recovery of left ventricular contractile function in patients with optimally treated acute myocardial infarction. Because the results of early pilot studies were promising,  we designed a placebo-controlled, double-blind, multicenter trial in which patients with acute myocardial infarction were randomly assigned to receive an infusion of either BMC or placebo medium in the infarct-related artery within 3 to 7 days after successful reperfusion therapy and the implantation of a stent. After 4 months, the global LVEF was significantly higher in the BMC group than in the placebo group. The enhanced recovery of global left ventricular contractile function after the intracoronary administration of BMC was due to a significant reduction in the extent and magnitude of regional left ventricular dysfunction within the territory of the infarct. Thus, segments with the most severe impairment in contractility at baseline appear to derive the greatest benefit from BMC administration. Moreover, intracoronary administration of BMC abrogated left ventricular end-systolic volume expansion after the infarction. Taken together, our findings indicate that when combined with optimal reperfusion therapy (stent implantation) and state-of-the-art medical treatment, intracoronary administration of BMC enhances the recovery of global and regional left ventricular function after myocardial infarction.\n\n【51】The results of our predefined subgroup analysis generate some important hypotheses essential for designing trials that address the clinical relevance of BMC administration. The magnitude of left ventricular contractile recovery was inversely related to the baseline LVEF, confirming similar observations in the Transplantation of Progenitor Cells and Regeneration Enhancement in Acute Myocardial Infarction (TOPCARE-AMI) pilot trial.  Patients with the most severely depressed left ventricular contractile function had the greatest improvement in contractile function after the intracoronary administration of BMC. A reduced LVEF during the acute phase of myocardial infarction is the most important independent predictor of a poor outcome, even in the era of optimal reperfusion therapy with the use of stenting of the infarct-related artery.  Thus, enhanced recovery of contractile function may be beneficial specifically in patients with large infarcts and depressed left ventricular function.\n\n【52】The mechanisms involved in mediating the recovery of contractile function after the intracoronary infusion of BMC are not well understood.  The microenvironment within the infarct tissue and the timing of cell delivery may be important determinants of the incorporation and effect of BMC.  We found that an intracoronary infusion of BMC within 4 days after reperfusion therapy for acute myocardial infarction had only marginal effects on the recovery of left ventricular contractile function. This finding is in agreement with the preliminary results of a small, randomized, placebo-controlled trial in which intracoronary infusion of bone marrow–derived mononuclear progenitor cells within 24 hours after reperfusion therapy failed to improve left ventricular function in patients with acute myocardial infarction. \n\n【53】Our study was not powered to assess whether intracoronary infusion of BMC can reduce the risk of complications and death among patients with acute myocardial infarction. However, the incidence of individual adverse clinical end points tended to be lower in the BMC group than in the placebo group. Thus, the intracoronary administration of BMC appears to be safe and feasible.\n\n【54】A major limitation of our study was the exclusive use of left ventricular angiography for the serial assessment of left ventricular function. Although angiography is well suited to delineate regional contractile function, the use of magnetic resonance imaging to assess global left ventricular function would have more precisely depicted changes in the distorted geometry of the infarcted hearts.\n\n【55】In summary, after acute myocardial infarction, the intracoronary administration of BMC enhances left ventricular contractile recovery. Given the safety profile of this treatment and the beneficial effects in patients with the most severely impaired left ventricular function, large-scale studies are warranted to examine the potential effects of this novel approach on the risk of death and complications in patients with large acute myocardial infarctions and depressed left ventricular contractile function.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 16:22:52", "endTime": "2024/08/13 16:27:07", "cost": 254.729}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 00:27:07", "grab_time": "2024-08-13 00:22:51"}
{"id": 2234542, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "91dc4272-7c14-469f-bfaa-69534e1484e7", "title": "Teamwork — Part 1: Divided We Fall", "text": "【0】Teamwork — Part 1: Divided We Fall\n### Audio Interview\n\n【1】 Audio roundtable discussion on learning to foster better teams. \n\n【2】Why, when there are so many easy ways to communicate, is fragmentation of patient care more common than streamlined collaboration among clinicians? And what are the barriers to better collaboration that could improve care?", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:51:53", "endTime": "2024/08/14 15:52:01", "cost": 8.01}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 23:52:01", "grab_time": "2024-08-13 23:51:52"}
{"id": 2234541, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "f53041bb-36a5-41fa-b021-72ce5c7b2062", "title": "Case 38-2021: A 76-Year-Old Woman with Abdominal Pain, Weight Loss, and Memory Impairment", "text": "【0】Case 38-2021: A 76-Year-Old Woman with Abdominal Pain, Weight Loss, and Memory Impairment\nA 76-year-old woman presented with abdominal pain, anorexia, memory impairment, and suicidal ideation. CT of the abdomen and pelvis revealed multiple dilated, fluid-filled loops of small bowel measuring up to 4 cm in diameter, with air–fluid levels and a transition point in the right lower quadrant. The urinary porphyrin levels were elevated. A diagnosis was made.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "A diagnosis was made.", "content": "【0】Case 38-2021: A 76-Year-Old Woman with Abdominal Pain, Weight Loss, and Memory Impairment\nA 76-year-old woman presented with abdominal pain, anorexia, memory impairment, and suicidal ideation. CT of the abdomen and pelvis revealed multiple dilated, fluid-filled loops of small bowel measuring up to 4 cm in diameter, with air–fluid levels and a transition point in the right lower quadrant. The urinary porphyrin levels were elevated. A diagnosis was made.", "index": 459, "show": true, "start": 459, "end": 480, "province": ["语义有效性", "语义不完整"], "isEdit": false}], "startTime": "2024/08/13 17:00:50", "endTime": "2024/08/13 17:01:02", "cost": 11.447}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 01:01:02", "grab_time": "2024-08-13 01:00:50"}
{"id": 2234540, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "4b9961e7-63ab-4805-9e78-91accafd7e92", "title": "Reduction in Firearm Injuries during NRA Annual Conventions", "text": "【0】Reduction in Firearm Injuries during NRA Annual Conventions\nTo the Editor:\n--------------\n\n【1】Despite high rates of unintentional firearm injuries,  and recognition by the National Rifle Association (NRA) that firearm education is important,  it is often said that firearm injuries occur primarily among inexperienced users and that firearm safety comes with experience and training. To investigate this contention, we conducted a study in which we hypothesized that firearm use would decline during the dates of NRA meetings — which attract tens of thousands of members from across the United States,  including firearm owners and owners of venues where firearms are used (e.g., firing ranges and hunting grounds) — and that firearm injuries would also decline even among experienced users.\n\n【2】We identified emergency department visits and hospitalizations for firearm injuries during NRA convention dates and during identical days in the 3 weeks before and 3 weeks after NRA conventions in a national database of privately insured patients during 2007 through 2015. We estimated the rates of firearm injuries during convention dates versus control dates in a beneficiary-level multivariable linear regression of firearm injury (a binary variable) as a function of indicator variables for convention and control dates, patient age, sex, indicators for calendar week and year, and state fixed effects. We conducted subgroup analyses according to census region and state-level stratum of gun-ownership rates, hypothesizing that larger reductions in the rates of injury would occur in areas with more firearm use; according to patient sex, hypothesizing that larger reductions would occur among males, who disproportionately attend NRA meetings  ; and according to whether a convention was held in a beneficiary’s state, hypothesizing that larger reductions would occur when conventions are easier to attend. In addition, we used the National Incident-Based Reporting System to analyze the proportion of crimes involving a firearm that occurred during convention versus control dates.\n\n【3】Figure 1. Firearm Injuries among Commercially Insured Persons That Occurred on Dates of National Rifle Association (NRA) Annual Conventions and Control Dates, 2007–2015.\n\n【4】Shown are the adjusted rates of firearm injuries during convention dates versus control dates in a beneficiary-level multivariable linear regression of firearm injury as a function of indicator variables for convention and control dates, age, sex, indicators for calendar week and year (to adjust for seasonal trends), and state fixed effects. In Panel A, the adjusted estimates are from a model in which the key explanatory variable was a binary variable for NRA convention dates versus all control dates combined. In Panel B, the adjusted estimates are from a model in which the key explanatory variables were indicator variables for week relative to the NRA annual convention. In both panels, 𝙸 bars indicate 95% confidence intervals.\n\n【5】Among 75,567,650 beneficiary-period observations in the claims analysis, 14.3% occurred on NRA convention dates. The unadjusted rate of firearm injuries was lower during convention dates than during control dates (129 beneficiaries with a firearm injury among 10,883,304 persons \\[1.19 per 100,000\\] vs. 963 beneficiaries with a firearm injury among 64,683,254 persons \\[1.49 per 100,000\\]; P=0.004; relative difference, 20.1%; 95% confidence interval, 6.7 to 34.0). The findings were unaffected by adjustment for covariates .\n\n【6】Reductions in firearm injuries during convention dates were largest among men, in the South and West, in states in the highest third of gun-ownership rates, and among people who resided in the state hosting the convention. There was no difference in the proportion of crimes involving a firearm between convention and control dates.\n\n【7】These findings are consistent with reductions in firearm injuries occurring as a result of lower rates of firearm use during the brief period when many firearm owners and owners of places where firearms are used may be attending an NRA convention. Our results suggest that firearm-safety concerns and risks of injury are relevant even among experienced gun owners.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 10:59:51", "endTime": "2024/08/14 11:00:04", "cost": 13.25}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 19:00:04", "grab_time": "2024-08-13 18:59:51"}
{"id": 2234539, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "e4d58982-4b88-4fd8-9171-6cb7eece3b0a", "title": "Clinical Trial of Lamivudine in Children with Chronic Hepatitis B", "text": "【0】Clinical Trial of Lamivudine in Children with Chronic Hepatitis B\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Lamivudine therapy is effective for chronic hepatitis B infection in adults. We evaluated the efficacy and tolerability of lamivudine as a treatment for chronic infection with hepatitis B virus (HBV) in children.\n\n【3】Methods\n-------\n\n【4】Children with chronic hepatitis B were randomly assigned in a  ratio to receive either oral lamivudine (3 mg per kilogram of body weight; maximum, 100 mg) or placebo once daily for 52 weeks. The primary end point was virologic response (defined by the absence of serum hepatitis B e antigen and serum HBV DNA) at week 52 of treatment.\n\n【5】Results\n-------\n\n【6】Of the 403 children screened, 191 were randomly assigned to receive lamivudine and 97 to receive placebo. The rate of virologic response at week 52 was higher among children who received lamivudine than among those who received placebo (23 percent vs. 13 percent, P=0.04). Lamivudine therapy was well tolerated and was also associated with higher rates of seroconversion from hepatitis B e antigen to hepatitis B e antibody, normalization of alanine aminotransferase levels, and suppression of HBV DNA.\n\n【7】Conclusions\n-----------\n\n【8】In children with chronic hepatitis B, 52 weeks of treatment with lamivudine was associated with a significantly higher rate of virologic response than was placebo.\n\n【9】Introduction\n------------\n\n【10】Chronic hepatitis B is a widespread disease that affects more than 350 million people worldwide, or approximately 5 percent of the world's population.  Typically, the virus is actively replicating in infected children, as demonstrated by the presence of hepatitis B e antigen (HBeAg) in serum and high serum levels of hepatitis B virus (HBV) DNA. The course of the disease varies, and it may result in spontaneous viral clearance, prolonged latency, or progressive damage to the liver. Those who become infected early in life are at highest risk for chronic infection, cirrhosis, and hepatocellular carcinoma. \n\n【11】Therapeutic options for adults with chronic hepatitis B include the nucleoside analogue lamivudine (Epivir-HBV, GlaxoSmithKline) and the cytokine interferon alfa. Interferon alfa therapy is cumbersome to deliver, is uncomfortable to receive, and has undesirable side effects. Since the rates of success of lamivudine therapy among adults are similar to those of interferon therapy, we undertook the present study to assess the safety and efficacy of lamivudine treatment in children with chronic hepatitis B.\n\n【12】Methods\n-------\n\n【13】Study Design\n------------\n\n【14】This randomized, double-blind, placebo-controlled study was conducted between September 1998 and July 2000 at 40 centers in North America, South America, and Europe. The academic investigators actively participated in the design of the study and the interpretation of results. The sponsor held the data, but all investigators had full access to them. The writing, review, and final approval of the manuscript were performed by a committee of 11 persons, including 4 representatives from the research and development departments of GlaxoSmithKline.\n\n【15】Children who completed the trial were stratified on the basis of HBeAg status at 48 weeks and offered either open-label lamivudine treatment or observation for an additional 2 years. Data from the first six months of the open-label study are available.\n\n【16】Patients\n--------\n\n【17】Eligibility requirements included an age between 2 and 17 years at enrollment, seropositivity for hepatitis B surface antigen (HBsAg) for at least 6 months before enrollment, seropositivity for HBeAg, undetectable levels of antibody against HBeAg (anti-HBe), serum alanine aminotransferase values that were more than 1.3 times the upper limit of the normal range (but less than 500 IU per liter) for at least 3 months before enrollment, evidence of inflammation on liver biopsy,  and measurable HBV DNA in serum on branched-chain DNA assay .\n\n【18】Patients were excluded if they had received interferon within the previous 12 months or systemic antiviral agents, immunomodulatory drugs, cytotoxic agents, or corticosteroids within the previous 6 months. Patients were also excluded if they were coinfected with the human immunodeficiency virus, hepatitis C virus, or hepatitis D virus or they had decompensated liver disease, renal insufficiency, pancreatitis, a clinically significant coexisting medical illness, or other types of liver disease. Women who were pregnant or breast-feeding were excluded. Liver biopsy to determine eligibility had to have been performed within 24 months before enrollment and at least 12 months after the completion of interferon therapy (for patients who had received interferon).\n\n【19】Patients or their parents or legal guardians provided written informed consent using a form approved by the appropriate institutional review board or ethics committee. We compared lamivudine with placebo, since there were no approved treatments for chronic hepatitis B in children when the trial was initiated.\n\n【20】Treatment\n---------\n\n【21】Randomization was performed at a central location. Patients were randomly assigned (in a  ratio) to receive either lamivudine solution at a dose of 3 mg per kilogram of body weight (maximal dose, 100 mg) or a matching placebo solution orally once daily for 52 weeks. \n\n【22】Clinical and Virologic Procedures\n---------------------------------\n\n【23】Patients were assessed two, four, and eight weeks after the initiation of therapy, every eight weeks until week 48, and at week 52. Blood samples were drawn at each visit to monitor blood chemical and hematologic values. Female patients with childbearing potential were required to have a pregnancy test at every study visit. During the 52-week study, investigators and patients were unaware of the results of HBV DNA and HBsAg assays. The result of the HBeAg assay was disclosed at week 48 and used for stratification at week 52 for the follow-up study. Commercially available enzyme-linked immunoassays were used to measure HBeAg, anti-HBe, HBsAg, and antibody against HBsAg (anti-HBs) (HBe \\[rDNA\\] Enzyme Immunoassay, AxSym HBe Microparticle Enzyme Immunoassay, HBs Auszyme Enzyme Immunoassay, and Ausab Enzyme Immunoassay, respectively; all from Abbott Laboratories). All samples were analyzed at a central reference laboratory (Covance Clinical Laboratory Services); however, prothrombin times were determined at each center, and genotypic analysis for resistance mutations was performed at GlaxoSmithKline Virology Laboratories. Serum samples collected at base line and week 52 were frozen at –80°C for subsequent genotypic analysis for resistance mutations. Mutations in the YMDD (tyrosine, methionine, aspartate, and aspartate) motif of the reverse-transcriptase domain in the HBV polymerase gene were assessed by the polymerase chain reaction and restriction-fragment–length polymorphism assay. \n\n【24】An independent histopathologist who was unaware of the patients' treatment assignments assessed liver-biopsy specimens obtained before treatment using the Knodell Histologic Activity Index.  Scores for this index can range from 0 (normal) to 22 (severely abnormal) and represent the sum of four histologic components: the severity of periportal necrosis (range of scores, 0 to 10), intralobular necrosis (range of scores, 0 to 4), portal inflammation (range of scores, 0 to 4), and fibrosis (range of scores, 0 to 4).\n\n【25】Efficacy Assessments\n--------------------\n\n【26】All assessments of efficacy were based on data obtained after 52 weeks of treatment. The primary efficacy end point was virologic response, a composite measure defined by the loss of serum HBeAg and by the reduction of serum HBV DNA to undetectable levels — changes indicative of a durable remission.  Secondary end points included sustained normalization of the alanine aminotransferase values (at least two consecutive values below the upper limit of the normal range without any subsequent abnormality through the end of therapy); seroconversion from HBeAg to anti-HBe, with or without the disappearance of HBV DNA; the loss of HBeAg; the loss of HBsAg; and the absence of detectable levels of HBV DNA in serum. Follow-up liver biopsy was not part of the protocol.\n\n【27】Safety Assessments\n------------------\n\n【28】All patients were assessed for adverse events at each visit. Levels of alanine aminotransferase, albumin, bilirubin, amylase, lipase, creatine kinase, hemoglobin, white cells, neutrophils, and platelets were assessed. Weight and height were measured.\n\n【29】Statistical Analysis\n--------------------\n\n【30】All analyses were prespecified. On the basis of similar studies of adults with chronic hepatitis B, we estimated that the rates of virologic response would be 25 percent among children in the lamivudine group and 9 percent among children in the placebo group. Given these estimated response rates, we calculated that 255 patients (170 in the lamivudine group and 85 in the placebo group) would be required for the study to have 80 percent power to detect an absolute difference between groups of 17 percent at an alpha level of 0.05. This sample size would also give the study 90 percent power to identify an absolute difference between groups of 34 percent with respect to the proportion of patients with the secondary end point of sustained normalization of alanine aminotransferase values.\n\n【31】We used a modified intention-to-treat analysis, which included all patients with confirmed chronic hepatitis B who were assigned to either treatment group, to assess efficacy. For the primary end point of virologic response, as well as for the secondary end points, patients who withdrew before week 52 or for whom data were missing at week 52 were considered to have had no response. All statistical tests (chi-square, Fisher's exact, and Wilcoxon rank-sum) for comparisons between treatment groups and resulting P values were two-sided.\n\n【32】For the analysis of safety, we analyzed the data according to the treatment received. We included all patients who were randomly assigned to either treatment group and who received at least one dose of study medication.\n\n【33】We used logistic-regression models to assess whether there were treatment-related differences in the rate of virologic response after adjustment for the following base-line factors: score on the Histologic Activity Index, alanine aminotransferase level, HBV DNA level, age, sex, racial or ethnic origin, body-mass index, weight, and presence or absence of cirrhosis. Logistic regression was also used to examine the differences between groups according to whether the patients had previously received interferon therapy and whether they had YMDD-variant HBV DNA.\n\n【34】Results\n-------\n\n【35】Study Population\n----------------\n\n【36】Figure 1. Numbers of Patients Included in or Excluded from Randomization and Subsequent Analyses.\n\n【37】The numbers of patients who were screened, underwent randomization, withdrew from the study, and were analyzed are presented in Figure 1 . There were no significant differences in demographic characteristics between the treatment groups . Although at base line, the median alanine aminotransferase value (2.3 vs. 2.1 times the upper limit of the normal range) and HBV DNA level (1032 vs. 895 meq per milliliter) tended to be higher in the placebo group than in the lamivudine group, these differences were not statistically significant. Forty-five percent of the children had had no response to interferon therapy, and the proportions were similar in the lamivudine group and the placebo group (47 percent and 42 percent, respectively).\n\n【38】Pretreatment Liver Biopsy\n-------------------------\n\n【39】Table 1. Results of Liver Biopsy Performed before Treatment.\n\n【40】Evaluations of liver-biopsy specimens obtained before treatment indicated that, although the median total scores on the Histologic Activity Index and the median scores for necrosis and inflammation were similar in the two groups, the mean scores were higher in the placebo group than in the lamivudine group . The range of scores was wide in both groups, however, and some children had severe disease with clinically significant fibrosis. Three patients had cirrhosis (two assigned to receive lamivudine and one assigned to receive placebo).\n\n【41】Efficacy\n--------\n\n【42】Table 2. Efficacy of Treatment. Figure 2.  Figure 2. Median Alanine Aminotransferase Values during the 52-Week Treatment Period  and Rates of Virologic Response According to the Base-Line Alanine Aminotransferase Value .\n\n【43】A virologic response was defined by the absence of hepatitis B e antigen and hepatitis B virus DNA in serum at 52 weeks. In Panel A, not all patients were evaluated at each follow-up visit. The dotted line indicates the upper limit of alanine aminotransferase values. In Panel B, values in parentheses are the number of patients with a response and the total number of patients with a base-line alanine aminotransferase value in that range.\n\n【44】A virologic response had occurred by week 52 in 23 percent of children in the lamivudine group, as compared with 13 percent of children in the placebo group (44 of 191 vs. 12 of 95; odds ratio, 2.1; 95 percent confidence interval, 1.0 to 4.1; P=0.04) . The median time to the normalization of alanine aminotransferase levels in the lamivudine group was 24 weeks . The rate of virologic response increased with increasing base-line alanine aminotransferase values . Only 2 of the 44 patients in the lamivudine group who had a virologic response did not have detectable anti-HBe at week 52. However, in both patients, this antibody had been present at week 48 and was present again one month after treatment.\n\n【45】Table 3. Adjusted Odds Ratios for Virologic Response to Lamivudine Associated with Potential Prognostic Variables.\n\n【46】Logistic-regression analyses demonstrated that higher base-line alanine aminotransferase values and scores on the Histologic Activity Index were associated with a greater likelihood of virologic response. After adjustment for these factors, a logistic-regression model confirmed that the difference between lamivudine and placebo was significant (adjusted odds ratio, 3.89; 95 percent confidence interval, 1.66 to 9.08; P=0.002). The adjusted odds ratios and confidence intervals associated with various potential prognostic factors are presented in Table 3 . Logistic-regression analysis showed that there were no significant differences in the rates of virologic response and normalization of alanine aminotransferase values between children who had previously received interferon and those who never received interferon.\n\n【47】Safety\n------\n\n【48】The nature, incidence, and severity of adverse clinical events and abnormal laboratory values in patients receiving lamivudine were similar to those in patients receiving placebo . There were no deaths during the study. The incidence and extent of elevations in alanine aminotransferase values were similar in the two groups. In no patient was the alanine aminotransferase value elevated in association with hyperbilirubinemia or other signs of hepatic decompensation.\n\n【49】There was no significant difference between the lamivudine group and the placebo group in the change in the weight-for-age z scores from base line to week 52 (P=0.75). The median changes were 0.01 (range, –1.11 to 3.35) in the lamivudine group and 0.12 (range, –1.69 to 0.98) in the placebo group. Height-for-age z scores were calculated at the time of screening and at week 48; there was no significant difference between groups in the change in the height-for-age z score (P=0.61): the median change was 0.01 (range, –1.68 to 2.81) in the lamivudine group and 0.05 (range, –0.84 to 1.9) in the placebo group.\n\n【50】Analysis of HBV Genotypic Resistance\n------------------------------------\n\n【51】Table 4. Median Levels of Hepatitis B Virus (HBV) DNA and Alanine Aminotransferase, According to the Presence or Absence of a Mutation in the YMDD Motif.\n\n【52】Serum samples were available for genotypic analysis from 90 percent of patients in the placebo group (86 of 96) and 87 percent of patients in the lamivudine group (166 of 191) at week 52. HBV DNA from 19 percent of patients in the lamivudine group (31 of 166) had detectable codon changes at site 552 (methionine to valine or isoleucine) in the C domain of the YMDD motif of the HBV polymerase gene. Demographic characteristics were similar between patients with YMDD-variant HBV DNA and patients with the wild-type sequence. The median serum HBV DNA level tended to be higher at base line in the patients in whom the YMDD variant was present at 52 weeks . Median alanine aminotransferase values, bilirubin levels, and scores for the Histologic Activity Index were similar in these two subgroups.\n\n【53】HBeAg disappeared during the study in only one child in whom the YMDD-variant HBV DNA was present at week 52. This child had anti-HBe and normal alanine aminotransferase values at week 52. However, the median HBV DNA level in the 31 children with variant HBV was substantially lower at week 52 than at base line . Among these patients, 29 percent had HBV DNA levels at week 52 that were below the limit of detection of a conventional assay and were measurable only by the polymerase chain reaction. Ninety-one percent of patients with detectable levels of HBV DNA at week 52 (20 of 22) had levels that were lower than the base-line level. The median alanine aminotransferase value was also lower at week 52 than at base line in children with YMDD-variant HBV DNA ; the levels were normal in 45 percent (14 of 31).\n\n【54】Follow-up Study\n---------------\n\n【55】During the first six months of open-label treatment with lamivudine, a virologic response occurred in an additional 10 percent of patients (12 of 123) who had previously been assigned to receive lamivudine. Among patients who were merely observed during follow-up because they had had a virologic response in the first year of treatment, 82 percent (33 of 40) had a sustained response. Patients who had had a response to lamivudine during the first year were as likely to have a sustained response as those who had had spontaneous clearance of HBeAg and HBV DNA.\n\n【56】Discussion\n----------\n\n【57】This international study of children with chronic hepatitis B demonstrated that 52 weeks of treatment with lamivudine resulted in a higher rate of virologic response than did 52 weeks of placebo. The secondary end points of virologic response with the development of anti-HBe and undetectable levels of HBV DNA and normalization of serum alanine aminotransferase values were also more frequent in lamivudine-treated children. These results are consistent with those in adults with chronic hepatitis B. \n\n【58】The average base-line alanine aminotransferase level and Histologic Activity Index score were higher in the placebo group, the latter significantly so. Since these factors have been associated with a virologic response in this and other studies, there may have been an intrinsic bias favoring placebo that would have minimized the differential effects of lamivudine.\n\n【59】Preparations of interferon alfa have been approved for the treatment of chronic hepatitis B in children. Although generally safe and effective, interferon has substantial limitations, including the need for repeated injections for six months, undesirable side effects such as growth impairment,  and a low rate of efficacy in patients with serum HBV DNA levels above 200 pg per milliliter or only minimally elevated levels of alanine aminotransferase.  Our study included patients who had had no response to interferon therapy, and the rate of virologic response of 23 percent in the lamivudine group was similar to the rate of 26 percent reported with interferon therapy in children.  These results were achieved despite the fact that the median base-line levels of alanine aminotransferase were higher in the interferon study than in our study. As is the case with interferon, the rates of virologic response to lamivudine were higher with higher base-line levels of alanine aminotransferase.\n\n【60】The emergence of YMDD-variant HBV may reverse the response in some patients and has been considered a limitation of lamivudine therapy. This variant was detected in 19 percent of patients who received lamivudine for 52 weeks, as compared with 16 to 32 percent of adults in other studies.  In these other studies, few adults with YMDD-variant HBV had lost HBeAg after one year of treatment. In some instances, liver disease may progress with continued treatment in patients with persistent viremia who have YMDD-variant HBV. However, long-term trials have indicated that seroconversion can still occur with extended treatment and that the presence of YMDD-variant HBV DNA does not necessarily signify a complete loss of efficacy or preclude HBeAg seroconversion.  We found that the frequency of HBeAg responses was substantially lower with continued treatment but that the HBV DNA and alanine aminotransferase levels remained below base-line values in the majority of patients with YMDD-variant HBV, suggesting that the replicative ability of these viral variants was decreased.  The optimal duration of treatment in children in whom YMDD-variant HBV develops has not been established, and longer-term follow-up is warranted.\n\n【61】We found that treatment of chronic hepatitis B with lamivudine for one year is safe in children and is superior to placebo, although neither approach is highly efficacious. Efficacy may be improved by selecting patients whose alanine aminotransferase value is at least twice the upper limit of the normal range. Preliminary data suggest that virologic and biochemical responses achieved with lamivudine therapy are as durable as spontaneous responses, at least for the first six months. Although there are interim data to suggest that further therapeutic responses are achieved with longer therapy, the development of genotypic resistance may limit the benefits of extended therapy, since the long-term outcome of chronic hepatitis B in children with lamivudine-resistant mutants is unknown.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-14 00:21:51", "grab_time": "2024-08-13 23:49:51"}
{"id": 2234538, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "2b95c6c0-6d53-45f0-80a4-07a401e48cfc", "title": "An Anti-Opioid System, Courtesy of a Worm Model", "text": "【0】An Anti-Opioid System, Courtesy of a Worm Model\nA forward genetic screen using the worm _Caenorhabditis elegans_ implicated the G protein–coupled receptor 139 in suppressing signaling by the mu opioid receptor. Further experiments in mouse models suggest that antagonizing this receptor could enhance the analgesic efficacy of medicinal opioids.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:13:40", "endTime": "2024/08/14 15:13:53", "cost": 12.782}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 23:13:53", "grab_time": "2024-08-13 23:13:40"}
{"id": 2234537, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "9d2d8c2d-3303-49ff-81ed-ee8b28713a04", "title": "Ventricular Systolic Septal Thickening and Excursion in Idiopathic Hypertrophic Subaortic Stenosis", "text": "【0】Ventricular Systolic Septal Thickening and Excursion in Idiopathic Hypertrophic Subaortic Stenosis\nAbstract\n--------\n\n【1】Asymmetric septal hypertrophy has been described as the pathognomonic abnormality in idiopathic hypertrophic subaortic stenosis. It has been suggested that the ventricular septum is hypercontractile and accounts for the left ventricular outflow-tract obstruction. Twenty-nine patients with idiopathic hypertrophic subaortic stenosis were studied by cardiac ultrasound to determine the degree of systolic thickening and amplitude of excursion of the ventricular septum. In all patients septal thickening was significantly reduced from normal, with a range of 0 to 22 per cent (mean of 9.3 per cent). The excursion of the left ventricular septal echo ranged from 1 to 6 mm (mean of 4 mm) and was decreased from normal in 21 patients. Therefore, the septum does not appear to be a hypercontractile structure in this disorder. These results take issue with previously proposed pathophysiology and suggest that other hypotheses need further investigation.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 18:35:49", "endTime": "2024/08/13 18:36:35", "cost": 46.513}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 02:36:35", "grab_time": "2024-08-13 02:35:48"}
{"id": 2234536, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "aeb78b4d-6569-4bfd-8a8f-ec5e878f921b", "title": "Spinal Cord Injury — Healing from Within", "text": "【0】Spinal Cord Injury — Healing from Within\nLoss of oligodendrocytes after spinal cord injury results in demyelination and impairs the function of neurons. A recent study shows a potential strategy to replace oligodendrocytes.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:41:14", "endTime": "2024/08/14 14:41:25", "cost": 11.049}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 22:41:25", "grab_time": "2024-08-13 22:41:14"}
{"id": 2234535, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "93b7eb93-1bee-4671-b518-bab5b59a1b40", "title": "Beyond the Ebola Battle — Winning the War against Future Epidemics", "text": "【0】Beyond the Ebola Battle — Winning the War against Future Epidemics\nArticle\n-------\n\n【1】The battle to contain and ultimately defeat the Ebola epidemic of 2014–2015 has been vividly described.  Caught off guard from the start and hindered by myriad coordination, communication, and other problems, a combination of local and international teams fought back with determination, courage, and eventually the deployment of substantial resources to stem the contagion and save lives. Yet more than 11,000 people died, and local economies were brought to a halt. The battle was won, but at immense cost.\n\n【2】With the immediate crisis over, the world’s attention has moved on. Ebola has vanished from the headlines and seemingly from policymakers’ to-do lists. Attention has shifted to Zika and other competing priorities. Yet it would be a huge mistake to turn away and declare the war over, for West Africa remains vulnerable to a resurgence of Ebola. There will undoubtedly be new outbreaks; the only question is how well they will be contained.\n\n【3】The capabilities and infrastructure required to prevent, identify, and respond to infectious-disease outbreaks are well understood. They include disease surveillance and escalation, case detection and diagnosis, contact tracing and isolation, clinical care and infection control, community engagement, and communication. Yet low-income countries like Guinea, Sierra Leone, and Liberia need support to put these capacities in place and to sustain them. They have neither the money nor the human resources to do it all themselves.\n\n【4】The imperative to reinforce public health preparedness and response capabilities is not unique either to West Africa or to Ebola. Zika has revealed similar weaknesses in Latin America and the Caribbean, as has MERS (Middle Eastern respiratory syndrome) in the Middle East and Asia. But while we scramble to mobilize resources in response to new outbreaks, we skimp on building better defenses.\n\n【5】Stronger public health capabilities at a national level are the essential first line of defense against potential pandemics, as we and other members of the National Academy of Medicine Commission on a Global Health Risk Framework for the Future have argued.  The commission has called for rigorous and transparent benchmarking of such capabilities, concrete plans for filling the gaps, and adequate and sustainable financing.\n\n【6】Some observers contend that benchmarking the poorest countries is pointless, since we already know that the gaps are huge. But benchmarking will help governments and donor partners establish priorities and track progress. Transparent benchmarking will enable due credit to be given to countries that are making progress and inspire a sense of urgency about those where gaps persist. Moreover, deficiencies in pandemic preparedness extend beyond the poorest countries. Many middle-income countries fall short on this front, as do some countries with advanced economies. Benchmarking will enable civil society to hold governments accountable and will sharpen debates about domestic fiscal priorities.\n\n【7】Our commission argued that pandemic preparedness and response should be treated as an essential tenet of human and economic security, not just as a health issue, and set out the case for greater investment. Nearly 100 million people were killed in the 20th century by the “Spanish Flu” epidemic of 1918–1919 and the HIV–AIDS epidemic. Examining only direct economic costs, we estimated that annual expected losses from potential pandemics exceed $60 billion per year. Fan et al. have since provided estimates incorporating the economic costs of deaths, which range as high as $490 billion per year.  The world has grossly underinvested in efforts to prevent and mitigate infectious-disease risks, as compared with other major threats to global security. The commission proposed an investment of $4.5 billion per year — not a small sum but not out of reach, and only a fraction of what we stand to lose if we continue to neglect preparedness. The largest component of this investment, as much as $3.4 billion per year, would comprise investments in upgrading national public health systems.\n\n【8】The problem is that until the outbreak happens and people begin dying, there is limited political attraction to spending money on it; we hesitate to invest in preventing and preparing for something that may not happen. Like fire engines with flashing lights and loud sirens rushing to a conflagration, an effective response strategy can make good politics. Yet we need to invest in the equivalent of fire-retardant furnishings, strict building codes, and the installation of smoke sensors and commercial sprinkler systems. It is the painstaking building of perhaps unglamorous capabilities related to disease surveillance, diagnostics, emergency preparedness, and infection-control protocols that will save the most lives and minimize economic disruption.\n\n【9】Many of the lives lost in the Ebola epidemic in West Africa could have been saved if Guinea, Sierra Leone, and Liberia had been better prepared. We know what needs to be put in place. And though the funding requirements are substantial, the case for global security and economy is compelling: it is so much more cost-effective to invest in preparedness than to spend in response. If, in a few years, there is another Ebola outbreak that once again kills several thousand people, we will have no excuse.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:32:16", "endTime": "2024/08/14 15:32:51", "cost": 34.258}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 23:32:51", "grab_time": "2024-08-13 23:32:16"}
{"id": 2234534, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "81b640a2-fbe0-43c8-abdc-668ece6f111a", "title": "Effectiveness of Immunization against Paralytic Poliomyelitis in Nigeria", "text": "【0】Effectiveness of Immunization against Paralytic Poliomyelitis in Nigeria\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】The number of cases of paralytic poliomyelitis has declined in Nigeria since the introduction of newly licensed monovalent oral poliovirus vaccines and new techniques of vaccine delivery. Understanding the relative contribution of these vaccines and the improved coverage to the decline in incident cases is essential for future planning.\n\n【3】Methods\n-------\n\n【4】We estimated the field efficacies of monovalent type 1 oral poliovirus vaccine and trivalent oral poliovirus vaccine, using the reported number of doses received by people with poliomyelitis and by matched controls as identified in Nigeria's national surveillance database, in which 27,379 cases of acute flaccid paralysis were recorded between 2001 and 2007. Our estimates of vaccine coverage and vaccine-induced immunity were based on the number of doses received by children listed in the database who had paralysis that was not caused by poliovirus.\n\n【5】Results\n-------\n\n【6】The estimated efficacies per dose of monovalent type 1 oral poliovirus vaccine and trivalent oral poliovirus vaccine against type 1 paralytic poliomyelitis were 67% (95% confidence interval \\[CI\\], 39 to 82) and 16% (95% CI, 10 to 21), respectively, and the estimated efficacy per dose of trivalent oral poliovirus vaccine against type 3 paralytic poliomyelitis was 18% (95% CI, 9 to 26). In the northwestern region of Nigeria, which reported the majority of cases during the study period, coverage with at least one dose of vaccine increased from 59 to 78%. Between 2005 and 2007, vaccine-induced immunity levels among children under the age of 5 years more than doubled, to 56%.\n\n【7】Conclusions\n-----------\n\n【8】The higher efficacy of monovalent type 1 oral poliovirus vaccine (four times as effective as trivalent oral poliovirus vaccine) and the moderate gains in coverage dramatically increased vaccine-induced immunity against serotype 1 in northern Nigeria. Further increases in coverage in Nigerian states with infected populations are required to achieve the levels of vaccine-induced immunity associated with the sustained elimination achieved in other parts of the country.\n\n【9】Introduction\n------------\n\n【10】By 2003, the Global Polio Eradication Initiative had interrupted the transmission of indigenous wild polioviruses in all but six countries worldwide, including Nigeria.  In that year, however, the temporary suspension of all poliovirus immunization in one Nigerian state contributed to a national epidemic of poliomyelitis and the reinfection of at least 20 previously wild-type poliovirus–free countries.  Although poliovirus immunization was reinstituted within 12 months, vaccine coverage remained low across northern Nigeria, and case numbers continued to increase.\n\n【11】In early 2006, Nigerian health authorities adopted new tools and tactics to accelerate poliovirus eradication. To respond to lingering community concerns, Nigeria's national immunization days have been replaced by “immunization-plus days,” during which a range of childhood vaccinations and other health interventions are offered along with the oral poliovirus vaccine. To enhance the effectiveness of immunization contacts against types 1 and 3 paralytic poliomyelitis, trivalent oral poliovirus vaccine was replaced with monovalent oral poliovirus vaccine on a number of immunization-plus days from February 2006 to the present (type 1) and from July 2007 to the present (type 3).  In 2007, type 1 poliomyelitis cases in Nigeria fell by 86% as compared with 2006, contributing to an overall decline in poliomyelitis cases of 75% . International exportations of poliovirus also plummeted, suggesting a vast improvement in the prospects for global eradication.\n\n【12】Although both the use of monovalent type 1 oral poliovirus vaccine and the implementation of immunization-plus days are generally credited with the progress in 2007, a critical evaluation of the interventions used is essential in assessing the feasibility of completely eliminating wild-type poliovirus in Nigeria and, ultimately, the world. An estimate of the efficacy of the poliovirus vaccines is especially important in the context of the recent resurgence of cases of type 1 poliomyelitis in 2008 in northern Nigeria. We investigated the protective efficacies of monovalent type 1 oral poliovirus vaccine and trivalent oral poliovirus vaccine in Nigeria, the changes in vaccine coverage after the introduction of immunization-plus days, the resulting vaccine-induced population immunity over time, and the levels of immunity associated with local interruption of wild poliovirus in this setting. We discuss the implications of these results for the elimination of wild-type poliovirus from Nigeria.\n\n【13】Methods\n-------\n\n【14】Data Collection\n---------------\n\n【15】We identified cases of poliomyelitis in the national database maintained by the government of Nigeria, which since December 1996 has recorded all cases of acute flaccid paralysis detected and reported among children under the age of 15 years.  Acute flaccid paralysis is characterized by the rapid onset of weakness and progression to maximum severity within several days to weeks, with the absence of spasticity or other signs of disordered motor tracts in the central nervous system, such as hyperreflexia, clonus, or extensor plantar responses.  Since 2001, the quality of national surveillance for cases of acute flaccid paralysis not caused by poliovirus has exceeded the international performance standard of at least 1 case reported annually per 100,000 children.  Consequently, the cases of acute flaccid paralysis examined had reported dates of onset of paralysis between January 1, 2001, and December 31, 2007. All such cases are subject to standard clinical, epidemiologic, and laboratory investigations, including the collection of two stool samples, at least 24 hours apart, to test for wild and vaccine poliovirus. The number of doses of oral poliovirus vaccine received by each child with acute flaccid paralysis (as reported by a parent or guardian) was recorded during interviews before laboratory testing of the stool samples to ensure blinding of both parents (or other caregivers) and investigators.\n\n【16】Other data collected in the initial interviews included date of birth, date of onset of paralysis, and location of residence (administratively, Nigeria is divided into 6 zones, 37 states, and 774 local government areas). A total of 27,379 cases of acute flaccid paralysis were in the data set. The following cases were excluded from the study: those in which there was residual paralysis compatible with poliomyelitis and for which two adequate stool specimens were not available (3.0%), those in which vaccine virus was isolated from stool (5.4%), and those in which the number of vaccine doses received or the age at the onset of paralysis were not reported (9.3% and 3.9%, respectively). Consequently, a total of 21,815 cases of acute flaccid paralysis (79.7%) were included in the study .\n\n【17】A case of type 1 or type 3 poliomyelitis was defined as any case of acute flaccid paralysis with virologic confirmation of type 1 or type 3 wild poliovirus, respectively, from at least one stool sample. The sensitivity of testing for poliovirus in two stool samples was estimated with the use of published methods  . In this study, cases of acute flaccid paralysis not caused by poliovirus were defined as those in which neither wild nor vaccine-related poliovirus was isolated. Acute flaccid paralysis not caused by poliovirus may result from a range of other conditions, including the Guillain–Barré syndrome and infection with other enteroviruses.  Routine immunization coverage in Nigeria is low; nationwide in 2006, just 37% of children had received three doses of trivalent oral poliovirus vaccine by 1 year of age. Routine coverage is extremely heterogeneous nationwide and particularly low in northern states.  Most poliovirus vaccine doses are received through supplementary immunization activities, which were introduced in 1996. We therefore assumed that children received all doses of oral poliovirus vaccine through supplementary immunization activities rather than through routine immunization.\n\n【18】The number of these activities during which a child with acute flaccid paralysis was exposed to each vaccine type was calculated on the basis of the child's date of birth, age at onset of paralysis, and state of residence . The fraction of the rounds in which each vaccine type was used was multiplied by the number of reported doses received to yield an expected number of doses of each type received.  The sensitivity of the results to the assumption that all doses were received by means of supplementary immunization activities was assessed by assuming that the first three doses received by randomly chosen children in the analysis were trivalent oral poliovirus vaccine provided during routine services and that the remaining doses were provided during supplementary immunization activities and consisted of monovalent type 1 oral poliovirus vaccine, trivalent oral poliovirus vaccine, and monovalent type 3, as described above. The fraction of children assumed to have received routine trivalent oral poliovirus vaccine doses in this sensitivity analysis was based on the reported routine immunization coverage in each zone  ; the random analysis was repeated 100 times . The potency of each monovalent vaccine is equivalent to the individual components of the trivalent vaccine. Thus, a dose of monovalent type 1 oral poliovirus vaccine contains 10 <sup>6 </sup> median cell-culture infectious doses (CCID <sub>50 </sub> ), and a dose of monovalent type 3 oral poliovirus vaccine contains 10 <sup>5.8 </sup> CCID <sub>50 </sub> , as found in the trivalent formulation.\n\n【19】Surveillance includes investigation of all potential cases of vaccine-associated paralytic poliomyelitis. Among children who have received the first dose of vaccine, the incidence of vaccine-associated paralytic poliomyelitis is 1 case per 1 million children, and the incidence is much lower after subsequent doses.  The Expert Review Committee in Nigeria examines all potential cases of vaccine-associated paralytic poliomyelitis and has reported no increase in the incidence since the introduction of monovalent type 1 oral poliovirus vaccine. Analysis of the National Surveillance database, which tracks the use of standard vaccines licensed by the National Regulatory Authority of the Government of Nigeria for use in Nigeria, without potential for individual case identification, does not require institutional ethics approval. All authors vouch for the completeness and accuracy of the data reported.\n\n【20】Statistical Analysis\n--------------------\n\n【21】Two matched case–control studies (one for type 1 poliovirus, and one for type 3) were used to estimate the efficacies of the vaccines against paralytic poliomyelitis (type 2 wild poliovirus was eradicated globally in 1999). Children with poliomyelitis were matched in a  ratio with controls randomly selected from the database of children with acute flaccid paralysis not caused by poliovirus; matching was based on the age at onset of paralysis (within 6 months), the date of onset of paralysis (within 6 months), and region (same local government area). These matching criteria were chosen to maximize the number of case–control pairs while minimizing the biases that might be introduced by a failure to control for differences in exposure between cases and controls. Children with acute flaccid paralysis that was not caused by poliovirus were considered appropriate controls because all cases of acute flaccid paralysis were investigated before confirmation of poliovirus status, ensuring the blinding of investigators and parents (or guardian) during dose-reporting interviews. Conditional logistic-regression analysis of the  matched data was used to relate the log-odds of disease to the number of doses of vaccine . To assess the validity of reporting a constant efficacy per dose of vaccine, the number of doses was entered as a continuous variable and as a categorical variable in separate models, and these models were compared by means of a likelihood-ratio test. Variations in vaccine efficacy by zone and potential interactions between the vaccines were investigated. The sensitivity of the efficacy estimates to the matching criteria was also examined.\n\n【22】Vaccine coverage was estimated on the basis of the reported number of doses in cases of acute flaccid paralysis not caused by poliovirus, with cases weighted to match the underlying distribution of the population by state and single years of age.  Differences in vaccine coverage between 2005 and 2007 were tested with the use of a multinomial chi-square test . The fraction of children younger than 5 years of age who were protected by direct vaccination against type 1 paralytic poliomyelitis (vaccine-induced population immunity) was calculated from the estimated coverage with monovalent type 1 oral poliovirus vaccine and trivalent oral poliovirus vaccine and their estimated efficacies . Confidence intervals were estimated with the use of the delta method . The contribution of changes in coverage only to changes in population immunity was estimated by recalculating these levels with the assumption that trivalent oral poliovirus vaccine was used in all rounds. The correlation between the proportion of children younger than 5 years of age who were protected by vaccination in each state and the reported numbers of cases of type 1 poliomyelitis was estimated with the use of Spearman's rank-correlation coefficient.\n\n【23】Results\n-------\n\n【24】Vaccine Efficacy\n----------------\n\n【25】Table 1. Estimated Protective Efficacy of Oral Poliovirus Vaccines against Type 1 and Type 3 Paralytic Poliomyelitis in Nigeria According to Zone, 2001–2007.\n\n【26】A total of 2532 children were reported to have type 1 poliomyelitis and 1092 were reported to have type 3 poliomyelitis during the study period. Of these children, 1174 with type 1 poliomyelitis (46%) and 502 with type 3 poliomyelitis (46%) were matched with a suitable control . The estimated efficacy of trivalent oral poliovirus vaccine against paralysis from type 1 poliomyelitis across Nigeria was 16% (95% confidence interval \\[CI\\], 10 to 21) per dose, and the efficacy of monovalent type 1 oral poliovirus vaccine was 67% (95% CI, 39 to 82) per dose. The estimated efficacy of trivalent oral poliovirus vaccine against paralysis from type 3 poliomyelitis was 18% (95% CI, 9 to 26) per dose. There was insufficient use of monovalent type 3 oral poliovirus vaccine to allow the efficacy of this vaccine to be estimated reliably.\n\n【27】Vaccine efficacies did not differ significantly according to the zone of the country , nor were there significant differences when efficacies were estimated separately according to year or age . There was no evidence of an interaction between monovalent type 1 oral poliovirus vaccine and trivalent oral poliovirus vaccine in the type 1 model (P=0.82). Comparisons of the fit of the model with a constant efficacy per dose of vaccine with a model that allowed the protective efficacy to vary according to the dose number showed that a constant efficacy per dose was a reasonable assumption for both monovalent type 1 oral poliovirus vaccine and trivalent oral poliovirus vaccine (P=0.93 and P=0.085, respectively, for monovalent and trivalent oral poliovirus vaccine against type 1 paralytic poliomyelitis; P=0.36 for trivalent oral poliovirus vaccine against type 3) . These findings are consistent with the all-or-nothing mode of action of these live-virus vaccines. Tighter matching of cases and controls according to age and date at the onset of paralysis did not substantially alter the estimates of vaccine efficacy . Sensitivity analyses showed that our results were robust with respect to various assumptions regarding the number of doses received through routine immunization .\n\n【28】The estimated sensitivity of laboratory testing for wild poliovirus was 99% and 98% for types 1 and 3, respectively. The prevalence of type 1 and type 3 poliovirus among cases of acute flaccid paralysis was estimated at 9.3% and 3.9%, respectively. Therefore, the probability of misclassifying a case of acute flaccid paralysis not caused by poliovirus as a case of type 1 or type 3 poliomyelitis was 0.0011 and 0.0006, respectively.\n\n【29】Immunization Coverage and Program Effectiveness\n-----------------------------------------------\n\n【30】Table 2. Vaccine Coverage among Children with Acute Flaccid Paralysis Not Caused by Poliovirus, According to Zone and Estimated Percentage of Children Less Than 5 Years of Age Who Were Protected against Type 1 Paralytic Poliomyelitis in 2005 and 2007.\n\n【31】Significant improvements in immunization coverage were registered between 2005 (before the administration of monovalent type 1 oral poliovirus vaccine and immunization-plus days) and 2007 (after the administration of monovalent type 1 oral poliovirus vaccine and immunization-plus days) in the northwestern and northeastern zones, which reported the majority of poliomyelitis cases (P<0.001) . Coverage in the southeastern zone declined significantly between 2005 and 2007 (P<0.001) . Coverage in the three remaining zones was high, and there were no significant changes between 2005 and 2007.\n\n【32】Figure 1. Estimated Percentage of Children Younger Than 5 Years of Age Who Were Protected against Type 1 Paralytic Poliomyelitis as a Result of Direct Immunization, 2001–2007.\n\n【33】Maps of Nigeria from 2001 through 2007, with state boundaries, show the percentage of the population younger than 5 years of age protected by vaccination against type 1 paralytic poliomyelitis. Black dots represent the locations of reported cases of paralysis from type 1 poliovirus. The inset shows the boundaries of Nigeria's six administrative zones.\n\n【34】The combination of improved coverage and use of the more efficacious monovalent type 1 oral poliovirus vaccine has resulted in substantial increases in the proportion of children protected through direct immunization against type 1 paralytic poliomyelitis . In the northwestern zone, 33% of the improvement in vaccine-induced immunity between 2005 and 2007 was due to improved coverage, whereas in the southern zones of the country, the improvement in vaccine-induced immunity was solely due to the introduction of the monovalent vaccine .\n\n【35】Figure 2. Average Annual Incidence of Type 1 Paralytic Poliomyelitis According to the Estimated Percentage of Children Younger Than 5 Years of Age Who Were Protected by Direct Immunization, 2001–2007.\n\n【36】Each state contributes seven times to the incidence — once for each year from 2001 to 2007. The number of states represented in each bar is indicated above the bar. Vaccine-induced immunity for two key states in 2006 and 2007 is indicated by the arrows.\n\n【37】The estimated fraction of children who were protected against type 1 paralytic poliomyelitis strongly correlates with the reported numbers of cases of type 1 poliomyelitis . The correlation was significant in all years, rising significantly in more recent years (P=0.02) . Plotting the fraction of children younger than 5 years of age who were protected from type 1 paralytic poliomyelitis against the incidence of poliomyelitis for each year and state suggests that in some areas a level of 80% protection has been sufficient to achieve local elimination .\n\n【38】Discussion\n----------\n\n【39】This study provides estimates of the efficacy of oral poliovirus vaccines in Nigeria and the effect of these vaccines on population immunity. Although trivalent oral poliovirus vaccine was successfully used to interrupt transmission of indigenous type 1 wild polioviruses across southern Nigeria, the recently licensed monovalent type 1 oral poliovirus vaccine, with an estimated efficacy per dose that is four times that of trivalent oral poliovirus vaccine, substantially improves the prospects for accelerating elimination in northern Nigeria. Because of improvements in immunization coverage and the introduction of monovalent type 1 oral poliovirus vaccine, vaccine-induced immunity in the northwestern and northeastern zones (which reported 96% of all type 1 cases in Nigeria in 2006) more than doubled between 2005 and 2007. However, further gains in immunization coverage are required to achieve elimination, since 21% of children in the northwestern zone (where the majority of cases have occurred) still have never received a single dose of vaccine, with a further 55% having received fewer than the recommended four doses.\n\n【40】The estimated efficacy of trivalent oral poliovirus vaccine in Nigeria is similar to its efficacy in India, with the exception of the northern Indian state of Uttar Pradesh, where the substantially lower efficacy of oral poliovirus vaccines appears to be the result of a high prevalence of diarrheal and other infections that interfere with seroconversion.  The efficacy of trivalent oral poliovirus vaccine did not show significant variation across Nigeria, although case numbers in the South were limited . The efficacy of monovalent type 1 oral poliovirus vaccine is higher in northern Nigeria than in Uttar Pradesh  and is similar to rates of seroconversion after administration of monovalent type 1 oral poliovirus vaccine in other developing countries.  This finding suggests that the persistence of poliovirus in northern Nigeria is not a result of environmental conditions that can compromise vaccine efficacy, as it is in northern India.\n\n【41】The precision of our efficacy estimates could be affected by the accuracy of the reporting of oral poliovirus vaccine doses and potential differences in exposure to poliovirus between cases and controls. However, the fact that the parent (or guardian) is unaware of the poliovirus status of a child when being interviewed minimizes the risk of systematic bias in dose reporting. In addition, since controls came from the same area as case subjects, the two groups are likely to have had similar exposure to virus; indeed, efficacy estimates were robust to closer matching of case subjects with controls. Nearly 50% of case subjects were matched to a control, and the resulting exclusion of some case subjects does not appear to have introduced any bias . Perhaps more important, irrespective of the precision of the point estimate of vaccine efficacy, the calculated relative gain in efficacy for monovalent type 1 oral poliovirus vaccine as compared with trivalent oral poliovirus vaccine against type 1 paralytic poliomyelitis was robust with respect to these potential biases. Vaccine quality is unlikely to have been an issue, since temperature monitors on vaccine vials have been used nationwide since 2000 to prevent the administration of vaccine with low potency.\n\n【42】Our estimates of population immunity do not account for secondary transmission of vaccine virus, maternal antibodies in the first few months of life, or natural immunity from exposure to circulating wild poliovirus. However, they do allow a direct comparison of vaccine-induced immunity between states that have had supplementary immunization activities with different types of vaccine and variable frequency and coverage, thereby providing a good relative indication of program effectiveness. The improvements observed in vaccine coverage indicate that increases in immunity levels in northwestern Nigeria are not purely a result of the higher efficacy of monovalent type 1 oral poliovirus vaccine. Many factors probably contributed, including the introduction of immunization-plus days and other such efforts by field staff and local and national leaders to address the concerns of community leaders and parents that had contributed to the suspension of the use of oral poliovirus vaccine in 2003.\n\n【43】The encouraging findings of this study must be interpreted with caution in assessing the overall outlook for the elimination of poliovirus in Nigeria. With substantial population movements and an annual birth rate of approximately 40 births per 1000 population,  the growth of the susceptible population is considerable. Although a level of direct immunity from vaccination of approximately 30% can reduce the transmission of type 1 poliovirus in Nigeria , a level of at least 80% is required for sustained local elimination of transmission. As of 2007, some degree of control appears to have been achieved in many northern states, but considerable further improvements are still required to reach a level at which poliovirus can be eradicated . The consequences of such ongoing immunity gaps were evident in the recent emergence of a circulating vaccine-derived poliovirus in the North  and a resurgence of type 1 cases in early 2008 <sup><a>8 </a></sup> that have spread to the South. Nonetheless, giving each child in the northwestern zone just one additional dose of monovalent type 1 oral poliovirus vaccine could increase direct population immunity to more than 80% in much of this area — a substantial increase from the 56% immunity recorded in 2007.\n\n【44】India and Nigeria reported 88% of poliomyelitis cases worldwide in 2007 and are central to global eradication. In contrast with India, in northern Nigeria vaccine coverage remains a significant barrier to completing the elimination of poliovirus. The relatively high efficacy of monovalent type 1 oral poliovirus vaccine in Nigeria offers the potential for rapid eradication of type 1 poliovirus, provided that vaccination coverage continues to improve in the northern part of the country.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-14 00:18:53", "grab_time": "2024-08-13 23:02:31"}
{"id": 2234533, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "4cbeb074-9075-4d18-a220-29dbd47407c5", "title": "Renal Transplantation in Children — A Report of the North American Pediatric Renal Transplant Cooperative Study", "text": "【0】Renal Transplantation in Children — A Report of the North American Pediatric Renal Transplant Cooperative Study\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】Previous studies of renal transplantation in children have focused on the survival of grafts and patients. Little information is available about the cause of renal disease, the sources of donated organs, or children's growth after transplantation. The North American Pediatric Renal Transplant Cooperative Study was organized to identify the diseases that require transplantation and to analyze factors that affect the success of transplantation in children.\n\n【3】Methods.\n--------\n\n【4】We collected data from 73 pediatric transplantation centers from 1987 through 1990. These data included information about demographic characteristics of patients, graft function, and therapy one month after transplantation and every six months thereafter for each patient 17 years of age or younger.\n\n【5】Results.\n--------\n\n【6】Altogether, 1550 children received 1667 renal allografts during this period; 31 percent of the children were five years of age or younger. Forty-three percent of the transplanted kidneys came from a living related donor, and 57 percent from a cadaver. The two most common causes of renal disease leading to transplantation were congenital malformations of the kidneys and urinary tract (42 percent of the patients) and focal segmental glomerulosclerosis (12 percent). One year after transplantation, the rate of graft survival in recipients of a kidney from a living related donor was 89 percent; it was 80 percent after three years. For recipients of cadaver kidneys, the comparable rates were 74 percent and 62 percent, respectively (P<0.001). The best growth was observed in patients who were no more than five years old at the time of transplantation. During follow-up, 79 patients died, and cancer developed in 12 patients.\n\n【7】Conclusions.\n------------\n\n【8】The most common causes of end-stage renal disease in children and adolescents are congenital malformations of the kidneys and urinary tract and focal segmental glomerulosclerosis. The rates of graft survival at one and three years are better in children and adolescents who receive a kidney from a living related donor than in those who receive a kidney from a cadaver. \n\n【9】Introduction\n------------\n\n【10】CHRONIC renal disease in children is frequently due to a congenital renal lesion, such as aplasia or dysplasia, which leads to end-stage renal disease in early infancy. Such children have retarded growth and renal osteodystrophy. Dialysis therapy tends to exacerbate renal bone disease and leads to early epiphyseal closure. To avoid this additional injury, physicians frequently prefer to perform renal transplantation as soon as possible, even before dialysis is initiated. Because of the small number of procedures performed annually at individual centers, data on the outcome of renal transplantation in children are sparse. The North American Pediatric Renal Transplant Cooperative Study was organized in 1987 to register and follow children up to 17 years of age in the United States and Canada who receive renal allografts. This report is based on the 1550 patients who underwent 1667 transplantation procedures that were reported to the registry during its first four years of operation (1987 through 1990).\n\n【11】Methods\n-------\n\n【12】The North American Pediatric Renal Transplant Cooperative Study is made up of a clinical coordinating center, a data-coordinating center, and 73 medical centers treating children with renal disease in the United States and Canada. The data for this report, compiled in February 1991, include transplantations reported during the four preceding years. Since January 1987 each allograft received by a child or adolescent ≤17 years of age at a participating center has been reported to the study registry, along with information on graft function and therapy one month after transplantation and every six months thereafter, as described previously.  Standard univariate and multivariate statistical methods, including product—limit estimates of survival distributions, were used to analyze the data. Proportional-hazards survival models were constructed that equated an individual patient's hazard to an underlying hazard multiplied by an estimated exponentiated linear combination of risk factors. Multivariate models were scaled so that risk increased with larger values of the covariates; the relative risk for a single dichotomous risk factor is the exponentiated parameter.\n\n【13】Results\n-------\n\n【14】Characteristics of the Patients\n-------------------------------\n\n【15】Table 1. Characteristics of Pediatric Renal-Transplant Recipients, According to Year of Transplantation. Table 2.  Table 2. Characteristics of pediatric Renal-Transplant Recipients, According to Age at the Time of Transplantation.\n\n【16】Both the number of patients who received transplants during each of the four years and the number of transplantation procedures have decreased slightly each year since 1987, although a lag in reporting probably accounts for the small size of the 1990 group . The age, race, and sex distribution of the patients did not change significantly over time. The youngest patient who underwent transplantation was five months old. Among the patients five months to five years of age, 70 percent were boys; the sex ratio was more nearly equal in the two older age groups, which included 76 percent of the patients .\n\n【17】The most common causes of renal failure were congenital lesions (renal dysplasia, obstructive malformations, or both) in 42 percent of the patients and glomerulonephritis in 18 percent (including focal segmental glomerulosclerosis in 12 percent). Lupus nephritis (5 percent) and hemolytic—uremic syndrome (3 percent) were rare, and only one patient had diabetic nephropathy. Of the patients 5 years of age or younger, 46 percent had congenital lesions, whereas various forms of glomerulonephritis — such as focal segmental glomerulosclerosis, membranoproliferative glomerulonephritis, and lupus nephritis — were the most frequent causes of renal failure among those 13 to 17 years of age. Although nonwhite patients made up 31 percent of all transplant recipients, 44 percent of the patients with focal segmental glomerulosclerosis were nonwhite.\n\n【18】At the time of entry into the registry, 14 percent of the patients had just received their second or subsequent transplants, with a median of 46 months (range, 5 to 178) since the previous transplantation. Transplantation was used as initial therapy (without dialysis) in 22 percent of the patients; 34 percent of the transplants from living related donors and 12 percent of those from cadavers were received by such patients. The rate of transplantation as initial therapy was similar in all four age groups (≤1, 2 to 5, 6 to 12, and 13 to 17 years). Among the patients treated by dialysis, the median length of time from the initiation of dialysis to transplantation was 12 months (mean, 21). All native renal tissue was removed in 29 percent of the patients, and the existing grafts were removed in 62 percent of the patients who had undergone a previous transplantation.\n\n【19】Characteristics of Donors and HLA Matching\n------------------------------------------\n\n【20】The patient's parent was the source of the allograft in 624 (37 percent) of the transplantations; in 94 (6 percent) the kidney came from a sibling or other living relative. Six of the sibling donors were under 18 years of age, and three were identical twins of the patients; the youngest of these pairs of twins was 13 years old. In 949 (57 percent) of the transplantations, the kidney was obtained from a cadaver; 39 percent of the cadaver donors were 10 years of age or younger. In the case of allografts from cadavers, 82 percent were maintained with an iced electrolyte perfusion; the cold-storage times of the grafts were at least 24 hours in 56 percent of the cases and more than 48 hours in 1 percent.\n\n【21】The percentage of recipients who received transfusions of blood from the donor of the allograft decreased during the four years, from 43 percent in 1987 to 19 percent in 1990. Twenty-nine percent of the patients who received kidneys from living related donors and 53 percent of those who received cadaver kidneys received more than five transfusions of blood from unidentified donors. Among the recipients of kidneys from living related donors, 87 percent had at least one haplotype match with the donor (HLA-B and HLA-DR), whereas 12 percent had only one HLA-B or one HLA-DR antigen match. Matches of all A, B, and DR alleles occurred in only 2 percent of the cases of transplantation of a kidney from a cadaver.\n\n【22】Medication after Transplantation\n--------------------------------\n\n【23】The median doses of prednisone received by the patients were 0.31 mg per kilogram of body weight per day 6 months after transplantation and 0.19 mg per kilogram per day after 30 months. The percentage of transplant recipients who received prednisone therapy on alternate days increased from 12 percent to 36 percent during the same period. There was little change in the proportion of patients who received prednisone, cyclosporine, and azathioprine at each follow-up evaluation. The dose of azathioprine was constant throughout the study period (mean, 1.7 mg per kilogram per day); the median dose of cyclosporine was 6.1 mg per kilogram per day at 6 months and 4.1 mg per kilogram per day at 30 months. The proportion of recipients of kidneys from living related donors who received triple-drug therapy at six months increased each year; 54 percent of those who underwent transplantation in 1987 and 87 percent of those who received transplants in 1990 received all three drugs. For the recipients of kidneys from cadavers, the comparable figures were 69 percent and 81 percent. The dose of each of the three maintenance immunosuppressive medications correlated positively with age and weight, although the patients who weighed less received more medication per kilogram of body weight.\n\n【24】One month after transplantation, 72 percent of the patients were receiving antihypertensive therapy, but this percentage decreased to 53 percent at 30 months. Similarly, 59 percent initially received prophylactic antibiotic therapy, and 31 percent continued to receive it at 30 months; such treatment was more frequent among patients who had had obstructive lesions (40 percent).\n\n【25】Rejection\n---------\n\n【26】A total of 1707 episodes of rejection (defined as the initiation of antirejection therapy or graft failure due to rejection) were reported in 966 recipients, of whom 404 had 2 or more episodes of rejection (maximum, 7). Overall, half of all transplant recipients had had an episode of rejection by 66 days after transplantation (median, 187 days for recipients of grafts from living related donors and 39 days for recipients of cadaver kidneys). At the end of the second year, 40 percent of the recipients of kidneys from living related donors and 27 percent of the recipients of cadaver kidneys had not had an episode of rejection.\n\n【27】The younger patients were at no disadvantage with respect to the length of time to the first episode of rejection. The perioperative use of antithymocyte globulin—antilymphocyte globulin or OKT3 monoclonal antibody was associated with a significantly longer time to the first episode of rejection among all kidney-transplant recipients, regardless of the source of the graft. The recipients of kidneys from donors five years of age or younger had a higher relative risk of rejection (1.5; 95 percent confidence interval, 1.3 to 1.6; P<0.001) than those who received kidneys from older donors; 18 percent of the recipients of kidneys from cadaver donors five years of age or younger had had no rejection episodes after one year, as compared with 35 percent of the recipients of kidneys from donors more than five years of age.\n\n【28】Overall, 54 percent of the episodes of rejection were completely reversed, 38 percent were partially reversed, and 8 percent ended in graft failure or death. The rates of complete reversal declined with an increasing number of rejection episodes, from 62 percent for the first episode to 30 percent when four or more episodes had occurred. Treatment with antithymocyte globulin-antilymphocyte globulin or OKT3 antibody at the time of transplantation did not affect the probability that a later episode of rejection would be completely reversed. Among the 28 patients who received OKT3 antibody at the time of transplantation and again for the treatment of an episode of rejection, 18 had complete reversal and 8 partial reversal of the rejection episode. OKT3 antibody was given during 469 (27 percent) of the episodes of rejection, and intravenous methylprednisolone during 1187 (70 percent), whereas dialysis was used during 242 (14 percent) of the episodes.\n\n【29】Graft Survival\n--------------\n\n【30】Table 3. Causes of Graft Failure in Pediatric Renal-Transplant Recipients.\n\n【31】Of the 1667 grafts, 378 (23 percent) failed at some time during follow-up . Forty-nine percent of the graft failures were caused by rejection, including 26 percent caused by acute rejection episodes. In 7 percent of the patients, recurrence of the original disease resulted in graft failure; the most common recurrent disease was focal segmental glomerulosclerosis. Vascular thrombosis was the cause of graft failure in 15 percent of the cases. \n\n【32】Figure 1. Graft Survival According to Source. Table 4.  Table 4. Risk of Graft Failure in Recipients of Renal Allografts from Cadavers, Based on a Proportional-Hazards Model.\\*\n\n【33】Figure 1 shows the rates of graft survival in the recipients of kidneys from cadavers and from living related donors. Among recipients of cadaver kidneys, 74 percent of grafts survived at one year and 62 percent at three years; among recipients of kidneys from living relatives, 89 percent of the grafts survived at one year and 80 percent at three years (P<0.001). For patients who were two years old or younger at the time of transplantation and received kidneys from cadavers, the one-year graft-survival rate was only 46 percent. For all patients who received grafts from cadaver donors less than six years old, the two-year graft-survival rate rose only to 57 percent. Proportional-hazards analysis identified several factors that were associated with an increased risk of graft failure among recipients of cadaver kidneys . Among these children, 74 percent of those who did not undergo dialysis in the first week after transplantation had functional grafts at two years, as compared with 52 percent among those in whom a delay in graft function caused by acute tubular necrosis necessitated dialysis during the first week. Among children 2 to 17 years old who received kidneys from living relatives, the graft-survival rate for various age groups (2 to 5, 6 to 12, and 13 to 17 years) ranged from 81 to 85 percent. In those less than one year old at the time of transplantation, the two-year graft-survival rate was 71 percent. The only factor associated with an increased risk of graft failure in the recipients of kidneys from living related donors was acute tubular necrosis in recipients less than one year old (relative risk, 2.4; 95 percent confidence interval, 1.1 to 5.4; P<0.01).\n\n【34】Growth of Children\n------------------\n\n【35】Figure 2. Mean (±SE) Change in Standardized Height Scores for Patients with Graft Function at Each Follow-up Interval, According to Age at Transplantation.\n\n【36】Data on height at the end of each six-month period were converted to a standard-deviation score (z score) according to the following formula:\n\n【37】patient's height — height at 50th percentile for age and sex. z score =\n\n【38】standard deviation of height for age and sex\n\n【39】Standardization was achieved with the use of normative data from the National Center for Health Statistics.\n\n【40】At the time of transplantation, the mean height for all patients was 2.2 SD below the appropriate age- and sex-adjusted mean for normal children and adolescents (z score). This deficit was comparable in both sexes, although it was greater among younger patients ( — 2.8 SD for patients ≤5 years of age) and those with previous transplantations ( — 3.2 SD). The mean height scores remained relatively constant after transplantation in all but the two youngest groups of children . The recipients who were 1 year old or younger at the time of transplantation had an increase of 0.3 SD in height during the first 6 months after the procedure; this increase was 0.8 SD by the 12th month. Accelerated growth did not continue, however, and the z score for height changed little in subsequent months. An anticipated adolescent growth spurt or catchup growth was not observed during the three years of observation after transplantation. In particular, patients who were 13 years old or older at the time of transplantation had decreases in the mean z score. All but the youngest age group had increases of 1.0 SD in weight scores by the 12th month after transplantation. After two and three years, the mean weight values were comparable to those in normal children and adolescents.\n\n【41】Morbidity and Mortality\n-----------------------\n\n【42】The median length of hospitalization at the time of transplantation decreased from 19 to 16 days during the study; the median stay was 2 days longer for the recipients of cadaver kidneys than for the recipients of kidneys from living related donors. The number of hospital days after the procedure was negatively correlated with the patient's age; the median hospital stay was 24 days for children 1 year old or younger, 19 days for those 2 to 5 years old, 17 days for those 6 to 12 years old, and 15 days for those 13 to 17 years old. During the first one to five months after transplantation, 58 percent of the recipients were rehospitalized (mean duration of hospital stay, nine days), 30 percent for symptoms of rejection. Bacterial infection (12 percent), viral infection (12 percent), and hypertension requiring hospital treatment (8 percent) were the other major causes of hospitalization. Both the frequency and the length of hospitalizations decreased with increasing follow-up.\n\n【43】Cancer developed in 12 patients, of whom 6 had a lymphoproliferative disorder, 5 sarcoma, and 1 a thyroid carcinoma. Eight of the patients with cancer died, five within a month of diagnosis. Four of these 12 patients had received more than one renal allograft.\n\n【44】Seventy-nine of the patients (including the 8 with cancer) died during the study period; infection was the cause of death in 32 patients. In 38 patients the graft was reported to be functioning at the time of death. Nineteen deaths occurred within 30 days after the initial transplantation during the study period, and 10 during the first postoperative week. At two years, 95 percent of the patients who received kidneys from living related donors and 92 percent of those who received kidneys from cadavers were alive (P = 0.03). Sixteen (15 percent) of the patients one year old or younger died, nine of them with functioning grafts; they accounted for 20 percent of all deaths.\n\n【45】Discussion\n----------\n\n【46】The North American Pediatric Renal Transplant Cooperative Study was established to study systematically the effects of renal transplantation in a large population of children and adolescents and to generate data that could ultimately improve the probability of successful transplantation in such patients. The problems of the adverse effects of immunosuppression, growth deficits, and questions about the optimal timing of transplantation surgery are apparent in our results. These observations also highlight several factors affecting prognosis that are different from those in adults.\n\n【47】The geometric mean hospital stay authorized for adults undergoing renal transplantation under the Medicare system of prospective payment according to diagnosis-related groups was 15.8 days in 1987—1988 and 15.4 days in 19881989.3 The median length of the hospital stay after transplantation surgery in children was 17.6 days, but the number of hospital days was negatively correlated with the patient's age; thus, the median hospital stay for transplant recipients one year old or younger was 24.5 days.\n\n【48】In 1989 a total of 8882 renal transplantations were performed in adults, of which 1900 (21 percent) used kidneys from living related donors.  We found that 47 percent of the kidneys transplanted into children in 1989 came from living related donors; the comparable figure was 43 percent during the four years of this study. In 1983 through 1986, the European Dialysis and Transplant Association recorded 226 transplantations of kidneys from living related donors (20 percent) among 1105 transplantations in children.  Whether the proportion of renal allografts from living related donors in children in North America is high because a smaller number of kidneys from cadavers are allocated to children or because of the presence of a more altruistic attitude than that in Europe is a matter for conjecture, but the high rate could be due to the knowledge that the graft-survival rate for cadaver kidneys in children has been inferior to that for kidneys from living related donors. In this study, the 89 percent graft-survival rate at one year for kidneys from living related donors decreased to 80 percent by the third year, whereas the 74 percent one-year graft-survival rate for kidneys from cadavers decreased to 62 percent at three years.\n\n【49】An age of two years or less in the recipient, more than 24 hours of cold storage, an age of five years or less in the donor, black race, and delayed graft function due to acute tubular necrosis were associated with a lower rate of graft survival for cadaver kidneys. Almost 40 percent of all cadaver kidneys were obtained from donors under 10 years of age, with donors from 1 to 5 years old accounting for 25 percent of all such transplants. The graft-survival rate for kidneys from cadaver donors five years of age or younger was lower and the rejection rates were higher than when the donors were older. In addition, the incidence of graft thrombosis was inversely related to the age of the donor.  <sup>, </sup>  These results suggest that the current practice of transplanting kidneys from very young donors into young recipients does not lead to optimal graft survival.\n\n【50】At the time of transplantation, the mean height deficit for all the recipients exceeded 2.0 SD, with the youngest children having the greatest deficit. Deceleration of growth is more frequent than stable growth in patients undergoing peritoneal dialysis or hemodialysis.  <sup>, </sup>  The children who were one year old or younger had an acceleration of growth soon after transplantation, but this group also had the worst long-term outcome. In contrast, adolescent recipients (13 to 17 years of age) had a deceleration in growth after transplantation. Our results suggest that delaying transplantation beyond the 12th year of age for children who need a transplant is disadvantageous in terms of improvement in height. Thus, vigorous attempts should be made to allocate more kidneys to children from 2 to 12 years of age. The process of allocating kidneys from cadavers to children has been addressed by the United Network for Organ Sharing,  which now adds points for children 10 years old and younger on the waiting list. The results of this policy are not yet available.\n\n【51】An additional important result that emerges from this study relates to the role of immunosuppression after transplantation. As in adults, sequential therapy after the transplantation of a cadaver kidney is increasingly popular in children. The use of multiple drugs in children increases the risk of cancer as well as that of infection, however. Of the deaths in this study group, 45 percent were attributable to infection. The increase in triple-drug immunosuppression therapy —from 52 percent of the recipients of kidneys from living related donors in 1987 to 80 percent in 1990 —indicates the need for a study of the effects of various treatment regimens (with three drugs, two drugs, or lower doses of therapeutic agents) on graft survival and patient growth.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 10:09:07", "endTime": "2024/08/14 10:21:12", "cost": 724.926}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 18:21:12", "grab_time": "2024-08-13 18:09:06"}
{"id": 2234532, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "d95d9f4e-f0ca-4ab9-a360-4d06d1564b30", "title": "Informing the Debate about Telemedicine Reimbursement — What Do We Need to Know?", "text": "【0】Informing the Debate about Telemedicine Reimbursement — What Do We Need to Know?\n### Audio Interview\n\n【1】 Interview with Dr. Ateev Mehrotra on federal pandemic-era telemedicine policies and research that could help inform permanent regulations. \n\n【2】Short-term extensions of pandemic-era telemedicine regulations create an opportunity to answer critical questions and ensure that permanent policies will be informed by the best possible evidence.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:58:58", "endTime": "2024/08/14 14:59:10", "cost": 11.679}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 22:59:10", "grab_time": "2024-08-13 22:58:48"}
{"id": 2234531, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "d2e7c56e-536f-40ec-ab32-faa69259486e", "title": "Graphic Perspective: Screen Time", "text": "【0】Graphic Perspective: Screen Time\n*   _8_ Comments\n\n【1】Article\n-------\n\n【2】### Audio Interview\n\n【3】 Interview with Dr. Elizabeth Rourke on practicing primary care over the Internet during the Covid-19 pandemic.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:07:39", "endTime": "2024/08/14 15:08:15", "cost": 36.098}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 23:08:15", "grab_time": "2024-08-13 23:07:38"}
{"id": 2234530, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "57b1bf1d-cef0-47dc-9331-fe4da91eeb7f", "title": "Protecting Service Members in War — Non-Battle Morbidity and Command Responsibility", "text": "【0】Protecting Service Members in War — Non-Battle Morbidity and Command Responsibility\nAlthough traumatic brain injury and traumatic amputations may be signature wounds of the Afghanistan and Iraq wars, the toll on military personnel from diseases and nonbattle injuries is substantial — and largely preventable. The critical element is command support.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:51:00", "endTime": "2024/08/14 14:51:09", "cost": 9.351}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 22:51:09", "grab_time": "2024-08-13 22:51:00"}
{"id": 2234529, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "8785a815-979e-42cc-9bae-5f5dabb59e15", "title": "Fungal Infections Associated with Contaminated Methylprednisolone in Tennessee", "text": "【0】Fungal Infections Associated with Contaminated Methylprednisolone in Tennessee\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】We investigated an outbreak of fungal infections of the central nervous system that occurred among patients who received epidural or paraspinal glucocorticoid injections of preservative-free methylprednisolone acetate prepared by a single compounding pharmacy.\n\n【3】Methods\n-------\n\n【4】Case patients were defined as patients with fungal meningitis, posterior circulation stroke, spinal osteomyelitis, or epidural abscess that developed after epidural or paraspinal glucocorticoid injections. Clinical and procedure data were abstracted. A cohort analysis was performed.\n\n【5】Results\n-------\n\n【6】The median age of the 66 case patients was 69 years (range, 23 to 91). The median time from the last epidural glucocorticoid injection to symptom onset was 18 days (range, 0 to 56). Patients presented with meningitis alone (73%), the cauda equina syndrome or focal infection (15%), or posterior circulation stroke with or without meningitis (12%). Symptoms and signs included headache (in 73% of the patients), new or worsening back pain (in 50%), neurologic symptoms (in 48%), nausea (in 39%), and stiff neck (in 29%). The median cerebrospinal fluid white-cell count on the first lumbar puncture among patients who presented with meningitis, with or without stroke or focal infection, was 648 per cubic millimeter (range, 6 to 10,140), with 78% granulocytes (range, 0 to 97); the protein level was 114 mg per deciliter (range, 29 to 440); and the glucose concentration was 44 mg per deciliter (range, 12 to 121) (2.5 mmol per liter \\[range, 0.7 to 6.7\\]). A total of 22 patients had laboratory confirmation of _Exserohilum rostratum_ infection (21 patients) or _Aspergillus fumigatus_ infection (1 patient). The risk of infection increased with exposure to lot 06292012@26, older vials, higher doses, multiple procedures, and translaminar approach to epidural glucocorticoid injection. Voriconazole was used to treat 61 patients (92%); 35 patients (53%) were also treated with liposomal amphotericin B. Eight patients (12%) died, seven of whom had stroke.\n\n【7】Conclusions\n-----------\n\n【8】We describe an outbreak of fungal meningitis after epidural or paraspinal glucocorticoid injection with methylprednisolone from a single compounding pharmacy. Rapid recognition of illness and prompt initiation of therapy are important to prevent complications. \n\n【9】Introduction\n------------\n\n【10】More than 500,000 epidural glucocorticoid injections are administered in the United States each year in the Medicare population alone.  Complications after epidural glucocorticoid injections are rare; when complications do occur, the most common are epidural abscesses and meningitis due to bacterial pathogens, with the complications frequently occurring in immunosuppressed persons.  Infectious disease outbreaks associated with epidural glucocorticoid injections have rarely been reported. \n\n【11】Fungal infections of the central nervous system are also uncommon and typically occur in immunosuppressed persons. Outbreaks of fungal meningitis after epidural or spinal injection are extremely rare; an outbreak of _Exophiala dermatitidis_ meningitis in 2002 associated with contaminated methylprednisolone acetate prepared at a compounding pharmacy affected five patients.  An outbreak of _Aspergillus fumigatus_ meningitis associated with contaminated needles used for epidural anesthesia after the Indian Ocean tsunami affected five patients.  Exserohilum species are environmental fungi common in grass and soil but have rarely been identified as human pathogens. \n\n【12】We report preliminary results from Tennessee of an ongoing multistate investigation of fungal infections associated with preservative-free methylprednisolone acetate produced at a single compounding pharmacy.\n\n【13】Methods\n-------\n\n【14】Surveillance\n------------\n\n【15】The Tennessee Department of Health (TDH) conducts ongoing surveillance for health care–associated infections, including outbreaks. In response to a report of a single patient in whom aspergillus meningitis developed after a recent epidural injection, active surveillance for additional case patients was performed. Hospitals, laboratories, and medical providers performing such procedures were asked to report to the TDH all possible cases of sterile-site fungal infections after epidural injections. Pharmacy records with information on the manufacture and distribution of the implicated product were obtained, and all patients reported by medical facilities as having received potentially contaminated product were actively contacted.\n\n【16】Case Patients\n-------------\n\n【17】Case patients were defined as persons who had fungal meningitis or nonbacterial and nonviral meningitis of subacute onset, posterior circulation stroke when no cerebrospinal fluid was obtained (with no other obvious cause of stroke such as dissection of vertebral artery or cardioembolic source), or spinal or paraspinal osteomyelitis or epidural abscess at the site of injection, after an epidural or paraspinal glucocorticoid injection that was administered after May 21, 2012, in Tennessee.  Cerebrospinal fluid, isolates, and tissue obtained from clinical specimens were sent to the Centers for Disease Control and Prevention (CDC) for identification of the pathogen with the use of polymerase chain reaction (PCR) amplification of fungal DNA and genomic sequencing.  (PCR for fungal detection is a research test. The test has not been cleared or approved by the Food and Drug Administration \\[FDA\\]. The performance characteristics have not been established. The results of this test should not be used for the diagnosis, treatment, or assessment of patient health or management.)\n\n【18】For patients meeting the case definition, detailed information was obtained from medical chart reviews and interviews with the patients, their families, and physicians. Data were abstracted with the use of a standardized form that included information on demographic characteristics, symptoms, results of laboratory tests, treatment, and outcomes. For all patients who had received an epidural or paraspinal glucocorticoid injection at one of the three clinics that had received methylprednisolone from the same compounding pharmacy, information on patient characteristics, the type and date of the procedure, the personnel involved, the supplies and equipment used, and the medications administered was also collected. Since medication lot numbers were not recorded in patient clinic records, clinic protocols and invoices were evaluated to determine the probable lot used for each procedure. We determined the lots for each procedure by working back from the remaining vials in the clinic and using data collected on the volume used during each procedure. Lot assignment had to be estimated for our calculations and therefore was not considered authoritative.\n\n【19】Statistical Analysis\n--------------------\n\n【20】A cohort analysis was performed of all patients who had undergone epidural or paraspinal glucocorticoid injection procedures at a single clinic (Clinic A) since July 1, 2012, to assess for risk factors for infection. We performed analyses on both the patient and procedure level, since many patients had undergone multiple procedures. We excluded patients whose case status was under investigation. We stratified exposures according to the assigned medication lot and the vial age (defined as the number of days from lot production to injection). Patient age was analyzed as a dichotomous variable on the basis of the median age of 61 years. We evaluated the risk of infection by developing a logistic-regression model that included the age and sex of the patient, the cumulative dose of methylprednisolone according to the vial age (in 15-day increments) and lot, the procedure approach (translaminar vs. other), and the use or nonuse of contrast material. This model excluded procedures that were performed on days on which two different lots could have been used.\n\n【21】The data were analyzed with the use of SAS software, version 9.3. Fisher's exact test or the Mantel–Haenszel chi-square statistic was used for categorical variables, and Student's t-test or Wilcoxon rank-sum test was used for continuous variables. All data were analyzed as of October 19, 2012. This investigation was considered to be a public health response and was not considered to be research that was subject to approval by an institutional review board or that required written informed consent from patients.\n\n【22】Results\n-------\n\n【23】Initial Investigation\n---------------------\n\n【24】On September 18, 2012, an astute clinician reported to the TDH a case of _A. fumigatus_ meningitis in an immunocompetent adult after an epidural glucocorticoid injection at Clinic A; this report prompted an epidemiologic investigation.  Two days later, active surveillance identified two additional cases of meningitis of unknown cause in hospitalized immunocompetent adults who had also recently received an epidural glucocorticoid injection at Clinic A; the CDC was notified of the TDH investigation. On-site review of Clinic A, which had closed voluntarily, revealed no obvious source of environmental contamination, such as recent construction or water damage, or relevant lapses in sterile technique. By September 25, a total of eight potential case patients (including the index patient) at Clinic A were identified; the patients had undergone epidural glucocorticoid injections on separate days and different times of the day.\n\n【25】Multiple common products had been used for all the patients. These included a commercially available epidural procedure tray, povidone–iodine, lidocaine, and single-dose vials containing 80 mg per milliliter of preservative-free methylprednisolone acetate from the New England Compounding Center (NECC, Framingham, MA). As specified in the package instructions, all products were stored at room temperature. The TDH contacted the Massachusetts Department of Health on September 24 to express concern and to obtain a distribution list of facilities that had received methylprednisolone from NECC in order to assist with enhanced case finding. On September 25, the TDH, in collaboration with the Massachusetts Department of Public Health, the Massachusetts Board of Registration in Pharmacy, and the CDC, contacted the compounding pharmacy, requested a list of facilities that had received methylprednisolone, and determined that the pharmacy had not received any reports of adverse events. The FDA was also notified about the ongoing public health investigation.\n\n【26】On September 26, 2012, NECC, in consultation with the Massachusetts Board of Registration in Pharmacy, issued a voluntary recall of the three lots of methylprednisolone that had been associated with case-patient exposure (05212012@68, 06292012@26, and 08102012@51); vials from these lots had been distributed to 76 facilities in 23 states. An analysis of Clinic A data identified no important clinic-related risk factors for infection (e.g., with respect to the day and time of the procedure, the room in which the procedure was performed, or the provider) but did indicate a relationship between increased exposure to methylprednisolone from this pharmacy and the likelihood of becoming a case patient. Active surveillance was conducted in the two additional clinics in Tennessee that had received medication from at least one of these three lots. The TDH activated emergency operations with the use of a statewide incident command structure and initiated a large-scale investigation, including personal contact and tracking of exposed patients. On October 4, 2012, the FDA announced that on microscopic examination, the agency had detected fungal contamination of unopened vials of methylprednisolone (lot 08102012@51) that had been collected from NECC. \n\n【27】Description of Case Patients\n----------------------------\n\n【28】In the three clinics in Tennessee that had received methylprednisolone from NECC, 1009 patients had received epidural or paraspinal glucocorticoid injections with methylprednisolone from one or more of the three recalled lots. A total of 66 of these patients (7%) met the case definition through October 19, 2012. In the index patient, culturing of the cerebrospinal fluid yielded _A. fumigatus;_ in 21 patients _Exserohilum rostratum_ was identified from cultures of cerebrospinal fluid, tissue, or abscess fluid (6 patients) or was detected by means of PCR in cerebrospinal fluid (14 patients) or tissue (1 patient). Although all the patients had received epidural or paraspinal glucocorticoid injections at one of three clinics in Tennessee, case patients presented in one of seven states, and 2 case patients were outside the United States, when symptoms developed.\n\n【29】Table 1. Demographic Characteristics of the Patients and Signs and Symptoms at First Admission.\n\n【30】The median age of the patients was 69 years (range 23 to 91), and 71% were women . A total of 124 procedures were performed in the 66 case patients between July 3, 2012, and September 26, 2012: 110 were lumbar epidural injections, 12 were cervical epidural injections, 1 was a sacroiliac-joint injection, and 1 was recorded as “other.” The median time from the last injection to symptom onset was 18 days (range 0 to 56). All the patients presented with one of three primary syndromes: 47 (71%) had meningitis alone, 11 (17%) had the cauda equina syndrome or focal infection near the injection site (4 of whom had documented epidural abscess), with or without meningitis, and 8 (12%) had posterior circulation stroke (with or without meningitis). Symptoms on admission included headache in 48 patients (73%), with 20 of these (43%) reporting severe headache. Other symptoms included new or worsening back pain in 33 patients (50%), nausea in 26 (39%), and stiff neck in 19 (29%).\n\n【31】Other neurologic symptoms were seen in 32 patients (48%) and included vertigo in 11 patients (17%) and new or increasing falls in 9 (14%). Ten patients (15%) had symptoms suggestive of the cauda equina syndrome: new urinary incontinence or urinary retention in 6 (9%), gluteal or radiating leg pain in 3 (5%), and saddle anesthesia in 3 (5%). Signs on admission included fever (temperature >38°C) in 4 patients (6%), nuchal rigidity in 10 (15%), and altered mental status in 5 (8%). Results of a detailed neurologic examination were not recorded for many patients.\n\n【32】Table 2. Cerebrospinal Fluid Findings from the First Lumbar Puncture among Patients with Meningitis.\n\n【33】Lumbar puncture was performed within 24 hours after hospital admission in 50 patients (76%). The median time from the last epidural glucocorticoid injection to the lumbar puncture was 25 days (range, 18 to 36). The median cerebrospinal fluid white-cell count on the first lumbar puncture among patients who presented with meningitis, with or without stroke or focal infection, was 648 per cubic millimeter (range, 6 to 10,140), with 78% granulocytes (range, 0 to 97); the protein level was 114 mg per deciliter (range, 29 to 440); and the glucose concentration was 44 mg per deciliter (range, 12 to 121) (2.5 mmol per liter \\[range, 0.7 to 6.7\\]) . The results from the first lumber puncture among patients in whom meningitis developed at any time (until October 19) are shown in Table 2 . Initial imaging results identified abnormalities possibly related to fungal infection in 8 of 27 patients (30%) who underwent magnetic resonance imaging (MRI) of the head and in 16 of 35 (46%) who underwent MRI of the spine. Abnormalities included findings consistent with arachnoiditis, neuritis, epidural abscess, psoas or paraspinal muscle abscess, ventriculitis, enhancement of the meninges, and subarachnoid hemorrhage or infarcts involving the thalamus, pons, midbrain, or cerebellum.\n\n【34】The 13 patients who had a stroke did not differ significantly from those who did not have a stroke with respect to the site of injection (lumbar, cervical, sacroiliac-joint, or other), the time from symptom onset to lumbar puncture (7 days \\[range, 0 to 43\\] and 8 days \\[range, 0 to 39\\], respectively; P=0.76), or the time from symptom onset to initiation of intravenous antifungal therapy (12 days \\[range, 0 to 44\\] and 10.5 days \\[range, 0 to 39\\], respectively; P=0.65). Eight of these 13 patients initially presented with posterior circulation stroke; of these, 4 had onset of symptoms less than 48 hours before admission. The remaining 5 patients had a posterior circulation stroke during hospitalization; none of these 5 patients had received antifungal therapy on admission. These 5 patients presented with meningitis early during the outbreak before a fungal cause was clearly established. We compared these 5 patients with the 46 patients who did not have a stroke at admission and who received antifungal therapy. There was no significant difference with respect to the median time from onset of symptoms to the initiation of intravenous antifungal therapy (12 days \\[range, 10 to 26\\] and 10.5 days \\[range, 0 to 39\\], respectively; P=0.33); however there was a significant difference in the median time from admission to initiation of intravenous antifungal therapy (6 days \\[range, 3 to 23\\] as compared with 1 day \\[range, 0 to 31\\]; P=0.006). Three patients presented with posterior circulation strokes early in the outbreak and did not undergo a lumbar puncture before death to confirm meningitis. No alternate explanation for stroke in this vascular territory was found (e.g., no cardioembolic source or evidence of dissection of vertebral artery).\n\n【35】A total of eight patients (12%) died. Seven of the eight deaths (88%) occurred in patients who had a stroke. The other patient who died initially presented after 2 weeks of having nonspecific symptoms that developed into radicular pain in a saddle distribution, headache, and fever. Imaging revealed extradural and intradural abscesses; the results of a lumbar puncture showed meningitis. He was given liposomal amphotericin B and voriconazole, with resulting improvement in cerebrospinal fluid variables but paroxysmal atrial fibrillation developed, and he had a fatal arrest.\n\n【36】Voriconazole was initially administered in 61 of the patients (92%); 35 of those patients (57%) were also treated with liposomal amphotericin B. The median time from symptom onset to initiation of voriconazole therapy was 10 days (range, 0 to 44), and the median time from symptom onset to initiation of amphotericin B therapy was 14 days (range, 0 to 44). Serum drug levels were tested in 29 of the patients who received voriconazole (48%). The median time from initiation of voriconazole therapy to the first test for serum voriconazole level was 8 days (range, 3 to 21). Initial levels were greater than 2 μg per milliliter in 24 patients (83%); of these, 7 (29%) had levels higher than 6 μg per milliliter. Treatment with liposomal amphotericin B was discontinued in 34 patients (97%) after a median of 4 days (range, 1 to 25), primarily because of renal toxic effects. In these patients, the glomerular filtration rate decreased from baseline by a median of 31% (with the change ranging from 28% to −88%).\n\n【37】Assessment of Risk Factors for Infection\n----------------------------------------\n\n【38】Clinic A used 1663 vials of methylprednisolone from the three recalled lots during the outbreak period (83% of the vials they had received). Clinic B used 189 vials (86%), and Clinic C used 211 vials (70%). For the cohort analysis, we abstracted data on 817 patients who underwent a total of 1335 procedures at Clinic A between July 1, 2012, and September 20, 2012. The procedures included 779 translaminar epidural glucocorticoid injections (23 thoracic, 146 cervical, and 610 lumbar), 368 transforaminal epidural glucocorticoid injections, 132 caudal injections, 31 facet-joint injections, 17 sacroiliac-joint injections, and 8 other injections. A patient-level cohort analysis revealed that all the patients had received methylprednisolone; no cases of fungal infection occurred among 124 persons who underwent procedures without methylprednisolone.\n\n【39】Table 3. Univariate Patient-Level Analysis of Risk Factors among Clinic A Patients with Known Case Status.\n\n【40】In a univariate analysis of patients in this cohort with known case status (including those who did not receive methylprednisolone) , patients who had multiple procedures had an increased risk of a fungal infection (11.5% \\[41 of 355 patients\\] vs. 4.0% \\[17 of 425 patients\\]; relative risk, 2.9; 95% confidence interval \\[CI\\], 1.7 to 5.0). The attack rates were 5.0%, 8.4%, 13.7%, and 14.3% among those who had undergone one, two, three, and four procedures, respectively. Patients who had received at least one epidural glucocorticoid injection with the use of a translaminar approach were more likely to become case patients than were those who had never been treated with a translaminar approach (9.6% \\[47 of 488 patients\\] vs. 3.8% \\[11 of 291 patients\\]; relative risk, 2.5; 95% CI, 1.3 to 4.8). Women were nearly twice as likely to become case patients as were men (9.5% \\[41 of 431 patients\\] vs. 4.9% \\[17 of 346 patients\\]; relative risk, 1.9; 95% CI, 1.1 to 3.4). Patients older than 60 years of age were four times as likely to become case patients as were those 60 years of age or younger (11.8% \\[47 of 400 patients\\] vs. 2.9% \\[11 of 380 patients\\]; relative risk, 4.1; 95% CI, 2.1 to 7.7). There were no significant associations between infection and factors related to physicians, technicians, operating room, operating room time, time spent with physician or technician, time of day, day of the week, or cervical versus lumbar sites.\n\n【41】Figure 1. Number of Epidural and Paraspinal Glucocorticoid Injections and Attack Rate.\n\n【42】Shown are the number of epidural and paraspinal glucocorticoid injection procedures performed in case patients, as well as the attack rates among persons who received methylprednisolone acetate from the implicated lots during these procedures. Data are shown according to 5-day time periods.\n\n【43】Among 656 persons who received methylprednisolone at Clinic A, infections developed in 58 (9%). The risk of disease among patients who had any exposure to the 06292012@26 lot was significantly greater than the risk among those who had exposure to the 05212012@68 lot or the 08102012@51 lot alone: infections developed in 51 of 424 patients (12%) who received methylprednisolone from the 06292012@26 lot as compared with 7 of 231 (3%) who had received injections from one of the other lots (relative risk, 4.0; 95% CI, 1.8 to 8.6). Figure 1 shows the attack rate on a procedure level, according to lot number, over time. Among patients receiving methylprednisolone from the 06292012@26 lot, exposure to only older vials (vial age >50 days) was associated with higher attack rates than was exposure to only newer vials, with infections developing in 29 of 149 patients exposed to methylprednisolone from older vials (19%) as compared with infections in 6 of 190 (3%) exposed to methylprednisolone from newer vials (relative risk, 6.2; 95% CI, 2.6 to 14.5). Among recipients of medication from the older vials from lot 06292012@26, the attack rates after injection of 40 to 80 mg, 120 to 160 mg, and more than 160 mg were 15% (11 of 73 patients), 19% (26 of 138), and 35% (8 of 23), respectively.\n\n【44】We performed a multivariate analysis confined to patients who received methylprednisolone with a known case status and excluded time periods of potential lot overlap. This analysis confirmed the following risk factors: age older than 60 years (adjusted odds ratio, 4.01; 95% CI, 1.95 to 8.24); female sex (adjusted odds ratio, 2.56; 95% CI, 1.29 to 5.12); and cumulative dose of 06292012@26 lot injected 45 to 60 days and more than 60 days after production, in 40-mg increments (adjusted odds ratio, 1.29; 95% CI, 1.02 to 1.63 and adjusted odds ratio 1.65; 95% CI, 1.29 to 2.11, respectively). Two factors improved the fit of the model, but were not significant: a translaminar approach (adjusted odds ratio, 2.01; 95% CI, 0.96 to 4.23) and the use of contrast material (adjusted odds ratio, 0.23; 95% CI, 0.05 to 1.14).\n\n【45】Discussion\n----------\n\n【46】The case cluster described here is part of the ongoing multistate outbreak of fungal infections associated with epidural, paraspinal, and peripheral-joint glucocorticoid injections. On October 18, the CDC and FDA announced that _E. rostratum_ had been identified in unopened vials of methylprednisolone from the 08102012@51 lot; exserohilum was also subsequently identified in the 06292012@26 lot.  The outbreak is ongoing and involves multiple states  ; morbidity and mortality have been high. Rapid recognition and evaluation of infections after a patient's exposure to implicated methylprednisolone are critical, and appropriate therapy should be initiated promptly.\n\n【47】We found a strong association between the age of the methylprednisolone vials and the rate of infection in one clinic. One possible explanation for this observation is that the level of contamination in the vials may have increased over time, with subsequent higher fungal burdens present in older vials. Injectable, preservative-free glucocorticoid preparations have been shown to be suitable media to support or increase the growth of pathogenic fungi, including _A. fumigatus._  We also describe the increased risk of infection associated with increasing amounts of methylprednisolone administered. This may reflect exposure to an increasing amount of contaminant with increased volume of methylprednisolone administered. In addition, because the medication came in 80-mg vials, multiple injections or single injections with a dose of more than 80 mg increased the likelihood of exposure to at least one contaminated vial.\n\n【48】Among the most striking features of this outbreak are the high prevalence and anatomical location of strokes. Epidural glucocorticoid injections can lead to localized infection, and fungal pathogens can invade the dura, leading to meningitis and, in some patients, invasion of the posterior circulation vasculature leading to stroke, hemorrhage, or both.  Stroke was seen more commonly early in the outbreak, with four patients presenting with stroke less than 48 hours after the onset of any symptoms. The incidence of stroke declined as diagnostic testing became more prevalent and aggressive and patients were identified earlier in their clinical course; stroke did not develop in any patients in this report in whom therapeutic doses of antifungal medications were instituted within 48 hours after the initial presentation.\n\n【49】In this series, the mortality associated with untreated _A. fumigatus_ and _E. rostratum_ meningitis was very high; all eight deaths in our series occurred in persons who received delayed, minimal, or no treatment. We found that the initial presenting symptoms were frequently mild and nonspecific and often difficult to distinguish from the chronic symptoms for which the epidural or paraspinal glucocorticoid injection was originally administered. Lumbar puncture performed promptly at the first suspicion of clinical illness allowed early identification of infection and prompt initiation of therapy.\n\n【50】Exserohilum species are environmental fungi that are common in grass and soil but have rarely been identified as human pathogens.  Although uncertainty exists about the appropriate treatment of exserohilum infections,  treatment recommendations have been developed by the CDC in response to this outbreak. These recommendations include treatment with voriconazole (at an initial dose of 6 mg per kilogram of body weight every 12 hours). The addition of liposomal amphotericin B can be considered in patients who present with severe disease or whose conditions deteriorate or do not improve with voriconazole alone.  Voriconazole can cause substantial side effects, including hepatotoxic effects, rash, central nervous system toxic effects including visual disturbances and hallucinations, prolongation of the corrected QT interval, and drug interactions.  Serum voriconazole levels can be assessed as soon as the fifth day of treatment, with a suggested therapeutic range of 2 to 5 μg per milliliter.  The use of liposomal amphotericin B was associated with decreasing renal function and early cessation of therapy in all but one of the patients in this series. Additional studies are needed to assess the best possible treatment.\n\n【51】There are several limitations of this investigation. First, the pathogen was laboratory-confirmed in only 22 patients at the time of the analysis. PCR assay was helpful in identifying the pathogen in several patients; however, the sensitivity of a fungal PCR assay is unknown. Second, there was a potential for misclassification of exposure to specific lots of medication. Third, because case patients continue to be identified, the overall estimates of risk and risk by lot may change over time. Fourth, we do not have long-term outcome data for many of the patients in this series, data that will be important in developing more definitive treatment recommendations. Fifth, our attack rates represent cumulative risk at the time of last injection; as the time from injection increases, the current risk of an infection decreases dramatically. Sixth, our analysis was conducted on data available as of October 19, 2012, and the clinical status of patients, including complications, continues to evolve. Finally, the results of the investigation in Tennessee may not be generalizable to other states because of differences in lot exposure and procedure types.\n\n【52】Pharmaceutical compounding refers to the combining, mixing, or altering of ingredients of a drug by a licensed pharmacist to produce a drug that is tailored to an individual patient's medical needs, on the basis of a valid prescription from a licensed medical practitioner. There are few reliable data on the prevalence of compounding, but it has been estimated that 0.25% to more than 2% of dispensed prescriptions in the United States are compounded drugs.  Under certain conditions, compounding may serve an important public health benefit by providing access to medications tailored to the needs of individual patients when a commercially available product is unavailable; however, compounded drugs are not approved by the FDA and should not be confused with generic drugs. Unlike brand name and generic drugs, all of which must be approved by FDA before marketing, compounded drugs are not reviewed and approved by the FDA; therefore, their safety, efficacy, quality, and conformance with federal manufacturing standards have not been established. The current outbreak is only the most recent example of deaths and serious adverse events associated with drugs made by a compounding pharmacy.  The regulatory authority of the FDA over compounding pharmacies is different and more limited than is its authority over pharmaceutical manufacturers; states license pharmacies and have primary responsibility for the oversight of the day-to-day operations of compounding pharmacies.\n\n【53】An aggressive public health response to a single report of an unusual infection resulted in the identification of a multistate outbreak of fungal infections and the rapid recall of the implicated product involved. The investigation of this outbreak in Tennessee required a close and collaborative approach between the public health system and the medical community. Maintaining a strong public health infrastructure is critical to ensuring that there is capacity to investigate such outbreaks quickly and effectively.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-14 00:22:35", "grab_time": "2024-08-13 23:34:18"}
{"id": 2234528, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "11146ac9-8f72-41b7-9121-5e081ff37a2e", "title": "Pain in Sickle Cell Disease — Rates and Risk Factors", "text": "【0】Pain in Sickle Cell Disease — Rates and Risk Factors\nAbstract\n--------\n\n【1】Background and Methods.\n-----------------------\n\n【2】Acute episodes of pain are the principal symptom of sickle cell disease, but little is known about the epidemiologic features of these episodes or risk factors for them, nor is it known whether patients with high rates of such episodes die prematurely. We prospectively studied the natural history of sickle cell disease in 3578 patients ranging from newborns to persons up to 66 years old who were followed at clinical centers across the United States.\n\n【3】Results.\n--------\n\n【4】There were 12,290 episodes of pain in 18,356 patient-years. The average rate was 0.8 episode per patient-year in sickle cell anemia, 1.0 episode per patient-year in sickle β  \\-thalassemia, and 0.4 episode per patient-year in hemoglobin SC disease and sickle β <sup>+ </sup> \\-thalassemia. The rate varied widely within each of these four groups — e.g., 39 percent of patients with sickle cell anemia had no episodes of pain, and 1 percent had more than six episodes per year. The 5.2 percent of patients with 3 to 10 episodes per year had 32.9 percent of all episodes. Among patients with sickle cell anemia who were more than 20 years old, those with high rates of pain episodes tended to die earlier than those with low rates. High rates were associated with a high hematocrit and low fetal hemoglobin levels. α-Thalassemia had no effect on pain apart from its association with an increased hematocrit.\n\n【5】Conclusions.\n------------\n\n【6】The \"pain rate\" (episodes per year) is a measure of clinical severity and correlates with early death in patients with sickle cell anemia over the age of 20. Even when the fetal hemoglobin level is low, one can predict that small increments in the level may have an ameliorating effect on the pain rate and may ultimately improve survival. This outcome is particularly encouraging to investigators studying hydroxyurea and other treatments designed to increase the fetal hemoglobin level. \n\n【7】Introduction\n------------\n\n【8】PERIODIC, self-limited episodes of excruciating musculoskeletal pain punctuate the lives of patients with sickle cell disease. Often referred to as \"crises,\" these episodes are the principal cause of morbidity among these patients. Although Western observers named sickle cell anemia for its curious microscopical morphologic features, African cultures have named it for its painful episodes. In the Ga language of Ghana, for example, the disease is known as _chwechweechwe_ —\"relentless, repetitive chewing.\"  Despite the obvious importance of this clinical syndrome, we know little about its epidemiologic characteristics. Here we report the findings of the National Heart, Lung and Blood Institute's Cooperative Study of Sickle Cell Disease, in which we sought to answer questions frequently asked by patients, clinicians, and investigators: What is the incidence of the episodes of pain, what are the associated risk factors, and are patients with high rates of pain at risk for early death?\n\n【9】Methods\n-------\n\n【10】Study Population\n----------------\n\n【11】Table 1. Summary of Inclusions and Exclusions from the Study Analysis among 4082 Patients.\\*\n\n【12】The design of the study has been described elsewhere.  <sup>, </sup>  The present analysis includes 3578 patients  ranging at enrollment from newborns to persons up to 66 years old. Patients were enrolled by 23 clinical centers across the continental United States, with a broad geographic and urban—rural distribution of subjects. They were followed between 1979 and 1988 (patients entering after May 31, 1986, were excluded from this analysis); the retention rate was 74.3 percent at the end of follow-up (67.7 percent of the patients were under active study, and 6.6 percent had died). Diagnoses were assigned at the Centers for Disease Control on the basis of hemoglobin electrophoresis — i.e., a diagnosis of sickle cell anemia, sickle β  \\-thalassemia, sickle β <sup>+ </sup> \\-thalassemia, or hemoglobin SC disease. Patients without diagnoses were excluded from analysis. Alpha-gene mapping  <sup>, </sup>  was done by Stephen H. Embury at the University of California at San Francisco. Consent was obtained from the patients or their parents or legal guardians.\n\n【13】Base-Line and Steady-State Studies\n----------------------------------\n\n【14】Patients visited their centers for laboratory evaluation and physical examination at regular intervals. At entry, base-line studies included a complete blood count and measurement of urea nitrogen, creatinine, aspartate aminotransferase, alanine aminotransferase, alkaline phosphatase, and uric acid. The results analyzed in this report were obtained at entry, not during illness.\n\n【15】Acute Events\n------------\n\n【16】Patients who received acute care at hospitals not participating in the study were excluded from analysis . An episode of pain was defined as the occurrence of pain in the extremities, back, abdomen, chest, or head that lasted at least two hours, led to a clinic visit, and could not be explained except by sickle cell disease. If the patient was old enough to judge whether the pain was of the type usually associated with a crisis and reported such pain, or if a young child had irritability accompanied by pain on palpation, this was considered appropriate evidence of a crisis. This working definition excluded hand—foot syndrome, chest syndrome, right upper quadrant syndrome, and osteomyelitis, as well as any episode of pain that was treated entirely at home.\n\n【17】Statistical Analysis\n--------------------\n\n【18】### _Descriptive Statistics_\n\n【19】The \"pain rate\" was calculated by dividing the number of episodes by the number of patient-years. Episodes that occurred within a two-week period were counted as one episode. Seventy-four patients had more than 10 closely spaced episodes, making it difficult to determine an accurate pain rate because the boundaries between the end of one episode and the beginning of another were blurred. These patients were therefore formally excluded from the present analysis, but when we counted each of their bursts of closely spaced visits as a single episode, the overall results were unchanged (data not shown).\n\n【20】### _Pain and Mortality_\n\n【21】The relation between the pain rate and mortality was examined with the use of a modified product-limit approach to compare the survival of patients with different pain rates.  The resulting survival curves are analogous to life tables for patients who were alive at the age of 20. Events during the last year of follow-up were excluded from the calculation of the pain rate to avoid biasing the comparisons with premorbid changes in the pain rate. Accidents and homicides were treated as censored observations. Because of the shape of the pain rate—age curve (discussed below), data on patients who entered the study at 10 to 19 years of age were analyzed separately from the data on those who entered when 20 or older. Log-rank statistics were calculated with the 2L program of BMDP. \n\n【22】### _Modeling the Pain Rate_\n\n【23】To identify and quantitate factors that influenced the pain rate, wc used Poisson regression (with GLIM \\[Generalised Linear Interactive Modelling\\]), with correction for overdispersion.  <sup><a>9 </a></sup>  <sup><a>11 </a></sup> We included patients with sickle cell anemia whose alpha-gene status was known and excluded those under five years of age to avoid age-related changes in the complete blood count and fetal hemoglobin level. Patients for whom any covariate was missing were excluded ; data on them were compared with data on the patients included for modeling, and a t-test showed that their average pain rates were not significantly different (data not shown). Patients with a hemoglobin level above 7 mmol per liter ( 11 g per deciliter) were considered to be potentially misclassified and were therefore excluded. The confounding variables were age, sex, and clinical center. The variables considered the most important candidates for predictors were tested first (hemoglobin level, hematocrit, mean cell volume, number of red cells, percentage of fetal hemoglobin, and presence or absence of α-thalassemia). Once the significance (likelihood ratio) of these variables was determined, the rest were tested in models that included the significant terms. Variables were then sequentially removed, and terms with a significance level of 0.05 were retained to produce a final model.\n\n【24】All P values presented are two-tailed. Type I error rates were controlled with use of Bonferroni corrections. \n\n【25】Results\n-------\n\n【26】Pain Rate and Genotype\n----------------------\n\n【27】Figure 1. Distribution of Pain Rates among Patients with Sickle Syndromes.\n\n【28】r denotes the number of episodes of pain per patient-year, SS sickle cell anemia, SC hemoglobin SC disease, Sβ <sup>+ </sup> sickleβ <sup>+ </sup> \\-thalassemia, and Sβ  sickle β  \\-thalassemia.\n\n【29】Figure 1 shows the pain rates in the four hemoglobinopathy groups and the distribution of episodes among the patients within each group. We further examined the patients with sickle cell anemia who averaged 3 to 10 episodes a year and found that although they represented only 5.2 percent of the group, they accounted for 32.9 percent of episodes.\n\n【30】Sickle Cell Anemia\n------------------\n\n【31】### _Pain Rate and Age_\n\n【32】Figure 2. Age-Specific Pain Rates (Episodes per Patient-Year) among Male (Dashed Line) and Female (Solid Line) Patients with Sickle Cell Anemia. Table 2. Table 2. Distribution of Pain Rates among Patients with Sickle Cell Anemia, According to Age. Table 3.  Table 3. Trends in the Average Pain Rate in Individual Patients with Sickle Cell Anemia.\n\n【33】Figure 2 and Table 2 show the relation between the pain rate and age in the group with sickle cell anemia. Figure 2 implies that the pain rate increased as patients grew older, from 0 to 30 years, and declined thereafter. The rates for patients 20 to 29 years old were significantly higher than those for patients 0 to 9, 40 to 49, or ≥50 years old (data for Poisson regression not shown). However, this cross-sectional analysis may be misleading. To determine whether, on average, individual patients actually had worsening or improvement with time, we evaluated average individual trends in the pain rate among patients with at least six years of follow-up. Table 3 summarizes the data obtained when the pain rate in individual patients dur'ing the first three years of observation was compared with the rate during the next three or more years. Among patients less than 20 years of age, the pain rate was consistently higher during the second period than during the first period, whereas among those over 20, the rates during these periods were not significantly different (even when 5-year age categories were combined to increase the sample).\n\n【34】### _Pain and Mortality_\n\n【35】Table 4. Pain Rate and Mortality among Patients with Sickle Cell Anemia. Figure 3.  Figure 3. Survival of Patients with Sickle Cell Anemia (≥=20 Years Old at Entry) Who Had Different Pain Rates.\n\n【36】r denotes the number of episodes of pain per patient-year.\n\n【37】No relation between mortality and the pain rate was detected among patients who entered the study when 10 to 19 years of age , although the small number of deaths in this age group limited the statistical power of the analysis. Mortality did vary with the pain rate among patients more than 20 years old; it was elevated among those with the highest pain rate .\n\n【38】### _Risk Factors for Pain_\n\n【39】Table 5. Summary of Poisson Model for Pain Rate in Sickle Cell Anemia.\n\n【40】When we controlled for age, sex, and clinic, we found that of all the laboratory variables tested, only the hematocrit and the fetal hemoglobin level emerged as important risk factors for pain . The pain rate varied directly with the hematocrit and could be modeled with the equation\n\n【41】rate = exp\\[A + 0.086 (hematocrit)\\],\n\n【42】where A depends on the patient's age, fetal hemoglobin level, clinic, and sex . α-Thalassemia in itself had no influence on pain. The slight increase in the pain rate associated with α-thalassemia was attributable to the slightly higher hematocrit of patients with this hemoglobinopathy. The same direct relation between hematocrit and pain was observed whether or not α-thalassemia was present (data not shown).\n\n【43】The pain rate varied inversely with the square of the fetal hemoglobin level and could be modeled with the equation\n\n【44】rate = exp\\[B —0.0032 (fetal hemoglobin)  \\],\n\n【45】where B depends on the patient's age, hematocrit, clinic, and sex .\n\n【46】Discussion\n----------\n\n【47】Pain is the most common cause of acute morbidity in sickle cell disease and signals underlying sudden marrow ischemia or necrosis.  <sup>, </sup>  Our analysis of the epidemiology of pain in a contemporary, prospective study of 3578 patients (the Cooperative Study of Sickle Cell Disease) strengthens some previously held clinical impressions but also sheds new light on the variation in disease severity, the influence of hematologic factors on severity, and implications for survival.\n\n【48】The patients with sickle cell anemia or sickle β  \\-thalassemia had more episodes of pain  and a higher degree of anemia (data not shown) than the patients with hemoglobin SC disease or sickle β <sup>+ </sup> \\-thalassemia. These observations correlate with the tendency of hemoglobins S, C, and A to polymerize and suggest that the severity of both hemolysis and clinical vasoocclusion varies directly with the tendency toward polymerization. This pattern was evident when we compared patients with different genetic sickle syndromes, but did not apply when we compared patients within the group with sickle cell anemia.\n\n【49】Figure 1 shows how poorly the average pain rate for a diagnosis group (genotype) reflects the rates of individual patients. Each group contained many asymptomatic patients and various percentages of patients with higher pain rates. The proportion of asymptomatic patients was underestimated in this study because its subjects (except for the newborns) were recruited through hospitals and not through population-based surveys. Two important clinical points can be drawn from our data: some patients with \"mild\" syndromes (hemoglobin SC disease or sickle β <sup>+ </sup> \\-thalassemia) have a higher pain rate than some patients with the more severe syndromes (sickle cell anemia or sickle β  \\-thalassemia), and many patients, particularly children, do not seek treatment for pain at all, even those with sickle cell anemia.\n\n【50】In an average five-year period, 38.5 percent of the patients with sickle cell anemia did not seek medical attention for treatment of pain . A similar proportion of asymptomatic patients was observed by Baum and coworkers in Jamaica  and by Vichinsky and coworkers in California.  These findings may be greeted with considerable skepticism by hospital-based physicians, whose experience has suggested that most patients tend to have multiple episodes. The 38.5 percent of asymptomatic patients were \"invisible,\" and the 5.2 percent of patients who averaged 3 to 10 episodes of pain a year accounted for 32.9 percent of the episodes treated by physicians at hospitals.\n\n【51】The cross-sectional data in Figure 2 suggest that the pain rate increased until patients reached their third decade, and then declined. However, we discovered that although on average, individual patients' rates did increase with time among those under the age of 20, there was no significant trend among those 20 or older . As discussed below, a possible explanation of the observed lower pain rate among older patients is that patients over 20 with high pain rates tend to die prematurely.\n\n【52】The survival curves for patients with sickle cell anemia who were 20 years of age or older, stratified according to pain rate , demonstrated a significant relation between the pain rate and death. Patients with an average of three or more episodes per year had a higher mortality rate than those with fewer than three episodes per year. A high pain rate is a marker for early death in these young adults. We saw no correlation between pain and mortality in patients less than 20 years old, confirming the analysis of Leikin and his coworkers.  However, the relatively small number of deaths in this age group may have prevented us from finding a significant correlation.\n\n【53】The data of Powars and Chan suggest that patients with high pain rates tend to continue to have high rates even over long periods of follow-up.  Because we observed our patients for an average of only 5.13 years, we cannot answer the very important question, Will children with high pain rates have high rates as adults, and therefore be at high risk? This question is being addressed by follow-up of the original cohort of newborns in this study.\n\n【54】The large Jamaican study  and a smaller study by Lande and colleagues in California  pointed out an apparent paradox: patients with sickle cell anemia whose anemia is more severe have fewer episodes of pain. Our Poisson model (after controlling for age, sex, and fetal hemoglobin level) confirmed that the pain rate varied directly with hematocrit — an example of divergence between clinical severity and hematologic severity. The lower blood viscosity of the patients with more severe anemia may ameliorate the severity of vasoocclusion. The correlation between the hematocrit and the pain rate may have obscured the pathophysiologic importance of certain characteristics of red cells, since any property associated with a higher hematocrit may correlate with increased severity. For example, the following, logically beneficial conditions are ironically associated with high pain rates: a low percentage of dense cells,  <sup>, </sup>  a high degree of cell deformability,  <sup>, </sup>  and a low percentage of irreversibly sickled cells. \n\n【55】In our study population as well as other populations, the presence of α-thalassemia lowered the rate of hemolysis in patients with sickle cell anemia.  The slight increase in the pain rate among these patients is attributable to their higher hematocrits. When we controlled for the hematocrit, α-thalassemia did not contribute to the model for the pain rate; and when we grouped the patients according to whether they had thalassemia or not, the hematocrit was found to be a predictor of pain in each group.\n\n【56】Fetal hemoglobin has an efficient inhibitory effect on both the extent  and kinetics  of hemoglobin S polymerization. Powars and coworkers studied the effect of fetal hemoglobin on pain and determined that no ameliorative effect occurred until the fetal hemoglobin level exceeded 20 percent.  This was an unexpected finding, considering that no threshold effect on polymerization inhibition has been observed in vitro. We found (after controlling for age, sex, and hematocrit) that the fetal hemoglobin level had a strong influence on the pain rate, without a threshold effect. Increments in the fetal hemoglobin level were beneficial even when the level was low. For example, the estimates in Table 5 predict that a population of 24-year-old women with sickle cell anemia who have a hematocrit of 0.25 and a fetal hemoglobin level of 0.15 would have an average pain rate (0.7 episode per year) half that of a similar group with a fetal hemoglobin level of 0.05 (1.4 episodes per year). This difference in the average pain rate is comparable to the difference in the average pain rate between patients with sickle cell anemia and patients with hemoglobin SC disease . This observation has implications for therapy with drugs, such as hydroxyurea, that increase the production of fetal hemoglobin. The model predicts that even moderate increases in the fetal hemoglobin level can reduce the pain rate, as suggested by the clinical experience of Charache and colleagues,  and may ultimately improve survival.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 10:25:47", "endTime": "2024/08/14 10:38:59", "cost": 792.41}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 18:38:59", "grab_time": "2024-08-13 18:25:46"}
{"id": 2234527, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "36f60b3a-e00a-4178-83d6-5c1a13d150ee", "title": "Realizing the Dream of Molecularly Targeted Therapies for Cystic Fibrosis", "text": "【0】Realizing the Dream of Molecularly Targeted Therapies for Cystic Fibrosis\nArticle\n-------\n\n【1】Figure 1. Diary of Child with Cystic Fibrosis.\n\n【2】A girl with cystic fibrosis wrote this entry in her diary on Aug. 25, 1989 — the day when researchers announced identification of the first genetic mutation that causes the life-shortening rare disease. From the Office of NIH History. \n\n【3】The diary entry of an 8-year-old girl with cystic fibrosis indicates that Aug. 25, 1989, was an important day for her . That was the day the research teams at the University of Michigan and the Hospital for Sick Children, Toronto, announced the discovery of the cystic fibrosis gene and the most common mutation, a three-base deletion that results in a missing phenylalanine in codon 508 (denoted the Phe508del _CFTR_ mutation). We hoped that the gene discovery would someday lead to effective treatments for children and adults with cystic fibrosis, but we knew that would be a long road.  Now, 30 years later, that time has come. The results of a pair of phase 3 clinical trials in the _Journal_  and in a simultaneous publication in the _Lancet_  document impressive benefits from triple-drug therapy for persons with cystic fibrosis and at least one copy of the Phe508del _CFTR_ mutation, who represent approximately 90% of persons affected by this life-shortening autosomal recessive disease.\n\n【4】The journey to gene-based therapies for cystic fibrosis began with enthusiasm over the prospect of gene therapy. But the challenges of using gene transfer to achieve long-lasting correction in the airway proved daunting. Immune rejection of corrected cells emerged quickly, and clinical trials produced disappointing results.  Other approaches had to be tried. Despite the high risk of pursuing small-molecule therapy for a recessive disease, drug-development efforts were initiated in hopes of restoring the function of the protein affected by cystic fibrosis, the cystic fibrosis transmembrane conductance regulator (CFTR).\n\n【5】It was clear this was going to be a heavy lift. Normally, CFTR serves as a gated channel for chloride ions, helping to maintain the balance of salt and water in the lungs, pancreas, gastrointestinal tract, sweat glands, and other organ systems. Drug researchers had to consider that the Phe508del _CFTR_ mutation, the most common of the more than 1700 known _CFTR_ mutations that can cause cystic fibrosis,  results in a protein with not just one — but two — serious functional deficits. Not only do patients with this mutation have a CFTR protein that is misfolded and trapped in the endoplasmic reticulum of the cell, but any CFTR that does manage to reach the proper location in the cell membrane is deficient in activation. So the search for therapeutics had to include both small molecules that could correct the misfolding of the CFTR protein (“correctors”) and those that could activate its function when it reaches the cell membrane (“potentiators”).\n\n【6】Figure 2. Progress in Molecularly Targeted Therapies for Cystic Fibrosis.\n\n【7】In 2012, the first drug to address the molecular cause of cystic fibrosis, ivacaftor, was approved by the Food and Drug Administration (FDA); this monotherapy benefits the approximately 5% of patients with cystic fibrosis with the G551D _CFTR_ mutation and nine other rare mutations. In 2018, the FDA approved a dual-combination therapy, tezacaftor–ivacaftor, that benefits the approximately 50% of patients with cystic fibrosis with two copies of the Phe508del _CFTR_ mutation or a single copy of 26 other mutations. Now, results from two phase 3, multicenter clinical trials  show the safety and efficacy of a triple-combination therapy, elexacaftor–tezacaftor–ivacaftor, for the approximately 90% of patients with cystic fibrosis with either one or two copies of the Phe508del _CFTR_ mutation. Adapted from the Cystic Fibrosis Foundation. \n\n【8】Academic investigators, many funded by the National Institutes of Health, derived a deep understanding of CFTR function in the first 10 years after gene discovery. Building on that fundamental platform of knowledge, the Cystic Fibrosis Foundation and a small company called Aurora Biosciences (later, Vertex Pharmaceuticals) joined forces in the late 1990s to embark on a high-throughput search for small-molecule correctors and potentiators. These collaborative efforts, now spanning more than two decades, can be seen as an important model for other rare genetic diseases.  In 2012, the Food and Drug Administration (FDA) approved the first drug, the potentiator ivacaftor, to address an underlying cause of cystic fibrosis: the relatively uncommon G551D _CFTR_ mutation, which codes for a protein that does not have the misfolding problem — it just needs activation at the cell membrane.  Although only approximately 5% of patients with cystic fibrosis stood to benefit from ivacaftor, their heartening clinical response served to stimulate vigorous pursuit of drugs for more common cystic fibrosis–causing mutations, especially the Phe508del _CFTR_ mutation. Encouragingly, the past 7 years have seen a steady, stepwise expansion of small-molecule treatment options for more patients with cystic fibrosis .\n\n【9】The pair of phase 3, multicenter clinical trials reported now document the efficacy and safety of elexacaftor–tezacaftor–ivacaftor triple-combination therapy (two correctors, one potentiator) for patients with one or two copies of the Phe508del _CFTR_ mutation. Given the recent approval of this therapy by the FDA, these findings indicate that it may be possible to offer safe and effective molecularly targeted therapies to 90% of persons with cystic fibrosis.\n\n【10】This should be a cause for major celebration. Yet we must not abandon the patients with cystic fibrosis who have null mutations  and will not have a response to these drugs. Even beyond that, the “best day ever” for all of us traveling down this long road together will be the day when the more than 70,000 persons with cystic fibrosis worldwide  do not need to take drug therapy at all and there finally is a permanent cure for cystic fibrosis that works for everyone. Although the challenges are substantial, one can imagine such an ultimate approach involving in vivo somatic-cell gene editing of airway epithelial cells.\n\n【11】Shortly after our identification of _CFTR_ , I wrote a song entitled “Dare to Dream.” The lyrics expressed hope that the gene discovery would lead to effective treatments for cystic fibrosis — that someday we would see “all our brothers and sisters breathing free.”  It is profoundly gratifying to see that this dream is coming true.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 16:28:59", "endTime": "2024/08/13 16:31:18", "cost": 138.671}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 00:31:18", "grab_time": "2024-08-13 00:28:59"}
{"id": 2234526, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "3ce3d714-ee6f-4bd4-8c9a-f730ded20efb", "title": "Disturbance of the Blood T:B Lymphocyte Ratio in Lepromatous Leprosy — Clinical and Immunologic Correlations", "text": "【0】Disturbance of the Blood T:B Lymphocyte Ratio in Lepromatous Leprosy — Clinical and Immunologic Correlations\nAbstract\n--------\n\n【1】A significant increase in absolute numbers of bone-marrow-derived (B) lymphocytes and a significant decrease in the absolute numbers of lymphocytes forming spontaneous rosettes with sheep red blood cells (thymus derived \\[T\\] lymphocytes) were observed in peripheral blood among a group of 17 patients with lepromatous leprosy. Lymphocyte response to phytohemagglutinin after three days of culture was significantly reduced in the patient group. A generalized impairment of delayed hypersensitivity responses was observed among our patients as manifested by skin-test anergy to lepromin and fungal antigens. These findings suggest that anergy of the cellular immune system in patients with lepromatous leprosy may be secondary to the destruction of T lymphocytes or disturbance of their recirculation.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": null, "finished": false, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-14 00:17:39", "grab_time": "2024-08-14 00:22:19"}
{"id": 2234525, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "7fe643f7-05b8-43ac-b08e-1e6ca36da00b", "title": "Transplantation 50 Years Later — Progress, Challenges, and Promises", "text": "【0】Transplantation 50 Years Later — Progress, Challenges, and Promises\nA half-century has elapsed since the first transplantation, and this procedure is now accepted as the treatment of choice for end-stage organ failure. This article reviews the many developments since that historic moment. Although tremendous progress has contributed to the success of this form of therapy, several challenges remain if transplantation is to be widely available with minimal risks and optimal outcomes.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:44:51", "endTime": "2024/08/14 14:44:59", "cost": 8.748}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 22:45:00", "grab_time": "2024-08-13 22:44:51"}
{"id": 2234524, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "60ccdb88-8f53-416a-896a-be1d9f812ea6", "title": "Handle Survivors with Care", "text": "【0】Handle Survivors with Care\nArticle\n-------\n\n【1】In 1967, a woman became ill after exposure to a newly discovered pathogen that we now call Marburg virus, a member of the family Filoviridae (filoviruses), to which Ebola virus also belongs.  Testing of the semen of her husband, who had recovered from the disease 6 weeks previously, determined that her exposure was through sexual intercourse. This was the first confirmed case of sexual transmission of filovirus disease from a convalescent man. It was also the last \\. until the West African outbreak.\n\n【2】In March 2015, Ebola virus disease (EVD) developed in a Liberian woman after the country had been free from EVD for 30 days.  This woman had no identifiable risk factors for EVD other than sexual contact with a male survivor of the disease. This survivor’s semen tested positive for Ebola virus RNA, which suggested sexual transmission. Mate and colleagues presented in the _Journal_ the results of a genomic analysis that provided support for the development of EVD in this woman through sexual transmission from a male survivor 6 months after his recovery.  Before this case, the furthest into convalescence that Ebola virus had been isolated from semen was 82 days. \n\n【3】This case raised the question of how late into convalescence male survivors are capable of infecting their sexual contacts. Deen and colleagues address this concern in a study whose final results now appear in the _Journal_ .  They examined semen specimens from male survivors of EVD and were able to detect Ebola virus RNA in a surprisingly large proportion, with RNA present in semen as late as 470 days (15.7 months) into convalescence. As Deen et al. acknowledge, finding Ebola virus RNA in semen does not imply that it is infectious. Further testing of semen specimens with viral culture is necessary to determine whether active virus is present. Regardless of the results of such study, sexual transmission clearly occurs, but it appears to be a rare event.\n\n【4】There are more than 17,000 survivors of the West African EVD outbreak, approximately half of whom are male.  Most of these male survivors are now more than 2 years into their convalescence. If sexual transmission from survivors were an important means of disease propagation, we would have seen a number of cases by now. As Deen and colleagues noted in their preliminary report in 2015, fewer than 20 suspected sexually transmitted infections had been reported, and there have been only two well-documented cases of probable sexual transmission since then. \n\n【5】The challenge with sexual transmission is not that it is a source of many new EVD cases but that it is a source of late EVD cases, such as those that sparked the resurgence of EVD in Sierra Leone in January 2016 and in Guinea in March 2016.  The World Health Organization (WHO) usually declares an outbreak in a given location to be finished 42 days after the resolution of the “last” case.  However, the possibility of cases arising from sexual transmission as late as 500 days after the survivor’s onset of symptoms  creates an atmosphere of uncertainty as to when an outbreak is truly over.\n\n【6】We cannot ask a country emerging from an EVD outbreak to be alert for late presentation of new cases without calling attention to the risk posed by male survivors, even if this risk can be managed somewhat by providing them with condoms and counseling. Communities within and beyond western Africa have not dealt kindly with perceived risks when it comes to Ebola. Survivors have been isolated from their communities, have been evicted from their homes, and have lost their jobs.  Male survivors have been involuntarily quarantined  and even, reportedly, have been jailed  by governmental authorities who are afraid these survivors may transmit EVD.\n\n【7】Their treatment raises a practical concern. If we want to be able to detect the next case of EVD that might emerge from late sexual transmission, we must consider that the people who may one day become the next patient will see how survivors are treated. If they find that being identified as a patient with EVD has but two outcomes — death in a frightening treatment unit or survival to return as a social outcast — they have a considerable disincentive to be identified. This prospect may drive persons with new cases of EVD into hiding and defeat the objective of the surveillance system. When Médecins sans Frontières (MSF) was compelled by the government of Guinea to share the results of semen testing in survivors of EVD who came to our clinic, we disclosed this fact to our patients. The rate of presentations of survivors for testing subsequently fell by 50% (MSF internal data). Failing to exert extreme caution in the way we communicate the risk that survivors of EVD pose to the public might have devastating effects both on the well-being of the survivors and on the effectiveness of the surveillance we need to end outbreaks. Treating survivors with discretion and coupling survivor surveillance with communication programs that reduce stigma and facilitate the social reintegration of survivors will be more effective at motivating them to participate in surveillance programs.\n\n【8】Some survivors consent to semen testing in order to know the risk they pose to their loved ones, and some participate in research because they are financially compensated, but for many these are insufficient inducement. Survivors of EVD have needs, care for both the medical and psychological consequences of their illness, as well as a desire to be reintegrated into their communities. Coupling surveillance with services that address their needs may be the most effective way to ensure the well-being of survivors and their communities.\n\n【9】To the extent that the unfortunate situation of male survivors of EVD stems from their being seen as a continued threat to their communities, perhaps some hope is offered by the prospect of effective vaccines. The results of the Partnership for Research on Ebola Virus in Liberia (PREVAIL) I trial that are now presented in the _Journal_ by Kennedy and colleagues  show the safety and immunogenicity of the chimpanzee adenovirus 3 vaccine (ChAd3-EBO-Z) and add to our understanding of the recombinant vesicular stomatitis virus vaccine (rVSVΔG-ZEBOV-GP), the efficacy of which was shown in a ring vaccination trial conducted in Guinea.  Vaccines against EVD have been traditionally thought of as countermeasures that might be used in the context of a bioterrorism event, as protection for front-line workers during EVD outbreaks, and as a means to control outbreaks by stopping transmission. To this list we might add the protection of the contacts of survivors of EVD. If such protection allows communities and public health agencies some measure of certainty that the end of an outbreak is truly the end, perhaps the survivors of EVD can be granted some peace and the opportunity to resume their lives beyond Ebola.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:43:33", "endTime": "2024/08/14 15:44:01", "cost": 28.847}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 23:44:01", "grab_time": "2024-08-13 23:43:32"}
{"id": 2234523, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "962e1339-f627-4018-af59-22d0aded04ba", "title": "Excess Mortality among Blacks and Whites in the United States", "text": "【0】Excess Mortality among Blacks and Whites in the United States\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Although the general relations between race, socioeconomic status, and mortality in the United States are well known, specific patterns of excess mortality are not well understood.\n\n【3】Methods\n-------\n\n【4】Using standard demographic techniques, we analyzed death certificates and census data and made sex-specific population-level estimates of the 1990 death rates for people 15 to 64 years of age. We studied mortality among blacks in selected areas of New York City, Detroit, Los Angeles, and Alabama (in one area of persistent poverty and one higher-income area each) and among whites in areas of New York City, metropolitan Detroit, Kentucky, and Alabama (one area of poverty and one higher-income area each). Sixteen areas were studied in all.\n\n【5】Results\n-------\n\n【6】When they were compared with the nationwide age-standardized annual death rate for whites, the death rates for both sexes in each of the poverty areas were excessive, especially among blacks (standardized mortality ratios for men and women in Harlem, 4.11 and 3.38; in Watts, 2.92 and 2.60; in central Detroit, 2.79 and 2.58; and in the Black Belt area of Alabama, 1.81 and 1.89). Boys in Harlem who reached the age of 15 had a 37 percent chance of surviving to the age of 65; for girls, the likelihood was 65 percent. Of the higher-income black areas studied, Queens–Bronx had the income level most similar to that of whites and the lowest standardized mortality ratios (men, 1.18; women, 1.08). Of the areas where poor whites were studied, Detroit had the highest standardized mortality ratios (men, 2.01; women, 1.90). On the Lower East Side of Manhattan, in Appalachia, and in Northeast Alabama, the ratios for whites were below the national average for blacks (men, 1.90; women, 1.95).\n\n【7】Conclusions\n-----------\n\n【8】Although differences in mortality rates before the age of 65 between advantaged and disadvantaged groups in the United States are sometimes vast, there are important differences among impoverished communities in patterns of excess mortality.\n\n【9】Introduction\n------------\n\n【10】Nationwide and statewide studies in the United States indicate that young and middle-aged black Americans have disproportionately high morbidity and mortality  and that differences between socioeconomic groups in premature mortality may be increasing.  These findings may seriously understate the health problems of blacks living in areas of concentrated poverty. McCord and Freeman  estimated that black men living in Harlem in 1980 had less chance of surviving to the age of 65 than men in Bangladesh. It is uncertain whether the findings in Harlem can be generalized to other areas of poverty in the United States or to other black communities.\n\n【11】We estimated the 1990 death rates of people 15 to 64 years of age in eight persistently poor geographic areas and eight geographically proximate, but more advantaged areas, matched for race. We studied the extent to which disadvantaged people in the prime of life have shorter life expectancy than people in more advantaged groups and than the national averages. We also compared mortality rates among different types of communities with persistent poverty.\n\n【12】Methods\n-------\n\n【13】Study Groups\n------------\n\n【14】Table 1. Summary Data on the Study Areas, 1990.\n\n【15】Summary data on the 16 areas studied are shown in Table 1 . The geographic areas where the groups resided are described in greater detail in the Appendix. Our analyses of black populations include only blacks in those areas, and the analyses of white populations include only whites. In each area, two geographically proximate groups of people of the same race — one poor and one of higher income — were selected for study. In keeping with the distribution of income nationally, the black groups (both poor and higher-income) tended to be less well off than the white groups, and the disparities between the more disadvantaged and less disadvantaged groups were greater in the urban North than in the rural South.\n\n【16】The areas studied were not randomly selected areas of concentrated poverty. Instead, they were chosen for their racial and geographic diversity, given the constraints of the data. Each group needed to be large enough for detailed analyses of mortality in persons 15 to 64 years of age to be performed. In the case of blacks, this requirement limited us to major cities and southern rural areas. Our study was also limited to states that provide information on vital statistics with geographic identifiers and, for areas with large Hispanic populations, differentiation between non-Hispanic and Hispanic residents.\n\n【17】Statistical Analysis\n--------------------\n\n【18】For each group, we combined information from death certificates for the three years from 1989 to 1991 with age-stratified counts of persons of each sex from the 1990 U.S. Census to calculate age- and sex-specific rates of death, both overall and from specific causes. To reduce bias due to undercounting in the census, we adjusted the population counts. Specific estimates of undercounting in local areas could not be obtained for every group. We replicated the analyses for Harlem with adjustment for both local and national rates of undercounting. Because the conclusions were the same regardless of the adjustment made, estimates for all the study populations are based on the adjustment for undercounting nationally.\n\n【19】We then computed age- and cause-specific standardized mortality ratios and annualized excess-death rates.  To ensure that the reported measures were comparable among the study groups, we standardized our calculations with reference to the age distribution of the white population nationwide, according to sex.  For each group, we calculated the number of deaths that would be expected among whites nationwide if their age- and cause-specific death rates were the same as those of the study group. To compute the standardized mortality ratios, we divided the number of expected deaths by the number of observed deaths in the white population nationwide. We calculated excess-death rates as 100,000 times the difference between expected deaths and observed deaths, divided by the white population nationwide.\n\n【20】We used Greville's method  to derive the likelihood that a 15-year-old living in a given area would survive to a specified age. We used standard life-table methods to calculate the average number of years of life lost between the ages of 15 and 65 in each group.  Using standard multidecrement life-table techniques,  we also estimated how many of the years of life lost between the ages of 15 and 65 in that group could be attributed to a particular cause of death, when competing mortality risks were taken into account.\n\n【21】We classified deaths according to their underlying causes, using the diagnostic categories of the _International Classification of Diseases, 9th Revision_ (ICD-9). After examining many causes, we report on those found to be especially important in explaining the disparities in death rates: diseases of the circulatory system (ICD-9 codes 390 to 459); cancer (codes 140 to 208); accidents (codes E800 to E949); human immunodeficiency virus (HIV) infection (codes 042 to 044); homicide (codes E960 to E969); infectious disease, pneumonia, and influenza (codes 001 to 041, 045 to 139, and 480 to 487); and a separate category that included all the remaining causes.\n\n【22】Using standard methods, we estimated the sampling variability associated with each measure of mortality.  For every possible pair of groups, we conducted two-tailed statistical tests of the hypothesis that the measures of mortality would be the same. For the poor populations, the estimated 95 percent confidence intervals never exceeded 11 percent above or below the standardized mortality ratio, 84 deaths more or less than the excess-death rate, 0.03 more or less than the probability of survival, or 0.88 year more or less than the number of years of life lost.\n\n【23】Results\n-------\n\n【24】Summary Measures\n----------------\n\n【25】Table 2. Measures of Mortality among Blacks and Whites 15 to 64 Years Old in Selected Populations, According to Sex, 1989–1991.\n\n【26】Table 2 shows annualized excess-death rates and standardized mortality ratios according to sex for people 15 to 64 years old in each study group, relative to the national averages among whites, and the probability of survival to the age of 65 among persons who had survived to the age of 15. The death rates for both sexes in every group of poor blacks were excessive. The disparity was not as great in the Black Belt area of Alabama as in central Detroit, Watts, or Harlem, and it was greatest in Harlem. Mortality rates among blacks in Black Belt Alabama were similar to the national average for blacks and to the rates in northern Alabama, the comparison group, but all the other groups of poor blacks had higher mortality rates than their comparison groups. The disparity between Harlem and its comparison group (Queens–Bronx) was particularly large, with standardized mortality ratios of 4.11 among men and 3.38 among women in Harlem, as compared with ratios of 1.18 and 1.08, respectively, in Queens–Bronx. Black residents in the latter area had mortality rates similar to the national average for whites.\n\n【27】People living in the poor white areas generally had mortality rates exceeding the national average for whites. Except for white men in Detroit, however, they had mortality rates below the national average for blacks. People in poor white areas generally had higher mortality rates than people in their comparison groups. In the case of Detroit, this difference was marked. The standardized mortality ratios for whites were 2.01 among men and 1.90 among women in Detroit, as compared with 0.41 among men and 0.54 among women in Sterling Heights.\n\n【28】Probability of Survival\n-----------------------\n\n【29】Typical white Americans who were 15 years old had a higher likelihood of surviving to the age of 65 than blacks nationwide or poor 15-year-olds in any of the poor study groups. With the exception of white residents of Detroit, the poor whites had higher probabilities of survival than the blacks (P<0.001). Among the poor black groups, people in Harlem, central Detroit, and Watts had a lower probability of surviving to the age of 65 than people in Black Belt Alabama (P<0.001). The lowest probability of survival to the age of 65 was in Harlem, among blacks: 0.37 in men and 0.65 in women. For men, this represents less than half the probability of survival of whites nationwide. For poor whites, the lowest probability of survival was in Detroit (men, 0.60; women, 0.77). The probability that a 15-year-old girl in Harlem would survive to the age of 45 was the same as the probability that a typical white girl anywhere in the United States would survive to the age of 65; for boys in Harlem, this probability was lower (P<0.001) (data not shown).\n\n【30】Figure 1. Average Years of Life Lost between the Ages of 15 and 65 in Men and Boys, According to Study Area and for Selected Causes of Death. Figure 2.  Figure 2. Average Years of Life Lost between the Ages of 15 and 65 in Women and Girls, According to Study Area and for Selected Causes of Death.\n\n【31】There was marked variation among the groups studied in the average number of years of life lost between the ages of 15 and 65 . Among men from Harlem, an average of 14 years were lost; among men from central Detroit, 11 years; among men from Watts, 12 years; and among men from Black Belt Alabama, 7 years. Poor whites generally lost more years of life than whites either nationally or in the four comparison groups of higher-income whites. Except in Detroit, poor whites lost fewer years than poor blacks. Queens–Bronx was the only black area that compared favorably with some advantaged white areas.\n\n【32】Causes of Excess Mortality\n--------------------------\n\n【33】Table 3. Causes of Excess Mortality among Poor Blacks and Whites 15 to 64 Years Old, According to Sex, 1989–1991.\n\n【34】Specific causes of excess death in the poor groups are shown in Table 3 . Diseases of the circulatory system were important contributors to excess mortality in every group, and in most instances they were the leading cause. HIV was the principal cause of excess death among men in Harlem and the Lower East Side, and the second most common cause among women. Accidents were the leading cause of excess mortality among men in Appalachia, and the second most common cause among men in Black Belt Alabama. Homicide was the leading cause of excess death among men in Watts, the second most common cause among men of either race in Detroit, and the third most common cause among men in Harlem. Cancer was an important cause of excess mortality among both sexes in many groups, notably residents of Harlem, Watts, and both the poor black and poor white areas of Detroit, and infections were a prominent cause among both men and women in Harlem.\n\n【35】Figure 1 and Figure 2 show the average number of years of life lost between the ages of 15 and 65 in each study group that could be attributed to HIV, homicide, and all other causes combined. By studying years of life lost, we magnified the contributions of HIV and homicide to excess mortality, because more people died at earlier ages from these causes than from other important causes, such as diseases of the circulatory system or cancer. Even so, only excess deaths in the Lower East Side are explained by these causes. Among poor black urban men, excluding these causes would substantially reduce excess mortality, but the number of excess deaths would remain considerable, especially in Harlem.\n\n【36】Discussion\n----------\n\n【37】Our findings paint a stark portrait of social inequalities in mortality, but also a varied and complicated one. The differences between the advantaged and disadvantaged groups were sometimes vast. The situation in Harlem in 1990 was particularly dire. Comparison of the estimates by McCord and Freeman  with ours shows that in Harlem mortality among women relative to that nationwide has not improved since 1980, whereas mortality among men has deteriorated. On the other hand, groups that might have been expected to have excess-mortality rates equivalent to or higher than the rates in Harlem did not.\n\n【38】Our results show that there are important differences among impoverished communities in patterns of mortality. The data suggest that reducing excess mortality may require interventions that address local conditions and mortality risks. For example, our findings underscore the need for interventions to reduce the incidence of diseases of the circulatory system in all the locations examined, but they suggest that HIV, homicide, and accident prevention need to be emphasized differently in different places.\n\n【39】Our findings are generally consistent with the association between race and excess mortality in the United States that is often reported. However, the poverty rate and the location of a group (urban and northern vs. rural and southern) are also important. White residents of Detroit fared as poorly as residents of some black areas that we studied. One black comparison group (that in Queens–Bronx) had a mortality rate only slightly higher than the national average for whites.\n\n【40】Thirty percent of the people in the Queens–Bronx area were black immigrants from the West Indies, but analyses that do not include this foreign-born population indicate that this factor does not explain the favorable mortality profile. An alternative explanation is that when a black population has the same degree of economic advantage as a white population, it also has a favorable mortality rate. In the groups we studied, the number of years of life lost generally increased with the percentage of people in the group who were living in poverty, with the poverty rate accounting for more than half the racial differences in mortality (data not shown).\n\n【41】Although we could not study the extent to which individual economic well-being was itself associated with the likelihood of premature death, our findings were consistent with recent analyses showing that controlling for indicators of individual socioeconomic status accounts for some, but not all, the racial disparity in mortality among people of comparable age.  Other factors that may matter include population density, household crowding, and correlates of residential segregation, such as residence in an area that is medically or socially underserved, one with dilapidated housing stock or a high crime rate, or one with excessive exposure to environmental hazards. Relevant psychosocial factors may be associated with chronic uncertainty, racial stress, or ongoing problems with social injustice and community disruption. \n\n【42】The data we obtained in Harlem and Black Belt Alabama highlight the importance of accounting for social factors that are not represented in typical measures of socioeconomic status. Black Belt Alabama had the lowest excess mortality of the poor black groups, although it had the highest rate of poverty, whereas Harlem had the highest excess mortality but the lowest poverty rate. These findings remained valid after adjustment for cost-of-living differences between the rural South and the urban North. \n\n【43】More generally, our findings underscore the importance of conducting repeated analyses at the population level in several areas as complements to analyses of individuals or single areas. Population analysis can take into account a more complete and longer-term set of social factors that affect mortality,  and the study of multiple populations yields more evidence about the generalizability of data and permits extreme or anomalous populations to be identified. The consideration of current or historical features peculiar to such populations can improve an understanding of the social epidemiology of excess mortality.\n\n【44】That young people in some areas of the United States cannot expect to survive through middle adulthood is a disturbing manifestation of social inequality. Living with high levels of risk and uncertainty may affect social behavior and health habits and exacerbate the risk of disease.  In addition, young people and middle-aged adults provide financial support and care for their families. As public policy shifts away from supporting poor families, we should consider the implications of excess mortality for the ability of adults in persistently poor populations to shoulder more economic responsibilities than they already have.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-14 00:21:13", "grab_time": "2024-08-13 23:18:12"}
{"id": 2234522, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "690d7e0c-272e-4c79-aa96-a266ceedc491", "title": "Rituximab after Autologous Stem-Cell Transplantation in Mantle-Cell Lymphoma", "text": "【0】Rituximab after Autologous Stem-Cell Transplantation in Mantle-Cell Lymphoma\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Mantle-cell lymphoma is generally incurable. Despite high rates of complete response after initial immunochemotherapy followed by autologous stem-cell transplantation, patients have relapses. We investigated whether rituximab maintenance therapy at a dose of 375 mg per square meter of body-surface area administered every 2 months for 3 years after transplantation would prolong the duration of response.\n\n【3】Methods\n-------\n\n【4】In a phase 3 trial involving 299 patients who were younger than 66 years of age at diagnosis, we randomly assigned 240 patients to receive rituximab maintenance therapy or to undergo observation after autologous stem-cell transplantation (120 patients per group); 59 patients did not undergo randomization. The primary end point was event-free survival (with an event defined as disease progression, relapse, death, allergy to rituximab, or severe infection) after transplantation among patients who underwent randomization.\n\n【5】Results\n-------\n\n【6】After four courses of immunochemotherapy induction (rituximab, dexamethasone, cytarabine, and a platinum derivative \\[R-DHAP\\]), the overall response rate was 89%, and the complete response rate 77%. Transplantation was performed in 257 patients. The median follow-up from randomization after transplantation was 50.2 months (range, 46.4 to 54.2). Starting from randomization, the rate of event-free survival at 4 years was 79% (95% confidence interval \\[CI\\], 70 to 86) in the rituximab group versus 61% (95% CI, 51 to 70) in the observation group (P=0.001). The rate of progression-free survival at 4 years was 83% (95% CI, 73 to 88) in the rituximab group versus 64% (95% CI, 55 to 73) in the observation group (P<0.001). The rate of overall survival was 89% (95% CI, 81 to 94) in the rituximab group versus 80% (95% CI, 72 to 88) in the observation group (P=0.04). According to a Cox regression unadjusted analysis, the rate of overall survival at 4 years was higher in the rituximab group than in the observation group (hazard ratio for death, 0.50; 95% CI, 0.26 to 0.99; P=0.04).\n\n【7】Conclusions\n-----------\n\n【8】Rituximab maintenance therapy after transplantation prolonged event-free survival, progression-free survival, and overall survival among patients with mantle-cell lymphoma who were younger than 66 years of age at diagnosis. \n\n【9】Introduction\n------------\n\n【10】Mantle-cell lymphoma, which is characterized by a specific immunophenotype and the chromosomal translocation t(11;14),  accounts for approximately 6% of non-Hodgkin’s lymphomas among adults. After treatment, most patients have a relapse, and the duration of response decreases with each successive salvage therapy. \n\n【11】One of the commonly recommended first-line treatments for patients who are eligible (according to standard guidelines) to undergo transplantation includes combined treatment with rituximab and high-dose cytarabine followed by autologous stem-cell transplantation.  Recently, a phase 3 prospective trial showed an advantage of alternating a chemotherapy regimen consisting of rituximab, cyclophosphamide, doxorubicin, vincristine, and prednisolone (R-CHOP) and a regimen consisting of rituximab, dexamethasone, high-dose cytarabine, and a platinum derivative (R-DHAP), as compared with the R-CHOP regimen alone, before transplantation.  Young patients with untreated mantle-cell lymphoma who received the R-CHOP and R-DHAP regimens had longer progression-free survival and a longer duration of remission than those who received the R-CHOP regimen alone, but they did not have longer overall survival.\n\n【12】The lack of a plateau on the survival curve in the results of the prospective trials that have been published to date  suggests that residual tumor cells may persist after the end of treatment and that these may drive relapses. Thus, we hypothesized that maintenance therapy may prolong the duration of complete response and reduce the risk of relapse.\n\n【13】Rituximab, a monoclonal antibody targeting CD20, has shown a good safety profile and high efficiency in patients with various B-cell lymphomas. Prospective trials have investigated maintenance therapy with rituximab.  The European Mantle Cell Lymphoma Network found that among elderly patients who had an initial response to R-CHOP, rituximab maintenance therapy until disease progression prolonged both progression-free survival and overall survival.  Rituximab maintenance therapy is currently not recommended after transplantation.\n\n【14】We conducted a randomized, prospective, phase 3 trial to investigate the role of rituximab maintenance therapy in patients with mantle-cell lymphoma who had undergone autologous stem-cell transplantation. Because cytarabine plays a major role before transplantation in patients with mantle-cell lymphoma, four courses of R-DHAP were used as induction therapy. R-DHAP is an immunochemotherapy regimen without alkylating and anthracycline agents. To reduce the risk of long-term toxic effects, we used a transplantation conditioning regimen without total-body irradiation. The primary end point of the trial was event-free survival as evaluated from the date of randomization.\n\n【15】Methods\n-------\n\n【16】Characteristics of the Patients\n-------------------------------\n\n【17】The trial included patients 18 to 65 years of age who had untreated mantle-cell lymphoma and were eligible to undergo autologous stem-cell transplantation, who had disease of Ann Arbor stage II through IV (on a four-stage scale on which stage I indicates localized disease and increasing stage indicates more widespread disease), and who had an Eastern Cooperative Oncology Group (ECOG) performance-status score of less than 3 (on a 5-point scale, with higher numbers indicating increasing disability). Patients who were positive for the human immunodeficiency virus or those who presented with major coexisting conditions at diagnosis that were not related to lymphoma were excluded. The diagnosis of mantle-cell lymphoma was established by local expert pathologists and reviewed centrally by pathology experts according to the 2008 World Health Organization classification. All the patients provided written informed consent.\n\n【18】Trial Protocol\n--------------\n\n【19】Patients were included in the trial at the time of diagnosis. In brief, patients received induction chemotherapy with four courses of R-DHAP, repeated every 21 days. According to local practice (or in case of renal failure during treatment), investigators were allowed to use carboplatin or oxaliplatin instead of cisplatin. Stem cells were obtained according to local practice, after the third or fourth course of R-DHAP. The use of a chemotherapy regimen for stem-cell mobilization was not authorized.\n\n【20】Tumor status was assessed according to the 1999 International Working Group criteria by local investigators . After four courses of R-DHAP, patients who were having a partial response and whose tumor mass had been reduced by less than 75%, as assessed by means of computed tomography (CT), received a rescue induction therapy with four courses of R-CHOP (rituximab, cyclophosphamide, doxorubicin, vincristine, and prednisolone), administered as one course every 14 days. Only patients who were having a response, including those in complete remission (confirmed or unconfirmed) and those having a partial response (whose tumor mass was reduced by ≥75% after induction), were eligible to undergo transplantation. A minimal peripheral-blood progenitor-cell graft of 2×10 <sup>6 </sup> CD34+ cells per kilogram of body weight was required.\n\n【21】The conditioning regimen before transplantation was R-BEAM (rituximab, carmustine, etoposide, cytarabine, and melphalan). After transplantation and up to 3 months later, patients were randomly assigned to receive rituximab maintenance therapy or to undergo observation. The schedule for maintenance therapy was the receipt of 375 mg of rituximab per square meter of body-surface area, administered intravenously every 2 months for 3 years. The total number of planned doses of rituximab was 23 (4 doses administered with induction therapy, 1 dose with the preparative regimen for transplantation, and 18 doses over the 3 years of maintenance therapy).\n\n【22】Oversight\n---------\n\n【23】This unblinded, randomized prospective trial was performed according to the principles of the Declaration of Helsinki, and the protocol was approved by an ethics committee. The trial began before it was registered on ClinicalTrials.gov owing to an administrative error. A total of 29 patients were enrolled before registration. The first author and the last two authors designed the trial. Data were gathered by the investigators and by the sponsor and were analyzed by LYSARC (the academic research organization of the Lymphoma Study Association \\[LYSA\\]). All the authors had access to the data. The first author wrote the initial draft of the manuscript. All the authors contributed to the subsequent drafts, reviewed them, and jointly decided to submit the manuscript for publication. All the authors vouch for the integrity, accuracy, and completeness of the data and analyses and for the fidelity of the trial to the protocol . Roche supplied rituximab for the R-BEAM regimen and for maintenance therapy and funded the trial but did not contribute to the protocol design, trial execution, data collection or analysis, the writing of the manuscript, or the decision to submit the manuscript for publication.\n\n【24】Staging, Monitoring, and End Points\n-----------------------------------\n\n【25】At the time of inclusion, the disease characteristics of the patients were assessed by means of clinical examination, standard biologic variables, bone marrow biopsy, and CT scan (neck, chest, abdomen, and pelvis). Response to therapy was assessed after the receipt of four courses of R-DHAP (and after R-CHOP in patients who received salvage therapy) and after transplantation. Randomization was stratified, in a  ratio, according to the use or nonuse of R-CHOP before transplantation.\n\n【26】The primary end point was event-free survival after randomization. Events were defined as disease progression, relapse, death, severe infection (grade 4 with life-threatening severity), or allergy to rituximab that led to the discontinuation of treatment after randomization. Secondary end points were progression-free survival (i.e., freedom from disease progression, relapse, and death from any cause) and overall survival as assessed from inclusion and from randomization. The trial design and follow-up assessments are described in detail in the Supplementary Appendix .\n\n【27】Statistical Analysis\n--------------------\n\n【28】Event-free survival was monitored and analyzed according to a group-sequential plan that included one interim analysis in order to allow for early stopping on the basis of efficacy. The total sample of 299 patients provided the trial with 80% power to detect a difference of 13 percentage points in the rate of event-free survival at 4 years (expected rates of 83% in the rituximab group vs. 70% in the observation group) at an alpha level of 0.05. O’Brien–Fleming boundaries were used to check for type I error, with the overall alpha level being 0.05 for the number of patients who were included at the time of data cutoff. The interim analysis was performed when at least 82 patients had reached 3 years after transplantation. The significance level for the interim analysis was set at 0.0051, and the significance level for the final analysis was set at 0.0475. At the interim analysis, with a median follow-up of 34 months after transplantation, the rate of event-free survival (P=0.006 by the log-rank test) was under the O’Brien–Fleming boundary. The present analysis is the final analysis.\n\n【29】The intention-to-treat population included all the patients who had undergone randomization, and the primary and secondary end points were evaluated with the inclusion of all patients who had protocol violations or withdrew. The included-patients population constituted all the patients who provided written informed consent.\n\n【30】Time-to-event survival curves were estimated with the use of the Kaplan–Meier method. Time-to-event end points in the different groups were compared with the use of log-rank tests and Cox proportional-hazards regression. Patients who withdrew (e.g., all the patients who did not undergo randomization for any reason) and patients who were lost to follow-up (e.g., all the patients who underwent randomization and for whom an outcome was not updated for >1 year at the time of the final analysis) who did not have an event, as defined in the protocol at the time of the final analysis, had their data censored at the time of their last visit. Response rates were expressed in percentages with 95% exact confidence intervals that were based on the Clopper–Pearson method. All the statistical analyses were performed with the use of SAS software, version 9.3 (SAS Institute).\n\n【31】Results\n-------\n\n【32】Treatment\n---------\n\n【33】Figure 1. Eligibility Assessment, Treatment, Randomization, and Follow-up of the Patients.\n\n【34】The R-DHAP regimen consisted of rituximab, dexamethasone, high-dose cytarabine, and a platinum derivative. A total of 20 patients who received all four courses of the R-DHAP regimen then received the R-CHOP regimen, which consisted of rituximab, cyclophosphamide, doxorubicin, vincristine, and prednisolone. After autologous stem-cell transplantation, 120 patients were assigned to receive rituximab maintenance therapy and 120 were assigned to the observation group.Table 1.  Table 1. Demographic and Clinical Characteristics of the Patients at the Time of Inclusion in the Trial.\n\n【35】From September 2008 through August 2012, we enrolled 299 patients in the study . The characteristics of the patients at the time of inclusion are shown in Table 1 . The central pathological review confirmed the diagnosis in all patients (by means of immunochemical testing for immunophenotype, except in 5 patients in whom the diagnosis was made by means of fluorescence in situ hybridization of blood samples) except for 1, whose disease was classified as hairy-cell leukemia (this patient was retained in the included-patients population but did not undergo randomization).\n\n【36】One course of cyclophosphamide, vincristine, and prednisolone was administered to 35 patients (12%) before the initiation of R-DHAP induction therapy. Carboplatin was used from the first course of R-DHAP in 76 patients, and oxaliplatin was used in 38; the remainder received cisplatin. The overall response rate after induction therapy was 94%, including a complete response in 124 patients (41%) and an unconfirmed complete response in 107 (36%). The main reasons to stop treatment during induction therapy were disease progression (in 5 patients) and toxic effects (in 7) . All the patients who had renal toxic effects had received cisplatin. R-CHOP was administered in 20 patients who had an insufficient response after R-DHAP, and 10 of these patients proceeded to transplantation (3 patients were having a complete remission, 6 were having an unconfirmed complete remission, and 1 was having a partial response).\n\n【37】Overall, 257 of 299 patients (86%) underwent transplantation. After transplantation, 168 of 257 patients (65%) had a complete remission, and 61 (24%) had an unconfirmed complete remission. A total of 240 of 299 patients (80%) underwent randomization and constituted the intention-to-treat population; 120 patients were randomly assigned to the group that received rituximab maintenance therapy and 120 to the observation group. There was no significant difference between the two groups regarding the characteristics at enrollment (inclusion) and the patients’ disease status at randomization .\n\n【38】Outcome\n-------\n\n【39】At the stopping date (July 1, 2015), the median follow-up from inclusion was 54.4 months (range, 52.7 to 59.2), and the median follow-up from randomization was 50.2 months (range, 46.4 to 54.2). In the included-patients population, the median progression-free survival and median overall survival, as calculated from inclusion, were not reached. Among these patients, the 4-year rate of progression-free survival was 68% (95% confidence interval \\[CI\\], 62 to 73), and the 4-year rate of overall survival was 78% (95% CI, 73 to 82). According to the Mantle Cell Lymphoma International Prognostic Index (MIPI),  which is used to assess risk on the basis of age, ECOG performance-status score, lactate dehydrogenase level, and white-cell count , the median progression-free survival and overall survival were not reached among low-risk and intermediate-risk patients; among high-risk patients, the median progression-free survival was 47.4 months and the median overall survival was 56.2 months (P<0.001 for both comparisons with the low-risk group). (Results regarding progression-free survival and overall survival that were calculated from inclusion and according to MIPI score are provided in Figs. S2 through S5 in the Supplementary Appendix .)\n\n【40】According to the protocol definition, 25 patients (21%) had an event in the rituximab group, as compared with 47 (39%) in the observation group. A total of 83 patients in the rituximab group completed the scheduled 3-year course of therapy. The main reasons to stop maintenance therapy were disease progression (in 16 patients) and neutropenia (in 9). Serious infection after transplantation was observed in 4 patients in each group (spondylitis, pyelonephritis, septicemia, and varicella pneumonia in 1 patient each in the rituximab group and septicemia, cellulitis, meningitis, and severe pneumonia in both lungs in 1 patient each in the observation group).\n\n【41】Information regarding grade 3 and 4 toxic effects, according to randomization and trial period, is provided in Table S1 in the Supplementary Appendix . In brief, the most frequent toxic event of grade 3 or 4 was neutropenia. A second cancer caused death in 3 patients in the rituximab group and in 1 in the observation group. No late effect of rituximab has been reported so far in either trial group. After randomization, 16 patients had disease progression and 13 patients died in the rituximab group, as compared with 37 patients who had disease progression and 24 who died in the observation group. The major cause of death in each group was lymphoma (in 8 patients in the rituximab group and 16 in the observation group).\n\n【42】Figure 2. Event-free Survival, Progression-free Survival, and Overall Survival.\n\n【43】The Kaplan–Meier analyses of event-free survival, progression-free survival, and overall survival were performed according to trial group. Survival was calculated from the time of randomization. Event-free survival was defined as freedom from disease progression, relapse, death, allergy to rituximab, and severe infection. The hazard ratio for progression, relapse, death, rituximab allergy, or infection was 0.46 (95% CI, 0.28 to 0.74; P=0.002) . Tick marks indicate censored data, and the shaded areas 95% confidence intervals. Progression-free survival was defined as freedom from disease progression, relapse, and death from any cause. The hazard ratio for progression, relapse, or death was 0.40 (95% CI, 0.23 to 0.68; P<0.001) . In the analysis of overall survival, the hazard ratio for death was 0.50 (95% CI, 0.26 to 0.99; P=0.04) .\n\n【44】The median event-free survival from randomization was not reached in either group . The 4-year rate of event-free survival as calculated from randomization was 79% (95% CI, 70 to 86) in the rituximab group, as compared with 61% (95% CI, 51 to 70) in the observation group (P=0.001), with a hazard ratio for disease progression, relapse, death, rituximab allergy, or severe infection of 0.46 (95% CI, 0.28 to 0.74; P=0.002).\n\n【45】The median progression-free survival and overall survival from randomization were not reached in either group. The 4-year rates of progression-free survival and overall survival were significantly higher in the rituximab group than in the observation group. The rate of progression-free survival was 83% (95% CI, 73 to 88) in the rituximab group, as compared with 64% (95% CI, 55 to 73) in the observation group (hazard ratio for disease progression, relapse, or death, 0.40; 95% CI, 0.23 to 0.68; P<0.001) . The rate of overall survival was 89% (95% CI, 81 to 94) in the rituximab group, as compared with 80% (95% CI, 72 to 88) in the observation group (hazard ratio for death, 0.50; 95% CI, 0.26 to 0.99; P=0.04) . The per-protocol analysis yielded similar results .\n\n【46】A total of 11 patients received R-CHOP before randomization; of these patients, 4 were assigned to the rituximab group (1 patient had disease progression and died and 3 did not have a relapse and were alive at the time of the final analysis) and 7 to the observation group (4 patients had a relapse and were alive at the time of the final analysis and 3 died). Among the 59 patients who did not undergo randomization, the median progression-free survival was 11.0 months (95% CI, 6.4 to 28.0), and the median overall survival was 30.6 months (95% CI, 12.3 to 44.6).\n\n【47】Discussion\n----------\n\n【48】Rituximab maintenance therapy that was administered every other month for 3 years after transplantation prolonged event-free survival, progression-free survival, and overall survival among patients with mantle-cell lymphoma who were younger than 66 years of age. These results show the efficacy of a cytarabine-based induction regimen free of anthracycline or alkylating agents in patients with this condition.\n\n【49】Among patients with chemotherapy-sensitive disease who had a response to induction therapy and transplantation and received rituximab maintenance therapy, the 4-year rate of progression-free survival was 83%, and the 4-year rate of overall survival was 89%. Maintenance therapy with rituximab after R-DHAP induction therapy, followed by R-BEAM consolidation therapy, prevented relapses and was associated with a low risk of major infection. Whether maintenance therapy with rituximab improves outcomes in patients who are treated with other regimens is unknown.\n\n【50】The prolongation in overall survival that was observed in this trial suggests that the delivery of maintenance therapy beyond 3 years might be questionable. We did not measure changes in immunoglobulin levels and are unable to assess the degree and duration of immune suppression that are associated with this approach to treatment. We did not detect a higher rate of infectious complications in the rituximab group than in the observation group. Because status regarding minimal residual disease can predict outcome in patients, it could be postulated that patients with negative minimal residual disease status (i.e., those with a level of disease below the threshold of detection) after transplantation may not benefit from maintenance therapy. However, this question has not been addressed. In addition to monitoring for minimal residual disease,  F-fluorodeoxyglucose–positron-emission tomography (FDG-PET) could also be a useful tool to drive medical decision making regarding the use of maintenance therapy after transplantation. Monitoring for minimal residual disease and FDG-PET were performed in the present trial but were not used for decision making.\n\n【51】The use of high-dose cytarabine plus rituximab is recommended in young patients with mantle-cell lymphoma. The most common regimens — that is, alternating R-CHOP or R-DHAP, the alternative maxi-CHOP regimen with high-dose cytarabine (Nordic MCL2 protocol), and R-hyper-CVAD (rituximab, hyperfractionated cyclophosphamide, vincristine, doxorubicin, and dexamethasone)  — combine rituximab and cytarabine, alkylating agents, and an anthracycline. We reasoned, on the basis of results from previous clinical trials, that cytarabine and platinum derivatives alone might be sufficient to induce a response rate similar to that seen in combined protocols that have used regimens with anthracyclines or alkylating agents. The rates of response and complete response after the administration of R-DHAP in the trial population seem to be similar to those that have been observed with regimens including anthracycline or alkylating agents. R-DHAP induction therapy has several advantages, including its easy use in daily practice, short duration, and low doses of cytarabine. In addition, it has no late cardiac toxic effects. Among the 184 patients who received cisplatin in the first course of chemotherapy, 27 switched to carboplatin and 38 switched to oxaliplatin. In contrast, only 1 patient who was treated with carboplatin switched to cisplatin, and 1 who was treated with oxaliplatin switched to carboplatin. In view of the toxicity of cisplatin, a prospective trial addressing the choice of platinum compound in chemotherapy for lymphoma is warranted.\n\n【52】The most commonly used conditioning regimens are BEAM (carmustine, etoposide, cytarabine, and melphalan), BEAC (carmustine, etoposide, cytarabine, and cyclophosphamide), and a total-body irradiation–based regimen.  The role of total-body irradiation is still a matter of debate because it is not available in all centers and is associated with considerable short-term and long-term toxic effects. Our results with regard to progression-free survival and overall survival are in line with those of the Nordic Lymphoma Group and suggest that total-body irradiation–based conditioning regimens may not be superior to chemotherapy alone when an effective regimen is used during induction. \n\n【53】In conclusion, our trial showed that an induction regimen with four courses of R-DHAP followed by transplantation without total-body irradiation resulted in a high rate of complete response. A 3-year course of rituximab maintenance therapy administered every 2 months prolonged overall survival among young patients with mantle-cell lymphoma.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "(Results regarding progression-free survival and overall survival that were calculated from inclusion and according to MIPI score are provided in Figs. S2 through S5 in the Supplementary Appendix .)", "content": "【0】Rituximab after Autologous Stem-Cell Transplantation in Mantle-Cell Lymphoma\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Mantle-cell lymphoma is generally incurable. Despite high rates of complete response after initial immunochemotherapy followed by autologous stem-cell transplantation, patients have relapses. We investigated whether rituximab maintenance therapy at a dose of 375 mg per square meter of body-surface area administered every 2 months for 3 years after transplantation would prolong the duration of response.\n\n【3】Methods\n-------\n\n【4】In a phase 3 trial involving 299 patients who were younger than 66 years of age at diagnosis, we randomly assigned 240 patients to receive rituximab maintenance therapy or to undergo observation after autologous stem-cell transplantation (120 patients per group); 59 patients did not undergo randomization. The primary end point was event-free survival (with an event defined as disease progression, relapse, death, allergy to rituximab, or severe infection) after transplantation among patients who underwent randomization.\n\n【5】Results\n-------\n\n【6】After four courses of immunochemotherapy induction (rituximab, dexamethasone, cytarabine, and a platinum derivative \\[R-DHAP\\]), the overall response rate was 89%, and the complete response rate 77%. Transplantation was performed in 257 patients. The median follow-up from randomization after transplantation was 50.2 months (range, 46.4 to 54.2). Starting from randomization, the rate of event-free survival at 4 years was 79% (95% confidence interval \\[CI\\], 70 to 86) in the rituximab group versus 61% (95% CI, 51 to 70) in the observation group (P=0.001). The rate of progression-free survival at 4 years was 83% (95% CI, 73 to 88) in the rituximab group versus 64% (95% CI, 55 to 73) in the observation group (P<0.001). The rate of overall survival was 89% (95% CI, 81 to 94) in the rituximab group versus 80% (95% CI, 72 to 88) in the observation group (P=0.04). According to a Cox regression unadjusted analysis, the rate of overall survival at 4 years was higher in the rituximab group than in the observation group (hazard ratio for death, 0.50; 95% CI, 0.26 to 0.99; P=0.04).\n\n【7】Conclusions\n-----------\n\n【8】Rituximab maintenance therapy after transplantation prolonged event-free survival, progression-free survival, and overall survival among patients with mantle-cell lymphoma who were younger than 66 years of age at diagnosis. \n\n【9】Introduction\n------------\n\n【10】Mantle-cell lymphoma, which is characterized by a specific immunophenotype and the chromosomal translocation t(11;14),  accounts for approximately 6% of non-Hodgkin’s lymphomas among adults. After treatment, most patients have a relapse, and the duration of response decreases with each successive salvage therapy. \n\n【11】One of the commonly recommended first-line treatments for patients who are eligible (according to standard guidelines) to undergo transplantation includes combined treatment with rituximab and high-dose cytarabine followed by autologous stem-cell transplantation.  Recently, a phase 3 prospective trial showed an advantage of alternating a chemotherapy regimen consisting of rituximab, cyclophosphamide, doxorubicin, vincristine, and prednisolone (R-CHOP) and a regimen consisting of rituximab, dexamethasone, high-dose cytarabine, and a platinum derivative (R-DHAP), as compared with the R-CHOP regimen alone, before transplantation.  Young patients with untreated mantle-cell lymphoma who received the R-CHOP and R-DHAP regimens had longer progression-free survival and a longer duration of remission than those who received the R-CHOP regimen alone, but they did not have longer overall survival.\n\n【12】The lack of a plateau on the survival curve in the results of the prospective trials that have been published to date  suggests that residual tumor cells may persist after the end of treatment and that these may drive relapses. Thus, we hypothesized that maintenance therapy may prolong the duration of complete response and reduce the risk of relapse.\n\n【13】Rituximab, a monoclonal antibody targeting CD20, has shown a good safety profile and high efficiency in patients with various B-cell lymphomas. Prospective trials have investigated maintenance therapy with rituximab.  The European Mantle Cell Lymphoma Network found that among elderly patients who had an initial response to R-CHOP, rituximab maintenance therapy until disease progression prolonged both progression-free survival and overall survival.  Rituximab maintenance therapy is currently not recommended after transplantation.\n\n【14】We conducted a randomized, prospective, phase 3 trial to investigate the role of rituximab maintenance therapy in patients with mantle-cell lymphoma who had undergone autologous stem-cell transplantation. Because cytarabine plays a major role before transplantation in patients with mantle-cell lymphoma, four courses of R-DHAP were used as induction therapy. R-DHAP is an immunochemotherapy regimen without alkylating and anthracycline agents. To reduce the risk of long-term toxic effects, we used a transplantation conditioning regimen without total-body irradiation. The primary end point of the trial was event-free survival as evaluated from the date of randomization.\n\n【15】Methods\n-------\n\n【16】Characteristics of the Patients\n-------------------------------\n\n【17】The trial included patients 18 to 65 years of age who had untreated mantle-cell lymphoma and were eligible to undergo autologous stem-cell transplantation, who had disease of Ann Arbor stage II through IV (on a four-stage scale on which stage I indicates localized disease and increasing stage indicates more widespread disease), and who had an Eastern Cooperative Oncology Group (ECOG) performance-status score of less than 3 (on a 5-point scale, with higher numbers indicating increasing disability). Patients who were positive for the human immunodeficiency virus or those who presented with major coexisting conditions at diagnosis that were not related to lymphoma were excluded. The diagnosis of mantle-cell lymphoma was established by local expert pathologists and reviewed centrally by pathology experts according to the 2008 World Health Organization classification. All the patients provided written informed consent.\n\n【18】Trial Protocol\n--------------\n\n【19】Patients were included in the trial at the time of diagnosis. In brief, patients received induction chemotherapy with four courses of R-DHAP, repeated every 21 days. According to local practice (or in case of renal failure during treatment), investigators were allowed to use carboplatin or oxaliplatin instead of cisplatin. Stem cells were obtained according to local practice, after the third or fourth course of R-DHAP. The use of a chemotherapy regimen for stem-cell mobilization was not authorized.\n\n【20】Tumor status was assessed according to the 1999 International Working Group criteria by local investigators . After four courses of R-DHAP, patients who were having a partial response and whose tumor mass had been reduced by less than 75%, as assessed by means of computed tomography (CT), received a rescue induction therapy with four courses of R-CHOP (rituximab, cyclophosphamide, doxorubicin, vincristine, and prednisolone), administered as one course every 14 days. Only patients who were having a response, including those in complete remission (confirmed or unconfirmed) and those having a partial response (whose tumor mass was reduced by ≥75% after induction), were eligible to undergo transplantation. A minimal peripheral-blood progenitor-cell graft of 2×10 <sup>6 </sup> CD34+ cells per kilogram of body weight was required.\n\n【21】The conditioning regimen before transplantation was R-BEAM (rituximab, carmustine, etoposide, cytarabine, and melphalan). After transplantation and up to 3 months later, patients were randomly assigned to receive rituximab maintenance therapy or to undergo observation. The schedule for maintenance therapy was the receipt of 375 mg of rituximab per square meter of body-surface area, administered intravenously every 2 months for 3 years. The total number of planned doses of rituximab was 23 (4 doses administered with induction therapy, 1 dose with the preparative regimen for transplantation, and 18 doses over the 3 years of maintenance therapy).\n\n【22】Oversight\n---------\n\n【23】This unblinded, randomized prospective trial was performed according to the principles of the Declaration of Helsinki, and the protocol was approved by an ethics committee. The trial began before it was registered on ClinicalTrials.gov owing to an administrative error. A total of 29 patients were enrolled before registration. The first author and the last two authors designed the trial. Data were gathered by the investigators and by the sponsor and were analyzed by LYSARC (the academic research organization of the Lymphoma Study Association \\[LYSA\\]). All the authors had access to the data. The first author wrote the initial draft of the manuscript. All the authors contributed to the subsequent drafts, reviewed them, and jointly decided to submit the manuscript for publication. All the authors vouch for the integrity, accuracy, and completeness of the data and analyses and for the fidelity of the trial to the protocol . Roche supplied rituximab for the R-BEAM regimen and for maintenance therapy and funded the trial but did not contribute to the protocol design, trial execution, data collection or analysis, the writing of the manuscript, or the decision to submit the manuscript for publication.\n\n【24】Staging, Monitoring, and End Points\n-----------------------------------\n\n【25】At the time of inclusion, the disease characteristics of the patients were assessed by means of clinical examination, standard biologic variables, bone marrow biopsy, and CT scan (neck, chest, abdomen, and pelvis). Response to therapy was assessed after the receipt of four courses of R-DHAP (and after R-CHOP in patients who received salvage therapy) and after transplantation. Randomization was stratified, in a  ratio, according to the use or nonuse of R-CHOP before transplantation.\n\n【26】The primary end point was event-free survival after randomization. Events were defined as disease progression, relapse, death, severe infection (grade 4 with life-threatening severity), or allergy to rituximab that led to the discontinuation of treatment after randomization. Secondary end points were progression-free survival (i.e., freedom from disease progression, relapse, and death from any cause) and overall survival as assessed from inclusion and from randomization. The trial design and follow-up assessments are described in detail in the Supplementary Appendix .\n\n【27】Statistical Analysis\n--------------------\n\n【28】Event-free survival was monitored and analyzed according to a group-sequential plan that included one interim analysis in order to allow for early stopping on the basis of efficacy. The total sample of 299 patients provided the trial with 80% power to detect a difference of 13 percentage points in the rate of event-free survival at 4 years (expected rates of 83% in the rituximab group vs. 70% in the observation group) at an alpha level of 0.05. O’Brien–Fleming boundaries were used to check for type I error, with the overall alpha level being 0.05 for the number of patients who were included at the time of data cutoff. The interim analysis was performed when at least 82 patients had reached 3 years after transplantation. The significance level for the interim analysis was set at 0.0051, and the significance level for the final analysis was set at 0.0475. At the interim analysis, with a median follow-up of 34 months after transplantation, the rate of event-free survival (P=0.006 by the log-rank test) was under the O’Brien–Fleming boundary. The present analysis is the final analysis.\n\n【29】The intention-to-treat population included all the patients who had undergone randomization, and the primary and secondary end points were evaluated with the inclusion of all patients who had protocol violations or withdrew. The included-patients population constituted all the patients who provided written informed consent.\n\n【30】Time-to-event survival curves were estimated with the use of the Kaplan–Meier method. Time-to-event end points in the different groups were compared with the use of log-rank tests and Cox proportional-hazards regression. Patients who withdrew (e.g., all the patients who did not undergo randomization for any reason) and patients who were lost to follow-up (e.g., all the patients who underwent randomization and for whom an outcome was not updated for >1 year at the time of the final analysis) who did not have an event, as defined in the protocol at the time of the final analysis, had their data censored at the time of their last visit. Response rates were expressed in percentages with 95% exact confidence intervals that were based on the Clopper–Pearson method. All the statistical analyses were performed with the use of SAS software, version 9.3 (SAS Institute).\n\n【31】Results\n-------\n\n【32】Treatment\n---------\n\n【33】<mark>Figure 1. </mark>Eligibility Assessment, Treatment, Randomization, and Follow-up of the Patients.\n\n【34】The R-DHAP regimen consisted of rituximab, dexamethasone, high-dose cytarabine, and a platinum derivative. A total of 20 patients who received all four courses of the R-DHAP regimen then received the R-CHOP regimen, which consisted of rituximab, cyclophosphamide, doxorubicin, vincristine, and prednisolone. After autologous stem-cell transplantation, 120 patients were assigned to receive rituximab maintenance therapy and 120 were assigned to the observation group.Table 1.  Table 1. Demographic and Clinical Characteristics of the Patients at the Time of Inclusion in the Trial.\n\n【35】From September 2008 through August 2012, we enrolled 299 patients in the study . The characteristics of the patients at the time of inclusion are shown in Table 1 . The central pathological review confirmed the diagnosis in all patients (by means of immunochemical testing for immunophenotype, except in 5 patients in whom the diagnosis was made by means of fluorescence in situ hybridization of blood samples) except for 1, whose disease was classified as hairy-cell leukemia (this patient was retained in the included-patients population but did not undergo randomization).\n\n【36】One course of cyclophosphamide, vincristine, and prednisolone was administered to 35 patients (12%) before the initiation of R-DHAP induction therapy. Carboplatin was used from the first course of R-DHAP in 76 patients, and oxaliplatin was used in 38; the remainder received cisplatin. The overall response rate after induction therapy was 94%, including a complete response in 124 patients (41%) and an unconfirmed complete response in 107 (36%). The main reasons to stop treatment during induction therapy were disease progression (in 5 patients) and toxic effects (in 7) . All the patients who had renal toxic effects had received cisplatin. R-CHOP was administered in 20 patients who had an insufficient response after R-DHAP, and 10 of these patients proceeded to transplantation (3 patients were having a complete remission, 6 were having an unconfirmed complete remission, and 1 was having a partial response).\n\n【37】Overall, 257 of 299 patients (86%) underwent transplantation. After transplantation, 168 of 257 patients (65%) had a complete remission, and 61 (24%) had an unconfirmed complete remission. A total of 240 of 299 patients (80%) underwent randomization and constituted the intention-to-treat population; 120 patients were randomly assigned to the group that received rituximab maintenance therapy and 120 to the observation group. There was no significant difference between the two groups regarding the characteristics at enrollment (inclusion) and the patients’ disease status at randomization .\n\n【38】Outcome\n-------\n\n【39】At the stopping date (July 1, 2015), the median follow-up from inclusion was 54.4 months (range, 52.7 to 59.2), and the median follow-up from randomization was 50.2 months (range, 46.4 to 54.2). In the included-patients population, the median progression-free survival and median overall survival, as calculated from inclusion, were not reached. Among these patients, the 4-year rate of progression-free survival was 68% (95% confidence interval \\[CI\\], 62 to 73), and the 4-year rate of overall survival was 78% (95% CI, 73 to 82). According to the Mantle Cell Lymphoma International Prognostic Index (MIPI),  which is used to assess risk on the basis of age, ECOG performance-status score, lactate dehydrogenase level, and white-cell count , the median progression-free survival and overall survival were not reached among low-risk and intermediate-risk patients; among high-risk patients, the median progression-free survival was 47.4 months and the median overall survival was 56.2 months (P<0.001 for both comparisons with the low-risk group). (Results regarding progression-free survival and overall survival that were calculated from inclusion and according to MIPI score are provided in Figs. S2 through S5 in the Supplementary Appendix .)\n\n【40】According to the protocol definition, 25 patients (21%) had an event in the rituximab group, as compared with 47 (39%) in the observation group. A total of 83 patients in the rituximab group completed the scheduled 3-year course of therapy. The main reasons to stop maintenance therapy were disease progression (in 16 patients) and neutropenia (in 9). Serious infection after transplantation was observed in 4 patients in each group (spondylitis, pyelonephritis, septicemia, and varicella pneumonia in 1 patient each in the rituximab group and septicemia, cellulitis, meningitis, and severe pneumonia in both lungs in 1 patient each in the observation group).\n\n【41】Information regarding grade 3 and 4 toxic effects, according to randomization and trial period, is provided in Table S1 in the Supplementary Appendix . In brief, the most frequent toxic event of grade 3 or 4 was neutropenia. A second cancer caused death in 3 patients in the rituximab group and in 1 in the observation group. No late effect of rituximab has been reported so far in either trial group. After randomization, 16 patients had disease progression and 13 patients died in the rituximab group, as compared with 37 patients who had disease progression and 24 who died in the observation group. The major cause of death in each group was lymphoma (in 8 patients in the rituximab group and 16 in the observation group).\n\n【42】<mark>Figure 2. </mark>Event-free Survival, Progression-free Survival, and Overall Survival.\n\n【43】The Kaplan–Meier analyses of event-free survival, progression-free survival, and overall survival were performed according to trial group. Survival was calculated from the time of randomization. Event-free survival was defined as freedom from disease progression, relapse, death, allergy to rituximab, and severe infection. The hazard ratio for progression, relapse, death, rituximab allergy, or infection was 0.46 (95% CI, 0.28 to 0.74; P=0.002) . Tick marks indicate censored data, and the shaded areas 95% confidence intervals. Progression-free survival was defined as freedom from disease progression, relapse, and death from any cause. The hazard ratio for progression, relapse, or death was 0.40 (95% CI, 0.23 to 0.68; P<0.001) . In the analysis of overall survival, the hazard ratio for death was 0.50 (95% CI, 0.26 to 0.99; P=0.04) .\n\n【44】The median event-free survival from randomization was not reached in either group . The 4-year rate of event-free survival as calculated from randomization was 79% (95% CI, 70 to 86) in the rituximab group, as compared with 61% (95% CI, 51 to 70) in the observation group (P=0.001), with a hazard ratio for disease progression, relapse, death, rituximab allergy, or severe infection of 0.46 (95% CI, 0.28 to 0.74; P=0.002).\n\n【45】The median progression-free survival and overall survival from randomization were not reached in either group. The 4-year rates of progression-free survival and overall survival were significantly higher in the rituximab group than in the observation group. The rate of progression-free survival was 83% (95% CI, 73 to 88) in the rituximab group, as compared with 64% (95% CI, 55 to 73) in the observation group (hazard ratio for disease progression, relapse, or death, 0.40; 95% CI, 0.23 to 0.68; P<0.001) . The rate of overall survival was 89% (95% CI, 81 to 94) in the rituximab group, as compared with 80% (95% CI, 72 to 88) in the observation group (hazard ratio for death, 0.50; 95% CI, 0.26 to 0.99; P=0.04) . The per-protocol analysis yielded similar results .\n\n【46】A total of 11 patients received R-CHOP before randomization; of these patients, 4 were assigned to the rituximab group (1 patient had disease progression and died and 3 did not have a relapse and were alive at the time of the final analysis) and 7 to the observation group (4 patients had a relapse and were alive at the time of the final analysis and 3 died). Among the 59 patients who did not undergo randomization, the median progression-free survival was 11.0 months (95% CI, 6.4 to 28.0), and the median overall survival was 30.6 months (95% CI, 12.3 to 44.6).\n\n【47】Discussion\n----------\n\n【48】Rituximab maintenance therapy that was administered every other month for 3 years after transplantation prolonged event-free survival, progression-free survival, and overall survival among patients with mantle-cell lymphoma who were younger than 66 years of age. These results show the efficacy of a cytarabine-based induction regimen free of anthracycline or alkylating agents in patients with this condition.\n\n【49】Among patients with chemotherapy-sensitive disease who had a response to induction therapy and transplantation and received rituximab maintenance therapy, the 4-year rate of progression-free survival was 83%, and the 4-year rate of overall survival was 89%. Maintenance therapy with rituximab after R-DHAP induction therapy, followed by R-BEAM consolidation therapy, prevented relapses and was associated with a low risk of major infection. Whether maintenance therapy with rituximab improves outcomes in patients who are treated with other regimens is unknown.\n\n【50】The prolongation in overall survival that was observed in this trial suggests that the delivery of maintenance therapy beyond 3 years might be questionable. We did not measure changes in immunoglobulin levels and are unable to assess the degree and duration of immune suppression that are associated with this approach to treatment. We did not detect a higher rate of infectious complications in the rituximab group than in the observation group. Because status regarding minimal residual disease can predict outcome in patients, it could be postulated that patients with negative minimal residual disease status (i.e., those with a level of disease below the threshold of detection) after transplantation may not benefit from maintenance therapy. However, this question has not been addressed. In addition to monitoring for minimal residual disease,  F-fluorodeoxyglucose–positron-emission tomography (FDG-PET) could also be a useful tool to drive medical decision making regarding the use of maintenance therapy after transplantation. Monitoring for minimal residual disease and FDG-PET were performed in the present trial but were not used for decision making.\n\n【51】The use of high-dose cytarabine plus rituximab is recommended in young patients with mantle-cell lymphoma. The most common regimens — that is, alternating R-CHOP or R-DHAP, the alternative maxi-CHOP regimen with high-dose cytarabine (Nordic MCL2 protocol), and R-hyper-CVAD (rituximab, hyperfractionated cyclophosphamide, vincristine, doxorubicin, and dexamethasone)  — combine rituximab and cytarabine, alkylating agents, and an anthracycline. We reasoned, on the basis of results from previous clinical trials, that cytarabine and platinum derivatives alone might be sufficient to induce a response rate similar to that seen in combined protocols that have used regimens with anthracyclines or alkylating agents. The rates of response and complete response after the administration of R-DHAP in the trial population seem to be similar to those that have been observed with regimens including anthracycline or alkylating agents. R-DHAP induction therapy has several advantages, including its easy use in daily practice, short duration, and low doses of cytarabine. In addition, it has no late cardiac toxic effects. Among the 184 patients who received cisplatin in the first course of chemotherapy, 27 switched to carboplatin and 38 switched to oxaliplatin. In contrast, only 1 patient who was treated with carboplatin switched to cisplatin, and 1 who was treated with oxaliplatin switched to carboplatin. In view of the toxicity of cisplatin, a prospective trial addressing the choice of platinum compound in chemotherapy for lymphoma is warranted.\n\n【52】The most commonly used conditioning regimens are BEAM (carmustine, etoposide, cytarabine, and melphalan), BEAC (carmustine, etoposide, cytarabine, and cyclophosphamide), and a total-body irradiation–based regimen.  The role of total-body irradiation is still a matter of debate because it is not available in all centers and is associated with considerable short-term and long-term toxic effects. Our results with regard to progression-free survival and overall survival are in line with those of the Nordic Lymphoma Group and suggest that total-body irradiation–based conditioning regimens may not be superior to chemotherapy alone when an effective regimen is used during induction. \n\n【53】In conclusion, our trial showed that an induction regimen with four courses of R-DHAP followed by transplantation without total-body irradiation resulted in a high rate of complete response. A 3-year course of rituximab maintenance therapy administered every 2 months prolonged overall survival among young patients with mantle-cell lymphoma.", "index": 1050, "show": true, "start": 1050, "end": 1248, "province": ["文本干净度", "无关文本"], "isEdit": false}]}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-14 00:15:56", "grab_time": "2024-08-13 23:46:25"}
{"id": 2234521, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "e51f33b3-4d39-423d-b6f1-218e5c1a7d0e", "title": "Treating Rhythmic and Periodic EEG Patterns in Comatose Survivors of Cardiac Arrest", "text": "【0】Treating Rhythmic and Periodic EEG Patterns in Comatose Survivors of Cardiac Arrest\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Whether the treatment of rhythmic and periodic electroencephalographic (EEG) patterns in comatose survivors of cardiac arrest improves outcomes is uncertain.\n\n【3】Methods\n-------\n\n【4】Download a PDF of the Research Summary .\n\n【5】We conducted an open-label trial of suppressing rhythmic and periodic EEG patterns detected on continuous EEG monitoring in comatose survivors of cardiac arrest. Patients were randomly assigned in a  ratio to a stepwise strategy of antiseizure medications to suppress this activity for at least 48 consecutive hours plus standard care (antiseizure-treatment group) or to standard care alone (control group); standard care included targeted temperature management in both groups. The primary outcome was neurologic outcome according to the score on the Cerebral Performance Category (CPC) scale at 3 months, dichotomized as a good outcome (CPC score indicating no, mild, or moderate disability) or a poor outcome (CPC score indicating severe disability, coma, or death). Secondary outcomes were mortality, length of stay in the intensive care unit (ICU), and duration of mechanical ventilation.\n\n【6】Results\n-------\n\n【7】We enrolled 172 patients, with 88 assigned to the antiseizure-treatment group and 84 to the control group. Rhythmic or periodic EEG activity was detected a median of 35 hours after cardiac arrest; 98 of 157 patients (62%) with available data had myoclonus. Complete suppression of rhythmic and periodic EEG activity for 48 consecutive hours occurred in 49 of 88 patients (56%) in the antiseizure-treatment group and in 2 of 83 patients (2%) in the control group. At 3 months, 79 of 88 patients (90%) in the antiseizure-treatment group and 77 of 84 patients (92%) in the control group had a poor outcome (difference, 2 percentage points; 95% confidence interval, −7 to 11; P=0.68). Mortality at 3 months was 80% in the antiseizure-treatment group and 82% in the control group. The mean length of stay in the ICU and mean duration of mechanical ventilation were slightly longer in the antiseizure-treatment group than in the control group.\n\n【8】Conclusions\n-----------\n\n【9】In comatose survivors of cardiac arrest, the incidence of a poor neurologic outcome at 3 months did not differ significantly between a strategy of suppressing rhythmic and periodic EEG activity with the use of antiseizure medication for at least 48 hours plus standard care and standard care alone. \n\n【10】Introduction\n------------\n\n【11】 QUICK TAKE  \nTreating Epileptiform Activity after Cardiac Arrest  \n\n【12】Rhythmic and periodic electroencephalographic (EEG) patterns that may reflect electrographic seizures have been reported in 10 to 35% of comatose patients after cardiac arrest. Unequivocal electrographic or clinical seizures are infrequent, whereas generalized periodic discharges are common in these patients  and have generally been associated with a poor neurologic outcome.  Whether rhythmic and periodic EEG patterns should be treated with antiseizure medications, with the goal of improving the neurologic outcome, is unclear. \n\n【13】Uncertainty about the efficacy of treatment has been reflected in surveys showing that approximately one third of neurologists use a stepwise antiseizure-medication strategy to suppress epileptiform EEG activity in nonconvulsive status epilepticus and status epilepticus, one third use these medications in a nonstandardized way, and one third do not use antiseizure medications because of presumed futility of improving the neurologic outcome.  It has been suggested that the effects of antiseizure medication depend on the specific EEG pattern being treated. \n\n【14】We conducted the Treatment of Electroencephalographic Status Epilepticus after Cardiopulmonary Resuscitation (TELSTAR) trial to assess whether intensive, stepwise antiseizure and sedative treatment to suppress rhythmic and periodic EEG patterns detected in continuous EEG monitoring would alter the outcomes in comatose patients after cardiac arrest. We hypothesized that the use of antiseizure medication would reduce the incidence of a poor neurologic outcome at 3 months.\n\n【15】Methods\n-------\n\n【16】Trial Design\n------------\n\n【17】This trial was a pragmatic, multicenter clinical trial with randomized treatment assignments, open-label treatment, and blinded end-point evaluation at 11 intensive care units (ICUs) in the Netherlands and Belgium. Stepwise treatment to suppress rhythmic and periodic EEG patterns on continuously monitored EEG plus standard care was compared with standard care alone in comatose patients after cardiac arrest. The trial was supported by a grant from the Dutch Epilepsy Foundation (NEF14-18), which was not involved in trial design or conduct, data analysis, or manuscript preparation or review.\n\n【18】The trial protocol  was approved by a central medical ethics committee and by the research boards at each participating center. Written informed consent was obtained from legal representatives of patients before randomization or, from January 10, 2017, was obtained in a deferred manner from the patient if possible, within 24 hours after randomization. Written informed consent for follow-up was obtained from surviving patients or from legal representatives. An independent data and safety monitoring board analyzed safety when 25%, 50%, and 75% of the patients had been enrolled and assessed efficacy when 50% of the patients had been enrolled.\n\n【19】This trial was an investigator-initiated trial, with no commercial involvement. The executive committee designed the trial. Members of the executive committee and local investigators collected and analyzed the data and wrote the manuscript. The authors vouch for the accuracy and completeness of the data and for the fidelity of the trial to the protocol.\n\n【20】Trial Population\n----------------\n\n【21】Eligible patients were 18 years of age or older, were comatose (Glasgow Coma Scale score, ≤8; range, 3 to 15, with lower scores indicating worse responses to stimuli) after resuscitation for cardiac arrest, had continuous EEG monitoring started less than 24 hours after the return of spontaneous circulation, and had rhythmic or periodic activity on EEG. Continuous EEG monitoring was standard practice in all participating hospitals, but we did not maintain a case log of all patients with cardiac arrest in these units during the trial. Rhythmic and periodic EEG patterns were defined as periodic discharges, rhythmic delta activity, spike-and-wave or sharp-and-wave EEG patterns, each at a rate of 0.5 Hz or more, irrespective of their spatial evolution across EEG montages or temporal evolution. The minimum duration of continuous activity of these patterns for inclusion in the trial was 30 minutes or, if intermittent, 5 minutes, recurring at least twice at intervals of less than 60 minutes. Detailed inclusion and exclusion criteria are listed under Additional Methods in the Supplementary Appendix .\n\n【22】Trial Interventions\n-------------------\n\n【23】Patients were randomly assigned to receive protocol-defined antiseizure medication plus standard care (antiseizure-treatment group) or standard care alone (control group) with the use of the Web-based service ALEA (Clinical Trial Center Maastricht, the Netherlands) in a  ratio with permuted blocks (block size, 4 to 10) stratified according to center. The antiseizure intervention consisted of a stepwise treatment strategy with the intent of completely suppressing rhythmic and periodic EEG activity on continuous EEG monitoring. Standard care was left to the discretion of the treating physicians but generally followed European guidelines and included targeted temperature management in both trial groups. \n\n【24】In the antiseizure-treatment group, treatment of rhythmic and periodic EEG patterns was based on international guidelines for the treatment of status epilepticus.  Step 1 was a first antiseizure drug plus a first sedative agent (usually midazolam or propofol), step 2 was a second antiepileptic drug plus a second sedative agent, and step 3 was a high-dose barbiturate; all medications were administered intravenously. Permitted antiseizure medications were phenytoin, valproate, and levetiracetam. Because no antiseizure or sedative drug has been proven superior to another in improving outcomes after status epilepticus, medications were chosen by the treating physician in the doses and infusion rates as indicated in the protocol.  The treatment flow chart is available in the Supplementary Appendix under Additional Methods.\n\n【25】The goal of antiseizure treatment was to suppress all rhythmic and periodic EEG activity for at least 48 consecutive hours (defined as >90% of activity suppressed). Each subsequent step was taken as soon as possible when the previous step failed to suppress all this activity. There was no obligation to induce burst suppression on EEG. In the antiseizure-treatment group, treatment was started within 3 hours after detection of rhythmic and periodic EEG patterns. Treatment was guided by a neurologist or clinical neurophysiologist who analyzed the EEG findings and adjusted or changed medication according to the protocol in consultation with the ICU physician. Treating physicians were allowed to follow local protocols for treatment of seizurelike activity, provided that these were in line with the overall stepwise approach. If rhythmic and periodic EEG patterns returned after 48 hours with the use of at least two antiseizure medications, the decision to prolong antiseizure treatment was left to the discretion of the treating physician. In the control group, physicians were allowed to prescribe sedative medication if needed for mechanical ventilation or to suppress clinically manifest myoclonus, irrespective of the EEG findings; additional use of antiseizure drugs was discouraged in the control group.\n\n【26】In both groups, decisions regarding limitation or withdrawal of treatment were based on Dutch guidelines, which were derived from the European guidelines at the time we started the trial.  Withdrawal of treatment could be considered during normothermia and while the patient was not receiving sedation if there was incomplete return of brain-stem reflexes and bilateral absence of somatosensory evoked potentials  ; however, EEG patterns in the previous 72 hours were not taken into account in these decisions.\n\n【27】Trial Outcomes\n--------------\n\n【28】The primary outcome was neurologic outcome according to the score on the Cerebral Performance Category (CPC) scale at 3 months, dichotomized as a good outcome (CPC score of 1 \\[no or mild neurologic disability\\] or 2 \\[moderate disability\\]) or a poor outcome (CPC score of 3 \\[severe disability\\], 4 \\[coma\\], or 5 \\[death\\]).  These scores were obtained at 3 months after admission by a standardized telephone interview conducted by an investigator who was unaware of the trial-group assignments and EEG pattern. Secondary outcomes were mortality at 3 months, length of stay in the ICU, and duration of mechanical ventilation. Safety outcomes included any serious adverse events. Outcomes at 6 and 12 months have not yet been analyzed. Treating physicians were aware of the trial-group assignments and reported serious adverse events to the principal investigator by e-mail.\n\n【29】EEG Monitoring\n--------------\n\n【30】Continuous EEG monitoring was initiated within 24 hours after resuscitation as part of standard care in participating ICUs and continued for at least 3 days, until discharge from the ICU or until rhythmic and periodic EEG activity was extinguished. The standard international 10–20 system of electrode placement (in nine hospitals) or a limited montage with 10 electrodes (in two hospitals) was used according to local protocols. EEG recordings were checked every 3 hours by a neurologist, clinical neurophysiologist, or clinical neurophysiology technician. The diagnosis of rhythmic and periodic EEG patterns was made by the attending neurologist or clinical neurophysiologist. Guidance was given by typical examples of eligible EEG patterns on our website, at yearly meetings to discuss these patterns, and on a 24/7 online platform through which we were able to exchange EEG information and provide advice in real time if requested.\n\n【31】The final classifications of EEG patterns at baseline and suppression of activity were determined by central reading of EEGs by the first two and last two authors, who were aware of the trial-group assignments. They classified the EEG pattern at inclusion as electrographic seizures (discharges at ≥2.5 Hz), evolving patterns (0.5 to 2.5 Hz), generalized periodic discharges (0.5 to 2.5 Hz), or other periodic patterns (0.5 to 2.5 Hz), with continuous, discontinuous, or suppressed background activity. They classified the treatment effect on the index EEG activity in both groups as complete suppression (>90%), partial suppression (50 to 90%), or no suppression (<50%).\n\n【32】Statistical Analysis\n--------------------\n\n【33】We calculated a sample size of 172 patients: 84 per group on the basis of a prevalence of a poor outcome of 99% derived from uncontrolled cohorts,  a presumed lower incidence of a poor outcome in the antiseizure-treatment group than in the control group by 7 percentage points, an alpha level of 5%, a beta level of 80%, and one-tailed testing as well as two additional patients per group to compensate for a planned interim analysis after 86 patients had been enrolled.  The statistical analysis plan  was finalized before the database was locked and before data were analyzed.\n\n【34】The primary analysis was a single comparison between the two trial groups with regard to the dichotomized primary outcome according to the intention-to-treat principle, expressed as the risk difference (between-group difference in percentage points) of a poor outcome, including the corresponding 95% confidence interval. The level of statistical significance for the difference in the primary outcome was P=0.0429 to accommodate a single interim analysis of efficacy that used O’Brien–Fleming boundaries. \n\n【35】Secondary analyses of the primary outcome included risk differences of a poor outcome for all other dichotomous outcomes on the CPC scale, as well as the shift across CPC scores in the direction of a better outcome in the antiseizure-treatment group, analyzed by means of multivariable ordinal logistic regression and expressed as a common odds ratio. For secondary outcomes, between-group differences were analyzed by means of independent-samples t-tests, Mann–Whitney tests, or Fisher exact tests, where appropriate. Because there was no prespecified plan for adjustment of the widths of confidence intervals for multiple comparisons of secondary outcomes, no definite conclusions can be drawn from these data. There was no prespecified plan for the handling of missing data. We performed prespecified per-protocol analyses involving all patients who received antiseizure drugs as compared with those who did not receiving antiseizure drugs. We planned multivariable logistic-regression analysis to adjust for imbalances in baseline prognostic variables between the antiseizure-treatment group and the control group, if applicable.\n\n【36】Treatment-effect modification was explored in prespecified subgroups defined by seizure type at inclusion (electrographic seizures, evolving patterns, generalized periodic discharges, or other), background continuity at inclusion (continuous, discontinuous, or suppressed), and time of onset of rhythmic and periodic EEG patterns (≤24 hours, >24 to <48 hours, or ≥48 hours after the return of spontaneous circulation), but the trial was not powered for these subgroups. An additional post hoc exploratory subgroup analysis was added according to generalized periodic discharges as compared with nongeneralized periodic discharges in EEG patterns at inclusion, as suggested by findings reported in the literature.  All analyses were performed with the use of MATLAB software, version 2021a (MathWorks).\n\n【37】Results\n-------\n\n【38】Baseline Characteristics\n------------------------\n\n【39】Between May 1, 2014, and January 24, 2021, continuous EEG recordings were started in 2528 patients, rhythmic and periodic EEG activity was detected in 354, and 172 were included in the trial, with 88 assigned to the antiseizure-treatment group and 84 to the control group . A total of 72 patients were not enrolled because their EEG recordings were not interpreted rapidly enough to be included. All included patients had complete follow-up at 3 months. There was one interim analysis after 86 patients had been enrolled.\n\n【40】Table 1. Characteristics of the 172 Patients at Baseline.\n\n【41】The median age of the patients was 65 years (interquartile range, 57 to 74), and 118 (69%) were men. Rhythmic and periodic EEG patterns started at a median of 35 hours (interquartile range, 27 to 44) after cardiac arrest, and 98 of 157 patients (62%) had myoclonus. Approximately 80% of the patients in both groups had generalized periodic discharges, and 10% had electrographic seizures. Baseline characteristics were similar in the two groups . The representativeness of trial patients is shown in Table S1.\n\n【42】EEG Response\n------------\n\n【43】Table 2. Antiseizure Treatment and EEG Response.\n\n【44】All the patients in the antiseizure-treatment group and 8 in the control group were treated with at least one antiseizure medication. All the patients who were assigned to the antiseizure-treatment group received the intended treatment strategy. Complete suppression of paroxysmal EEG activity for the 24 hours after randomization was achieved in 64 of 88 patients (73%) in the antiseizure-treatment group and in 3 of 83 patients (4%) in the control group. Complete suppression of the index EEG activity for 48 consecutive hours at any time after the start of treatment occurred in 49 of 88 patients (56%) in the antiseizure-treatment group and in 2 of 83 patients (2%) in the control group . Suppression for more than 24 hours is shown in Table 2 . Examples of the rhythmic and periodic activity encountered in the trial are shown in Figure S4. The typical evolution of generalized periodic discharges is illustrated in Figure S5: these started with low-frequency activity (<0.5 Hz) and gradually evolved toward frequencies of discharges that met our trial inclusion criteria, on time scales of hours.\n\n【45】Outcomes\n--------\n\n【46】Table 3. Primary, Secondary, and Safety Outcomes (Intention-to-Treat Population). Figure 1.  Figure 1. Cerebral Performance Category Scores at 3 Months (Intention-to-Treat Population).\n\n【47】Patients in the antiseizure-treatment group received intensive antiseizure treatment plus standard care, and patients in the control group received standard care alone. Scores on the Cerebral Performance Category scale range from 1 to 5, with 1 indicating no or mild neurologic disability, 2 moderate disability, 3 severe disability, 4 coma, and 5 death.\n\n【48】At 3 months, 79 of 88 patients (90%) in the antiseizure-treatment group and 77 of 84 patients (92%) in the control group had a poor outcome as defined by a CPC score of 3, 4, or 5 (difference, 2 percentage points; 95% confidence interval \\[CI\\], −7 to 11; P=0.68) . Results were similar for per-protocol analyses . At 3 months, 70 of 88 patients (80%) in the antiseizure-treatment group and 69 of 84 patients (82%) in the control group had died (difference, 3 percentage points; 95% CI, −9 to 14); however, mortality within 24 hours after randomization was 9% in the antiseizure-treatment group and 24% in the control group . Survival curves are shown in Figure S3. All but one death within 24 hours after randomization occurred after withdrawal of life-sustaining treatment. Two patients in each group had a second cardiac arrest; one patient in the control group died more than 24 hours after randomization as a result of a second cardiac arrest. The distribution of CPC scores was similar in the two groups (common odds ratio, 1.19; 95% CI, 0.56 to 2.53) . The mean length of stay in the IUC was 8.7 days in the antiseizure-treatment group and 7.5 days in the control group . The incidence of withdrawal of life-sustaining treatment was approximately 77% in both trial groups . The timing of withdrawal of life-sustaining treatment ranged from 1 to 33 days after ICU admission; in the first 24 hours, withdrawal occurred in 2% of the patients in the antiseizure-treatment group and in 13% of those in the control group .\n\n【49】Safety\n------\n\n【50】The incidence of serious adverse events in the overall population was 145 of 172 patients (84%); serious adverse events were similar in incidence and type in the two trial groups . Adverse events of lesser degree than serious adverse events, such as hypotension, were not systematically recorded.\n\n【51】Exploratory Subgroup Analyses\n-----------------------------\n\n【52】Figure 2. Subgroup Analyses.\n\n【53】The trial was not powered to analyze subgroups, and these results should be considered exploratory. One patient in the control group gave consent for inclusion in the analysis of the primary outcome but not in any other analyses. The between-group difference was calculated as antiseizure-treatment group minus control group. Black squares indicate point estimates of effects, dotted vertical lines indicate no effect, and solid vertical lines indicate the overall effect in the antiseizure-treatment group. EEG denotes electroencephalography, and GPD generalized periodic discharge.\n\n【54】Visual inspection of subgroup plots  suggested that for the most common type of EEG activity, generalized periodic discharges, the antiseizure-treatment group may have had a smaller proportion of good outcomes than the control group, but the trial was not powered to make conclusions from these subgroup results and the results are exploratory. Post hoc analyses of outcomes of generalized periodic discharges as compared with all other patterns are shown in Figure 2B .\n\n【55】Discussion\n----------\n\n【56】In this trial involving comatose patients after cardiac arrest who had rhythmic and periodic EEG patterns, intensive antiseizure treatment adapted from protocols for status epilepticus did not result in fewer poor outcomes at 3 months than standard treatment. Sedative medications were used in both the antiseizure-treatment group and the control group to support mechanical ventilation or suppress myoclonus, which may have led to cessation of rhythmic and periodic EEG activity in the standard-care group that reduced the differences in the incidence of EEG and clinical outcomes between the two groups. The antiseizure intervention was associated with a slightly longer length of stay in the ICU and a longer duration of mechanical ventilation. Overall mortality was 81%, similar to findings in observational studies involving patients who were comatose after cardiac arrest.  A total of 10% of the patients in the antiseizure-treatment group and 8% of those in the control group in our trial had a good neurologic recovery.\n\n【57】In a previous observational study, stepwise, intensive treatment resulted in a good outcome in 16 of 36 patients (44%) with rhythmic and periodic EEG patterns other than generalized periodic discharges, as compared with none of 13 patients with generalized periodic discharges.  In our trial, generalized periodic discharges were the most common aberrant EEG pattern, present in approximately 80% of the patients. As in some other studies, generalized periodic discharges typically started with low frequencies (<0.5Hz), with a gradual evolution toward frequencies that met our inclusion criteria over a period of hours.  This pattern differs from the usual evolution of seizures in status epilepticus, which is characterized by rapid onset of EEG abnormalities, evolving over seconds.  Data from several studies suggest that generalized periodic discharges in postanoxic encephalopathy may be a direct expression of severe ischemic brain damage rather than of epilepsy. \n\n【58】Exploratory subgroup analyses suggested that there may have been fewer good outcomes with the antiseizure intervention in patients with generalized periodic discharges than in those with other patterns.  However, no conclusions can be drawn from these results, because the trial was underpowered for these analyses.\n\n【59】Trial physicians were allowed to decide to withdraw antiseizure or life-sustaining treatment after 48 hours of intensive antiseizure treatment. Treatment for longer than 48 hours has been advocated in the type of patient included in the trial.  In the aforementioned observational study, the mean duration of treatment was approximately 5 days,  as compared with the mean duration of ICU treatment in our antiseizure-treatment group of approximately 9 days, during which antiseizure medications were continued in all the patients in the group.\n\n【60】Strengths of our trial include a prospective, randomized design; the use of continuous EEG monitoring; and outcome assessors who were unaware of the trial-group assignments. Limitations are that mortality within 24 hours was higher in the control group than in the antiseizure-treatment group, and we cannot rule out the possibility that decisions with respect to withdrawal of life-sustaining treatment were not balanced between the trial groups, which potentially resulted in poorer outcomes in the control group. Furthermore, patients in the antiseizure-treatment group more often received sedative medication as part of the antiseizure treatment regimen, and withdrawal of life-sustaining treatment may have been delayed in this group. Treating physicians in the trial were aware of the trial-group assignments, which may have influenced choice regarding medication treatment choices and decisions about withdrawal of care. The final classification of seizure types and degree of suppression of index EEG activity was determined by experienced EEG readers who were aware of the trial-group assignments. Finally, the wide confidence interval around the point estimate for the between-group difference in the primary outcome cannot rule out benefit or harm of aggressive antiseizure treatment in these patients.\n\n【61】In comatose patients after cardiac arrest with rhythmic and periodic EEG activity, intensive antiseizure treatment over a period of at least 48 hours did not improve neurologic outcomes at 3 months, but the wide confidence interval for the primary outcome may not rule out modest benefit or harm.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "【4】Download a PDF of the Research Summary .", "content": "【0】Treating Rhythmic and Periodic EEG Patterns in Comatose Survivors of Cardiac Arrest\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Whether the treatment of rhythmic and periodic electroencephalographic (EEG) patterns in comatose survivors of cardiac arrest improves outcomes is uncertain.\n\n【3】Methods\n-------\n\n【4】Download a PDF of the Research Summary .\n\n【5】We conducted an open-label trial of suppressing rhythmic and periodic EEG patterns detected on continuous EEG monitoring in comatose survivors of cardiac arrest. Patients were randomly assigned in a  ratio to a stepwise strategy of antiseizure medications to suppress this activity for at least 48 consecutive hours plus standard care (antiseizure-treatment group) or to standard care alone (control group); standard care included targeted temperature management in both groups. The primary outcome was neurologic outcome according to the score on the Cerebral Performance Category (CPC) scale at 3 months, dichotomized as a good outcome (CPC score indicating no, mild, or moderate disability) or a poor outcome (CPC score indicating severe disability, coma, or death). Secondary outcomes were mortality, length of stay in the intensive care unit (ICU), and duration of mechanical ventilation.\n\n【6】Results\n-------\n\n【7】We enrolled 172 patients, with 88 assigned to the antiseizure-treatment group and 84 to the control group. Rhythmic or periodic EEG activity was detected a median of 35 hours after cardiac arrest; 98 of 157 patients (62%) with available data had myoclonus. Complete suppression of rhythmic and periodic EEG activity for 48 consecutive hours occurred in 49 of 88 patients (56%) in the antiseizure-treatment group and in 2 of 83 patients (2%) in the control group. At 3 months, 79 of 88 patients (90%) in the antiseizure-treatment group and 77 of 84 patients (92%) in the control group had a poor outcome (difference, 2 percentage points; 95% confidence interval, −7 to 11; P=0.68). Mortality at 3 months was 80% in the antiseizure-treatment group and 82% in the control group. The mean length of stay in the ICU and mean duration of mechanical ventilation were slightly longer in the antiseizure-treatment group than in the control group.\n\n【8】Conclusions\n-----------\n\n【9】In comatose survivors of cardiac arrest, the incidence of a poor neurologic outcome at 3 months did not differ significantly between a strategy of suppressing rhythmic and periodic EEG activity with the use of antiseizure medication for at least 48 hours plus standard care and standard care alone. \n\n【10】Introduction\n------------\n\n【11】 QUICK TAKE  \nTreating Epileptiform Activity after Cardiac Arrest  \n\n【12】Rhythmic and periodic electroencephalographic (EEG) patterns that may reflect electrographic seizures have been reported in 10 to 35% of comatose patients after cardiac arrest. Unequivocal electrographic or clinical seizures are infrequent, whereas generalized periodic discharges are common in these patients  and have generally been associated with a poor neurologic outcome.  Whether rhythmic and periodic EEG patterns should be treated with antiseizure medications, with the goal of improving the neurologic outcome, is unclear. \n\n【13】Uncertainty about the efficacy of treatment has been reflected in surveys showing that approximately one third of neurologists use a stepwise antiseizure-medication strategy to suppress epileptiform EEG activity in nonconvulsive status epilepticus and status epilepticus, one third use these medications in a nonstandardized way, and one third do not use antiseizure medications because of presumed futility of improving the neurologic outcome.  It has been suggested that the effects of antiseizure medication depend on the specific EEG pattern being treated. \n\n【14】We conducted the Treatment of Electroencephalographic Status Epilepticus after Cardiopulmonary Resuscitation (TELSTAR) trial to assess whether intensive, stepwise antiseizure and sedative treatment to suppress rhythmic and periodic EEG patterns detected in continuous EEG monitoring would alter the outcomes in comatose patients after cardiac arrest. We hypothesized that the use of antiseizure medication would reduce the incidence of a poor neurologic outcome at 3 months.\n\n【15】Methods\n-------\n\n【16】Trial Design\n------------\n\n【17】This trial was a pragmatic, multicenter clinical trial with randomized treatment assignments, open-label treatment, and blinded end-point evaluation at 11 intensive care units (ICUs) in the Netherlands and Belgium. Stepwise treatment to suppress rhythmic and periodic EEG patterns on continuously monitored EEG plus standard care was compared with standard care alone in comatose patients after cardiac arrest. The trial was supported by a grant from the Dutch Epilepsy Foundation (NEF14-18), which was not involved in trial design or conduct, data analysis, or manuscript preparation or review.\n\n【18】The trial protocol  was approved by a central medical ethics committee and by the research boards at each participating center. Written informed consent was obtained from legal representatives of patients before randomization or, from January 10, 2017, was obtained in a deferred manner from the patient if possible, within 24 hours after randomization. Written informed consent for follow-up was obtained from surviving patients or from legal representatives. An independent data and safety monitoring board analyzed safety when 25%, 50%, and 75% of the patients had been enrolled and assessed efficacy when 50% of the patients had been enrolled.\n\n【19】This trial was an investigator-initiated trial, with no commercial involvement. The executive committee designed the trial. Members of the executive committee and local investigators collected and analyzed the data and wrote the manuscript. The authors vouch for the accuracy and completeness of the data and for the fidelity of the trial to the protocol.\n\n【20】Trial Population\n----------------\n\n【21】Eligible patients were 18 years of age or older, were comatose (Glasgow Coma Scale score, ≤8; range, 3 to 15, with lower scores indicating worse responses to stimuli) after resuscitation for cardiac arrest, had continuous EEG monitoring started less than 24 hours after the return of spontaneous circulation, and had rhythmic or periodic activity on EEG. Continuous EEG monitoring was standard practice in all participating hospitals, but we did not maintain a case log of all patients with cardiac arrest in these units during the trial. Rhythmic and periodic EEG patterns were defined as periodic discharges, rhythmic delta activity, spike-and-wave or sharp-and-wave EEG patterns, each at a rate of 0.5 Hz or more, irrespective of their spatial evolution across EEG montages or temporal evolution. The minimum duration of continuous activity of these patterns for inclusion in the trial was 30 minutes or, if intermittent, 5 minutes, recurring at least twice at intervals of less than 60 minutes. Detailed inclusion and exclusion criteria are listed under Additional Methods in the Supplementary Appendix .\n\n【22】Trial Interventions\n-------------------\n\n【23】Patients were randomly assigned to receive protocol-defined antiseizure medication plus standard care (antiseizure-treatment group) or standard care alone (control group) with the use of the Web-based service ALEA (Clinical Trial Center Maastricht, the Netherlands) in a  ratio with permuted blocks (block size, 4 to 10) stratified according to center. The antiseizure intervention consisted of a stepwise treatment strategy with the intent of completely suppressing rhythmic and periodic EEG activity on continuous EEG monitoring. Standard care was left to the discretion of the treating physicians but generally followed European guidelines and included targeted temperature management in both trial groups. \n\n【24】In the antiseizure-treatment group, treatment of rhythmic and periodic EEG patterns was based on international guidelines for the treatment of status epilepticus.  Step 1 was a first antiseizure drug plus a first sedative agent (usually midazolam or propofol), step 2 was a second antiepileptic drug plus a second sedative agent, and step 3 was a high-dose barbiturate; all medications were administered intravenously. Permitted antiseizure medications were phenytoin, valproate, and levetiracetam. Because no antiseizure or sedative drug has been proven superior to another in improving outcomes after status epilepticus, medications were chosen by the treating physician in the doses and infusion rates as indicated in the protocol.  The treatment flow chart is available in the Supplementary Appendix under Additional Methods.\n\n【25】The goal of antiseizure treatment was to suppress all rhythmic and periodic EEG activity for at least 48 consecutive hours (defined as >90% of activity suppressed). Each subsequent step was taken as soon as possible when the previous step failed to suppress all this activity. There was no obligation to induce burst suppression on EEG. In the antiseizure-treatment group, treatment was started within 3 hours after detection of rhythmic and periodic EEG patterns. Treatment was guided by a neurologist or clinical neurophysiologist who analyzed the EEG findings and adjusted or changed medication according to the protocol in consultation with the ICU physician. Treating physicians were allowed to follow local protocols for treatment of seizurelike activity, provided that these were in line with the overall stepwise approach. If rhythmic and periodic EEG patterns returned after 48 hours with the use of at least two antiseizure medications, the decision to prolong antiseizure treatment was left to the discretion of the treating physician. In the control group, physicians were allowed to prescribe sedative medication if needed for mechanical ventilation or to suppress clinically manifest myoclonus, irrespective of the EEG findings; additional use of antiseizure drugs was discouraged in the control group.\n\n【26】In both groups, decisions regarding limitation or withdrawal of treatment were based on Dutch guidelines, which were derived from the European guidelines at the time we started the trial.  Withdrawal of treatment could be considered during normothermia and while the patient was not receiving sedation if there was incomplete return of brain-stem reflexes and bilateral absence of somatosensory evoked potentials  ; however, EEG patterns in the previous 72 hours were not taken into account in these decisions.\n\n【27】Trial Outcomes\n--------------\n\n【28】The primary outcome was neurologic outcome according to the score on the Cerebral Performance Category (CPC) scale at 3 months, dichotomized as a good outcome (CPC score of 1 \\[no or mild neurologic disability\\] or 2 \\[moderate disability\\]) or a poor outcome (CPC score of 3 \\[severe disability\\], 4 \\[coma\\], or 5 \\[death\\]).  These scores were obtained at 3 months after admission by a standardized telephone interview conducted by an investigator who was unaware of the trial-group assignments and EEG pattern. Secondary outcomes were mortality at 3 months, length of stay in the ICU, and duration of mechanical ventilation. Safety outcomes included any serious adverse events. Outcomes at 6 and 12 months have not yet been analyzed. Treating physicians were aware of the trial-group assignments and reported serious adverse events to the principal investigator by e-mail.\n\n【29】EEG Monitoring\n--------------\n\n【30】Continuous EEG monitoring was initiated within 24 hours after resuscitation as part of standard care in participating ICUs and continued for at least 3 days, until discharge from the ICU or until rhythmic and periodic EEG activity was extinguished. The standard international 10–20 system of electrode placement (in nine hospitals) or a limited montage with 10 electrodes (in two hospitals) was used according to local protocols. EEG recordings were checked every 3 hours by a neurologist, clinical neurophysiologist, or clinical neurophysiology technician. The diagnosis of rhythmic and periodic EEG patterns was made by the attending neurologist or clinical neurophysiologist. Guidance was given by typical examples of eligible EEG patterns on our website, at yearly meetings to discuss these patterns, and on a 24/7 online platform through which we were able to exchange EEG information and provide advice in real time if requested.\n\n【31】The final classifications of EEG patterns at baseline and suppression of activity were determined by central reading of EEGs by the first two and last two authors, who were aware of the trial-group assignments. They classified the EEG pattern at inclusion as electrographic seizures (discharges at ≥2.5 Hz), evolving patterns (0.5 to 2.5 Hz), generalized periodic discharges (0.5 to 2.5 Hz), or other periodic patterns (0.5 to 2.5 Hz), with continuous, discontinuous, or suppressed background activity. They classified the treatment effect on the index EEG activity in both groups as complete suppression (>90%), partial suppression (50 to 90%), or no suppression (<50%).\n\n【32】Statistical Analysis\n--------------------\n\n【33】We calculated a sample size of 172 patients: 84 per group on the basis of a prevalence of a poor outcome of 99% derived from uncontrolled cohorts,  a presumed lower incidence of a poor outcome in the antiseizure-treatment group than in the control group by 7 percentage points, an alpha level of 5%, a beta level of 80%, and one-tailed testing as well as two additional patients per group to compensate for a planned interim analysis after 86 patients had been enrolled.  The statistical analysis plan  was finalized before the database was locked and before data were analyzed.\n\n【34】The primary analysis was a single comparison between the two trial groups with regard to the dichotomized primary outcome according to the intention-to-treat principle, expressed as the risk difference (between-group difference in percentage points) of a poor outcome, including the corresponding 95% confidence interval. The level of statistical significance for the difference in the primary outcome was P=0.0429 to accommodate a single interim analysis of efficacy that used O’Brien–Fleming boundaries. \n\n【35】Secondary analyses of the primary outcome included risk differences of a poor outcome for all other dichotomous outcomes on the CPC scale, as well as the shift across CPC scores in the direction of a better outcome in the antiseizure-treatment group, analyzed by means of multivariable ordinal logistic regression and expressed as a common odds ratio. For secondary outcomes, between-group differences were analyzed by means of independent-samples t-tests, Mann–Whitney tests, or Fisher exact tests, where appropriate. Because there was no prespecified plan for adjustment of the widths of confidence intervals for multiple comparisons of secondary outcomes, no definite conclusions can be drawn from these data. There was no prespecified plan for the handling of missing data. We performed prespecified per-protocol analyses involving all patients who received antiseizure drugs as compared with those who did not receiving antiseizure drugs. We planned multivariable logistic-regression analysis to adjust for imbalances in baseline prognostic variables between the antiseizure-treatment group and the control group, if applicable.\n\n【36】Treatment-effect modification was explored in prespecified subgroups defined by seizure type at inclusion (electrographic seizures, evolving patterns, generalized periodic discharges, or other), background continuity at inclusion (continuous, discontinuous, or suppressed), and time of onset of rhythmic and periodic EEG patterns (≤24 hours, >24 to <48 hours, or ≥48 hours after the return of spontaneous circulation), but the trial was not powered for these subgroups. An additional post hoc exploratory subgroup analysis was added according to generalized periodic discharges as compared with nongeneralized periodic discharges in EEG patterns at inclusion, as suggested by findings reported in the literature.  All analyses were performed with the use of MATLAB software, version 2021a (MathWorks).\n\n【37】Results\n-------\n\n【38】Baseline Characteristics\n------------------------\n\n【39】Between May 1, 2014, and January 24, 2021, continuous EEG recordings were started in 2528 patients, rhythmic and periodic EEG activity was detected in 354, and 172 were included in the trial, with 88 assigned to the antiseizure-treatment group and 84 to the control group . A total of 72 patients were not enrolled because their EEG recordings were not interpreted rapidly enough to be included. All included patients had complete follow-up at 3 months. There was one interim analysis after 86 patients had been enrolled.\n\n【40】Table 1. Characteristics of the 172 Patients at Baseline.\n\n【41】The median age of the patients was 65 years (interquartile range, 57 to 74), and 118 (69%) were men. Rhythmic and periodic EEG patterns started at a median of 35 hours (interquartile range, 27 to 44) after cardiac arrest, and 98 of 157 patients (62%) had myoclonus. Approximately 80% of the patients in both groups had generalized periodic discharges, and 10% had electrographic seizures. Baseline characteristics were similar in the two groups . The representativeness of trial patients is shown in Table S1.\n\n【42】EEG Response\n------------\n\n【43】Table 2. Antiseizure Treatment and EEG Response.\n\n【44】All the patients in the antiseizure-treatment group and 8 in the control group were treated with at least one antiseizure medication. All the patients who were assigned to the antiseizure-treatment group received the intended treatment strategy. Complete suppression of paroxysmal EEG activity for the 24 hours after randomization was achieved in 64 of 88 patients (73%) in the antiseizure-treatment group and in 3 of 83 patients (4%) in the control group. Complete suppression of the index EEG activity for 48 consecutive hours at any time after the start of treatment occurred in 49 of 88 patients (56%) in the antiseizure-treatment group and in 2 of 83 patients (2%) in the control group . Suppression for more than 24 hours is shown in Table 2 . Examples of the rhythmic and periodic activity encountered in the trial are shown in Figure S4. The typical evolution of generalized periodic discharges is illustrated in Figure S5: these started with low-frequency activity (<0.5 Hz) and gradually evolved toward frequencies of discharges that met our trial inclusion criteria, on time scales of hours.\n\n【45】Outcomes\n--------\n\n【46】Table 3. Primary, Secondary, and Safety Outcomes (Intention-to-Treat Population). Figure 1.  Figure 1. Cerebral Performance Category Scores at 3 Months (Intention-to-Treat Population).\n\n【47】Patients in the antiseizure-treatment group received intensive antiseizure treatment plus standard care, and patients in the control group received standard care alone. Scores on the Cerebral Performance Category scale range from 1 to 5, with 1 indicating no or mild neurologic disability, 2 moderate disability, 3 severe disability, 4 coma, and 5 death.\n\n【48】At 3 months, 79 of 88 patients (90%) in the antiseizure-treatment group and 77 of 84 patients (92%) in the control group had a poor outcome as defined by a CPC score of 3, 4, or 5 (difference, 2 percentage points; 95% confidence interval \\[CI\\], −7 to 11; P=0.68) . Results were similar for per-protocol analyses . At 3 months, 70 of 88 patients (80%) in the antiseizure-treatment group and 69 of 84 patients (82%) in the control group had died (difference, 3 percentage points; 95% CI, −9 to 14); however, mortality within 24 hours after randomization was 9% in the antiseizure-treatment group and 24% in the control group . Survival curves are shown in Figure S3. All but one death within 24 hours after randomization occurred after withdrawal of life-sustaining treatment. Two patients in each group had a second cardiac arrest; one patient in the control group died more than 24 hours after randomization as a result of a second cardiac arrest. The distribution of CPC scores was similar in the two groups (common odds ratio, 1.19; 95% CI, 0.56 to 2.53) . The mean length of stay in the IUC was 8.7 days in the antiseizure-treatment group and 7.5 days in the control group . The incidence of withdrawal of life-sustaining treatment was approximately 77% in both trial groups . The timing of withdrawal of life-sustaining treatment ranged from 1 to 33 days after ICU admission; in the first 24 hours, withdrawal occurred in 2% of the patients in the antiseizure-treatment group and in 13% of those in the control group .\n\n【49】Safety\n------\n\n【50】The incidence of serious adverse events in the overall population was 145 of 172 patients (84%); serious adverse events were similar in incidence and type in the two trial groups . Adverse events of lesser degree than serious adverse events, such as hypotension, were not systematically recorded.\n\n【51】Exploratory Subgroup Analyses\n-----------------------------\n\n【52】Figure 2. Subgroup Analyses.\n\n【53】The trial was not powered to analyze subgroups, and these results should be considered exploratory. One patient in the control group gave consent for inclusion in the analysis of the primary outcome but not in any other analyses. The between-group difference was calculated as antiseizure-treatment group minus control group. Black squares indicate point estimates of effects, dotted vertical lines indicate no effect, and solid vertical lines indicate the overall effect in the antiseizure-treatment group. EEG denotes electroencephalography, and GPD generalized periodic discharge.\n\n【54】Visual inspection of subgroup plots  suggested that for the most common type of EEG activity, generalized periodic discharges, the antiseizure-treatment group may have had a smaller proportion of good outcomes than the control group, but the trial was not powered to make conclusions from these subgroup results and the results are exploratory. Post hoc analyses of outcomes of generalized periodic discharges as compared with all other patterns are shown in Figure 2B .\n\n【55】Discussion\n----------\n\n【56】In this trial involving comatose patients after cardiac arrest who had rhythmic and periodic EEG patterns, intensive antiseizure treatment adapted from protocols for status epilepticus did not result in fewer poor outcomes at 3 months than standard treatment. Sedative medications were used in both the antiseizure-treatment group and the control group to support mechanical ventilation or suppress myoclonus, which may have led to cessation of rhythmic and periodic EEG activity in the standard-care group that reduced the differences in the incidence of EEG and clinical outcomes between the two groups. The antiseizure intervention was associated with a slightly longer length of stay in the ICU and a longer duration of mechanical ventilation. Overall mortality was 81%, similar to findings in observational studies involving patients who were comatose after cardiac arrest.  A total of 10% of the patients in the antiseizure-treatment group and 8% of those in the control group in our trial had a good neurologic recovery.\n\n【57】In a previous observational study, stepwise, intensive treatment resulted in a good outcome in 16 of 36 patients (44%) with rhythmic and periodic EEG patterns other than generalized periodic discharges, as compared with none of 13 patients with generalized periodic discharges.  In our trial, generalized periodic discharges were the most common aberrant EEG pattern, present in approximately 80% of the patients. As in some other studies, generalized periodic discharges typically started with low frequencies (<0.5Hz), with a gradual evolution toward frequencies that met our inclusion criteria over a period of hours.  This pattern differs from the usual evolution of seizures in status epilepticus, which is characterized by rapid onset of EEG abnormalities, evolving over seconds.  Data from several studies suggest that generalized periodic discharges in postanoxic encephalopathy may be a direct expression of severe ischemic brain damage rather than of epilepsy. \n\n【58】Exploratory subgroup analyses suggested that there may have been fewer good outcomes with the antiseizure intervention in patients with generalized periodic discharges than in those with other patterns.  However, no conclusions can be drawn from these results, because the trial was underpowered for these analyses.\n\n【59】Trial physicians were allowed to decide to withdraw antiseizure or life-sustaining treatment after 48 hours of intensive antiseizure treatment. Treatment for longer than 48 hours has been advocated in the type of patient included in the trial.  In the aforementioned observational study, the mean duration of treatment was approximately 5 days,  as compared with the mean duration of ICU treatment in our antiseizure-treatment group of approximately 9 days, during which antiseizure medications were continued in all the patients in the group.\n\n【60】Strengths of our trial include a prospective, randomized design; the use of continuous EEG monitoring; and outcome assessors who were unaware of the trial-group assignments. Limitations are that mortality within 24 hours was higher in the control group than in the antiseizure-treatment group, and we cannot rule out the possibility that decisions with respect to withdrawal of life-sustaining treatment were not balanced between the trial groups, which potentially resulted in poorer outcomes in the control group. Furthermore, patients in the antiseizure-treatment group more often received sedative medication as part of the antiseizure treatment regimen, and withdrawal of life-sustaining treatment may have been delayed in this group. Treating physicians in the trial were aware of the trial-group assignments, which may have influenced choice regarding medication treatment choices and decisions about withdrawal of care. The final classification of seizure types and degree of suppression of index EEG activity was determined by experienced EEG readers who were aware of the trial-group assignments. Finally, the wide confidence interval around the point estimate for the between-group difference in the primary outcome cannot rule out benefit or harm of aggressive antiseizure treatment in these patients.\n\n【61】In comatose patients after cardiac arrest with rhythmic and periodic EEG activity, intensive antiseizure treatment over a period of at least 48 hours did not improve neurologic outcomes at 3 months, but the wide confidence interval for the primary outcome may not rule out modest benefit or harm.", "index": 314, "show": true, "start": 314, "end": 357, "province": ["文本干净度", "无关文本"], "isEdit": false}]}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-14 00:18:15", "grab_time": "2024-08-13 22:51:57"}
{"id": 2234520, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "d52d2016-2a77-4fdf-b4b2-1303cc8323ed", "title": "Outcomes of Medical Emergencies on Commercial Airline Flights", "text": "【0】Outcomes of Medical Emergencies on Commercial Airline Flights\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Worldwide, 2.75 billion passengers fly on commercial airlines annually. When in-flight medical emergencies occur, access to care is limited. We describe in-flight medical emergencies and the outcomes of these events.\n\n【3】Methods\n-------\n\n【4】We reviewed records of in-flight medical emergency calls from five domestic and international airlines to a physician-directed medical communications center from January 1, 2008, through October 31, 2010. We characterized the most common medical problems and the type of on-board assistance rendered. We determined the incidence of and factors associated with unscheduled aircraft diversion, transport to a hospital, and hospital admission, and we determined the incidence of death.\n\n【5】Results\n-------\n\n【6】There were 11,920 in-flight medical emergencies resulting in calls to the center (1 medical emergency per 604 flights). The most common problems were syncope or presyncope (37.4% of cases), respiratory symptoms (12.1%), and nausea or vomiting (9.5%). Physician passengers provided medical assistance in 48.1% of in-flight medical emergencies, and aircraft diversion occurred in 7.3%. Of 10,914 patients for whom postflight follow-up data were available, 25.8% were transported to a hospital by emergency-medical-service personnel, 8.6% were admitted, and 0.3% died. The most common triggers for admission were possible stroke (odds ratio, 3.36; 95% confidence interval \\[CI\\], 1.88 to 6.03), respiratory symptoms (odds ratio, 2.13; 95% CI, 1.48 to 3.06), and cardiac symptoms (odds ratio, 1.95; 95% CI, 1.37 to 2.77).\n\n【7】Conclusions\n-----------\n\n【8】Most in-flight medical emergencies were related to syncope, respiratory symptoms, or gastrointestinal symptoms, and a physician was frequently the responding medical volunteer. Few in-flight medical emergencies resulted in diversion of aircraft or death; one fourth of passengers who had an in-flight medical emergency underwent additional evaluation in a hospital. \n\n【9】Introduction\n------------\n\n【10】 QUICK TAKE  \nIn-Flight Medical Emergencies  \n\n【11】Commercial airlines serve approximately 2.75 billion passengers worldwide annually. When in-flight medical emergencies occur, access to care is limited. Physicians and other medical professionals are often called on to assist when traveling, despite limited training or experience with these situations.  Airlines partner with health care institutions to deliver real-time medical advice from an emergency call center to airline personnel, in an effort to improve the quality of care provided to passengers.\n\n【12】There is limited information on the incidence and characteristics of in-flight medical emergencies.  Although previous studies of these events have characterized the incidence, categories of symptoms, rates of aircraft diversion, and resources accessed, many have used information obtained from single airlines and have lacked information on patient outcomes. \n\n【13】We conducted a study of in-flight medical emergencies involving large commercial airlines, characterizing on-board assistance provided by flight crews and other passengers and identifying the outcomes of these events, including ambulance transport to a hospital and hospital admission. On the basis of our findings, we suggest a practical approach to the initial management of common in-flight medical emergencies for medical personnel who may be called on to render aid.\n\n【14】Methods\n-------\n\n【15】Data Collection\n---------------\n\n【16】We reviewed records of all calls to a medical communications center from five domestic and international airlines that represented approximately 10% of the global passenger flight volume from January 1, 2008, through October 31, 2010. The communications center provides medical consultations with the use of radio or satellite telephone communications. It is located at an academic medical center and is staffed by emergency physicians who are trained in telemedicine and the management of in-flight medical emergencies.\n\n【17】A narrative summary of each event is recorded, and categorical data are entered into an electronic database (Excel 2007, Microsoft). Data include medical problem, flight origin and destination, flight phase (i.e., airplane at terminal, taxiing, in flight, or landing), availability of on-board assistance, and use of medications or medical equipment. In cases in which more than one passenger renders medical assistance, the person with the highest level of training is recorded. After each event, communications-center personnel determine whether or not the patient was taken to a hospital and the disposition from the emergency department. Outcome variables collected include whether or not the aircraft was diverted from its intended destination, whether or not the passenger was transported to a hospital, and, if transported, the passenger's disposition from the emergency department. We excluded events that did not occur in flight, such as during preflight gate screenings or on-board emergencies occurring before takeoff or after landing.\n\n【18】Table 1. In-Flight Medical Emergencies According to Medical-Problem Category and Outcome.\n\n【19】The first two authors reviewed the most common primary symptoms in the electronic database and created medical categories according to body system, nature of illness, or both . For example, we categorized loss of consciousness, “blacking out,” or feeling lightheaded as syncope or presyncope. Similarly, we categorized chest pain, palpitations, or pacemaker concerns as cardiac symptoms. Cardiac arrest was in a separate category. All events categorized as “other” were individually of low incidence. Our abstractor used a standardized form, referring cases of uncertain classification to the first two authors to resolve by consensus.\n\n【20】We used the recorded origin and scheduled destination of each flight to determine flight distance and whether it was domestic (within the United States) or international. To determine the overall number of passengers during our study period, we obtained statistics from the U.S. Department of Transportation,  supplemented by personal communication with the airlines. We determined whether an automated external defibrillator (AED) was used and collected data on clinical factors (loss of consciousness, loss of pulses, shock delivery, and return of pulses) through a review of narrative records of these cases. The University of Pittsburgh institutional review board approved the study and waived the requirement for informed consent. The second author vouches for the completeness and accuracy of the data.\n\n【21】Statistical Analysis\n--------------------\n\n【22】Table 2. Multivariable Analysis of Factors Associated with Selected Outcomes.\n\n【23】We determined the frequency of each medical-problem category, aircraft type, AED use, availability of on-board medical assistance, airline, and flight distance. We report descriptive data (means ±SD) for continuous variables and percentages for categorical variables. We performed a univariable analysis of the association between the factors above and specific patient outcomes, using a two-sample t-test for the continuous variable of age and chi-square tests for categorical variables. Next, we performed a multivariable analysis, using logistic regression to identify factors associated with specific outcomes while controlling for other factors that were found to have an association in the univariable analysis . All reported P values are two-sided; a P value of less than 0.05 was considered to indicate statistical significance. We used SPSS software, version 19.0 (IBM), for the analyses.\n\n【24】Results\n-------\n\n【25】Characteristics of Medical Emergencies and Outcomes\n---------------------------------------------------\n\n【26】The communications center received calls about 11,920 in-flight medical emergencies among an estimated 744 million airline passengers during the study period, for a rate of 16 medical emergencies per 1 million passengers. There were 7,198,118 flights by the included airlines during the study period, for an incidence of 1 in-flight medical emergency per 604 flights. The age of the passengers with in-flight emergencies ranged from 14 days to 100 years (mean, 48±21 years). The most common medical problems were syncope or presyncope (37.4%), respiratory symptoms (12.1%), and nausea or vomiting (9.5%) , with some variation across airlines . Aircraft diversion occurred in 875 of 11,920 cases (7.3%); the remaining flights landed at their scheduled destinations.\n\n【27】Figure 1. Outcomes of In-Flight Medical Emergencies.\n\n【28】Postflight follow-up data were not available for Airline 4 (1006 passengers with in-flight medical emergencies); two deaths occurred in this group. ED denotes emergency department, and EMS emergency medical services.\n\n【29】Postflight follow-up data were available for 10,914 passengers with in-flight medical emergencies (91.6%) . For 3402 passengers (31.2%), the situation resolved sufficiently before landing so that emergency-medical-service (EMS) personnel were not requested. Of the 7508 patients for whom EMS personnel were requested to meet the aircraft on landing, 2804 (37.3%) were transported to a hospital emergency department. Subsequently, 901 patients (8.6% of those for whom follow-up data were available) were admitted to the hospital or left the emergency department against medical advice. In addition to cardiac arrest, medical problems that were associated with the highest rates of hospital admission were strokelike symptoms (23.5%), obstetrical or gynecologic symptoms (23.4%), and cardiac symptoms (21.0%). Of the 36 deaths identified, 30 occurred during flight. The mean age of passengers who died was 59±21 years (range, 1 month to 92 years).\n\n【30】Of the 61 cases of obstetrical or gynecologic symptoms in our study, most (60.7%) occurred in pregnant women at less than 24 weeks of gestation with signs of possible miscarriage (e.g., vaginal bleeding), including 7 of 11 obstetrical or gynecologic cases resulting in diversion. Eleven cases (18.0%) involved women in labor beyond 24 weeks, of which 3 cases resulted in diversion.\n\n【31】Providers of On-Board Medical Assistance\n----------------------------------------\n\n【32】On-board assistance was provided by physicians (48.1%), nurses (20.1%), EMS providers (4.4%), or other health care professionals (3.7%). Aircraft-diversion and hospitalization rates differed according to the type of medical volunteer. Diversion rates according to provider (from highest to lowest) were as follows: physicians, 9.4% (95% confidence interval \\[CI\\], 8.7 to 10.2); EMS providers, 9.3% (95% CI, 6.8 to 11.7); nurses, 6.2% (95% CI, 5.2 to 7.2); and flight crew only, 3.8% (95% CI, 3.1 to 4.5). Hospitalization rates according to provider were as follows: EMS providers, 10.2% (95% CI, 7.5 to 12.9); physicians, 9.3% (95% CI, 8.5 to 10.0); nurses, 8.7% (95% CI, 7.5 to 9.8); and flight crew only, 4.7% (95% CI, 3.9 to 5.6). In the multivariable analysis, the factors that had the strongest association with aircraft diversion were AED use and on-board assistance by an EMS provider as the highest-level provider . Hospital admission was associated with possible stroke, respiratory symptoms, and cardiac symptoms.\n\n【33】Medication Administration\n-------------------------\n\n【34】Medications administered during in-flight medical emergencies are listed in Table S2 in the Supplementary Appendix . Most medications that were used are available in the Federal Aviation Administration (FAA)–mandated emergency medical kit,  which may be supplemented by individual airlines . Some medications that were administered came from other passengers or the patients themselves. The most commonly used medications and medical therapies were oxygen (in 49.9% of cases), intravenous 0.9% saline solution (in 5.2%), and aspirin (in 5.0%). Among 1136 passengers with an in-flight emergency related to nausea or vomiting and documentation of whether an antiemetic agent was used, 1 of 109 (0.9%) who received an antiemetic agent had an event that resulted in aircraft diversion versus 55 of 1027 (5.4%) who did not receive an antiemetic (P=0.04). Diversion rates did not differ significantly according to whether albuterol was used for respiratory symptoms or whether nitroglycerin was used for cardiac symptoms.\n\n【35】AED Use\n-------\n\n【36】An AED was applied to 137 patients with an in-flight medical emergency (1.3%). Among 134 patients (97.8%) for whom narrative records were available, the chief symptoms were syncope or presyncope (41.0%) and chest pain (23.9%); 84 patients (62.7%) had a loss of consciousness. An AED was applied in 24 cases of cardiac arrest. A shock was delivered in 5 cases. A return of spontaneous circulation occurred in 1 patient receiving defibrillation and 8 other patients when an AED was used but no shock was indicated. All but 1 patient with a return of spontaneous circulation survived long enough to be admitted to a hospital.\n\n【37】Discussion\n----------\n\n【38】On the basis of our data, we estimate that 44,000 in-flight medical emergencies occur worldwide each year. Medical emergencies during commercial airline travel, although rare when considered on a per-passenger basis, occur daily; traveling physicians and other health care providers are often called on to aid ill passengers. A basic knowledge of in-flight medical emergencies and awareness of the resources available can help them be effective volunteers. The emergency medical kit available on every commercial airliner regulated by the FAA is usually sufficient to initiate treatment for serious problems. Many airlines have an enhanced emergency medical kit, increasing treatment options . Most in-flight medical emergencies are self-limiting or are effectively evaluated and treated without disruption of the planned route of flight. Serious illness is infrequent, and death is rare.\n\n【39】Although the FAA does not require consultation with a physician on the ground in the case of an in-flight emergency, airlines partner with specific health care delivery groups to provide consistent availability of medical expertise. Consulting physicians on the ground are able to communicate directly with flight crew members and on-board health care volunteers or through efficient relay processes involving the pilot. In our experience, passengers' symptoms can often be managed in collaboration with the flight attendants, who are well versed in the equipment that the airplanes carry and in operational procedures. When the need for evaluation or intervention exceeds their capabilities, flight attendants may seek health care professionals on the flight. Many airlines require consultation with a ground-based physician before the emergency medical kit is used. A collaborative approach to management of the medical problem should ensue. The health care provider in flight can make direct observations, and the consulting ground-based physician has familiarity with the environment, the available medical resources, knowledge of passenger health issues, and awareness of airline operational concerns. As a team, they provide the best possible care, given the constraints.\n\n【40】The risk of medical liability may be a concern for volunteer health care providers. The 1998 Aviation Medical Assistance Act includes a Good Samaritan provision,  protecting passengers who offer medical assistance from liability, other than liability for gross negligence or willful misconduct.  Although there is no legal obligation to intervene, we believe that physicians and other health care providers have a moral and professional obligation to act as Good Samaritans.\n\n【41】Table 3. Recommendations for Traveling Physicians or Other Health Care Providers during In-Flight Medical Emergencies.\n\n【42】We suggest an algorithm for approaching the more common in-flight medical emergencies on the basis of our findings . In our study, syncope, respiratory symptoms, nausea or vomiting, and cardiac symptoms were the most common in-flight emergencies, findings that are consistent with the results of prior studies.  Although patients with syncope are often unresponsive and may initially have hypotension, in most cases, improvement occurs within 15 to 20 minutes, and further treatment is usually not required, other than oral or intravenous fluids. The partial pressure of oxygen is lower in a pressurized aircraft than at sea level, and supplemental oxygen can be helpful. Persistently altered mental status or factors that raise concern about time-sensitive conditions, such as myocardial infarction or stroke, should prompt consideration of landing the aircraft.\n\n【43】Potential cardiac symptoms account for a relatively large number of in-flight medical emergencies. Most can be managed with simple treatment after a focused history taking, until definitive care is available. Aspirin, nitrates, and oxygen are available in the emergency medical kit. Patients with angina or atypical chest pain can be treated and transferred to an ambulance on landing. In cases in which myocardial infarction or acute dysrhythmia is suspected, monitoring with an AED may aid in diagnosis and decisions about disposition. Serious nonarrest cardiac events resulting in hospital admission are rare; of the 920 nonarrest cardiac cases, none resulted in death.\n\n【44】Obstetrical symptoms were rare causes of in-flight medical emergencies, a finding that supports existing recommendations that air travel is safe up to the 36th week of gestation.  The majority of cases of obstetrical or gynecologic symptoms (60.7%) occurred in pregnant women at less than 24 weeks of gestation. Only three cases involving pregnant women in labor beyond 24 weeks resulted in diversion.\n\n【45】In-flight cardiac arrest can be managed with an AED and epinephrine, which is stocked in the emergency medical kit. The rate of survival after cardiac arrest on a commercial airliner ranges from 14 to 55%, with the higher rates among patients with ventricular fibrillation.  We found that in 42.1% of cases of cardiac arrest, the flight was not diverted. These cases included arrests that occurred at a time when immediate diversion was not feasible (e.g., while the airplane was crossing the ocean), and arrests that occurred when the airplane was close to the intended destination and diversion would not have been beneficial to the patient. The death rate among all patients with in-flight medical emergencies was 0.3%, which is consistent with previously reported rates of 0.3 to 1.3%. \n\n【46】Common challenges to providing medical care aboard an aircraft include limited space and equipment. In unfamiliar settings, physicians and others may rely on what they know best, including making specific diagnoses on the basis of their areas of expertise. Physicians and other health care providers may be called on by the crew for more serious cases, which may help explain the higher rates of diversion and hospitalization when health care professionals provide on-board assistance.\n\n【47】Diversion of a commercial airliner to an unscheduled destination for an ill passenger requires consideration of both medical and operational issues. The potential medical benefit should be assessed on the basis of the condition and its time sensitivity, the ability to stabilize the patient's condition with available supplies, and the likely time savings with consideration of the time needed to land and the proximity of medical resources to specific airports. Immediate operational factors that may contribute to variability in airline practices include weather, fuel load and the potential need to drop fuel before landing, the availability of specific aircraft services at airports, and air-traffic control.\n\n【48】Our study is limited by its retrospective nature, with only in-flight medical emergencies that prompted calls to our communications center included in the analysis. Although all flight crews are instructed to use this consultation service for any in-flight medical emergency, there are events that occur without notification of the communications center. The medical categories we used were based on descriptions of the passenger's primary symptom, not on diagnoses. The data obtained as part of these consultations were limited by the use of radio or satellite-telephone transmission, communications among multiple people, and the collection of follow-up data from facilities located across the world. Follow-up data were not available for one airline, although the medical problems encountered by that airline were similar to the problems encountered by the other airlines. Differences among airlines in the likelihood of diversion, EMS transport, and hospital admission warrant further study.\n\n【49】On the basis of our findings, we believe that airline passengers who are health care professionals should be aware of their potential role as volunteer responders to in-flight medical emergencies. We also advocate for systematic tracking of all in-flight medical emergencies, including subsequent hospital care and other outcomes, to better guide interventions in this sequestered population.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-14 00:18:10", "grab_time": "2024-08-13 22:37:19"}
{"id": 2234519, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "ef125d6a-bca2-46c1-a8cc-c066a2790d97", "title": "RNA Interference — A New Weapon against HIV and Beyond", "text": "【0】RNA Interference — A New Weapon against HIV and Beyond\nA recently discovered type of RNA, small interfering RNA, silences messenger RNA (the transcript of an active gene) by binding to specific sequences in the messenger RNA. Small interfering RNAs can block the replication of HIV in vitro by triggering the degradation of specific viral messenger RNAs. This work reveals new possibilities for controlling not only HIV infection but also the growth of cancer cells.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:56:30", "endTime": "2024/08/14 14:57:13", "cost": 42.952}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 22:57:13", "grab_time": "2024-08-13 22:56:29"}
{"id": 2234518, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "900deb51-67d8-4a41-becc-1f036c811735", "title": "Current Concepts: Cystic Neoplasms of the Pancreas", "text": "【0】Current Concepts: Cystic Neoplasms of the Pancreas\nOwing to improvements in imaging techniques, cystic lesions of the pancreas are being identified more often, even in patients who are asymptomatic. These lesions range from benign to premalignant to highly malignant. This review offers guidance on the strategies for establishing the diagnosis, assessing risk, and making difficult decisions about when surgical resection is indicated.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:49:20", "endTime": "2024/08/14 15:50:34", "cost": 73.948}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 23:50:34", "grab_time": "2024-08-13 23:49:20"}
{"id": 2234517, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "4b33ba34-aaed-44e3-80bd-30ebf21a6693", "title": "Enzalutamide in Metastatic Prostate Cancer before Chemotherapy", "text": "【0】Enzalutamide in Metastatic Prostate Cancer before Chemotherapy\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Enzalutamide is an oral androgen-receptor inhibitor that prolongs survival in men with metastatic castration-resistant prostate cancer in whom the disease has progressed after chemotherapy. New treatment options are needed for patients with metastatic prostate cancer who have not received chemotherapy, in whom the disease has progressed despite androgen-deprivation therapy.\n\n【3】Methods\n-------\n\n【4】In this double-blind, phase 3 study, we randomly assigned 1717 patients to receive either enzalutamide (at a dose of 160 mg) or placebo once daily. The coprimary end points were radiographic progression-free survival and overall survival.\n\n【5】Results\n-------\n\n【6】The study was stopped after a planned interim analysis, conducted when 540 deaths had been reported, showed a benefit of the active treatment. The rate of radiographic progression-free survival at 12 months was 65% among patients treated with enzalutamide, as compared with 14% among patients receiving placebo (81% risk reduction; hazard ratio in the enzalutamide group, 0.19; 95% confidence interval \\[CI\\], 0.15 to 0.23; P<0.001). A total of 626 patients (72%) in the enzalutamide group, as compared with 532 patients (63%) in the placebo group, were alive at the data-cutoff date (29% reduction in the risk of death; hazard ratio, 0.71; 95% CI, 0.60 to 0.84; P<0.001). The benefit of enzalutamide was shown with respect to all secondary end points, including the time until the initiation of cytotoxic chemotherapy (hazard ratio, 0.35), the time until the first skeletal-related event (hazard ratio, 0.72), a complete or partial soft-tissue response (59% vs. 5%), the time until prostate-specific antigen (PSA) progression (hazard ratio, 0.17), and a rate of decline of at least 50% in PSA (78% vs. 3%) (P<0.001 for all comparisons). Fatigue and hypertension were the most common clinically relevant adverse events associated with enzalutamide treatment.\n\n【7】Conclusions\n-----------\n\n【8】Enzalutamide significantly decreased the risk of radiographic progression and death and delayed the initiation of chemotherapy in men with metastatic prostate cancer. \n\n【9】Introduction\n------------\n\n【10】Prostate cancer is the most commonly diagnosed cancer and the sixth leading cause of cancer-related death among men worldwide.  Strategies to block androgen-receptor signaling have formed the backbone of prostate-cancer therapy since the first description of the hormonal dependence of this cancer in 1941.  Advances in endocrine therapies have improved survival in men with high-risk locoregional prostate cancer.  However, new hormonal agents have been shown to extend survival in men with metastatic castration-resistant disease. \n\n【11】In most patients who are treated for advanced recurrent prostate cancer with androgen-deprivation therapy (comprising a luteinizing hormone–releasing hormone \\[LHRH\\] analogue or orchiectomy with or without an antiandrogen), disease progression occurs despite effective suppression of serum testosterone. This disease state, called castration-resistant prostate cancer, is almost always associated with increases in levels of serum prostate-specific antigen (PSA), suggesting that the disease continues to be driven by androgen-receptor signaling. Preclinical evidence suggests that androgen-receptor overexpression is sufficient to confer resistance to androgen deprivation in prostate-cancer cell lines  and that levels of intratumoral androgens are often increased in patients with progressive prostate cancer.  These observations have provided a clear basis for developing more effective methods to treat prostate cancer by further suppressing androgen-receptor signaling. \n\n【12】Enzalutamide (formerly known as MDV3100) is a rationally designed, targeted androgen-receptor inhibitor that competitively binds to the ligand-binding domain of the androgen receptor and inhibits androgen-receptor translocation to the cell nucleus, recruitment of androgen-receptor cofactors, and androgen-receptor binding to DNA.  In a phase 1–2 trial, enzalutamide was found to have encouraging antitumor activity in men with castration-resistant prostate cancer, with data suggesting a greater benefit in men who had not yet received chemotherapy.  In a previous phase 3 study, enzalutamide, as compared with placebo, prolonged overall and progression-free survival, improved patient-reported quality of life, and delayed the development of skeletal-related complications in men with metastatic castration-resistant prostate cancer who had previously received docetaxel.  In our study, we evaluated enzalutamide in men in whom hormonal agents are frequently administered (i.e., those who have asymptomatic or mildly symptomatic metastatic disease that has progressed despite the use of androgen-deprivation therapy) and who have not undergone chemotherapy.\n\n【13】Methods\n-------\n\n【14】Study Design and Conduct\n------------------------\n\n【15】The PREVAIL study was a multinational, double-blind, randomized, placebo-controlled, phase 3 trial of enzalutamide. The study was approved by the independent review board at each participating site and was conducted according to the provisions of the Declaration of Helsinki and the Good Clinical Practice Guidelines of the International Conference on Harmonisation. All patients provided written informed consent before participating in the trial. An independent data and safety monitoring committee reviewed safety data at regular intervals and reviewed the prespecified interim analysis conducted by an independent statistical group at the contract clinical research organization where the study database was held.\n\n【16】The study was designed by prostate-cancer experts and employees of the sponsors, Medivation and Astellas Pharma, which are codeveloping enzalutamide. Investigators at the participating centers entered the data into an electronic data-capture system that was verified for source data by monitors from a separate clinical research organization. The data analyses reported here were conducted by the sponsor and were provided to all the authors, who wrote the manuscript and made the decision to submit the manuscript for publication. A professional writer who was paid by the sponsors assisted in the preparation of the manuscript. All the authors and participating institutions have agreements with the sponsors regarding the confidentiality of the data.\n\n【17】Study Participants\n------------------\n\n【18】Patients were eligible if they had histologically or cytologically confirmed adenocarcinoma of the prostate with documented metastases and had PSA progression, radiographic progression, or both in bone or soft tissue, despite receiving LHRH analogue therapy or undergoing orchiectomy, with a serum testosterone level of 1.73 nmol per liter (50 ng per deciliter) or less. Continued androgen-deprivation therapy was required. Previous antiandrogen therapy and concurrent use of glucocorticoids were permitted but not required. Eligible patients had not received cytotoxic chemotherapy, ketoconazole, or abiraterone acetate, had an Eastern Cooperative Oncology Group performance status grade of 0 or 1 (no symptoms or ambulatory but restricted in strenuous activities), and were either asymptomatic (score of 0 to 1) or mildly symptomatic (score of 2 to 3), as measured on the Brief Pain Inventory Short Form question 3 (on which scores range from 0 to 10, with higher scores indicating a greater severity of pain). Patients with visceral disease, including lung or liver metastases, were eligible, as were patients with New York Heart Association class I or II heart failure. Patients with a history of seizure or a condition that could confer a predisposition to seizure were excluded, although patients taking medications associated with lowering the seizure threshold were eligible.\n\n【19】From September 2010 through September 2012, patients were enrolled at 207 sites globally. All patients were randomly assigned to receive either oral enzalutamide (at a dose of 160 mg) or placebo once daily with or without food. Randomization was stratified according to the study site. Treatment continued until the occurrence of unacceptable side effects or confirmed radiographic progression and the initiation of chemotherapy or an investigational agent. Treatment discontinuation because of an increase in the PSA level alone was discouraged.\n\n【20】Study End Points\n----------------\n\n【21】Coprimary end points were radiographic progression-free survival and overall survival. Secondary end points included the time until the initiation of cytotoxic chemotherapy, the time until the first skeletal-related event, the best overall soft-tissue response, the time until PSA progression, and a decline in the PSA level of 50% or more from baseline. Prespecified exploratory end points included quality of life, as measured with the use of the Functional Assessment of Cancer Therapy–Prostate (FACT-P) scale, and a decline in the PSA level of 90% or more from baseline.\n\n【22】Radiographic disease was evaluated with the use of either computed tomography or magnetic resonance imaging and with the use of bone scanning. Imaging was performed at the time of screening, at weeks 9, 17, and 25, and every 12 weeks thereafter. Radiologists at a central location who were unaware of the study-group assignments determined whether there was progressive disease on the basis of Response Evaluation Criteria in Solid Tumors (RECIST), version 1.1, for soft tissue or on the basis of criteria adapted from the Prostate Cancer Clinical Trials Working Group 2 <sup><a>17 </a></sup> for osseous disease .\n\n【23】Statistical Analysis\n--------------------\n\n【24】The planned enrollment was approximately 1680 patients. The coprimary end points were analyzed in the intention-to-treat population at a total type I error rate of 0.05, with an error rate of 0.001 (two-sided) allocated to radiographic progression-free survival and an error rate of 0.049 (two-sided) allocated to overall survival. It was planned that the final analysis of radiographic progression-free survival would be conducted after the occurrence of at least 410 events at the time of the interim analysis of overall survival. The interim analysis of overall survival was to be conducted after the occurrence of approximately 516 deaths, or 67% of the 765 deaths specified for the final analysis. The final analysis of radiographic progression-free survival was performed after the occurrence of 439 events (with data cutoff on May 6, 2012); the interim analysis of overall survival was performed after the occurrence of 540 deaths with the use of a two-sided type I error rate of 0.0147. Holm's step-down procedure was applied to the analyses of the secondary end points to maintain a two-sided type I error of 5%.  The results presented here are based on a cutoff date of September 16, 2013, unless otherwise specified. An updated survival analysis was performed with a data-cutoff date of January 15, 2014.\n\n【25】Results\n-------\n\n【26】Study Patients\n--------------\n\n【27】A total of 1717 patients were enrolled in the study, with 872 in the enzalutamide group and 845 in the placebo group; 1715 patients received at least one dose of a study drug . Baseline demographic and disease characteristics were well balanced between the two groups . The median time that patients received a study drug was substantially longer in the enzalutamide group than in the placebo group (16.6 months vs. 4.6 months). More patients in the enzalutamide group than in the placebo group received at least 12 months of treatment (68% vs. 18%) and continued to receive treatment as of the data-cutoff date (42% vs. 7%).\n\n【28】Coprimary End Points\n--------------------\n\n【29】### _Radiographic Progression-free Survival_\n\n【30】Figure 1. Kaplan–Meier Estimates of Radiographic Progression-free Survival and Overall Survival.\n\n【31】Shown are data for the coprimary end points of radiographic progression-free survival  and overall survival . The dashed horizontal lines indicate medians. Hazard ratios are based on unstratified Cox regression models with treatment as the only covariate, with values of less than 1.00 favoring enzalutamide.\n\n【32】At 12 months of follow-up, the rate of radiographic progression-free survival was 65% in the enzalutamide group and 14% in the placebo group. Treatment with enzalutamide, as compared with placebo, resulted in an 81% reduction in the risk of radiographic progression or death (hazard ratio in the enzalutamide group, 0.19; 95% confidence interval \\[CI\\], 0.15 to 0.23; P<0.001) . Fewer patients in the enzalutamide group than in the placebo group had radiographic progression or died (118 of 832 patients \\[14%\\] vs. 321 of 801 patients \\[40%\\]). The median radiographic progression-free survival was not reached in the enzalutamide group, as compared with 3.9 months in the placebo group. The treatment effect of enzalutamide on radiographic progression-free survival was consistent across all prespecified subgroups .\n\n【33】### _Overall Survival_\n\n【34】At the planned interim analysis of overall survival, the median duration of follow-up for survival was approximately 22 months. Fewer deaths occurred in the enzalutamide group than in the placebo group (241 of 872 patients \\[28%\\] vs. 299 of 845 patients \\[35%\\]). Treatment with enzalutamide, as compared with placebo, resulted in a 29% decrease in the risk of death (hazard ratio, 0.71; 95% CI, 0.60 to 0.84; P<0.001) . The median overall survival was estimated at 32.4 months in the enzalutamide group and 30.2 months in the placebo group. The treatment effect of enzalutamide on overall survival was consistent across all prespecified subgroups . The risk reductions for both coprimary end points were unaffected by previous exposure to antiandrogens. After review of the interim coprimary efficacy and safety results, the data and safety monitoring committee recommended halting the study and offering enzalutamide to eligible patients receiving placebo. An updated analysis of overall survival with 116 additional deaths showed that 82% of patients in the enzalutamide group and 73% of those in the placebo group were alive at 18 months; the estimated median was not yet reached in the enzalutamide group and was 31.0 months in the placebo group (hazard ratio, 0.73; 95% CI, 0.63 to 0.85; P<0.001) .\n\n【35】Subsequent Antineoplastic Therapy\n---------------------------------\n\n【36】Subsequent antineoplastic treatments associated with a demonstrated survival benefit in metastatic prostate cancer were received by 40% of patients in the enzalutamide group, as compared with 70% of those in the placebo group. The two most common subsequent therapies were docetaxel (received by 33% and 57% of patients, respectively) and abiraterone (received by 21% and 46%, respectively) . The use of abiraterone was more common in North America than in other regions. The duration and efficacy of post-progression therapies were not ascertained.\n\n【37】Prespecified Secondary and Exploratory End Points\n-------------------------------------------------\n\n【38】Table 1. Secondary and Prespecified Exploratory End Points. Figure 2.  Figure 2. Kaplan–Meier Estimates for the Times until the Initiation of Cytotoxic Chemotherapy and an Increased Level of Prostate-Specific Antigen.\n\n【39】Shown are secondary efficacy end points that include the time until the initiation of cytotoxic chemotherapy  and the time until an increased level of prostate-specific antigen (PSA) . The horizontal dashed lines indicate medians. Hazard ratios are based on unstratified Cox regression models with treatment as the only covariate, with values of less than 1.00 favoring enzalutamide. The full definition of PSA progression is provided in Table S1 in the Supplementary Appendix .\n\n【40】The superiority of enzalutamide over placebo was shown with respect to all secondary end points. The median time until the initiation of cytotoxic chemotherapy was 28.0 months in the enzalutamide group, as compared with 10.8 months in the placebo group (hazard ratio, 0.35; P<0.001) . Treatment with enzalutamide also resulted in a reduction in the risk of a first skeletal-related event, which occurred in 278 patients (32%) in the enzalutamide group and 309 patients (37%) in the placebo group (hazard ratio, 0.72; P<0.001) at a median of approximately 31 months in each of the two groups .\n\n【41】Among patients with measurable soft-tissue disease at baseline, 59% of the patients in the enzalutamide group, as compared with 5% in the placebo group, had an objective response (P<0.001) : complete and partial responses were observed in 20% and 39% of the patients, respectively, in the enzalutamide group, as compared with 1% and 4%, respectively, in the placebo group. Enzalutamide was also superior to placebo with respect to reductions of at least 50% and 90% in the PSA level, the time until PSA progression, and the time until a decline in the quality of life . The median time until a quality-of-life deterioration, as measured on the FACT-P scale, was 11.3 months in the enzalutamide group and 5.6 months in the placebo group (hazard ratio, 0.63; P<0.001).\n\n【42】Safety\n------\n\n【43】Table 2. Summary of Adverse Events. Table 3.  Table 3. Most Common Adverse Events and Events of Special Interest.\n\n【44】Adverse events are summarized in Table 2 and Table 3 (with events occurring in at least 10% of patients in the enzalutamide group listed in the latter table). The median reporting period for adverse events was 17.1 months in the enzalutamide group and 5.4 months in placebo group, which reflected the longer exposure of patients to enzalutamide. A grade 3 or higher adverse event was reported in 43% of the patients in the enzalutamide group, as compared with 37% in the placebo group; however, the median time until the first event of grade 3 or higher was 22.3 months in the enzalutamide group and 13.3 months in the placebo group . The most common adverse events leading to death were disease progression and a general deterioration in physical health, with similar incidences in the two groups.\n\n【45】Adverse events that occurred in 20% or more of patients receiving enzalutamide at a rate that was at least 2 percentage points higher than that in the placebo group were fatigue , back pain, constipation, and arthralgia. After adjustment for the length of exposure, events with a higher rate in the enzalutamide group than in the placebo group were hot flush (14 vs. 12 events per 100 patient-years), hypertension (11 vs. 7 events per 100 patient-years), and falls (11 vs. 9 events per 100 patient-years). The most common event of grade 3 or higher in the enzalutamide group was hypertension, which was reported in 7% of the patients. The most common cardiac event was atrial fibrillation, which was reported in 2% of the patients in the enzalutamide group and in 1% of those in the placebo group. One patient in each study group had a seizure. No evidence of hepatotoxicity, as measured by adverse events or laboratory assessments, was observed in the enzalutamide group.\n\n【46】Discussion\n----------\n\n【47】In our study involving men with metastatic prostate cancer who had not received previous chemotherapy, enzalutamide extended the time until radiographic progression or death, improved overall survival, and delayed the initiation of chemotherapy by a median of 17 months. The benefit of enzalutamide on radiographic progression-free survival was observed from the first assessment 2 months after randomization and conferred a relative reduction of 81% in the risk of progression or death. Consistent benefit was observed in all prespecified subgroups, including patients with visceral disease, a population with a poorer prognosis that has been excluded from other trials involving men with metastatic prostate cancer who have not received previous chemotherapy. \n\n【48】Enzalutamide significantly reduced the risk of death by 29% over placebo, even though patients in the placebo group had received effective post-progression therapy more frequently and earlier than those in the enzalutamide group. The benefit of enzalutamide was observed as early as 4 months after randomization and was maintained throughout the study, as depicted by the separation in the Kaplan–Meier survival curves . At the time the trial was halted, following the interim analysis, the median follow-up for survival was 22 months, approximately 8 to 10 months shorter than the estimated survival medians. Because less than 5% of the patients were at risk when the estimated medians were reached, the hazard ratio, which analyzes the differences in outcome across the entire follow-up period, is a more accurate characterization of the survival benefit and other late-occurring end points than is the estimate of the median time until the event.\n\n【49】Health-related quality-of-life assessments can reinforce and augment objective measures such as overall survival and radiographic progression. In this population of men with metastatic prostate cancer, deterioration in the quality of life was delayed by enzalutamide, a result suggesting that the treatment effects translated into patient-perceived benefits.\n\n【50】The benefit of enzalutamide was achieved with a favorable safety profile. Grade 3 or higher adverse events were more common in enzalutamide-treated patients than in placebo-treated patients (43% vs. 37%), a finding that was probably influenced by the fact that the safety-reporting period for the enzalutamide group was approximately 1 year longer than that for the placebo group. The safety profile is further illustrated by the 9-month delay in the median time until the first adverse event of grade 3 or higher in the enzalutamide group. A similar proportion of patients in each group (6%) discontinued treatment because of an adverse event.\n\n【51】The safety profile was generally consistent with that previously reported for enzalutamide in patients who had received previous chemotherapy, with a few exceptions.  Seizure, which was previously observed in the enzalutamide group among patients who had received chemotherapy, occurred in a single patient (0.1%) in each group in our study. Both patients had a history of seizure that was unknown to investigators at the time of enrollment. Hypertension was more commonly observed in the enzalutamide group than in the placebo group (13% vs. 4%) and occurred more often in patients with a medical history of hypertension. These events were not associated with symptoms of mineralocorticoid excess or an increased risk of cardiovascular or renal sequelae and generally were managed with the use of standard therapies. In contrast to other antiandrogens, enzalutamide was not associated with hepatotoxicity. Other adverse events that were reported more frequently in the enzalutamide group than in the placebo group included fatigue or asthenia, back pain, hot flush, and falls.\n\n【52】Although chemotherapy has been shown to improve overall and progression-free survival in men with metastatic prostate cancer,  many patients do not receive such therapy primarily because of preexisting medical conditions or associated toxic effects.  Thus, there is a need for effective, convenient, and less toxic therapies. Sipuleucel-T showed an overall survival advantage in asymptomatic or mildly symptomatic men, most of whom had not received chemotherapy, but did not induce tumor responses or delay disease progression or deterioration in quality of life.  Radium-223 was recently shown to extend survival in men with symptomatic castration-resistant prostate cancer and bone metastases.  Abiraterone plus prednisone, which was recently compared with prednisone in patients with metastatic prostate cancer  who had not received chemotherapy, improved progression-free survival, lengthened the time until a quality-of-life deterioration, delayed chemotherapy use, and was associated with a trend in favor of an overall survival benefit that did not reach statistical significance. Treatment with abiraterone requires concomitant use of prednisone to ameliorate symptoms of mineralocorticoid excess, including fluid overload, hypokalemia, and hypertension. \n\n【53】Multiple agents are now reported to improve survival for patients with metastatic prostate cancer that has progressed after androgen-deprivation therapy. The most effective use of these therapies (order of administration, duration of treatment, and efficacy of combinations) has not yet been defined.\n\n【54】In conclusion, in men with minimally symptomatic or asymptomatic metastatic prostate cancer who had not received chemotherapy, enzalutamide, an oral therapy with an excellent side-effect profile, significantly delayed radiographic disease progression or death, the need for cytotoxic chemotherapy, and the deterioration in quality of life and significantly improved overall survival.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-14 00:18:22", "grab_time": "2024-08-13 22:53:52"}
{"id": 2234516, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "12ff4bf7-28bf-4a15-b8b2-2ac93d414423", "title": "Reanalysis of Clinical Exome Sequencing Data", "text": "【0】Reanalysis of Clinical Exome Sequencing Data\nTo the Editor:\n--------------\n\n【1】The rapid accrual of knowledge in genomic medicine has prompted the reanalysis of existing data.  We clinically reanalyzed data from two patient series that had undergone diagnostic proband-only exome sequencing.\n\n【2】Figure 1. Effect of Systematic Reanalysis on Diagnostic Yields in Two Patient Series Referred to Clinical Exome Sequencing.\n\n【3】Panel A (Cohort 1) and Panel B (Cohort 2) depict the change in the molecular diagnostic yield between the original value, evidenced by respective publications,  and the reanalysis values. The yield alteration originates from patients whose diagnostic molecular findings changed from zero to one or more (new diagnosis, in red in the reanalysis bar), from one to two or more (multilocus pathogenic variation; the black segment below the red segment in the reanalysis bar), and from one to zero (overturned molecular diagnosis) . The black segment above the red segment represents the proportion of patients who received a partial diagnosis from reanalysis (two patients in Cohort 1 and five patients in Cohort 2), which is not counted toward the diagnostic yield. The Pareto charts to the right of the bar charts illustrate the breakdown of the interpretive reasons contributing to each new molecular diagnosis, with cumulative counts from each category shown in the bottom axis and the cumulative percentages shown in the top axis. CNV denotes copy-number variant.\n\n【4】The exome sequences of the first series of 250 patients were obtained during 2011 and 2012.  Cumulative reanalyses of extant data after the release of the initial clinical report increased the molecular diagnostic yield of cases from 24.8% to 46.8% (comprehensive manual reanalysis was performed on the basis of a knowledge source from December 2017) . Although clinical laboratories often use a “manual” approach  for routine exome-sequence analysis, this approach may not be sustainable at scale, particularly for iterative reanalyses accruing historical cases. We designed a semiautomated reanalysis process, which prioritizes variants on the basis of genetic or functional evidence and prioritizes genes on the basis of semantic phenotypic similarity scores . This approach, when used to analyze the first series, achieved a diagnostic sensitivity of 92.9% (with the manual reanalysis as the reference standard), while sustaining a manageable workload under a model of annual reanalysis over a 5-year period .\n\n【5】This semiautomated reanalysis approach was then applied to a second cohort of 2000 consecutive cases originally analyzed in 2012 and 2013,  and the molecular diagnostic yield increased from 25.2% to 36.7% . We did not carry out manual reanalysis of the exome sequences of the second, much larger cohort, given the burden of the task. Potential factors contributing to the difference in the overall diagnostic yields between the two series (46.8% vs. 36.7%) include different percentages of patients with mendelian disorders and a difference in sensitivity between comprehensive manual analysis and semiautomated analysis.\n\n【6】In line with the rapid pace of improvement in knowledge of genetic causes of disease, the vast majority of new molecular diagnoses resulted from newly discovered disease genes (75% in Cohort 1 and 64% in Cohort 2) . In addition, several newly implicated genes that were initially associated with childhood-onset neurologic disorders, including _PURA_ , _DDX3X_ , and _TANGO2_ , rank highly among the most frequently mutated in our clinical cohorts . New molecular diagnoses also resulted from upgraded variant classifications in known disease genes (6% in Cohort 1 and 14% in Cohort 2) . Other contributors include the emergence of additional clinically observed phenotypes, the identification of pathogenic copy-number variants, and the positive identification of a genetic cause that had been missed previously . The number of patients with multiple molecular diagnoses increased from 25 to 48 (in the combined series) after reanalysis, which illustrates the contribution of continued genomic analyses to the deconvolution of clinically blended phenotypes . \n\n【7】Education is necessary for physicians and patients to understand the concept of an “evolving” molecular interpretation. The communication and counseling processes are complicated pragmatically by the temporal separation between the initial report and the updated report and by the dilemma of whom to send the report to. We sent a survey to 55 health care providers of the 64 patients in the first series for whom the reanalysis had yielded new molecular diagnoses and received a response from 23 providers (42%) regarding follow-up data for 42 patients (66%). Of these, 10 reported a preference that all physicians involved in the patient’s care be informed of the results of the reanalysis, and 13 reported a preference that only the physician who ordered the reanalysis or who had ordered the original analysis be informed. The respondents reported that about three quarters of their patients (30) had received genetic counseling for the updated findings, and of these 30, approximately half (17) had their clinical management changed as a consequence of the new results . These findings suggest that periodic, cost-effective reanalysis may benefit patients and their families and physicians, although an important caveat is that our study was not designed to measure the clinical benefit of the intervention.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 18:01:26", "endTime": "2024/08/13 18:01:39", "cost": 13.134}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 02:01:39", "grab_time": "2024-08-13 02:01:25"}
{"id": 2234515, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "962ce99f-dd42-4552-9300-4693863b77eb", "title": "A Randomized Trial of a Transglutaminase 2 Inhibitor for Celiac Disease", "text": "【0】Abstract\n--------\n\n【1】Background\n----------\n\n【2】In celiac disease, small intestinal transglutaminase 2 causes deamidation of glutamine residues in gluten peptides, which enhances stimulation of T cells and leads to mucosal injury. Inhibition of transglutaminase 2 is a potential treatment for celiac disease.\n\n【3】Methods\n-------\n\n【4】Download a PDF of the Research Summary .\n\n【5】In a proof-of-concept trial, we assessed the efficacy and safety of a 6-week treatment with ZED1227, a selective oral transglutaminase 2 inhibitor, at three dose levels as compared with placebo, in adults with well-controlled celiac disease who underwent a daily gluten challenge. The primary end point was the attenuation of gluten-induced mucosal damage, as measured by the ratio of villus height to crypt depth. Secondary end points included intraepithelial lymphocyte density, the Celiac Symptom Index score, and the Celiac Disease Questionnaire score (for assessment of health-related quality of life).\n\n【6】Results\n-------\n\n【7】Of the 41 patients assigned to the 10-mg ZED1227 group, the 41 assigned to the 50-mg group, the 41 assigned to the 100-mg group, and the 40 assigned to the placebo group, 35, 39, 38, and 30 patients, respectively, had adequate duodenal-biopsy samples for the assessment of the primary end point. Treatment with ZED1227 at all three dose levels attenuated gluten-induced duodenal mucosal injury. The estimated difference from placebo in the change in the mean ratio of villus height to crypt depth from baseline to week 6 was 0.44 (95% confidence interval \\[CI\\], 0.15 to 0.73) in the 10-mg group (P=0.001), 0.49 (95% CI, 0.20 to 0.77) in the 50-mg group (P<0.001), and 0.48 (95% CI, 0.20 to 0.77) in the 100-mg group (P<0.001). The estimated differences from placebo in the change in intraepithelial lymphocyte density were −2.7 cells per 100 epithelial cells (95% CI, −7.6 to 2.2) in the 10-mg group, −4.2 cells per 100 epithelial cells (95% CI, −8.9 to 0.6) in the 50-mg group, and −9.6 cells per 100 epithelial cells (95% CI, −14.4 to −4.8) in the 100-mg group. Use of the 100-mg dose may have improved symptom and quality-of-life scores. The most common adverse events, the incidences of which were similar across all groups, were headache, nausea, diarrhea, vomiting, and abdominal pain. Rash developed in 3 of 40 patients (8%) in the 100-mg group.\n\n【8】Conclusions\n-----------\n\n【9】In this preliminary trial, treatment with ZED1227 attenuated gluten-induced duodenal mucosal damage in patients with celiac disease. \n\n【10】Introduction\n------------\n\n【11】 QUICK TAKE  \nA Randomized Trial of a Transglutaminase 2 Inhibitor for Celiac Disease  \n\n【12】Celiac disease is characterized by inflammation of the small intestine, is frequently associated with autoimmunity, and affects 0.2 to 2.0% of the population in most countries.  The identification of cases has increased in the past decades owing to improved serologic diagnosis, as has the true prevalence of celiac disease.  Celiac disease is driven by the ingestion of gluten in wheat and related grains in genetically predisposed persons who have HLA-DQ2 and HLA-DQ8 genotypes, which are necessary but not sufficient for the manifestation of celiac disease. The classic symptoms of celiac disease are diarrhea, weight loss, and malnutrition, but celiac disease frequently manifests with nonspecific or atypical symptoms, including fatigue, altered bowel habits, anemia, osteoporosis, or autoimmune diseases such as autoimmune thyroiditis and type 1 diabetes. \n\n【13】Active celiac disease is diagnosed on the basis of elevated levels of serum autoantibodies to transglutaminase 2 and is confirmed by histologic villus atrophy and crypt hyperplasia in the proximal small intestine, accompanied by intraepithelial lymphocyte infiltration in duodenal mucosa.  The only available treatment for celiac disease is lifelong adherence to a strict gluten-free diet, a diet that is difficult to maintain,  and only 50% of patients have mucosal recovery and often do not have negative serum autoantibodies 1 year or later after diagnosis.  Moreover, many patients with celiac disease report having persistent symptoms despite adherence to the gluten-free diet.  Thus, there is an unmet medical need for an effective treatment adjunct to a strict gluten-free diet. Currently, no drug therapy reliably prevents the effects of dietary gluten or has been approved by regulators to treat celiac disease.\n\n【14】Transglutaminase 2, the celiac autoantigen,  is expressed in the intestinal mucosa, where it modifies immunogenic gluten peptides by means of deamidation of certain charge-neutral glutamine residues, yielding negatively charged glutamic acid residues.  This modification promotes gluten-peptide presentation by HLA-DQ2 or HLA-DQ8 molecules on mucosal antigen–presenting cells  and enables the activation and expansion of gluten peptide–specific CD4+ type 1 helper T cells and the secretion of proinflammatory cytokines. This process leads to villus atrophy and crypt hyperplasia and to B-cell differentiation and the production of transglutaminase 2 IgA. \n\n【15】ZED1227 inhibits transglutaminase 2 with high specificity and prevents the formation of deamidated gluten and, putatively, the initial steps of gluten-induced T-cell activation.  ZED1227 is formulated as an oral capsule for duodenal targeting and has been tested for clinical safety in earlier studies . Our phase 1 clinical studies, which involved 106 healthy persons who were exposed to doses of up to 500 mg of ZED1227 for up to 8 days, did not show drug-related adverse effects or signs of drug toxicity, and systemic drug levels after oral ingestion were low. Here, we report the results of a phase 2, randomized, double-blind, placebo-controlled, dose-finding trial of ZED1227 capsules to evaluate efficacy and safety in adult patients with celiac disease in histologic and serologic (transglutaminase 2 IgA) remission owing to a gluten-free diet who were challenged with daily gluten intake for 6 weeks.\n\n【16】Methods\n-------\n\n【17】Trial Oversight\n---------------\n\n【18】We conducted this trial at 20 sites in seven countries (Estonia, Finland, Germany, Ireland, Lithuania, Norway, and Switzerland). The trial was approved by an independent ethics committee at each site. Written informed consent was obtained from each patient before screening. The sponsor, Dr. Falk Pharma, contributed to the trial design, data analysis, and the writing and editing of the manuscript. Data were collected by the investigators with the use of electronic case-report forms.\n\n【19】Trial Patients\n--------------\n\n【20】Adults 18 to 65 years of age who had received a biopsy-confirmed diagnosis of celiac disease at least 12 months before screening and who were positive for HLA-DQ2 or HLA-DQ8 genotypes were considered for inclusion in the trial. Patients had to have successfully adhered to a gluten-free diet for at least 12 months, to present with negative serologic testing for transglutaminase 2 IgA and a mean ratio of villus height to crypt depth of 1.5 or higher, and to agree to tolerate a challenge of ingesting 3 g of gluten daily for 6 weeks.\n\n【21】Trial Design and Treatment\n--------------------------\n\n【22】In this double-blind, placebo-controlled, dose-ranging trial, eligible patients were randomly assigned, in a : ratio, to one of four parallel groups to receive 10 mg of ZED1227, 50 mg of ZED1227, 100 mg of ZED1227, or placebo, all with matched appearance, concurrent with the gluten challenge . Each morning after at least 6 hours of fasting, patients took ZED1227 or placebo orally and, 30 minutes later, ate one sponsor-provided biscuit containing 3 g of gluten before breakfast. Throughout the 6-week trial, patients were required to continue their strict gluten-free diet, aside from eating the sponsor-provided gluten-containing biscuit.\n\n【23】Duodenal mucosal damage as an objective marker of gluten-induced celiac disease activity can be measured quantitatively by means of standardized histopathological morphometry.  The gluten challenge, in which a moderate amount of gluten is ingested daily for a limited duration, produces a statistically and clinically significant but reversible deterioration of duodenal mucosa and allows for the assessment of efficacy of the active treatment. \n\n【24】End Points\n----------\n\n【25】The primary end point was the attenuation of gluten-induced deterioration of intestinal mucosal morphologic features, as measured by the ratio of villus height to crypt depth in duodenal-biopsy samples obtained starting at the baseline (screening) visit to the end of the 6-week gluten challenge and treatment period.  Secondary end points included changes from baseline to week 6 in the density of CD3+ intraepithelial lymphocytes, the modified Marsh–Oberhuber classification,  patient-reported outcomes as measured by the Celiac Symptom Index  and the Celiac Disease Questionnaire,  blood markers of malabsorption (e.g., ferritin, transferrin saturation, and albumin), plasma concentrations of ZED1227, and serologic markers of celiac disease. On the modified Marsh–Oberhuber classification, a score of 0 indicates normal duodenal morphology without increased intraepithelial lymphocytes; a score of 1, normal duodenal morphology with increased intraepithelial lymphocytes; a score of 2, normal villi but crypt hyperplasia; and scores of 3a through 3c, increasing severity of villus atrophy and crypt hyperplasia, with a score of 3c indicating complete villus atrophy. The Celiac Symptom Index is a 16-item questionnaire, with each item rated on a scale of 1 (no symptoms) to 5 (symptoms all the time); overall scores range from 16 to 80, with higher scores indicating worse celiac disease–related symptoms.  The Celiac Disease Questionnaire is a 28-item questionnaire, with each item rated from 1 (reduced health-related quality of life) to 7 (high health-related quality of life); overall scores range from 28 to 196, with higher scores indicating better quality of life. \n\n【26】Safety was evaluated by the monitoring of adverse events, vital signs, body weight, clinical laboratory tests, and side-effect profile as assessed by the investigator and the patient. For the assessment of change in the ratio of villus height to crypt depth, patients were excluded from the analysis if they did not have adequate follow-up duodenal-biopsy samples that allowed for the measurement of at least three separate villus–crypt units.  A sensitivity analysis included all the patients who underwent randomization and received at least one dose of ZED1227 or placebo. All the other efficacy analyses involved patients who underwent randomization and received at least one dose of ZED1227 or placebo, without imputation of missing values at follow-up; modeling was performed with the use of complete cases only.\n\n【27】Trial Procedures and Assessments\n--------------------------------\n\n【28】Enrollment required a screening period of no more than 8 weeks, including upper gastrointestinal endoscopy with duodenal biopsies performed within 4 weeks before the administration of the first dose in order to provide baseline histologic data. At the week 0 visit, the trial drug (ZED1227 or placebo) and gluten biscuits were dispensed to patients according to assigned group. Patients returned to the trial sites at weeks 2, 4, and 6 for assessments and at week 10 for a follow-up visit. A second endoscopy with biopsies was performed at the week 6 or withdrawal visit. Both endoscopies were conducted by experienced gastroenterologists. Four forceps biopsy samples (one biopsy sample per pass) were obtained from the second and third parts of the duodenum, put in a PAXgene fixative, and sent to the central histopathology laboratory (Jilab, Tampere, Finland) for processing and reading. Validated, standardized morphometric procedures separately evaluated mucosal morphology and inflammation.  The categorical Marsh–Oberhuber classification  was used for the standard classification of the mucosal lesions .\n\n【29】Patients kept a diary (on paper or electronically) to record their daily use of the assigned trial drug as well as their gluten biscuit and food intake, concomitant medications, and stool frequency and characteristics. Scores on the Celiac Symptom Index and Celiac Disease Questionnaire were determined at all visits. At the end of the treatment period (week 6), investigators and patients independently rated the trial treatment as being “very good,” “good,” “satisfactory,” or “poor” with regard to both efficacy and the side-effect profile.\n\n【30】Adverse events were recorded and evaluated by the investigators. Blood samples were obtained to determine hematologic, coagulation, and serum markers.\n\n【31】Statistical Analysis\n--------------------\n\n【32】We estimated that a sample of 136 patients, or 34 patients per group, would provide the trial with 80% power for the primary analysis, assuming an alpha error of 0.05, an effect size of 0.6, and standard deviation of 0.8. On the basis of an estimated 15% of patients either withdrawing or having insufficient samples for evaluation, we planned for the enrollment of 160 patients (40 per group).\n\n【33】The primary end point, the mean change in the ratio of villus height to crypt depth from baseline to week 6, was analyzed with the use of a generalized linear model with the identity link, in which trial group and the baseline ratio of villus height to crypt depth were fixed effects, because assumptions for the parametric model were met. Each ZED1227 dose group was compared with the placebo group. The same statistical method was used for the analyses of the change from baseline to week 6 in the intraepithelial lymphocyte density, Celiac Symptom Index scores, and Celiac Disease Questionnaire scores, which were key secondary end points. The statistical analysis of other end points (the change of Marsh–Oberhuber classification, transglutaminase 2 IgA and IgA antiendomysial antibodies, and blood malabsorption markers) is described in the Supplementary Appendix . The analysis to assess sensitivity to missing data is described in the Supplementary Appendix .\n\n【34】Plasma concentrations of ZED1227 and metabolites were measured and analyzed for pharmacokinetic profiles. The results are not reported here.\n\n【35】All statistical comparisons between each ZED1227 dose and placebo were two-sided, with a familywise alpha error of 0.05. For the analysis of the primary end point, 95% confidence intervals and P values were adjusted for multiple comparisons with the use of Bonferroni correction to account for the three comparisons with placebo. An adjusted P value of 0.0167 was considered to indicate statistical significance for the primary end point, and individual confidence intervals were constructed with the use of 98.3% levels. For secondary end points, 95% confidence intervals are reported without P values; the 95% confidence intervals have not been adjusted for multiple comparisons and cannot be used to infer definitive treatment effects. One interim analysis was conducted for the primary efficacy variable .\n\n【36】Results\n-------\n\n【37】Characteristics of the Patients and Regimen Adherence\n-----------------------------------------------------\n\n【38】The trial was conducted from May 16, 2018, to February 27, 2020. Of the 163 patients who underwent randomization (with 41 patients assigned to the 10-mg ZED1227 group, 41 to the 50-mg group, 41 to the 100-mg group, and 40 to the placebo group), 3 did not receive ZED1227 or placebo because of the development of other clinical conditions, and 1 patient received ZED1227 but was lost to follow-up . Analyses of efficacy excluded these 4 patients and thus included 41 patients in the 10-mg group, 41 in the 50-mg group, 39 in the 100-mg group, and 38 in the placebo group.\n\n【39】Table 1. Demographic Characteristics of the Patients.\n\n【40】The demographic characteristics of these 159 patients were similar across the groups, except for a higher percentage of women in the 10-mg group . According to the investigators’ assessment and patients’ diaries, adherence was high and similar in all four groups, ranging from 96 to 100% both for the trial regimen and for gluten intake.\n\n【41】Efficacy Results\n----------------\n\n【42】Histology-related efficacy end points could be evaluated in 142 patients who had sufficient biopsy samples at both baseline and week 6; a total of 35 patients in the 10-mg group, 39 in the 50-mg group, 38 in the 100-mg group, and 30 in the placebo group were included in the analysis. Four of these patients stopped treatment before week 6 but qualified for inclusion in the primary end-point analysis with a treatment duration of 23 to 32 days.\n\n【43】Table 2. Effect of ZED1227 Treatment on the Ratio of Villus Height to Crypt Depth. Figure 1.  Figure 1. Paired Data Plots of the Mean Ratio of Villus Height to Crypt Depth (Primary End Point).\n\n【44】The primary end point was the attenuation of gluten-induced mucosal damage, as measured by the ratio of villus height to crypt depth. The prespecified population for this analysis included the 142 patients who had villus height and crypt depth measurements from at least three villus–crypt units in total from the duodenum biopsies available at both the screening (baseline) visit and the final or withdrawal visit. Horizontal bars indicate mean values in each group at each time point.\n\n【45】As expected, in the placebo group, the gluten challenge decreased the ratio of villus height to crypt depth from baseline to week 6 (estimated change, −0.61; 95% confidence interval \\[CI\\], −0.78 to −0.44). Treatment with daily doses of 50 mg and 100 mg of ZED1227 prevented this deterioration (estimated change, −0.12 \\[95% CI, −0.27 to 0.03\\] and −0.13 \\[95% CI, −0.28 to 0.03\\], respectively); efficacy in the 10-mg group was slightly less (estimated change, −0.17; 95% CI, −0.33 to −0.01). As compared with placebo, all three dose levels of ZED1227 significantly prevented a decrease in the ratio of villus height to crypt depth (P≤0.001 for all comparisons) . Results of the sensitivity analysis were similar to those of the primary end-point analysis .\n\n【46】Table 3. Effect of ZED1227 Treatment on Intraepithelial Lymphocyte Density and Scores on the Celiac Symptom Index and Celiac Disease Questionnaire.\n\n【47】Gluten ingestion caused an increase from baseline in intraepithelial lymphocyte density, a key variable of mucosal inflammation, in the placebo group, the 10-mg group, and the 50-mg group but not in the 100-mg group; the increase was attenuated by ZED1227 dose-dependently . According to the modified Marsh–Oberhuber classification, a histologic score in which class 2 describes deepened crypts and class 3a to 3c categorically describes increasing severity of villus atrophy and increasing crypt depth, the odds and risk ratios favored all three doses of ZED1227 over placebo .\n\n【48】The Celiac Symptom Index score increased from baseline to week 6 in all groups and returned to baseline at the follow-up visit. Comparison with placebo favored all dose levels of ZED1227. The Celiac Disease Questionnaire overall score increased from baseline to week 6 in all ZED1227 dose groups but decreased with placebo. The changes in the Celiac Disease Questionnaire gastrointestinal subscore from baseline to week 6 and comparison with placebo favored ZED1227. At the week 6 visit, 10% of the patients in the 10-mg group, 7% of those in the 50-mg group, 8% of those in the 100-mg group, and 26% of those in the placebo group assessed the efficacy as “poor.” Data are shown in Table 3 and S4 and Figure S5.\n\n【49】At screening (baseline), all the patients had normal levels of transglutaminase 2 IgA. At the week 6 assessment, 1 patient (2%) who received the 10-mg dose, 1 (2%) who received the 50-mg dose, and no patient who received the 100-mg dose, as compared with 6 patients (16%) who received placebo, had a conversion to a positive result. The titer of transglutaminase 2 IgA increased by a mean of 2.4 kU per liter in the placebo group, by 1.7 kU per liter in the 10-mg group, and by 0.3 kU per liter in the 50-mg group and decreased by 0.1 kU per liter in the 100-mg group. Similar results were obtained regarding IgA antiendomysial antibodies .\n\n【50】Safety\n------\n\n【51】Table 4. Common Adverse Events That Occurred in Three or More Patients in Any Group.\n\n【52】Adverse events occurred in 125 of the 160 patients (78%) who received at least one dose of ZED1227 or placebo . (In addition to the 159 patients in the efficacy analysis, 1 patient was added to the 100-mg group for the safety analysis because this patient received the trial drug but was lost to follow-up, so the administration of the medication was uncertain.) Most adverse events appeared to be related to the gluten challenge. A total of 74 patients (46%), including 14 of 41 patients (34%) in the 10-mg group, 19 of 41 (46%) in the 50-mg group, 20 of 40 (50%) in the 100-mg group, and 21 of 38 (55%) in the placebo group, had an adverse event that the investigators considered to be potentially related to ZED1227 or placebo. The most common adverse events across all groups were headache, nausea, diarrhea, vomiting, and abdominal pain. With the exception of rash, which occurred in 3 patients (8%) in the 100-mg group, no adverse events appeared to be more common in the ZED1227 groups than in the placebo group. Serious adverse events that were considered by the investigators to be related to ZED1227 or placebo occurred in 2 patients (migraine with aura in 1 patient receiving 50 mg of ZED1227 and ventricular extrasystoles in 1 patient receiving placebo). These 2 patients discontinued ZED1227 or placebo and recovered.\n\n【53】A broad range of variables were measured in blood, including cell counts, liver and kidney functions, surrogates of resorption (albumin, transferrin saturation, zinc, vitamin B <sub>12 </sub> , and folic acid), and factor XIII, another common transglutaminase. Results were similar across all the trial groups. During the gluten challenge, the levels of alanine aminotransferase and alkaline phosphatase increased from baseline to week 6 in the placebo group and then normalized at week 10. Such changes were not observed in any of the ZED1227 groups .\n\n【54】Discussion\n----------\n\n【55】In this preliminary, randomized, double-blind, placebo-controlled, 6-week trial, the effectiveness of transglutaminase 2 inhibition with the oral transglutaminase 2 inhibitor ZED1227 was shown in patients with celiac disease who were challenged with a moderate amount (3 g) of daily gluten intake. ZED1227 was developed to specifically block transglutaminase 2–mediated potentiation of gluten-peptide immunogenicity in the small intestinal mucosa, a key driver of celiac disease pathogenesis.  As compared with placebo, all doses of ZED1227 attenuated the gluten-induced small intestinal damage.\n\n【56】This trial showed that treatment with the highly specific transglutaminase 2 inhibitor ZED1227 attenuated the gluten-induced damage in the duodenal mucosa. The ratio of villus height to crypt depth is widely considered to be the most objective and valid primary end point in clinical studies for therapies for celiac disease,  and the end point was achieved at all three dose levels of ZED1227. The benefits across multiple end points were most pronounced for the 50-mg and 100-mg doses. Improved patient-reported outcomes across the dose groups need to be confirmed in a larger study, since they may reflect the rather small size of each group for the evaluation of symptoms or the scales capturing some symptoms that may overlap with, but are unrelated to, celiac disease. Overall, the incidence and severity of adverse events were similar in the ZED1227 groups and the placebo group.\n\n【57】Since the discovery of transglutaminase 2 as the autoantigen in celiac disease,  extensive research has confirmed it to be a crucial mechanistic driver of gluten-induced inflammation and clinical manifestations in patients with celiac disease.  This trial supports the role of transglutaminase 2 in the pathogenesis of celiac disease, given that its inhibition prevents the deamidation of gluten peptides in the small intestinal mucosa and thus abolishes the immunogenic process. ZED1227 targets the intestinal mucosa predominantly and thereby mediates protection; thus, it is unaffected by the complexity of the food matrix and is less dependent on the timing of ingestion of gluten-containing food.\n\n【58】The Food and Drug Administration recently reinforced its recommendation that, in pharmacologic trials of celiac disease, the prevention of histologic damage should be a major end point in phase 2 clinical studies, and the improvement of celiac disease–related patient-reported outcomes and quality of life should both be primary end points in phase 3 trials.  This recommendation is justified, since only 40% of adult patients with newly diagnosed celiac disease have gastrointestinal symptoms, whereas a gluten challenge induces a manifest duodenal mucosal lesion, often before any symptoms occur.  Furthermore, mucosal healing is considered to be the key criterion of successful treatment and a prerequisite for patients’ long-term well-being and the prevention of severe complications.  Therefore, we selected the gluten challenge and used validated quantitative histopathological testing as the primary end point in our proof-of-concept trial. \n\n【59】Celiac disease is highly prevalent in White, Middle Eastern, and Indian populations and is prevalent among Native Americans and Northeast Asians. The prevalence is low among Black Africans and Southeast Asians, but the prevalence in these populations can be high if European ancestry is also involved. Therefore, the patients in our trial represented the ancestral cross-section of the European countries participating in the trial; there was no intention to include or exclude certain racial or ethnic groups from the trial.\n\n【60】Strengths of this trial were the high levels of patient adherence to the regimen and to the gluten challenge, which maximized the data that could be evaluated. Limitations include a substantial amount of missing data and the loss of several patients to follow-up, the short duration of the trial, and the controlled gluten ingestion. Future studies of ZED1227 in more patients are needed to provide additional evidence of the safety and efficacy of the drug, potentially in real-life conditions with minor gluten ingestion.\n\n【61】In this phase 2 trial, we found that the oral transglutaminase 2 inhibitor ZED1227 effectively attenuated intestinal mucosal injury in patients with celiac disease challenged with a moderate dose of daily gluten.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "【4】Download a PDF of the Research Summary .", "content": "【0】Abstract\n--------\n\n【1】Background\n----------\n\n【2】In celiac disease, small intestinal transglutaminase 2 causes deamidation of glutamine residues in gluten peptides, which enhances stimulation of T cells and leads to mucosal injury. Inhibition of transglutaminase 2 is a potential treatment for celiac disease.\n\n【3】Methods\n-------\n\n【4】Download a PDF of the Research Summary .\n\n【5】In a proof-of-concept trial, we assessed the efficacy and safety of a 6-week treatment with ZED1227, a selective oral transglutaminase 2 inhibitor, at three dose levels as compared with placebo, in adults with well-controlled celiac disease who underwent a daily gluten challenge. The primary end point was the attenuation of gluten-induced mucosal damage, as measured by the ratio of villus height to crypt depth. Secondary end points included intraepithelial lymphocyte density, the Celiac Symptom Index score, and the Celiac Disease Questionnaire score (for assessment of health-related quality of life).\n\n【6】Results\n-------\n\n【7】Of the 41 patients assigned to the 10-mg ZED1227 group, the 41 assigned to the 50-mg group, the 41 assigned to the 100-mg group, and the 40 assigned to the placebo group, 35, 39, 38, and 30 patients, respectively, had adequate duodenal-biopsy samples for the assessment of the primary end point. Treatment with ZED1227 at all three dose levels attenuated gluten-induced duodenal mucosal injury. The estimated difference from placebo in the change in the mean ratio of villus height to crypt depth from baseline to week 6 was 0.44 (95% confidence interval \\[CI\\], 0.15 to 0.73) in the 10-mg group (P=0.001), 0.49 (95% CI, 0.20 to 0.77) in the 50-mg group (P<0.001), and 0.48 (95% CI, 0.20 to 0.77) in the 100-mg group (P<0.001). The estimated differences from placebo in the change in intraepithelial lymphocyte density were −2.7 cells per 100 epithelial cells (95% CI, −7.6 to 2.2) in the 10-mg group, −4.2 cells per 100 epithelial cells (95% CI, −8.9 to 0.6) in the 50-mg group, and −9.6 cells per 100 epithelial cells (95% CI, −14.4 to −4.8) in the 100-mg group. Use of the 100-mg dose may have improved symptom and quality-of-life scores. The most common adverse events, the incidences of which were similar across all groups, were headache, nausea, diarrhea, vomiting, and abdominal pain. Rash developed in 3 of 40 patients (8%) in the 100-mg group.\n\n【8】Conclusions\n-----------\n\n【9】In this preliminary trial, treatment with ZED1227 attenuated gluten-induced duodenal mucosal damage in patients with celiac disease. \n\n【10】Introduction\n------------\n\n【11】 QUICK TAKE  \nA Randomized Trial of a Transglutaminase 2 Inhibitor for Celiac Disease  \n\n【12】Celiac disease is characterized by inflammation of the small intestine, is frequently associated with autoimmunity, and affects 0.2 to 2.0% of the population in most countries.  The identification of cases has increased in the past decades owing to improved serologic diagnosis, as has the true prevalence of celiac disease.  Celiac disease is driven by the ingestion of gluten in wheat and related grains in genetically predisposed persons who have HLA-DQ2 and HLA-DQ8 genotypes, which are necessary but not sufficient for the manifestation of celiac disease. The classic symptoms of celiac disease are diarrhea, weight loss, and malnutrition, but celiac disease frequently manifests with nonspecific or atypical symptoms, including fatigue, altered bowel habits, anemia, osteoporosis, or autoimmune diseases such as autoimmune thyroiditis and type 1 diabetes. \n\n【13】Active celiac disease is diagnosed on the basis of elevated levels of serum autoantibodies to transglutaminase 2 and is confirmed by histologic villus atrophy and crypt hyperplasia in the proximal small intestine, accompanied by intraepithelial lymphocyte infiltration in duodenal mucosa.  The only available treatment for celiac disease is lifelong adherence to a strict gluten-free diet, a diet that is difficult to maintain,  and only 50% of patients have mucosal recovery and often do not have negative serum autoantibodies 1 year or later after diagnosis.  Moreover, many patients with celiac disease report having persistent symptoms despite adherence to the gluten-free diet.  Thus, there is an unmet medical need for an effective treatment adjunct to a strict gluten-free diet. Currently, no drug therapy reliably prevents the effects of dietary gluten or has been approved by regulators to treat celiac disease.\n\n【14】Transglutaminase 2, the celiac autoantigen,  is expressed in the intestinal mucosa, where it modifies immunogenic gluten peptides by means of deamidation of certain charge-neutral glutamine residues, yielding negatively charged glutamic acid residues.  This modification promotes gluten-peptide presentation by HLA-DQ2 or HLA-DQ8 molecules on mucosal antigen–presenting cells  and enables the activation and expansion of gluten peptide–specific CD4+ type 1 helper T cells and the secretion of proinflammatory cytokines. This process leads to villus atrophy and crypt hyperplasia and to B-cell differentiation and the production of transglutaminase 2 IgA. \n\n【15】ZED1227 inhibits transglutaminase 2 with high specificity and prevents the formation of deamidated gluten and, putatively, the initial steps of gluten-induced T-cell activation.  ZED1227 is formulated as an oral capsule for duodenal targeting and has been tested for clinical safety in earlier studies . Our phase 1 clinical studies, which involved 106 healthy persons who were exposed to doses of up to 500 mg of ZED1227 for up to 8 days, did not show drug-related adverse effects or signs of drug toxicity, and systemic drug levels after oral ingestion were low. Here, we report the results of a phase 2, randomized, double-blind, placebo-controlled, dose-finding trial of ZED1227 capsules to evaluate efficacy and safety in adult patients with celiac disease in histologic and serologic (transglutaminase 2 IgA) remission owing to a gluten-free diet who were challenged with daily gluten intake for 6 weeks.\n\n【16】Methods\n-------\n\n【17】Trial Oversight\n---------------\n\n【18】We conducted this trial at 20 sites in seven countries (Estonia, Finland, Germany, Ireland, Lithuania, Norway, and Switzerland). The trial was approved by an independent ethics committee at each site. Written informed consent was obtained from each patient before screening. The sponsor, Dr. Falk Pharma, contributed to the trial design, data analysis, and the writing and editing of the manuscript. Data were collected by the investigators with the use of electronic case-report forms.\n\n【19】Trial Patients\n--------------\n\n【20】Adults 18 to 65 years of age who had received a biopsy-confirmed diagnosis of celiac disease at least 12 months before screening and who were positive for HLA-DQ2 or HLA-DQ8 genotypes were considered for inclusion in the trial. Patients had to have successfully adhered to a gluten-free diet for at least 12 months, to present with negative serologic testing for transglutaminase 2 IgA and a mean ratio of villus height to crypt depth of 1.5 or higher, and to agree to tolerate a challenge of ingesting 3 g of gluten daily for 6 weeks.\n\n【21】Trial Design and Treatment\n--------------------------\n\n【22】In this double-blind, placebo-controlled, dose-ranging trial, eligible patients were randomly assigned, in a : ratio, to one of four parallel groups to receive 10 mg of ZED1227, 50 mg of ZED1227, 100 mg of ZED1227, or placebo, all with matched appearance, concurrent with the gluten challenge . Each morning after at least 6 hours of fasting, patients took ZED1227 or placebo orally and, 30 minutes later, ate one sponsor-provided biscuit containing 3 g of gluten before breakfast. Throughout the 6-week trial, patients were required to continue their strict gluten-free diet, aside from eating the sponsor-provided gluten-containing biscuit.\n\n【23】Duodenal mucosal damage as an objective marker of gluten-induced celiac disease activity can be measured quantitatively by means of standardized histopathological morphometry.  The gluten challenge, in which a moderate amount of gluten is ingested daily for a limited duration, produces a statistically and clinically significant but reversible deterioration of duodenal mucosa and allows for the assessment of efficacy of the active treatment. \n\n【24】End Points\n----------\n\n【25】The primary end point was the attenuation of gluten-induced deterioration of intestinal mucosal morphologic features, as measured by the ratio of villus height to crypt depth in duodenal-biopsy samples obtained starting at the baseline (screening) visit to the end of the 6-week gluten challenge and treatment period.  Secondary end points included changes from baseline to week 6 in the density of CD3+ intraepithelial lymphocytes, the modified Marsh–Oberhuber classification,  patient-reported outcomes as measured by the Celiac Symptom Index  and the Celiac Disease Questionnaire,  blood markers of malabsorption (e.g., ferritin, transferrin saturation, and albumin), plasma concentrations of ZED1227, and serologic markers of celiac disease. On the modified Marsh–Oberhuber classification, a score of 0 indicates normal duodenal morphology without increased intraepithelial lymphocytes; a score of 1, normal duodenal morphology with increased intraepithelial lymphocytes; a score of 2, normal villi but crypt hyperplasia; and scores of 3a through 3c, increasing severity of villus atrophy and crypt hyperplasia, with a score of 3c indicating complete villus atrophy. The Celiac Symptom Index is a 16-item questionnaire, with each item rated on a scale of 1 (no symptoms) to 5 (symptoms all the time); overall scores range from 16 to 80, with higher scores indicating worse celiac disease–related symptoms.  The Celiac Disease Questionnaire is a 28-item questionnaire, with each item rated from 1 (reduced health-related quality of life) to 7 (high health-related quality of life); overall scores range from 28 to 196, with higher scores indicating better quality of life. \n\n【26】Safety was evaluated by the monitoring of adverse events, vital signs, body weight, clinical laboratory tests, and side-effect profile as assessed by the investigator and the patient. For the assessment of change in the ratio of villus height to crypt depth, patients were excluded from the analysis if they did not have adequate follow-up duodenal-biopsy samples that allowed for the measurement of at least three separate villus–crypt units.  A sensitivity analysis included all the patients who underwent randomization and received at least one dose of ZED1227 or placebo. All the other efficacy analyses involved patients who underwent randomization and received at least one dose of ZED1227 or placebo, without imputation of missing values at follow-up; modeling was performed with the use of complete cases only.\n\n【27】Trial Procedures and Assessments\n--------------------------------\n\n【28】Enrollment required a screening period of no more than 8 weeks, including upper gastrointestinal endoscopy with duodenal biopsies performed within 4 weeks before the administration of the first dose in order to provide baseline histologic data. At the week 0 visit, the trial drug (ZED1227 or placebo) and gluten biscuits were dispensed to patients according to assigned group. Patients returned to the trial sites at weeks 2, 4, and 6 for assessments and at week 10 for a follow-up visit. A second endoscopy with biopsies was performed at the week 6 or withdrawal visit. Both endoscopies were conducted by experienced gastroenterologists. Four forceps biopsy samples (one biopsy sample per pass) were obtained from the second and third parts of the duodenum, put in a PAXgene fixative, and sent to the central histopathology laboratory (Jilab, Tampere, Finland) for processing and reading. Validated, standardized morphometric procedures separately evaluated mucosal morphology and inflammation.  The categorical Marsh–Oberhuber classification  was used for the standard classification of the mucosal lesions .\n\n【29】Patients kept a diary (on paper or electronically) to record their daily use of the assigned trial drug as well as their gluten biscuit and food intake, concomitant medications, and stool frequency and characteristics. Scores on the Celiac Symptom Index and Celiac Disease Questionnaire were determined at all visits. At the end of the treatment period (week 6), investigators and patients independently rated the trial treatment as being “very good,” “good,” “satisfactory,” or “poor” with regard to both efficacy and the side-effect profile.\n\n【30】Adverse events were recorded and evaluated by the investigators. Blood samples were obtained to determine hematologic, coagulation, and serum markers.\n\n【31】Statistical Analysis\n--------------------\n\n【32】We estimated that a sample of 136 patients, or 34 patients per group, would provide the trial with 80% power for the primary analysis, assuming an alpha error of 0.05, an effect size of 0.6, and standard deviation of 0.8. On the basis of an estimated 15% of patients either withdrawing or having insufficient samples for evaluation, we planned for the enrollment of 160 patients (40 per group).\n\n【33】The primary end point, the mean change in the ratio of villus height to crypt depth from baseline to week 6, was analyzed with the use of a generalized linear model with the identity link, in which trial group and the baseline ratio of villus height to crypt depth were fixed effects, because assumptions for the parametric model were met. Each ZED1227 dose group was compared with the placebo group. The same statistical method was used for the analyses of the change from baseline to week 6 in the intraepithelial lymphocyte density, Celiac Symptom Index scores, and Celiac Disease Questionnaire scores, which were key secondary end points. The statistical analysis of other end points (the change of Marsh–Oberhuber classification, transglutaminase 2 IgA and IgA antiendomysial antibodies, and blood malabsorption markers) is described in the Supplementary Appendix . The analysis to assess sensitivity to missing data is described in the Supplementary Appendix .\n\n【34】Plasma concentrations of ZED1227 and metabolites were measured and analyzed for pharmacokinetic profiles. The results are not reported here.\n\n【35】All statistical comparisons between each ZED1227 dose and placebo were two-sided, with a familywise alpha error of 0.05. For the analysis of the primary end point, 95% confidence intervals and P values were adjusted for multiple comparisons with the use of Bonferroni correction to account for the three comparisons with placebo. An adjusted P value of 0.0167 was considered to indicate statistical significance for the primary end point, and individual confidence intervals were constructed with the use of 98.3% levels. For secondary end points, 95% confidence intervals are reported without P values; the 95% confidence intervals have not been adjusted for multiple comparisons and cannot be used to infer definitive treatment effects. One interim analysis was conducted for the primary efficacy variable .\n\n【36】Results\n-------\n\n【37】Characteristics of the Patients and Regimen Adherence\n-----------------------------------------------------\n\n【38】The trial was conducted from May 16, 2018, to February 27, 2020. Of the 163 patients who underwent randomization (with 41 patients assigned to the 10-mg ZED1227 group, 41 to the 50-mg group, 41 to the 100-mg group, and 40 to the placebo group), 3 did not receive ZED1227 or placebo because of the development of other clinical conditions, and 1 patient received ZED1227 but was lost to follow-up . Analyses of efficacy excluded these 4 patients and thus included 41 patients in the 10-mg group, 41 in the 50-mg group, 39 in the 100-mg group, and 38 in the placebo group.\n\n【39】Table 1. Demographic Characteristics of the Patients.\n\n【40】The demographic characteristics of these 159 patients were similar across the groups, except for a higher percentage of women in the 10-mg group . According to the investigators’ assessment and patients’ diaries, adherence was high and similar in all four groups, ranging from 96 to 100% both for the trial regimen and for gluten intake.\n\n【41】Efficacy Results\n----------------\n\n【42】Histology-related efficacy end points could be evaluated in 142 patients who had sufficient biopsy samples at both baseline and week 6; a total of 35 patients in the 10-mg group, 39 in the 50-mg group, 38 in the 100-mg group, and 30 in the placebo group were included in the analysis. Four of these patients stopped treatment before week 6 but qualified for inclusion in the primary end-point analysis with a treatment duration of 23 to 32 days.\n\n【43】Table 2. Effect of ZED1227 Treatment on the Ratio of Villus Height to Crypt Depth. Figure 1.  Figure 1. Paired Data Plots of the Mean Ratio of Villus Height to Crypt Depth (Primary End Point).\n\n【44】The primary end point was the attenuation of gluten-induced mucosal damage, as measured by the ratio of villus height to crypt depth. The prespecified population for this analysis included the 142 patients who had villus height and crypt depth measurements from at least three villus–crypt units in total from the duodenum biopsies available at both the screening (baseline) visit and the final or withdrawal visit. Horizontal bars indicate mean values in each group at each time point.\n\n【45】As expected, in the placebo group, the gluten challenge decreased the ratio of villus height to crypt depth from baseline to week 6 (estimated change, −0.61; 95% confidence interval \\[CI\\], −0.78 to −0.44). Treatment with daily doses of 50 mg and 100 mg of ZED1227 prevented this deterioration (estimated change, −0.12 \\[95% CI, −0.27 to 0.03\\] and −0.13 \\[95% CI, −0.28 to 0.03\\], respectively); efficacy in the 10-mg group was slightly less (estimated change, −0.17; 95% CI, −0.33 to −0.01). As compared with placebo, all three dose levels of ZED1227 significantly prevented a decrease in the ratio of villus height to crypt depth (P≤0.001 for all comparisons) . Results of the sensitivity analysis were similar to those of the primary end-point analysis .\n\n【46】Table 3. Effect of ZED1227 Treatment on Intraepithelial Lymphocyte Density and Scores on the Celiac Symptom Index and Celiac Disease Questionnaire.\n\n【47】Gluten ingestion caused an increase from baseline in intraepithelial lymphocyte density, a key variable of mucosal inflammation, in the placebo group, the 10-mg group, and the 50-mg group but not in the 100-mg group; the increase was attenuated by ZED1227 dose-dependently . According to the modified Marsh–Oberhuber classification, a histologic score in which class 2 describes deepened crypts and class 3a to 3c categorically describes increasing severity of villus atrophy and increasing crypt depth, the odds and risk ratios favored all three doses of ZED1227 over placebo .\n\n【48】The Celiac Symptom Index score increased from baseline to week 6 in all groups and returned to baseline at the follow-up visit. Comparison with placebo favored all dose levels of ZED1227. The Celiac Disease Questionnaire overall score increased from baseline to week 6 in all ZED1227 dose groups but decreased with placebo. The changes in the Celiac Disease Questionnaire gastrointestinal subscore from baseline to week 6 and comparison with placebo favored ZED1227. At the week 6 visit, 10% of the patients in the 10-mg group, 7% of those in the 50-mg group, 8% of those in the 100-mg group, and 26% of those in the placebo group assessed the efficacy as “poor.” Data are shown in Table 3 and S4 and Figure S5.\n\n【49】At screening (baseline), all the patients had normal levels of transglutaminase 2 IgA. At the week 6 assessment, 1 patient (2%) who received the 10-mg dose, 1 (2%) who received the 50-mg dose, and no patient who received the 100-mg dose, as compared with 6 patients (16%) who received placebo, had a conversion to a positive result. The titer of transglutaminase 2 IgA increased by a mean of 2.4 kU per liter in the placebo group, by 1.7 kU per liter in the 10-mg group, and by 0.3 kU per liter in the 50-mg group and decreased by 0.1 kU per liter in the 100-mg group. Similar results were obtained regarding IgA antiendomysial antibodies .\n\n【50】Safety\n------\n\n【51】Table 4. Common Adverse Events That Occurred in Three or More Patients in Any Group.\n\n【52】Adverse events occurred in 125 of the 160 patients (78%) who received at least one dose of ZED1227 or placebo . (In addition to the 159 patients in the efficacy analysis, 1 patient was added to the 100-mg group for the safety analysis because this patient received the trial drug but was lost to follow-up, so the administration of the medication was uncertain.) Most adverse events appeared to be related to the gluten challenge. A total of 74 patients (46%), including 14 of 41 patients (34%) in the 10-mg group, 19 of 41 (46%) in the 50-mg group, 20 of 40 (50%) in the 100-mg group, and 21 of 38 (55%) in the placebo group, had an adverse event that the investigators considered to be potentially related to ZED1227 or placebo. The most common adverse events across all groups were headache, nausea, diarrhea, vomiting, and abdominal pain. With the exception of rash, which occurred in 3 patients (8%) in the 100-mg group, no adverse events appeared to be more common in the ZED1227 groups than in the placebo group. Serious adverse events that were considered by the investigators to be related to ZED1227 or placebo occurred in 2 patients (migraine with aura in 1 patient receiving 50 mg of ZED1227 and ventricular extrasystoles in 1 patient receiving placebo). These 2 patients discontinued ZED1227 or placebo and recovered.\n\n【53】A broad range of variables were measured in blood, including cell counts, liver and kidney functions, surrogates of resorption (albumin, transferrin saturation, zinc, vitamin B <sub>12 </sub> , and folic acid), and factor XIII, another common transglutaminase. Results were similar across all the trial groups. During the gluten challenge, the levels of alanine aminotransferase and alkaline phosphatase increased from baseline to week 6 in the placebo group and then normalized at week 10. Such changes were not observed in any of the ZED1227 groups .\n\n【54】Discussion\n----------\n\n【55】In this preliminary, randomized, double-blind, placebo-controlled, 6-week trial, the effectiveness of transglutaminase 2 inhibition with the oral transglutaminase 2 inhibitor ZED1227 was shown in patients with celiac disease who were challenged with a moderate amount (3 g) of daily gluten intake. ZED1227 was developed to specifically block transglutaminase 2–mediated potentiation of gluten-peptide immunogenicity in the small intestinal mucosa, a key driver of celiac disease pathogenesis.  As compared with placebo, all doses of ZED1227 attenuated the gluten-induced small intestinal damage.\n\n【56】This trial showed that treatment with the highly specific transglutaminase 2 inhibitor ZED1227 attenuated the gluten-induced damage in the duodenal mucosa. The ratio of villus height to crypt depth is widely considered to be the most objective and valid primary end point in clinical studies for therapies for celiac disease,  and the end point was achieved at all three dose levels of ZED1227. The benefits across multiple end points were most pronounced for the 50-mg and 100-mg doses. Improved patient-reported outcomes across the dose groups need to be confirmed in a larger study, since they may reflect the rather small size of each group for the evaluation of symptoms or the scales capturing some symptoms that may overlap with, but are unrelated to, celiac disease. Overall, the incidence and severity of adverse events were similar in the ZED1227 groups and the placebo group.\n\n【57】Since the discovery of transglutaminase 2 as the autoantigen in celiac disease,  extensive research has confirmed it to be a crucial mechanistic driver of gluten-induced inflammation and clinical manifestations in patients with celiac disease.  This trial supports the role of transglutaminase 2 in the pathogenesis of celiac disease, given that its inhibition prevents the deamidation of gluten peptides in the small intestinal mucosa and thus abolishes the immunogenic process. ZED1227 targets the intestinal mucosa predominantly and thereby mediates protection; thus, it is unaffected by the complexity of the food matrix and is less dependent on the timing of ingestion of gluten-containing food.\n\n【58】The Food and Drug Administration recently reinforced its recommendation that, in pharmacologic trials of celiac disease, the prevention of histologic damage should be a major end point in phase 2 clinical studies, and the improvement of celiac disease–related patient-reported outcomes and quality of life should both be primary end points in phase 3 trials.  This recommendation is justified, since only 40% of adult patients with newly diagnosed celiac disease have gastrointestinal symptoms, whereas a gluten challenge induces a manifest duodenal mucosal lesion, often before any symptoms occur.  Furthermore, mucosal healing is considered to be the key criterion of successful treatment and a prerequisite for patients’ long-term well-being and the prevention of severe complications.  Therefore, we selected the gluten challenge and used validated quantitative histopathological testing as the primary end point in our proof-of-concept trial. \n\n【59】Celiac disease is highly prevalent in White, Middle Eastern, and Indian populations and is prevalent among Native Americans and Northeast Asians. The prevalence is low among Black Africans and Southeast Asians, but the prevalence in these populations can be high if European ancestry is also involved. Therefore, the patients in our trial represented the ancestral cross-section of the European countries participating in the trial; there was no intention to include or exclude certain racial or ethnic groups from the trial.\n\n【60】Strengths of this trial were the high levels of patient adherence to the regimen and to the gluten challenge, which maximized the data that could be evaluated. Limitations include a substantial amount of missing data and the loss of several patients to follow-up, the short duration of the trial, and the controlled gluten ingestion. Future studies of ZED1227 in more patients are needed to provide additional evidence of the safety and efficacy of the drug, potentially in real-life conditions with minor gluten ingestion.\n\n【61】In this phase 2 trial, we found that the oral transglutaminase 2 inhibitor ZED1227 effectively attenuated intestinal mucosal injury in patients with celiac disease challenged with a moderate dose of daily gluten.", "index": 333, "show": true, "start": 333, "end": 376, "province": ["文本干净度", "无关文本"], "isEdit": false}]}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-14 00:23:51", "grab_time": "2024-08-13 23:47:39"}
{"id": 2234514, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "3924a2f2-290c-488b-b6e1-140ea7f251c7", "title": "Brief Report: Donor-Derived Long-Term Multilineage Hematopoiesis in a Liver-Transplant Recipient", "text": "【0】Brief Report: Donor-Derived Long-Term Multilineage Hematopoiesis in a Liver-Transplant Recipient\nIntroduction\n------------\n\n【1】Graft-versus-host disease (GVHD) has been well documented in several recipients of liver transplants  . In this syndrome alloreactive cells from the donor attack the recipient's skin, gastrointestinal tissue, and hematopoietic tissue. Severe myelosuppression commonly results, but there has been a degree of recovery of hematopoiesis in some patients after immunosuppressive therapy. The recovery of hematopoiesis resulted from the recovery of the recipient's bone marrow in some cases,  but it also could be due to the proliferation of hematopoietic precursor cells in the donor's liver, since the liver is a site of hematopoiesis in fetuses and, under certain circumstances, in adults. We investigated this possibility in a liver-transplant recipient in whom hematopoiesis recovered after treatment of GVHD. We found that the hematopoiesis in our patient derived from stem cells present in the donor's liver.\n\n【2】Case Report\n-----------\n\n【3】A 65-year-old woman with cryptogenic cirrhosis received an orthotopic liver transplant from a 17-year-old boy. The recipient had no history, physical findings, or laboratory evidence suggestive of immunodeficiency. Immunosuppression after transplantation consisted of cyclosporine, prednisolone, and azathioprine. All blood products for transfusions were irradiated (2500 cGy). Twelve days after transplantation, the white-cell count decreased to 3200 per cubic millimeter and continued to decline thereafter. By day 23 after transplantation, the white-cell count was 1000 per cubic millimeter, and treatment with granulocyte colony-stimulating factor was begun. By day 32, however, the white-cell count had decreased to 300 per cubic millimeter, and the patient had become dependent on platelet and red-cell transfusions. The cellularity of the bone marrow was 5 percent. HLA typing of peripheral-blood mononuclear cells demonstrated only the phenotype of the donor. A presumptive diagnosis of GVHD was made, although the only other manifestation of GVHD was a faint macular rash over the upper part of the trunk. Treatment of GVHD was begun on day 32 and consisted of methylprednisolone (at an initial dose of 5 mg per kilogram of body weight per day, with a rapid tapering of the dose to 1 mg per kilogram per day) and Minnesota antilymphocyte globulin (10 mg per kilogram per day). The patient responded rapidly to treatment. On day 43 the white-cell count was 9100 per cubic millimeter, with 89 percent neutrophils; treatment with antilymphocyte globulin and granulocyte colony-stimulating factor was discontinued. For four weeks the patient did not need platelet transfusions. The white-cell count ranged from 2000 to 10,000 per cubic millimeter for the remainder of the patient's course. About 90 days after the transplantation, her clinical status began to decline. By day 128 bloody diarrhea and a faint macular rash over the upper part of the trunk had developed, suggesting a flare of GVHD. The dose of methylprednisolone was increased to 3 mg per kilogram per day. Although the diarrhea and rash improved, the patient's overall clinical status continued to deteriorate, and she died on day 135.\n\n【4】Postmortem examination showed pulmonary infection with cytomegalovirus, enterovirus, Torulopsis glabrata, and Enterobacter cloacae. Histologic examination of the small and large bowels suggested GVHD, with loss of the normal villous architecture and infiltration of the lamina propria by reactive lymphocytes and plasma cells. There was no histologic evidence of liver rejection. The cellularity of the bone marrow was 50 percent, with trilineage maturation. There was no evidence of extramedullary hematopoiesis.\n\n【5】Methods\n-------\n\n【6】HLA Typing and Analysis of Restriction-Fragment-Length Polymorphisms\n--------------------------------------------------------------------\n\n【7】Mononuclear cells were obtained from the donor's lymph nodes, the recipient's peripheral blood at various times, and the recipient's spleen, liver, and lymph nodes post mortem. Typing of HLA class I and II antigens was performed by a standard microcytotoxic assay with a two-color fluorescent technique. High-molecular-weight DNA was prepared from samples of peripheral blood and bone marrow. Analysis of restriction-fragment-length polymorphisms (RFLPs) was then carried out as previously described,  with five highly polymorphic probes (Collaborative Diagnostics, Waltham, Mass.).\n\n【8】Analysis of Hematopoietic Progenitor Cells by Flow Cytometry and Cell Culture\n-----------------------------------------------------------------------------\n\n【9】Bone marrow cells were isolated and analyzed by flow cytometry as previously described  . Uncommitted stem cells and early committed progenitor cells were stained with anti-CD34 antibodies labeled with fluoroscein isothiocyanate, anti-CD38 antibodies labeled with phycoerythrin, and either anti-HLA-DR antibodies labeled with peridinin chlorophyll protein or anti-HLA-DR antibodies labeled with biotin followed by incubation with streptavidin allophycocyanin, before analysis and cell sorting (FACScan and FACStar <sup>Plus </sup> , Becton Dickinson Immunocytometry Systems, San Jose, Calif.). Myeloid, erythroid, and lymphoid progenitor cells were labeled with lineage-defining panels of immunofluorescent antibodies. The degree of forward and orthogonal light scattering and the presence of three fluorescence signals were determined for each cell. In addition, the cells were sorted directly onto a slide for sex-chromosome analysis or were sorted singly into 96-well flat-bottomed plates for culture to detect primitive hematopoietic blasts, as described previously  . Each well contained a mixture of alpha medium (Terry Fox Laboratory, Vancouver, B.C., Canada), β-fibroblast growth factor, insulin-like growth factor I, and several hematopoietic growth factors. The cultures were incubated in 5 percent carbon dioxide in air at 37 °C in a humidified incubator. The plates were examined on days 7 through 14 for the appearance of colonies.\n\n【10】Sex-Chromosome Analysis with Fluorescence in Situ Hybridization\n---------------------------------------------------------------\n\n【11】Fluorescence in situ hybridization was performed as previously described  on smears of bone marrow, directly sorted progenitor cells, and differentiated progeny derived from sorted single progenitor cells in the culture system described above. The bone marrow smears were stained with Wright's stain, and the cells were photographed; their location on the slides was noted with a graduated microscope stage. After the slides were denatured in formamide, probes for sex chromosomes were denatured separately, applied to the slides under coverslips, and allowed to anneal overnight. The probes used for hybridization included a probe labeled with Spectrum Orange dye that reacted with the centromere repeat sequences on the X chromosome (Imagenetics, Naperville, Ill.) and a biotinylated probe that detected the centromere of the Y chromosome (Oncor, Gaithersburg, Md.). The samples were washed, and fluorescein-labeled avidin (Vector, Burlingame, Calif.) was used to detect the biotinylated Y-chromosome probe. The previously photographed cells were relocated and were considered to be male if X and Y signals were identified and to be female if two X signals but no Y signal was seen. In addition to scoring photographed cells, we scored 200 to 400 other cells at random. Peripheral blood from normal women and men was used as a control. Additional hybridizations with the same probes were performed on frozen sections of spleen, lymph node, and lung obtained at autopsy and fixed with methanol-acetic acid.\n\n【12】Fluorescence in situ hybridization of sorted progenitor cells and cultured cells was carried out as described above, but different probes were used (provided by Kathy Yokobata, Becton Dickinson): a fluorescein isothiocyanate-labeled probe specific for the Y chromosome and a digoxigenin-labeled probe specific for the X chromosome. Anti-digoxigenin antibody conjugated to rhodamine was used to detect the X probe.\n\n【13】Results\n-------\n\n【14】HLA Typing and RFLP Analysis\n----------------------------\n\n【15】The donor's HLA type was A2,24;B44,60;Bw4,w6;-Cw4,-;DR4,w8;DQw3,-;DRw52,53. The recipient's HLA type was A2,3;B7,44;Bw4,w6;DRw13,w14; DQw1,w6;DRw52 before transplantation. After transplantation, on days 32, 46, 53, 74, 81, 88, 95, 102, 109, and 129, HLA typing demonstrated only the donor's HLA type. Mononuclear cells obtained post mortem from abdominal and thoracic lymph nodes, liver, and spleen showed only the donor's HLA type.\n\n【16】On day 39, RFLP analysis of peripheral-blood cells showed that 90 to 95 percent of DNA was derived from the donor and only 5 to 10 percent was derived from the recipient. RFLP analysis of peripheral-blood cells and bone marrow cells on day 59 showed that approximately 75 percent of the DNA was derived from the donor, and 25 percent derived from the recipient. Subsequent RFLP analyses of peripheral-blood cells (on days 85 and 113) and bone marrow cells (on day 120) showed that at least 95 percent of the DNA was derived from the donor.\n\n【17】Sex-Chromosome Analysis of Differentiated Cells\n-----------------------------------------------\n\n【18】Figure 1. Sex-Chromosome Analysis of Bone Marrow Cells from a Woman Who Received a Liver Transplant from a Teenage Boy.\n\n【19】The cells were studied by fluorescence in situ hybridization with DNA probes specific for the X and Y chromosomes. The directly labeled X-chromosome probe emits a red fluorescent signal (Spectrum Orange dye); after detection with fluorescein-labeled avidin, the biotinylated Y-chromosome probe emits a green signal. In Panel A, bone marrow obtained on day 59 and stained with Wright's stain shows three monocytic precursors and a single erythroid precursor. In Panel B, fluorescence in situ hybridization of the four cells reveals that the monocytic precursors are male (red and green signals, XY genotype) and the erythroid precursor (arrow) is female (red signals, XX genotype). In Panel C, bone marrow obtained on day 101 and stained with Wright's stain shows four granulocytes. In Panel D, fluorescence in situ hybridization of the granulocytes shows that all four cells are male. At the time of this later study, nearly all the bone marrow elements (including erythroid, granulocytic, monocytic, lymphoid, and megakaryocytic cells) were male\\.\n\n【20】Study of the control specimens indicated that fluorescence in situ hybridization could detect male and female cells with a high degree of accuracy; no signals for the Y chromosome were seen in any of the cells in the specimens from normal women, and both red and green signals, indicating an XY genotype, were seen in 96 percent of the cells from normal men. On the first analysis of the patient's bone marrow (results pooled from days 59 and 66), 74 percent of the cells were male . The percentage of male cells differed among the various types of cells. Monocytes and macrophages, which were increased in number and present in small clusters, were over 90 percent male. Seventy-five percent of the lymphocytes and 66 percent of the granulocytes were male. Fifty-six percent of the nucleated red cells were male, and these types of cells were present in small groups of all-male or all-female cells. There were decreased numbers of megakaryocytes, but all 12 megakaryocytes studied were female. The second (day 101) and third (day 129) analyses showed that nearly all the bone marrow cells (>98 percent) were male . Megakaryocytes were rare in these specimens; however, the two studied were male.\n\n【21】In frozen-tissue sections obtained post mortem and fixed with methanol-acetic acid, virtually all the cells in the sections of the spleen and lymph node were male. Sections from the lung contained both male and female cells, although it was not possible to correlate these results with histologic findings.\n\n【22】Analysis of Hematopoietic Progenitor Cells\n------------------------------------------\n\n【23】Figure 2. Flow-Cytometric Analysis of Stem Cells and Progenitor Cells in the Recipient's Bone Marrow Obtained on Day 121.\n\n【24】The bone marrow cells were stained with fluorescein-labeled anti-CD34, phycoerythrin-labeled anti-CD38, and biotin-labeled anti-HLA-DR antibodies, followed by incubation with streptavidin allophycocyanin. The degree of forward and orthogonal light scatter and the presence of three fluorescence signals were determined simultaneously for each cell and are expressed in arbitrary units. Only the results for CD34+ cells are shown. CD34+ cells with the size and low granularity of blast cells are shown in Panel A. The expression of CD38 by CD34+ cells is shown in Panel B, and the expression of CD38 and HLA-DR by CD34+ cells is shown in Panel C. In Panel A, Panel B, and Panel C, the pluripotent CD34+, CD38-, HLA-DR-/+ stem cells are black, and the lineage-committed CD34+, CD38+, HLA-DR+ progenitor cells are gray. The two cell populations were sorted and analyzed for the presence of XX or XY chromosomes by fluorescence in situ hybridization .\n\n【25】Flow-cytometric analysis of bone marrow obtained on day 121 revealed only a few CD34+ progenitor cells (<1 percent). Among the CD34+ progenitor cells were uncommitted stem cells (CD34+, CD38-, HLA-DR-/+) and committed progenitor cells (CD34+, CD38+, HLA-DR+) . The maturation of neutrophils, monocytes, and erythrocytes, as assessed by flow cytometry, was normal. The frequency of B lymphocytes and B-cell progenitors was low. Sex-chromosome analysis  of sorted bone marrow cells showed that among the uncommitted stem cells (CD34+, CD38-, HLA-DR-/+) there were XX as well as XY cells. Among the committed cells (CD34+, CD38+, HLA-DR+), early myeloid cells (CD33+, CD15±), late myeloid cells (CD33+, CD15+), erythroid cells (CD71+, CD45-), and T cells (CD3+, CD19-), the majority had X and Y chromosomes. In the culture assay, the clonal plating efficiency of single sorted cells was 88 percent among uncommitted stem cells (CD34+, CD38-, HLA-DR-/+) and 25 percent among committed progenitor cells (CD34+, CD38+, HLA-DR+). Colonies from the CD34+, CD38-, HLA-DR-/+ fraction were probed for the presence of cells containing XX or XY chromosomes. Fifty percent of the colonies were female, and 50 percent were male.\n\n【26】Discussion\n----------\n\n【27】We found that stem cells with pluripotent function were present in the transplanted liver. These cells may have been normal residents of the liver, since hematopoiesis occurs in the fetal liver  and in the adult liver under certain circumstances,  and since hematopoietic stem cells have been detected in the liver of normal adult mice  . Since these cells circulate,  however, they may have been derived from peripheral blood in the liver at the time of transplantation; although donor livers are extensively perfused before transplantation, small amounts of blood probably remain in the organ and associated lymphoid tissue.\n\n【28】Donor cells migrated to the bone marrow, spleen, lymph nodes, and lungs. Donor cells with the phenotype of hematopoietic stem cells (CD34+, CD38-, HLA-DR-/+)  were identified in the bone marrow. These cells gave rise to mature donor cells of several hematopoietic lineages, and multilineage donor-derived hematopoiesis persisted for more than four months after transplantation. The donor uncommitted stem cells may have had lymphopoietic potential, since they had the phenotype of cells shown in other studies  to have full lymphohematopoietic potential (CD34+, CD38-, HLA-DR-/+). It is possible, however, that the male lymphocytes detected in the recipient were long-lived mature cells that had migrated from the transplanted liver. Stem cells from the recipient also were detected. Although their contribution to hematopoiesis was substantial soon after recovery from GVHD, it was very limited later in the course. In summary, sufficient numbers of hematopoietic stem cells were present in the donor liver to give rise to long-term multilineage hematopoiesis in a patient whose lymphohematopoietic system had been severely suppressed by GVHD and immunosuppressive medications.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 16:36:12", "endTime": "2024/08/13 16:36:32", "cost": 20.059}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 00:36:32", "grab_time": "2024-08-13 00:36:12"}
{"id": 2234513, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "f6810497-cb32-421f-8ccf-386eb1767be7", "title": "Accidental Nuclear War — A Post–Cold War Assessment", "text": "【0】Accidental Nuclear War — A Post–Cold War Assessment\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】In the 1980s, many medical organizations identified the prevention of nuclear war as one of the medical profession's most important goals. An assessment of the current danger is warranted given the radically changed context of the post–Cold War era.\n\n【3】Methods\n-------\n\n【4】We reviewed the recent literature on the status of nuclear arsenals and the risk of nuclear war. We then estimated the likely medical effects of a scenario identified by leading experts as posing a serious danger: an accidental launch of nuclear weapons. We assessed possible measures to reduce the risk of such an event.\n\n【5】Results\n-------\n\n【6】U.S. and Russian nuclear-weapons systems remain on high alert. This fact, combined with the aging of Russian technical systems, has recently increased the risk of an accidental nuclear attack. As a conservative estimate, an accidental intermediate-sized launch of weapons from a single Russian submarine would result in the deaths of 6,838,000 persons from firestorms in eight U.S. cities. Millions of other people would probably be exposed to potentially lethal radiation from fallout. An agreement to remove all nuclear missiles from high-level alert status and eliminate the capability of a rapid launch would put an end to this threat.\n\n【7】Conclusions\n-----------\n\n【8】The risk of an accidental nuclear attack has increased in recent years, threatening a public health disaster of unprecedented scale. Physicians and medical organizations should work actively to help build support for the policy changes that would prevent such a disaster.\n\n【9】Introduction\n------------\n\n【10】During the Cold War, physicians and others described the potential medical consequences of thermonuclear war and concluded that health care personnel and facilities would be unable to provide effective care to the vast number of victims of a nuclear attack.  In 1987, a report by the World Health Organization concluded, “The only approach to the treatment of health effects of nuclear warfare is primary prevention, that is, the prevention of nuclear war.”  Many physicians and medical organizations have argued that the prevention of nuclear war should be one of the medical profession's most important goals. \n\n【11】Continued Danger of a Nuclear Attack\n------------------------------------\n\n【12】Although many people believe that the threat of a nuclear attack largely disappeared with the end of the Cold War, there is considerable evidence to the contrary.  The United States and Russia no longer confront the daily danger of a deliberate, massive nuclear attack, but both nations continue to operate nuclear forces as though this danger still existed. Each side routinely maintains thousands of nuclear warheads on high alert. Furthermore, to compensate for its weakened conventional armed forces, Russia has abandoned its “no first use” policy. \n\n【13】Even though both countries declared in 1994 that they would not aim strategic missiles at each other, not even one second has been added to the time required to launch a nuclear attack: providing actual targeting (or retargeting) instructions is simply a component of normal launch procedures.  The default targets of U.S. land-based missiles are now the oceans, but Russian missiles launched without specific targeting commands automatically revert to previously programmed military targets. \n\n【14】There have been numerous “broken arrows” (major nuclear-weapons accidents) in the past, including at least five instances of U.S. missiles that are capable of carrying nuclear devices flying over or crashing in or near the territories of other nations.  From 1975 to 1990, 66,000 military personnel involved in the operational aspects of U.S. nuclear forces were removed from their positions. Of these 66,000, 41 percent were removed because of alcohol or other drug abuse and 20 percent because of psychiatric problems.  General George Lee Butler, who as commander of the U.S. Strategic Command from 1991 to 1994 was responsible for all U.S. strategic nuclear forces, recently reported that he had “investigated a dismaying array of accidents and incidents involving strategic weapons and forces.” \n\n【15】Any nuclear arsenal is susceptible to accidental, inadvertent, or unauthorized use.  This is true both in countries declared to possess nuclear weapons (the United States, Russia, France, the United Kingdom, and China) and in other countries widely believed to possess nuclear weapons (Israel, India, and Pakistan). The combination of the massive size of the Russian nuclear arsenal (almost 6000 strategic warheads) and growing problems in Russian control systems makes Russia the focus of greatest current concern.\n\n【16】Since the end of the Cold War, Russia's nuclear command system has steadily deteriorated. Aging nuclear communications and computer networks are malfunctioning more frequently, and deficient early-warning satellites and ground radar are more prone to reporting false alarms.  The saga of the Mir space station bears witness to the problems of aging Russian technical systems. In addition, budget cuts have reduced the training of nuclear commanders and thus their proficiency in operating nuclear weapons safely. Elite nuclear units suffer pay arrears and housing and food shortages, which contribute to low morale and disaffection. New offices have recently been established at Strategic Rocket Forces bases to address the problem of suicide  (and unpublished data).\n\n【17】Safeguards against a nuclear attack will be further degraded if the Russian government implements its current plan to distribute both the unlock codes and conditional launch authority down the chain of command. Indeed, a recent report by the Central Intelligence Agency, which was leaked to the press, warned that some Russian submarine crews may already be capable of authorizing a launch.  As then Russian Defense Minister Igor Rodionov warned last year, “No one today can guarantee the reliability of our control systems\\. Russia might soon reach the threshold beyond which its rockets and nuclear systems cannot be controlled.” \n\n【18】A particular danger stems from the reliance by both Russia and the United States on the strategy of “launch on warning” — the launching of strategic missiles after a missile attack by the enemy has been detected but before the missiles actually arrive. Each country's procedures allow a total response time of only 15 minutes: a few minutes for detecting an enemy attack, another several minutes for top-level decision making, and a couple of minutes to disseminate the authorization to launch a response. \n\n【19】Possible scenarios of an accidental or otherwise unauthorized nuclear attack range from the launch of a single missile due to a technical malfunction to the launch of a massive salvo due to a false warning. A strictly mechanical or electrical event as the cause of an accidental launch, such as a stray spark during missile maintenance, ranks low on the scale of plausibility.  Analysts also worry about whether computer defects in the year 2000 may compromise the control of strategic missiles in Russia, but the extent of this danger is not known.\n\n【20】Several authorities consider a launch based on a false warning to be the most plausible scenario of an accidental attack.  This danger is not merely theoretical. Serious false alarms occurred in the U.S. system in 1979 and 1980, when human error and computer-chip failures resulted in indications of a massive Soviet missile strike.  On January 25, 1995, a warning related to a U.S. scientific rocket launched from Norway led to the activation, for the first time in the nuclear era, of the “nuclear suitcases” carried by the top Russian leaders and initiated an emergency nuclear-decision-making conference involving the leaders and their top nuclear advisors. It took about eight minutes to conclude that the launch was not part of a surprise nuclear strike by Western submarines — less than four minutes before the deadline for ordering a nuclear response under standard Russian launch-on-warning protocols. \n\n【21】A missile launch activated by false warning is thus possible in both U.S. and Russian arsenals. For the reasons noted above, an accidental Russian launch is currently considered the greater risk. Several specific scenarios have been considered by the Ballistic Missile Defense Organization of the Department of Defense.  We have chosen to analyze a scenario that falls in the middle range of the danger posed by an accidental attack: the launch against the United States of the weapons on board a single Russian Delta-IV ballistic-missile submarine, for two reasons. First, the safeguards against the unauthorized launch of Russian submarine-based missiles are weaker than those against either silo-based or mobile land-based rockets, because the Russian general staff cannot continuously monitor the status of the crew and missiles or use electronic links to override unauthorized launches by the crews. Second, the Delta-IV is and will remain the mainstay of the Russian strategic submarine fleet. \n\n【22】Delta-IV submarines carry 16 missiles. Each missile is armed with four 100-kt warheads and has a range of 8300 km, which is sufficient to reach almost any part of the continental United States from typical launch stations in the Barents Sea.  These missiles are believed to be aimed at “soft” targets, usually in or near American cities, whereas the more accurate silo-based missiles would attack U.S. military installations.  Although a number of targeting strategies are possible for any particular Delta-IV, it is plausible that two of its missiles are assigned to attack war-supporting targets in each of eight U.S. urban areas. If 4 of the 16 missiles failed to reach their destinations because of malfunctions before or after the launch, then 12 missiles carrying a total of 48 warheads would reach their targets.\n\n【23】Potential Consequences of a Nuclear Accident\n--------------------------------------------\n\n【24】We assume that eight U.S. urban areas are hit: four with four warheads and four with eight warheads. We also assume that the targets have been selected according to standard military priorities: industrial, financial, and transportation sites and other components of the infrastructure that are essential for supporting or recovering from war. Since low-altitude bursts are required to ensure the destruction of structures such as docks, concrete runways, steel-reinforced buildings, and underground facilities, most if not all detonations will cause substantial early fallout.\n\n【25】Physical Effects\n----------------\n\n【26】Under our model, the numbers of immediate deaths are determined primarily by the area of the “superfires” that would result from a thermonuclear explosion over a city. Fires would ignite across the exposed area to roughly 10 or more calories of radiant heat per square centimeter, coalescing into a giant firestorm with hurricane-force winds and average air temperatures above the boiling point of water. Within this area, the combined effects of superheated wind, toxic smoke, and combustion gases would result in a death rate approaching 100 percent. \n\n【27】For each 100-kt warhead, the radius of the circle of nearly 100 percent short-term lethality would be 4.3 km (2.7 miles), the range within which 10 cal per square centimeter is delivered to the earth's surface from the hot fireball under weather conditions in which the visibility is 8 km (5 miles), which is low for almost all weather conditions. We used Census CD to calculate the residential population within these areas according to 1990 U.S. Census data, adjusting for areas where circles from different warheads overlapped.  In many urban areas, the daytime population, and therefore the casualties, would be much higher.\n\n【28】Fallout\n-------\n\n【29】The cloud of radioactive dust produced by low-altitude bursts would be deposited as fallout downwind of the target area. The exact areas of fallout would not be predictable, because they would depend on wind direction and speed, but there would be large zones of potentially lethal radiation exposure. With average wind speeds of 24 to 48 km per hour (15 to 30 miles per hour), a 100-kt low-altitude detonation would result in a radiation zone 30 to 60 km (20 to 40 miles) long and 3 to 5 km (2 to 3 miles) wide in which exposed and unprotected persons would receive a lethal total dose of 600 rad within six hours.  With radioactive contamination of food and water supplies, the breakdown of refrigeration and sanitation systems, radiation-induced immune suppression, and crowding in relief facilities, epidemics of infectious diseases would be likely. \n\n【30】Deaths\n------\n\n【31】Table 1. Predicted Immediate Deaths from Firestorms after Nuclear Detonations in Eight U.S. Cities.\n\n【32】Table 1 shows the estimates of early deaths for each cluster of targets in or near the eight major urban areas, with a total of 6,838,000 initial deaths. Given the many indeterminate variables (e.g., the altitude of each warhead's detonation, the direction of the wind, the population density in the fallout zone, the effectiveness of evacuation procedures, and the availability of shelter and relief supplies), a reliable estimate of the total number of subsequent deaths from fallout and other sequelae of the attack is not possible. With 48 explosions probably resulting in thousands of square miles of lethal fallout around urban areas where there are thousands of persons per square mile, it is plausible that these secondary deaths would outnumber the immediate deaths caused by the firestorms.\n\n【33】Medical Care in the Aftermath\n-----------------------------\n\n【34】Earlier assessments have documented in detail the problems of caring for the injured survivors of a nuclear attack: the need for care would completely overwhelm the available health care resources.  Most of the major medical centers in each urban area lie within the zone of total destruction. The number of patients with severe burns and other critical injuries would far exceed the available resources of all critical care facilities nationwide, including the country's 1708 beds in burn-care units (most of which are already occupied).  The danger of intense radiation exposure would make it very difficult for emergency personnel even to enter the affected areas. The nearly complete destruction of local and regional transportation, communications, and energy networks would make it almost impossible to transport the severely injured to medical facilities outside the affected area. After the 1995 earthquake in Kobe, Japan, which resulted in a much lower number of casualties (6500 people died and 34,900 were injured) and which had few of the complicating factors that would accompany a nuclear attack, there were long delays before outside medical assistance arrived. \n\n【35】From Danger to Prevention\n-------------------------\n\n【36】Public health professionals now recognize that many, if not most, injuries and deaths from violence and accidents result from a predictable series of events that are, at least in principle, preventable.  The direct toll that would result from an accidental nuclear attack of the type described above would dwarf all prior accidents in history. Furthermore, such an attack, even if accidental, might prompt a retaliatory response resulting in an all-out nuclear exchange. The World Health Organization has estimated that this would result in billions of direct and indirect casualties worldwide. \n\n【37】Limitations of Ballistic-Missile Defense\n----------------------------------------\n\n【38】There are two broad categories of efforts to avert the massive devastation that would follow the accidental launch of nuclear weapons: interception of the launched missile in a way that prevents detonation over a populated area and prevention of the launch itself. Intercepting a launched ballistic missile might appear to be an attractive option, since it could be implemented unilaterally by a country. To this end, construction of a U.S. ballistic-missile defense system has been suggested. Unfortunately, the technology for ballistic-missile defense is unproved, and even its most optimistic advocates predict that it cannot be fully protective. Furthermore, the estimated costs would range from $4 billion to $13 billion for a single-site system to $31 billion to $60 billion for a multiple-site system.  In either case, the system would not be operational for many years. \n\n【39】A Bilateral Agreement to Eliminate High-Level Alert Status\n----------------------------------------------------------\n\n【40】Since ballistic-missile defense offers no solution at all in the short term and at best an expensive and incomplete solution in the long term, what can the United States as well as other nations do to reduce the risk of an accidental nuclear attack substantially and quickly? The United States should make it the most urgent national public health priority to seek a permanent, verified agreement with Russia to take all nuclear missiles off high alert and remove the capability of a rapid launch.  This approach is much less expensive and more reliable than ballistic-missile defense and can be implemented in short order. In various forms, such an agreement has been urged by the National Academy of Sciences,  the Canberra Commission,  General Butler and his military colleagues throughout the world,  and other experts, such as Sam Nunn, former chairman of the U.S. Senate Armed Services Committee, and Stansfield Turner, former director of the Central Intelligence Agency.  The Joint Chiefs of Staff and an interagency working group are completing a detailed study of de-alerting options that will be presented to Defense Secretary William Cohen. \n\n【41】Major improvements in nuclear stability can be achieved rapidly. In the wake of the 1991 attempted coup in Moscow, Presidents George Bush and Mikhail Gorbachev moved quickly to enhance nuclear safety and stability by taking thousands of strategic weapons off high alert almost overnight.  Today, there are specific steps that the United States can take almost immediately, since they require only the authority of a presidential directive. These steps include putting in storage the warheads of the MX missiles, which will be retired under Strategic Arms Reduction Treaty (START) II in any case, and the warheads of the four Trident submarines that will be retired under START III; placing the remaining U.S. ballistic-missile submarines on low alert so that it would take at least 24 hours to prepare them to launch their missiles; disabling all Minuteman III missiles by pinning their safety switches open (as was done with the Minuteman II missiles under President Bush's 1991 directive); and allowing Russia to verify these actions with the on-site inspections allowed under START I. Similar measures should be taken by the Russians.  These steps — all readily reversible if warranted by future developments or if a permanent bilateral agreement is not reached — would eliminate today's dangerous launch-on-warning systems, making the U.S. and Russian populations immediately safer. Both nations should then energetically promote a universal norm against maintaining nuclear weapons on high alert.\n\n【42】The Role of Physicians\n----------------------\n\n【43】In awarding the 1985 Nobel Peace Prize to International Physicians for the Prevention of Nuclear War, the Nobel Committee underscored the “considerable service to mankind” that physicians have performed by “spreading authoritative information and by creating an awareness of the catastrophic consequences of atomic warfare. This in turn contributes to an increase in the pressure of public opposition to the proliferation of nuclear weapons and to a redefining of priorities\\.”  No group is as well situated as physicians to help policy makers and the public fully appreciate the magnitude of the disaster that can ensue if changes in the alert status of all nuclear weapons are not instituted. \n\n【44】The only way to make certain that an accidental (or any other) nuclear attack never occurs is through the elimination of all nuclear weapons and the airtight international control of all fissile materials that can be used in nuclear weapons. In 1995, the World Court stated that the abolition of nuclear weapons is a binding legal obligation of the United States, Russia, and all signatories to the Nuclear Nonproliferation Treaty, under Article 6.  Preferring the term “prohibition” to “abolition,” the Committee on International Security and Arms Control of the U.S. National Academy of Sciences concluded in its 1997 report, “The potential benefits of comprehensive nuclear disarmament are so attractive relative to the attendant risks — and the opportunities presented by the end of the Cold War \\. are so compelling — that \\. increased attention is now warranted to studying and fostering the conditions that would have to be met to make prohibition desirable and feasible.” \n\n【45】Leading U.S. medical organizations, including the American College of Physicians and the American Public Health Association, have already joined Physicians for Social Responsibility, International Physicians for the Prevention of Nuclear War, and over 1000 other nongovernmental organizations in 75 nations to support Abolition 2000, which calls for a signed agreement by the year 2000 committing all countries to the permanent elimination of nuclear weapons within a specified time frame.  The American Medical Association has recently endorsed the abolition of nuclear weapons,  as have the Canberra Commission,  military leaders throughout the world,  major religious organizations,  and over 100 current and recent heads of state and other senior political leaders.  Some supporters of the abolition of nuclear weapons have specifically called for immediate steps to eliminate the high-level alert status of such weapons, as urgent interim measures. All parties should cooperate to ensure that these measures are implemented rapidly.\n\n【46】Conclusions\n-----------\n\n【47】The time, place, and circumstances of a specific accident are no more predictable for nuclear weapons than for other accidents. Nonetheless, as long as there is a finite, nonzero, annual probability that an accidental launch will occur, then given sufficient time, the probability of such a launch approaches certainty. Until the abolition of nuclear weapons reduces the annual probability to zero, our immediate goal must be to reduce the probability of a nuclear accident to as low a level as possible. Given the massive casualties that would result from such an accident, achieving this must be among the most urgent of all global public health priorities.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-14 00:19:50", "grab_time": "2024-08-13 23:00:33"}
{"id": 2234512, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "a136a5b6-e4c1-41c8-860c-984a7f3d798c", "title": "Effects of Tolazamide and Exogenous Insulin on Insulin Action in Patients with Non-Insulin-Dependent Diabetes Mellitus", "text": "【0】Effects of Tolazamide and Exogenous Insulin on Insulin Action in Patients with Non-Insulin-Dependent Diabetes Mellitus\nAbstract\n--------\n\n【1】To determine whether sulfonylureas and exogenous insulin have different effects on insulin action, we studied eight patients with non-insulin-dependent diabetes mellitus before and after three months of treatment with tolazamide and exogenous semisynthetic human insulin, using a randomized crossover design. Therapy with tolazamide and therapy with insulin resulted in similar improvement of glycemic control, as measured by a decrease in mean glycosylated hemoglobin (±SEM) from 9.4±0.7 percent to 7.7±0.5 percent with tolazamide and to 7.1±0.2 percent with exogenous insulin (P<0.01 for both comparisons). Therapy with either tolazamide or exogenous insulin resulted in a similar lowering (P<0.05) of postabsorptive glucose-production rates (from 2.3±0.1 to 2.0±0.2 and 1.8±0.1 mg per kilogram of body weight per minute, respectively) but not to normal (1.5±0.1 mg per kilogram per minute). Both tolazamide and exogenous insulin increased (P<0.05) glucose utilization at supraphysiologic insulin concentrations (from 6.2±0.7 to 7.7±0.6 mg per kilogram per minute with tolazamide and to 7.8±0.6 mg per kilogram per minute with exogenous insulin) to nondiabetic rates (7.9±0.5 mg per kilogram per minute). Neither agent altered erythrocyte insulin binding at physiologic insulin concentrations.\n\n【2】We conclude that treatment with sulfonylureas or exogenous insulin results in equivalent improvement in insulin action in patients with non-insulin-dependent diabetes mellitus. Therefore, the choice between these agents should be based on considerations other than their ability to ameliorate insulin resistance.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:31:53", "endTime": "2024/08/14 15:32:02", "cost": 8.579}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:33", "update_time": "2024-08-13 23:32:02", "grab_time": "2024-08-13 23:31:53"}
{"id": 2234511, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "12d45e3f-0b28-4f6a-ad9f-dcd81f5e826f", "title": "Prenatal Diagnosis of β-Thalassemia — Detection of a Single Nucleotide Mutation in DNA", "text": "【0】Prenatal Diagnosis of β-Thalassemia — Detection of a Single Nucleotide Mutation in DNA\nAbstract\n--------\n\n【1】We investigated a method employing synthetic oligonucleotides for the prenatal diagnosis of β-thalassemia due to a single nucleotide mutation. The β  thalassemia we tested is produced by a nonsense mutation and is commonly found in Sardinia and other parts of the Mediterranean. In this DNA lesion, the glutamine codon CAG at the β  position is mutated to TAG, which results in a stop codon and premature termination of the β-globin chain. We synthesized two oligonucleotides: one homologous to the normal β <sup>A </sup> gene and the other to the β  thalassemia gene at the β  location. The oligonucleotides were labeled with  P and used as hybridization probes for normal and thalassemic DNA. The β <sup>A </sup> probe hybridized only to the normal DNA, and the β-thalassemia probe only to thalassemic DNA, thus providing a technique for direct demonstration of the mutation. The method is sensitive enough to be applied directly to DNA that is isolated from uncultured cells obtained from only 20 ml of amniotic fluid as early as the 16th gestational week.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:36:45", "endTime": "2024/08/14 14:37:17", "cost": 31.698}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 22:37:17", "grab_time": "2024-08-13 22:36:45"}
{"id": 2234510, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "59995957-f3d0-4e29-910d-c4c4fd75b604", "title": "Multidrug-Resistant Tuberculosis in Patients without HIV Infection", "text": "【0】Multidrug-Resistant Tuberculosis in Patients without HIV Infection\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Investigations of outbreaks of multidrug-resistant tuberculosis have found low rates of treatment response and very high mortality, and they have mainly involved patients with advanced human immunodeficiency virus (HIV) infection. For patients without HIV infection, one study reported an overall rate of response to treatment of 56 percent, and the mortality from tuberculosis was 22 percent. We investigated treatment response and mortality rates in 26 HIV-negative patients in New York with multidrug-resistant tuberculosis.\n\n【3】Methods\n-------\n\n【4】We obtained detailed data from seven teaching hospitals in New York City on patients with multidrug-resistant tuberculosis — defined as tuberculosis resistant at least to isoniazid and rifampin — who were HIV-negative on serologic testing. Lengths of times from diagnosis to the initiation of appropriate therapy and from the initiation of appropriate therapy to conversion to negative cultures were assessed. Therapeutic responses were evaluated by both microbiologic and clinical criteria.\n\n【5】Results\n-------\n\n【6】Between March 1991 and September 1994, 26 HIV-negative patients were identified and treated. Of the 25 patients for whom adequate data were available for analysis, 24 (96 percent) had clinical responses; all 17 patients for whom data on microbiologic response were available had such a response. The median times from diagnosis to the initiation of appropriate therapy and from the initiation of therapy to culture conversion were 44 days (range, 0 to 181) and 69 days (range, 2 to 705), respectively. Side effects requiring the discontinuation of medication occurred in 4 of 23 patients (17 percent) who were treated with second-line antituberculosis medications. The median follow-up for the 23 patients who responded and who received appropriate therapy was 91 weeks (range, 41 to 225).\n\n【7】Conclusions\n-----------\n\n【8】In this report from New York City, HIV-negative patients with multidrug-resistant tuberculosis, contrary to previous reports, responded well to appropriate chemotherapy, both clinically and microbiologically.\n\n【9】Introduction\n------------\n\n【10】The emergence of multidrug-resistant tuberculosis has been well documented in both New York City and the rest of the United States.  Though New York City had the highest rate in a national survey of reported tuberculosis cases in the first quarter of 1991, cases of multidrug-resistant tuberculosis were reported from 13 states and 35 of the nation's counties (1.1 percent). \n\n【11】Previous studies have found that patients with drug-resistant tuberculosis have lower response rates than patients with drug-susceptible isolates.  Recent investigations of outbreaks of multidrug-resistant tuberculosis have found an extraordinarily high case fatality rate, with the median mortality being reached between 4 and 16 weeks.  In almost all instances, these outbreaks have involved patients severely immunosuppressed by infection with the human immunodeficiency virus (HIV). More recent data suggest that outcomes can be improved if patients promptly start to receive two or more drugs that have in vitro activity against the multidrug-resistant isolates. \n\n【12】The expected outcome in patients not infected with HIV who have multidrug-resistant tuberculosis is less well defined. However, a widely cited study of 171 HIV-negative patients treated from 1973 to 1983 at the National Jewish Center for Immunology and Respiratory Medicine found an overall response rate of 56 percent and a mortality rate attributable to tuberculosis of 22 percent. \n\n【13】In New York City, because of the recent dramatic increase in cases of tuberculosis and multidrug-resistant tuberculosis, we have had the opportunity to evaluate patients with multidrug-resistant tuberculosis who are not HIV-infected. We describe our experience with 25 patients whose clinical characteristics and outcomes differed dramatically from those of previously published studies.\n\n【14】Methods\n-------\n\n【15】We identified cases of multidrug-resistant tuberculosis — defined as tuberculosis caused by _Mycobacterium tuberculosis_ resistant at least to isoniazid and rifampin — through a network of hospital-based physicians who treat patients with tuberculosis at seven teaching hospitals in New York City, including five private hospitals (Bronx–Lebanon Hospital Center, Montefiore Medical Center, New York Hospital, St. Clare's Hospital, and Beth Israel Medical Center) and two public ones (Harlem Hospital Center and North Central Bronx Hospital). Only patients who were found to be HIV-negative by routine serologic testing were included in the review. For patients who met these criteria, detailed data-abstraction forms were completed by physicians at the hospitals where the patients initially received the diagnosis of multidrug-resistant tuberculosis. The forms were designed to obtain information on demographic characteristics, risk factors for tuberculosis infection, the extent and verification of tuberculosis, and the response to, and toxicity of, antituberculosis therapy.\n\n【16】The date of diagnosis of multidrug-resistant tuberculosis was defined as the date of collection of the first specimen from which multidrug-resistant tuberculosis was isolated. The time to the initiation of appropriate therapy was defined as the time from diagnosis to the institution of a regimen containing at least two drugs with in vitro activity against the isolate. For one patient, appropriate therapy was begun 63 days before the date of diagnosis. In the analysis, this patient was assigned a value of zero days from diagnosis to appropriate treatment. Another patient was in remission more than three years after his initial diagnosis, without ever having received appropriate treatment. He was removed from this analysis. The time to culture conversion was defined as the time from the start of appropriate therapy to the collection of the first in a series of two or more consecutive negative cultures at least two weeks apart. A therapeutic response was evaluated on the basis of both microbiologic and clinical criteria. A microbiologic response was defined as negative results of at least two consecutive sputum cultures at least two weeks apart. A clinical response was defined as the resolution of signs and symptoms associated with the diagnosis of tuberculosis. Patients were considered to have completed therapy if they had received a total of at least 18 months of appropriate therapy or if they had received at least 12 months of appropriate therapy after the conversion of their sputum cultures to negative; 13 patients satisfied this criterion. Three additional patients categorized as having completed therapy discontinued appropriate treatment against medical advice after they had clinical or bacteriologic responses or both. The duration of follow-up was defined as the interval between the date appropriate therapy was initiated and the date of the last known contact.\n\n【17】Microbiologic Methods\n---------------------\n\n【18】Standard procedures were used according to the practice of each hospital. Five hospitals used their own laboratories to identify _M. tuberculosis_ and to test for susceptibility to first-line antituberculosis medications, one hospital sent specimens to a commercial laboratory, and one hospital sent specimens to the laboratories of the New York City Department of Health. Bactec radiometric mediums (Becton Dickinson, Towson, Md.) were used by five of the laboratories, and solid mediums were used by the other two.  Tests for susceptibility to pyrazinamide were not routinely performed until April 1992, and results are included here when they were available. Testing for susceptibility to second-line antituberculosis medications and retesting for susceptibility to first-line drugs were performed for 20 patients (80 percent) by a referral laboratory at one of four institutions: the Centers for Disease Control and Prevention, the New York City Department of Health, the National Jewish Center for Immunology and Respiratory Medicine, and the West Haven Veterans Affairs Hospital.  For specimens tested by referral laboratories, multidrug resistance was defined by the growth on drug-containing mediums (0.2 μg of isoniazid per milliliter and 1.0 μg of rifampin per milliliter) of more than 1 percent of the colonies that grew on a drug-free (control) medium.\n\n【19】Results\n-------\n\n【20】Between March 1991 and September 1994, more than 200 patients received diagnoses of multidrug-resistant tuberculosis and were treated at the seven hospitals. The overwhelming majority of these patients were infected with HIV. During this interval, 26 HIV-negative patients with multidrug-resistant tuberculosis were identified and treated; for 25 of these adequate data were available for analysis. Case finding was complete at all seven hospitals. One hospital cared for seven patients, one for six, one for four, one for three, two for two, and one for one.\n\n【21】Table 1. Demographic Characteristics of 25 HIV-Negative Patients with Multidrug-Resistant Tuberculosis.\n\n【22】The demographic characteristics of the 25 patients are shown in Table 1 . The median age at the time of diagnosis was 37 years, and 14 patients (56 percent) were male. Fifteen patients (60 percent) were black, four (16 percent) were Hispanic, four (16 percent) were Asian, and two (8 percent) were white. Of the 10 patients born outside the United States or Puerto Rico, 5 were born in Asia, 3 in Latin America, 1 in Africa, and 1 in Europe.\n\n【23】Previously established risk factors for multidrug-resistant tuberculosis were identified in 17 of the patients (68 percent). Eight patients had a history of inadequately treated tuberculosis, and nine had known exposures to patients with multidrug-resistant tuberculosis. Of these nine, eight were health care workers and one was a patient hospitalized during a nosocomial outbreak of multidrug-resistant tuberculosis. Among the health care workers, five were physicians, two were nurses, and one was a medical administrator. An additional three patients were residents of the New York City shelter system for the homeless.\n\n【24】All but four patients (84 percent) had disease localized to the lung or pleura; one had both pulmonary and peritoneal disease, and three had extrapulmonary disease alone (in the lymph nodes, the lumbar vertebrae, and the soft tissues of the scrotum). Nineteen of the 25 patients had no underlying disease before the diagnosis of tuberculosis; of the remaining 6, 2 had diabetes mellitus and end-stage renal disease, 2 had diabetes alone, and 1 patient each had severe rheumatoid arthritis and adenocarcinoma of the lung.\n\n【25】Twenty-four patients (96 percent) had clinical responses. One woman with diabetes mellitus and end-stage renal disease died five days after standard doses of isoniazid, rifampin, ethambutol, and pyrazinamide were initiated. Results of susceptibility tests of her isolate became available post mortem and indicated resistance to isoniazid, rifampin, streptomycin, and ethambutol. No autopsy was performed, but the clinical impression was that she died of overwhelming tuberculosis.\n\n【26】Table 2. Profile of Susceptibility to First-Line Antituberculosis Drugs and Treatment Regimens for 23 Patients with Multidrug-Resistant Tuberculosis Who Responded to Drug Treatment and Who Received Appropriate Therapy.\n\n【27】The patterns of susceptibility to the five first-line antituberculosis medications and the treatment regimens used for the 23 patients with responses who received appropriate therapy are summarized in Table 2 . Twelve of the isolates (52 percent) were resistant to four or five of the first-line antituberculosis agents. Eight patients had isolates that were resistant to isoniazid and rifampin only. Susceptibility testing was not done for pyrazinamide in eight patients.\n\n【28】Twenty-three patients who responded were ultimately treated with at least three drugs that had in vitro activity against their isolates, and all received prolonged treatment with a quinolone. Radiographic abnormalities and clinical symptoms resolved without treatment in the remaining patient with a response.\n\n【29】Three patients underwent therapeutic lobectomies at the discretion of the primary treating physicians. Cultures for one patient became negative only after a lobectomy, despite approximately 15 months of appropriate chemotherapy. The other two patients had culture-negative sputum specimens before surgery, but surgery was performed because of localized cavitary disease found on chest radiography.\n\n【30】The median time from the diagnosis of multidrug-resistant tuberculosis to the initiation of appropriate therapy was 44 days (range, 0 to 181) for the 23 patients who ultimately received at least three drugs with in vitro activity against the multidrug-resistant isolate. All 17 patients for whom data on microbiologic response were available had such responses. The median time to a microbiologic response was 69 days (range, 2 to 705), with a mean of 126 days. The mean was influenced by two extreme values of 705 and 496 days. The first value was that of a patient who was noncompliant for more than 2 years but who subsequently responded after 90 days of appropriate therapy that was directly observed. The patient with the second value responded only after a lobectomy, despite appropriate and prolonged chemotherapy. All 17 patients who had microbiologic responses also had clinical responses, with the resolution of signs and symptoms.\n\n【31】Of the eight patients for whom microbiologic response could not be determined, four did not have follow-up specimens obtained because of the site of disease (lymph nodes, vertebrae, soft tissue of the scrotum, or pleura), and one patient died before follow-up specimens could be obtained. Follow-up sputum specimens were not obtained from three patients. Seven of these eight patients had clinical responses.\n\n【32】Table 3. Outcomes of 25 Patients with Multidrug-Resistant Tuberculosis.\n\n【33】As of March 31, 1995, 16 patients (64 percent) had completed a course of therapy without evidence of relapse . Seven patients (28 percent) were in remission while still receiving therapy, and one remained in remission without having ever received appropriate therapy. The 16 patients who had completed therapy received quinolones for a median of 568 days (range, 150 to 787). In addition, 13 of these 16 patients received parenteral therapy with either an aminoglycoside or capreomycin (median, 252 days; range, 34 to 595); 8 received ethionamide (median, 570 days; range, 119 to 766); and 7 received cycloserine (median, 559 days; range, 119 to 595).\n\n【34】The median duration of follow-up from the time that appropriate therapy was instituted to the date of last contact for the 23 patients with responses who received treatment was 91 weeks (range, 41 to 225). For the 17 patients who had microbiologic responses, the median duration of follow-up from the time of microbiologic response was 81 weeks (range, 30 to 146). For the 16 patients who completed therapy, the median duration of follow-up after the initiation of appropriate therapy was 121 weeks, and after the completion of therapy, 22 weeks (range, 0 to 52).\n\n【35】Eight patients had a history of tuberculosis; seven of them completed therapy during the study period. These patients had had tuberculosis for a median of 2.5 years (range, <1 to 6) and had received a median of 3.5 antituberculosis drugs before the initiation of appropriate therapy for their multidrug-resistant tuberculosis. The median time to a microbiologic response in the 7 patients for whom data were available was 79 days, as compared with 62 days in the 10 patients with available data and no history of tuberculosis.\n\n【36】Table 4. Side Effects of Second-Line Antituberculosis Medications Leading to the Withdrawal of Treatment in 4 of 23 Patients Treated for Multidrug-Resistant Tuberculosis.\n\n【37】Serious side effects requiring the discontinuation of second-line antituberculosis medication occurred in four patients (17 percent) . Nineteen patients had no serious adverse reactions. In addition, 13 patients had six or more months of parenteral therapy with an aminoglycoside or capreomycin or both. Ototoxicity in one patient necessitated the discontinuation of kanamycin.\n\n【38】Discussion\n----------\n\n【39】Drug-resistant and multidrug-resistant tuberculosis is a growing problem in the United States. The emergence of resistance may be due to either patient noncompliance  or the transmission of already resistant strains.  The Centers for Disease Control and Prevention conducted a nationwide susceptibility survey of tuberculosis cases reported in 1991 and found that 14.2 percent were resistant to at least one drug and 3.5 percent were resistant to both isoniazid and rifampin and therefore considered to be multidrug-resistant. \n\n【40】The optimal therapy for drug-susceptible tuberculosis is well established after numerous trials comprising thousands of patients. The optimal therapy for drug-resistant tuberculosis, particularly multidrug-resistant tuberculosis, is less well studied and standardized. Mitchison and Nunn reviewed the outcomes of patients with drug-resistant tuberculosis in 12 controlled trials conducted in Africa, Hong Kong, and Singapore.  Of 8212 patients studied, 1041 (12.7 percent) had tuberculosis with initial resistance to at least one drug and 256 (3.1 percent) had tuberculosis resistant to both isoniazid and streptomycin. Only 11 isolates were resistant to rifampin. Chemotherapy failed in 5 of the 11 patients with tuberculosis resistant to rifampin, and 3 of the remaining 6 patients relapsed after therapy was stopped. These responses are in contrast to the high response rates and few relapses that were seen in patients whose disease was initially resistant to drugs other than rifampin. The authors attributed these findings to the excellent sterilizing activity of both rifampin and pyrazinamide and to the ability of rifampin to help prevent the emergence of drug resistance during treatment.\n\n【41】A recently published study described the outcomes of 171 patients with multidrug-resistant tuberculosis treated over an 11-year period from 1973 to 1983.  These patients had tuberculosis for a median of six years and had received a median of six drugs before being referred to the National Jewish Center for Immunology and Respiratory Medicine in Denver. Patients were shedding tubercle bacilli that were resistant to a median of six drugs. Outcomes in this group were poor: of 134 patients for whom adequate follow-up data were available, 87 (65 percent) initially responded to chemotherapy and 47 (35 percent) had no response, as manifested by persistently positive cultures. The overall response rate, including relapses, was 56 percent, and the mortality attributable to tuberculosis was 22 percent.\n\n【42】In studies of outbreaks in the early 1990s, patients with the acquired immunodeficiency syndrome (AIDS) and multidrug-resistant tuberculosis had a median survival of 4 to 16 weeks.  In one report, those who were HIV-infected but without a diagnosis of AIDS had a median survival of 14 months.  Recent reports have described improved outcomes when HIV-infected patients received prompt diagnoses and were treated rapidly with appropriate medications.  In our series, the median time from the diagnosis of multidrug-resistant tuberculosis to the initiation of appropriate therapy was 44 days. This relatively short period, as compared with those reported previously, is probably due to three factors: the practice of starting treatment with isoniazid, rifampin, pyrazinamide, and ethambutol for all patients with tuberculosis before the results of susceptibility testing were available; the use of Bactec radiometric mediums; and maintenance of a high index of suspicion for drug-resistant tuberculosis.\n\n【43】We have shown that HIV-negative patients with multidrug-resistant tuberculosis can be expected to have a good response to medical therapy. All of our patients who received appropriate therapy have had clinical and microbiologic responses. There were no relapses or treatment failures during a median follow-up period of 91 weeks. It is still possible that some of these patients will relapse. This group, however, in addition to having the benefits of quinolone therapy, probably represents patients of a different type from those described in the Denver study. The Denver patients, as we have mentioned, were heavily pretreated and were referred after treatment by physicians in their own communities had failed. Many of our patients, on the other hand, probably had primary disease; in fact, only eight of the patients (32 percent) had a history of tuberculosis. As recent studies based on restriction-fragment–length polymorphisms have demonstrated, recent transmission accounts for as much as 40 percent of cases of adult tuberculosis in certain urban populations.  It may be that our results reflect the advantage of treating primary resistant disease, rather than disease in persons exposed intermittently to antituberculosis medication for years, resulting in secondary resistance and damaged lungs. Even our patients with previous tuberculosis, all of whom responded, represented a group different from those treated in the Denver series. They had tuberculosis for a shorter period (2.5 years, vs. 6 for the Denver patients) and were not as heavily pretreated (median number of drugs, 3.5, vs. 6 in Denver). Lastly, as we saw in one of our patients, primary tuberculosis, even when due to a multidrug-resistant strain, may resolve with no effective chemotherapy, although the risk of reactivation clearly remains.\n\n【44】Since this retrospective review is based on the experience of seven hospitals, laboratory techniques and treatment regimens varied. Nevertheless, we conclude that contrary to previous reports, patients without HIV infection who contract multidrug-resistant tuberculosis can be expected to respond to appropriate chemotherapy, both clinically and microbiologically. As in other studies, serious drug toxicity is not unusual, and safer agents are needed. Assessment of the long-term efficacy of this approach awaits several more years of patient follow-up.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 18:16:59", "endTime": "2024/08/13 18:23:15", "cost": 375.782}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 02:23:15", "grab_time": "2024-08-13 02:16:59"}
{"id": 2234509, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "36e0dc48-33a8-40bb-bc50-083ce42a5218", "title": "Extended Antiretroviral Prophylaxis to Reduce Breast-Milk HIV-1 Transmission", "text": "【0】Extended Antiretroviral Prophylaxis to Reduce Breast-Milk HIV-1 Transmission\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Effective strategies are urgently needed to reduce mother-to-child transmission of human immunodeficiency virus type 1 (HIV-1) through breast-feeding in resource-limited settings.\n\n【3】Methods\n-------\n\n【4】Women with HIV-1 infection who were breast-feeding infants were enrolled in a randomized, phase 3 trial in Blantyre, Malawi. At birth, the infants were randomly assigned to one of three regimens: single-dose nevirapine plus 1 week of zidovudine (control regimen) or the control regimen plus daily extended prophylaxis either with nevirapine (extended nevirapine) or with nevirapine plus zidovudine (extended dual prophylaxis) until the age of 14 weeks. Using Kaplan–Meier analyses, we assessed the risk of HIV-1 infection among infants who were HIV-1–negative on DNA polymerase-chain-reaction assay at birth.\n\n【5】Results\n-------\n\n【6】Among 3016 infants in the study, the control group had consistently higher rates of HIV-1 infection from the age of 6 weeks through 18 months. At 9 months, the estimated rate of HIV-1 infection (the primary end point) was 10.6% in the control group, as compared with 5.2% in the extended-nevirapine group (P<0.001) and 6.4% in the extended-dual-prophylaxis group (P=0.002). There were no significant differences between the two extended-prophylaxis groups. The frequency of breast-feeding did not differ significantly among the study groups. Infants receiving extended dual prophylaxis had a significant increase in the number of adverse events (primarily neutropenia) that were deemed to be possibly related to a study drug.\n\n【7】Conclusions\n-----------\n\n【8】Extended prophylaxis with nevirapine or with nevirapine and zidovudine for the first 14 weeks of life significantly reduced postnatal HIV-1 infection in 9-month-old infants. \n\n【9】Introduction\n------------\n\n【10】In sub-Saharan Africa, where breast-feeding is critical for infant survival, postnatal transmission of human immunodeficiency virus type 1 (HIV-1) occurs in up to 16% of untreated infants when breast-feeding continues into the second year of life.  Although effective interventions have been identified to reduce in utero and intrapartum transmission of HIV-1 in resource-limited countries,  breast-feeding attenuates the efficacy of such methods.  Thus, a major concern in developing countries is HIV-1 transmission through breast milk.  To optimize the survival of infants who are born to mothers with HIV-1 infection, interventions that allow safe breast-feeding during the first 6 months of life or longer are needed.\n\n【11】The aim of our trial, called the Post-Exposure Prophylaxis of Infants (PEPI) trial, was to determine whether extended prophylaxis of infants with nevirapine or with nevirapine plus zidovudine until the age of 14 weeks (when the infant immunization schedule is completed in Malawi) would decrease the rate of HIV-1 infection, as compared with single-dose nevirapine combined with 1 week of zidovudine (control regimen). The control regimen, which was previously shown to be effective in a randomized trial in Malawi, is recommended in resource-limited settings, including Malawi. \n\n【12】Methods\n-------\n\n【13】Study Population\n----------------\n\n【14】Pregnant women who presented for either antenatal or delivery services at Queen Elizabeth Central Hospital or at one of five other health centers in Blantyre, Malawi, were offered HIV-1 counseling and testing. All women with HIV-1 infection, except those whose HIV-1 infection was not identified until after they gave birth (late presenters), received intrapartum single-dose nevirapine. Women could be enrolled in the trial if they had HIV-1 infection, were at least 18 years of age (although women <18 years of age could be enrolled if they consented and a guardian gave permission), were pregnant or had given birth within the previous 24 hours at one of the study clinics, were a resident of the study area, were willing to return for postnatal follow-up visits for up to 2 years, and intended to breast-feed. Infants with life-threatening conditions requiring immediate care were excluded. All eligible women provided written informed consent at enrollment.\n\n【15】The protocol and study consent forms were approved by institutional review boards at the University of Malawi, Johns Hopkins University, and the Centers for Disease Control and Prevention. Enrollment began on April 20, 2004. The current analysis includes data on women and their infants who were enrolled in the study through August 7, 2007. All authors vouch for the completeness and accuracy of the data presented.\n\n【16】Study Design\n------------\n\n【17】In our randomized, controlled, open-label, phase 3 clinical trial, infants were randomly assigned at birth to receive one of three regimens: single-dose nevirapine combined with 1 week of daily zidovudine (control group) or the control regimen followed by extended daily prophylaxis with either oral nevirapine (extended-nevirapine group) or oral nevirapine plus zidovudine (extended-dual-prophylaxis group) until the age of 14 weeks. Women were counseled at each visit to breast-feed exclusively for 6 months and to consider weaning thereafter.\n\n【18】Study-Drug Regimens\n-------------------\n\n【19】Beginning immediately after birth, all infants received a single oral dose of nevirapine (2 mg per kilogram of body weight) plus oral zidovudine (4 mg per kilogram), given twice daily for 1 week. Zidovudine was given for 1 week rather than 4 weeks for the following reasons: the 1-week regimen was shown to be more effective than single-dose nevirapine alone in a randomized trial in Malawi  and is the recommended regimen for infants born to women who have not received antenatal antiretroviral prophylaxis in Malawi; no clinical trials have shown that a 4-week regimen is superior to a 1-week regimen when single-dose nevirapine is also given; and in a study in South Africa,  a 6-week regimen of zidovudine provided no better protection than single-dose nevirapine alone.\n\n【20】Drugs for infants in the two extended-prophylaxis groups were dispensed to the mothers starting at the 1-week study visit and at subsequent visits until the infant completed the 14-week regimen. In the extended-prophylaxis groups, the oral dose of nevirapine was 2 mg per kilogram once daily during week 2, then 4 mg per kilogram once daily during weeks 3 through 14. The oral dose of zidovudine was 4 mg per kilogram twice daily during weeks 2 through 5, 4 mg per kilogram three times daily during weeks 6 through 8, and 6 mg per kilogram three times daily during weeks 9 through 14.\n\n【21】Prophylaxis regimens were discontinued for infants in the extended-prophylaxis groups who were found to have HIV-1 infection during the first 14 weeks of life. However, these infants were still followed for the duration of the study.\n\n【22】Study Follow-up and Procedures\n------------------------------\n\n【23】Study visits were conducted at 1, 3, 6, 9, and 14 weeks and at 6, 9, 12, 15, 18, and 24 months of infant age. Infant blood samples were collected by heel-stick or venous puncture for HIV-1 testing and dried-blood spot storage at each visit except week 3. Specimens for a complete blood count and testing of alanine aminotransferase levels were collected at each visit through 6 months; plasma was collected at birth, at 6 and 14 weeks, and at 6, 12, and 18 or 24 months.\n\n【24】All women in the study and any of their infants who were found to have HIV-1 infection were referred for antiretroviral therapy at clinics at a study health center, although the availability of antiretroviral treatment in Malawi was limited, with increased availability only late in the study. Only small percentages of women (2.6% in the control group, 2.8% in the extended-nevirapine group, and 3.2% in the extended-dual-prophylaxis group) received antiretroviral therapy before 14 weeks post partum (P=0.77 for all comparisons). The maternal rates of antiretroviral therapy were slightly higher after the 14-week study period (11.8% in the control group, 12.2% in the extended-nevirapine group, and 11.4% in the extended-dual-prophylaxis group) (P=0.87 for all comparisons). All infants who were exposed to or infected with HIV-1 received prophylaxis with trimethoprim–sulfamethoxazole to prevent pneumocystis pneumonia. Further details regarding the monitoring and randomization of patients and the collection of data are available in the Supplementary Appendix , available with the full text of this article at www.nejm.org.\n\n【25】Study End Points\n----------------\n\n【26】The primary study end point was the rate of HIV-1 infection by the age of 9 months among live-born infants who were negative for HIV-1 infection on DNA polymerase-chain-reaction (PCR) assay at birth (i.e., within the first 48 hours). Infants were evaluated for the presence of HIV-1 infection at 6, 9, and 14 weeks and at 6, 12, 18, and 24 months. Additional primary end points were survival free of HIV-1 infection during follow-up and the safety of the experimental regimens.\n\n【27】The presence or absence of HIV-1 infection was determined by Roche Amplicor 1.5 DNA PCR (Roche Molecular Systems). Positive specimens were confirmed by testing a second specimen obtained as soon as possible after an initial positive test. Specimens with discrepant test results at the local laboratory were retested in a reference laboratory at the University of North Carolina, Chapel Hill. Final infection status was determined by three investigators who were unaware of infants' study-group assignments. For infants whose infection status was not resolved by retesting at the reference laboratory (e.g., because no sample was available for repeat testing), those with a positive test result that was followed by multiple negative tests (either on DNA PCR or on HIV-antibody enzyme immunoassays) were considered to be uninfected. All other infants whose HIV-1 status still could not be resolved (e.g., owing to termination from the study because of relocation or removal from the study by a parent) were excluded from the analysis, including 14 infants in the control group, 5 in the extended-nevirapine group, and 15 in the extended-dual-prophylaxis group.\n\n【28】Diagnosis of HIV-1 infection was based on a positive HIV-1 DNA PCR assay at any visit or a positive enzyme-linked immunosorbent assay (ELISA) and Western blot analysis at the age of 15 months or later. An infant with at least two positive HIV-1 test results on separate visits was classified as having confirmed HIV-1 infection, and an infant with only a single positive result (due to the death of the infant, loss to follow-up, or a pending confirmatory test) was classified as having presumptive HIV-1 infection. All identified adverse events were documented and graded with the use of a toxicity table adopted in April 1994 by the Division of AIDS at the National Institutes of Health.\n\n【29】Statistical Analysis\n--------------------\n\n【30】We present all data that were obtained through the cutoff date for the second interim analysis (August 7, 2007). Study groups were examined for similarity according to baseline covariates (continuous or categorical) with the use of the t-test, analysis of variance, Fisher's exact test, and the chi-square test.\n\n【31】In an intention-to-treat analysis, we compared each extended-prophylaxis group with the control group. We used Kaplan–Meier analyses to estimate the time until the first positive HIV-1 test (either confirmed or presumptive, with data for infants without a positive HIV-1 test censored at the time of death), the time to death, and the time to either death or the first positive HIV-1 test (whichever came first), according to study group. Cox proportional-hazards models of the time until the first positive HIV-1 test, with adjustment for study group and other covariates that were considered to have biologic or epidemiological importance, were performed with SAS software, version 9.1 (SAS Institute).\n\n【32】The study was designed to enroll 3500 infants to include at least 3000 who were not infected with HIV-1 at birth on the basis of an assumed rate of infection of 8% and an assumed rate of postpartum transmission of 14% at 9 months in the control group. The data and safety monitoring board recommended that enrollment in the study be stopped at the second interim analysis (December 10, 2007), since the P value for the difference between the extended-nevirapine group and the control group exceeded a Bonferroni-adjusted O'Brien–Fleming rejection threshold (alpha level, 0.0063). At this time, 3016 infants who were not infected with HIV-1 at birth were enrolled in the study. A total of 2522 infants either with HIV-1 infection or without HIV-1 infection were enrolled for at least 9 months.\n\n【33】Results\n-------\n\n【34】Patients\n--------\n\n【35】Figure 1. Enrollment and Outcomes, 2004–2007.\n\n【36】A total of 46,186 women underwent screening for HIV-1 infection. Women with HIV-1 infection who met the inclusion criteria and signed an informed consent form were enrolled in the study. Of 3276 infants who were enrolled and underwent randomization at birth, 260 were excluded from the efficacy analysis: 226 because they were found to have HIV-1 infection and 34 because their HIV-1 status at birth was not known. These exclusions were distributed equally among the three study groups. Therefore, 3016 infants were included in the primary analysis .\n\n【37】Table 1. Baseline Characteristics of Mothers and Infants.\n\n【38】Baseline demographic and laboratory characteristics of the women and their infants were similar in the three study groups . All infants received a single dose of nevirapine at birth, and of the 2427 infants who returned for the first-week visit, 99% received zidovudine. At 14 weeks, adherence (defined as the proportion of infants who received treatment among those who returned for the visit) was 97.3% (658 of 676 infants) in the extended-nevirapine group and 97.8% (673 of 688 infants) in the extended-dual-prophylaxis group (P=0.60).\n\n【39】Frequency of Breast-Feeding\n---------------------------\n\n【40】Table 2. Frequency of Breast-Feeding, According to Study Visit.\n\n【41】The frequency of reported breast-feeding was high up to the age of 6 months, ranging from nearly all infants at 1 week to approximately 90% at 6 months in all three study groups. Between the ages of 6 and 9 months, there was a substantial reduction in the frequency of breast-feeding in all three groups, with rates at 9 months of 32.0% in the control group, 26.9% in the extended-nevirapine group, and 29.2% in the extended-dual-prophylaxis group (P=0.16 for all comparisons). By the age of 15 months, the rate of breast-feeding had declined to 19.4% in the control group, 14.4% in the extended-nevirapine group, and 18.1% in the extended-dual-prophylaxis group .\n\n【42】HIV-1 Infection\n---------------\n\n【43】Of the 3016 infants, 255 were found to have HIV-1 infection by August 7, 2007. Of these cases, 242 were confirmed and 13 were presumptive; the frequency of HIV infections that were classified as presumptive was similar in the three study groups (P=0.22 for all comparisons). Both confirmed and presumptive HIV-1 infections were included in the primary analysis, although limiting the analysis to only confirmed HIV-1 infections produced similar results (data not shown). The rates of HIV-1 positivity on DNA analysis at birth were 6.5% in the control group and 7.1% in both extended-prophylaxis groups (P=0.85 for all comparisons). Before the primary end point at 9 months, the numbers of infants who were lost to follow-up without a positive HIV-1 test were 136 in the control group, 131 in the extended-nevirapine group, and 109 in the extended-dual-prophylaxis group.\n\n【44】Figure 2. Kaplan–Meier Estimates of the Rates of HIV-1 Infection, Death, and a Composite of HIV-1 Infection or Death among Infants during Their First 24 Months.\n\n【45】Among infants who were uninfected with HIV-1 at birth on the basis of DNA polymerase-chain-reaction assay, rates are shown for HIV-1 infection , death , and either HIV-1 infection or death  during the first 24 months in the three study groups. The I bars represent 95% confidence intervals.\n\n【46】Among infants who were not infected at birth (i.e., excluding infants with positive DNA PCR tests for HIV), between the ages of 6 weeks and 18 months, the control group had consistently higher rates of HIV-1 infection, as compared with both extended-prophylaxis groups . Among 9-month-old infants, the rate of HIV-1 infection, as estimated from Kaplan–Meier curves for which data were censored at the time of loss to follow-up, was 10.6% (95% confidence interval \\[CI\\], 8.7 to 12.8) in the control group, 5.2% (95% CI, 3.9 to 7.0) in the extended-nevirapine group (P<0.001 for the comparison with the control group), and 6.4% (95% CI, 4.9 to 8.3) in the extended-dual-prophylaxis group (P=0.002 for the comparison with the control group). The total numbers of infants with positive results on HIV-1 DNA PCR at 9 months were 98 in the control group, 51 in the extended-nevirapine group, and 61 in the extended-dual-prophylaxis group. The estimated protective efficacy  of the extended-nevirapine regimen was 67% (95% CI, 43 to 81) at 6 weeks, 67% (95% CI, 49 to 79) at 14 weeks, 60% (95% CI, 42 to 73) at 6 months, and 51% (95% CI, 30 to 66) at 9 months. The estimated protective efficacy of the extended-dual-prophylaxis regimen was 69% (95% CI, 45 to 83) at 6 weeks, 66% (95% CI, 48 to 78) at 14 weeks, 49% (95% CI, 27 to 64) at 6 months, and 40% (95% CI, 16 to 57) at 9 months. There were no significant differences between the two extended-prophylaxis groups at any time point.\n\n【47】Death\n-----\n\n【48】Regardless of HIV-1–infection status, 285 infants died during the study: 106 in the control group, 89 in the extended-nevirapine group, and 90 in the extended-dual-prophylaxis group. Of these infants, those who had already died by the age of 9 months included 71 in the control group, 55 in the extended-nevirapine group, and 51 in the extended-dual-prophylaxis group. Although mortality in the control group exceeded that in the two extended-prophylaxis groups after the age of 6 months, the differences were not significant . At 9 months, mortality was 8.9% (95% CI, 7.1 to 11.1) in the control group, 6.8% (95% CI, 5.2 to 8.7) in the extended-nevirapine group, and 6.3% (95% CI, 4.8 to 8.2) in the extended-dual-prophylaxis group.\n\n【49】Table 3. Associated Risk Factors for HIV-1 Infection and for a Composite of HIV-1 Infection or Death.\n\n【50】Table 3 shows the results of the Cox proportional-hazards analyses of risk factors for HIV-1 infection and for either HIV-1 infection or death. In the adjusted analysis, both extended-prophylaxis regimens were significantly associated with a reduced risk of HIV-1 infection; a decrease in the maternal CD4 cell count was associated with an increased risk of infection. Lower infant birth weight was also associated with an increased risk of either HIV-1 infection or death.\n\n【51】The primary causes of infant death were gastroenteritis (30% in the control group, 26% in the extended-nevirapine group, and 30% in the extended-dual-prophylaxis group) and pneumonia (26%, 23%, and 21%, respectively). HIV-1–free survival was significantly better in both extended-prophylaxis groups through the age of 9 months and in the extended-nevirapine group through the age of 15 months .\n\n【52】Serious Adverse Events\n----------------------\n\n【53】Table 4. Serious Adverse Events.\n\n【54】Overall, 1283 serious adverse events were reported in 887 infants, with no significant differences among the three study groups for any adverse event (P=0.34 for all comparisons by Fisher's exact test) or for ordered treatment relatedness of adverse events (P=0.14 by the Jonckheere–Terpstra test  ) . The most frequent serious adverse events in all three groups were respiratory (329 events), gastrointestinal (227 events), and hematologic (191 events), and the rates were similar in all three study groups . Overall, most serious adverse events (87.3%) were not significantly associated with a study drug. However, there were significantly more infants with serious adverse events that were deemed to be possibly related to a study drug in the extended-dual-prophylaxis group than in either the extended-nevirapine group or the control group (P=0.02 for all comparisons). The most common serious adverse event in the extended-dual-prophylaxis group was neutropenia. The numbers of events that were deemed to be probably related to a study drug were low and did not differ among the study groups (P=0.42 for all comparisons).\n\n【55】Discussion\n----------\n\n【56】We evaluated two different extended 14-week post-exposure regimens to reduce postnatal HIV-1 transmission in a large, randomized clinical trial. Our study demonstrated that both extended-prophylaxis regimens significantly reduced the risk of postnatal transmission at 14 weeks with a protective efficacy of more than 60%. The cumulative risk of postnatal infection between birth and 14 weeks was 8.4% in the control group, as compared with approximately 2.8% in the extended-prophylaxis groups. This net difference of approximately 5% between the extended-prophylaxis groups and the control group continued at 24 months.\n\n【57】Although there were no significant differences in overall mortality, the control group had consistently higher mortality after the age of 6 months than did either of the extended-prophylaxis groups, a difference that appeared to be largely due to a higher rate of HIV-1 infection in the control group. There were significant increases in HIV-1–free survival for the infants in both extended-prophylaxis groups at the age of 9 months and for those in the extended-nevirapine group up to the age of 15 months.\n\n【58】The frequency of breast-feeding was high during the first 6 months (approximately 90%). Although most infants were weaned between the ages of 6 and 9 months, more than 20% were still breast-feeding at that time. After discontinuation of extended prophylaxis, the rate of postnatal HIV-1 infection occurring in infants between the ages of 14 weeks and 9 months was similar in the three study groups, with a rate of additional HIV-1 infections of 2.2% in the control group, 2.4% in the extended-nevirapine group, and 3.5% in the extended-dual-prophylaxis group.\n\n【59】The choice of providing daily prophylaxis up to 14 weeks was based on the recommended infant immunization schedule in Malawi, which is completed at 14 weeks. Most infants do not return to the clinic until the age of 9 months to receive measles immunization. Therefore, from a public health point of view, an approach to HIV-1 prophylaxis that is integrated into the typical infant immunization schedule would facilitate implementation in resource-constrained settings. There were no significant differences in efficacy between the two extended-prophylaxis groups. However, serious adverse events (primarily neutropenia) that were possibly related to a study drug were more frequent in the extended-dual-prophylaxis group. Whether the two-drug regimen would reduce the risk of resistance to nevirapine among infants who become infected with HIV-1 despite extended prophylaxis is being investigated.\n\n【60】Another approach to the prevention of postnatal transmission of HIV-1 is the treatment of mothers with HIV-1 infection with highly active antiretroviral therapy (HAART). Although maternal HAART is clearly warranted in women who require therapy for their own health, the benefits and safety of HAART used solely for prevention of postnatal transmission in healthy women with HIV infection have not yet been demonstrated in clinical trials, although several observational studies suggest it may be effective.  Data from two observational studies in Tanzania have suggested that infant antiretroviral prophylaxis (the MITRA study  ) and maternal HAART prophylaxis (the MITRA-Plus study  ) may result in similar postnatal transmission rates. Since HAART that is used solely for prophylaxis is stopped after the infant is weaned, the mother may receive 9 months or more of HAART (if therapy is started before birth), followed by an interruption. The effect of interruption of long-term HAART on maternal health is unknown. Some studies have demonstrated an increased risk of disease progression and death among HIV-1–infected adults with high CD4 counts who interrupted treatment, as compared with that associated with continuous therapy.  Antiretroviral treatment of the mother may also expose infants to potential toxic effects or drug resistance if the infant becomes infected because of a potential elevation in the plasma concentration of these drugs in the infant.  Thus, further evaluation of maternal HAART that is used solely for prophylaxis is needed to determine efficacy and long-term safety for both mothers and infants.\n\n【61】On the basis of data from our trial, the 14-week extended nevirapine regimen appears to be safe, with the rate of adverse events similar to that in the control group. This infant-only antiretroviral prophylaxis is practical and effective in reducing HIV-1 transmission and in improving HIV-1–free survival in settings in which breast-feeding is common. The question of whether infants who are born to HIV-1–infected mothers should receive antiretroviral prophylaxis for the entire duration of breast-feeding needs to be assessed, including analysis of safety, added efficacy, and cost-effectiveness.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 17:44:22", "endTime": "2024/08/13 17:50:48", "cost": 386.112}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 01:50:48", "grab_time": "2024-08-13 01:44:22"}
{"id": 2234508, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "2738bb0f-bae4-4cda-a87d-7c6bb3509b1f", "title": "Reversal by Levodopa of Cholinergic Hypersensitivity in Parkinson's Disease", "text": "【0】Reversal by Levodopa of Cholinergic Hypersensitivity in Parkinson's Disease\nAbstract\n--------\n\n【1】The neurologic manifestations of Parkinson's disease may be derived from an imbalance of the dopaminergic and cholinergic pathways in the central nervous system. Levodopa was found to decrease or block completely the hypersensitivity to cholinergic stimulation in Parkinson's disease as measured by the physostigmine test. Levodopa-treated patients whose neurologic manifestations were no longer aggravated by intravenous physostigmine did not benefit by the addition of standard anticholinergic drugs. Cholinergic hyperactivity in Parkinson's disease may be secondary to decreased brain dopamine.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:02:56", "endTime": "2024/08/14 15:03:05", "cost": 8.553}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 23:03:05", "grab_time": "2024-08-13 23:02:56"}
{"id": 2234507, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "868931f9-3f79-4472-9ab8-8af8c0858622", "title": "Defective Myelopoiesis in Congenital Neutropenia", "text": "【0】Defective Myelopoiesis in Congenital Neutropenia\nAbstract\n--------\n\n【1】Two patients with congenital neutropenia were found to have abnormalities of the immature myeloid cells. These cells were incapable of complete differentiation to a mature stage and also had a substantial reduction in their capacity for cell proliferation. The defect in one patient appeared to be intrinsic to an abnormal cell line, but in the other bone-marrow environmental factors may have contributed to the defect in maturation and proliferation. The surprisingly benign clinical courses may be explained by compensatory defense mechanisms.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 17:03:22", "endTime": "2024/08/13 17:04:00", "cost": 37.543}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 01:04:00", "grab_time": "2024-08-13 01:03:22"}
{"id": 2234506, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "4f48edc3-7cd4-4cdd-a78e-54c09d0b8ecc", "title": "Evidence That Histamine Is the Causative Toxin of Scombroid-Fish Poisoning", "text": "【0】Evidence That Histamine Is the Causative Toxin of Scombroid-Fish Poisoning\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】The highest morbidity worldwide from fish poisoning results from the ingestion of spoiled scombroid fish, such as tuna and mackerel, and its cause is not clear. Histamine could be responsible, because spoiled scombroid fish contain large quantities of histamine. Whether histamine is the causative toxin, however, has remained in question. To address this issue, we investigated whether histamine homeostasis is altered in poisoned people.\n\n【3】Methods.\n--------\n\n【4】The urinary excretion of histamine and its metabolite, N-methylhistamine, was measured in three persons who had scombroid-fish poisoning (scombrotoxism) after the ingestion of marlin. We measured 9α, 11β-dihydroxy-15–oxo–2,3,18,19-tetranorprost-5-ene-1,20-dioic acid (PGD-M), the principal metabolite of prostaglandin D <sub>2 </sub> , a mast-cell secretory product, to assess whether mast cells had been activated to release histamine.\n\n【5】Results.\n--------\n\n【6】The fish contained high levels of histamine (842 to 2503 μmol per 100 g of tissue). Symptoms of scombrotoxism — flushing and headache — began 10 to 30 minutes after the ingestion of fish. In urine samples collected one to four hours after fish ingestion, the levels of histamine and N-methylhistamine were 9 to 20 times and 15 to 20 times the normal mean, respectively. During the subsequent 24 hours, the levels fell to 4 to 15 times and 4 to 11 times the normal values. Levels of both were normal 14 days later. PGD-M excretion was not increased at any time. Two persons treated with diphenhydramine had prompt amelioration of symptoms.\n\n【7】Conclusions.\n------------\n\n【8】Scombroid-fish poisoning is associated with urinary excretion of histamine in quantities far exceeding those required to produce toxicity. The histamine is most likely derived from the spoiled fish. These results identify histamine as the toxin responsible for scombroid-fish poisoning. \n\n【9】Introduction\n------------\n\n【10】SCOMBROID-fish poisoning (scombrotoxism) refers to the clinical syndrome that results from the ingestion of spoiled fish, usually of the families Scombridae and Scomberesocidae. This includes tuna, mackerel, skipjack, and bonito.  However, nonscombroid fish, such as mahi-mahi, bluefish, amberjack, herring, sardines, and anchovies, as well as cheese, have also been implicated as causes of scombrotoxism.  Scombroid-fish poisoning is the most common cause of ichthyotoxicosis worldwide.  In the United States, such poisoning represents one of the major chemical food-borne illnesses reported to the Centers for Disease Control (CDC). \n\n【11】Symptoms of scombroid-fish poisoning usually occur within an hour after the ingestion of spoiled fish and last for several hours.  The symptoms include flushing, sweating, nausea, vomiting, diarrhea, headache, palpitations, dizziness, rash, and occasionally, swelling of the face and tongue. Respiratory distress can also occur, and vasodilatory shock has been noted on occasion. \n\n【12】The cause of scombroid-fish poisoning is not clearly understood. The CDC refers to the causative agent as scombrotoxin.  The toxin is not present when the fish are caught, but it is produced subsequently during spoilage.  Histamine was first suggested as the causative toxin in the 1940s,  on the basis of a number of observations. Fish that have caused scombroid poisoning consistently contain large quantities of histamine.  Scombroid fish contain substantial amounts of free histidine that can be decarboxylated to form histamine by enteric bacteria present in spoiled fish.  <sup>, </sup>  Furthermore, the symptoms of scombroid-fish poisoning resemble those of histamine toxicity, and improvement in symptoms has been reported after treatment with antihistamines. \n\n【13】The chief factor that has cast doubt on the role of histamine in scombroid-fish poisoning is that although it has been possible to produce mild symptoms of histamine excess after the oral administration of the substance in massive doses to humans, it has not been possible to reproduce the illness with doses comparable to the quantities ingested in fish that have caused scombrotoxism.  <sup><a>10 </a></sup>  This may be because histamine is absorbed very poorly from the gastrointestinal tract and because the liver and intestinal mucosa have a great capacity to inactivate histamine.  <sup>, </sup>  These results have led to speculation that substances may be present in the spoiled fish that enhance the pharmacologic activity of histamine, facilitate its absorption, or inhibit its inactivation by histamine _N_ \\-methyltransferase, diamine oxidase, or both.  <sup>, </sup> \n\n【14】The crucial information required to support or refute the speculation that histamine may be the causative toxin of scombroid-fish poisoning — i.e., a direct assessment of whether levels of histamine sufficient to cause toxicity are present in vivo in humans in association with such poisoning — has never been obtained. A recent outbreak of scombroid poisoning at a local cafeteria provided us with the opportunity to address this question.\n\n【15】Methods\n-------\n\n【16】Materials\n---------\n\n【17】\\[  H <sub>4 </sub> \\] Histamine and \\[  H <sub>3 </sub> \\] _N_ \\-methylhistamine were obtained from MSD Isotopes (Montreal). The principal urinary metabolite of prostaglandin D <sub>2 </sub> – 9α, 11-β-dihydroxy-15-oxo-2,3,18,19-tetranorprost-5-ene-1,20-dioic acid (PGD-M) — was synthesized and converted to the \\[  O <sub>4 </sub> \\]-labeled internal standard, as described elsewhere.  <sup>, </sup> \n\n【18】Measurement of Histamine, _N_ \\-Methylhistamine. and PGD-M in Urine\n-------------------------------------------------------------------\n\n【19】Histamine, _N_ \\-methylhistamine, and PGD-M were all measured in urine by highly accurate stable-isotope-dilution mass-spectrometric assays.  <sup><a>16 </a></sup>  The precision and accuracy of the assays were as follows: for histamine, ±3 percent and 98 percent, respectively; for _N_ \\-methylhistamine, ±2 percent and 97 percent; and for PGD-M, ±7 percent and 96 percent. The urinary creatinine concentration was measured by the sodium picrate method with an AutoAnalyzer II (Technicon, Tarrytown, N.Y.). The results of the histamine and _N_ \\-methylhistamine assays were expressed as picomoles per micromole of creatinine, and the results of the PGD-M assay as picomoles per millimole of creatinine. The normal range for each substance was determined by measurements in 20 normal subjects.\n\n【20】Preservation and Handling of the Fish\n-------------------------------------\n\n【21】The marlin implicated in the poisoning incident was caught in Costa Rican waters and flown to Miami. It was shipped to Nashville by refrigerated truck on June 9, 1990. It arrived at the local commercial supplier in Nashville on June 12 and was placed in a walk-in cooler at 1°C. The fish was transported to a local cafeteria on June 14 by refrigerated truck and stored in a walk-in cooler at 7°C. Later that day, the fish was sliced and placed in a reach-in cooler at 9°C. The following morning the fish was cooked and served for lunch. Approximately 50 servings of 100 to 150 g each were prepared, of which 25 were served that day.\n\n【22】In a control study, normal subjects were fed fresh marlin. This fish, obtained on the day of its arrival in Nashville from the same local supplier, was grilled and served immediately after being purchased.\n\n【23】Clinical Study\n--------------\n\n【24】We studied three persons who had symptoms of scombrotoxism after eating the implicated marlin. Each ate one serving of fish. A fourth person, a chief medical resident at Vanderbilt University, recognized an unusual peppery, metallic taste in the fish. Because he knew that this taste was characteristic of fish implicated in scombroid-fish poisoning,  <sup>, </sup>  he ate only a small portion and did not swallow portions that tasted peppery. He had no symptoms of scombrotoxism subsequently. The poisoned persons were two men and one woman, 35, 27, and 25 years of age, respectively. All were healthy, and none had any history of allergic reactions to fish nor were they taking any medications. Three separate urine samples were collected from each of the four persons for measurements of histamine, _N_ \\-methylhistamine, and PGD-M. The first urine sample was obtained one to four hours after the ingestion of fish. The second was a 24-hour collection begun after the collection of the first sample. The third sample was collected for 24 hours 14 days after the poisoning.\n\n【25】The persons studied were all medical personnel at Vanderbilt University. We were made aware of their cases by another physician at the university who recognized that the symptoms were probably due to scombroid-fish poisoning. Subsequently, the cafeteria was informed of the poisoning, and it stopped serving the fish. It was not possible to identify the other persons who had eaten fish at the cafeteria that day to determine whether any of them had had symptoms of poisoning. Unserved portions of fish were seized and sent to the laboratories of the Food and Drug Administration in Atlanta for an analysis of the histamine content by a standard fluorometric method. \n\n【26】In the control study, we also measured the urinary excretion of histamine and _N_ \\-methylhistamine in three normal subjects after the ingestion of fresh marlin. Each subject ate 125 g of cooked fish. Urine samples were obtained for analysis from each person during the 24-hour period before the fish was eaten. After the ingestion of the fish, the first urine sample voided (obtained within the first 4 hours) and a subsequent 24-hour collection were obtained from each subject. Three portions of the fresh marlin were also analyzed for their histamine content.\n\n【27】Results\n-------\n\n【28】Clinical Summary\n----------------\n\n【29】The three affected persons had symptoms of poisoning that began 10 to 30 minutes after ingestion of the fish and consisted of severe headache, mild nausea, and intense flushing, most notably in the face. One person also had severe diarrhea of sudden onset. One of the three sought care in the Vanderbilt Hospital emergency room and received diphenhydramine (50 mg intramuscularly) that resulted in an amelioration of symptoms within 30 minutes. A second person, a physician, administered diphenhydramine (50 mg intramuscularly) to himself, which also resulted in rapid improvement in symptoms within approximately 30 minutes. The third person did not receive an antihistamine. His symptoms abated after approximately three hours.\n\n【30】In the control study, none of the three subjects who ate fresh marlin had symptoms of scombrotoxism.\n\n【31】Histamine Content of the Ingested Fish\n--------------------------------------\n\n【32】The FDA's analysis of the four random samples of the batch of fish implicated in the poisoning revealed levels of 2495, 1456, 842, and 2503 μmol of histamine per 100 g of fish. Although marlin is a nonscombroid fish and has not previously been reported to cause scombroid poisoning, the histamine content of the fish was very high. The FDA has established a hazard level for poisoning from tuna that contains histamine in concentrations above 450 μmol per 100 g  ; fresh tuna contains less than 9 μmol per 100 g.  The histamine content of the fresh marlin that did not cause symptoms of poisoning was undetectable (<4.5 μmol per 100 g).\n\n【33】Urinary Excretion of Histamine and _N_ \\-Methylhistamine\n--------------------------------------------------------\n\n【34】Figure 1. Urinary Excretion of N-Methylhistamine, Histamine, and PGD-M in Three Persons with Scombrotoxism.\n\n【35】The first urine voided was collected between 1 and 4 hours after the poisoning, followed immediately by a 24-hour collection and then by a second 24-hour collection 14 days after the poisoning. Each person is indicated by a different symbol. The horizontal lines indicate the normal means +2 SD.\n\n【36】Initially, we examined whether the ingestion of the fish resulted in the absorption of substantial amounts of histamine or its metabolites by measuring the urinary excretion of the histamine metabolite _N_ \\-methylhistamine . The urinary levels of _N_ \\-methylhistamine were normal in the urine samples collected from the three persons 14 days after the poisoning. The levels were much higher, however, in the urine samples collected during the symptomatic phase of scombrotoxism in each of these three persons. The initial samples collected one to four hours after the ingestion of the fish contained levels of _N_ \\-methylhistamine 15 to 20 times the normal mean. In the samples collected during the subsequent 24 hours, the levels were still elevated but to a lesser extent, ranging from 4 to 11 times the normal mean.\n\n【37】Thus, the ingestion of the fish resulted in substantially increased urinary excretion of _N_ \\-methylhistamine. These results do not prove, however, that systemic concentrations of free histamine were also elevated, since ingested histamine could have been metabolized in the intestinal mucosa and liver before entering the systemic circulation.  To address this question, we measured the urinary excretion of histamine in the same urine samples. Fourteen days after poisoning, the urinary excretion of histamine in each of the three poisoned persons was normal. However, as we found for the urinary excretion of _N_ \\-methylhistamine, the levels of histamine were elevated in the urine samples collected immediately after the ingestion of the fish. In the urine samples collected between one and four hours after the ingestion of the fish, the levels of histamine were 9 to 20 times the normal mean. In the samples collected during the subsequent 24-hour period, these levels had fallen to 4 to 15 times the normal mean .\n\n【38】Table 1. Urinary Excretion of Histamine and N-Methylhistamine in the Person Who Ate Only a Small Quantity of the Marlin Implicated in the Poisoning and Did Not Have Scombrotoxism. Table 2.  Table 2. Urinary Excretion of Histamine and N-Methylhistamine in Three Control Subjects Who Ate Fresh Marlin Containing No Detectable Histamine.\n\n【39】As previously mentioned, one person recognized the peppery, metallic taste of spoiled scombroid fish and thus ate only a small portion of the serving. This person had no symptoms of scombrotoxism, and the urinary levels of both histamine and _N_ \\-methylhistamine were normal both in the urine sample collected soon after the meal and in that collected during the subsequent 24 hours . Hence, only those persons in whom scombrotoxism developed had increased circulating concentrations of histamine after ingesting the spoiled fish. In addition, the urinary excretion of both histamine and _N_ \\-methylhistamine remained normal in the three control subjects who ate fresh marlin that contained undetectable quantities of histamine and that did not produce symptoms of poisoning .\n\n【40】Assessment of PGD-M Excretion\n-----------------------------\n\n【41】The increased urinary excretion of histamine in the affected persons could have been due to the ingestion of histamine contained in the fish or the ingestion of other substances present in the fish that evoked the release of endogenous histamine from tissue mast cells. The latter, if it occurs, is unlikely to involve an allergic IgE-dependent mechanism of mast-cell activation, since all persons who eat spoiled scombroid fish have symptoms of poisoning.  We and others have found that mast cells activated by either IgE-dependent or independent mechanisms in vitro and in vivo release prostaglandin D <sub>2 </sub> along with histamine.  <sup><a>22 </a></sup>  <sup><a>24 </a></sup>  <sup><a>26 </a></sup> Therefore, we examined whether there was evidence of increased release of prostaglandin D <sub>2 </sub> in the poisoned persons by measuring the urinary excretion of PGD-M. In contrast to the increased urinary excretion of histamine and _N_ \\-methylhistamine, the excretion of PGD-M was normal in all three urine samples from each of the three persons .\n\n【42】Discussion\n----------\n\n【43】Histamine was suggested approximately 50 years ago as the causative agent of scombrotoxism, but its role has remained in question. One reason for the lingering doubt is that it has been impossible to reproduce the illness in normal subjects by administering histamine orally in doses comparable to those ingested when spoiled fish is eaten.  <sup>, </sup>  The crucial information required to resolve this question has not been obtained — namely, whether scombroid-fish poisoning is associated with sufficient increases in circulating histamine to cause toxicity. Our results document clearly that this does indeed occur. The urinary levels of histamine in the affected persons far exceeded those associated with symptoms of histamine excess. Kaliner and colleagues found that the urinary excretion of histamine during intravenous infusions of histamine in doses that resulted in flushing, headache, and tachycardia was approximately 34 nmol per hour, or 92 pmol per micromole of creatinine on the basis of an hourly rate of excretion of creatinine of 370 μmol.  When first measured, the urinary histamine levels in the three poisoned persons were all higher than 200 pmol per micromole of creatinine .\n\n【44】Whether potentiators of histamine toxicity were present in the spoiled scombroid fish is unknown.  <sup>, </sup>  It is noteworthy, however, that the increases in the urinary excretion of both histamine and _N_ \\-methylhistamine in the poisoned persons were of similar magnitude. Thus, it is probably valid to conclude that the spoiled fish did not contain substances that potentiated histamine toxicity by inhibiting its inactivation by histamine _N_ \\-methyltransferase.\n\n【45】The failure to find increased endogenous release of prostaglandin D <sub>2 </sub> in association with increased levels of histamine suggests that the source of the excess histamine was the fish rather than the release of histamine from mast cells. This is further supported by the finding that the ingestion of fresh marlin containing undetectable quantities of histamine did not result in increased urinary excretion of histamine. Although it is unlikely, we cannot exclude the possibility that other unknown substances may be present in spoiled fish that selectively release histamine but not prostaglandin D <sub>2 </sub> from mast cells or that selectively activate basophils, which do not produce prostaglandin D <sub>2 </sub> , to release histamine.  <sup><a>29 </a></sup>  <sup><a>31 </a></sup> Whether histamine is derived from exogenous or endogenous sources, however, does not influence the conclusion that it is the causative toxin of scombroid-fish poisoning.\n\n【46】The identification of histamine as the causative agent of scombrotoxism should serve as the basis for a general public health policy recommendation that persons with scombroid poisoning receive treatment with an antihistamine. Symptoms usually improve with the administration of H <sub>1 </sub> \\-receptor—antagonist drugs.  The two persons in our study who took diphenhydramine also had rapid amelioration of symptoms. A single report has also described symptomatic improvement after the administration of an H <sub>2 </sub> \\-antagonist drug.  We and others have demonstrated previously that blood vessels in humans have H <sub>2 </sub> receptors and that blocking the vascular effects of histamine requires the blockade of both H <sub>1 </sub> and H <sub>2 </sub> receptors.  <sup>, </sup>  Thus, there is a rational basis for recommending that persons with scombroid poisoning be treated with antagonists to both H <sub>1 </sub> and H <sub>2 </sub> receptors in combination.\n\n【47】We conclude that histamine is the toxin responsible for scombroid-fish poisoning. Such poisoning can be prevented effectively by handling and refrigerating fish appropriately.  If warming occurs at any point from the time the fish is caught until it is consumed, bacterial proliferation can lead to the production of histamine in quantities sufficient to cause poisoning in the absence of obvious putrefaction.  For these reasons, scombroid-fish poisoning will probably continue to be one of the most common causes of ichthyotoxicosis.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "diamine oxidase, or both.  , ", "content": "【0】Evidence That Histamine Is the Causative Toxin of Scombroid-Fish Poisoning\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】The highest morbidity worldwide from fish poisoning results from the ingestion of spoiled scombroid fish, such as tuna and mackerel, and its cause is not clear. Histamine could be responsible, because spoiled scombroid fish contain large quantities of histamine. Whether histamine is the causative toxin, however, has remained in question. To address this issue, we investigated whether histamine homeostasis is altered in poisoned people.\n\n【3】Methods.\n--------\n\n【4】The urinary excretion of histamine and its metabolite, N-methylhistamine, was measured in three persons who had scombroid-fish poisoning (scombrotoxism) after the ingestion of marlin. We measured 9α, 11β-dihydroxy-15–oxo–2,3,18,19-tetranorprost-5-ene-1,20-dioic acid (PGD-M), the principal metabolite of prostaglandin D <sub>2 </sub> , a mast-cell secretory product, to assess whether mast cells had been activated to release histamine.\n\n【5】Results.\n--------\n\n【6】The fish contained high levels of histamine (842 to 2503 μmol per 100 g of tissue). Symptoms of scombrotoxism — flushing and headache — began 10 to 30 minutes after the ingestion of fish. In urine samples collected one to four hours after fish ingestion, the levels of histamine and N-methylhistamine were 9 to 20 times and 15 to 20 times the normal mean, respectively. During the subsequent 24 hours, the levels fell to 4 to 15 times and 4 to 11 times the normal values. Levels of both were normal 14 days later. PGD-M excretion was not increased at any time. Two persons treated with diphenhydramine had prompt amelioration of symptoms.\n\n【7】Conclusions.\n------------\n\n【8】Scombroid-fish poisoning is associated with urinary excretion of histamine in quantities far exceeding those required to produce toxicity. The histamine is most likely derived from the spoiled fish. These results identify histamine as the toxin responsible for scombroid-fish poisoning. \n\n【9】Introduction\n------------\n\n【10】SCOMBROID-fish poisoning (scombrotoxism) refers to the clinical syndrome that results from the ingestion of spoiled fish, usually of the families Scombridae and Scomberesocidae. This includes tuna, mackerel, skipjack, and bonito.  However, nonscombroid fish, such as mahi-mahi, bluefish, amberjack, herring, sardines, and anchovies, as well as cheese, have also been implicated as causes of scombrotoxism.  Scombroid-fish poisoning is the most common cause of ichthyotoxicosis worldwide.  In the United States, such poisoning represents one of the major chemical food-borne illnesses reported to the Centers for Disease Control (CDC). \n\n【11】Symptoms of scombroid-fish poisoning usually occur within an hour after the ingestion of spoiled fish and last for several hours.  The symptoms include flushing, sweating, nausea, vomiting, diarrhea, headache, palpitations, dizziness, rash, and occasionally, swelling of the face and tongue. Respiratory distress can also occur, and vasodilatory shock has been noted on occasion. \n\n【12】The cause of scombroid-fish poisoning is not clearly understood. The CDC refers to the causative agent as scombrotoxin.  The toxin is not present when the fish are caught, but it is produced subsequently during spoilage.  Histamine was first suggested as the causative toxin in the 1940s,  on the basis of a number of observations. Fish that have caused scombroid poisoning consistently contain large quantities of histamine.  Scombroid fish contain substantial amounts of free histidine that can be decarboxylated to form histamine by enteric bacteria present in spoiled fish.  <sup>, </sup>  Furthermore, the symptoms of scombroid-fish poisoning resemble those of histamine toxicity, and improvement in symptoms has been reported after treatment with antihistamines. \n\n【13】The chief factor that has cast doubt on the role of histamine in scombroid-fish poisoning is that although it has been possible to produce mild symptoms of histamine excess after the oral administration of the substance in massive doses to humans, it has not been possible to reproduce the illness with doses comparable to the quantities ingested in fish that have caused scombrotoxism.  <sup><a>10 </a></sup>  This may be because histamine is absorbed very poorly from the gastrointestinal tract and because the liver and intestinal mucosa have a great capacity to inactivate histamine.  <sup>, </sup>  These results have led to speculation that substances may be present in the spoiled fish that enhance the pharmacologic activity of histamine, facilitate its absorption, or inhibit its inactivation by histamine _N_ \\-methyltransferase, diamine oxidase, or both.  <sup>, </sup> \n\n【14】The crucial information required to support or refute the speculation that histamine may be the causative toxin of scombroid-fish poisoning — i.e., a direct assessment of whether levels of histamine sufficient to cause toxicity are present in vivo in humans in association with such poisoning — has never been obtained. A recent outbreak of scombroid poisoning at a local cafeteria provided us with the opportunity to address this question.\n\n【15】Methods\n-------\n\n【16】Materials\n---------\n\n【17】\\[  H <sub>4 </sub> \\] Histamine and \\[  H <sub>3 </sub> \\] _N_ \\-methylhistamine were obtained from MSD Isotopes (Montreal). The principal urinary metabolite of prostaglandin D <sub>2 </sub> – 9α, 11-β-dihydroxy-15-oxo-2,3,18,19-tetranorprost-5-ene-1,20-dioic acid (PGD-M) — was synthesized and converted to the \\[  O <sub>4 </sub> \\]-labeled internal standard, as described elsewhere.  <sup>, </sup> \n\n【18】Measurement of Histamine, _N_ \\-Methylhistamine. and PGD-M in Urine\n-------------------------------------------------------------------\n\n【19】Histamine, _N_ \\-methylhistamine, and PGD-M were all measured in urine by highly accurate stable-isotope-dilution mass-spectrometric assays.  <sup><a>16 </a></sup>  The precision and accuracy of the assays were as follows: for histamine, ±3 percent and 98 percent, respectively; for _N_ \\-methylhistamine, ±2 percent and 97 percent; and for PGD-M, ±7 percent and 96 percent. The urinary creatinine concentration was measured by the sodium picrate method with an AutoAnalyzer II (Technicon, Tarrytown, N.Y.). The results of the histamine and _N_ \\-methylhistamine assays were expressed as picomoles per micromole of creatinine, and the results of the PGD-M assay as picomoles per millimole of creatinine. The normal range for each substance was determined by measurements in 20 normal subjects.\n\n【20】Preservation and Handling of the Fish\n-------------------------------------\n\n【21】The marlin implicated in the poisoning incident was caught in Costa Rican waters and flown to Miami. It was shipped to Nashville by refrigerated truck on June 9, 1990. It arrived at the local commercial supplier in Nashville on June 12 and was placed in a walk-in cooler at 1°C. The fish was transported to a local cafeteria on June 14 by refrigerated truck and stored in a walk-in cooler at 7°C. Later that day, the fish was sliced and placed in a reach-in cooler at 9°C. The following morning the fish was cooked and served for lunch. Approximately 50 servings of 100 to 150 g each were prepared, of which 25 were served that day.\n\n【22】In a control study, normal subjects were fed fresh marlin. This fish, obtained on the day of its arrival in Nashville from the same local supplier, was grilled and served immediately after being purchased.\n\n【23】Clinical Study\n--------------\n\n【24】We studied three persons who had symptoms of scombrotoxism after eating the implicated marlin. Each ate one serving of fish. A fourth person, a chief medical resident at Vanderbilt University, recognized an unusual peppery, metallic taste in the fish. Because he knew that this taste was characteristic of fish implicated in scombroid-fish poisoning,  <sup>, </sup>  he ate only a small portion and did not swallow portions that tasted peppery. He had no symptoms of scombrotoxism subsequently. The poisoned persons were two men and one woman, 35, 27, and 25 years of age, respectively. All were healthy, and none had any history of allergic reactions to fish nor were they taking any medications. Three separate urine samples were collected from each of the four persons for measurements of histamine, _N_ \\-methylhistamine, and PGD-M. The first urine sample was obtained one to four hours after the ingestion of fish. The second was a 24-hour collection begun after the collection of the first sample. The third sample was collected for 24 hours 14 days after the poisoning.\n\n【25】The persons studied were all medical personnel at Vanderbilt University. We were made aware of their cases by another physician at the university who recognized that the symptoms were probably due to scombroid-fish poisoning. Subsequently, the cafeteria was informed of the poisoning, and it stopped serving the fish. It was not possible to identify the other persons who had eaten fish at the cafeteria that day to determine whether any of them had had symptoms of poisoning. Unserved portions of fish were seized and sent to the laboratories of the Food and Drug Administration in Atlanta for an analysis of the histamine content by a standard fluorometric method. \n\n【26】In the control study, we also measured the urinary excretion of histamine and _N_ \\-methylhistamine in three normal subjects after the ingestion of fresh marlin. Each subject ate 125 g of cooked fish. Urine samples were obtained for analysis from each person during the 24-hour period before the fish was eaten. After the ingestion of the fish, the first urine sample voided (obtained within the first 4 hours) and a subsequent 24-hour collection were obtained from each subject. Three portions of the fresh marlin were also analyzed for their histamine content.\n\n【27】Results\n-------\n\n【28】Clinical Summary\n----------------\n\n【29】The three affected persons had symptoms of poisoning that began 10 to 30 minutes after ingestion of the fish and consisted of severe headache, mild nausea, and intense flushing, most notably in the face. One person also had severe diarrhea of sudden onset. One of the three sought care in the Vanderbilt Hospital emergency room and received diphenhydramine (50 mg intramuscularly) that resulted in an amelioration of symptoms within 30 minutes. A second person, a physician, administered diphenhydramine (50 mg intramuscularly) to himself, which also resulted in rapid improvement in symptoms within approximately 30 minutes. The third person did not receive an antihistamine. His symptoms abated after approximately three hours.\n\n【30】In the control study, none of the three subjects who ate fresh marlin had symptoms of scombrotoxism.\n\n【31】Histamine Content of the Ingested Fish\n--------------------------------------\n\n【32】The FDA's analysis of the four random samples of the batch of fish implicated in the poisoning revealed levels of 2495, 1456, 842, and 2503 μmol of histamine per 100 g of fish. Although marlin is a nonscombroid fish and has not previously been reported to cause scombroid poisoning, the histamine content of the fish was very high. The FDA has established a hazard level for poisoning from tuna that contains histamine in concentrations above 450 μmol per 100 g  ; fresh tuna contains less than 9 μmol per 100 g.  The histamine content of the fresh marlin that did not cause symptoms of poisoning was undetectable (<4.5 μmol per 100 g).\n\n【33】Urinary Excretion of Histamine and _N_ \\-Methylhistamine\n--------------------------------------------------------\n\n【34】Figure 1. Urinary Excretion of N-Methylhistamine, Histamine, and PGD-M in Three Persons with Scombrotoxism.\n\n【35】The first urine voided was collected between 1 and 4 hours after the poisoning, followed immediately by a 24-hour collection and then by a second 24-hour collection 14 days after the poisoning. Each person is indicated by a different symbol. The horizontal lines indicate the normal means +2 SD.\n\n【36】Initially, we examined whether the ingestion of the fish resulted in the absorption of substantial amounts of histamine or its metabolites by measuring the urinary excretion of the histamine metabolite _N_ \\-methylhistamine . The urinary levels of _N_ \\-methylhistamine were normal in the urine samples collected from the three persons 14 days after the poisoning. The levels were much higher, however, in the urine samples collected during the symptomatic phase of scombrotoxism in each of these three persons. The initial samples collected one to four hours after the ingestion of the fish contained levels of _N_ \\-methylhistamine 15 to 20 times the normal mean. In the samples collected during the subsequent 24 hours, the levels were still elevated but to a lesser extent, ranging from 4 to 11 times the normal mean.\n\n【37】Thus, the ingestion of the fish resulted in substantially increased urinary excretion of _N_ \\-methylhistamine. These results do not prove, however, that systemic concentrations of free histamine were also elevated, since ingested histamine could have been metabolized in the intestinal mucosa and liver before entering the systemic circulation.  To address this question, we measured the urinary excretion of histamine in the same urine samples. Fourteen days after poisoning, the urinary excretion of histamine in each of the three poisoned persons was normal. However, as we found for the urinary excretion of _N_ \\-methylhistamine, the levels of histamine were elevated in the urine samples collected immediately after the ingestion of the fish. In the urine samples collected between one and four hours after the ingestion of the fish, the levels of histamine were 9 to 20 times the normal mean. In the samples collected during the subsequent 24-hour period, these levels had fallen to 4 to 15 times the normal mean .\n\n【38】Table 1. Urinary Excretion of Histamine and N-Methylhistamine in the Person Who Ate Only a Small Quantity of the Marlin Implicated in the Poisoning and Did Not Have Scombrotoxism. Table 2.  Table 2. Urinary Excretion of Histamine and N-Methylhistamine in Three Control Subjects Who Ate Fresh Marlin Containing No Detectable Histamine.\n\n【39】As previously mentioned, one person recognized the peppery, metallic taste of spoiled scombroid fish and thus ate only a small portion of the serving. This person had no symptoms of scombrotoxism, and the urinary levels of both histamine and _N_ \\-methylhistamine were normal both in the urine sample collected soon after the meal and in that collected during the subsequent 24 hours . Hence, only those persons in whom scombrotoxism developed had increased circulating concentrations of histamine after ingesting the spoiled fish. In addition, the urinary excretion of both histamine and _N_ \\-methylhistamine remained normal in the three control subjects who ate fresh marlin that contained undetectable quantities of histamine and that did not produce symptoms of poisoning .\n\n【40】Assessment of PGD-M Excretion\n-----------------------------\n\n【41】The increased urinary excretion of histamine in the affected persons could have been due to the ingestion of histamine contained in the fish or the ingestion of other substances present in the fish that evoked the release of endogenous histamine from tissue mast cells. The latter, if it occurs, is unlikely to involve an allergic IgE-dependent mechanism of mast-cell activation, since all persons who eat spoiled scombroid fish have symptoms of poisoning.  We and others have found that mast cells activated by either IgE-dependent or independent mechanisms in vitro and in vivo release prostaglandin D <sub>2 </sub> along with histamine.  <sup><a>22 </a></sup>  <sup><a>24 </a></sup>  <sup><a>26 </a></sup> Therefore, we examined whether there was evidence of increased release of prostaglandin D <sub>2 </sub> in the poisoned persons by measuring the urinary excretion of PGD-M. In contrast to the increased urinary excretion of histamine and _N_ \\-methylhistamine, the excretion of PGD-M was normal in all three urine samples from each of the three persons .\n\n【42】Discussion\n----------\n\n【43】Histamine was suggested approximately 50 years ago as the causative agent of scombrotoxism, but its role has remained in question. One reason for the lingering doubt is that it has been impossible to reproduce the illness in normal subjects by administering histamine orally in doses comparable to those ingested when spoiled fish is eaten.  <sup>, </sup>  The crucial information required to resolve this question has not been obtained — namely, whether scombroid-fish poisoning is associated with sufficient increases in circulating histamine to cause toxicity. Our results document clearly that this does indeed occur. The urinary levels of histamine in the affected persons far exceeded those associated with symptoms of histamine excess. Kaliner and colleagues found that the urinary excretion of histamine during intravenous infusions of histamine in doses that resulted in flushing, headache, and tachycardia was approximately 34 nmol per hour, or 92 pmol per micromole of creatinine on the basis of an hourly rate of excretion of creatinine of 370 μmol.  When first measured, the urinary histamine levels in the three poisoned persons were all higher than 200 pmol per micromole of creatinine .\n\n【44】Whether potentiators of histamine toxicity were present in the spoiled scombroid fish is unknown.  <sup>, </sup>  It is noteworthy, however, that the increases in the urinary excretion of both histamine and _N_ \\-methylhistamine in the poisoned persons were of similar magnitude. Thus, it is probably valid to conclude that the spoiled fish did not contain substances that potentiated histamine toxicity by inhibiting its inactivation by histamine _N_ \\-methyltransferase.\n\n【45】The failure to find increased endogenous release of prostaglandin D <sub>2 </sub> in association with increased levels of histamine suggests that the source of the excess histamine was the fish rather than the release of histamine from mast cells. This is further supported by the finding that the ingestion of fresh marlin containing undetectable quantities of histamine did not result in increased urinary excretion of histamine. Although it is unlikely, we cannot exclude the possibility that other unknown substances may be present in spoiled fish that selectively release histamine but not prostaglandin D <sub>2 </sub> from mast cells or that selectively activate basophils, which do not produce prostaglandin D <sub>2 </sub> , to release histamine.  <sup><a>29 </a></sup>  <sup><a>31 </a></sup> Whether histamine is derived from exogenous or endogenous sources, however, does not influence the conclusion that it is the causative toxin of scombroid-fish poisoning.\n\n【46】The identification of histamine as the causative agent of scombrotoxism should serve as the basis for a general public health policy recommendation that persons with scombroid poisoning receive treatment with an antihistamine. Symptoms usually improve with the administration of H <sub>1 </sub> \\-receptor—antagonist drugs.  The two persons in our study who took diphenhydramine also had rapid amelioration of symptoms. A single report has also described symptomatic improvement after the administration of an H <sub>2 </sub> \\-antagonist drug.  We and others have demonstrated previously that blood vessels in humans have H <sub>2 </sub> receptors and that blocking the vascular effects of histamine requires the blockade of both H <sub>1 </sub> and H <sub>2 </sub> receptors.  <sup>, </sup>  Thus, there is a rational basis for recommending that persons with scombroid poisoning be treated with antagonists to both H <sub>1 </sub> and H <sub>2 </sub> receptors in combination.\n\n【47】We conclude that histamine is the toxin responsible for scombroid-fish poisoning. Such poisoning can be prevented effectively by handling and refrigerating fish appropriately.  If warming occurs at any point from the time the fish is caught until it is consumed, bacterial proliferation can lead to the production of histamine in quantities sufficient to cause poisoning in the absence of obvious putrefaction.  For these reasons, scombroid-fish poisoning will probably continue to be one of the most common causes of ichthyotoxicosis.", "index": 20, "show": true, "start": 20, "end": 49, "province": ["格式规范性", "多余标点"], "isEdit": false}, {"text": " 10   ", "content": "【0】Evidence That His<mark>diamine oxidase, or both.  , </mark> of Scombroid-Fish Poisoning\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】The highest morbidity worldwide from fish poisoning results from the ingestion of spoiled scombroid fish, such as tuna and mackerel, and its cause is not clear. Histamine could be responsible, because spoiled scombroid fish contain large quantities of histamine. Whether histamine is the causative toxin, however, has remained in question. To address this issue, we investigated whether histamine homeostasis is altered in poisoned people.\n\n【3】Methods.\n--------\n\n【4】The urinary excretion of histamine and its metabolite, N-methylhistamine, was measured in three persons who had scombroid-fish poisoning (scombrotoxism) after the ingestion of marlin. We measured 9α, 11β-dihydroxy-15–oxo–2,3,18,19-tetranorprost-5-ene-1,20-dioic acid (PGD-M), the principal metabolite of prostaglandin D <sub>2 </sub> , a mast-cell secretory product, to assess whether mast cells had been activated to release histamine.\n\n【5】Results.\n--------\n\n【6】The fish contained high levels of histamine (842 to 2503 μmol per 100 g of tissue). Symptoms of scombrotoxism — flushing and headache — began 10 to 30 minutes after the ingestion of fish. In urine samples collected one to four hours after fish ingestion, the levels of histamine and N-methylhistamine were 9 to 20 times and 15 to 20 times the normal mean, respectively. During the subsequent 24 hours, the levels fell to 4 to 15 times and 4 to 11 times the normal values. Levels of both were normal 14 days later. PGD-M excretion was not increased at any time. Two persons treated with diphenhydramine had prompt amelioration of symptoms.\n\n【7】Conclusions.\n------------\n\n【8】Scombroid-fish poisoning is associated with urinary excretion of histamine in quantities far exceeding those required to produce toxicity. The histamine is most likely derived from the spoiled fish. These results identify histamine as the toxin responsible for scombroid-fish poisoning. \n\n【9】Introduction\n------------\n\n【10】SCOMBROID-fish poisoning (scombrotoxism) refers to the clinical syndrome that results from the ingestion of spoiled fish, usually of the families Scombridae and Scomberesocidae. This includes tuna, mackerel, skipjack, and bonito.  However, nonscombroid fish, such as mahi-mahi, bluefish, amberjack, herring, sardines, and anchovies, as well as cheese, have also been implicated as causes of scombrotoxism.  Scombroid-fish poisoning is the most common cause of ichthyotoxicosis worldwide.  In the United States, such poisoning represents one of the major chemical food-borne illnesses reported to the Centers for Disease Control (CDC). \n\n【11】Symptoms of scombroid-fish poisoning usually occur within an hour after the ingestion of spoiled fish and last for several hours.  The symptoms include flushing, sweating, nausea, vomiting, diarrhea, headache, palpitations, dizziness, rash, and occasionally, swelling of the face and tongue. Respiratory distress can also occur, and vasodilatory shock has been noted on occasion. \n\n【12】The cause of scombroid-fish poisoning is not clearly understood. The CDC refers to the causative agent as scombrotoxin.  The toxin is not present when the fish are caught, but it is produced subsequently during spoilage.  Histamine was first suggested as the causative toxin in the 1940s,  on the basis of a number of observations. Fish that have caused scombroid poisoning consistently contain large quantities of histamine.  Scombroid fish contain substantial amounts of free histidine that can be decarboxylated to form histamine by enteric bacteria present in spoiled fish.  <sup>, </sup>  Furthermore, the symptoms of scombroid-fish poisoning resemble those of histamine toxicity, and improvement in symptoms has been reported after treatment with antihistamines. \n\n【13】The chief factor that has cast doubt on the role of histamine in scombroid-fish poisoning is that although it has been possible to produce mild symptoms of histamine excess after the oral administration of the substance in massive doses to humans, it has not been possible to reproduce the illness with doses comparable to the quantities ingested in fish that have caused scombrotoxism.  <sup><a>10 </a></sup>  This may be because histamine is absorbed very poorly from the gastrointestinal tract and because the liver and intestinal mucosa have a great capacity to inactivate histamine.  <sup>, </sup>  These results have led to speculation that substances may be present in the spoiled fish that enhance the pharmacologic activity of histamine, facilitate its absorption, or inhibit its inactivation by histamine _N_ \\-methyltransferase, diamine oxidase, or both.  <sup>, </sup> \n\n【14】The crucial information required to support or refute the speculation that histamine may be the causative toxin of scombroid-fish poisoning — i.e., a direct assessment of whether levels of histamine sufficient to cause toxicity are present in vivo in humans in association with such poisoning — has never been obtained. A recent outbreak of scombroid poisoning at a local cafeteria provided us with the opportunity to address this question.\n\n【15】Methods\n-------\n\n【16】Materials\n---------\n\n【17】\\[  H <sub>4 </sub> \\] Histamine and \\[  H <sub>3 </sub> \\] _N_ \\-methylhistamine were obtained from MSD Isotopes (Montreal). The principal urinary metabolite of prostaglandin D <sub>2 </sub> – 9α, 11-β-dihydroxy-15-oxo-2,3,18,19-tetranorprost-5-ene-1,20-dioic acid (PGD-M) — was synthesized and converted to the \\[  O <sub>4 </sub> \\]-labeled internal standard, as described elsewhere.  <sup>, </sup> \n\n【18】Measurement of Histamine, _N_ \\-Methylhistamine. and PGD-M in Urine\n-------------------------------------------------------------------\n\n【19】Histamine, _N_ \\-methylhistamine, and PGD-M were all measured in urine by highly accurate stable-isotope-dilution mass-spectrometric assays.  <sup><a>16 </a></sup>  The precision and accuracy of the assays were as follows: for histamine, ±3 percent and 98 percent, respectively; for _N_ \\-methylhistamine, ±2 percent and 97 percent; and for PGD-M, ±7 percent and 96 percent. The urinary creatinine concentration was measured by the sodium picrate method with an AutoAnalyzer II (Technicon, Tarrytown, N.Y.). The results of the histamine and _N_ \\-methylhistamine assays were expressed as picomoles per micromole of creatinine, and the results of the PGD-M assay as picomoles per millimole of creatinine. The normal range for each substance was determined by measurements in 20 normal subjects.\n\n【20】Preservation and Handling of the Fish\n-------------------------------------\n\n【21】The marlin implicated in the poisoning incident was caught in Costa Rican waters and flown to Miami. It was shipped to Nashville by refrigerated truck on June 9, 1990. It arrived at the local commercial supplier in Nashville on June 12 and was placed in a walk-in cooler at 1°C. The fish was transported to a local cafeteria on June 14 by refrigerated truck and stored in a walk-in cooler at 7°C. Later that day, the fish was sliced and placed in a reach-in cooler at 9°C. The following morning the fish was cooked and served for lunch. Approximately 50 servings of 100 to 150 g each were prepared, of which 25 were served that day.\n\n【22】In a control study, normal subjects were fed fresh marlin. This fish, obtained on the day of its arrival in Nashville from the same local supplier, was grilled and served immediately after being purchased.\n\n【23】Clinical Study\n--------------\n\n【24】We studied three persons who had symptoms of scombrotoxism after eating the implicated marlin. Each ate one serving of fish. A fourth person, a chief medical resident at Vanderbilt University, recognized an unusual peppery, metallic taste in the fish. Because he knew that this taste was characteristic of fish implicated in scombroid-fish poisoning,  <sup>, </sup>  he ate only a small portion and did not swallow portions that tasted peppery. He had no symptoms of scombrotoxism subsequently. The poisoned persons were two men and one woman, 35, 27, and 25 years of age, respectively. All were healthy, and none had any history of allergic reactions to fish nor were they taking any medications. Three separate urine samples were collected from each of the four persons for measurements of histamine, _N_ \\-methylhistamine, and PGD-M. The first urine sample was obtained one to four hours after the ingestion of fish. The second was a 24-hour collection begun after the collection of the first sample. The third sample was collected for 24 hours 14 days after the poisoning.\n\n【25】The persons studied were all medical personnel at Vanderbilt University. We were made aware of their cases by another physician at the university who recognized that the symptoms were probably due to scombroid-fish poisoning. Subsequently, the cafeteria was informed of the poisoning, and it stopped serving the fish. It was not possible to identify the other persons who had eaten fish at the cafeteria that day to determine whether any of them had had symptoms of poisoning. Unserved portions of fish were seized and sent to the laboratories of the Food and Drug Administration in Atlanta for an analysis of the histamine content by a standard fluorometric method. \n\n【26】In the control study, we also measured the urinary excretion of histamine and _N_ \\-methylhistamine in three normal subjects after the ingestion of fresh marlin. Each subject ate 125 g of cooked fish. Urine samples were obtained for analysis from each person during the 24-hour period before the fish was eaten. After the ingestion of the fish, the first urine sample voided (obtained within the first 4 hours) and a subsequent 24-hour collection were obtained from each subject. Three portions of the fresh marlin were also analyzed for their histamine content.\n\n【27】Results\n-------\n\n【28】Clinical Summary\n----------------\n\n【29】The three affected persons had symptoms of poisoning that began 10 to 30 minutes after ingestion of the fish and consisted of severe headache, mild nausea, and intense flushing, most notably in the face. One person also had severe diarrhea of sudden onset. One of the three sought care in the Vanderbilt Hospital emergency room and received diphenhydramine (50 mg intramuscularly) that resulted in an amelioration of symptoms within 30 minutes. A second person, a physician, administered diphenhydramine (50 mg intramuscularly) to himself, which also resulted in rapid improvement in symptoms within approximately 30 minutes. The third person did not receive an antihistamine. His symptoms abated after approximately three hours.\n\n【30】In the control study, none of the three subjects who ate fresh marlin had symptoms of scombrotoxism.\n\n【31】Histamine Content of the Ingested Fish\n--------------------------------------\n\n【32】The FDA's analysis of the four random samples of the batch of fish implicated in the poisoning revealed levels of 2495, 1456, 842, and 2503 μmol of histamine per 100 g of fish. Although marlin is a nonscombroid fish and has not previously been reported to cause scombroid poisoning, the histamine content of the fish was very high. The FDA has established a hazard level for poisoning from tuna that contains histamine in concentrations above 450 μmol per 100 g  ; fresh tuna contains less than 9 μmol per 100 g.  The histamine content of the fresh marlin that did not cause symptoms of poisoning was undetectable (<4.5 μmol per 100 g).\n\n【33】Urinary Excretion of Histamine and _N_ \\-Methylhistamine\n--------------------------------------------------------\n\n【34】Figure 1. Urinary Excretion of N-Methylhistamine, Histamine, and PGD-M in Three Persons with Scombrotoxism.\n\n【35】The first urine voided was collected between 1 and 4 hours after the poisoning, followed immediately by a 24-hour collection and then by a second 24-hour collection 14 days after the poisoning. Each person is indicated by a different symbol. The horizontal lines indicate the normal means +2 SD.\n\n【36】Initially, we examined whether the ingestion of the fish resulted in the absorption of substantial amounts of histamine or its metabolites by measuring the urinary excretion of the histamine metabolite _N_ \\-methylhistamine . The urinary levels of _N_ \\-methylhistamine were normal in the urine samples collected from the three persons 14 days after the poisoning. The levels were much higher, however, in the urine samples collected during the symptomatic phase of scombrotoxism in each of these three persons. The initial samples collected one to four hours after the ingestion of the fish contained levels of _N_ \\-methylhistamine 15 to 20 times the normal mean. In the samples collected during the subsequent 24 hours, the levels were still elevated but to a lesser extent, ranging from 4 to 11 times the normal mean.\n\n【37】Thus, the ingestion of the fish resulted in substantially increased urinary excretion of _N_ \\-methylhistamine. These results do not prove, however, that systemic concentrations of free histamine were also elevated, since ingested histamine could have been metabolized in the intestinal mucosa and liver before entering the systemic circulation.  To address this question, we measured the urinary excretion of histamine in the same urine samples. Fourteen days after poisoning, the urinary excretion of histamine in each of the three poisoned persons was normal. However, as we found for the urinary excretion of _N_ \\-methylhistamine, the levels of histamine were elevated in the urine samples collected immediately after the ingestion of the fish. In the urine samples collected between one and four hours after the ingestion of the fish, the levels of histamine were 9 to 20 times the normal mean. In the samples collected during the subsequent 24-hour period, these levels had fallen to 4 to 15 times the normal mean .\n\n【38】Table 1. Urinary Excretion of Histamine and N-Methylhistamine in the Person Who Ate Only a Small Quantity of the Marlin Implicated in the Poisoning and Did Not Have Scombrotoxism. Table 2.  Table 2. Urinary Excretion of Histamine and N-Methylhistamine in Three Control Subjects Who Ate Fresh Marlin Containing No Detectable Histamine.\n\n【39】As previously mentioned, one person recognized the peppery, metallic taste of spoiled scombroid fish and thus ate only a small portion of the serving. This person had no symptoms of scombrotoxism, and the urinary levels of both histamine and _N_ \\-methylhistamine were normal both in the urine sample collected soon after the meal and in that collected during the subsequent 24 hours . Hence, only those persons in whom scombrotoxism developed had increased circulating concentrations of histamine after ingesting the spoiled fish. In addition, the urinary excretion of both histamine and _N_ \\-methylhistamine remained normal in the three control subjects who ate fresh marlin that contained undetectable quantities of histamine and that did not produce symptoms of poisoning .\n\n【40】Assessment of PGD-M Excretion\n-----------------------------\n\n【41】The increased urinary excretion of histamine in the affected persons could have been due to the ingestion of histamine contained in the fish or the ingestion of other substances present in the fish that evoked the release of endogenous histamine from tissue mast cells. The latter, if it occurs, is unlikely to involve an allergic IgE-dependent mechanism of mast-cell activation, since all persons who eat spoiled scombroid fish have symptoms of poisoning.  We and others have found that mast cells activated by either IgE-dependent or independent mechanisms in vitro and in vivo release prostaglandin D <sub>2 </sub> along with histamine.  <sup><a>22 </a></sup>  <sup><a>24 </a></sup>  <sup><a>26 </a></sup> Therefore, we examined whether there was evidence of increased release of prostaglandin D <sub>2 </sub> in the poisoned persons by measuring the urinary excretion of PGD-M. In contrast to the increased urinary excretion of histamine and _N_ \\-methylhistamine, the excretion of PGD-M was normal in all three urine samples from each of the three persons .\n\n【42】Discussion\n----------\n\n【43】Histamine was suggested approximately 50 years ago as the causative agent of scombrotoxism, but its role has remained in question. One reason for the lingering doubt is that it has been impossible to reproduce the illness in normal subjects by administering histamine orally in doses comparable to those ingested when spoiled fish is eaten.  <sup>, </sup>  The crucial information required to resolve this question has not been obtained — namely, whether scombroid-fish poisoning is associated with sufficient increases in circulating histamine to cause toxicity. Our results document clearly that this does indeed occur. The urinary levels of histamine in the affected persons far exceeded those associated with symptoms of histamine excess. Kaliner and colleagues found that the urinary excretion of histamine during intravenous infusions of histamine in doses that resulted in flushing, headache, and tachycardia was approximately 34 nmol per hour, or 92 pmol per micromole of creatinine on the basis of an hourly rate of excretion of creatinine of 370 μmol.  When first measured, the urinary histamine levels in the three poisoned persons were all higher than 200 pmol per micromole of creatinine .\n\n【44】Whether potentiators of histamine toxicity were present in the spoiled scombroid fish is unknown.  <sup>, </sup>  It is noteworthy, however, that the increases in the urinary excretion of both histamine and _N_ \\-methylhistamine in the poisoned persons were of similar magnitude. Thus, it is probably valid to conclude that the spoiled fish did not contain substances that potentiated histamine toxicity by inhibiting its inactivation by histamine _N_ \\-methyltransferase.\n\n【45】The failure to find increased endogenous release of prostaglandin D <sub>2 </sub> in association with increased levels of histamine suggests that the source of the excess histamine was the fish rather than the release of histamine from mast cells. This is further supported by the finding that the ingestion of fresh marlin containing undetectable quantities of histamine did not result in increased urinary excretion of histamine. Although it is unlikely, we cannot exclude the possibility that other unknown substances may be present in spoiled fish that selectively release histamine but not prostaglandin D <sub>2 </sub> from mast cells or that selectively activate basophils, which do not produce prostaglandin D <sub>2 </sub> , to release histamine.  <sup><a>29 </a></sup>  <sup><a>31 </a></sup> Whether histamine is derived from exogenous or endogenous sources, however, does not influence the conclusion that it is the causative toxin of scombroid-fish poisoning.\n\n【46】The identification of histamine as the causative agent of scombrotoxism should serve as the basis for a general public health policy recommendation that persons with scombroid poisoning receive treatment with an antihistamine. Symptoms usually improve with the administration of H <sub>1 </sub> \\-receptor—antagonist drugs.  The two persons in our study who took diphenhydramine also had rapid amelioration of symptoms. A single report has also described symptomatic improvement after the administration of an H <sub>2 </sub> \\-antagonist drug.  We and others have demonstrated previously that blood vessels in humans have H <sub>2 </sub> receptors and that blocking the vascular effects of histamine requires the blockade of both H <sub>1 </sub> and H <sub>2 </sub> receptors.  <sup>, </sup>  Thus, there is a rational basis for recommending that persons with scombroid poisoning be treated with antagonists to both H <sub>1 </sub> and H <sub>2 </sub> receptors in combination.\n\n【47】We conclude that histamine is the toxin responsible for scombroid-fish poisoning. Such poisoning can be prevented effectively by handling and refrigerating fish appropriately.  If warming occurs at any point from the time the fish is caught until it is consumed, bacterial proliferation can lead to the production of histamine in quantities sufficient to cause poisoning in the absence of obvious putrefaction.  For these reasons, scombroid-fish poisoning will probably continue to be one of the most common causes of ichthyotoxicosis.", "index": 4255, "show": true, "start": 4242, "end": 4248, "province": ["文本干净度", "页码/数字"], "isEdit": false}, {"text": " 16  ", "content": "【0】Evidence That His<mark>diamine oxidase, or both.  , </mark> of Scombroid-Fish Poisoning\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】The highest morbidity worldwide from fish poisoning results from the ingestion of spoiled scombroid fish, such as tuna and mackerel, and its cause is not clear. Histamine could be responsible, because spoiled scombroid fish contain large quantities of histamine. Whether histamine is the causative toxin, however, has remained in question. To address this issue, we investigated whether histamine homeostasis is altered in poisoned people.\n\n【3】Methods.\n--------\n\n【4】The urinary excretion of histamine and its metabolite, N-methylhistamine, was measured in three persons who had scombroid-fish poisoning (scombrotoxism) after the ingestion of marlin. We measured 9α, 11β-dihydroxy-15–oxo–2,3,18,19-tetranorprost-5-ene-1,20-dioic acid (PGD-M), the principal metabolite of prostaglandin D <sub>2 </sub> , a mast-cell secretory product, to assess whether mast cells had been activated to release histamine.\n\n【5】Results.\n--------\n\n【6】The fish contained high levels of histamine (842 to 2503 μmol per 100 g of tissue). Symptoms of scombrotoxism — flushing and headache — began 10 to 30 minutes after the ingestion of fish. In urine samples collected one to four hours after fish ingestion, the levels of histamine and N-methylhistamine were 9 to 20 times and 15 to 20 times the normal mean, respectively. During the subsequent 24 hours, the levels fell to 4 to 15 times and 4 to 11 times the normal values. Levels of both were normal 14 days later. PGD-M excretion was not increased at any time. Two persons treated with diphenhydramine had prompt amelioration of symptoms.\n\n【7】Conclusions.\n------------\n\n【8】Scombroid-fish poisoning is associated with urinary excretion of histamine in quantities far exceeding those required to produce toxicity. The histamine is most likely derived from the spoiled fish. These results identify histamine as the toxin responsible for scombroid-fish poisoning. \n\n【9】Introduction\n------------\n\n【10】SCOMBROID-fish poisoning (scombrotoxism) refers to the clinical syndrome that results from the ingestion of spoiled fish, usually of the families Scombridae and Scomberesocidae. This includes tuna, mackerel, skipjack, and bonito.  However, nonscombroid fish, such as mahi-mahi, bluefish, amberjack, herring, sardines, and anchovies, as well as cheese, have also been implicated as causes of scombrotoxism.  Scombroid-fish poisoning is the most common cause of ichthyotoxicosis worldwide.  In the United States, such poisoning represents one of the major chemical food-borne illnesses reported to the Centers for Disease Control (CDC). \n\n【11】Symptoms of scombroid-fish poisoning usually occur within an hour after the ingestion of spoiled fish and last for several hours.  The symptoms include flushing, sweating, nausea, vomiting, diarrhea, headache, palpitations, dizziness, rash, and occasionally, swelling of the face and tongue. Respiratory distress can also occur, and vasodilatory shock has been noted on occasion. \n\n【12】The cause of scombroid-fish poisoning is not clearly understood. The CDC refers to the causative agent as scombrotoxin.  The toxin is not present when the fish are caught, but it is produced subsequently during spoilage.  Histamine was first suggested as the causative toxin in the 1940s,  on the basis of a number of observations. Fish that have caused scombroid poisoning consistently contain large quantities of histamine.  Scombroid fish contain substantial amounts of free histidine that can be decarboxylated to form histamine by enteric bacteria present in spoiled fish.  <sup>, </sup>  Furthermore, the symptoms of scombroid-fish poisoning resemble those of histamine toxicity, and improvement in symptoms has been reported after treatment with antihistamines. \n\n【13】The chief factor that has cast doubt on the role of histamine in scombroid-fish poisoning is that although it has been possible to produce mild symptoms of histamine excess after the oral administration of the substance in massive doses to humans, it has not been possible to reproduce the illness with doses comparable to the quantities ingested in fish that have caused scombrotoxism. <mark> 10   </mark><a>10 </a></sup>  This may be because histamine is absorbed very poorly from the gastrointestinal tract and because the liver and intestinal mucosa have a great capacity to inactivate histamine.  <sup>, </sup>  These results have led to speculation that substances may be present in the spoiled fish that enhance the pharmacologic activity of histamine, facilitate its absorption, or inhibit its inactivation by histamine _N_ \\-methyltransferase, diamine oxidase, or both.  <sup>, </sup> \n\n【14】The crucial information required to support or refute the speculation that histamine may be the causative toxin of scombroid-fish poisoning — i.e., a direct assessment of whether levels of histamine sufficient to cause toxicity are present in vivo in humans in association with such poisoning — has never been obtained. A recent outbreak of scombroid poisoning at a local cafeteria provided us with the opportunity to address this question.\n\n【15】Methods\n-------\n\n【16】Materials\n---------\n\n【17】\\[  H <sub>4 </sub> \\] Histamine and \\[  H <sub>3 </sub> \\] _N_ \\-methylhistamine were obtained from MSD Isotopes (Montreal). The principal urinary metabolite of prostaglandin D <sub>2 </sub> – 9α, 11-β-dihydroxy-15-oxo-2,3,18,19-tetranorprost-5-ene-1,20-dioic acid (PGD-M) — was synthesized and converted to the \\[  O <sub>4 </sub> \\]-labeled internal standard, as described elsewhere.  <sup>, </sup> \n\n【18】Measurement of Histamine, _N_ \\-Methylhistamine. and PGD-M in Urine\n-------------------------------------------------------------------\n\n【19】Histamine, _N_ \\-methylhistamine, and PGD-M were all measured in urine by highly accurate stable-isotope-dilution mass-spectrometric assays.  <sup><a>16 </a></sup>  The precision and accuracy of the assays were as follows: for histamine, ±3 percent and 98 percent, respectively; for _N_ \\-methylhistamine, ±2 percent and 97 percent; and for PGD-M, ±7 percent and 96 percent. The urinary creatinine concentration was measured by the sodium picrate method with an AutoAnalyzer II (Technicon, Tarrytown, N.Y.). The results of the histamine and _N_ \\-methylhistamine assays were expressed as picomoles per micromole of creatinine, and the results of the PGD-M assay as picomoles per millimole of creatinine. The normal range for each substance was determined by measurements in 20 normal subjects.\n\n【20】Preservation and Handling of the Fish\n-------------------------------------\n\n【21】The marlin implicated in the poisoning incident was caught in Costa Rican waters and flown to Miami. It was shipped to Nashville by refrigerated truck on June 9, 1990. It arrived at the local commercial supplier in Nashville on June 12 and was placed in a walk-in cooler at 1°C. The fish was transported to a local cafeteria on June 14 by refrigerated truck and stored in a walk-in cooler at 7°C. Later that day, the fish was sliced and placed in a reach-in cooler at 9°C. The following morning the fish was cooked and served for lunch. Approximately 50 servings of 100 to 150 g each were prepared, of which 25 were served that day.\n\n【22】In a control study, normal subjects were fed fresh marlin. This fish, obtained on the day of its arrival in Nashville from the same local supplier, was grilled and served immediately after being purchased.\n\n【23】Clinical Study\n--------------\n\n【24】We studied three persons who had symptoms of scombrotoxism after eating the implicated marlin. Each ate one serving of fish. A fourth person, a chief medical resident at Vanderbilt University, recognized an unusual peppery, metallic taste in the fish. Because he knew that this taste was characteristic of fish implicated in scombroid-fish poisoning,  <sup>, </sup>  he ate only a small portion and did not swallow portions that tasted peppery. He had no symptoms of scombrotoxism subsequently. The poisoned persons were two men and one woman, 35, 27, and 25 years of age, respectively. All were healthy, and none had any history of allergic reactions to fish nor were they taking any medications. Three separate urine samples were collected from each of the four persons for measurements of histamine, _N_ \\-methylhistamine, and PGD-M. The first urine sample was obtained one to four hours after the ingestion of fish. The second was a 24-hour collection begun after the collection of the first sample. The third sample was collected for 24 hours 14 days after the poisoning.\n\n【25】The persons studied were all medical personnel at Vanderbilt University. We were made aware of their cases by another physician at the university who recognized that the symptoms were probably due to scombroid-fish poisoning. Subsequently, the cafeteria was informed of the poisoning, and it stopped serving the fish. It was not possible to identify the other persons who had eaten fish at the cafeteria that day to determine whether any of them had had symptoms of poisoning. Unserved portions of fish were seized and sent to the laboratories of the Food and Drug Administration in Atlanta for an analysis of the histamine content by a standard fluorometric method. \n\n【26】In the control study, we also measured the urinary excretion of histamine and _N_ \\-methylhistamine in three normal subjects after the ingestion of fresh marlin. Each subject ate 125 g of cooked fish. Urine samples were obtained for analysis from each person during the 24-hour period before the fish was eaten. After the ingestion of the fish, the first urine sample voided (obtained within the first 4 hours) and a subsequent 24-hour collection were obtained from each subject. Three portions of the fresh marlin were also analyzed for their histamine content.\n\n【27】Results\n-------\n\n【28】Clinical Summary\n----------------\n\n【29】The three affected persons had symptoms of poisoning that began 10 to 30 minutes after ingestion of the fish and consisted of severe headache, mild nausea, and intense flushing, most notably in the face. One person also had severe diarrhea of sudden onset. One of the three sought care in the Vanderbilt Hospital emergency room and received diphenhydramine (50 mg intramuscularly) that resulted in an amelioration of symptoms within 30 minutes. A second person, a physician, administered diphenhydramine (50 mg intramuscularly) to himself, which also resulted in rapid improvement in symptoms within approximately 30 minutes. The third person did not receive an antihistamine. His symptoms abated after approximately three hours.\n\n【30】In the control study, none of the three subjects who ate fresh marlin had symptoms of scombrotoxism.\n\n【31】Histamine Content of the Ingested Fish\n--------------------------------------\n\n【32】The FDA's analysis of the four random samples of the batch of fish implicated in the poisoning revealed levels of 2495, 1456, 842, and 2503 μmol of histamine per 100 g of fish. Although marlin is a nonscombroid fish and has not previously been reported to cause scombroid poisoning, the histamine content of the fish was very high. The FDA has established a hazard level for poisoning from tuna that contains histamine in concentrations above 450 μmol per 100 g  ; fresh tuna contains less than 9 μmol per 100 g.  The histamine content of the fresh marlin that did not cause symptoms of poisoning was undetectable (<4.5 μmol per 100 g).\n\n【33】Urinary Excretion of Histamine and _N_ \\-Methylhistamine\n--------------------------------------------------------\n\n【34】Figure 1. Urinary Excretion of N-Methylhistamine, Histamine, and PGD-M in Three Persons with Scombrotoxism.\n\n【35】The first urine voided was collected between 1 and 4 hours after the poisoning, followed immediately by a 24-hour collection and then by a second 24-hour collection 14 days after the poisoning. Each person is indicated by a different symbol. The horizontal lines indicate the normal means +2 SD.\n\n【36】Initially, we examined whether the ingestion of the fish resulted in the absorption of substantial amounts of histamine or its metabolites by measuring the urinary excretion of the histamine metabolite _N_ \\-methylhistamine . The urinary levels of _N_ \\-methylhistamine were normal in the urine samples collected from the three persons 14 days after the poisoning. The levels were much higher, however, in the urine samples collected during the symptomatic phase of scombrotoxism in each of these three persons. The initial samples collected one to four hours after the ingestion of the fish contained levels of _N_ \\-methylhistamine 15 to 20 times the normal mean. In the samples collected during the subsequent 24 hours, the levels were still elevated but to a lesser extent, ranging from 4 to 11 times the normal mean.\n\n【37】Thus, the ingestion of the fish resulted in substantially increased urinary excretion of _N_ \\-methylhistamine. These results do not prove, however, that systemic concentrations of free histamine were also elevated, since ingested histamine could have been metabolized in the intestinal mucosa and liver before entering the systemic circulation.  To address this question, we measured the urinary excretion of histamine in the same urine samples. Fourteen days after poisoning, the urinary excretion of histamine in each of the three poisoned persons was normal. However, as we found for the urinary excretion of _N_ \\-methylhistamine, the levels of histamine were elevated in the urine samples collected immediately after the ingestion of the fish. In the urine samples collected between one and four hours after the ingestion of the fish, the levels of histamine were 9 to 20 times the normal mean. In the samples collected during the subsequent 24-hour period, these levels had fallen to 4 to 15 times the normal mean .\n\n【38】Table 1. Urinary Excretion of Histamine and N-Methylhistamine in the Person Who Ate Only a Small Quantity of the Marlin Implicated in the Poisoning and Did Not Have Scombrotoxism. Table 2.  Table 2. Urinary Excretion of Histamine and N-Methylhistamine in Three Control Subjects Who Ate Fresh Marlin Containing No Detectable Histamine.\n\n【39】As previously mentioned, one person recognized the peppery, metallic taste of spoiled scombroid fish and thus ate only a small portion of the serving. This person had no symptoms of scombrotoxism, and the urinary levels of both histamine and _N_ \\-methylhistamine were normal both in the urine sample collected soon after the meal and in that collected during the subsequent 24 hours . Hence, only those persons in whom scombrotoxism developed had increased circulating concentrations of histamine after ingesting the spoiled fish. In addition, the urinary excretion of both histamine and _N_ \\-methylhistamine remained normal in the three control subjects who ate fresh marlin that contained undetectable quantities of histamine and that did not produce symptoms of poisoning .\n\n【40】Assessment of PGD-M Excretion\n-----------------------------\n\n【41】The increased urinary excretion of histamine in the affected persons could have been due to the ingestion of histamine contained in the fish or the ingestion of other substances present in the fish that evoked the release of endogenous histamine from tissue mast cells. The latter, if it occurs, is unlikely to involve an allergic IgE-dependent mechanism of mast-cell activation, since all persons who eat spoiled scombroid fish have symptoms of poisoning.  We and others have found that mast cells activated by either IgE-dependent or independent mechanisms in vitro and in vivo release prostaglandin D <sub>2 </sub> along with histamine.  <sup><a>22 </a></sup>  <sup><a>24 </a></sup>  <sup><a>26 </a></sup> Therefore, we examined whether there was evidence of increased release of prostaglandin D <sub>2 </sub> in the poisoned persons by measuring the urinary excretion of PGD-M. In contrast to the increased urinary excretion of histamine and _N_ \\-methylhistamine, the excretion of PGD-M was normal in all three urine samples from each of the three persons .\n\n【42】Discussion\n----------\n\n【43】Histamine was suggested approximately 50 years ago as the causative agent of scombrotoxism, but its role has remained in question. One reason for the lingering doubt is that it has been impossible to reproduce the illness in normal subjects by administering histamine orally in doses comparable to those ingested when spoiled fish is eaten.  <sup>, </sup>  The crucial information required to resolve this question has not been obtained — namely, whether scombroid-fish poisoning is associated with sufficient increases in circulating histamine to cause toxicity. Our results document clearly that this does indeed occur. The urinary levels of histamine in the affected persons far exceeded those associated with symptoms of histamine excess. Kaliner and colleagues found that the urinary excretion of histamine during intravenous infusions of histamine in doses that resulted in flushing, headache, and tachycardia was approximately 34 nmol per hour, or 92 pmol per micromole of creatinine on the basis of an hourly rate of excretion of creatinine of 370 μmol.  When first measured, the urinary histamine levels in the three poisoned persons were all higher than 200 pmol per micromole of creatinine .\n\n【44】Whether potentiators of histamine toxicity were present in the spoiled scombroid fish is unknown.  <sup>, </sup>  It is noteworthy, however, that the increases in the urinary excretion of both histamine and _N_ \\-methylhistamine in the poisoned persons were of similar magnitude. Thus, it is probably valid to conclude that the spoiled fish did not contain substances that potentiated histamine toxicity by inhibiting its inactivation by histamine _N_ \\-methyltransferase.\n\n【45】The failure to find increased endogenous release of prostaglandin D <sub>2 </sub> in association with increased levels of histamine suggests that the source of the excess histamine was the fish rather than the release of histamine from mast cells. This is further supported by the finding that the ingestion of fresh marlin containing undetectable quantities of histamine did not result in increased urinary excretion of histamine. Although it is unlikely, we cannot exclude the possibility that other unknown substances may be present in spoiled fish that selectively release histamine but not prostaglandin D <sub>2 </sub> from mast cells or that selectively activate basophils, which do not produce prostaglandin D <sub>2 </sub> , to release histamine.  <sup><a>29 </a></sup>  <sup><a>31 </a></sup> Whether histamine is derived from exogenous or endogenous sources, however, does not influence the conclusion that it is the causative toxin of scombroid-fish poisoning.\n\n【46】The identification of histamine as the causative agent of scombrotoxism should serve as the basis for a general public health policy recommendation that persons with scombroid poisoning receive treatment with an antihistamine. Symptoms usually improve with the administration of H <sub>1 </sub> \\-receptor—antagonist drugs.  The two persons in our study who took diphenhydramine also had rapid amelioration of symptoms. A single report has also described symptomatic improvement after the administration of an H <sub>2 </sub> \\-antagonist drug.  We and others have demonstrated previously that blood vessels in humans have H <sub>2 </sub> receptors and that blocking the vascular effects of histamine requires the blockade of both H <sub>1 </sub> and H <sub>2 </sub> receptors.  <sup>, </sup>  Thus, there is a rational basis for recommending that persons with scombroid poisoning be treated with antagonists to both H <sub>1 </sub> and H <sub>2 </sub> receptors in combination.\n\n【47】We conclude that histamine is the toxin responsible for scombroid-fish poisoning. Such poisoning can be prevented effectively by handling and refrigerating fish appropriately.  If warming occurs at any point from the time the fish is caught until it is consumed, bacterial proliferation can lead to the production of histamine in quantities sufficient to cause poisoning in the absence of obvious putrefaction.  For these reasons, scombroid-fish poisoning will probably continue to be one of the most common causes of ichthyotoxicosis.", "index": 125, "show": true, "start": 112, "end": 117, "province": ["文本干净度", "页码/数字"], "isEdit": false}, {"text": "  22   24   26", "content": "【0】Evidence That His<mark>diamine oxidase, or both.  , </mark> of Scombroid-Fish Poisoning\nAbstract\n--------\n\n【1】Background.\n<mark> 16  </mark>------\n\n【2】The highest morbidity worldwide from fish poisoning results from the ingestion of spoiled scombroid fish, such as tuna and mackerel, and its cause is not clear. Histamine could be responsible, because spoiled scombroid fish contain large quantities of histamine. Whether histamine is the causative toxin, however, has remained in question. To address this issue, we investigated whether histamine homeostasis is altered in poisoned people.\n\n【3】Methods.\n--------\n\n【4】The urinary excretion of histamine and its metabolite, N-methylhistamine, was measured in three persons who had scombroid-fish poisoning (scombrotoxism) after the ingestion of marlin. We measured 9α, 11β-dihydroxy-15–oxo–2,3,18,19-tetranorprost-5-ene-1,20-dioic acid (PGD-M), the principal metabolite of prostaglandin D <sub>2 </sub> , a mast-cell secretory product, to assess whether mast cells had been activated to release histamine.\n\n【5】Results.\n--------\n\n【6】The fish contained high levels of histamine (842 to 2503 μmol per 100 g of tissue). Symptoms of scombrotoxism — flushing and headache — began 10 to 30 minutes after the ingestion of fish. In urine samples collected one to four hours after fish ingestion, the levels of histamine and N-methylhistamine were 9 to 20 times and 15 to 20 times the normal mean, respectively. During the subsequent 24 hours, the levels fell to 4 to 15 times and 4 to 11 times the normal values. Levels of both were normal 14 days later. PGD-M excretion was not increased at any time. Two persons treated with diphenhydramine had prompt amelioration of symptoms.\n\n【7】Conclusions.\n------------\n\n【8】Scombroid-fish poisoning is associated with urinary excretion of histamine in quantities far exceeding those required to produce toxicity. The histamine is most likely derived from the spoiled fish. These results identify histamine as the toxin responsible for scombroid-fish poisoning. \n\n【9】Introduction\n------------\n\n【10】SCOMBROID-fish poisoning (scombrotoxism) refers to the clinical syndrome that results from the ingestion of spoiled fish, usually of the families Scombridae and Scomberesocidae. This includes tuna, mackerel, skipjack, and bonito.  However, nonscombroid fish, such as mahi-mahi, bluefish, amberjack, herring, sardines, and anchovies, as well as cheese, have also been implicated as causes of scombrotoxism.  Scombroid-fish poisoning is the most common cause of ichthyotoxicosis worldwide.  In the United States, such poisoning represents one of the major chemical food-borne illnesses reported to the Centers for Disease Control (CDC). \n\n【11】Symptoms of scombroid-fish poisoning usually occur within an hour after the ingestion of spoiled fish and last for several hours.  The symptoms include flushing, sweating, nausea, vomiting, diarrhea, headache, palpitations, dizziness, rash, and occasionally, swelling of the face and tongue. Respiratory distress can also occur, and vasodilatory shock has been noted on occasion. \n\n【12】The cause of scombroid-fish poisoning is not clearly understood. The CDC refers to the causative agent as scombrotoxin.  The toxin is not present when the fish are caught, but it is produced subsequently during spoilage.  Histamine was first suggested as the causative toxin in the 1940s,  on the basis of a number of observations. Fish that have caused scombroid poisoning consistently contain large quantities of histamine.  Scombroid fish contain substantial amounts of free histidine that can be decarboxylated to form histamine by enteric bacteria present in spoiled fish.  <sup>, </sup>  Furthermore, the symptoms of scombroid-fish poisoning resemble those of histamine toxicity, and improvement in symptoms has been reported after treatment with antihistamines. \n\n【13】The chief factor that has cast doubt on the role of histamine in scombroid-fish poisoning is that although it has been possible to produce mild symptoms of histamine excess after the oral administration of the substance in massive doses to humans, it has not been possible to reproduce the illness with doses comparable to the quantities ingested in fish that have caused scombrotoxism. <mark> 10   </mark><a>10 </a></sup>  This may be because histamine is absorbed very poorly from the gastrointestinal tract and because the liver and intestinal mucosa have a great capacity to inactivate histamine.  <sup>, </sup>  These results have led to speculation that substances may be present in the spoiled fish that enhance the pharmacologic activity of histamine, facilitate its absorption, or inhibit its inactivation by histamine _N_ \\-methyltransferase, diamine oxidase, or both.  <sup>, </sup> \n\n【14】The crucial information required to support or refute the speculation that histamine may be the causative toxin of scombroid-fish poisoning — i.e., a direct assessment of whether levels of histamine sufficient to cause toxicity are present in vivo in humans in association with such poisoning — has never been obtained. A recent outbreak of scombroid poisoning at a local cafeteria provided us with the opportunity to address this question.\n\n【15】Methods\n-------\n\n【16】Materials\n---------\n\n【17】\\[  H <sub>4 </sub> \\] Histamine and \\[  H <sub>3 </sub> \\] _N_ \\-methylhistamine were obtained from MSD Isotopes (Montreal). The principal urinary metabolite of prostaglandin D <sub>2 </sub> – 9α, 11-β-dihydroxy-15-oxo-2,3,18,19-tetranorprost-5-ene-1,20-dioic acid (PGD-M) — was synthesized and converted to the \\[  O <sub>4 </sub> \\]-labeled internal standard, as described elsewhere.  <sup>, </sup> \n\n【18】Measurement of Histamine, _N_ \\-Methylhistamine. and PGD-M in Urine\n-------------------------------------------------------------------\n\n【19】Histamine, _N_ \\-methylhistamine, and PGD-M were all measured in urine by highly accurate stable-isotope-dilution mass-spectrometric assays.  <sup><a>16 </a></sup>  The precision and accuracy of the assays were as follows: for histamine, ±3 percent and 98 percent, respectively; for _N_ \\-methylhistamine, ±2 percent and 97 percent; and for PGD-M, ±7 percent and 96 percent. The urinary creatinine concentration was measured by the sodium picrate method with an AutoAnalyzer II (Technicon, Tarrytown, N.Y.). The results of the histamine and _N_ \\-methylhistamine assays were expressed as picomoles per micromole of creatinine, and the results of the PGD-M assay as picomoles per millimole of creatinine. The normal range for each substance was determined by measurements in 20 normal subjects.\n\n【20】Preservation and Handling of the Fish\n-------------------------------------\n\n【21】The marlin implicated in the poisoning incident was caught in Costa Rican waters and flown to Miami. It was shipped to Nashville by refrigerated truck on June 9, 1990. It arrived at the local commercial supplier in Nashville on June 12 and was placed in a walk-in cooler at 1°C. The fish was transported to a local cafeteria on June 14 by refrigerated truck and stored in a walk-in cooler at 7°C. Later that day, the fish was sliced and placed in a reach-in cooler at 9°C. The following morning the fish was cooked and served for lunch. Approximately 50 servings of 100 to 150 g each were prepared, of which 25 were served that day.\n\n【22】In a control study, normal subjects were fed fresh marlin. This fish, obtained on the day of its arrival in Nashville from the same local supplier, was grilled and served immediately after being purchased.\n\n【23】Clinical Study\n--------------\n\n【24】We studied three persons who had symptoms of scombrotoxism after eating the implicated marlin. Each ate one serving of fish. A fourth person, a chief medical resident at Vanderbilt University, recognized an unusual peppery, metallic taste in the fish. Because he knew that this taste was characteristic of fish implicated in scombroid-fish poisoning,  <sup>, </sup>  he ate only a small portion and did not swallow portions that tasted peppery. He had no symptoms of scombrotoxism subsequently. The poisoned persons were two men and one woman, 35, 27, and 25 years of age, respectively. All were healthy, and none had any history of allergic reactions to fish nor were they taking any medications. Three separate urine samples were collected from each of the four persons for measurements of histamine, _N_ \\-methylhistamine, and PGD-M. The first urine sample was obtained one to four hours after the ingestion of fish. The second was a 24-hour collection begun after the collection of the first sample. The third sample was collected for 24 hours 14 days after the poisoning.\n\n【25】The persons studied were all medical personnel at Vanderbilt University. We were made aware of their cases by another physician at the university who recognized that the symptoms were probably due to scombroid-fish poisoning. Subsequently, the cafeteria was informed of the poisoning, and it stopped serving the fish. It was not possible to identify the other persons who had eaten fish at the cafeteria that day to determine whether any of them had had symptoms of poisoning. Unserved portions of fish were seized and sent to the laboratories of the Food and Drug Administration in Atlanta for an analysis of the histamine content by a standard fluorometric method. \n\n【26】In the control study, we also measured the urinary excretion of histamine and _N_ \\-methylhistamine in three normal subjects after the ingestion of fresh marlin. Each subject ate 125 g of cooked fish. Urine samples were obtained for analysis from each person during the 24-hour period before the fish was eaten. After the ingestion of the fish, the first urine sample voided (obtained within the first 4 hours) and a subsequent 24-hour collection were obtained from each subject. Three portions of the fresh marlin were also analyzed for their histamine content.\n\n【27】Results\n-------\n\n【28】Clinical Summary\n----------------\n\n【29】The three affected persons had symptoms of poisoning that began 10 to 30 minutes after ingestion of the fish and consisted of severe headache, mild nausea, and intense flushing, most notably in the face. One person also had severe diarrhea of sudden onset. One of the three sought care in the Vanderbilt Hospital emergency room and received diphenhydramine (50 mg intramuscularly) that resulted in an amelioration of symptoms within 30 minutes. A second person, a physician, administered diphenhydramine (50 mg intramuscularly) to himself, which also resulted in rapid improvement in symptoms within approximately 30 minutes. The third person did not receive an antihistamine. His symptoms abated after approximately three hours.\n\n【30】In the control study, none of the three subjects who ate fresh marlin had symptoms of scombrotoxism.\n\n【31】Histamine Content of the Ingested Fish\n--------------------------------------\n\n【32】The FDA's analysis of the four random samples of the batch of fish implicated in the poisoning revealed levels of 2495, 1456, 842, and 2503 μmol of histamine per 100 g of fish. Although marlin is a nonscombroid fish and has not previously been reported to cause scombroid poisoning, the histamine content of the fish was very high. The FDA has established a hazard level for poisoning from tuna that contains histamine in concentrations above 450 μmol per 100 g  ; fresh tuna contains less than 9 μmol per 100 g.  The histamine content of the fresh marlin that did not cause symptoms of poisoning was undetectable (<4.5 μmol per 100 g).\n\n【33】Urinary Excretion of Histamine and _N_ \\-Methylhistamine\n--------------------------------------------------------\n\n<mark>【34】Figure 1. </mark>Urinary Excretion of N-Methylhistamine, Histamine, and PGD-M in Three Persons with Scombrotoxism.\n\n【35】The first urine voided was collected between 1 and 4 hours after the poisoning, followed immediately by a 24-hour collection and then by a second 24-hour collection 14 days after the poisoning. Each person is indicated by a different symbol. The horizontal lines indicate the normal means +2 SD.\n\n【36】Initially, we examined whether the ingestion of the fish resulted in the absorption of substantial amounts of histamine or its metabolites by measuring the urinary excretion of the histamine metabolite _N_ \\-methylhistamine . The urinary levels of _N_ \\-methylhistamine were normal in the urine samples collected from the three persons 14 days after the poisoning. The levels were much higher, however, in the urine samples collected during the symptomatic phase of scombrotoxism in each of these three persons. The initial samples collected one to four hours after the ingestion of the fish contained levels of _N_ \\-methylhistamine 15 to 20 times the normal mean. In the samples collected during the subsequent 24 hours, the levels were still elevated but to a lesser extent, ranging from 4 to 11 times the normal mean.\n\n【37】Thus, the ingestion of the fish resulted in substantially increased urinary excretion of _N_ \\-methylhistamine. These results do not prove, however, that systemic concentrations of free histamine were also elevated, since ingested histamine could have been metabolized in the intestinal mucosa and liver before entering the systemic circulation.  To address this question, we measured the urinary excretion of histamine in the same urine samples. Fourteen days after poisoning, the urinary excretion of histamine in each of the three poisoned persons was normal. However, as we found for the urinary excretion of _N_ \\-methylhistamine, the levels of histamine were elevated in the urine samples collected immediately after the ingestion of the fish. In the urine samples collected between one and four hours after the ingestion of the fish, the levels of histamine were 9 to 20 times the normal mean. In the samples collected during the subsequent 24-hour period, these levels had fallen to 4 to 15 times the normal mean .\n\n<mark>【38】Table 1. </mark>Urinary Excretion of Histamine and N-Methylhistamine in the Person Who Ate Only a Small Quantity of the Marlin Implicated in the Poisoning and Did Not Have Scombrotoxism. <mark>Table 2.  Table 2.</mark> Urinary Excretion of Histamine and N-Methylhistamine in Three Control Subjects Who Ate Fresh Marlin Containing No Detectable Histamine.\n\n【39】As previously mentioned, one person recognized the peppery, metallic taste of spoiled scombroid fish and thus ate only a small portion of the serving. This person had no symptoms of scombrotoxism, and the urinary levels of both histamine and _N_ \\-methylhistamine were normal both in the urine sample collected soon after the meal and in that collected during the subsequent 24 hours . Hence, only those persons in whom scombrotoxism developed had increased circulating concentrations of histamine after ingesting the spoiled fish. In addition, the urinary excretion of both histamine and _N_ \\-methylhistamine remained normal in the three control subjects who ate fresh marlin that contained undetectable quantities of histamine and that did not produce symptoms of poisoning .\n\n【40】Assessment of PGD-M Excretion\n-----------------------------\n\n【41】The increased urinary excretion of histamine in the affected persons could have been due to the ingestion of histamine contained in the fish or the ingestion of other substances present in the fish that evoked the release of endogenous histamine from tissue mast cells. The latter, if it occurs, is unlikely to involve an allergic IgE-dependent mechanism of mast-cell activation, since all persons who eat spoiled scombroid fish have symptoms of poisoning.  We and others have found that mast cells activated by either IgE-dependent or independent mechanisms in vitro and in vivo release prostaglandin D <sub>2 </sub> along with histamine.  <sup><a>22 </a></sup>  <sup><a>24 </a></sup>  <sup><a>26 </a></sup> Therefore, we examined whether there was evidence of increased release of prostaglandin D <sub>2 </sub> in the poisoned persons by measuring the urinary excretion of PGD-M. In contrast to the increased urinary excretion of histamine and _N_ \\-methylhistamine, the excretion of PGD-M was normal in all three urine samples from each of the three persons .\n\n【42】Discussion\n----------\n\n【43】Histamine was suggested approximately 50 years ago as the causative agent of scombrotoxism, but its role has remained in question. One reason for the lingering doubt is that it has been impossible to reproduce the illness in normal subjects by administering histamine orally in doses comparable to those ingested when spoiled fish is eaten.  <sup>, </sup>  The crucial information required to resolve this question has not been obtained — namely, whether scombroid-fish poisoning is associated with sufficient increases in circulating histamine to cause toxicity. Our results document clearly that this does indeed occur. The urinary levels of histamine in the affected persons far exceeded those associated with symptoms of histamine excess. Kaliner and colleagues found that the urinary excretion of histamine during intravenous infusions of histamine in doses that resulted in flushing, headache, and tachycardia was approximately 34 nmol per hour, or 92 pmol per micromole of creatinine on the basis of an hourly rate of excretion of creatinine of 370 μmol.  When first measured, the urinary histamine levels in the three poisoned persons were all higher than 200 pmol per micromole of creatinine .\n\n【44】Whether potentiators of histamine toxicity were present in the spoiled scombroid fish is unknown.  <sup>, </sup>  It is noteworthy, however, that the increases in the urinary excretion of both histamine and _N_ \\-methylhistamine in the poisoned persons were of similar magnitude. Thus, it is probably valid to conclude that the spoiled fish did not contain substances that potentiated histamine toxicity by inhibiting its inactivation by histamine _N_ \\-methyltransferase.\n\n【45】The failure to find increased endogenous release of prostaglandin D <sub>2 </sub> in association with increased levels of histamine suggests that the source of the excess histamine was the fish rather than the release of histamine from mast cells. This is further supported by the finding that the ingestion of fresh marlin containing undetectable quantities of histamine did not result in increased urinary excretion of histamine. Although it is unlikely, we cannot exclude the possibility that other unknown substances may be present in spoiled fish that selectively release histamine but not prostaglandin D <sub>2 </sub> from mast cells or that selectively activate basophils, which do not produce prostaglandin D <sub>2 </sub> , to release histamine.  <sup><a>29 </a></sup>  <sup><a>31 </a></sup> Whether histamine is derived from exogenous or endogenous sources, however, does not influence the conclusion that it is the causative toxin of scombroid-fish poisoning.\n\n【46】The identification of histamine as the causative agent of scombrotoxism should serve as the basis for a general public health policy recommendation that persons with scombroid poisoning receive treatment with an antihistamine. Symptoms usually improve with the administration of H <sub>1 </sub> \\-receptor—antagonist drugs.  The two persons in our study who took diphenhydramine also had rapid amelioration of symptoms. A single report has also described symptomatic improvement after the administration of an H <sub>2 </sub> \\-antagonist drug.  We and others have demonstrated previously that blood vessels in humans have H <sub>2 </sub> receptors and that blocking the vascular effects of histamine requires the blockade of both H <sub>1 </sub> and H <sub>2 </sub> receptors.  <sup>, </sup>  Thus, there is a rational basis for recommending that persons with scombroid poisoning be treated with antagonists to both H <sub>1 </sub> and H <sub>2 </sub> receptors in combination.\n\n【47】We conclude that histamine is the toxin responsible for scombroid-fish poisoning. Such poisoning can be prevented effectively by handling and refrigerating fish appropriately.  If warming occurs at any point from the time the fish is caught until it is consumed, bacterial proliferation can lead to the production of histamine in quantities sufficient to cause poisoning in the absence of obvious putrefaction.  For these reasons, scombroid-fish poisoning will probably continue to be one of the most common causes of ichthyotoxicosis.", "index": 15790, "show": true, "start": 15712, "end": 15726, "province": ["文本干净度", "无关文本"], "isEdit": false}, {"text": "  29   31", "content": "【0】Evidence That His<mark>diamine oxidase, or both.  , </mark> of Scombroid-Fish Poisoning\nAbstract\n--------\n\n【1】Background.\n<mark> 16  </mark>------\n\n【2】The highest morbidity worldwide from fish poisoning results from the ingestion of spoiled scombroid fish, such as tuna and mackerel, and its cause is not clear. Histamine could be responsible, because spoiled scombroid fish contain large quantities of histamine. Whether histamine is the causative toxin, however, has remained in question. To address this issue, we investigated whether histamine homeostasis is altered in poisoned people.\n\n【3】Methods.\n--------\n\n【4】The urinary excretion of histamine and its metabolite, N-methylhistamine, was measured in three persons who had scombroid-fish poisoning (scombrotoxism) after the ingestion of marlin. We measured 9α, 11β-dihydroxy-15–oxo–2,3,18,19-tetranorprost-5-ene-1,20-dioic acid (PGD-M), the principal metabolite of prostaglandin D <sub>2 </sub> , a mast-cell secretory product, to assess whether mast cells had been activated to release histamine.\n\n【5】Results.\n--------\n\n【6】The fish contained high levels of histamine (842 to 2503 μmol per 100 g of tissue). Symptoms of scombrotoxism — flushing and headache — began 10 to 30 minutes after the ingestion of fish. In urine samples collected one to four hours after fish ingestion, the levels of histamine and N-methylhistamine were 9 to 20 times and 15 to 20 times the normal mean, respectively. During the subsequent 24 hours, the levels fell to 4 to 15 times and 4 to 11 times the normal values. Levels of both were normal 14 days later. PGD-M excretion was not increased at any time. Two persons treated with diphenhydramine had prompt amelioration of symptoms.\n\n【7】Conclusions.\n------------\n\n【8】Scombroid-fish poisoning is associated with urinary excretion of histamine in quantities far exceeding those required to produce toxicity. The histamine is most likely derived from the spoiled fish. These results identify histamine as the toxin responsible for scombroid-fish poisoning. \n\n【9】Introduction\n------------\n\n【10】SCOMBROID-fish poisoning (scombrotoxism) refers to the clinical syndrome that results from the ingestion of spoiled fish, usually of the families Scombridae and Scomberesocidae. This includes tuna, mackerel, skipjack, and bonito.  However, nonscombroid fish, such as mahi-mahi, bluefish, amberjack, herring, sardines, and anchovies, as well as cheese, have also been implicated as causes of scombrotoxism.  Scombroid-fish poisoning is the most common cause of ichthyotoxicosis worldwide.  In the United States, such poisoning represents one of the major chemical food-borne illnesses reported to the Centers for Disease Control (CDC). \n\n【11】Symptoms of scombroid-fish poisoning usually occur within an hour after the ingestion of spoiled fish and last for several hours.  The symptoms include flushing, sweating, nausea, vomiting, diarrhea, headache, palpitations, dizziness, rash, and occasionally, swelling of the face and tongue. Respiratory distress can also occur, and vasodilatory shock has been noted on occasion. \n\n【12】The cause of scombroid-fish poisoning is not clearly understood. The CDC refers to the causative agent as scombrotoxin.  The toxin is not present when the fish are caught, but it is produced subsequently during spoilage.  Histamine was first suggested as the causative toxin in the 1940s,  on the basis of a number of observations. Fish that have caused scombroid poisoning consistently contain large quantities of histamine.  Scombroid fish contain substantial amounts of free histidine that can be decarboxylated to form histamine by enteric bacteria present in spoiled fish.  <sup>, </sup>  Furthermore, the symptoms of scombroid-fish poisoning resemble those of histamine toxicity, and improvement in symptoms has been reported after treatment with antihistamines. \n\n【13】The chief factor that has cast doubt on the role of histamine in scombroid-fish poisoning is that although it has been possible to produce mild symptoms of histamine excess after the oral administration of the substance in massive doses to humans, it has not been possible to reproduce the illness with doses comparable to the quantities ingested in fish that have caused scombrotoxism. <mark> 10   </mark><a>10 </a></sup>  This may be because histamine is absorbed very poorly from the gastrointestinal tract and because the liver and intestinal mucosa have a great capacity to inactivate histamine.  <sup>, </sup>  These results have led to speculation that substances may be present in the spoiled fish that enhance the pharmacologic activity of histamine, facilitate its absorption, or inhibit its inactivation by histamine _N_ \\-methyltransferase, diamine oxidase, or both.  <sup>, </sup> \n\n【14】The crucial information required to support or refute the speculation that histamine may be the causative toxin of scombroid-fish poisoning — i.e., a direct assessment of whether levels of histamine sufficient to cause toxicity are present in vivo in humans in association with such poisoning — has never been obtained. A recent outbreak of scombroid poisoning at a local cafeteria provided us with the opportunity to address this question.\n\n【15】Methods\n-------\n\n【16】Materials\n---------\n\n【17】\\[  H <sub>4 </sub> \\] Histamine and \\[  H <sub>3 </sub> \\] _N_ \\-methylhistamine were obtained from MSD Isotopes (Montreal). The principal urinary metabolite of prostaglandin D <sub>2 </sub> – 9α, 11-β-dihydroxy-15-oxo-2,3,18,19-tetranorprost-5-ene-1,20-dioic acid (PGD-M) — was synthesized and converted to the \\[  O <sub>4 </sub> \\]-labeled internal standard, as described elsewhere.  <sup>, </sup> \n\n【18】Measurement of Histamine, _N_ \\-Methylhistamine. and PGD-M in Urine\n-------------------------------------------------------------------\n\n【19】Histamine, _N_ \\-methylhistamine, and PGD-M were all measured in urine by highly accurate stable-isotope-dilution mass-spectrometric assays.  <sup><a>16 </a></sup>  The precision and accuracy of the assays were as follows: for histamine, ±3 percent and 98 percent, respectively; for _N_ \\-methylhistamine, ±2 percent and 97 percent; and for PGD-M, ±7 percent and 96 percent. The urinary creatinine concentration was measured by the sodium picrate method with an AutoAnalyzer II (Technicon, Tarrytown, N.Y.). The results of the histamine and _N_ \\-methylhistamine assays were expressed as picomoles per micromole of creatinine, and the results of the PGD-M assay as picomoles per millimole of creatinine. The normal range for each substance was determined by measurements in 20 normal subjects.\n\n【20】Preservation and Handling of the Fish\n-------------------------------------\n\n【21】The marlin implicated in the poisoning incident was caught in Costa Rican waters and flown to Miami. It was shipped to Nashville by refrigerated truck on June 9, 1990. It arrived at the local commercial supplier in Nashville on June 12 and was placed in a walk-in cooler at 1°C. The fish was transported to a local cafeteria on June 14 by refrigerated truck and stored in a walk-in cooler at 7°C. Later that day, the fish was sliced and placed in a reach-in cooler at 9°C. The following morning the fish was cooked and served for lunch. Approximately 50 servings of 100 to 150 g each were prepared, of which 25 were served that day.\n\n【22】In a control study, normal subjects were fed fresh marlin. This fish, obtained on the day of its arrival in Nashville from the same local supplier, was grilled and served immediately after being purchased.\n\n【23】Clinical Study\n--------------\n\n【24】We studied three persons who had symptoms of scombrotoxism after eating the implicated marlin. Each ate one serving of fish. A fourth person, a chief medical resident at Vanderbilt University, recognized an unusual peppery, metallic taste in the fish. Because he knew that this taste was characteristic of fish implicated in scombroid-fish poisoning,  <sup>, </sup>  he ate only a small portion and did not swallow portions that tasted peppery. He had no symptoms of scombrotoxism subsequently. The poisoned persons were two men and one woman, 35, 27, and 25 years of age, respectively. All were healthy, and none had any history of allergic reactions to fish nor were they taking any medications. Three separate urine samples were collected from each of the four persons for measurements of histamine, _N_ \\-methylhistamine, and PGD-M. The first urine sample was obtained one to four hours after the ingestion of fish. The second was a 24-hour collection begun after the collection of the first sample. The third sample was collected for 24 hours 14 days after the poisoning.\n\n【25】The persons studied were all medical personnel at Vanderbilt University. We were made aware of their cases by another physician at the university who recognized that the symptoms were probably due to scombroid-fish poisoning. Subsequently, the cafeteria was informed of the poisoning, and it stopped serving the fish. It was not possible to identify the other persons who had eaten fish at the cafeteria that day to determine whether any of them had had symptoms of poisoning. Unserved portions of fish were seized and sent to the laboratories of the Food and Drug Administration in Atlanta for an analysis of the histamine content by a standard fluorometric method. \n\n【26】In the control study, we also measured the urinary excretion of histamine and _N_ \\-methylhistamine in three normal subjects after the ingestion of fresh marlin. Each subject ate 125 g of cooked fish. Urine samples were obtained for analysis from each person during the 24-hour period before the fish was eaten. After the ingestion of the fish, the first urine sample voided (obtained within the first 4 hours) and a subsequent 24-hour collection were obtained from each subject. Three portions of the fresh marlin were also analyzed for their histamine content.\n\n【27】Results\n-------\n\n【28】Clinical Summary\n----------------\n\n【29】The three affected persons had symptoms of poisoning that began 10 to 30 minutes after ingestion of the fish and consisted of severe headache, mild nausea, and intense flushing, most notably in the face. One person also had severe diarrhea of sudden onset. One of the three sought care in the Vanderbilt Hospital emergency room and received diphenhydramine (50 mg intramuscularly) that resulted in an amelioration of symptoms within 30 minutes. A second person, a physician, administered diphenhydramine (50 mg intramuscularly) to himself, which also resulted in rapid improvement in symptoms within approximately 30 minutes. The third person did not receive an antihistamine. His symptoms abated after approximately three hours.\n\n【30】In the control study, none of the three subjects who ate fresh marlin had symptoms of scombrotoxism.\n\n【31】Histamine Content of the Ingested Fish\n--------------------------------------\n\n【32】The FDA's analysis of the four random samples of the batch of fish implicated in the poisoning revealed levels of 2495, 1456, 842, and 2503 μmol of histamine per 100 g of fish. Although marlin is a nonscombroid fish and has not previously been reported to cause scombroid poisoning, the histamine content of the fish was very high. The FDA has established a hazard level for poisoning from tuna that contains histamine in concentrations above 450 μmol per 100 g  ; fresh tuna contains less than 9 μmol per 100 g.  The histamine content of the fresh marlin that did not cause symptoms of poisoning was undetectable (<4.5 μmol per 100 g).\n\n【33】Urinary Excretion of Histamine and _N_ \\-Methylhistamine\n--------------------------------------------------------\n\n<mark>【34】Figure 1. </mark>Urinary Excretion of N-Methylhistamine, Histamine, and PGD-M in Three Persons with Scombrotoxism.\n\n【35】The first urine voided was collected between 1 and 4 hours after the poisoning, followed immediately by a 24-hour collection and then by a second 24-hour collection 14 days after the poisoning. Each person is indicated by a different symbol. The horizontal lines indicate the normal means +2 SD.\n\n【36】Initially, we examined whether the ingestion of the fish resulted in the absorption of substantial amounts of histamine or its metabolites by measuring the urinary excretion of the histamine metabolite _N_ \\-methylhistamine . The urinary levels of _N_ \\-methylhistamine were normal in the urine samples collected from the three persons 14 days after the poisoning. The levels were much higher, however, in the urine samples collected during the symptomatic phase of scombrotoxism in each of these three persons. The initial samples collected one to four hours after the ingestion of the fish contained levels of _N_ \\-methylhistamine 15 to 20 times the normal mean. In the samples collected during the subsequent 24 hours, the levels were still elevated but to a lesser extent, ranging from 4 to 11 times the normal mean.\n\n【37】Thus, the ingestion of the fish resulted in substantially increased urinary excretion of _N_ \\-methylhistamine. These results do not prove, however, that systemic concentrations of free histamine were also elevated, since ingested histamine could have been metabolized in the intestinal mucosa and liver before entering the systemic circulation.  To address this question, we measured the urinary excretion of histamine in the same urine samples. Fourteen days after poisoning, the urinary excretion of histamine in each of the three poisoned persons was normal. However, as we found for the urinary excretion of _N_ \\-methylhistamine, the levels of histamine were elevated in the urine samples collected immediately after the ingestion of the fish. In the urine samples collected between one and four hours after the ingestion of the fish, the levels of histamine were 9 to 20 times the normal mean. In the samples collected during the subsequent 24-hour period, these levels had fallen to 4 to 15 times the normal mean .\n\n<mark>【38】Table 1. </mark>Urinary Excretion of Histamine and N-Methylhistamine in the Person Who Ate Only a Small Quantity of the Marlin Implicated in the Poisoning and Did Not Have Scombrotoxism. <mark>Table 2.  Table 2.</mark> Urinary Excretion of Histamine and N-Methylhistamine in Three Control Subjects Who Ate Fresh Marlin Containing No Detectable Histamine.\n\n【39】As previously mentioned, one person recognized the peppery, metallic taste of spoiled scombroid fish and thus ate only a small portion of the serving. This person had no symptoms of scombrotoxism, and the urinary levels of both histamine and _N_ \\-methylhistamine were normal both in the urine sample collected soon after the meal and in that collected during the subsequent 24 hours . Hence, only those persons in whom scombrotoxism developed had increased circulating concentrations of histamine after ingesting the spoiled fish. In addition, the urinary excretion of both histamine and _N_ \\-methylhistamine remained normal in the three control subjects who ate fresh marlin that contained undetectable quantities of histamine and that did not produce symptoms of poisoning .\n\n【40】Assessment of PGD-M Excretion\n-----------------------------\n\n【41】The increased urinary excretion of histamine in the affected persons could have been due to the ingestion of histamine contained in the fish or the ingestion of other substances present in the fish that evoked the release of endogenous histamine from tissue mast cells. The latter, if it occurs, is unlikely to involve an allergic IgE-dependent mechanism of mast-cell activation, since all persons who eat spoiled scombroid fish have symptoms of poisoning.  We and others have found that mast cells activated by either IgE-dependent or independent mechanisms in vitro and in vivo release prostaglandin D <sub>2 </sub> along with histamine.<mark>  22   24   26</mark>/a></sup>  <sup><a>24 </a></sup>  <sup><a>26 </a></sup> Therefore, we examined whether there was evidence of increased release of prostaglandin D <sub>2 </sub> in the poisoned persons by measuring the urinary excretion of PGD-M. In contrast to the increased urinary excretion of histamine and _N_ \\-methylhistamine, the excretion of PGD-M was normal in all three urine samples from each of the three persons .\n\n【42】Discussion\n----------\n\n【43】Histamine was suggested approximately 50 years ago as the causative agent of scombrotoxism, but its role has remained in question. One reason for the lingering doubt is that it has been impossible to reproduce the illness in normal subjects by administering histamine orally in doses comparable to those ingested when spoiled fish is eaten.  <sup>, </sup>  The crucial information required to resolve this question has not been obtained — namely, whether scombroid-fish poisoning is associated with sufficient increases in circulating histamine to cause toxicity. Our results document clearly that this does indeed occur. The urinary levels of histamine in the affected persons far exceeded those associated with symptoms of histamine excess. Kaliner and colleagues found that the urinary excretion of histamine during intravenous infusions of histamine in doses that resulted in flushing, headache, and tachycardia was approximately 34 nmol per hour, or 92 pmol per micromole of creatinine on the basis of an hourly rate of excretion of creatinine of 370 μmol.  When first measured, the urinary histamine levels in the three poisoned persons were all higher than 200 pmol per micromole of creatinine .\n\n【44】Whether potentiators of histamine toxicity were present in the spoiled scombroid fish is unknown.  <sup>, </sup>  It is noteworthy, however, that the increases in the urinary excretion of both histamine and _N_ \\-methylhistamine in the poisoned persons were of similar magnitude. Thus, it is probably valid to conclude that the spoiled fish did not contain substances that potentiated histamine toxicity by inhibiting its inactivation by histamine _N_ \\-methyltransferase.\n\n【45】The failure to find increased endogenous release of prostaglandin D <sub>2 </sub> in association with increased levels of histamine suggests that the source of the excess histamine was the fish rather than the release of histamine from mast cells. This is further supported by the finding that the ingestion of fresh marlin containing undetectable quantities of histamine did not result in increased urinary excretion of histamine. Although it is unlikely, we cannot exclude the possibility that other unknown substances may be present in spoiled fish that selectively release histamine but not prostaglandin D <sub>2 </sub> from mast cells or that selectively activate basophils, which do not produce prostaglandin D <sub>2 </sub> , to release histamine.  <sup><a>29 </a></sup>  <sup><a>31 </a></sup> Whether histamine is derived from exogenous or endogenous sources, however, does not influence the conclusion that it is the causative toxin of scombroid-fish poisoning.\n\n【46】The identification of histamine as the causative agent of scombrotoxism should serve as the basis for a general public health policy recommendation that persons with scombroid poisoning receive treatment with an antihistamine. Symptoms usually improve with the administration of H <sub>1 </sub> \\-receptor—antagonist drugs.  The two persons in our study who took diphenhydramine also had rapid amelioration of symptoms. A single report has also described symptomatic improvement after the administration of an H <sub>2 </sub> \\-antagonist drug.  We and others have demonstrated previously that blood vessels in humans have H <sub>2 </sub> receptors and that blocking the vascular effects of histamine requires the blockade of both H <sub>1 </sub> and H <sub>2 </sub> receptors.  <sup>, </sup>  Thus, there is a rational basis for recommending that persons with scombroid poisoning be treated with antagonists to both H <sub>1 </sub> and H <sub>2 </sub> receptors in combination.\n\n【47】We conclude that histamine is the toxin responsible for scombroid-fish poisoning. Such poisoning can be prevented effectively by handling and refrigerating fish appropriately.  If warming occurs at any point from the time the fish is caught until it is consumed, bacterial proliferation can lead to the production of histamine in quantities sufficient to cause poisoning in the absence of obvious putrefaction.  For these reasons, scombroid-fish poisoning will probably continue to be one of the most common causes of ichthyotoxicosis.", "index": 18700, "show": true, "start": 18609, "end": 18618, "province": ["文本干净度", "无关文本"], "isEdit": false}]}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-14 00:19:44", "grab_time": "2024-08-13 22:58:13"}
{"id": 2234505, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "7d9c0813-7957-4105-95ee-fade277fbba7", "title": "Antiretroviral Preexposure Prophylaxis for Heterosexual HIV Transmission in Botswana", "text": "【0】Antiretroviral Preexposure Prophylaxis for Heterosexual HIV Transmission in Botswana\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Preexposure prophylaxis with antiretroviral agents has been shown to reduce the transmission of human immunodeficiency virus (HIV) among men who have sex with men; however, the efficacy among heterosexuals is uncertain.\n\n【3】Methods\n-------\n\n【4】We randomly assigned HIV-seronegative men and women to receive either tenofovir disoproxil fumarate and emtricitabine (TDF–FTC) or matching placebo once daily. Monthly study visits were scheduled, and participants received a comprehensive package of prevention services, including HIV testing, counseling on adherence to medication, management of sexually transmitted infections, monitoring for adverse events, and individualized counseling on risk reduction; bone mineral density testing was performed semiannually in a subgroup of participants.\n\n【5】Results\n-------\n\n【6】A total of 1219 men and women underwent randomization (45.7% women) and were followed for 1563 person-years (median, 1.1 years; maximum, 3.7 years). Because of low retention and logistic limitations, we concluded the study early and followed enrolled participants through an orderly study closure rather than expanding enrollment. The TDF–FTC group had higher rates of nausea (18.5% vs. 7.1%, P<0.001), vomiting (11.3% vs. 7.1%, P=0.008), and dizziness (15.1% vs. 11.0%, P=0.03) than the placebo group, but the rates of serious adverse events were similar (P=0.90). Participants who received TDF–FTC, as compared with those who received placebo, had a significant decline in bone mineral density. K65R, M184V, and A62V resistance mutations developed in 1 participant in the TDF–FTC group who had had an unrecognized acute HIV infection at enrollment. In a modified intention-to-treat analysis that included the 33 participants who became infected during the study (9 in the TDF–FTC group and 24 in the placebo group; 1.2 and 3.1 infections per 100 person-years, respectively), the efficacy of TDF–FTC was 62.2% (95% confidence interval, 21.5 to 83.4; P=0.03).\n\n【7】Conclusions\n-----------\n\n【8】Daily TDF–FTC prophylaxis prevented HIV infection in sexually active heterosexual adults. The long-term safety of daily TDF–FTC prophylaxis, including the effect on bone mineral density, remains unknown. \n\n【9】Introduction\n------------\n\n【10】Biomedical strategies to prevent sexual transmission of human immunodeficiency virus (HIV) remain limited.  In animal models, preexposure prophylaxis with tenofovir disoproxil fumarate (TDF) or with the combination of TDF and emtricitabine (TDF–FTC) can prevent infections with HIV or hybrid simian–human immunodeficiency virus after vaginal or rectal challenge.  In humans, daily preexposure prophylaxis with TDF–FTC has been shown to reduce transmission of HIV by 44% among men who have sex with men  ; however, the findings from studies in heterosexual populations have been mixed. \n\n【11】Botswana has the world's second highest prevalence of HIV infection, estimated in 2008 to be 17.6% overall and approximately 40% among adults 30 to 44 years of age.  Although Botswana was among the first African countries to introduce HIV prevention programs focused on male circumcision, prevention of mother-to-child transmission, and voluntary HIV counseling and testing, there is a need for additional prevention strategies to better control the generalized epidemic in this country. In this context, we conducted the TDF2 study to evaluate whether prophylaxis with daily oral TDF–FTC could prevent HIV infection among sexually active heterosexual adults.\n\n【12】Methods\n-------\n\n【13】Study Population and Design\n---------------------------\n\n【14】In this phase 3, randomized, double-blind, placebo-controlled clinical trial, we screened for enrollment men and women in the Botswana cities of Francistown and Gaborone. Eligible participants were HIV-seronegative, sexually active adults, 18 to 39 years of age, with normal results on serum chemical and hematologic tests, a negative test result for hepatitis B virus surface antigen, and no chronic illnesses or long-term medication use. Female participants could not be pregnant or breast-feeding and had to be willing to use effective contraception to enroll in the study. Eligible men and women who provided written informed consent to participate in the study were randomly assigned, in a  ratio, to receive oral TDF–FTC or placebo once daily; randomization was performed with the use of random, permuted blocks of six, with stratification according to site and sex.\n\n【15】TDF1 and TDF2 Studies\n---------------------\n\n【16】In 2005, the study investigators initiated the TDF1 study to evaluate the safety and efficacy of preexposure prophylaxis with TDF, as compared with placebo, with both study drugs administered once daily. When data from studies in animals later showed the superior efficacy of TDF–FTC,  we changed the active drug to TDF–FTC (TDF2 study). Beginning on February 20, 2007, a total of 18 participants in the TDF1 study enrolled in the TDF2 study and continued to receive the study medication as previously assigned (i.e., active drug or placebo). The first new participant in the TDF2 study was enrolled on March 22, 2007, and the last on October 23, 2009. Data from the TDF1 study are not included in this report.\n\n【17】During the study period, we observed a lower-than-expected rate of retention, owing primarily to relocation for work or school (i.e., early withdrawals) or to participants' scheduling conflicts leading to repeatedly missed study visits. Revised sample-size calculations indicated that we would need to expand enrollment to more than 2500 participants for the study to maintain at least 80% power to identify an efficacy result. Given this difficult logistical challenge, the sponsors and study investigators decided to proceed with an orderly conclusion to the study. Study investigators and participants remained unaware of the treatment assignments during this decision-making process. We informed participants about the impending closure of the study and allowed them to continue the study medication until protocol revisions were approved by the ethics committees in the United States and Botswana; exit procedures began on March 29, 2010. Study staff attempted to find all participants who were not in active follow-up as of this date (excluding study participants who had withdrawn) and to test them for HIV infection. Participants who missed three or more consecutive recent visits and could not be located at the end of the study were considered to have been permanently lost to follow-up. All participants exited the study by May 31, 2010, except for participants who had become infected with HIV, were pregnant, or had an ongoing serious adverse event at exit; we followed these participants for up to 1 additional year after discontinuation of the study medication. The last participant visit occurred on March 11, 2011.\n\n【18】Study Oversight\n---------------\n\n【19】The Botswana Health Research and Development Committee and the institutional review board at the U.S. Centers for Disease Control and Prevention reviewed and approved the protocol, consent forms, and supporting documents. All participants provided written informed consent; as required by Botswana law, parental or guardian consent was obtained for participants 18 to 20 years of age. Participants could withdraw informed consent and exit the study at any time. We asked exiting participants to complete all exit procedures and contacted them again for study procedures only if the results of laboratory tests at exit were abnormal. An independent data and safety monitoring board  reviewed safety data at least annually and identified no safety concerns that necessitated modifying or stopping the study. We planned a single interim efficacy analysis once half the expected HIV end points had occurred or half the total expected person-years of follow-up had been accrued. Since neither threshold had been reached when we decided to conclude the study, the data and safety monitoring board did not review the efficacy data. Gilead Sciences donated the study medication but was not involved in the collection or analysis of the data or the preparation of the manuscript. All the authors vouch for the completeness and accuracy of the data presented and for the fidelity of the study to the protocol.\n\n【20】Study Procedures\n----------------\n\n【21】After obtaining written consent, we screened potential participants by means of a brief interview and performed pregnancy testing on the women. We tested for HIV infection by means of dual, parallel, rapid HIV tests on whole-blood samples, using Determine HIV-1/2 (Abbott Diagnostics) and either Uni-Gold Recombigen HIV (Trinity Biotech) or OraQuick Advance HIV-1/2 (OraSure Technologies) . We then obtained whole-blood samples from the HIV-uninfected, nonpregnant participants who were deemed to be eligible after the screening interview and performed serum chemical and hematologic measurements and testing for hepatitis B virus surface antigen. We assessed the participants' understanding of the study using a computer-based education program; participants were required to receive a score of at least 80% on a comprehension test to be eligible for enrollment.\n\n【22】We assessed the sexual behavior and condom use of the enrolled participants by means of face-to-face interviews (at baseline and monthly thereafter) and by means of audio computer-assisted self-interviews (at baseline and semiannually thereafter) and provided a comprehensive package of HIV prevention services, including individualized counseling on risk reduction, free male and female condoms, and screening for sexually transmitted infections followed, if applicable, by partner notification and treatment. HIV rapid testing at enrollment and at subsequent monthly visits was performed with the use of the OraQuick Advance HIV-1/2 test of oral transudate . We assessed bone mineral density by means of dual-energy x-ray absorptiometry (Hologic QDR 4500C) in a subgroup of eligible, consenting participants at enrollment and semi-annually thereafter.\n\n【23】Study visits were scheduled every 30 days until completion of the study, and participants were instructed to return to the clinic for evaluation in the event of an illness. Study staff contacted participants by telephone or visited them in their home after missed study visits. During monthly study visits, we performed testing for HIV infection and for pregnancy, collected information about any illness and side effects, assessed adherence to medication and self-reported sexual activity and condom use, and provided condoms. HIV-negative, nonpregnant participants with no contraindications (e.g., a new medical illness) were provided with a new bottle of study medication and given counseling on adherence. We collected any remaining medication from participants who were exiting the study. During quarterly visits, we performed serum chemistry testing and provided individualized counseling on risk reduction, with further discussion at intercurrent visits when requested by the participant. During semiannual visits, we performed physical examinations, including pelvic and genital examinations, and collected genital samples to test for sexually transmitted infections. At completion of the study, we tested all participants for HIV infection, using an enzyme-linked immunosorbent assay (ELISA). Specific laboratory assessments are shown in Table S1 in the Supplementary Appendix .\n\n【24】For participants with positive or indeterminate results on HIV testing of oral transudate, we performed dual, parallel, fingerstick rapid HIV testing and provided counseling . In addition, we obtained blood samples to test for HIV infection by means of ELISA and to measure the baseline viral load and CD4+ lymphocyte count; we also tested for antiretroviral resistance mutations, using standard and ultrasensitive techniques. We provided all results to HIV-infected participants and their designated health care providers. We retrospectively performed testing for HIV RNA on stored samples from participants who had undergone seroconversion in order to determine the earliest visit at which infection could be documented.\n\n【25】We measured the participants' plasma drug levels by means of an ultrahigh-performance liquid chromatography–mass spectrometry assay (lower limit of detection, 0.3 ng per milliliter for both tenofovir and emtricitabine). For each participant who underwent seroconversion, we assayed the available specimen collected before and closest to the interpolated seroconversion date and then randomly chose specimens obtained during the same study visit from three participants in the TDF–FTC group, matched for sex and study site, who had not undergone seroconversion. We limited testing to participants who reported having taken the study medication within the previous 30 days. Additional study procedures are described in the Supplementary Appendix .\n\n【26】Statistical Analysis\n--------------------\n\n【27】The primary efficacy end point was the difference in the rates of HIV infection between participants assigned to receive TDF–FTC and those assigned to receive placebo. The primary hypothesis was that TDF–FTC, as compared with placebo, would reduce the rate of HIV infection by at least 65%, with a predefined lower boundary for the 95% confidence interval of 10%. Assuming an annual incidence rate of HIV infection of 5%, we estimated that a sample of approximately 1000 participants overall would give the study more than 80% power, at a one-sided significance level of 0.05, to test the primary hypothesis and would detect at least a 65% reduction in the rate of HIV infection with TDF–FTC. To account for uncertainty in our estimated incidence rate of HIV infection and for losses to follow-up, the target for enrollment was 1200 participants.\n\n【28】The initial efficacy analysis included all study participants who were randomly assigned to receive a study medication (intention-to-treat cohort). The per-protocol primary efficacy analysis excluded participants who were retrospectively determined, by means of an RNA polymerase-chain-reaction assay, to have been infected with HIV at the time of enrollment (modified intention-to-treat cohort). We calculated efficacy using Cox regression to estimate the hazard rate and Kaplan–Meier methods to estimate the cumulative probability of HIV-1 infection. We also performed an as-treated analysis in which follow-up data from participants in the modified intention-to-treat cohort were censored 30 days after the participants reported taking their last dose of study medication.\n\n【29】Safety analyses were performed in the intention-to-treat cohort. Primary safety end points included the frequency of adverse clinical or laboratory events and the change in bone mineral density. We graded adverse events according to the National Institutes of Health Division of AIDS Table for Grading the Severity of Adult and Pediatric Adverse Events (December 2004). All analyses were performed with the use of SAS software, version 9.2 (SAS Institute). Although one-sided tests were used for sample-size calculations, we used two-sided tests for all final analyses. P values of less than 0.05 were considered to indicate statistical significance.\n\n【30】Results\n-------\n\n【31】Study Participants\n------------------\n\n【32】Figure 1. Screening, Enrollment, Randomization, and Follow-up.\n\n【33】Participants could have more than one reason for being ineligible. Reasons that potential participants were ineligible other than those listed specifically in the figure included that they did not pass the comprehension test (74 volunteers), were pregnant (43), were taking long-term medication (33), expected to be relocating soon (29), were breast-feeding (13), lived outside the study area (12), had a history of kidney or bone disease (4), were enrolled in another HIV prevention trial (2), declined to be tested for HIV infection (2), were unwilling to take the study medication (2), did not have parental consent (1), were too busy with work (1), and did not meet the age criteria (1). A total of 542 of 601 participants in the TDF–FTC group (90.2%) and 528 of 599 in the placebo group (88.1%) had known HIV status at study exit. HIV denotes human immunodeficiency virus, and TDF–FTC tenofovir disoproxil fumarate and emtricitabine.Table 1.  Table 1. Baseline Characteristics of the Study Participants.\n\n【34】We screened 2533 volunteers; 52.2% were eligible for enrollment. The primary reasons for ineligibility were abnormal laboratory test results (16.4%), especially hyperamylasemia (6.0%), hyperbilirubinemia (3.9%), and positivity for hepatitis B virus surface antigen (3.5%); not being sexually active (9.4%); and HIV infection (10.6%) . A total of 1219 participants (45.7% women) underwent randomization . Participants were followed for 1563 person-years (median, 1.1 years; maximum, 3.7 years). Among 1200 participants who were followed for seroconversion, 1072 (89.3%) completed exit procedures, with a final HIV test result available for 1070 (89.2%). However, 397 participants (33.1%) did not complete the study per protocol, of whom 115 (9.6%) were considered to have been permanently lost to follow-up . The study groups did not differ significantly with respect to the rates of withdrawal (15.0% in the TDF–FTC group and 12.4% in the placebo group, P=0.21) or loss to follow-up (8.7% and 10.5%, respectively; P=0.28). When asked about their perceived treatment assignment, a similar percentage of participants in each group guessed that they were receiving TDF–FTC .\n\n【35】Medication Adherence and Risk Behavior\n--------------------------------------\n\n【36】The two groups had similar rates of adherence to the study medication, as estimated by means of pill counts (84.1% in the TDF–FTC group and 83.7% in the placebo group, P=0.79) and self-reported adherence for the preceding 3 days (94.4% and 94.1%, respectively; P=0.32). A total of 12 participants in the TDF–FTC group (2.0%) and 9 in the placebo group (1.5%) had their study medication permanently discontinued for safety reasons (P=0.66).\n\n【37】At the time of enrollment, most participants reported having had only one sexual partner in the preceding month . The percentage of sexual episodes in which condoms were used with the main or most recent casual sexual partner was similar in the two study groups at enrollment (81.4% \\[range, 76.6 to 86.4\\] in the TDF–FTC group and 79.2% \\[range, 71.6 to 87.6\\] in the placebo group, P=0.66) and remained stable over time , and the reported number of sexual partners declined similarly in both groups during the course of the study . Few participants reported having had any anal intercourse (2.6% in the TDF–FTC group and 2.5% in the placebo group, P=1.00); none of these participants underwent seroconversion.\n\n【38】Safety\n------\n\n【39】Table 2. Adverse Events, According to Treatment Group.\n\n【40】Nausea, vomiting, and dizziness occurred more frequently among participants who received TDF–FTC than among those who received placebo (nausea: 18.5% vs. 7.1%, P<0.001; vomiting: 11.3% vs. 7.1%, P=0.008; and dizziness: 15.1% vs. 11.0%, P=0.03) . These symptoms lessened after the first month . In contrast, leukorrhea and urethral discharge occurred more frequently among participants who received placebo (leukorrhea: 4.9% with TDF–FTC vs. 8.7% with placebo, P=0.01; and urethral discharge: 0.3% vs. 1.8%, P=0.03). Rates of chlamydial infection and gonorrhea were similar in the two groups (chlamydial infection: 12.4% with TDF–FTC and 12.3% with placebo, P=0.80; gonorrhea: 4.6% and 3.0%, respectively; P=0.10) . There were no significant differences between the study groups in the rates of serious clinical adverse events (10.3% with TDF–FTC and 10.9% with placebo, P=0.90) or laboratory adverse events . There were 107 pregnancies among 101 women during the study. Neither the rate of pregnancy nor the rate of fetal loss in early pregnancy differed significantly between the study groups (pregnancy: 17.1% with TDF–FTC and 19.1% with placebo, P=0.58; fetal loss: 7.1% and 6.9%, respectively; P=1.00).\n\n【41】Effects on Bone Mineral Density\n-------------------------------\n\n【42】Table 3. Bone Mineral Density Scores.\n\n【43】Among 109 participants in the TDF–FTC group and 112 in the placebo group in whom bone mineral density was measured, there was a decline in T scores and z scores for bone mineral density at the forearm, hip, and lumbar spine in participants who received TDF–FTC, as compared with those who received placebo (P=0.004 for both T scores and z scores at the forearm and P<0.001 for both scores at the hip and lumbar spine) . Seven participants in the TDF–FTC group and 6 in the placebo group had a bone fracture after initiating the study treatment (P=0.74) .\n\n【44】Efficacy\n--------\n\n【45】Figure 2. Kaplan–Meier Estimates of Time to HIV Infection.\n\n【46】Panel A shows the Kaplan–Meier estimates of the time to HIV infection in the modified intention-to-treat analysis, which included all study participants who were randomly assigned to receive a study medication, with the exception of participants who were retrospectively determined to have been infected with HIV at the time of enrollment. Panel B shows Kaplan–Meier estimates of the time to HIV infection in the as-treated analysis, in which follow-up data from participants in the modified intention-to-treat cohort were censored 30 days after participants reported receiving their last dose of study medication. The insets in both panels show the same data on an enlarged y axis.\n\n【47】A total of 36 participants became infected with HIV — 10 in the TDF–FTC group and 26 in the placebo group — which was equivalent to a protective efficacy of TDF–FTC as compared with placebo of 61.7% (95% confidence interval \\[CI\\], 15.9 to 82.6; P=0.03). With the exclusion of 3 participants who were HIV-infected at the time of enrollment (1 in the TDF–FTC group and 2 in the placebo group), the overall protective efficacy of TDF–FTC in the modified intention-to-treat analysis (comprising 1216 participants) was 62.2% (95% CI, 21.5 to 83.4; P=0.03) . The incidence of HIV infection was estimated to be 1.2 cases per 100 person-years in the TDF–FTC group and 3.1 cases per 100 person-years in the placebo group. In the as-treated analysis, in which follow-up data for participants were censored 30 days after their last reported dose of study medication (with data censored for 4 participants in the TDF–FTC group and 19 in the placebo group), the protective efficacy was 77.9% (95% CI, 41.2 to 93.6; P=0.01) . TDF–FTC also had a protective effect in analyses of subgroups defined according to sex; however, the efficacy was not significant in all the analyses, owing to the occurrence of few end points in these subgroups .\n\n【48】Virus from two HIV-infected participants showed antiretroviral resistance mutations . In one participant in the TDF–FTC group, who had had unrecognized wild-type, acute HIV infection at the time of enrollment, K65R, M184V, and A62V reverse transcriptase resistance mutations developed at high levels (approximately 100%). After the diagnosis of HIV infection, the participant began receiving antiretroviral treatment with a combination of zidovudine, lamivudine, and lopinavir–ritonavir, with subsequent suppression of the plasma viral load to less than 400 copies per milliliter. In addition, one participant assigned to receive placebo had a K65R mutation intermittently and at very low levels (<1%) after seroconversion, although the mutation was not detected in the blood sample that had been obtained closest to the estimated date of seroconversion.\n\n【49】Plasma Drug Levels\n------------------\n\n【50】Among the 4 participants in the TDF–FTC group who became infected with HIV during the study, 2 (50%) had detectable levels of tenofovir and emtricitabine in plasma obtained at the visit before and closest to their estimated seroconversion dates, whereas among the 69 participants, matched by sample date, who did not undergo seroconversion, 55 (80%) and 56 (81%) had detectable levels of tenofovir and emtricitabine, respectively . The geometric mean detectable plasma concentrations of each drug were significantly lower among the participants who underwent seroconversion than among those who did not undergo seroconversion: 0.3 ng per milliliter (95% CI, 0.01, 8.02) vs. 30.6 ng per milliliter (95% CI, 16.3 to 57.5) for tenofovir (P=0.007) and 0.5 ng per milliliter (95% CI, 0.01 to 25.3) vs. 103.3 ng per milliliter (95% CI, 45.4 to 234.9) for emtricitabine (P=0.009). Neither drug was detected in any of the 19 participants in the placebo group who underwent seroconversion.\n\n【51】Discussion\n----------\n\n【52】In this study of 1219 young, heterosexual adults in Botswana, TDF–FTC, taken orally once daily, decreased the rate of HIV infection by 62.2% when it was administered as part of a comprehensive package of HIV-prevention services. The protective efficacy was higher when the analysis was limited to participants who reported having taken the study medication within the previous 30 days, a finding that is consistent with increased efficacy among participants with high adherence to study medication in other trials of preexposure prophylaxis.  The rates of nausea, vomiting, and dizziness were higher among participants who were assigned to receive TDF–FTC than among those assigned to received placebo; these symptoms were transient and in most cases resolved rapidly. Over the course of 2 years of prophylaxis, we observed a small but significant decline in bone mineral density among participants taking TDF–FTC. We previously reported that 57% of our study population had low bone mineral density at the time of enrollment,  and our study population may therefore have been at increased risk for loss of bone mineral density while taking TDF. The clinical relevance of the observed decline in bone mineral density with respect to the risk of fracture remains uncertain. In other studies of HIV-negative persons receiving TDF as preexposure prophylaxis and in studies of previously untreated HIV-infected patients who were prescribed TDF–FTC as part of an antiretroviral therapy regimen, rates of fracture attributable to TDF exposure were not increased, despite a modest loss of bone mineral density; however, the duration of medication use and the length of follow-up were relatively short. \n\n【53】We detected drug resistance among participants taking TDF–FTC who were infected with HIV at enrollment, an observation that has also been reported in other trials of preexposure prophylaxis.  The emergence of K65R, M184V, and A62V antiretroviral resistance mutations in a participant who had had unrecognized wild-type infection at the time of enrollment highlights the importance of careful HIV screening before and during preexposure prophylaxis. The low frequency of the K65R mutation detected intermittently in a participant in the placebo group falls within the reported natural polymorphism frequency for subtype C virus in the absence of drug,  suggesting that the mutation was probably not induced by tenofovir.\n\n【54】Our findings that participants who did not undergo seroconversion were more likely than those who did to have detectable plasma levels of drug and to have higher drug levels when detected highlight the critical importance of adherence. Both the Preexposure Prophylaxis Initiative (iPrEx) study and the Partners Preexposure Prophylaxis (Partners PrEP) study showed that the efficacy of preexposure prophylaxis depends largely on adherence to the medication, as assessed by measurement of plasma drug concentrations.  These findings are important to consider in light of the results of the Preexposure Prophylaxis Trial for HIV Prevention among African Women (FEM-PrEP) and the Vaginal and Oral Interventions to Control the Epidemic study , both of which involved high-risk women.  Final analyses for the VOICE trial are pending, but the FEM-PrEP investigators noted that less than 40% of HIV-infected women and of HIV-uninfected women who were tested had detectable levels of study medication around the time of HIV infection and concluded that this poor adherence was likely to have contributed to the inability to identify efficacy. \n\n【55】In our study, risky sexual behavior did not increase among the participants receiving study medication; however, taking a medication with known efficacy might lead to increased sexual disinhibition. Additional data from open-label and pilot implementation studies are needed to better understand the ways in which adherence to and acceptability of medication and potential increases in risky sexual behavior while taking medication alter the effectiveness of preexposure prophylaxis.\n\n【56】Our study has several limitations. First, the rates of study completion were lower than predicted, because more participants than expected withdrew from the study, mostly owing to relocation or conflicting obligations. Other researchers conducting studies in Botswana have noted difficulties in retaining this young, mobile, healthy population.  Our intensive efforts to reach participants who missed repeated visits ensured that 89.3% of all enrollees completed exit procedures and that final HIV infection status was known for 89.2%. Given the fact that the rates of study completion were similar in the two study groups, we believe that the lower-than-predicted retention rate did not confound or otherwise limit our findings. In addition, the total of 1563 person-years represented 80.2% of the person-years we had estimated we would need for our original power calculations. Second, our findings may not be generalizable to other populations, since we did not assess the efficacy of preexposure prophylaxis with TDF–FTC in preventing the transmission of HIV through anal sex or injection-drug use. Finally, we cannot state conclusively that TDF–FTC was protective for men and women independently, as was shown in the Partners PrEP study, which involved discordant couples who were prescribed TDF–FTC. \n\n【57】In conclusion, daily oral TDF–FTC, given in the context of other prevention services, prevented HIV infection among heterosexual men and women. Additional data from other studies of the efficacy of preexposure prophylaxis and operational open-label research will help determine the effectiveness of programs that promote preexposure prophylaxis for the prevention of HIV infection.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 17:04:18", "endTime": "2024/08/13 17:06:13", "cost": 115.93}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 01:06:14", "grab_time": "2024-08-13 01:04:17"}
{"id": 2234504, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "d00c3892-ea71-4127-8ace-c514101225e2", "title": "Prophylactic Red-Cell Transfusions in Pregnant Patients with Sickle Cell Disease", "text": "【0】Prophylactic Red-Cell Transfusions in Pregnant Patients with Sickle Cell Disease\nAbstract\n--------\n\n【1】Prophylactic blood transfusion has come to be regarded as necessary in the treatment of patients with sickle cell disease during pregnancy. Because of the risks associated with blood products and reports of successful outcomes without the use of blood transfusion, we conducted a prospective randomized controlled study of this issue.\n\n【2】Seventy-two pregnant patients with sickle cell anemia were randomly assigned to one of two treatment groups: 36 received prophylactic transfusions of frozen red cells, and 36 received red-cell transfusions only for medical or obstetric emergencies. Twenty-eight patients with sickle cell anemia who did not qualify for randomization (mainly because they had other medical disorders), 66 with sickle cell–hemoglobin C disease, and 23 with sickle cell–betathalassemia were also followed and received transfusions only for emergencies.\n\n【3】There was no significant difference in perinatal outcome between the offspring of mothers with sickle cell disease who were assigned to treatment with prophylactic transfusions and those who were not (15 vs. 5 percent). The occurrence of a perinatal death in a previous pregnancy and the presence of twins in the present pregnancy were two major risk factors for an unfavorable outcome; when they were present, perinatal mortality was 50 percent. Perinatal mortality was somewhat higher in the two groups that were randomized than in the three groups that were not.\n\n【4】Prophylactic transfusion significantly reduced the incidence of painful crises of sickle cell disease (P<0.01) and substantially reduced the cumulative incidence of other complications of this disorder (P = 0.07). Other medical and obstetric complications occurred with nearly equal frequency in the two randomized groups. Increases in costs, the number of hospitalizations, and the risk of alloimmunization were disadvantages of prophylactic transfusion.\n\n【5】We conclude that the omission of prophylactic red-cell transfusion will not harm pregnant patients with sickle cell disease or their offspring.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:56:05", "endTime": "2024/08/14 14:56:27", "cost": 21.99}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 22:56:27", "grab_time": "2024-08-13 22:55:48"}
{"id": 2234503, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "220635fc-0584-4452-8256-c9fd8fdd63e2", "title": "Hypocitraturia in Patients with Gastrointestinal Malabsorption", "text": "【0】Hypocitraturia in Patients with Gastrointestinal Malabsorption\nAbstract\n--------\n\n【1】We measured serum and urinary citrate, oxalate, calcium, and magnesium in 22 normal subjects and in 16 patients with malabsorption. The patients had subnormal levels of serum citrate and magnesium during fasting, subnormal 24-hour levels of urinary citrate, magnesium, and calcium, and excessive levels of urinary oxalate. Daily citrate excretion averaged only 15 per cent of normal.\n\n【2】The hypocitraturia in the patients resulted from a subnormal filtered load of citrate and abnormally high net tubular reabsorption of the anion. An oral citrate supplement raised both the serum concentration and the filtered load of citrate to normal fasting values, but net tubular reabsorption remained abnormally high and urinary excretion abnormally low. Intramuscular magnesium sulfate, which corrected the hypomagnesemia and hypomagnesuria, had no effect on serum citrate or its filtered load. Nevertheless the injection restored net tubular reabsorption of citrate to normal and partially improved the hypocitraturia. Full correction of the hypocitraturia was achieved by combined treatment with oral citrate and intramuscular magnesium sulfate. Hypocitraturia may contribute to the formation of oxalate stones in these patients, and therefore our treatment may help to prevent this complication.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 17:01:04", "endTime": "2024/08/13 17:01:42", "cost": 38.132}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 01:01:42", "grab_time": "2024-08-13 01:01:04"}
{"id": 2234502, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "b0bda86a-665a-4b1f-94d3-67af272f5070", "title": "Parametric Models of Therapeutic Efficacy in Breast Cancer", "text": "【0】Parametric Models of Therapeutic Efficacy in Breast Cancer\nTo the Editor:\n--------------\n\n【1】We were intrigued by the editorial by Dr. Henderson entitled “Paradigmatic Shifts in the Management of Breast Cancer” (April 6, 1995, issue).  Of particular interest are the questions he asks about the effect of adjuvant therapy: “Are some patients cured by adjuvant treatment whereas others derive no benefit at all? Or is the survival of most patients prolonged only transiently, with no patients or very few cured?”\n\n【2】Patients with breast cancer are eager to be shown the true balance sheet regarding adjuvant therapy. In return for a few months of toxic effects, is there an increase in the cure rate, or extra months of survival among uncured patients? To address this question, Dr. Henderson derives an important observation from Bonadonna's first prospective, randomized, controlled clinical trial of adjuvant therapy  : “Findings suggest that the percentage of women who died of breast cancer in the two groups was nearly the same but that the time at which they died was different.”\n\n【3】We agree, and we would like to recommend a more explicit approach to the question of cure in the context of clinical trials. If one wishes to know whether therapy has affected the cure rate in a trial involving two groups of patients, the question becomes this: Do the curves for cause-specific survival in the two treatment groups approach the same asymptote?\n\n【4】To determine whether two curves for cause-specific survival approach the same asymptote, one can start by simply looking at them. In the landmark study discussed above, the curves for relapse-free survival tended to converge with increasing follow-up, suggesting that they have a common limiting value.  To have scientific proof, however, we need a more objective and more precise measure of long-term therapeutic effect.\n\n【5】Parametric models with a cured-fraction component provide such a measure. These models test explicitly for a difference in the cure rate between two treatment groups. Cure can be defined in terms of either relapse or death from breast cancer, depending on the end point of interest. We performed a parametric analysis of the data from the same trial by Bonadonna et al.  that Dr. Henderson discusses.  Our results suggest that in that trial the relapse-defined cure rate did not differ between the treatment and control groups (P = 0.45).  There is evidence, however, that the treatment group had a significant advantage with respect to the median time to relapse (P<0.001). Thus, parametric analysis provides quantitative insights similar to those derived by Dr. Henderson from a careful inspection of long-term follow-up data. On a more encouraging note, our analysis  of a second trial performed by Bonadonna's group  gives evidence of a significant difference between treatment groups in the fraction of patients cured (P = 0.002).\n\n【6】We recommend that Dr. Henderson and readers of the _Journal_ consider the objective insight provided by parametric methods. These methods are especially valuable in the context of trials of adjuvant chemotherapy in stage II breast cancer, since they allow discrimination between the two types of therapeutic benefit: increasing the cure rate and increasing the time to relapse or death from recurrent disease. Such discrimination is important for the thousands of women who die of breast cancer each year.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:32:41", "endTime": "2024/08/14 15:33:39", "cost": 58.544}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 23:33:39", "grab_time": "2024-08-13 23:32:40"}
{"id": 2234501, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "9b2d06c1-78d5-44e9-97df-40ca49854cc2", "title": "A Wrong Turn", "text": "【0】A Wrong Turn\nA 21-year-old woman (gravida 1, para 1) with sickle cell trait presented to the hospital 5 days after delivery with abdominal pain and shortness of breath. She had been well before pregnancy.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:06:55", "endTime": "2024/08/14 15:07:07", "cost": 12.372}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 23:07:07", "grab_time": "2024-08-13 23:06:54"}
{"id": 2234500, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "5643198a-f465-4de3-8bd9-8ab3160198a3", "title": "Audio Interview: Covid-19 and the President", "text": "【0】Audio Interview: Covid-19 and the President\nArticle\n-------\n\n【1】### Audio Interview\n\n【2】 Covid-19 and the President \n\n【3】The continuing spread of SARS-CoV-2 remains a Public Health Emergency of International Concern. What physicians need to know about transmission, diagnosis, and treatment of Covid-19 is the subject of ongoing updates from infectious disease experts at the _Journal_ .\n\n【4】In this audio interview conducted on October 7, 2020, the editors discuss treatments the President has reportedly received for Covid-19, the rationale for them, and what is known about risks and benefits.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:02:21", "endTime": "2024/08/14 15:02:30", "cost": 9.08}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 23:02:30", "grab_time": "2024-08-13 23:02:21"}
{"id": 2234499, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "32834cac-317b-48b8-ad85-eff800d1e559", "title": "Case 28-2006 — A 59-Year-Old Man with Masses in Both Kidneys", "text": "【0】Case 28-2006 — A 59-Year-Old Man with Masses in Both Kidneys\nA 59-year-old man was found to have bilateral renal masses. The right renal mass invaded the inferior vena cava. Fine-needle aspiration of the left renal mass disclosed renal-cell carcinoma. A right radical nephrectomy was performed. The optimal management of the left renal tumor is discussed.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:34:32", "endTime": "2024/08/14 14:34:46", "cost": 13.719}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 22:34:46", "grab_time": "2024-08-13 22:34:32"}
{"id": 2234498, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "9622b672-0178-4d29-b3b2-f5578a7fd217", "title": "Caspase 3 and p27 as Predictors of Invasive Bladder Cancer", "text": "【0】Caspase 3 and p27 as Predictors of Invasive Bladder Cancer\nTo the Editor:\n--------------\n\n【1】In the United States and the United Kingdom, about 57,000 patients are given a diagnosis of bladder cancer each year. Invasive bladder cancer usually arises from a precursor lesion of either flat carcinoma in situ or noninvasive papillary transitional carcinoma. Flat carcinoma in situ is typified by the increased proliferation of transitional epithelial cells. In approximately 50 percent of patients, bladder carcinoma in situ will evolve into full-blown, invasive bladder cancer. Increased understanding of the molecular mechanisms driving the transition from carcinoma in situ to invasive cancer would have major implications for the treatment of this condition. Furthermore, it could lead to tests that would identify patients in whom carcinoma in situ will evolve into invasive bladder cancer.\n\n【2】The presence of p27, a cyclin-dependent kinase inhibitor that powerfully blocks progression of the cell cycle,  in the nucleus of a variety of tumor cells has been correlated with improved survival.  Activated caspase 3 is a downstream effector of the apoptotic pathway that can cleave p27 into two fragments that leave the nucleus, resulting in a dramatic up-regulation in the activity of cyclin-dependent kinase 2, a requirement for cell proliferation. \n\n【3】We hypothesized that the loss of the expression of p27 in nuclei coupled with increased expression of activated caspase 3 in bladder carcinoma-in-situ cells correlates with the subsequent development of invasive bladder cancer. To test this hypothesis, we performed immunocytochemical analysis, using standard techniques,  on tissue sections from 34 patients with a diagnosis of bladder carcinoma in situ and then determined whether or not invasive bladder cancer developed.\n\n【4】Figure 1. Immunocytochemical Analysis of Activated Caspase 3 Levels  and Nuclear p27 Levels  in Two Patients with Bladder Carcinoma in Situ (Immunostaining, with Hematoxylin Counterstaining).\n\n【5】Activated caspase 3 and p27 stain brown on immunocytochemical analysis with specific antibodies (New England Biolabs and Transduction Laboratories, respectively). The level of expression of activated caspase 3 is elevated , whereas the level of expression of p27 in nuclei is low  in a specimen from a patient with carcinoma in situ in whom invasive bladder cancer subsequently developed. Conversely, the level of expression of activated caspase 3 is low  and the level of expression of nuclear p27 is high  in a specimen from a patient with carcinoma in situ in whom invasive bladder cancer had not developed after 41 months of follow-up.\n\n【6】The mean length of follow-up was 3.6 years. Among the 34 patients, invasive bladder cancer developed in 14 (41 percent). Loss of immunostaining for p27 in the nucleus was associated with the subsequent development of invasive disease (sensitivity, 76 percent; specificity, 66 percent; P<0.05). The presence of high levels of activated caspase 3 was also associated with progression to invasive disease (sensitivity, 60 percent; specificity, 68 percent; P<0.05). However, the presence of both factors was associated even more strongly with invasiveness. Of the 14 patients in whom invasive bladder cancer developed, 11 had high levels of expression of activated caspase 3  and a total or near-total loss of nuclear immunostaining for p27 . In contrast, 17 of the 20 patients in whom invasive bladder cancer did not develop had low levels of activated caspase 3 on immunostaining  and high levels of nuclear p27  (sensitivity, 78 percent; specificity, 85 percent; P<0.001). Furthermore, among six patients with recurrent carcinoma in situ who received intravesicular bacille Calmette–Guérin as immunotherapy, the three patients in whom invasive bladder cancer subsequently developed had low levels of expression of p27 in the nuclei and high levels of expression of activated caspase 3. The three patients without disease recurrence after treatment with bacille Calmette–Guérin had high levels of expression of p27 in nuclei and low levels of expression of activated caspase 3.\n\n【7】These data suggest that the measurement of both nuclear p27 levels and activated caspase 3 levels may be useful in monitoring patients with bladder carcinoma in situ, to identify both those at increased risk for invasive bladder cancer and those who are more likely to have a response to intravesicular immunotherapy.\n\n【8】(This work was supported by the Medical Research Council of the United Kingdom.)", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-14 00:21:06", "grab_time": "2024-08-13 23:40:42"}
{"id": 2234497, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "f05d6870-54a9-48b8-baa4-c27d87ebacff", "title": "Case 7-2011 — A 52-Year-Old Man with Upper Respiratory Symptoms and Low Oxygen Saturation Levels", "text": "【0】Case 7-2011 — A 52-Year-Old Man with Upper Respiratory Symptoms and Low Oxygen Saturation Levels\nA 52-year-old man had low oxygen saturation by pulse oximetry, without other evidence of hypoxemia. He had dermatitis herpetiformis, treated with dapsone, and type 1 diabetes mellitus, with normal hemoglobin A <sub>1c </sub> levels despite poor glycemic control. A diagnostic test was performed.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 11:06:53", "endTime": "2024/08/14 11:07:09", "cost": 15.785}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 19:07:09", "grab_time": "2024-08-13 19:06:53"}
{"id": 2234496, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "8d45e5c0-49f5-490b-a5f6-8acbb52c0b4c", "title": "A No-Prophylaxis Platelet-Transfusion Strategy for Hematologic Cancers", "text": "【0】A No-Prophylaxis Platelet-Transfusion Strategy for Hematologic Cancers\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】The effectiveness of platelet transfusions to prevent bleeding in patients with hematologic cancers remains unclear. This trial assessed whether a policy of not giving prophylactic platelet transfusions was as effective and safe as a policy of providing prophylaxis.\n\n【3】Methods\n-------\n\n【4】We conducted this randomized, open-label, noninferiority trial at 14 centers in the United Kingdom and Australia. Patients were randomly assigned to receive, or not to receive, prophylactic platelet transfusions when morning platelet counts were less than 10×10 <sup>9 </sup> per liter. Eligible patients were persons 16 years of age or older who were receiving chemotherapy or undergoing stem-cell transplantation and who had or were expected to have thrombocytopenia. The primary end point was bleeding of World Health Organization (WHO) grade 2, 3, or 4 up to 30 days after randomization.\n\n【5】Results\n-------\n\n【6】A total of 600 patients (301 in the no-prophylaxis group and 299 in the prophylaxis group) underwent randomization between 2006 and 2011. Bleeding of WHO grade 2, 3, or 4 occurred in 151 of 300 patients (50%) in the no-prophylaxis group, as compared with 128 of 298 (43%) in the prophylaxis group (adjusted difference in proportions, 8.4 percentage points; 90% confidence interval, 1.7 to 15.2; P=0.06 for noninferiority). Patients in the no-prophylaxis group had more days with bleeding and a shorter time to the first bleeding episode than did patients in the prophylaxis group. Platelet use was markedly reduced in the no-prophylaxis group. A prespecified subgroup analysis identified similar rates of bleeding in the two study groups among patients undergoing autologous stem-cell transplantation.\n\n【7】Conclusions\n-----------\n\n【8】The results of our study support the need for the continued use of prophylaxis with platelet transfusion and show the benefit of such prophylaxis for reducing bleeding, as compared with no prophylaxis. A significant number of patients had bleeding despite prophylaxis. \n\n【9】Introduction\n------------\n\n【10】In patients with hematologic cancers, severe thrombocytopenia frequently develops as a consequence of the disease or its treatment. Most platelet transfusions are administered as prophylaxis, to increase low platelet counts and reduce the risk of bleeding.  However, the degree to which prophylactic platelet transfusions benefit patients with severe thrombocytopenia has been unclear.  A recent trial suggested that a policy of giving platelet transfusions only as treatment for bleeding might become a new standard of care in selected patients,  although the primary end point was a reduction in the number of platelet transfusions, not a clinical outcome such as bleeding.\n\n【11】We conducted a randomized, controlled trial to assess whether a policy of no prophylactic platelet transfusions was noninferior to prophylactic platelet transfusions with regard to the frequency of hemorrhage, on the basis of a platelet-count threshold of less than 10×10 <sup>9 </sup> per liter, which represents the current standard of practice for patients with hematologic cancers. \n\n【12】Methods\n-------\n\n【13】Study Design and Objective\n--------------------------\n\n【14】We conducted a randomized, parallel-group, open-label, noninferiority trial at 14 hematology centers in the United Kingdom and Australia. The primary objective was to determine whether a policy of not giving platelet transfusions as prophylaxis against clinical bleeding was as safe and effective as the provision of prophylaxis. Clinical bleeding was defined as bleeding of World Health Organization (WHO) grade 2 or higher, up to 30 days after randomization. The WHO grading system is the most commonly used assessment of the severity of bleeding events in platelet-transfusion trials.  In the WHO system, bleeding episodes are categorized as grade 1 (mild), grade 2 (moderate; red-cell transfusion not needed immediately), grade 3 (severe; requiring red-cell transfusion within 24 hours), or grade 4 (debilitating or life-threatening).\n\n【15】Eligibility Criteria\n--------------------\n\n【16】Eligible patients were persons 16 years of age or older who were undergoing, or about to undergo, chemotherapy or stem-cell transplantation to treat a hematologic cancer and who had or were expected to have thrombocytopenia (platelet count, <50×10 <sup>9 </sup> per liter) for at least 5 days. Exclusion criteria were a previous bleeding episode of WHO grade 3 or 4, a bleeding episode of WHO grade 2 during the current admission, an inherited hemostatic or thrombotic disorder, a requirement for therapeutic doses of anticoagulant agents, a diagnosis of acute promyelocytic leukemia, known HLA antibodies, or prior randomization in this trial.\n\n【17】Intervention\n------------\n\n【18】Patients were randomly assigned to receive either prophylactic platelet transfusions, or no prophylaxis, if the platelet count was less than 10×10 <sup>9 </sup> per liter. In the prophylaxis group, typically, a single adult dose was given on the same day that the platelet count was recorded to be less than 10×10 <sup>9 </sup> per liter.  The assigned treatment policy applied for 30 days after randomization, regardless of whether the patient was an inpatient or outpatient.\n\n【19】In both trial groups, platelet transfusions were given therapeutically for bleeding, given before invasive procedures, or given at the clinician's discretion (the rationale was recorded). Therapeutic platelet transfusions for bleeding episodes of WHO grade 2 were given according to standard practice, followed by prophylactic platelet transfusions per protocol, if indicated. Patients who had bleeding of WHO grade 3 or 4 during the study received platelet transfusions at the clinician's discretion; these patients no longer received treatment according to the trial protocol, but assessment continued for 30 days after randomization.\n\n【20】The type of platelet component was not specified. All platelet components were leukoreduced, platelets were collected by means of apheresis in approximately 80% of cases, and common hospital practice was to transfuse platelets that were ABO and RhD identical. For applicable national standards for platelet components, see the Supplementary Appendix . The threshold for red-cell transfusion (in the absence of blood loss due to bleeding) was a hemoglobin level of less than 90 g per liter.\n\n【21】Randomization\n-------------\n\n【22】Patients were randomly assigned to the two study groups in a  ratio by means of an independent, centralized, computerized randomization service (telephone-based until 2009 and then Internet-based). The first 10 patients were assigned with the use of simple randomization. The remaining patients were assigned with the use of minimization.  Minimization factors were study center, diagnosis, and treatment plan. Patients were assigned to the preferred treatment with a probability of 0.75. Owing to the nature of the intervention, patients and clinicians were aware of study-group assignments.\n\n【23】Data Collection\n---------------\n\n【24】Data collection continued for 30 days after randomization. Daily bleeding-assessment forms were completed by trained staff members each day that the patient was in the hospital. Patients who were discharged home during the follow-up period completed bleeding diaries  ; if patients reported bleeding, clinical bleeding-assessment forms were completed at the next hospital visit.\n\n【25】To ensure the accuracy and uniformity of bleeding assessments, repeated training sessions, scenario training, and guide notes (laminated information sheets) were provided for study staff, and on-site monitoring was performed, including duplicate bleeding assessments (full details are provided in the Supplementary Appendix ). All written descriptions of bleeding episodes were examined by two assessors who were unaware of the treatment assignments.\n\n【26】Outcomes\n--------\n\n【27】The primary outcome was the percentage of patients who had bleeding events of WHO grade 2, 3, or 4 up to 30 days after randomization . Before study commencement, piloting of the bleeding assessments indicated that certain forms of grade 1 bleeding were considered clinically significant in patients with severe thrombocytopenia and platelet counts of less than 10×10 <sup>9 </sup> per liter and acted as triggers for therapeutic platelet transfusions  ; these events included spreading or generalized petechiae and nosebleeds lasting more than 30 minutes. The grade of the bleeding event was assigned centrally with the use of a computer algorithm, which was validated by means of comparison with a manual assignment system (98% agreement for bleeding events of WHO grade 0 or 1 vs. ≥2 for 1472 bleeding assessments from 148 patients).\n\n【28】Secondary outcomes included the number of days with bleeding events of WHO grade 2, 3, or 4; time from randomization to first bleeding event of WHO grade 2, 3, or 4; bleeding event of WHO grade 3 or 4; numbers of platelet and red-cell transfusions; number of days with a platelet count of less than 20×10 <sup>9 </sup> per liter; time until recovery from thrombocytopenia (platelet count, >50×10 <sup>9 </sup> per liter for 3 days without platelet-transfusion support); and time in the hospital. Data on adverse events related to transfusion were collected from hospitals on the basis of the standard definitions used in the U.K. or Australian national hemovigilance reporting scheme.\n\n【29】Study Oversight\n---------------\n\n【30】The study was undertaken according to the Declaration of Helsinki and Good Clinical Practice principles. The protocol was approved by independent ethics committees in the United Kingdom and Australia. All patients provided written informed consent. An independent data and safety monitoring committee reviewed patient safety and the results of the interim data analysis. The study was conducted as specified by the protocol , and all the authors vouch for the integrity of the data and analyses reported and for the adherence of the study to the protocol. No one who is not an author contributed to the manuscript.\n\n【31】The funding bodies had no role in the analysis or the decision to submit the manuscript for publication; there was no commercial support for this study. The study was managed by the National Health Service Blood and Transplant and Medical Research Council Clinical Studies Unit. The study was adopted by the National Cancer Research Network and included in the United Kingdom Clinical Research Network Portfolio.\n\n【32】Statistical Analysis\n--------------------\n\n【33】The required sample size was calculated on the basis of a difference in proportions for the primary outcome of bleeding of WHO grade 2, 3, or 4. The rate of bleeding events in the prophylaxis group was initially assumed to be approximately 20%.  For 90% power, a one-sided significance level of 5%, and a noninferiority margin of 10%, 280 patients were required in each group. This number was rounded up to 300 patients per group, for a total of 600 patients. It was prespecified that the sample size would be recalculated on the basis of the event rate in the prophylaxis group at a blinded interim analysis after 100 patients had undergone randomization. At this stage, the overall event rate was 48%, which was similar to the rates reported in platelet-dose trials published after this study began.  A proportionately greater noninferiority margin was therefore allowed, at 15%. It was estimated that the original sample of 300 patients per group would provide at least 90% power at a one-sided significance level of 5%.\n\n【34】The primary analysis was based on the intention-to-treat principle and included all patients with at least one completed bleeding-assessment form. Per-protocol analyses were performed as secondary analyses and excluded patients who received a platelet transfusion for reasons not recommended in the protocol .\n\n【35】Noninferiority of the primary outcome was assessed on the basis of a 90% confidence interval for the between-group difference in proportions of patients who had bleeding events of WHO grade 2, 3, or 4 (no-prophylaxis group minus prophylaxis group) and was calculated with the use of a generalized linear model with identity link and binomial family. The declaration of noninferiority required the upper limit of the 90% confidence interval to be lower than the noninferiority margin. Days with missing bleeding assessments were accounted for with the use of a multiple-imputation approach . Sensitivity analyses were performed to assess the robustness of the primary analysis with respect to missing data.\n\n【36】All analyses were adjusted for diagnosis and study treatment as minimization variables  but were not adjusted for center, owing to overstratification. A negative binomial regression model was used to analyze the rate of bleeding events of grade 2, 3, or 4 up to 30 days after randomization, the numbers of platelet and red-cell transfusions and units transfused, the number of days in the hospital, and the number of days with a platelet count of less than 20×10 <sup>9 </sup> per liter. All analyses were performed with the use of Stata software, version 12.1 (StataCorp), and were predefined in the statistical analysis plan unless otherwise specified .\n\n【37】Results\n-------\n\n【38】Study Population\n----------------\n\n【39】Figure 1. Study Enrollment and Randomization.\n\n【40】Of 1075 patients screened, 301 patients were randomly assigned to no prophylaxis and 299 to prophylaxis; 1 patient in each study group withdrew immediately after randomization. A total of 546 patients were enrolled in the United Kingdom and 54 in Australia.Table 1.  Table 1. Baseline Characteristics of the Study Patients, According to Study Group.\n\n【41】Of 1075 patients screened, 600 underwent randomization (301 patients were assigned to no prophylaxis and 299 to prophylaxis) between August 2006 and August 2011 ; 546 patients were enrolled in the United Kingdom and 54 in Australia. Baseline characteristics were well matched between the two study groups . A total of 70% of patients in both groups underwent autologous stem-cell transplantation. Two patients (1 in each group) withdrew from the trial immediately after randomization and were excluded from the primary outcome analysis.\n\n【42】Bleeding Assessments\n--------------------\n\n【43】Bleeding assessments were completed on 93% of study days (8405 of 9030 days) for patients in the no-prophylaxis group and on 97% of study days (8733 of 8970) in the prophylaxis group. The majority of patients in both groups had bleeding information completed on each study day (median in the no-prophylaxis group, 30 days \\[interquartile range, 29 to 30\\]; median in the prophylaxis group, 30 days \\[interquartile range, 30 to 30\\]).\n\n【44】Adherence to Protocol\n---------------------\n\n【45】Most transfusions in both groups were given according to protocol (89% \\[450 of 504 transfusions\\] in the no-prophylaxis group and 91% \\[810 of 894\\] in the prophylaxis group). The proportion of patients who received all transfusions according to protocol was slightly higher in the no-prophylaxis group (86% \\[258 of 300 patients\\]) than in the prophylaxis group (77% \\[230 of 298\\]); patients who received all transfusions according to protocol were included in the per-protocol analysis .\n\n【46】Primary End Point\n-----------------\n\n【47】Bleeding events of WHO grade 2, 3, or 4 occurred in 50% of patients in the no-prophylaxis group (151 of 300 patients), as compared with 43% of those in the prophylaxis group (128 of 298; adjusted difference in proportions, 8.4 percentage points; 90% confidence interval \\[CI\\], 1.7 to 15.2; P=0.06 for noninferiority). Therefore, this study did not show that a no-prophylaxis strategy for platelet transfusions was noninferior to a prophylaxis strategy in relation to the frequency of bleeding events of WHO grade 2, 3, or 4. A post hoc superiority analysis showed that no prophylaxis was inferior to prophylaxis (P=0.04). Sensitivity analyses indicated that these results were robust . Per-protocol results are shown in the Supplementary Appendix .\n\n【48】Secondary End Points\n--------------------\n\n【49】### _Bleeding_\n\n【50】Table 2. Primary and Secondary Bleeding Outcomes. Figure 2.  Figure 2. Time to the Primary Outcome.\n\n【51】The primary outcome was a bleeding episode of grade 2 (moderate; red-cell transfusion not needed immediately), grade 3 (severe; requiring red-cell transfusion within 24 hours), or grade 4 (debilitating or life-threatening), according to the World Health Organization grading scheme. The time to the first bleeding episode was significantly shorter in the no-prophylaxis group than in the prophylaxis group.\n\n【52】Data on bleeding episodes are presented in Table 2 . The number of days with bleeding episodes of WHO grade 2, 3, or 4 during follow-up was higher in the no-prophylaxis group than in the prophylaxis group (rate ratio, 1.52; 95% CI, 1.14 to 2.03; P=0.004). The time to the first bleeding episode was significantly shorter in the no-prophylaxis group than in the prophylaxis group (P=0.02) . Although the proportion of patients with bleeding episodes of WHO grade 3 or 4 was higher in the no-prophylaxis group (2% \\[6 of 300 patients, including 1 with intracranial bleeding\\]) than in the prophylaxis group (<1% \\[1 of 298\\]), this difference was not significant.\n\n【53】There were no deaths due to bleeding. Only two of the seven patients who had bleeding of WHO grade 3 or 4 had a platelet count of less than 10×10 <sup>9 </sup> per liter at the onset of the bleeding episode (overall median platelet count, 16×10 <sup>9 </sup> per liter \\[range, 3×10 <sup>9 </sup> to 42×10 <sup>9 </sup> per liter\\]). Both these patients were in the no-prophylaxis group and were receiving induction chemotherapy for acute myeloid leukemia (data not shown).\n\n【54】### _Platelet Counts_\n\n【55】Table 3. Other Secondary Outcomes.\n\n【56】The average number of days with a platelet count of less than 20×10 <sup>9 </sup> per liter or less than 10×10 <sup>9 </sup> per liter was greater among patients in the no-prophylaxis group than among those in the prophylaxis group (P<0.001) . There was no significant difference in the time to recovery from thrombocytopenia between the two groups .\n\n【57】### _Platelet Transfusions_\n\n【58】The proportion of patients who received platelet transfusions was lower in the no-prophylaxis group than in the prophylaxis group (59% \\[176 of 300 patients\\] vs. 89% \\[266 of 298\\]), P<0.001) . The mean (±SD) number of platelet transfusions per patient was also lower in the no-prophylaxis group (1.7±2.6 vs. 3.0±3.2) . The total number of platelet units transfused was 580 in the no-prophylaxis group and 964 in the prophylaxis group.\n\n【59】### _Other Outcomes_\n\n【60】No significant difference between the study groups was noted in the number of days spent in the hospital or in the number of patients receiving a red-cell transfusion. A small but significant increase in the number of red-cell units transfused per patient was seen in the no-prophylaxis group .\n\n【61】### _Subgroup Analysis_\n\n【62】A predefined subgroup analysis showed a significant interaction between patients who underwent autologous stem-cell transplantation and other patients (P=0.04) . Within the subgroup of patients who underwent autologous stem-cell transplantation, a bleeding event of WHO grade 2, 3, or 4 occurred in 47% of the patients in the no-prophylaxis group (99 of 210 patients), as compared with 45% of those in the prophylaxis group (95 of 210; difference in proportions, 2.3 percentage points; 90% CI, −5.7 to 10.3).\n\n【63】### _Serious Adverse Events_\n\n【64】The proportion of patients with serious adverse events (including sepsis and respiratory deterioration) did not differ significantly between the study groups (6% of patients in the no-prophylaxis group \\[18 of 300 patients\\] and 7% of those in the prophylaxis group \\[20 of 298\\]; odds ratio with no prophylaxis, 0.85; 95% CI, 0.43 to 1.66; P=0.63). There was one transfusion-related serious adverse event (urticaria and angioedema), which occurred in the prophylaxis group.\n\n【65】Discussion\n----------\n\n【66】A general finding across all trials of prophylactic platelet transfusions, including the two largest studies that compared different thresholds for prophylaxis  or doses,  has been a lack of significant difference between trial groups in hemostatic outcomes (i.e., no increased bleeding with a restrictive policy of prophylaxis, regardless of whether the comparison was with a lower threshold for platelet count or a lower platelet dose for prophylaxis). This has raised questions about the benefit of prophylaxis.\n\n【67】In our study, more bleeding events of WHO grade 2, 3, or 4 occurred in the no-prophylaxis group than in the prophylaxis group, with a significant increase in the number of days with bleeding events of WHO grade 2, 3, or 4 and a decreased time to the first bleeding event of WHO grade 2, 3, or 4. Virtually all these bleeding episodes were WHO grade 2; only 7 of the 600 patients in the study had a bleeding event of WHO grade 3 or 4. More patients in the no-prophylaxis group had bleeding events of WHO grade 3 or 4, but this difference was not significant. The results of our study support the need for the continued use of prophylaxis with platelet transfusion and show the benefit of such prophylaxis for reducing bleeding, as compared with no prophylaxis. However, even though patients who received prophylactic platelet transfusions had fewer bleeding events overall, the rate of bleeding events of WHO grade 2, 3, or 4 remained high in this group (43%).\n\n【68】Most of the study participants were undergoing autologous stem-cell transplantation. Among these patients, the rates of bleeding events of WHO grade 2, 3, or 4 were similar in the two study groups. These results differ from those in a recent trial,  which showed rates of WHO grade 2 bleeding episodes that were higher among patients in the no-prophylaxis group who had undergone autologous stem-cell transplantation. Despite this finding, the authors suggested that a strategy of “therapeutic only” transfusion might become the standard of care at selected centers.  Our trial was not powered to specifically address the question of whether the strategy of no prophylactic platelet transfusions in patients undergoing autologous stem-cell transplantation is effective and safe. Such a strategy requires further research.\n\n【69】In our trial, the treatment effect was larger in the subgroup of patients with hematologic cancers who were treated with chemotherapy or allogeneic hematopoietic stem-cell transplantation than in those undergoing autologous stem-cell transplantation. Prophylactic platelet transfusions were associated with a marked reduction in the proportion of patients in whom WHO grade 2, 3, or 4 bleeding events developed. In the study by Wandt et al.,  higher rates of grade 3 or 4 bleeding events were also reported among patients with acute myeloid leukemia who received no prophylaxis, as compared with those who received prophylaxis, although the study protocol specified cranial imaging only in cases of patient-reported headaches in the no-prophylaxis group. On the basis of these findings, the use of prophylactic platelet transfusions in patients with hematologic cancers treated with chemotherapy or allogeneic hematopoietic stem-cell transplantation appears to be important.\n\n【70】The strengths of our trial include good protocol adherence and little loss to follow-up. There was a large decrease in platelet transfusions among patients in the no-prophylaxis group, as compared with those in the prophylaxis group, and evidence of a clear difference in mean platelet counts between the two groups. The computer algorithm used to assign WHO bleeding grades was validated by means of comparison with manual grading methods .  Rates of recorded bleeding can vary considerably among studies,  and a potential limitation of our study was heterogeneity in the assessment of bleeding at different participating centers. To address this issue, multiple measures were taken to standardize the documentation and recording of bleeding in our trial, including training and monitoring of the assessors .\n\n【71】Several issues are pertinent to trials of platelet transfusions, specifically those designed as noninferiority studies. Defining acceptable limits for increased rates of bleeding is challenging because little research has been done to understand how patients' and clinicians' perceptions of bleeding may vary. Bleeding events of WHO grade 2 are heterogeneous and may be considered to have varying degrees of clinical significance. However, such events (including skin bleeding) account for a large proportion of the primary-outcome events in this and other trials.  In our study, an analysis that excluded episodes of skin bleeding showed the same pattern of results .\n\n【72】The results of the primary analysis in the intention-to-treat population were compared with the results of per-protocol analyses, as is often recommended for noninferiority trials.  The results of these two analyses differed: the intention-to-treat analysis showed that the no-prophylaxis policy was statistically inferior, whereas the per-protocol analysis showed that it was noninferior. The reason may be related to the proportion of patients with bleeding who were excluded from the no-prophylaxis group, as compared with the prophylaxis group, leading to a potentially biased per-protocol analysis in favor of the no-prophylaxis group .\n\n【73】One of the challenges of conducting transfusion trials is to select a primary outcome with clinical relevance instead of simply using a change in the number of transfusions as the primary outcome.  This trial shows that transfusion studies with primary clinical outcomes can address fundamental issues of effectiveness.  Our results indicate that prophylactic platelet transfusions reduced rates of bleeding events in patients with hematologic cancers. The proportion of patients who had bleeding events of WHO grade 2, 3, or 4 was reduced by 7% overall in the group that received prophylactic platelet transfusions.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-14 00:20:31", "grab_time": "2024-08-13 23:09:02"}
{"id": 2234495, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "ad995660-9afd-414a-9b2a-87b5dc078fcb", "title": "Endorphins and the Control of Breathing — Ability of Naloxone to Restore Flow-Resistive Load Compensation in Chronic Obstructive Pulmonary Disease", "text": "【0】Endorphins and the Control of Breathing — Ability of Naloxone to Restore Flow-Resistive Load Compensation in Chronic Obstructive Pulmonary Disease\nAbstract\n--------\n\n【1】Since narcotic drugs profoundly depress breathing, we tested whether endogenous opioids influenced control of breathing in chronic obstructive pulmonary disease (COPD), reasoning that the stress of chronic dyspnea might cause elaboration of \"endorphins.\" In 14 patients with COPD (but without respiratory failure) and eight normal controls, we measured ventilation, mechanical lung function, respiratory sensitivity to carbon dioxide, and the increase in respiratory effort elicited by an increase in resistance to breathing; each measurement was performed before and after administration of the opiate antagonist naloxone. Before naloxone, increased resistance to breathing enhanced respiratory effort in all controls, but seven of 14 patients with COPD had no response. After naloxone, these seven patients had load responses. Furthermore, the respiratory effort elicited by the resistance also increased after the drug was given to the patients who had had a response. These data suggest that endorphin elaboration minimizes the stress of chronic airway obstruction.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:51:44", "endTime": "2024/08/14 15:51:51", "cost": 6.324}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 23:51:51", "grab_time": "2024-08-13 23:51:44"}
{"id": 2234494, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "fc2de87c-e783-40a5-a584-e39835ee6b56", "title": "Immunologic Factors and Clinical Activity in Systemic Lupus Erythematosus", "text": "【0】Immunologic Factors and Clinical Activity in Systemic Lupus Erythematosus\nAbstract\n--------\n\n【1】To clarify the association between certain immunologic factors and clinical activity in patients with systemic lupus erythematosus, 96 patients were studied. Those with antibodies to deoxyribonucleic acid (DNA) or heat-denatured DNA, or with serum complement levels of less than 50 C′H50 units per ml, were more likely to have renal involvement. Very low complement levels and high titers of complement-fixing antibodies to DNA were always associated with active disease, especially active renal disease, whereas the absence of these abnormalities usually indicated inactive renal disease. A 50 per cent fall in serum complement levels in 22 patients was accompanied by, or preceded the onset of, active nephritis in 19 patients. These serologic factors may thus reflect the in vivo formation of immune complexes that cause nephritis. Serial immunochemical observations may be useful in the management of patients with systemic lupus erythematosus.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:27:15", "endTime": "2024/08/14 15:27:22", "cost": 6.577}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 23:27:22", "grab_time": "2024-08-13 23:27:15"}
{"id": 2234493, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "151a3350-2c07-4dd1-a419-84ee27d2fa68", "title": "Fundamentals of Public Health: The Patchwork U.S. Public Health System", "text": "【0】Fundamentals of Public Health: The Patchwork U.S. Public Health System\n### Audio Interview\n\n【1】 Interview with Dr. Joshua Sharfstein on the haphazard organization of U.S. public health at the local, state, and federal levels. \n\n【2】The U.S. public health system is an uneven patchwork. In the shadow of a pandemic, understanding this haphazard architecture is a step toward elucidating the U.S. paradox of enormous health expenditures but poor outcomes for population health.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 18:25:42", "endTime": "2024/08/13 18:25:47", "cost": 4.906}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 02:25:48", "grab_time": "2024-08-13 02:25:42"}
{"id": 2234492, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "34565989-5fa4-4c2b-a844-5550eeef5afb", "title": "Case 18-2019: A 24-Year-Old Woman with a Pelvic Mass", "text": "【0】Case 18-2019: A 24-Year-Old Woman with a Pelvic Mass\nA 24-year-old woman was evaluated at the hospital for a pelvic mass. Several weeks earlier, intermittent vaginal bleeding, increased abdominal girth, and mild pelvic pain had developed. The blood human chorionic gonadotropin level was elevated. Management decisions were made.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:03:20", "endTime": "2024/08/14 15:03:29", "cost": 8.754}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 23:03:29", "grab_time": "2024-08-13 23:03:20"}
{"id": 2234491, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "9060619a-36c2-445f-afac-8fc62a0d1b50", "title": "The Natural History of the Inherited Methylmalonic Acidemias", "text": "【0】The Natural History of the Inherited Methylmalonic Acidemias\nAbstract\n--------\n\n【1】Six biochemical and genetic forms of methylmalonic acidemia have been defined previously: two ( _mut_ ° and _mut_  ) resulting from defects in the mutase apoenzyme, and four ( _cbl A, cbl B, cbl C_ , and _cbl D_ ) resulting from deficient adenosylcobalamin synthesis. We retrospectively surveyed the clinical presentation, response to cobalamin supplementation, and long-term outcome in the four most prevalent mutant classes by collecting detailed information on 45 patients (15 _mut_ °, 5 _mut_  , 14 _cbl A_ , and 11 _cbl B_ ). Most patients presented acutely with a common set of clinical and laboratory findings; however, there were significant differences between mutant classes: _mut_ ° patients presented earlier in infancy than did _cbl A_ and _cbl B_ patients; in response to cobalamin supplements, marked decreases in the concentration of methylmalonic acid in blood or urine were reported in most _cbl A_ patients and in nearly half the _cbl B_ patients, but not in _mut_ ° or _mut_  patients; and finally, most _cbl A, cbl B_ , and _mut_  patients were still living, whereas most _mut_  patients died during the first few months of life.\n\n【2】Our data indicate that genotypic classification of the methylmalonic acidemias has prognostic and therapeutic use as well as diagnostic value.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:50:41", "endTime": "2024/08/14 14:50:52", "cost": 10.784}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 22:50:52", "grab_time": "2024-08-13 22:50:41"}
{"id": 2234490, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "c352e7b3-8e9b-4b58-9050-6347e5db9c2d", "title": "High-Dose Melphalan versus Melphalan plus Dexamethasone for AL Amyloidosis", "text": "【0】High-Dose Melphalan versus Melphalan plus Dexamethasone for AL Amyloidosis\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】High-dose chemotherapy followed by autologous hematopoietic stem-cell transplantation has been reported to provide higher response rates and better overall survival than standard chemotherapy in immunoglobulin-light-chain (AL) amyloidosis, but these two strategies have not been compared in a randomized study.\n\n【3】Methods\n-------\n\n【4】We conducted a randomized trial comparing high-dose intravenous melphalan followed by autologous hematopoietic stem-cell rescue with standard-dose melphalan plus high-dose dexamethasone in patients with AL amyloidosis. Patients (age range, 18 to 70 years) with newly diagnosed AL amyloidosis were randomly assigned to receive intravenous high-dose melphalan plus autologous stem cells or oral melphalan plus oral high-dose dexamethasone.\n\n【5】Results\n-------\n\n【6】Fifty patients were enrolled in each group. The results were analyzed on an intention-to-treat basis, with overall survival as the primary end point. After a median follow-up of 3 years, the estimated median overall survival was 22.2 months in the group assigned to receive high-dose melphalan and 56.9 months in the group assigned to receive melphalan plus high-dose dexamethasone (P=0.04). Among patients with high-risk disease, overall survival was similar in the two groups. Among patients with low-risk disease, there was a nonsignificant difference between the two groups in overall survival at 3 years (58% in the group assigned to receive high-dose melphalan vs. 80% in the group assigned to receive melphalan plus high-dose dexamethasone; P=0.13).\n\n【7】Conclusions\n-----------\n\n【8】The outcome of treatment of AL amyloidosis with high-dose melphalan plus autologous stem-cell rescue was not superior to the outcome with standard-dose melphalan plus dexamethasone. \n\n【9】Introduction\n------------\n\n【10】The origin of amyloid in systemic immunoglobulin-light-chain (AL) amyloidosis is a clone of plasma cells in the bone marrow that synthesizes monoclonal immunoglobulin light chains. In tissues, these light chains aggregate into amyloid fibrils. The accumulation of amyloid deposits in vital organs leads to progressive disability and death. Life expectancy depends on the degree of organ involvement and ranges from a few years to less than 6 months for patients with severe cardiomyopathy.  In the mid-1990s, two randomized trials showed that standard-dose chemotherapy with melphalan and prednisone could prolong survival in patients with AL amyloidosis,  but clinical responses were rare and overall survival was extended by only a few months.\n\n【11】High-dose melphalan with autologous hematopoietic stem-cell rescue was introduced in the early 1990s, and it is increasingly used to treat patients with AL amyloidosis. However, transplant-related mortality is high, ranging between 13% (in referral centers) and 43% (in a French retrospective multicenter study).  The survival benefit of high-dose melphalan has been attributed to a patient-selection bias,  but a case–control study suggested a survival advantage for high-dose melphalan plus hematopoietic stem-cell rescue as compared with conventional treatment.  The present study is a randomized comparison of high-dose melphalan plus autologous hematopoietic stem-cell rescue with standard-dose melphalan plus high-dose dexamethasone in patients with AL amyloidosis.\n\n【12】Methods\n-------\n\n【13】Patients\n--------\n\n【14】Patients between 18 and 70 years of age who had biopsy-proven systemic AL amyloidosis, who had received no more than two previous courses of any chemotherapy regimen, who did not have symptomatic multiple myeloma, and who had an Eastern Cooperative Oncology Group (ECOG) performance-status score of 2 or lower were eligible. The inclusion criteria were a histologic diagnosis of amyloidosis and either immunohistochemical characterization of the amyloid deposits or evidence of a monoclonal immunoglobulin protein in the serum or urine specimen or a monoclonal staining pattern of bone marrow plasma cells. When immunohistochemical characterization was lacking, an effort was made to rule out hereditary amyloidosis by taking into account the patient's family history and the pattern of organ involvement.\n\n【15】The protocol was approved by the local ethics committee, and all of the patients gave their written informed consent. Randomization was based on a balanced randomization list with the use of blocks of variable size, stratified according to age (younger than 65 years or 65 years or older) and according to the affected organ system (cardiac, renal, neurologic, or other).\n\n【16】Treatment\n---------\n\n【17】Patients in the group assigned to receive melphalan plus dexamethasone received monthly courses of oral melphalan (10 mg per square meter of body-surface area on days 1 to 4) plus high-dose oral dexamethasone (40 mg per day on days 1 to 4) for up to 18 treatment courses if no severe adverse effects occurred. In January 2002, when 43 patients had been included, the protocol was amended to permit discontinuation of treatment after 12 courses if a complete hematologic remission occurred. The dose of melphalan was adjusted during the first three courses in order to induce mild cytopenia (white-cell count, <3000 per cubic millimeter) at midcourse. Prophylaxis with proton-pump inhibitors and trimethoprim–sulfamethoxazole (one double-strength tablet thrice weekly) was recommended.\n\n【18】In the group assigned to receive high-dose melphalan, autologous hematopoietic stem cells were obtained from the peripheral blood with granulocyte colony-stimulating factor (G-CSF) (5 μg per kilogram of body weight subcutaneously, twice daily). Cytapheresis was performed on day 5, with the use of the procedure described in the Supplementary Appendix , available with the full text of this article at www.nejm.org. The goal was to collect 2×10 <sup>6 </sup> CD34+ cells per kilogram. If this goal was not achieved, a second attempt to obtain the cells was permitted. Patients then received melphalan, 200 mg per square meter given intravenously on day 0, and stem cells were infused on day 2. The dose of melphalan was reduced to 140 mg per square meter for patients 65 years of age or older and for those with an ejection fraction below 30%, a calculated creatinine clearance of less than 30 ml per minute, or severe liver disease (prothrombin index, <50%; total bilirubin or alkaline phosphatase level, >5 times the normal level). G-CSF was administered subcutaneously daily from day 7 until neutropenia resolved. Transfusions to maintain the platelet count at more than 50,000 per cubic millimeter were recommended.\n\n【19】Assessment of Organ Involvement, Responses, and Outcome\n-------------------------------------------------------\n\n【20】Table 1. Criteria for Organ Involvement, Organ Response, and Hematologic (Immunochemical) Response.\n\n【21】Organ involvement and the response to therapy were evaluated according to the international consensus guidelines,  except that bone marrow studies were not required to define a complete response . Hematologic and clinical responses were analyzed only in patients who received three or more courses of melphalan plus dexamethasone and in patients who survived for more than 3 months after stem-cell transplantation. A clinical response was defined as improvement of an organ known to be involved with amyloid. A complete hematologic response was defined as the complete disappearance of the monoclonal immunoglobulin or light chain in a serum or urine specimen; a partial hematologic response was defined as more than a 50% reduction in these proteins. Light-chain levels in serum were assessed, whenever possible, with the free light-chain assay (Freelite, Binding Site),  which became available for use in this trial in 2003.\n\n【22】Statistical Analysis\n--------------------\n\n【23】The number of patients required for the study was calculated with the use of the log-rank test. The working hypothesis was that high-dose melphalan would improve the survival rate (estimated to be 55.5% in the group assigned to receive melphalan plus dexamethasone) by 25% at 18 months, with a type 1 error rate of 5% and a statistical power of 80%.  Thus, a minimum of 46 patients per group was required, with a total in both groups of at least 25 deaths. We decided to include a total of 100 patients.\n\n【24】The data were analyzed on an intention-to-treat basis. Descriptive analyses were based on frequencies for qualitative variables and means, standard deviations, and medians for quantitative variables. Comparisons were made with the use of the Student's t-test or the Mann–Whitney U test. Frequencies were compared with the use of the chi-square test or Fisher's exact test.\n\n【25】Survival analyses according to the treatment group and organ involvement were based on the Kaplan–Meier method with the use of the log-rank test and a univariate Cox proportional-hazards regression analysis. A two-sided P value of less than 0.05 was considered to indicate statistical significance. The start date was the date of randomization, and the cutoff date was August 15, 2006.\n\n【26】Subgroup analyses of patients with low-risk and those with high-risk AL amyloidosis were planned on the basis of the Mayo Clinic criteria. Patients with low-risk disease have all the following: an interventricular cardiac septum thickness of less than 15 mm, an ejection fraction of more than 55%, a serum creatinine level of 2 mg per deciliter (177 μmol per liter) or less, and a direct bilirubin value of 2 mg per deciliter (34 μmol per liter) or less. \n\n【27】A landmark analysis was also performed to study the efficacy of the two strategies independently of early toxic effects. This analysis focused on patients who survived for at least 6 months after randomization and who received their assigned treatment (either high-dose melphalan or three or more courses of melphalan plus high-dose dexamethasone). \n\n【28】Results\n-------\n\n【29】Figure 1. Randomization, Treatment Assignments, and Receipt of Treatment.\n\n【30】Between January 11, 2000, and January 7, 2005, 100 patients were enrolled in 29 centers . Two patients who had previously received three cycles of standard-dose chemotherapy were not excluded from the group assigned to receive melphalan plus dexamethasone, since this was considered a minor deviation from the inclusion criteria.\n\n【31】Table 2. Baseline Characteristics of the Patients.\n\n【32】Table 2 shows the baseline characteristics of the 100 patients. The AL amyloidosis type was determined by means of immunohistochemical analysis in 60 patients. All of the other patients had a monoclonal protein in blood or urine specimens and clinical features that were characteristic of AL amyloidosis. The AL type of amyloid was confirmed by means of immunohistochemical analysis in all five patients who had normal serum levels of kappa and lambda free light chains at diagnosis.\n\n【33】The characteristics of amyloid disease were well balanced between the two groups of patients . A total of 47 patients had cardiac involvement, 69 patients had renal involvement, 22 patients had nerve involvement, and 26 patients had liver involvement. The median number of organs involved was two (range, one to five). Sixteen patients in the group assigned to melphalan plus dexamethasone and 17 patients in the group assigned to high-dose melphalan had only one affected organ.\n\n【34】Treatment\n---------\n\n【35】Of the 50 patients in the group assigned to high-dose melphalan, 13 did not receive the planned treatment . Of the patients who did not receive the planned treatment, 1 patient declined treatment, 2 patients had an insufficient stem-cell harvest, and 10 patients died (8 patients died suddenly or had progressive heart failure, 1 had progressive hepatic amyloidosis, and 1 had sepsis). One patient's condition worsened before treatment with G-CSF began, and the patient died 40 days after undergoing randomization. Four patients died during treatment with G-CSF. No deaths occurred during leukapheresis. Five patients died between 11 and 45 days after stem-cell collection.\n\n【36】The median number of stem-cell harvests was two (range, 1 to 3); sufficient numbers of stem cells were collected after one course of G-CSF in 35 patients and after two courses of G-CSF in 2 patients. The median number of harvested CD34+ cells was 4.48×10 <sup>6 </sup> per kilogram (range, 0.68 to 11.0).\n\n【37】Of the 37 patients who received stem cells, 10 were given melphalan at a dose of 140 mg per square meter and 27 were given melphalan at a dose of 200 mg per square meter. Of these 37 patients, 9 died within 100 days after receiving high-dose melphalan — 5 from multiorgan failure with acute renal failure, 2 from sepsis, and 2 from cardiac arrhythmia. The transplant-related mortality was 24%. In total, 19 patients died within 130 days after randomization. In 11 patients, the serum creatinine level increased to more than three times the baseline level, and 8 patients required hemodialysis.\n\n【38】In the group assigned to melphalan plus dexamethasone, two patients died early of cardiac arrhythmia — one before receiving any treatment and one on the third day of the first course of treatment. Five other patients died within 130 days after randomization, all from disease progression. Seven patients had toxic effects of grade 3 or more, 16 patients had grade 1 or 2 toxic effects, 10 patients had sepsis, 18 patients had cytopenia, and 1 patient had diabetes mellitus.\n\n【39】The median number of courses of melphalan plus dexamethasone received was 12 (range, 0 to 25). The median time between randomization and initiation of treatment with melphalan plus dexamethasone was 2 days (range, 0 to 41), and the median time between randomization and initiation of treatment with G-CSF was 8 days (range, 0 to 43). The median time between randomization and administration of high-dose melphalan was 36 days (range, 16 to 83).\n\n【40】Hematologic Responses\n---------------------\n\n【41】Forty-three patients in the group assigned to receive melphalan plus dexamethasone received three or more courses of treatment, and 29 patients in the group assigned to receive high-dose melphalan survived for more than 3 months after grafting.\n\n【42】In 65 of these patients (38 in the group assigned to receive melphalan plus dexamethasone and 27 in the group assigned to receive high-dose melphalan), hematologic responses could be evaluated by means of serum and urine electrophoresis, immunofixation, or both methods. The free light-chain assay could also be used to evaluate these responses.\n\n【43】Table 3. Hematologic Response to Chemotherapy by Serum Free Light-Chain Assay, Conventional Techniques, and Both Approaches.\n\n【44】Hematologic responses did not differ significantly between the two treatment groups . They occurred in 26 patients in the group assigned to receive melphalan plus dexamethasone (68%) and in 18 patients in the group assigned to receive high-dose melphalan (66%); the response rates in the intention-to-treat analysis were 52% and 36%, respectively (P=0.11). Responses were evaluated by means of the free light-chain assay in 37 patients (19 in the group assigned to receive melphalan plus dexamethasone and 18 in the group assigned to receive high-dose melphalan). A complete remission was achieved in 9 patients (47%) in the group assigned to receive melphalan plus dexamethasone and in 11 patients (61%) in the group assigned to receive high-dose melphalan; 5 patients (26%) and 2 patients (11%), respectively, had partial remission, and no response was seen in 5 patients in each group.\n\n【45】The median levels of free light chains in serum at the time of best response after treatment were 28 mg per liter (range, 8 to 344) in the group assigned to receive melphalan plus dexamethasone and 26 mg per liter (range, 0.6 to 1140.0) in the group assigned to receive high-dose melphalan. Median pretreatment serum levels of true light chains in patients who underwent evaluation were 239 mg per liter (range, 32 to 1260) in the group assigned to receive melphalan plus dexamethasone and 118 mg per liter (range, 27 to 5460) in the group assigned to receive high-dose melphalan; normal serum values for kappa light chains range from 3.3 to 19.4 mg per deciliter, and normal serum values for lambda light chains range from 5.7 to 26.3 mg per deciliter.\n\n【46】Organ Responses\n---------------\n\n【47】Organ responses  could be assessed in 73 patients. At least one response occurred in 39% of the patients (17 of 44) assigned to receive melphalan plus dexamethasone and in 45% of the patients (13 of 29) assigned to receive high-dose melphalan (P=0.60). In these two groups, renal responses occurred in 11 and 8 patients, hepatic responses occurred in 3 and 5 patients, cardiac responses occurred in 3 and 4 patients, and neurologic responses occurred in 2 patients and 1 patient, respectively.\n\n【48】Relapses and Salvage Treatment\n------------------------------\n\n【49】Hematologic progression after the conclusion of treatment  occurred in six patients in each group. The median time from randomization to hematologic progression was 32.5 months (range, 26 to 47) in the group assigned to receive melphalan plus dexamethasone and 32.0 months (range, 15 to 55) in the group assigned to receive high-dose melphalan. Three patients in the former group received second-line treatment with high-dose melphalan for resistant disease, with less than a partial response. Only one of these patients had a hematologic (complete) response. Other patients with disease progression or resistant disease received various other treatments, but none received more than one high-dose regimen.\n\n【50】Overall Survival\n----------------\n\n【51】Figure 2. Survival According to Hematologic Responses and Treatment Group.\n\n【52】Panel A shows survival according to the hematologic response in 65 patients who could be evaluated. Panel B shows survival according to treatment group. The median survival for the group of patients assigned to melphalan plus dexamethasone was 56.9 months, and the median survival for the group of patients assigned to high-dose melphalan was 22.2 months. The crude estimated hazard ratio for death in the group assigned to receive melphalan plus dexamethasone was 0.57 (95% confidence interval, 0.32 to 0.99; P=0.05).\n\n【53】At the cutoff date of August 15, 2006, the median follow-up time for the entire cohort was 24 months, and for surviving patients it was 36 months. The median survival for the entire cohort was 48 months. Fifty-one patients died (20 in the group assigned to receive melphalan plus dexamethasone and 31 in the group assigned to receive high-dose melphalan) (P=0.04). At the cutoff date, among the surviving patients in the two groups, 23 of 30 patients assigned to receive melphalan plus dexamethasone and 11 of 19 patients assigned to receive high-dose melphalan did not receive additional chemotherapy; the performance-status score was 2 or more in 3 and 5 patients, respectively, and 3 patients and 1 patient, respectively, required long-term dialysis. Only the two late deaths (due to lung cancer and gastric cancer) in the group assigned to receive melphalan plus dexamethasone were not directly related to amyloidosis or to the treatments received. Overall survival after randomization was strongly related to the rate of hematologic responses .\n\n【54】In the intention-to-treat analysis, the Kaplan–Meier estimate of median overall survival was 56.9 months in the group assigned to receive melphalan plus dexamethasone and 22.2 months in the group assigned to receive high-dose melphalan (P=0.04 by the log-rank test) . The crude estimated hazard ratio for death in the group assigned to receive melphalan plus dexamethasone was 0.57 (95% confidence interval \\[CI\\], 0.32 to 0.99; P=0.05). The hazard ratio did not change after adjustment for the main prognostic factors (performance status, number of organs involved, risk group, presence or absence of renal insufficiency, and presence or absence of cardiac involvement). Exclusion of the two patients who had received three courses of melphalan plus dexamethasone before enrollment did not affect these results.\n\n【55】Figure 3. Survival According to Risk Group, According to the Treatment Group among Patients with Low-Risk Disease, and According to the Treatment Group in the Landmark Analysis.\n\n【56】Panel A shows survival according to disease severity. A total of 59 patients were at low risk for an adverse outcome of intensive treatment, and 41 were at high risk. Panel B shows survival according to treatment group in the 59 patients with low-risk disease. The 3-year survival in the group of patients assigned to melphalan plus dexamethasone was 80%, and in the group of patients assigned to high-dose melphalan it was 58%. Panel C shows survival according to treatment group in the landmark analysis. A total of 37 patients were assigned to melphalan plus dexamethasone, and 8 died. A total of 28 patients were assigned to high-dose melphalan, and 10 died.\n\n【57】On the basis of the Mayo Clinic criteria,  59 patients were at low risk for an adverse outcome of intensive treatment, and 41 were at high risk, mainly because of severe cardiac disease.  The estimated 3-year overall survival rates were 70% among patients with low-risk disease and 25% among patients with high-risk disease (P<0.001) . Overall survival was similar in the two groups with high-risk disease (P=0.27). In the group with low-risk disease, overall survival at 3 years was 80% in the group assigned to receive melphalan plus dexamethasone and 58% in the group assigned to receive high-dose melphalan (P=0.13) . Among the 69 patients with renal involvement (proteinuria, defined as >0.5 g of protein per liter), the estimated 3-year overall survival rates were 70% in the group assigned to receive melphalan plus dexamethasone and 37% in the group assigned to receive high-dose melphalan (P=0.02).\n\n【58】In a landmark analysis of patients who survived for at least 6 months after randomization and who received their assigned treatment, there were 10 deaths among the 28 patients in the group assigned to receive high-dose melphalan and 8 deaths among the 37 patients in the group assigned to receive melphalan plus dexamethasone (P=0.38) .\n\n【59】Discussion\n----------\n\n【60】This study, which was powered to show a 25% survival advantage with high-dose melphalan as compared with melphalan plus dexamethasone, did not show any superiority of high-dose melphalan over melphalan plus dexamethasone. On the contrary, the median overall survival was significantly longer (56.9 months) in the group assigned to receive melphalan plus dexamethasone than in the group assigned to receive high-dose melphalan (22.2 months) (P=0.04). Moreover, we found no significant difference in response rates between the two treatment groups. In a nonrandomized study with the use of the free light-chain assay, Lachmann et al. also found no difference in responses to high-dose chemotherapy or cytotoxic regimens such as vincristine, doxorubicin, and dexamethasone (VAD) or cyclophosphamide, vincristine, doxorubicin, and methylprednisolone (C-VAMP). \n\n【61】More than two thirds of patients who received oral melphalan plus dexamethasone had durable hematologic responses. Similar results were reported in 2004 by Palladini et al., who treated 46 patients with melphalan plus dexamethasone and obtained a hematologic response rate of 67% and a clinical response rate of 48%.  These rates are two to three times better than those obtained with the classic melphalan–prednisone combination mainly used in the case–control study in which intensive treatment was shown to offer better survival. \n\n【62】One explanation for the relatively poor results with high-dose melphalan in our study is the high mortality rate before and after such intensive treatment. Most patients were treated in the same hospital where amyloidosis was diagnosed, and the median time from diagnosis to randomization was only 48 days for the two groups combined. Treatment in the same center would tend to limit the selection bias that may occur when patients are treated in tertiary referral centers, where patients who die rapidly after diagnosis cannot be treated.  Because of the time required to collect stem cells and arrange hospitalization for treatment with high-dose melphalan, the delay before initiation of therapy was about 1 month longer in the group assigned to receive high-dose melphalan than in the group assigned to receive melphalan plus dexamethasone. This delay also contributed, along with the toxic effects of the procedure, to the higher number of early deaths in the group assigned to receive high-dose melphalan.\n\n【63】The treatment-related mortality rate after high-dose melphalan was higher in our multicenter study (24%) than in single-center studies of intensive treatment.  However, it was similar to that observed in two other multicenter series: 25% among 114 patients treated in 50 U.S. centers  and 23% among 92 patients treated in 31 British centers.  Thus, our results are representative of those obtained with intensive treatment for AL amyloidosis in multicenter trials, even if the treatment-related mortality rate is reduced by strict patient selection.  The toxic effects of G-CSF in patients with AL amyloidosis should be emphasized, since four of our patients died while receiving G-CSF. \n\n【64】Our inclusion criteria were not as stringent as those used in large North American centers.  To take into account the possible enrollment of patients with advanced disease, resulting in a disadvantage for the group assigned to receive high-dose melphalan, we stratified the patients according to whether they had low-risk or high-risk disease, using the criteria defined by Dispenzieri et al.  Patients with high-risk disease in the two treatment groups had similarly poor outcomes, underlining the need for new treatments for these patients. Patients with low-risk disease are usually considered to be good candidates for intensive treatment. Among such patients in our study, survival did not differ significantly between the two groups.\n\n【65】To reduce the influence of early treatment-related deaths on the survival analysis, we performed a landmark analysis that included only patients who survived for more than 6 months after randomization and who received their assigned treatment. This analysis also showed no advantage of high-dose melphalan as compared with melphalan plus dexamethasone .\n\n【66】In conclusion, this trial shows that high-dose melphalan is not superior to melphalan plus dexamethasone in patients with AL amyloidosis. A trial comparing the two treatments in a tertiary referral center, where the treatment-related mortality rate is likely to be lower, may have different results.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 16:38:45", "endTime": "2024/08/13 16:39:09", "cost": 24.519}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 00:39:09", "grab_time": "2024-08-13 00:38:44"}
{"id": 2234489, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "aca066ee-77e6-4fbc-99ee-0cb12c286d44", "title": "Brief Report: Licorice-Induced Hypermineralocorticoidism", "text": "【0】Brief Report: Licorice-Induced Hypermineralocorticoidism\nIntroduction\n------------\n\n【1】EXCESSIVE ingestion of licorice may result in sodium and water retention, hypertension, hypokalemia, and suppression of the renin-aldosterone system.  <sup>, </sup>  It was thought for years that licorice produced these effects through the binding of its active components, glycyrrhizic acid and its hydrolytic metabolite glycyrrhetinic acid, to mineralocorticoid receptors. Two findings, however, argue against this proposed mechanism. First, the affinity of glycyrrhetinic acid, the most active component of licorice, for mineralocorticoid receptors is 0.01 percent of that of aldosterone.  Second, licorice, or glycyrrhetinic acid, does not have mineralocorticoid effects in patients with Addison's disease  or adrenalectomized rats  unless cortisone or hydrocortisone is administered concomitantly.\n\n【2】Figure 1. Overview of Cortisol Metabolism.\n\n【3】Licorice inhibits 11β-hydroxysteroid dehydrogenase (11β-OHSD) activity, resulting in a relative increase in cortisol (F) metabolites, such as 5α- and 5β-tetrahydrocortisol (The) and cortols, and a relative decrease in cortisone (E) metabolites, such as 5β-tetrahydrocortisone (THE) and cortolones.\n\n【4】Stewart et al.  have proposed that licorice acts by inhibiting Cortisol oxidase, a component of the widely distributed 11β-hydroxysteroid dehydrogenase system that converts Cortisol to cortisone, producing a state of apparent mineralocorticoid excess similar to that in children with 11/3-hydroxysteroid dehydrogenase deficiency  . In vitro, cortisol has the same binding affinity for mineralocorticoid receptors as aldosterone,  whereas that of cortisone is much less. Licorice, by inhibiting 11β-hydroxysteroid dehydrogenase in aldosterone-responsive tissues such as the kidney, where it is found in high concentrations,  <sup>, </sup>  produces high renal levels of cortisol, which then binds to and activates mineralocorticoid receptors.  The degree to which licorice inhibits 11β-hydroxysteroid dehydrogenase activity can be measured by examining the ratio of the metabolites of cortisone to those of cortisol in urine.\n\n【5】Epstein et al.  studied several subjects with a history of chronic licorice ingestion and found that the renin-aldosterone axis was suppressed while the subjects were taking licorice, but normal function resumed within two to four months after licorice was discontinued. The pattern of clinical and hormonal recovery of suppressed 11β-hydroxysteroid dehydrogenase activity has not been determined, however. In the present study we examined the duration of the suppressive effects of licorice on 11β-hydroxysteroid dehydrogenase activity and the renin-aldosterone system before and after licorice withdrawal in a patient with chronic licorice intoxication.\n\n【6】Case Report\n-----------\n\n【7】A 70-year old man was referred to us for an evaluation of hypertension and hypokalemia. Hypertension had been diagnosed four years earlier and had been severe during the previous year. Nine months before referral, therapy with a thiazide diuretic agent had produced severe hypokalemia (plasma potassium level, 1.9 mmol per liter) and rhabdomyolysis. The patient subsequently required potassium supplements and spironolactone to maintain normal potassium levels and blood pressure. His symptoms during the year before our evaluation included weakness, mental slowness, and the loss of approximately 15 kg in weight. An investigation of possible mineralocorticoid excess while he was taking medications revealed normal plasma levels of renin activity, aldosterone, and 18-hydroxycorticosterone.\n\n【8】He was admitted to our clinic to be evaluated for possible mineralocorticoid excess due to factors other than aldosterone. Further history taking, however, revealed that he had been eating 60 to 100 g of licorice candies, each weighing 2.5 g (Panda, Vaajakoski, Finland), daily for the past four to five years. The licorice contained approximately 0.3 percent glycyrrhizic acid, which is converted to glycyrrhetinic acid after ingestion. The patient's medications, which he continued to take until the day of admission, included potassium chloride (20 mmol three times daily), spironolactone (25 mg four times daily), and verapamil (240 mg daily). He stopped eating licorice one week before admission. Physical examination revealed the patient to be a thin man with a blood pressure of 124/63 mm Hg; the examination was normal in other respects. The plasma sodium level was 137 mmol per liter, and the plasma potassium level was 5.7 mmol per liter.\n\n【9】Methods\n-------\n\n【10】The patient was admitted to the General Clinical Research Center of San Francisco General Hospital Medical Center. Because he had hyperkalemia, licorice was again incorporated into his diet (approximately 100 g per day, or 300 mg of glycyrrhetinic acid per day, an amount similar to that used by Stewart et al.  ) to determine sodium retention, potassium excretion, and 11β-hydroxysteroid dehydrogenase activity. The potassium supplements and spironolactone were stopped; verapamil treatment was continued throughout the two-week study period.\n\n【11】During the study, the patient ate a constant diet, which included 135 mmol of sodium and 85 mmol of potassium per day. His blood pressure, weight, and plasma sodium and potassium levels were measured daily, as was urinary sodium and potassium excretion. Plasma renin activity, levels of aldosterone, cortisol, and deoxycorticosterone, and urinary excretion of aldosterone, cortisol, glycyrrhetinic acid, and steroids were measured intermittently.\n\n【12】The licorice was discontinued after one week. We continued to measure urinary electrolytes, plasma renin activity, plasma aldosterone, and urinary glycyrrhetinic acid and steroids during a second week of hospitalization. After discharge, the patient was seen at intervals of one to two months for continued hormonal measurements, and plasma samples were collected under random conditions for the measurement of renin activity and aldosterone. The patient was asked to continue eating the same amounts of sodium and potassium after discharge.\n\n【13】The study was approved by our institutional review committee, and the patient gave informed written consent.\n\n【14】Assay of Plasma Steroids, Urinary Aldosterone, and Urinary Cortisol\n-------------------------------------------------------------------\n\n【15】Plasma concentrations of aldosterone, cortisol, and deoxycorticosterone were measured by radioimmunoassay after isolation by high-performance liquid chromatography, as previously described.  Urinary aldosterone was measured as the 18-glucuronide metabolite by radioimmunoassay (normal range, 11 to 55.6 nmol per day), and urinary cortisol by radioimmunoassay after isolation by high-performance liquid chromatography (normal range, 3 to 119 nmol per day). Plasma renin activity was determined by radioimmunoassay of angiotensin I in plasma incubated in vitro. \n\n【16】Gas Chromatography and Mass Spectrometry of Urinary Steroid Metabolites\n-----------------------------------------------------------------------\n\n【17】Urinary steroids were measured by gas chromatography and mass spectrometry according to an automated procedure.  The steroid conjugates were extracted with a C18 cartridge, hydrolyzed, and the hydrolysis mixtures extracted again. After formation of methyloxime and trimethylsilyl derivatives, the steroids were separated and quantified with a gas chromatograph-mass spectrometer (model 5970, Hewlett-Packard, Waltham, Mass.). Thirty-five urinary steroids, including metabolites of cortisol and androgens, were measured by a specific technique of selected ion monitoring to monitor changes in metabolism after licorice withdrawal.\n\n【18】Although numerous steroids were measured in each urine sample, only selected cortisol metabolites were considered to be relevant to this study. These were steroids that provided information concerning the relative activity of enzymes involved in cortisone reduction and cortisol oxidation (i.e., reactions catalyzed by 11β-hydroxysteroid dehydrogenase), the relative production of 5α- and 5β-reduced products of steroids, and the overall excretion of cortisol metabolites retaining the hormonal 3-oxo-4-ene structure (an intact A ring). These categories were selected on the basis of the following findings: in the syndrome of apparent mineralocorticoid excess in children, which licorice ingestion mimics, the conversion of cortisol to cortisone is impaired; 5α-reduction of cortisol is relatively more important than 5β-reduction; and there is an overall decrease in A-ring reduction. To evaluate 11β-hydroxysteroid dehydrogenase activity, we measured the ratio of tetrahydrocortisone to 5β-tetrahydrocortisol plus 5α-tetrahydrocortisol and the ratio of α-cortolone plus β-cortolone to α-cortol plus β-cortol. To evaluate the potential attenuation of 5β-reduction, we determined the ratio of 5β-tetrahydrocortisol to 5α-tetrahydrocortisol.\n\n【19】Gas Chromatography and Mass Spectrometry of Urinary Glycyrrhetinic Acid\n-----------------------------------------------------------------------\n\n【20】Urinary glycyrrhetinic acid was measured by gas chromatography and mass spectrometry (Hewlett-Packard) after silylation of a hydroxyl group and methylation of a carboxyl group. Internal standards, stigmasterol and cholesteryl butyrate, were added to a portion of the urine extracts. The urine extracts were dissolved in 0.5 ml of ethereal diazomethane (prepared in a Wheaton generator  ), and methylation was completed within five minutes at room temperature. After the ether was evaporated under nitrogen, silylation was carried out with trimethylsilyl-imidazole.  The carbonyl group at position 11 in glycyrrhetinic acid is not reactive under the conditions used for the formation of methyloxime; the methyloxime reaction was thus not necessary.\n\n【21】Derivatives of authentic glycyrrhetinic acid were found in the presence of the internal standards, and the mass spectrum was analyzed by gas chromatography and mass spectrometry. The molecular ion was observed at m/z 556, and prominent ions were seen at m/z 427 (M-129) and m/z 317 (M-129–90). These ions were considered suitable for the assay of urinary glycyrrhetinic acid derivatives by selected ion monitoring. The instrument was set up to monitor these ions and the ion m/z 368 from the internal standard cholesterol butyrate. We measured urinary glycyrrhetinic acid with a standard curve generated by using known amounts of glycyrrhetinic acid in the assay.\n\n【22】Results\n-------\n\n【23】Electrolyte Balance and Plasma Steroid Levels\n---------------------------------------------\n\n【24】Figure 2. Plasma Potassium Concentrations (Circles), Urinary Excretion of Sodium (Solid Bars) and Potassium (Hatched Bars) Electrolytes, and Measurements of the Renin-Aldosterone System before and during Licorice Ingestion and for the First Five Days after Licorice Withdrawal.\n\n【25】The initial measurements were obtained before the patient was admitted to the hospital. Plasma renin activity was measured as levels of angiotensin I (normal range, 0.14 to 1.8 ng per liter · second). Urinary aldosterone was measured as the 18-glucuronide metabolite (normal range, 11.8 to 55.6 nmol per day). The normal range for plasma aldosterone concentration is 111 to 334 pmol per liter. ND denotes not determined.\n\n【26】At the time of admission the patient had hyperkalemia because he had continued to take potassium supplements and spironolactone for at least one week after ceasing to eat licorice . After he began ingesting licorice again, the net sodium balance became positive and the net potassium balance negative, with a decline in plasma potassium to subnormal levels by the end of the two-week inpatient period. These changes in electrolyte balance were accompanied by an increase in body weight of 4.9 kg and a moderate increase in blood pressure (from 124/63 to 154/72 mm Hg). The effects of licorice on electrolyte metabolism persisted for a week after the patient discontinued licorice. During the ensuing months, his blood pressure was normal (verapamil therapy was continued), as was his plasma potassium concentration (without supplementation). Plasma levels of deoxycorticosterone (mean \\[±SD\\] level, 303±64 pmol per liter) and cortisol (309±22 nmol per liter) were consistently normal throughout the study period.\n\n【27】Renin-Aldosterone System\n------------------------\n\n【28】Figure 3. Recovery of Plasma Renin Activity, Plasma Aldosterone Levels, and Urinary Aldosterone Excretion after the Withdrawal of Licorice.\n\n【29】Measurements were made with the patient in a recumbent position. Day 0 was the final day of licorice ingestion. Values at right are normal ranges.\n\n【30】The levels of plasma renin activity, plasma aldosterone, and urinary aldosterone excretion were elevated at the time of admission, when the patient had hyperkalemia as a result of potassium supplementation and spironolactone therapy. During the week in which he received licorice in the hospital, these hormones all fell to low levels. Sixty-four days after licorice withdrawal, basal plasma renin activity and plasma and urinary aldosterone concentrations were slightly low or normal , and they rose further by day 130.\n\n【31】Urinary Steroid and Glycyrrhetinic Acid Excretion\n-------------------------------------------------\n\n【32】Figure 4. Urinary Excretion of Glycyrrhetinic Acid (Stippled Circles) and Cortisol (Bars), and the Ratio of Tetrahydrocortisone to 5β-Tetrahydrocortisol plus 5α-Tetrahydrocortisol (Solid Circles) in Urine after Licorice Withdrawal.\n\n【33】Day 0 was the final day of licorice ingestion.Table 1.  Table 1. Ratios of Urinary Cortisol Metabolites during and after the Ingestion of Licorice.\n\n【34】Urinary glycyrrhetinic acid excretion and selected urinary steroid ratios are shown in Figure 4 and Table 1 . At the end of the one-week period of licorice treatment, urinary cortisol excretion was elevated and the ratio of urinary tetrahydrocortisone to 5β-tetrahydrocortisol plus 5α-tetrahydrocortisol was low, indicating the inhibition of 11β-hydroxysteroid dehydrogenase activity. Urinary glycyrrhetinic acid, which was present in the first three urine samples after the ingestion of licorice ended, was undetectable 18 days after licorice withdrawal. Concomitant with the decrease in urinary excretion of glycyrrhetinic acid, urinary cortisol excretion normalized. The ratio of tetrahydrocortisone to 5β-tetrahydrocortisol plus 5α-tetrahydrocortisol, which was much lower than normal when licorice was ingested, gradually increased to a normal level by day 27. The pattern of results for the ratios of cortolones to cortols was similar.\n\n【35】The measurements of 5α- and 5β-reduced cortisol metabolites  revealed several unexpected findings. The ratio of 5β-tetrahydrocortisol to 5α-tetrahydrocortisol was initially elevated but decreased over a one-month period, indicating a relative increase in the 5α-reduced product. The ratio of unconjugated cortisol metabolites to total cortisol metabolites was elevated, but gradually declined to normal levels.\n\n【36】Discussion\n----------\n\n【37】A syndrome of mineralocorticoid excess (characterized by hypertension, sodium and water retention, and hypokalemia) resulting from the ingestion of licorice has been well described.  <sup>, </sup>  Stewart et al.  proposed that licorice acts by inhibiting renal 11β-hydroxysteroid dehydrogenase activity, thereby diminishing the conversion of cortisol to cortisone and resulting in high renal levels of cortisol, which is available for binding to mineralocorticoid receptors. During licorice ingestion, plasma cortisol levels and the pituitary-adrenal axis are normal, although the plasma half-life of cortisol is prolonged.  Our findings of elevated urinary excretion of cortisol, increased amounts of unconjugated cortisol metabolites relative to total cortisol metabolites in urine, and decreased urinary ratios of cortisone to cortisol metabolites (the ratios of tetrahydrocortisone to 5β-tetrahydrocortisol plus 5α-tetrahydrocortisol and of 5α- plus 5β-cortolones to cortols) confirm that licorice impairs normal cortisol metabolism.\n\n【38】The effects of licorice on 11β-hydroxysteroid dehydrogenase activity are similar to those in children with the syndrome of apparent mineralocorticoid excess. The elevated urinary ratio of 5β-tetrahydrocortisol to 5α-tetrahydrocortisol that occurs with licorice ingestion is, however, unlike the findings in such children, in whom 5α-reductase activity is increased relative to 5β-reductase activity.  In children with the syndrome of apparent mineralocorticoid excess, reduced metabolism of the A ring (3-oxo-4-ene) also occurs, resulting in a high relative level of excretion of unconjugated cortisol metabolites.  <sup>, </sup>  In our patient, the relative level of unconjugated steroid excretion was elevated during the ingestion of licorice and decreased somewhat during the recovery period. Although the effects of licorice on A-ring metabolism are different from those of the apparent mineralocorticoid excess syndrome of children, the effects on cortisol production should not be different.\n\n【39】Epstein et al.  investigated the effects of short-term (one to four weeks) licorice ingestion in normal subjects and found that the urinary excretion of cortisol remained elevated one week after licorice was withdrawn, although the ratio of cortisone to cortisol metabolites had become normal. In our patient, who had consumed licorice regularly for several years, we found that the suppression of 11β-hydroxysteroid dehydrogenase activity, as well as many of the changes in electrolyte balance, persisted for almost two weeks after licorice intake was discontinued. His excretion of glycyrrhetinic acid gradually diminished during the same two-week period. Thus, the prolonged suppression of 11β-hydroxysteroid dehydrogenase activity appeared to be due to the continued action of glycyrrhetinic acid; as urinary glycyrrhetinic acid levels fell, the suppression of 11β-hydroxysteroid dehydrogenase activity reversed.\n\n【40】Limited data exist concerning the recovery of the renin-aldosterone axis after the suppression that occurs during chronic ingestion of licorice. Epstein et al.  found that the function of the renin-aldosterone system became normal within two to four months in four subjects who had ingested 25 to 200 g per day of licorice for six months to five years. In our patient, four to five years of licorice ingestion had profound effects: the unstimulated renin-aldosterone system was suppressed for nearly four months after the cessation of licorice ingestion. These prolonged suppressive effects are much like those that occur after the removal of an aldosterone-producing adenoma, which creates a similar state of chronic mineralocorticoid excess.  Before the study period the patient's potassium and spironolactone treatment was appropriate for the licorice-induced hypermineralocorticoid state that probably maintained the renin-aldosterone system at a low set point. When spironolactone and potassium treatment was continued without licorice, however, the effects of spironolactone on the renin-aldosterone system were unopposed and resulted in relative stimulation, indicating that the system was capable of responding to a powerful stimulus. Whether direct stimulation with angiotensin II would have produced such a response is uncertain. In our patient, however, ambulatory plasma renin activity after discharge remained below normal overnight values in recumbent subjects for four months, implying prolonged suppression. This conclusion is supported by the low level of urinary aldosterone excretion during this time.\n\n【41】Our findings demonstrate that the rates of recovery differ in two enzyme systems that are suppressed by the long-term ingestion of licorice. The activity of 11β-hydroxysteroid dehydrogenase was suppressed for two weeks after licorice was withdrawn, but it then increased as urinary glycyrrhetinic acid levels decreased. In contrast, the basal activity of the renin-aldosterone system remained low for several months after licorice withdrawal. This prolonged suppression of the renin-aldosterone axis demonstrates the potency of licorice toxicity and emphasizes the need to consider licorice, and possibly other factors or drugs that affect 11β-hydroxysteroid dehydrogenase activity, as a cause of low-renin hypertension.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-14 00:20:42", "grab_time": "2024-08-13 23:33:41"}
{"id": 2234488, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "4fe80eeb-eab2-4641-8045-4c2e47e2742b", "title": "Oseltamivir Ring Prophylaxis for Containment of 2009 H1N1 Influenza Outbreaks", "text": "【0】Oseltamivir Ring Prophylaxis for Containment of 2009 H1N1 Influenza Outbreaks\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】From June 22 through June 25, 2009, four outbreaks of infection with the pandemic influenza A (H1N1) virus occurred in Singapore military camps. We report the efficacy of ring chemoprophylaxis (geographically targeted containment by means of prophylaxis) with oseltamivir to control outbreaks of 2009 H1N1 influenza in semiclosed environments.\n\n【3】Methods\n-------\n\n【4】All personnel with suspected infection were tested and clinically isolated if infection was confirmed. In addition, we administered postexposure ring chemoprophylaxis with oseltamivir and segregated the affected military units to contain the spread of the virus. All personnel were screened three times weekly both for virologic infection, by means of nasopharyngeal swabs and reverse-transcriptase–polymerase-chain-reaction assay with sequencing, and for clinical symptoms, by means of questionnaires.\n\n【5】Results\n-------\n\n【6】A total of 1175 personnel were at risk across the four sites, with 1100 receiving oseltamivir prophylaxis. A total of 75 personnel (6.4%) were infected before the intervention, and 7 (0.6%) after the intervention. There was a significant reduction in the overall reproductive number (the number of new cases attributable to the index case), from 1.91 (95% credible interval, 1.50 to 2.36) before the intervention to 0.11 (95% credible interval, 0.05 to 0.20) after the intervention. Three of the four outbreaks showed a significant reduction in the rate of infection after the intervention. Molecular analysis revealed that all four outbreaks were derived from the New York lineage of the 2009 H1N1 virus and that cases within each outbreak were due to transmission rather than unrelated episodes of infection. Of the 816 personnel treated with oseltamivir who were surveyed, 63 (7.7%) reported mild, nonrespiratory side effects of the drug, with no severe adverse events.\n\n【7】Conclusions\n-----------\n\n【8】Oseltamivir ring chemoprophylaxis, together with prompt identification and isolation of infected personnel, was effective in reducing the impact of outbreaks of 2009 H1N1 influenza in semiclosed settings.\n\n【9】Introduction\n------------\n\n【10】The 2009 pandemic influenza A (H1N1) virus has spread rapidly worldwide, despite initial attempts at containment through screening, isolation, and quarantine.  Many countries moved rapidly into the mitigation phase after the outbreak was detected, which affected essential services, especially in the health and education sectors. Mexico, the first country affected, shut down all major public services for a week to halt transmission of the virus. Other large outbreaks in population centers had a similar effect on essential services. Even though pandemic vaccines are available, the lack of availability during a pandemic results in incomplete global protection.\n\n【11】Mathematical models of the efficacy of containment measures in an influenza epicenter have been described,  although these measures ultimately proved ineffective at preventing the spread of the 2009 pandemic H1N1 virus. However, containment measures may be effective within specific closed environments, such as schools, health care settings, or military installations, all of which have a high risk of transmission.  Chemoprophylaxis with a neuraminidase inhibitor has been effective in preventing the household transmission of influenza,  and modeling studies have predicted that well-timed chemoprophylaxis could significantly reduce the rate of absenteeism among health care workers due to illness, to maintain business continuity. \n\n【12】Although antiviral “ring chemoprophylaxis” strategies (aimed at geographically targeted containment by means of prophylaxis) were predicted to be effective in mathematical models, data are needed to document their actual effectiveness during a pandemic. We therefore describe our experience in responding to four outbreaks of the 2009 pandemic influenza A (H1N1) virus in military camps (including one in a health care setting) and evaluate the role of oseltamivir “ring chemoprophylaxis” in attenuating transmission of the virus.\n\n【13】Methods\n-------\n\n【14】Singapore is a city–state of 4.84 million people.  All Singaporean men perform 2 years of military service after high school, at 18 to 19 years of age. Most military personnel live in barracks-style accommodations on weekdays and return home on weekends, resulting in an interaction between the military community and the Singapore population.\n\n【15】Singapore identified its first imported case of infection with the 2009 pandemic influenza A (H1N1) virus on May 27, 2009,  and the first transmission to the local community was reported on June 18, 2009.  In line with World Health Organization (WHO) recommendations,  Singapore began the transition to mitigation on July 1, 2009.  The Singapore Armed Forces (SAF) identified its first imported case of infection on June 15, 2009, and its first four outbreak clusters (outbreaks I, II, III, and IV) involving local transmission from June 22 to 25, 2009.\n\n【16】National Protocols and Management\n---------------------------------\n\n【17】A suspected case of 2009 H1N1 influenza was defined as influenza-like illness (temperature ≥38.0°C with cough or sore throat) with an onset of symptoms within 7 days after travel to an affected area, close contact with a person with confirmed infection, or contact with a local cluster of infected persons.  Laboratory confirmation of suspected cases was performed by means of real-time reverse-transcriptase–polymerase-chain-reaction (RT-PCR) assay or viral culture. \n\n【18】Until July 1, 2009, all persons with suspected infection with the 2009 H1N1 virus were screened with the use of RT-PCR assay, according to national protocols,  and patients with confirmed infection were isolated in hospitals to prevent transmission. Contact tracing was performed to identify close contacts, defined as persons who had had unprotected exposure, within 2 m, to an infected patient for 1 hour or more since the day before the onset of symptoms.  Most contacts were quarantined at home for a 7-day period.\n\n【19】SAF Protocol and Management\n---------------------------\n\n【20】Performing its function as a critical national resource, the SAF implemented additional interventions to contain the spread of the 2009 H1N1 virus. Primarily, “ring prophylaxis” with oseltamivir (Tamiflu, Roche), at a dose of 75 mg daily, was administered to coworkers of the patient with confirmed infection for a period of 10 days after exposure.  The oseltamivir had been purchased and stockpiled several years previously as part of the SAF influenza-pandemic preparedness plan. A coworker was defined as a member of the same military unit, where contact opportunities were substantial even if they did not fulfill the Singapore Ministry of Health criteria for close contact. This wider definition was prompted by difficulties in identifying actual contacts and the practicalities of rapidly administering prophylaxis. Larger prophylaxis rings were instituted if cases were present in multiple units. In addition, interactions between affected units and other units were reduced within the camp, by allocating to each unit different times of arrival, departure, and meal delivery.\n\n【21】Epidemiologic Investigation\n---------------------------\n\n【22】Our investigation of the outbreaks was approved by the SAF Joint Medical Committee, as well as the National University of Singapore and the Australian National University institutional review boards. Written informed consent was obtained from all persons for whom follow-up nasopharyngeal swabs were obtained, and oral assent was provided by all others during the surveys.\n\n【23】The four outbreaks occurred in different locations: one in each of three military units and one at a camp medical center. All personnel with suspected infection were tested and isolated in the hospital if the test was positive. In addition, all asymptomatic personnel in the same unit were screened through the collection of nasopharyngeal swabs, three times a week, to detect subclinical infections.  A written questionnaire was administered at each screening visit, as well as after the completion of prophylaxis, to collect data on demographic characteristics, medical history, activity patterns, and clinical symptoms. Screening was performed until no additional cases were identified for 3 days after the last previously identified case or after the end of the 10-day prophylaxis period, whichever was later. After the prophylaxis period, a telephone questionnaire was administered to personnel who had left camp before the screening was completed.\n\n【24】Molecular Diagnosis and Sequencing\n----------------------------------\n\n【25】Nasopharyngeal swabs were collected, resuspended in 2.0 ml of viral-transport medium, and sent for RT-PCR testing, all within a 24-hour period. The RT-PCR assay involved protocols with the swine H1 forward–reverse primer set and probe.  Positive samples with sufficient RNA underwent whole-genome sequencing according to a previously reported approach.  The resulting sequences were used to generate phylogenetic trees with the use of Molecular Evolutionary Genetics Analysis 4 software.  All sequenced samples were screened for known and suspected mutations that would confer oseltamivir resistance, including the H274Y mutation. Additional methods are described in the Supplementary Appendix .\n\n【26】Statistical Analysis\n--------------------\n\n【27】Following the statistical argument of Cauchemez and colleagues,  we assumed that each case of 2009 H1N1 influenza leads to new cases, distributed as a Poisson variate with a mean of λ or λθ in the absence or presence of intervention, respectively, as well as a specific form for the generation interval. The λ variable represents the reproductive number (the mean number of new cases attributable to the index case) in the absence of intervention, and λθ the reproductive number after intervention. Analysis was performed according to the Bayesian paradigm,  and with the use of the statistical programming language R.  The Supplementary Appendix describes that analysis as well as the methods used to quantify the strength of the intervention effect, obtain credible intervals, and evaluate the hypothesis of a reduction in infection rates after intervention (i.e., θ<1). For measures of statistical significance, we report the posterior hypothesis probabilities as described in the Supplementary Appendix .\n\n【28】Results\n-------\n\n【29】Table 1. Summary of the Four Outbreaks of 2009 H1N1 Influenza and Efficacy of Oseltamivir Prophylaxis and Other Interventions.\n\n【30】A total of 82 confirmed cases of infection with the 2009 pandemic influenza A (H1N1) virus were identified during the four outbreaks .\n\n【31】Outbreak 1\n----------\n\n【32】Figure 1. Timing of Events and Cases during Outbreak 1, According to Date of Onset of Influenza.\n\n【33】Generations 1 and 2 are the first and second generations, respectively, of 2009 H1N1 influenza spread from the three presumed index cases.\n\n【34】From June 21 to 22, 2009, four personnel (B, C, E, and F in Figure 1 ) tested positive for 2009 H1N1 influenza. Three (B, E, and F) had performed overnight guard duty together on June 18, 2009. Four more (A, G, H, and I) were confirmed to be infected during initial investigations. The remaining 208 coworkers were given oseltamivir prophylaxis; of these, 81 were identified as close contacts and were quarantined at home. During the outbreak, three more personnel tested positive, of whom two (D and J) had not been initially identified as close contacts. Of the remaining 205 personnel, 185 (90.2%) completed the course of prophylaxis. Fourteen personnel reported minor respiratory symptoms; 11 tested negative for 2009 H1N1 influenza and 3 were not tested. The other personnel continued working in the camp, and none tested positive, as assessed by testing three consecutive nasopharyngeal swabs obtained over a 1-week period. Overall, 11 of the 216 personnel (5.1%) were infected .\n\n【35】Outbreak 2\n----------\n\n【36】In a military medical center, 6 of 47 health care workers tested positive from June 24 to 25, 2009. Because health care workers were essential for the medical center to function, oseltamivir prophylaxis was administered to the remaining 41 personnel, who continued to work while wearing personal protective equipment (N95 mask, gloves, gown, and cap). All 41 health care workers completed the prophylaxis, and none had evidence of infection on testing of three consecutive nasopharyngeal swabs obtained over a 1-week period.\n\n【37】Outbreak 3\n----------\n\n【38】On June 23, 2009, the index patient presented with influenza-like illness and tested positive. On June 20, 2009, he had visited a nightclub in Singapore (where there was a separate outbreak).  One other asymptomatic case in the unit was confirmed during initial investigations. The remaining 217 personnel in the unit were immediately started on prophylaxis, and active surveillance was performed, consisting of testing of two nasopharyngeal swabs obtained over a 3-day period. None tested positive. After prophylaxis, telephone surveillance was performed, with 193 of the 217 personnel (88.9%) successfully contacted; 186 of 193 (96.4%) had completed the prophylaxis. Only one soldier reported fever; he tested negative.\n\n【39】Outbreak 4\n----------\n\n【40】Figure 2. Epidemiologic Data and Model Projections for Outbreak 4, According to Date of Onset of Influenza.\n\n【41】The numbers of cases of 2009 H1N1 influenza during outbreak 4 are shown. Also shown (as circles) are predicted numbers of cases on the basis of assumptions that the apparent effect of the interventions was due to either chance alone (“no control”) or to the release of the personnel to home (“home leave only”), rather than to the oseltamivir prophylaxis. I bars indicate 95% credible intervals of the predicted values.\n\n【42】A unit of 693 army-reserve personnel entered the camp from the community on June 22, 2009, for 5 days of training. From June 25 to 26, a total of 59 personnel presented with fever and respiratory symptoms and tested positive. The index patient could not be conclusively identified. Prophylaxis was begun in the remaining 634 personnel, who were given home leave after completion of training on June 26. They were followed by means of telephone surveillance. Throughout the outbreak period, a total of 63 personnel (9.1%) had confirmed infection . After prophylaxis was completed, the remaining 630 unaffected personnel were surveyed by means of telephone; 535 (84.9%) responded, of whom 517 (96.6%) reported having completed the prophylaxis. A total of 41 respondents reported having respiratory symptoms, and 10 reported having fever with respiratory symptoms. Of these personnel, six and five, respectively, were tested; all tests were negative.\n\n【43】Molecular Sequencing\n--------------------\n\n【44】Figure 3. Phylogenetic Relationships among the Viruses Identified during the Four Outbreaks with the Use of Whole-Genome Sequencing.\n\n【45】Numbers in parentheses indicate the identifier of the substrain; the letters refer to the patient identifiers used in Figure 1. Strains from each outbreak are denoted in a unique color. Numbers at each node in the tree indicate the bootstrap value (reflecting the robustness of the evidence supporting the clade of which that node is the root). The scale bar denotes the number of DNA base substitutions (a measure of evolutionary divergence).\n\n【46】The use of whole-genome sequencing allowed for a molecular epidemiologic analysis, as previously described.  Whole-genome sequences were used to identify the relatedness of the isolated viruses and to suggest clusters of transmission to further describe the conditions of the outbreak .\n\n【47】Each of the four outbreaks formed a distinct cluster, with the closest international strains derived from the New York lineage A/New York/18/2009(H1N1). Outbreak 4 comprised two viral clusters, one New York–like and the other similar to the Singapore local-nightclub cluster  ; strains isolated during the other outbreaks matched Singapore strains closely. The whole-genome sequences of viruses from outbreak 2 were tightly clustered, suggesting a single causal virus, whereas the local components of outbreaks 1, 3, and 4 were from introductions of highly related Singapore strains, not repeated introductions of distinct viruses. The molecular evidence strongly supports the results of our epidemiologic investigation, which bear out the premise that the outbreaks consisted of transmitted cases of infection rather than unrelated cases.\n\n【48】All seven confirmed cases with an onset after oseltamivir prophylaxis occurred within 4 days after the intervention. The affected patients had complied with the prophylaxis; at the time of infection, they were switched to a treatment dose. In six of the seven cases, there was sufficient genetic material for sequencing. None of the sequenced samples (37 in total, including these 6) had any known or suspected mutations that might have conferred resistance to oseltamivir (including the H274Y mutation).\n\n【49】Rates of Infection and Efficacy of Interventions\n------------------------------------------------\n\n【50】The overall proportion of personnel with infection before the oseltamivir prophylaxis and the other interventions were instituted was 6.4% across all four military units . After prophylaxis was begun, in combination with home leave coordination of schedules to avoid contact among the units at the camp, seven more cases were confirmed (0.6% of the study population). After intervention, the infection rate was reduced to 5.9% of the original rate (95% credible interval, 2.5 to 10.9), (posterior hypothesis probability, <0.001).\n\n【51】Guided by the phylogenetic analyses, we used mathematical modeling to investigate the effect of the interventions on the course of the outbreaks. If we considered only confirmed cases, the global estimate of the reproductive number before intervention was 1.91 (95% credible interval, 1.50 to 2.36). There was a significant reduction in the reproductive number after intervention, to 0.11 (95% credible interval, 0.05 to 0.20) (posterior hypothesis probability, <0.001). If untested, symptomatic cases were included, the reproductive number before the interventions was 1.85 (95% credible interval, 1.48 to 2.24), with a significant reduction after intervention, to 0.28 (95% credible interval, 0.20 to 0.38) (posterior hypothesis probability, <0.001).\n\n【52】The rate of infection was clearly reduced as a result of interventions in outbreaks 2, 3, and 4 . In outbreak 4, ring prophylaxis coincided with the sending home of personnel; thus, to test the effectiveness of prophylaxis, we projected the distribution of one further generation of cases, using the posterior mean of the reproductive number during the preintervention period . The two distributions we estimated represent what we would expect if the apparent efficacy of the interventions was due to chance alone or due to the isolation measures, not the oseltamivir prophylaxis. The large discrepancy between these distributions and the observed trajectory of the epidemic strongly suggests that the sharp drop in rate of infection was due to prophylaxis, which reduced the transmission of the virus, as well as isolation (rather than isolation alone).\n\n【53】Side Effects of Oseltamivir\n---------------------------\n\n【54】Table 2. Side Effects of Oseltamivir Prophylaxis.\n\n【55】We surveyed a total of 816 personnel for side effects of oseltamivir prophylaxis. In all, 63 (7.7%) reported mild, nonrespiratory symptoms . No neuropsychiatric events or severe adverse events were reported.\n\n【56】Discussion\n----------\n\n【57】Many essential services are provided by persons who work in semiclosed or closed environments where influenza outbreaks can be rapid and severe.  In an influenza outbreak among Taiwanese military recruits, the rate of infection was 57.7%  ; an influenza A (H3N2) outbreak on a U.S. Navy ship had an infection rate of 42%.  High rates of infection are also reported at schools, which are similarly enclosed. One boarding school had 56 cases (in 6.5% of the population) a week after the index case occurred,  and another had an overall rate of infection of 71%.  During a New York City school outbreak of the 2009 pandemic influenza A (H1N1) virus, 35% of students reported symptoms of influenza-like illness.  In our study, during outbreak 4, 59 cases occurred within 4 days after the first contact with the index patient.\n\n【58】Two modeling studies of the containment of pandemic epicenters, although not specifically based on closed communities, have predicted the effectiveness of ring prophylaxis.  The effectiveness of antiviral prophylaxis has not been well documented in outbreak situations outside the household setting.  The use of postexposure prophylaxis with oseltamivir in close household contacts of patients with seasonal influenza resulted in protective efficacies of 68%  and 89%  against clinically diagnosed influenza. Early prophylaxis with amantadine also reduced the incidence of influenza, and its associated mortality rate, in outbreaks at long-term care facilities. \n\n【59】For the 2009 influenza pandemic, H1N1 observations suggest that antiviral prophylaxis administered in contacts within households, schools, and workplaces is effective in slowing transmission.  In the present study, we have shown that ring prophylaxis with oseltamivir given after exposure in military camps, including a health care setting, was effective, allowing training and operations to continue while substantially reducing the risk of further generations of cases during prophylaxis. The settings studied have the potential for intense transmission and are similar to environments such as hospital wards, boarding schools and other schools, and long-term care facilities. The initial response to outbreak 1 also reflects the limitations of quarantining only people considered to be close contacts of an affected patient, since some cases were identified in patients who were contacts, but not close contacts as defined by the Singapore Ministry of Health. Ring prophylaxis, based on spatial proximity, was more effective in controlling the spread of disease than was an exclusive focus on close contacts.\n\n【60】The pandemic (H1N1) 2009 vaccine is now available  ; however, antiviral prophylaxis may be considered as an additional strategy in reducing the pandemic's effects, especially in areas in which the supply of vaccine is limited. Furthermore, this strategy may be important in future epidemics and pandemics, either before vaccines are available or when there is a poor match between the vaccine and circulating strains.\n\n【61】The threshold for initiating neuraminidase-inhibitor prophylaxis has not been well defined. For outbreaks 1, 2, and 3 in our study, prophylaxis was initiated early and was followed by rapid cessation of the outbreak. This was possible because of rapid detection through health education, surveillance through daily measurement of temperature and monitoring of symptoms, and laboratory testing. Although outbreak 4 was not detected early, postexposure prophylaxis was effective in breaking the chain of transmission and probably helped prevent a higher rate of infection.\n\n【62】Study limitations include the facts that the data were observational and that multiple interventions were applied simultaneously. The relative strength of the nonpharmaceutical interventions as compared with prophylaxis could only be inferred through modeling. However, it would have been difficult to use prophylaxis as the sole control measure, owing to external pressure to do everything possible to halt transmission and the spontaneous social-distancing measures people take. Although the best efforts were made to ensure consistency of the data collection and use of interventions across the four outbreaks, local circumstances influenced the study activities and should be considered part of any investigation of outbreaks. In addition, monitoring data were incomplete for some outbreaks, because personnel completed their training and were given home leave; we subsequently performed telephone surveillance instead to obtain as much information as possible.\n\n【63】The use of oseltamivir prophylaxis as a containment measure may be limited to semiclosed or closed communities, since transmission in communities in the general population may subsequently lead to further outbreaks. In the boarding school where the use of amantadine prophylaxis significantly reduced the number of influenza cases, the number of cases increased after the prophylaxis was stopped.  However, the overall rate of infection was significantly lower than expected, and cases were spread out over time, reducing the peak rate of absenteeism.\n\n【64】Our experience provides evidence that early case detection and the use of antiviral ring prophylaxis effectively truncate the spread of infection during an epidemic, giving empirical support to theoretical mathematical models. Aggressive prophylaxis may be justifiable to provide protection from an influenza strain that causes severe disease or to protect vulnerable populations such as frail or elderly residents of long-term care facilities or persons in closed or semiclosed environments such as schools, prisons, and military camps. Finally, containing the pandemic's spread may postpone the onset of substantial illness and distribute temporally the burden on the health care system until other control measures, such as vaccine, become available.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 18:06:29", "endTime": "2024/08/13 18:13:27", "cost": 417.727}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 02:13:28", "grab_time": "2024-08-13 02:06:29"}
{"id": 2234487, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "c42476f3-74f5-4008-9e03-50ceeff974ec", "title": "Collection of Data on Patients' Race and Ethnic Group by Physician Practices", "text": "【0】Collection of Data on Patients' Race and Ethnic Group by Physician Practices\nThe authors argue that physician practices should routinely collect data on the race and ethnic group of their patients. They caution against the use of these data to infer information about health-related values or beliefs, and they discuss the benefit of using these data at the population level to detect disparities in care and to improve the quality of care.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 17:43:59", "endTime": "2024/08/13 17:44:18", "cost": 19.869}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 01:44:19", "grab_time": "2024-08-13 01:43:59"}
{"id": 2234486, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "afd5b066-c68c-4ac0-a802-96376bb11665", "title": "Controlled Clinical Trial of Prophylactic Human-Leukocyte Interferon in Renal Transplantation — Effects on Cytomegalovirus and Herpes Simplex Virus Infections", "text": "【0】Controlled Clinical Trial of Prophylactic Human-Leukocyte Interferon in Renal Transplantation — Effects on Cytomegalovirus and Herpes Simplex Virus Infections\nAbstract\n--------\n\n【1】A double-blind, placebo-controlled trial of interferon prophylaxis against viral infections was conducted in renal-transplant recipients receiving standard immunosuppressive therapy with or without antithymocyte globulin. Interferon was administered for six weeks, beginning on the day of transplantation.\n\n【2】Cytomegalovirus excretion began earlier and viremia was more frequent in placebo-treated than in interferon-treated patients. Cytomegalovirus viremia correlated with clinical syndromes and was more frequent in recipients of antithymocyte globulin. In contrast, neither interferon nor antithymocyte globulin altered excretion of herpes simplex virus.\n\n【3】Reversible leukopenia and thrombocytopenia occurred in seven interferon recipients. Patient and graft survival were comparable in interferon and placebo groups. These preliminary results suggest that a six-week course of prophylactic interferon delays shedding of cytomegalovirus and decreases the incidence of viremia after transplantation. In contrast, antithymocyte globulin appears to increase the severity of infection from cytomegalovirus among these patients.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:40:17", "endTime": "2024/08/14 15:44:31", "cost": 254.405}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 23:44:31", "grab_time": "2024-08-13 23:40:16"}
{"id": 2234485, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "08e7b35f-bb77-42e0-bf2a-97200585bd3a", "title": "Variability of Body Weight and Health Outcomes in the Framingham Population", "text": "【0】Variability of Body Weight and Health Outcomes in the Framingham Population\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】Fluctuation in body weight is a common phenomenon, due in part to the high prevalence of dieting. In this study we examined the associations between variability in body weight and health end points in subjects participating in the Framingham Heart Study, which involves follow-up examinations every two years after entry.\n\n【3】Methods.\n--------\n\n【4】The degree of variability of body weight was expressed as the coefficient of variation of each subject's measured body-mass-index values at the first eight biennial examinations during the study and on their recalled weight at 25 years of age. Using the 32-year follow-up data, we analyzed total mortality, mortality from coronary heart disease, and morbidity due to coronary heart disease and cancer in relation to intraindividual variation in body weight, including only end points that occurred after the 10th biennial examination. We used age-adjusted proportional-hazards regression for the data analysis.\n\n【5】Results.\n--------\n\n【6】Subjects with highly variable body weights had increased total mortality (P = 0.005 for men, P = 0.01 for women), mortality from coronary heart disease (P = 0.009 for men, P = 0.009 for women), and morbidity due to coronary heart disease (P = 0.0009 for men, P = 0.006 for women). Using a multivariate analysis that also controlled for obesity, trends in weight over time, and five indicators of cardiovascular risk, we found that the positive associations between fluctuations in body weight and end points related to mortality and coronary heart disease could not be attributed to these potential confounding factors. The relative risks of these end points in subjects whose weight varied substantially, as compared with those whose weight was relatively stable, ranged from 1.27 to 1.93.\n\n【7】Conclusions.\n------------\n\n【8】Fluctuations in body weight may have negative health consequences, independent of obesity and the trend of body weight over time. \n\n【9】Introduction\n------------\n\n【10】BODY weight can fluctuate for a variety of reasons, one of which is dieting with the goal of weight reduction and the subsequent regaining of the weight that was lost. Because repeated episodes of weight loss and gain are so common, it is important to examine the implications for health of this pattern, which we refer to as weight cycling. The results of a study of employees of the Western Electric Company indicated that a single cycle of weight gain and loss in men was a risk factor for death from coronary heart disease, but not for death from all causes.  The Gothenburg Prospective Studies found that variability in body weight measured at three time points was a risk factor for subsequent coronary heart disease in men and for total mortality in both men and women.  In contrast, no significant associations between fluctuations in body weight and mortality were detected in two other cohorts.  <sup>, </sup>  Three of these studies  <sup><a>2 </a></sup>  were limited by the fact that only a single cycle of weight fluctuation was represented in the indicators of variability of body weight used by the investigators.\n\n【11】These studies demonstrate the importance of investigating further the associations between fluctuations in body weight and health, and they underscore the challenges of doing such research. In overweight persons, voluntary weight reduction is assumed to be beneficial to health, whereas involuntary weight loss often reflects serious disease. Conversely, weight gain may lead to obesity and its concomitant adverse effects, yet some increments in body weight occur normally in healthy persons as they age. Fluctuations in weight that precede disease must be distinguished from those caused by disease. We addressed these issues by studying the associations between the degree of variability in body weight and subsequent health outcomes in subjects participating in the Framingham Heart Study.\n\n【12】Methods\n-------\n\n【13】Data Collection\n---------------\n\n【14】The Framingham Heart Study offers a valuable opportunity for the analysis of fluctuations in body weight in relation to the subsequent incidence of chronic disease. This prospective study contains more data on measured body weight and uses longer follow-up periods than much of the previous work on weight fluctuations and health. Since 1948, the health status of 5127 male and female residents of Framingham, Massachusetts, who were initially free of coronary heart disease has been monitored. At entry the subjects were between 30 and 62 years of age. Body weight was measured at entry and every two years thereafter at regular follow-up examinations; body weight at 25 years of age as recalled by the subjects was also recorded. The details of sampling, response rates, methods, and follow-up have been described in detail,  and the results of the 24-year follow-up have been reported in a comprehensive review.  This new analysis is based on data from 32 years of follow-up. Other investigators have previously used these data to address questions on the relation of obesity, weight loss, and weight gain to various health end points.  <sup>, </sup> \n\n【15】Chronology\n----------\n\n【16】Figure 1. Chronology and Schematic Representation of Body-Weight Variables for a Hypothetical Subject.\n\n【17】The chronology illustrates the timing of measurements of body weight (made at intervals of two years as part of the Framingham Study) in relation to the occurrence of end points, with a four-year interval (\"window\") required between the measurement of weight at the eighth examination and the first end point included in the analysis. Weight was converted to body-mass index (BMI), defined as the weight in kilograms divided by the square of the height in meters, which was used to calculate three key independent variables: a subject's mean BMI (level), the linear trend in the BMI over time (slope), and the BMI's degree of variability from the mean (coefficient of variation). Determinations of the BMI are indicated by shaded circles and arrows.\n\n【18】In order to study the relations between fluctuations in weight and chronic disease, it is important to understand the temporal sequence of weight change and onset of disease. The design for this analysis entailed a chronologic separation of weight change and health end points , by specifying the lengths of time required between determinations of body weight and end points included in the analyses. All measurements of body weight during the first 14 years of the Framingham Heart Study (eight follow-up examinations), along with each subject's recalled body weight at the age of 25, were used to construct independent variables representing body weight and its fluctuation. The subjects included in this analysis were examined at all of the first eight scheduled follow-up visits; those who missed any of these examinations were excluded. The dependent variables in our analyses were various end points occurring during a follow-up period that began at visit 10 — that is, at least four years after the last body-weight measurement was analyzed. The purpose of excluding earlier end points was to eliminate variability in body weight that might be attributed to antecedent disease. We also analyzed body weight in relation to the same end points after increasing the length of time required from the eighth follow-up examination to the first end points included in the analysis from four to six years.\n\n【19】Weight Cycling and Major Covariates\n-----------------------------------\n\n【20】Weight cycling was defined on the basis of variability in each subject's body-mass index (the weight in kilograms divided by the square of the height in meters) during the period from the age of 25 (recalled weight) through the eighth biennial follow-up examination. A coefficient of variation for each subject's body-mass-index values was calculated at nine time points from the age of 25 through the eighth examination . This value, which will be referred to as variability in weight, was calculated as the standard deviation of each subject's nine body-mass-index values divided by the average body-mass index for that subject. This variable reflects the extent to which a subject's body-mass index fluctuated around his or her own mean value. A high degree of variability in weight indicates many changes in weight or large changes, whereas a low value indicates stability of the body-weight values.\n\n【21】The two key covariates in this analysis were also within-subject variables. The first was a subject's mean body-mass index over the same nine time points. We call this a body-mass-index \"level\" to emphasize the fact that a value for this variable exists for each subject. The second covariate indicates the direction and magnitude of the change in a subject's body-mass index over the same period and is calculated as the change in the body-mass index per year (\"slope\"). A positive value indicates weight gain over time, whereas a negative value indicates weight loss.\n\n【22】Table 1. Characteristics of the Subjects during the Observation Period.\\*\n\n【23】Descriptive statistics for the key independent variables are shown in Table 1 . For men and women, respectively, the average age at entry was 42.8 and 43.5 years. The average body-mass index (the mean of the individual means) was 25.9 for the men and 24.9 for the women, values that are based on mean body weights of 77.0 and 63.2 kg, respectively (data not shown). The mean values for the slope of the body-mass index indicate that both the men and the women gained weight at an average rate of 0.11 kg per square meter per year. Finally, the mean coefficients of variation suggest that women's weights tend to vary more than men's. A value of 0.06 indicates an average 6 percent deviation about a subject's mean body-mass index.\n\n【24】We had several reasons for including the level and slope of the body-mass index as covariates in this analysis. Because we included the slope of the body-mass index over time as an independent variable, it was possible to distinguish the effects of systematic change in body weight from the effects of random or periodic fluctuation. This distinction was necessary because the coefficient of variation of the body-mass index and the slope of the body-mass index are correlated . Similarly, correcting for the level of the body-mass index enabled us to separate any effects of obesity from the effects of weight cycling. This was important because obese subjects are likely to have more fluctuation in weight induced by dieting than subjects who are not obese.\n\n【25】End Points\n----------\n\n【26】The four end points evaluated in relation to the degree of variability in body weight were total mortality, morbidity due to coronary heart disease, mortality from coronary heart disease, and morbidity due to cancer. Total mortality was determined and validated by a review of death certificates and other pertinent data from hospital records. Morbidity due to coronary heart disease was defined as angina pectoris, coronary insufficiency, myocardial infarction, sudden death, or death as a result of any other coronary heart disease identified on the basis of a review of the records by a panel of three physicians.  Clinical, electrocardiographic, and enzymatic data were used to establish the diagnosis of myocardial infarction. Mortality from coronary heart disease was a subgroup of total morbidity due to coronary heart disease, as described above. Both categories included sudden death from coronary heart disease, which was defined as death in a subject who had apparently been well who died within 60 minutes of the onset of symptoms in the absence of any other cause. Morbidity due to cancer included all malignant neoplasms. The cases were documented by reviewing the records of all subjects suspected or known to have had cancer. The dates of diagnosis were ascertained and all pertinent data reviewed. Pathological or cytologic reports were available for all but a few potential cases. A supplemented format from the _International Classification of Diseases for Oncology_ was used to encode topographic and morphologic features.  <sup>, </sup>  Because of the relatively small number of cancers at specific sites, this group included all cases of cancer. The exclusion of subjects with skin cancer from this group did not alter the results.\n\n【27】To preserve the four-year intervals between the measurements of weight and health-outcome end points, any subject with a specific end point before the 10th examination was eliminated from the analysis of data on that particular outcome. As a result of these exclusions, the sample in this analysis was smaller than that of the original Framingham cohort.\n\n【28】Statistical Analysis\n--------------------\n\n【29】Proportional-hazards regression was used to analyze the data.  Separate analyses were conducted for men and women, and all analyses were stratified to correct for age group at entry (30 through 44, 45 through 54, and 55 through 62 years). In the first analysis (Model A), each of the four outcome variables was modeled as a function of the variability of weight, with adjustment for age group. Next, the level of the body-mass index and the slope of the body-mass index over the same period were included with variability of weight in an age-adjusted multivariate model predicting each of the four outcomes (Model B). Finally, in Model C, a set of standard cardiovascular risk factors measured early in the study was added to the variables in the previous model. These were the number of cigarettes smoked daily, physical-activity level, serum cholesterol concentration, results of glucose-tolerance tests, and systolic blood pressure. Physical activity was assessed at the fourth examination; the other risk factors were measured in all subjects at the time of the first or second examination (or both), and the earliest available value for each subject was used.\n\n【30】The results for the three regression models are presented separately. Estimates of relative risk and the results of analyses in which we used an increasing interval between measurements of weight variability and end points, excluded recalled weight at 25 years of age, and stratified the data according to age are described separately. Two-tailed tests were used, and probability levels of less than 0.05 were considered to indicate statistical significance.\n\n【31】Results\n-------\n\n【32】Model A\n-------\n\n【33】Table 2. Regression Coefficients and Significance Levels for Variability of Weight in Relation to Outcome, According to Models A and B.\\*\n\n【34】In the first regression analysis (Model A), each of the four end points was modeled as a function of body-weight variability. As shown in Table 2 , all end points except cancer were significantly related to the variability of body weight. All the significant regression coefficients were positive, indicating that a high degree of variability in body weight was associated with an increased risk of death from all causes, coronary heart disease, and death from coronary heart disease in both men and women.\n\n【35】Model B\n-------\n\n【36】In the next analysis (Model B), we added two covariates to the model that already included variability of weight in order to determine whether any of the significant effects of variability of weight could be accounted for by the average level or slope of a subject's body-mass index over time. The results of this analysis were largely consistent with those of the Model A analysis; in both men and women, variability of weight was significantly and positively associated with total mortality and mortality from coronary heart disease, but not with cancer . Variation in weight remained a strong independent risk factor for total coronary heart disease in men. For the mortality and coronary heart disease end points, the regression coefficients of the level of the body-mass index were positive, and those of the slope of the body-mass index were negative (data not shown).\n\n【37】Model C\n-------\n\n【38】Table 3. Partial Regression Coefficients (β) and Significance Levels of Selected Independent Variables, According to Multivariate Analysis in Model C.\\*\n\n【39】In Model C we added a set of standard cardiovascular risk factors to the independent variables included in Model B, in order to determine whether the results were confounded by cigarette smoking, physical-activity level, serum cholesterol level, systolic blood pressure, or glucose tolerance. After correction for the slope and level of the body-mass index, along with these five cardiovascular-disease risk factors, all the end points that were correlated with variability of weight in the previous analysis remained correlated with it . Among men, death from all causes, coronary heart disease, and death from coronary heart disease all remained significantly associated with variability of weight. In women, significant positive associations remained for death from all causes and death from coronary heart disease.\n\n【40】One of these risk factors, cigarette smoking, was examined in greater detail to determine whether the associations between fluctuation in weight and the health end points were dependent on smoking. We found, first, that the results from Model B were unaffected by the inclusion of cigarette smoking as the only additional covariate, indicating that cigarette smoking was not a significant confounding factor in this analysis. Second, we found no significant or suggestive statistical interactions between variability of weight and smoking in the prediction of coronary heart disease, death from coronary heart disease, or death from all causes, indicating that base-line smoking status did not modify the observed associations.\n\n【41】Estimates of Relative Risk\n--------------------------\n\n【42】Table 4. Age-Adjusted Relative Risk of Each Outcome for the Subjects with the Highest Degree of Variability of Weight, as Compared with Those with the Least Variable Weights.\\*\n\n【43】For purposes of illustration and to assist in the interpretation of the regression coefficients presented in Tables 2 and 3 , we calculated the relative risk of each end point among the subjects whose weights were most variable (upper third), as compared with those whose weights varied least (lower third). This was done by dividing the group of subjects into thirds according to weight variability, calculating the mean values for the high-variability and low-variability groups, and applying proportional-hazards regression analysis to the distance between these points. As shown in Table 4 , the relative-risk estimates for total mortality and both coronary heart disease end points were between 1.27 and 2.00 and tended to be higher for men than for women. However, the lower 95 percent confidence limit was less than 1 in the multivariate model describing coronary heart disease in women and that describing cancer in men and women; these findings are in agreement with the results of the analyses in which weight variability was treated as a continuous variable.\n\n【44】Six-Year Intervals\n------------------\n\n【45】The Model B analysis was repeated after we increased the length of time required between the eighth examination and the first occurrence in the study of death, coronary heart disease, or death from coronary heart disease. The number of end points included in this analysis was smaller than before, but the likelihood that the end points were determinants rather than consequences of the fluctuation in weight was also smaller. When the interval required for the inclusion of end points was increased from four to six years, the regression coefficients were similar; the average deviation from the original values was 11.5 percent. All previously significant outcomes remained significant after the extension of this interval except death from coronary heart disease among women (P = 0.07). Therefore, the associations became statistically weaker but did not decrease appreciably in magnitude when we used a more conservative chronology for independent and dependent variables.\n\n【46】Recalled Weight at 25 Years of Age\n----------------------------------\n\n【47】We included the recalled weight at the age of 25 in the calculation of body-weight variability for several reasons. The first was that subjects' reports of their body weight are fairly accurate.  More important, changes in body weight during young adulthood may have important implications for health in later life and may be captured, at least partially, by using the weight at 25 years of age. Nonetheless, we repeated the Model B analysis after excluding the weight at the age of 25 from the calculation of variability of weight. The association with total mortality remained statistically significant for both men (P = 0.0003) and women (P = 0.0008), as did that with death from coronary heart disease among women (P = 0.0002). Although the other coronary heart disease end points were no longer significantly related to variability of weight, the direction of the associations was the same. These results suggest that weight at 25 years of age makes an important contribution to the total variance of individual subjects' weight, which is likely to reflect true change in addition to inaccuracies in self-reporting.\n\n【48】Results According to Age Groups\n-------------------------------\n\n【49】Although the associations already described were found in analyses in which the three defined age groups were pooled, the results were also considered for each age group individually. The strongest and most consistent associations between weight variability and the health end points were found in the youngest age groups (men and women 30 through 44 years of age).\n\n【50】Discussion\n----------\n\n【51】These results indicate that persons whose body weight fluctuates often or greatly have a higher risk of coronary heart disease and death than do persons with relatively stable body weights. The associations observed were generally independent of both weight for height and temporal trends in weight, as well as of a number of cardiovascular risk factors. Therefore, it appears that body-weight variability, together with obesity, the overall trend in body weight, and other known risk factors for disease, has value in predicting the risk of mortality and coronary heart disease.\n\n【52】The relative risks attributable to fluctuation in weight were comparable in magnitude to the risks attributable to being overweight for total mortality,  cardiovascular disease,  and coronary heart disease.  Recalled body weight at the age of 25 did not affect the associations between fluctuation in weight and mortality from all causes, but it was important in some of the associations with coronary heart disease, suggesting that weight changes in early adulthood may have different health implications from subsequent weight changes. Although not central to this analysis, systematic weight change (as measured by the slope of the body-mass index) was inversely associated with many of the end points examined here. Further research is needed to examine the independent effects of systematic weight change and variability of weight.\n\n【53】The associations reported here may be interpreted in a number of different ways. One possibility is that many of the subjects who died or were given diagnoses of disease during follow-up were already ill when their body weight was measured. In this case, the fluctuations in weight could be the consequence, and not the cause, of the health end points. However, the intervals between each subject's last body-weight measurement and any end point included in our analyses were intended to exclude serious preexisting illnesses that might have affected weight. Furthermore, we controlled for unidirectional trends in body weight in order to diminish the effect of systematic weight loss (presumably associated with chronic illness) on the associations observed. Certain diseases, such as gastrointestinal disorders and alcoholism, may be associated with periodic fluctuations in weight rather than with systematic losses or gains, but this pattern is probably less characteristic of most illnesses than is weight loss alone. These observations decrease the plausibility of the explanation that the subjects' weight fluctuated because they were already seriously ill.\n\n【54】An alternative possibility is that subjects with risk factors for coronary heart disease are the most likely to be put on weight-loss regimens (and thereby to have weight loss or loss-regain patterns), but that these changes would not reverse the health risks they already face. We attempted to minimize this possibility by including the earliest available values for five risk factors for cardiovascular disease in the multivariate analysis. Furthermore, the absence of a significant interaction between variability of weight and smoking in the prediction of the health end points suggests that these associations do not vary significantly between smokers and nonsmokers.\n\n【55】Finally, these results may reflect an adverse effect of voluntary weight loss and subsequent relapse. Although adherence to weight-reduction diets was not routinely documented at the Framingham examinations, another study indicated that body-weight variability was significantly correlated with a history of dieting.  In addition, our review of selected medical records from the Framingham Heart Study indicated that dieting was common among subjects whose body weights varied. Specifically, in a review of the medical charts of the 40 subjects with the greatest variability in body weight (corrected for the level and slope of the body-mass index), we found that weight-reduction dieting was documented in 50 percent of these subjects before the eighth examination. This rate of dieting is likely to underestimate the true rate, since dieting was not recorded consistently. Therefore, dieting cannot be ruled out as an explanation of these findings, although its specific role can be elucidated only by prospective studies designed to collect this type of information.\n\n【56】If dieting emerges as a major factor in body-weight fluctuation, it may be important to evaluate further the public health implications of current weight-loss practices. Approximately 50 percent of American women and 25 percent of American men are dieting at any time,  and many diets are unsuccessful. In view of the high rates of dieting, we wish to highlight two aspects of our results. First, weight fluctuation was most strongly associated with adverse health outcomes in the youngest cohort (age, 30 through 44 years). In addition to being the age category in which the results were least distorted by competing causes of illness, this is the age group in which dieting is likely to be most common. Second, because the relative risks associated with variation in weight were similar to those attributed to obesity, the risks due to excess weight may not outweigh the risks due to weight fluctuation. Although it would be premature to make clinical recommendations on the basis of our findings, these results do suggest that overweight persons should be taught skills to maintain weight loss and that the prevention of relapse should become a more central focus of weight-loss programs.  <sup>, </sup> \n\n【57】These results underscore the difficulties of using epidemiologic data to study the effects of weight change on health and longevity. Despite uncertainties in interpreting the associations described here, our findings are strengthened by their consistency with those of two earlier studies involving body-weight variability and health.  <sup>, </sup>  Together, these results raise the possibility that weight cycling by dietary means may have a role in the development of chronic disease.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-14 00:19:10", "grab_time": "2024-08-13 22:48:40"}
{"id": 2234484, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "e9ca3c71-b300-4f2b-8718-78a3440156c1", "title": "Tipping the Scale — The Norms Hypothesis and Primary Care Physician Behavior", "text": "【0】Tipping the Scale — The Norms Hypothesis and Primary Care Physician Behavior\nThe norms hypothesis suggests that physicians will develop a relatively uniform approach to care that’s consistent with their overall financial incentives. So physician behavior may not change until enough patients are covered by risk-based contracts to justify change.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 17:01:44", "endTime": "2024/08/13 17:01:55", "cost": 10.816}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 01:01:55", "grab_time": "2024-08-13 01:01:44"}
{"id": 2234483, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "41353e52-a934-4f07-852e-892d937c823a", "title": "Clinical Prediction Rules — Applications and Methodological Standards", "text": "【0】Clinical Prediction Rules — Applications and Methodological Standards\nAbstract\n\n【1】The objective of clinical prediction rules is to reduce the uncertainty inherent in medical practice by defining how to use clinical findings to make predictions. Clinical prediction rules are derived from systematic clinical observations. They can help physicians identify patients who require diagnostic tests, treatment, or hospitalizaron.\n\n【2】Before adopting a prediction rule, clinicians must evaluate its applicability to their patients. We describe methodological standards that can be used to decide whether a prediction rule is suitable for adoption in a clinician's practice. We applied these standards to 33 reports of prediction rules; 42 per cent of the reports contained an adequate description of the prediction rules, the patients, and the clinical setting. The misclassification rate of the rule was measured in only 34 per cent of reports, and the effects of the rule on patient care were described in only 6 per cent of reports.\n\n【3】If the objectives of clinical prediction rules are to be fully achieved, authors and readers need to pay close attention to basic principles of study design.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:24:53", "endTime": "2024/08/14 15:25:10", "cost": 17.731}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 23:25:11", "grab_time": "2024-08-13 23:24:53"}
{"id": 2234482, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "56e3ba5a-a07f-4673-af5c-8fa8eb6f3647", "title": "Regulatory Action on Rosiglitazone by the U.S. Food and Drug Administration", "text": "【0】Regulatory Action on Rosiglitazone by the U.S. Food and Drug Administration\nArticle\n-------\n\n【1】There have been ongoing concerns about the safety of the diabetes drugs containing rosiglitazone (Avandia, Avandaryl, and Avandamet) — a thiazolidinedione antidiabetic agent indicated as an adjunct to diet and exercise to improve glycemic control in adults with type 2 diabetes mellitus.\n\n【2】In 2007, a meta-analysis of controlled clinical trials found increases in the risk of myocardial infarction and a near-significant increased risk of death from cardiovascular causes when rosiglitazone was compared with placebo or with standard diabetes drugs.  Following an advisory committee meeting held in July 2007, the U.S. Food and Drug Administration (FDA) added information about the possibility of ischemic cardiovascular risk to the drug's existing boxed warning. At the same time, the FDA also required the sponsors to conduct a head-to-head cardiovascular safety trial of rosiglitazone versus pioglitazone — the other antidiabetic drug in this class available in the United States. After new data became available, the FDA held a second advisory committee meeting on rosiglitazone safety on July 13 and 14, 2010. On September 23, 2010, the FDA announced regulatory actions stemming from these deliberations.\n\n【3】The FDA is restricting access to rosiglitazone by requiring the drug sponsor to submit a Risk Evaluation and Mitigation Strategy, or REMS. Under the Food and Drug Administration Amendments Act of 2007, the FDA can require a drug sponsor to issue a REMS to impose certain restrictions so that the benefits of a drug continue to outweigh its risks. When the REMS for rosiglitazone is implemented, the drug will be available to patients not already taking it only if they are unable to achieve glycemic control using other medications and, in consultation with their health care professional, decide not to take pioglitazone for medical reasons. Current users of rosiglitazone will be able to continue using the medication if they appear to be benefiting from it and they acknowledge that they understand these risks. Doctors will have to attest to and document their patients' eligibility; patients will have to review statements describing the cardiovascular safety concerns. The agency anticipates that the REMS will limit use of rosiglitazone significantly.\n\n【4】The FDA is taking this step on the basis of its assessment of all available data on the cardiovascular ischemic risk of rosiglitazone. At the recent advisory committee meeting, FDA scientists and external experts presented new signals of risk from observational studies and meta-analyses. Each of these data sources has its limitations, including the potential for bias in observational studies and the fact that pooling the results of the studies that were not designed to assess cardiovascular risk can lead to invalid conclusions. But there was no reliable evidence to refute these cardiovascular safety concerns.\n\n【5】After considering the data, 18 members of the advisory committee found significant cause for concern about an increase in ischemic cardiovascular events with rosiglitazone relative to other non-thiazolidinedione antidiabetic agents, whereas 6 committee members did not. Twenty-one members believed that the cardiovascular risk with rosiglitazone was significant as compared with pioglitazone. Three members did not reach this conclusion. This 21-to-3 vote also reflected recognition that available evidence on pioglitazone, including the results of a well-designed trial in high-risk patients, does not show a signal of a cardiovascular ischemic risk.\n\n【6】The rosiglitazone controversy is remarkable because there are strongly held, differing positions on how the agency should respond to emerging safety data, both inside the FDA and in the biomedical community. The 2010 advisory committee was split in advising the agency about what to do. Moving from the least to most restrictive options, 3 members voted to allow continued marketing with no changes to the label; 7 voted that the FDA should adjust the label to account for the new concerns but take no additional action; 10 members voted for the FDA to both increase warnings and limit access to rosiglitazone; and 12 voted that the medication should be removed from the market altogether. The FDA decided to increase warnings and limit access to rosiglitazone substantially.\n\n【7】The FDA anticipates questions on whether the agency has gone too far, or not far enough.\n\n【8】Some may note the limitations of available data and argue that the FDA should provide more information to clinicians but not impose additional restrictions. The FDA's response is that a label change alone does not provide adequate assurance that use of rosiglitazone will be limited to appropriate patients. New label warnings are not always read. The significant questions about the drug's cardiovascular safety justify stronger measures to support good clinical decision making and protect patients.\n\n【9】Others may argue that rosiglitazone should be removed from the market because there is no predefined patient population for whom it is known that it will be more advantageous than pioglitazone. Our response starts with the fact that rosiglitazone does have benefits in glycemic control. These benefits include reductions in short-term complications of hyperglycemia. There is also a broad range of evidence supporting glycemic control as a reliable surrogate marker for decreasing the rate of progression of the microvascular complications of diabetes, including retinopathy and kidney disease. \n\n【10】Against these benefits, we must assess the evidence of rosiglitazone's cardiovascular risks. This evidence is concerning, but it is not definitive. There are patients with severe type 2 diabetes whose disease may not be controlled on other medications and either may not tolerate pioglitazone or, in consultation with their health care professional, decide not to take pioglitazone for other medical reasons. If well informed, these patients may be willing to accept the concern about cardiovascular safety in exchange for the known benefits of glycemic control. The FDA recently announced that the agency is investigating further signals of a possible increase in the risk of bladder cancer with long-term use of pioglitazone.  Although the absolute risk to all patients appears to be small, some patients with a history of bladder cancer, in consultation with their doctors, may decide not to take pioglitazone. When there are just two drugs in a class, and many outstanding uncertainties, maintaining some flexibility may have value for patient care.\n\n【11】The FDA will continue to review emerging data on rosiglitazone. The agency is requiring an independent readjudication of end points at the patient level of an important trial of rosiglitazone's safety — the Rosiglitazone Evaluated for Cardiovascular Outcomes in Oral Agent Combination Therapy for Type 2 Diabetes, or RECORD, trial.  As published, RECORD demonstrated the noninferiority of rosiglitazone when compared with sulfonylureas and metformin with respect to a composite end point of multiple cardiovascular events and death, but it did not rule out an elevated risk of myocardial infarction. However, during the course of the FDA's review of the RECORD study, serious questions arose about potential bias in identification of cardiovascular events arising from the study's open-label design. The FDA is requiring the readjudication of end points to provide additional clarity about the findings.\n\n【12】Other actions taken by the agency include the discontinuation of the trial known as TIDE (Thiazolidinedione Intervention with Vitamin D Evaluation) — the head-to-head cardiovascular safety trial of rosiglitazone versus pioglitazone. Given the current state of the evidence and the FDA's recent actions, participants would need to be informed of significant concerns that rosiglitazone may cause more cardiovascular disease than pioglitazone, the restrictions on the use of rosiglitazone that will be imposed through the REMS, and that it is unlikely that, outside the study, the patient would receive rosiglitazone. According to recent recommendations from an Institute of Medicine committee, such an informed consent process might be justified if the study's outcome could realistically yield a significant benefit to public health. At this point, however, the FDA does not consider TIDE such a study. It is possible that additional data, including information from the readjudication of RECORD, could support additional clinical trials of rosiglitazone safety.\n\n【13】How can the FDA prevent such uncertainty about a major risk from happening again? In 2008, the FDA issued draft guidance on the assessment of cardiovascular risk for new antidiabetic drugs.  In this guidance, the FDA proposed upper boundaries for the risk of major cardiovascular events in a meta-analysis or a noninferiority study that compares the new drug with standard therapy. The FDA also recommends that the data for these comparisons come from longer-term trials — that is, trials of at least 2 years' duration. Guidance represents the FDA's current thinking on how to meet a specific requirement — in this case, demonstration of the safety of a new drug for this indication. Drug sponsors are free to use other methods to show safety, but such methods need to be equally robust. The expectation of longer-term evidence on the cardiovascular risks of new antidiabetic drugs will assure that such evaluations are routinely conducted and that longer-term data on multiple safety parameters are also available.\n\n【14】The case of rosiglitazone underscores the need for a robust evidence base to demonstrate the safety of medicines administered long-term. The FDA is committed to advancing the science of drug safety evaluation, during both drug development and in the postmarketing period.\n\n【15】_Editor's note:_ The European Medicines Agency also took regulatory action on rosiglitazone on September 23 .", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "【15】Editor’s note: The European Medicines Agency also took regulatory action on rosiglitazone on September 23 .", "content": "【0】Regulatory Action on Rosiglitazone by the U.S. Food and Drug Administration\nArticle\n-------\n\n【1】There have been ongoing concerns about the safety of the diabetes drugs containing rosiglitazone (Avandia, Avandaryl, and Avandamet) — a thiazolidinedione antidiabetic agent indicated as an adjunct to diet and exercise to improve glycemic control in adults with type 2 diabetes mellitus.\n\n【2】In 2007, a meta-analysis of controlled clinical trials found increases in the risk of myocardial infarction and a near-significant increased risk of death from cardiovascular causes when rosiglitazone was compared with placebo or with standard diabetes drugs.  Following an advisory committee meeting held in July 2007, the U.S. Food and Drug Administration (FDA) added information about the possibility of ischemic cardiovascular risk to the drug's existing boxed warning. At the same time, the FDA also required the sponsors to conduct a head-to-head cardiovascular safety trial of rosiglitazone versus pioglitazone — the other antidiabetic drug in this class available in the United States. After new data became available, the FDA held a second advisory committee meeting on rosiglitazone safety on July 13 and 14, 2010. On September 23, 2010, the FDA announced regulatory actions stemming from these deliberations.\n\n【3】The FDA is restricting access to rosiglitazone by requiring the drug sponsor to submit a Risk Evaluation and Mitigation Strategy, or REMS. Under the Food and Drug Administration Amendments Act of 2007, the FDA can require a drug sponsor to issue a REMS to impose certain restrictions so that the benefits of a drug continue to outweigh its risks. When the REMS for rosiglitazone is implemented, the drug will be available to patients not already taking it only if they are unable to achieve glycemic control using other medications and, in consultation with their health care professional, decide not to take pioglitazone for medical reasons. Current users of rosiglitazone will be able to continue using the medication if they appear to be benefiting from it and they acknowledge that they understand these risks. Doctors will have to attest to and document their patients' eligibility; patients will have to review statements describing the cardiovascular safety concerns. The agency anticipates that the REMS will limit use of rosiglitazone significantly.\n\n【4】The FDA is taking this step on the basis of its assessment of all available data on the cardiovascular ischemic risk of rosiglitazone. At the recent advisory committee meeting, FDA scientists and external experts presented new signals of risk from observational studies and meta-analyses. Each of these data sources has its limitations, including the potential for bias in observational studies and the fact that pooling the results of the studies that were not designed to assess cardiovascular risk can lead to invalid conclusions. But there was no reliable evidence to refute these cardiovascular safety concerns.\n\n【5】After considering the data, 18 members of the advisory committee found significant cause for concern about an increase in ischemic cardiovascular events with rosiglitazone relative to other non-thiazolidinedione antidiabetic agents, whereas 6 committee members did not. Twenty-one members believed that the cardiovascular risk with rosiglitazone was significant as compared with pioglitazone. Three members did not reach this conclusion. This 21-to-3 vote also reflected recognition that available evidence on pioglitazone, including the results of a well-designed trial in high-risk patients, does not show a signal of a cardiovascular ischemic risk.\n\n【6】The rosiglitazone controversy is remarkable because there are strongly held, differing positions on how the agency should respond to emerging safety data, both inside the FDA and in the biomedical community. The 2010 advisory committee was split in advising the agency about what to do. Moving from the least to most restrictive options, 3 members voted to allow continued marketing with no changes to the label; 7 voted that the FDA should adjust the label to account for the new concerns but take no additional action; 10 members voted for the FDA to both increase warnings and limit access to rosiglitazone; and 12 voted that the medication should be removed from the market altogether. The FDA decided to increase warnings and limit access to rosiglitazone substantially.\n\n【7】The FDA anticipates questions on whether the agency has gone too far, or not far enough.\n\n【8】Some may note the limitations of available data and argue that the FDA should provide more information to clinicians but not impose additional restrictions. The FDA's response is that a label change alone does not provide adequate assurance that use of rosiglitazone will be limited to appropriate patients. New label warnings are not always read. The significant questions about the drug's cardiovascular safety justify stronger measures to support good clinical decision making and protect patients.\n\n【9】Others may argue that rosiglitazone should be removed from the market because there is no predefined patient population for whom it is known that it will be more advantageous than pioglitazone. Our response starts with the fact that rosiglitazone does have benefits in glycemic control. These benefits include reductions in short-term complications of hyperglycemia. There is also a broad range of evidence supporting glycemic control as a reliable surrogate marker for decreasing the rate of progression of the microvascular complications of diabetes, including retinopathy and kidney disease. \n\n【10】Against these benefits, we must assess the evidence of rosiglitazone's cardiovascular risks. This evidence is concerning, but it is not definitive. There are patients with severe type 2 diabetes whose disease may not be controlled on other medications and either may not tolerate pioglitazone or, in consultation with their health care professional, decide not to take pioglitazone for other medical reasons. If well informed, these patients may be willing to accept the concern about cardiovascular safety in exchange for the known benefits of glycemic control. The FDA recently announced that the agency is investigating further signals of a possible increase in the risk of bladder cancer with long-term use of pioglitazone.  Although the absolute risk to all patients appears to be small, some patients with a history of bladder cancer, in consultation with their doctors, may decide not to take pioglitazone. When there are just two drugs in a class, and many outstanding uncertainties, maintaining some flexibility may have value for patient care.\n\n【11】The FDA will continue to review emerging data on rosiglitazone. The agency is requiring an independent readjudication of end points at the patient level of an important trial of rosiglitazone's safety — the Rosiglitazone Evaluated for Cardiovascular Outcomes in Oral Agent Combination Therapy for Type 2 Diabetes, or RECORD, trial.  As published, RECORD demonstrated the noninferiority of rosiglitazone when compared with sulfonylureas and metformin with respect to a composite end point of multiple cardiovascular events and death, but it did not rule out an elevated risk of myocardial infarction. However, during the course of the FDA's review of the RECORD study, serious questions arose about potential bias in identification of cardiovascular events arising from the study's open-label design. The FDA is requiring the readjudication of end points to provide additional clarity about the findings.\n\n【12】Other actions taken by the agency include the discontinuation of the trial known as TIDE (Thiazolidinedione Intervention with Vitamin D Evaluation) — the head-to-head cardiovascular safety trial of rosiglitazone versus pioglitazone. Given the current state of the evidence and the FDA's recent actions, participants would need to be informed of significant concerns that rosiglitazone may cause more cardiovascular disease than pioglitazone, the restrictions on the use of rosiglitazone that will be imposed through the REMS, and that it is unlikely that, outside the study, the patient would receive rosiglitazone. According to recent recommendations from an Institute of Medicine committee, such an informed consent process might be justified if the study's outcome could realistically yield a significant benefit to public health. At this point, however, the FDA does not consider TIDE such a study. It is possible that additional data, including information from the readjudication of RECORD, could support additional clinical trials of rosiglitazone safety.\n\n【13】How can the FDA prevent such uncertainty about a major risk from happening again? In 2008, the FDA issued draft guidance on the assessment of cardiovascular risk for new antidiabetic drugs.  In this guidance, the FDA proposed upper boundaries for the risk of major cardiovascular events in a meta-analysis or a noninferiority study that compares the new drug with standard therapy. The FDA also recommends that the data for these comparisons come from longer-term trials — that is, trials of at least 2 years' duration. Guidance represents the FDA's current thinking on how to meet a specific requirement — in this case, demonstration of the safety of a new drug for this indication. Drug sponsors are free to use other methods to show safety, but such methods need to be equally robust. The expectation of longer-term evidence on the cardiovascular risks of new antidiabetic drugs will assure that such evaluations are routinely conducted and that longer-term data on multiple safety parameters are also available.\n\n【14】The case of rosiglitazone underscores the need for a robust evidence base to demonstrate the safety of medicines administered long-term. The FDA is committed to advancing the science of drug safety evaluation, during both drug development and in the postmarketing period.\n\n【15】_Editor's note:_ The European Medicines Agency also took regulatory action on rosiglitazone on September 23 .", "index": 9965, "show": true, "start": 9965, "end": 10076, "province": ["文本干净度", "无关文本"], "isEdit": false}], "startTime": "2024/08/14 15:12:33", "endTime": "2024/08/14 15:13:31", "cost": 58.394}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 23:13:31", "grab_time": "2024-08-13 23:12:32"}
{"id": 2234481, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "31e87349-f225-43c7-93cb-a7291a1c479b", "title": "Current Concepts: Newborn Hearing Screening — A Silent Revolution", "text": "【0】Current Concepts: Newborn Hearing Screening — A Silent Revolution\nThe implementation of universal screening programs to detect hearing defects in newborns has dramatically increased the identification of hearing loss in infants. Recent advances in understanding the nature and causes of prelingual hearing loss, combined with advances in technology, suggest that further improvement in these programs can readily be achieved.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:24:07", "endTime": "2024/08/14 15:24:15", "cost": 7.672}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 23:24:15", "grab_time": "2024-08-13 23:24:07"}
{"id": 2234480, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "d01a88e1-fa91-4b75-be79-da631b0c8d35", "title": "Case 33-2012 — A 34-Year-Old Woman with Episodic Paresthesias and Altered Mental Status after Childbirth", "text": "【0】Case 33-2012 — A 34-Year-Old Woman with Episodic Paresthesias and Altered Mental Status after Childbirth\nA 34-year-old woman, 2.5 months post partum, was admitted to the hospital because of episodic paresthesias and altered mental status, with amnesia for the events. During one episode, hypoglycemia was noted. A diagnostic test was performed.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:24:17", "endTime": "2024/08/14 15:24:25", "cost": 7.396}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 23:24:25", "grab_time": "2024-08-13 23:24:17"}
{"id": 2234479, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "517069e7-c7f3-4ee1-a045-b83304b2a130", "title": "Considerations for Developing a Zika Virus Vaccine", "text": "【0】Considerations for Developing a Zika Virus Vaccine\nArticle\n-------\n\n【1】### Audio Interview\n\n【2】 Interview with Dr. Anthony Fauci on potential strategies for conducting clinical trials of Zika virus vaccines. \n\n【3】The rapid spread of Zika virus through the Americas and its devastating consequences for pregnant women and infants have precipitated an international, multisectoral response. Current prevention strategies focus on mosquito control, protection of the blood supply, barrier protection during sex, and other forms of contraception. When this explosive epidemic abates, Zika virus could remain endemic in many countries, where the risk to pregnant women, the general public, and travelers will persist. Therefore, a safe and effective vaccine is essential.\n\n【4】Development of a safe, effective Zika vaccine should be feasible. Vaccines against related flaviviruses, such as yellow fever and Japanese encephalitis, have been developed and deployed, and Zika infection appears to generate protective immunity in nonhuman primates.  Scientific feasibility, however, does not ensure successful development. An efficient development pathway must be delineated, including the optimal ways to evaluate the safety, immunogenicity, and effectiveness of vaccine candidates for intended target populations.\n\n【5】The primary goal of Zika vaccination is to prevent infection and protect against serious sequelae of the virus, particularly fetal congenital anomalies following in utero infection; however, given the relatively low frequency of these events in relation to the total number of infections, generating evidence of efficacy against these sequelae in prelicensure trials may not be feasible within a reasonable time frame. Demonstrating that vaccination averts congenital anomalies will most likely require postlicensure studies.\n\n【6】Prevention of congenital anomalies through vaccination of women during pregnancy faces several challenges. First, to protect the developing fetus, one must achieve protective immunity before the time of peak vulnerability, which is probably during the first and early second trimesters (although complications resulting from infections later in pregnancy have been reported).  Furthermore, many women are unaware of their pregnancies until well into the first trimester. Although replicating live-virus vaccines may be protective after a single dose, these are generally not good candidates for vaccines administered during pregnancy. Inactivated, recombinant subunit, and other nonreplicating vaccines, more appropriate for use during pregnancy, usually require multiple doses to achieve protective immunity, thereby delaying effective immunity beyond the window of peak vulnerability for the fetus.\n\n【7】Second, vaccine safety and immunogenicity are generally established in nonpregnant adults before vaccination of pregnant women is considered — a standard practice that delays vaccine use in the latter population until some assurances of safety are provided. Hence, it is likely that vaccinating women of childbearing age (and men in order to prevent sexual transmission) would be the optimal initial public health strategy. In the longer term, it may be advisable to vaccinate pediatric populations, well before their first sexual contact. Here, the experience with rubella is instructive: protection of pregnant women was achieved through broad vaccination of young children. Adoption of this strategy would depend on the durability of protection offered by a Zika vaccine.\n\n【8】In approaching clinical development of Zika vaccines, investigators should adopt the most efficient methods for generating high-quality data on safety, immunogenicity, and efficacy. There are several reasons to favor randomized, controlled trials (RCTs) for this purpose. First, regional and temporal variability in Zika incidence due to differences in vector density and infection rates complicate the use of non-RCT trial designs. Second, specific aspects of the pathogenesis of Zika virus and other flavivirus diseases raise potential safety concerns that can best be assessed through direct comparison with a simultaneously enrolled control population. Concerns include the risk of vaccine-associated Guillain–Barré syndrome, the potential for neurotropism with live-attenuated vaccines, and the theoretical risk of antibody-dependent enhancement of Zika virus replication in persons who have previously been infected with or vaccinated against a flavivirus. RCTs offer the most reliable means of obtaining an early assessment of these potential complications.\n\n【9】 Pathways for Clinical Evaluation of Zika Vaccine Candidates.\n\n【10】Strategies 1a and 1b would require high infection rates in trial communities in order to accumulate sufficient infection end points. Strategy 1a would use incidence of confirmed symptomatic infection as a primary end point, relying on report of symptoms and diagnostic confirmation. This approach would not capture asymptomatic infections. Strategy 1b would capture both asymptomatic and symptomatic infections. Strategies 2 and 3 could be used if the incidence of infection falls substantially, rendering Strategies 1a and 1b infeasible to pursue. In these cases, human challenge (Strategy 2) and animal models (Strategy 3) could provide evidence of vaccine efficacy.\n\n【11】In conducting clinical trials, we envision three potential strategies . The relative merit of each plan depends largely on disease incidence and the resultant likelihood of generating reliable data on safety and efficacy. Regardless of the strategy used, affected communities must be actively engaged in trial design and execution to ensure that their concerns are reflected in all aspects of clinical evaluation.\n\n【12】Strategy 1 would use a traditional vaccine-development approach, in which phase 1 and phase 2 studies assess safety and immunogenicity, including the effect of prior flavivirus exposure on responses to Zika vaccines (e.g., in dengue-endemic regions). Investigators could adopt one of two end points for evaluation of efficacy in phase 2b or phase 3 studies. The first would be symptomatic infection alone (confirmed by polymerase chain reaction, which can distinguish Zika virus from cocirculating arboviruses such as chikungunya and flaviviruses such as dengue that cross-react serologically with Zika \\[Strategy 1a\\]). The second would be a combination of symptomatic and asymptomatic infections (Strategy 1b), which would require active surveillance, most likely through the regular collection of urine or blood, since an estimated 80% of infections are asymptomatic.  The advantage of this approach is that it would facilitate efficacy evaluation using a smaller sample size. Moreover, demonstrating protection against asymptomatic infection may be important if such infection is shown to be associated with congenital disease.\n\n【13】In Strategy 2, human challenge studies would be conducted after phase 1 and 2 studies. This approach could prove a viable alternative to Strategy 1 if the incidence of Zika disease drops to low levels before large vaccine efficacy studies can be initiated.\n\n【14】Although this approach could permit efficient assessment of vaccine efficacy, it would require careful and specific ethical review in which the risk to volunteers is weighed against the potential public health benefit.  Risks could include neurologic sequelae and sex-specific concerns: for male and female vaccinees, the risk of sexual transmission to partners (and thus the risk to any resulting pregnancy); for female vaccinees, the risk of inadvertent or unrecognized pregnancy. Some of these issues could be managed through subject selection and counseling. Until the risks of neurologic sequelae are well understood, the prospect of conducting human challenge studies should be approached with caution.\n\n【15】Challenge studies might also identify immunologic markers that could be used as surrogate end points to support accelerated approval of vaccine candidates. Vaccines approved through this pathway are subject to the additional requirement of postlicensure study to verify clinical benefit.\n\n【16】Strategy 3 would apply only in situations in which human efficacy studies are not feasible (e.g., if the incidence drops dramatically). In this scenario, developers could rely on the Food and Drug Administration Animal Rule, under which licensure would be based on adequate and well-controlled efficacy studies in animals coupled with the evaluation of safety and immunogenicity studies in humans. Reliance on Strategy 3 would require more thorough characterization of animal models and protective immune responses.\n\n【17】Finally, since there are several vaccine candidates in various stages of development, it will be challenging to efficiently identify the most promising candidates. One solution is for public institutions to consider supporting trials evaluating multiple candidates over time against a common control group. The selection of candidates for inclusion would be based on preclinical and early clinical data and other considerations (e.g., manufacturing timelines).\n\n【18】Given the effects of Zika infection, especially on the developing fetus, control of the Zika epidemic is a critical global health goal. The development of a safe and effective Zika vaccine is an important component of a long-term solution. Carefully executed evaluation of candidate Zika vaccines, coupled with thoughtful planning for eventual use and deployment, will be essential to durable control of Zika virus infections.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:23:41", "endTime": "2024/08/14 15:24:04", "cost": 23.546}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 23:24:04", "grab_time": "2024-08-13 23:23:40"}
{"id": 2234478, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "fd7ca74d-f0d0-4cf9-8bca-c26a1fc3eb77", "title": "Relation of High Blood Pressure to Headache, Epistaxis, and Selected Other Symptoms — The United States Health Examination Survey of Adults", "text": "【0】Relation of High Blood Pressure to Headache, Epistaxis, and Selected Other Symptoms — The United States Health Examination Survey of Adults\nAbstract\n--------\n\n【1】From the records of the Health Examination Survey of adults, 1960–62, the blood pressure of each of 6672 subjects was tabulated against his response to several questions on a self-administered medical history form. The responses to questions regarding headache, epistaxis, and tinnitus showed no relation to either systolic or diastolic blood pressure. The occurrence of dizziness was increased only in persons with very high diastolic pressure. The occurrence of fainting was inversely related to blood pressure.\n\n【2】Headache, tinnitus, and dizziness were each reported slightly but significantly more often in subjects with than without retinopathy; this relation held true in both normotensive and hypertensive groups.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:43:15", "endTime": "2024/08/14 14:43:23", "cost": 8.795}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 22:43:24", "grab_time": "2024-08-13 22:43:14"}
{"id": 2234477, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "5781fcd1-318b-469b-ba36-8dd36f4630a2", "title": "FOLFIRINOX or Gemcitabine as Adjuvant Therapy for Pancreatic Cancer", "text": "【0】FOLFIRINOX or Gemcitabine as Adjuvant Therapy for Pancreatic Cancer\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Among patients with metastatic pancreatic cancer, combination chemotherapy with fluorouracil, leucovorin, irinotecan, and oxaliplatin (FOLFIRINOX) leads to longer overall survival than gemcitabine therapy. We compared the efficacy and safety of a modified FOLFIRINOX regimen with gemcitabine as adjuvant therapy in patients with resected pancreatic cancer.\n\n【3】Methods\n-------\n\n【4】We randomly assigned 493 patients with resected pancreatic ductal adenocarcinoma to receive a modified FOLFIRINOX regimen (oxaliplatin \\[85 mg per square meter of body-surface area\\], irinotecan \\[180 mg per square meter, reduced to 150 mg per square meter after a protocol-specified safety analysis\\], leucovorin \\[400 mg per square meter\\], and fluorouracil \\[2400 mg per square meter\\] every 2 weeks) or gemcitabine (1000 mg per square meter on days 1, 8, and 15 every 4 weeks) for 24 weeks. The primary end point was disease-free survival. Secondary end points included overall survival and safety.\n\n【5】Results\n-------\n\n【6】At a median follow-up of 33.6 months, the median disease-free survival was 21.6 months in the modified-FOLFIRINOX group and 12.8 months in the gemcitabine group (stratified hazard ratio for cancer-related event, second cancer, or death, 0.58; 95% confidence interval \\[CI\\], 0.46 to 0.73; P<0.001). The disease-free survival rate at 3 years was 39.7% in the modified-FOLFIRINOX group and 21.4% in the gemcitabine group. The median overall survival was 54.4 months in the modified-FOLFIRINOX group and 35.0 months in the gemcitabine group (stratified hazard ratio for death, 0.64; 95% CI, 0.48 to 0.86; P=0.003). The overall survival rate at 3 years was 63.4% in the modified-FOLFIRINOX group and 48.6% in the gemcitabine group. Adverse events of grade 3 or 4 occurred in 75.9% of the patients in the modified-FOLFIRINOX group and in 52.9% of those in the gemcitabine group. One patient in the gemcitabine group died from toxic effects (interstitial pneumonitis).\n\n【7】Conclusions\n-----------\n\n【8】Adjuvant therapy with a modified FOLFIRINOX regimen led to significantly longer survival than gemcitabine among patients with resected pancreatic cancer, at the expense of a higher incidence of toxic effects. \n\n【9】Introduction\n------------\n\n【10】Pancreatic adenocarcinoma is a major cause of cancer-related death in Western countries and is anticipated to emerge as the second leading cause of cancer-related death in the United States by 2030.  The prognosis of patients with pancreatic cancer has changed little over the past two decades,  and according to recent studies, it is estimated that almost 44,000 persons in the United States  and 89,000 in Europe  will die from this disease in 2018.\n\n【11】Surgery offers the only chance of cure, but 5-year survival rates after surgical resection alone are low (approximately 10%).  A 6-month regimen of adjuvant therapy with gemcitabine  or a fluoropyrimidine (fluorouracil plus leucovorin  or S-1 in Japan  ) has been shown to significantly improve outcomes and is recognized as standard care in patients with resected pancreatic cancer.  However, recurrence rates remain high despite adjuvant treatment, with 69 to 75% of patients having a relapse within 2 years. \n\n【12】The combination of fluorouracil, leucovorin, irinotecan, and oxaliplatin (FOLFIRINOX) has resulted in longer overall survival than gemcitabine when administered as first-line treatment in patients with metastatic pancreatic cancer.  On the basis of these results, we initiated a phase 3 trial to explore the efficacy of FOLFIRINOX, as compared with gemcitabine, as adjuvant therapy after resection of pancreatic cancer. A modified version of the FOLFIRINOX regimen, without bolus fluorouracil, was used to decrease the incidence and severity of hematologic toxic effects and diarrhea and has been shown to not reduce treatment efficacy in patients with advanced disease. \n\n【13】Methods\n-------\n\n【14】Trial Oversight\n---------------\n\n【15】The trial was designed under the auspices of the PRODIGE (Partenariat de Recherche en Oncologie Digestive) intergroup and the Canadian Cancer Trials Group. An independent data and safety monitoring committee was established to review all the trial data and to ensure the ethical conduct of the trial. A central review of surgical reports, postsurgical computed tomographic (CT) and magnetic resonance imaging (MRI) scans, and pathology reports was performed to confirm the eligibility of the patients and to check major prognostic factors. R&D Unicancer (one of the trial sponsors) and its representatives collected and analyzed the data. All the versions of the manuscript were prepared by the authors (two of whom are employees of R&D Unicancer), with editorial and writing assistance funded by R&D Unicancer. The investigators agreed to keep all the aspects of the trial confidential. All the authors reviewed the manuscript and made the decision to submit it for publication. Oxaliplatin was supplied to the Canadian centers by Sanofi-Aventis Canada, which had no role in the trial design, the data collection or analysis, or the manuscript preparation or review.\n\n【16】Patients\n--------\n\n【17】Patients 18 to 79 years of age who had histologically confirmed pancreatic ductal adenocarcinoma, who had undergone complete macroscopic (R0 \\[no cancer cells within 1 mm of all resection margins\\] or R1 \\[cancer cells present within 1 mm of one or more resection margins\\]) resection within 3 to 12 weeks before randomization, and who had no evidence of metastatic disease, malignant ascites, or pleural effusion were eligible for inclusion. Other inclusion criteria were full recovery from surgery, a World Health Organization (WHO) performance-status score of 0 or 1 (on a 5-point scale, with higher numbers indicating greater disability), and adequate hematologic function (absolute neutrophil count, ≥1500 per cubic millimeter; platelet count, ≥100,000 per cubic millimeter; and hemoglobin level, ≥10 g per deciliter), liver function (serum total bilirubin level, ≤1.5 times the upper limit of the normal range), and renal function (creatinine clearance, ≥50 ml per minute). Patients with nonductal pancreatic tumors, incomplete (R2) resection, a serum CA 19-9 level of more than 180 U per milliliter within 21 days before randomization, receipt of previous chemotherapy or radiotherapy, or symptomatic heart failure or coronary heart disease were ineligible.\n\n【18】Trial Design\n------------\n\n【19】This multicenter, randomized, open-label, phase 3 trial (PRODIGE 24–ACCORD \\[Actions Concertées dans les Cancers Colorectaux et Digestifs\\] 24 and CCTG PA \\[Canadian Cancer Trials Group Pancreatic Adenocarcinoma\\] 6) was conducted at 77 hospitals in France and Canada. Patients were randomly assigned to start receiving the modified FOLFIRINOX regimen or gemcitabine within 1 week after enrollment. Randomization at a  ratio was performed centrally with the use of an independent Web-based system, with stratification according to trial center, lymph-node status (pN0 \\[no lymph-node involvement\\] or pN1 \\[lymph-node involvement\\]), resection status (R0 vs. R1), and CA 19-9 level (≤90 U per milliliter vs. 91 to 180 U per milliliter). Randomization of patients with pN0 status was also stratified according to the number of lymph nodes examined (<12 vs. ≥12).\n\n【20】The trial protocol was approved by an independent ethics committee in France (Comité de Protection des Personnes Est III) and by ethics committees at participating centers in Canada. All the patients provided written informed consent. The trial was conducted in accordance with the latest version of the Declaration of Helsinki, with the Good Clinical Practice guidelines of the International Conference on Harmonisation, and with relevant French, European, and Canadian laws and directives.\n\n【21】Treatment Regimens\n------------------\n\n【22】Gemcitabine at a dose of 1000 mg per square meter of body-surface area was delivered by means of a 30-minute intravenous infusion on days 1, 8, and 15 every 28 days for 24 weeks (6 cycles). The modified FOLFIRINOX regimen consisted of oxaliplatin, at a dose of 85 mg per square meter delivered as a 2-hour intravenous infusion, followed by leucovorin, at a dose of 400 mg per square meter given as a 2-hour intravenous infusion, and after 30 minutes, the addition of irinotecan at a dose of 180 mg per square meter administered as a 90-minute intravenous infusion, immediately followed by fluorouracil at a dose of 2400 mg per square meter administered by continuous intravenous infusion over a period of 46 hours, every 14 days for 24 weeks (12 cycles). The dose of irinotecan was reduced to 150 mg per square meter after the enrollment of 162 patients, in accordance with a protocol-specified safety analysis. In cases of febrile neutropenia or delay in treatment administration due to neutropenia, the use of granulocyte colony-stimulating factor (G-CSF) was advised for the following cycles. Protocol-specified treatment modifications were allowed when prespecified toxic effects occurred .\n\n【23】End Points and Assessments\n--------------------------\n\n【24】The primary end point was disease-free survival. Secondary end points were overall survival, metastasis-free survival, cancer-specific survival, and safety. Disease-free survival was calculated from the date of randomization until the date of the first cancer-related event, second cancer, or death from any cause. Overall survival was calculated from the date of randomization until death from any cause. Metastasis-free survival was calculated from the date of randomization until the date of the first detectable distant disease or death. Cancer-specific survival was calculated from the date of randomization until death due to the treated cancer or a treatment-related complication. Patients without events at the time of analysis had their data censored on the date of last informative follow-up.\n\n【25】Evaluations at baseline included a postoperative abdominal, thoracic, and pelvic CT scan (or MRI if the patient could not receive a contrast agent) and the assessment of postoperative serum CA 19-9 levels. At the start of every cycle, the status of the patient was assessed by means of a complete physical examination, WHO performance-status assessment, complete blood counts, and blood biochemical testing. Follow-up assessments included CT scans or MRI, serum CA 19-9 levels, and clinical examinations repeated every 3 months for 2 years and then every 6 months for 3 years. Patients with disease recurrence were monitored every 6 months for survival and long-term toxic effects. Safety assessments were performed before each cycle and until the end of follow-up. Adverse events were graded according to the National Cancer Institute Common Terminology Criteria for Adverse Events, version 4.0. \n\n【26】Statistical Analysis\n--------------------\n\n【27】On the basis of a median overall survival benefit of 4.3 months with FOLFIRINOX among patients with metastatic pancreatic cancer,  we anticipated that the 3-year disease-free survival rate would be 10 percentage points higher with the modified FOLFIRINOX regimen than with gemcitabine therapy, which would correspond to a hazard ratio for cancer-related event, second cancer, or death of 0.74. We calculated that the inclusion of 490 patients (with 342 events required for the analyses) would provide the trial with 80% power to detect a difference of 10 percentage points in the 3-year disease-free survival rate at a two-sided significance level of 5%.\n\n【28】On February 5, 2018, for ethical reasons, the independent data and safety monitoring committee recommended early analysis and publication of the findings. The database was locked on April 13, 2018, at which time 314 cancer-related events, second cancers, or deaths from any cause (91.8% of the expected events regarding disease-free survival) had occurred. The findings from this analysis are presented here.\n\n【29】All the analyses were performed on an intention-to-treat basis, except for the safety analyses, which included only the treated patients. Qualitative variables were compared by the chi-square test or Fisher’s exact test, and quantitative variables by the Kruskal–Wallis test. Survival rate estimates were calculated with the use of the Kaplan–Meier method  and compared with the use of a stratified log-rank test. A Cox proportional-hazards model (stratified according to the stratification factors, except for trial center) was used to estimate hazard ratios with 95% confidence intervals. The proportional-hazards assumption was verified by the Schoenfeld residual method.  All the tests were two-sided, and a P value of less than 0.05 was considered to indicate statistical significance.\n\n【30】A Cox proportional-hazards model was used to evaluate the effects of prognostic factors on disease-free survival in univariate and multivariate analyses, including the effect size of treatment. Clinically relevant factors or variables with P values of less than 0.20 were explored further in a multivariate analysis with the use of ascending or descending selection techniques. Hazard ratios indicating the effects of prognostic factors were calculated and displayed in a forest plot.  The interaction test was used to assess the heterogeneity of treatment effects for subgroup analyses.  Exploratory analyses to identify risk factors for the occurrence of diarrhea were performed with the use of a logistic-regression model. All the analyses were performed with the use of Stata software, version 13.0 (StataCorp).\n\n【31】Results\n-------\n\n【32】Characteristics of the Patients\n-------------------------------\n\n【33】Figure 1. Randomization and Treatment of the Patients.\n\n【34】The modified FOLFIRINOX regimen consisted of fluorouracil (without bolus), leucovorin, irinotecan, and oxaliplatin.Table 1.  Table 1. Demographic and Clinical Characteristics of the Patients at Baseline (Intention-to-Treat Population).\n\n【35】From April 2012 through October 2016, a total of 493 patients at 58 centers in France and 19 centers in Canada were randomly assigned to receive the modified FOLFIRINOX regimen (247 patients) or gemcitabine (246 patients); these patients constituted the intention-to-treat population . A total of 9 patients in the modified-FOLFIRINOX group and 6 in the gemcitabine group had major violations of eligibility criteria, primarily because some patients were found to have metastatic disease (8 and 5 patients, respectively). The demographic and disease characteristics of the patients at baseline were similar in the two treatment groups , except for lymphovascular invasion, which was significantly more common in the modified-FOLFIRINOX group than in the gemcitabine group (73.7% vs. 63.1%, P=0.02).\n\n【36】Treatment\n---------\n\n【37】The median number of cycles was 12 (range, 1 to 12) in the modified-FOLFIRINOX group and 6 (range, 1 to 6) in the gemcitabine group . The median duration of treatment was 24.6 weeks (range, 2.0 to 36.6) in the modified-FOLFIRINOX group and 24.0 weeks (range, 3.0 to 36.0) in the gemcitabine group. A total of 158 patients (66.4%) in the modified-FOLFIRINOX group and 192 patients (79.0%) in the gemcitabine group received all the planned cycles of chemotherapy (P=0.002). The relative dose intensity (i.e., the proportion of administered doses per time unit relative to planned doses) was 0.70 or higher in 116 patients (48.7%) in the modified-FOLFIRINOX group and in 222 patients (91.4%) in the gemcitabine group (P<0.001).\n\n【38】Efficacy\n--------\n\n【39】Figure 2. Kaplan–Meier Estimates of Disease-free Survival and Overall Survival in the Intention-to-Treat Population, According to Treatment Group.\n\n【40】The median disease-free survival was 21.6 months in the modified-FOLFIRINOX group, as compared with 12.8 months in the gemcitabine group . The median overall survival was 54.4 months in the modified-FOLFIRINOX group, as compared with 35.0 months in the gemcitabine group . Tick marks indicate censored data.\n\n【41】The median duration of follow-up in the intention-to-treat population was 33.6 months (95% confidence interval \\[CI\\], 30.3 to 36.0). A cancer-related event, second cancer, or death occurred in 134 patients (54.3%) in the modified-FOLFIRINOX group and in 180 (73.2%) in the gemcitabine group . The median disease-free survival was 21.6 months (95% CI, 17.7 to 27.6) in the modified-FOLFIRINOX group, as compared with 12.8 months (95% CI, 11.7 to 15.2) in the gemcitabine group (stratified hazard ratio for cancer-related event, second cancer, or death, 0.58; 95% CI, 0.46 to 0.73; P<0.001) . Disease-free survival rates at 1 year, 2 years, and 3 years were 69.0% (95% CI, 62.6 to 74.6), 47.0% (95% CI, 40.2 to 53.5), and 39.7% (95% CI, 32.8 to 46.6), respectively, in the modified-FOLFIRINOX group, as compared with 53.7% (95% CI, 47.2 to 59.8), 30.7% (95% CI, 24.8 to 36.8), and 21.4% (95% CI, 15.8 to 27.5), respectively, in the gemcitabine group. The pattern of recurrence was similar in the two groups .\n\n【42】Tumor grade indicating moderately or poorly differentiated or undifferentiated tumor, pN1 nodal status, higher tumor stage (IIB, III, or IV), R1 resection status, superior-mesenteric-vein resection, and portal-vein resection were identified as adverse prognostic factors for disease-free survival in the univariate analysis. Tumor grade and portal-vein resection were the only adverse prognostic factors that were identified in the multivariate analysis. The beneficial effect of the modified FOLFIRINOX regimen as compared with gemcitabine therapy on disease-free survival remained significant after adjustment for these factors (adjusted hazard ratio for cancer-related event, second cancer, or death, 0.60; 95% CI, 0.48 to 0.76; P<0.001). Details are provided in Tables S4 and S5 in the Supplementary Appendix .\n\n【43】Figure 3. Forest Plot of the Treatment Effect on Disease-free Survival in Subgroup Analyses.\n\n【44】In the analysis of disease-free survival, the hazard ratio is for the first cancer-related event, second cancer, or death. The position of each square represents the point estimate of the treatment effect, and error bars represent 95% confidence intervals. The sizes of the squares are proportional to the precision of the estimates. The diamond represents the overall point estimate of the treatment effect, with the lateral points indicating the 95% confidence interval. The vertical line indicates a hazard ratio of 1.0, which was the null hypothesis value. Scores for the World Health Organization (WHO) performance status are on a 5-point scale, with higher numbers indicating greater disability; a score of 0 indicates that the patient is fully active and able to carry on activities without restriction, and a score of 1 that the patient is restricted in physically strenuous activity but is ambulatory and able to carry out light work. Primary tumor status was assessed as pT1 (tumor limited to the pancreas and ≤2 cm in the greatest dimension), pT2 (tumor limited to pancreas and >2 cm in the greatest dimension), pT3 (tumor extends beyond pancreas but without involvement of celiac axis or superior mesenteric artery), or pT4 (tumor involves celiac axis or superior mesenteric artery). Nodal status was assessed as pN0 (no lymph-node involvement) and pN1 (lymph-node involvement). Tumor stage was assessed according to the 2009 tumor–node–metastasis (TNM) classification, 7th edition.  A surgical margin of R0 indicates that no cancer cells were present within 1 mm of all resection margins, and R1 the presence of cancer cells within 1 mm of one or more resection margins.\n\n【45】The subgroup analysis showed no evidence of heterogeneity of the effect size of treatment on disease-free survival . In particular, the benefit of the modified FOLFIRINOX regimen as compared with gemcitabine therapy was similar in patients younger than 65 years of age and those 65 years of age or older. In the 101 patients who were 70 years of age or older (20.5% of the trial population), however, the benefit of the modified FOLFIRINOX regimen as compared with gemcitabine therapy did not reach significance (hazard ratio for cancer-related event, second cancer, or death, 0.86; 95% CI, 0.53 to 1.39). The reduction in the irinotecan dose from 180 mg per square meter (90 patients at this level) to 150 mg per square meter (124 patients at this level) after a prespecified toxicity analysis did not significantly affect disease-free survival (hazard ratio in the subgroup with the reduced dose, 0.97; 95% CI, 0.67 to 1.40; P=0.87). A total of 24 patients received a maximum dose of irinotecan between 155 and 175 mg per square meter.\n\n【46】The median overall survival was 54.4 months (95% CI, 41.8 to not reached) in the modified-FOLFIRINOX group, as compared with 35.0 months (95% CI, 28.7 to 43.9) in the gemcitabine group (stratified hazard ratio for death, 0.64; 95% CI, 0.48 to 0.86; P=0.003) . The overall survival rate at 3 years was 63.4% (95% CI, 55.7 to 70.1) in the modified-FOLFIRINOX group and 48.6% (95% CI, 40.9 to 55.8) in the gemcitabine group.\n\n【47】The median metastasis-free survival was 30.4 months (95% CI, 21.7 to not reached) in the modified-FOLFIRINOX group, as compared with 17.7 months (95% CI, 14.2 to 21.5) in the gemcitabine group (stratified hazard ratio for detectable distant disease or death, 0.59; 95% CI, 0.46 to 0.75; P<0.001) . The metastasis-free survival rate at 3 years was 48.2% (95% CI, 41.0 to 55.0) in the modified-FOLFIRINOX group and 30.9% (95% CI, 24.4 to 37.6) in the gemcitabine group.\n\n【48】The median cancer-specific survival was not reached (95% CI, 47.3 to not reached) in the modified-FOLFIRINOX group, as compared with 36.4 months (95% CI, 30.9 to 46.2) in the gemcitabine group (stratified hazard ratio for death due to the treated cancer or a treatment-related complication, 0.63; 95% CI, 0.47 to 0.85; P=0.003) . The cancer-specific survival rate at 3 years was 66.2% (95% CI, 58.7 to 72.7) in the modified-FOLFIRINOX group and 51.2% (95% CI, 43.5 to 58.4) in the gemcitabine group.\n\n【49】All the secondary end points remained significant after Bonferroni adjustment. Treatments that were administered after tumor relapse were chemotherapy (in 63.0% of the patients in the modified-FOLFIRINOX group \\[with gemcitabine-based therapy used in 78.8% of these patients\\] and in 75.7% of the patients in the gemcitabine group \\[with FOLFIRINOX therapy used in 75.8%\\]), radiotherapy with or without chemotherapy (in 12.6% and 5.9%, respectively), and surgery (in 4.7% and 4.7%) .\n\n【50】Adverse Events\n--------------\n\n【51】Table 2. Adverse Events during Treatment (Safety Population).\n\n【52】Adverse events of grade 3 or 4 were reported in 180 of 237 patients (75.9%) in the modified-FOLFIRINOX group and in 128 of 242 (52.9%) in the gemcitabine group, and grade 4 events were reported in 29 patients (12.2%) and 29 patients (12.0%), respectively . One patient in the gemcitabine group died because of treatment-related toxic effects (interstitial pneumonitis). All the toxic effects were reversible, except for oxaliplatin-induced peripheral neurotoxic effect, which was persistent at 3 years in 2 patients in the modified-FOLFIRINOX group.\n\n【53】The incidence of grade 3 or 4 events of diarrhea, increase in the γ-glutamyltransferase level, paresthesia, fatigue, sensory peripheral neuropathy, nausea, vomiting, abdominal pain, and mucositis was significantly higher in the modified-FOLFIRINOX group, whereas thrombocytopenia of grade 3 or 4 was significantly more common in the gemcitabine group. The occurrence of neutropenia was similar in the two groups, but G-CSF was administered to 148 patients (62.2% \\[41.8% of cycles administered in this group\\]) in the modified-FOLFIRINOX group and to only 9 patients (3.7% \\[1.1% of cycles\\]) in the gemcitabine group (P<0.001). In the modified-FOLFIRINOX group, 84 of 148 patients (56.8%) received G-CSF as primary prophylaxis or for uncomplicated neutropenia without cycle delay.\n\n【54】In the modified-FOLFIRINOX group, diarrhea of grade 3 or 4 occurred in 18 of 90 patients (20.0%) who received at least one cycle with irinotecan at a dose of more than 175 mg per square meter and in 21 of 123 patients (17.1%) who received irinotecan at a dose of 150 mg or less per square meter, with diarrhea occurring in significantly fewer cycles at the lower doses (35.3% vs. 40.2% of the cycles, P=0.02). Diarrhea of grade 3 or 4 was more likely to occur during the first two cycles of the modified FOLFIRINOX regimen than during later cycles . Significant predictors for the occurrence of diarrhea of grade 3 or 4 were treatment with the modified FOLFIRINOX regimen rather than with gemcitabine (adjusted odds ratio, 6.0; 95% CI, 2.9 to 12.8; P<0.001) and a higher number of lymph nodes retrieved during surgery (≥20 vs. <20; adjusted odds ratio, 2.4; 95% CI, 1.3 to 4.4; P<0.001). No significant differences in the incidence of toxic effects of grade 3 or 4, either as the most common events or overall, were seen between the two treatment groups regardless of the age of the patients (<70 or ≥70 years).\n\n【55】Discussion\n----------\n\n【56】In this trial involving patients with resected pancreatic adenocarcinoma, adjuvant chemotherapy with a modified FOLFIRINOX regimen led to significantly longer disease-free survival, overall survival, metastasis-free survival, and cancer-specific survival than treatment with gemcitabine. The median disease-free survival (primary end point) was significantly longer, by 8.8 months, in the modified-FOLFIRINOX group than in the gemcitabine group. The disease-free survival benefit with modified FOLFIRINOX was significant in the majority of subgroups, including subgroups of patients with adverse prognostic factors (i.e., T3 or T4 tumor status, positive lymph nodes, or R1 resection).\n\n【57】The median disease-free survival in the gemcitabine group (12.8 months) was similar to that reported in previous phase 3 trials of adjuvant therapy (11.3 to 15.3 months), although the median overall survival was longer in our trial (35.0 months vs. 20.1 to 26.5 months).  This may be due to the high use of FOLFIRINOX after relapse in the gemcitabine group (in 76% of the patients). Nevertheless, overall survival was significantly longer, by 19.4 months, in the modified-FOLFIRINOX group than in the gemcitabine group, with a similar duration of follow-up in each group. However, the data remain immature, with 61% of all the patients being alive at the time of analysis.\n\n【58】As expected, the safety profile of the modified FOLFIRINOX regimen was less favorable than that of gemcitabine but appeared to be manageable. The occurrence of neutropenia of grade 3 or 4 was efficiently reduced by the deletion of bolus fluorouracil (and a reduction in the irinotecan dose) from the FOLFIRINOX regimen — from 46% of the patients with metastatic disease who received the unmodified regimen in the previous PRODIGE trial  to 28% of the patients who received the modified FOLFIRINOX regimen in the current trial — although the use of G-CSF with the modified FOLFIRINOX regimen remained high (62% of the patients). Both the protocol-specified irinotecan-dose modifications and the per-protocol dose reduction of irinotecan to 150 mg per square meter significantly reduced the incidence of grade 3 or 4 diarrhea. The occurrence of grade 3 or 4 diarrhea in the overall population and in the modified-FOLFIRINOX group was significantly associated with the number of lymph nodes retrieved, as described previously by others. \n\n【59】The selection of patients in this trial required that patients had to be eligible to receive the modified FOLFIRINOX regimen, and all the patients were required to undergo postsurgical CT or MRI and to have postoperative serum CA 19-9 levels of less than 180 U per milliliter in order to minimize the risk of incorrect inclusion of patients with metastatic disease. A central review of surgical reports, postsurgical CT and MRI scans, and pathology reports was performed to check prognostic factors. Disease-free survival rather than overall survival was chosen as the primary end point because it provides an earlier assessment of efficacy, requires fewer patients for evaluation, and avoids any bias that may result from the crossover of patients between groups. Although disease-free survival is not validated as a surrogate end point for overall survival in trials of adjuvant therapy for pancreatic cancer, this criterion was robust and correlated with overall survival. Disease-free survival was also used as the primary end point and correlated with overall survival in the Charité Onkologie (CONKO) trials, including a trial that compared adjuvant gemcitabine therapy with surgery alone (CONKO-001) and two trials that compared gemcitabine therapy with the use of gemcitabine plus targeted agents (CONKO-005 and CONKO-006).  Our trial is ongoing, with 3 years of follow-up currently.\n\n【60】In conclusion, among patients who underwent complete resection of pancreatic cancer, adjuvant chemotherapy with a modified FOLFIRINOX regimen led to significantly longer disease-free survival and overall survival than adjuvant chemotherapy with gemcitabine. The incidence of toxic effects was higher with the modified FOLFIRINOX regimen than with gemcitabine therapy.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-14 00:22:20", "grab_time": "2024-08-13 23:29:51"}
{"id": 2234476, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "301df7c9-0fbd-4a24-b0dc-f8f5e9ce97a1", "title": "Ofatumumab versus Teriflunomide in Multiple Sclerosis", "text": "【0】Ofatumumab versus Teriflunomide in Multiple Sclerosis\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Ofatumumab, a subcutaneous anti-CD20 monoclonal antibody, selectively depletes B cells. Teriflunomide, an oral inhibitor of pyrimidine synthesis, reduces T-cell and B-cell activation. The relative effects of these two drugs in patients with multiple sclerosis are not known.\n\n【3】Methods\n-------\n\n【4】In two double-blind, double-dummy, phase 3 trials, we randomly assigned patients with relapsing multiple sclerosis to receive subcutaneous ofatumumab (20 mg every 4 weeks after 20-mg loading doses at days 1, 7, and 14) or oral teriflunomide (14 mg daily) for up to 30 months. The primary end point was the annualized relapse rate. Secondary end points included disability worsening confirmed at 3 months or 6 months, disability improvement confirmed at 6 months, the number of gadolinium-enhancing lesions per T1-weighted magnetic resonance imaging (MRI) scan, the annualized rate of new or enlarging lesions on T2-weighted MRI, serum neurofilament light chain levels at month 3, and change in brain volume.\n\n【5】Results\n-------\n\n【6】Overall, 946 patients were assigned to receive ofatumumab and 936 to receive teriflunomide; the median follow-up was 1.6 years. The annualized relapse rates in the ofatumumab and teriflunomide groups were 0.11 and 0.22, respectively, in trial 1 (difference, −0.11; 95% confidence interval \\[CI\\], −0.16 to −0.06; P<0.001) and 0.10 and 0.25 in trial 2 (difference, −0.15; 95% CI, −0.20 to −0.09; P<0.001). In the pooled trials, the percentage of patients with disability worsening confirmed at 3 months was 10.9% with ofatumumab and 15.0% with teriflunomide (hazard ratio, 0.66; P=0.002); the percentage with disability worsening confirmed at 6 months was 8.1% and 12.0%, respectively (hazard ratio, 0.68; P=0.01); and the percentage with disability improvement confirmed at 6 months was 11.0% and 8.1% (hazard ratio, 1.35; P=0.09). The number of gadolinium-enhancing lesions per T1-weighted MRI scan, the annualized rate of lesions on T2-weighted MRI, and serum neurofilament light chain levels, but not the change in brain volume, were in the same direction as the primary end point. Injection-related reactions occurred in 20.2% in the ofatumumab group and in 15.0% in the teriflunomide group (placebo injections). Serious infections occurred in 2.5% and 1.8% of the patients in the respective groups.\n\n【7】Conclusions\n-----------\n\n【8】Among patients with multiple sclerosis, ofatumumab was associated with lower annualized relapse rates than teriflunomide. \n\n【9】Introduction\n------------\n\n【10】The pathophysiology of multiple sclerosis involves B cells. Anti-CD20 monoclonal antibodies that induce B-cell depletion, such as rituximab and ocrelizumab, are effective disease-modifying therapies for multiple sclerosis.  Ofatumumab, a fully human antibody that is used to treat chronic leukemia, binds to a region distinct from that of other anti-CD20 antibodies, including the smaller and the larger loop of CD20 receptors.  In experimental models, a high binding affinity and slow off-rate (slow dissociation of the binding between ofatumumab and the CD20 receptor in B cells) result in efficient B-cell lysis, mediated through complement-dependent and, to a lesser extent, antibody-dependent cytotoxicity.  In patients with multiple sclerosis, ofatumumab can be given at lower doses  than those studied in chronic lymphocytic leukemia and rheumatoid arthritis,  and ofatumumab can be administered subcutaneously by the patient after initial doses are given under medical supervision.  Experimental models have shown that there may be more direct access to lymph nodes through the lymphatic system with subcutaneous administration than with intravenous infusion,  but this has not been tested under clinical conditions. On treatment cessation, B-cell repletion and reconstitution of humoral immunity have been reported to occur faster with ofatumumab than with other intravenously administered B-cell–targeted therapies. \n\n【11】Teriflunomide, an oral disease-modifying therapy for relapsing multiple sclerosis, inhibits pyrimidine synthesis, reducing T-cell and B-cell activation.  According to the results of one comparative prospective trial  and a network meta-analysis,  the efficacy of teriflunomide to reduce annualized relapse rates is similar to that of interferons and glatiramer acetate, but according to observational studies  it is probably inferior to other oral and monoclonal antibody treatments for multiple sclerosis. We report the results of two phase 3, randomized, double-blind, double-dummy, active-controlled clinical trials of identical design, which assessed the efficacy and safety of subcutaneous ofatumumab as compared with oral teriflunomide.\n\n【12】Methods\n-------\n\n【13】Trial Oversight\n---------------\n\n【14】The ASCLEPIOS I and II trials were designed by the sponsor (Novartis Pharma) in consultation with the steering committee. The investigators collected data, which were analyzed by the sponsor. The investigators, the sponsor, and the steering committee were unaware of treatment assignments throughout the trials. An independent data monitoring committee reviewed the safety of treatment using regular analyses performed by independent statisticians, who were not involved in the conduct of the trials. The manuscript was drafted with medical writing assistance funded by the sponsor. All the authors, including those employed by Novartis, had full access to the data and were involved in the critical review of all drafts of the manuscript. All the authors vouch for the accuracy and completeness of the data, the accurate reporting of adverse events, and the fidelity of the trials to the protocols . There were confidentiality agreements in place between the authors and the sponsor. Novartis supplied the trial drugs and placebo. The trials were conducted in accordance with the International Conference on Harmonisation guidelines for Good Clinical Practice  and the principles of the Declaration of Helsinki.  The protocol was approved by an institutional review board or ethics committee at each trial site. All the patients or their legal representatives provided written informed consent before commencing trial-related procedures.\n\n【15】Patients\n--------\n\n【16】Eligibility criteria at screening included an age of 18 to 55 years; a diagnosis of multiple sclerosis (according to the 2010 revised McDonald criteria  ) with a relapsing–remitting course or a secondary progressive course with disease activity (according to the criteria of Lublin et al.  ); an Expanded Disability Status Scale (EDSS) score of 0 to 5.5 (scores range from 0 to 10.0, with higher scores indicating greater disability  ); at least one relapse in the year before screening, at least two relapses in the 2 years before screening, or at least one lesion detected with the use of gadolinium enhancement (gadolinium-enhancing lesion) on magnetic resonance imaging (MRI) in the year before randomization; and a neurologically stable condition for at least 1 month before randomization.\n\n【17】Trial Design\n------------\n\n【18】ASCLEPIOS I and II were randomized, double-blind, double-dummy, active-controlled, multicenter trials of identical design that were conducted concurrently. Patients, centers, and investigators could participate in only one of the trials. The trials featured a blinded sample-size reestimation to adjust the sample size and trial duration on the basis of a predefined overall minimum event rate. Each trial was powered for the primary end point (annualized relapse rate); the combined trials provided the required sample size and power for the preplanned meta-analysis of disability worsening confirmed at 3 months or 6 months. Eligible patients were randomly assigned in a  ratio through interactive response technology to receive ofatumumab at a dose of 20 mg subcutaneously every 4 weeks after 20-mg loading doses at days 1, 7, and 14 or oral teriflunomide at a dose of 14 mg once daily, for up to 30 months. Patients in the ofatumumab group also received oral placebo and patients in the teriflunomide group also received subcutaneous placebo corresponding to the active drug in the other group. Patients received their first subcutaneous injection at the trial site, which was administered by a health care provider (investigator, trial nurse, or trial coordinator). On days 7 and 14 and at month 1, patients returned to the site to administer the injection themselves under the supervision of trial staff, who provided training on the correct method. The patient’s ability to administer the injection had to be demonstrated and documented before administration at home after month 1 was permitted. Randomization was stratified according to geographic region and subtype of multiple sclerosis. (For more on trial design, see the Additional Methodology Details section in the Supplementary Appendix .)\n\n【19】End Points\n----------\n\n【20】The primary end point was the annualized relapse rate up to the end of the trial. The annualized relapse rate was defined as the number of confirmed relapses of multiple sclerosis per year, according to prespecified criteria. Secondary clinical end points were disability worsening confirmed at 3 months, disability worsening confirmed at 6 months, and disability improvement (i.e., lessening of disability) confirmed at 6 months; a prespecified meta-analysis of these end points used the combined data from both trials. Secondary MRI end points included the number of gadolinium-enhancing lesions per T1-weighted MRI scan, the number of new or enlarging lesions on T2-weighted MRI per year, and the annual rate of brain-volume loss . A secondary biomarker end point was the serum neurofilament light chain concentration at month 3 and beyond, analyzed centrally by Navigate BioPharma using single-molecule-array immunoassay technology. Exploratory secondary end points included the relationship between neurofilament light chain concentration at baseline and the formation of new or enlarging lesions on T2-weighted MRI or brain-volume loss. Adverse events were recorded at all visits and graded according to the Common Terminology Criteria for Adverse Events (CTCAE).  (For more on trial end points, see the Additional Methodology Details section and Safety section in the Supplementary Appendix .)\n\n【21】Statistical Analysis\n--------------------\n\n【22】We calculated that a sample size of 900 patients per trial would provide greater than 90% power in each trial to detect a 40% lower annualized relapse rate with ofatumumab than with teriflunomide. In the combined data from both trials, a sample of 900 patients per trial (i.e. a total of 1800 patients) would provide 90% power and 80% power to detect a 38.6% lower risk of disability worsening confirmed at 3 months and at 6 months, respectively, with ofatumumab than with teriflunomide. Sample size could be increased to a maximum of 1250 patients per trial, and the end of the trials was declared on the basis of a statistical projection when sufficient events had accumulated to power the analysis for the primary end point and the two end points of disability worsening. \n\n【23】Efficacy analyses were carried out according to the intention-to-treat principle. Data on the annualized relapse rate were analyzed with the use of a negative binomial-regression model, with an offset for time spent in the trial in years to adjust for varying treatment durations among patients. The type I error was controlled by a statistical testing procedure, with seven prespecified secondary end points tested; disability worsening confirmed at 3 months or 6 months and disability improvement confirmed at 6 months were tested in preplanned meta-analyses of the combined trials only if the primary null hypothesis for the annualized relapse rate was rejected in both trials independently. Other secondary end points were tested in hierarchical sequential order in each trial (number of gadolinium-enhancing lesions per T1-weighted MRI scan, annualized rate of new or enlarging lesions on T2-weighted MRI, serum neurofilament light chain concentration, and annual rate of brain-volume loss) as long as all preceding null hypotheses could be rejected .\n\n【24】Data from disability-related end points were analyzed with the use of a Cox proportional-hazards model, stratified according to trial. Numbers of gadolinium-enhancing lesions on T1-weighted MRI and new or enlarging lesions on T2-weighted MRI were assessed with the use of negative binomial-regression models; for analysis of data on gadolinium-enhancing lesions on T1-weighted MRI, the number of available MRI scans was used as an offset; for lesions on T2-weighted MRI, the time between the last available scan and baseline scan was used as an offset.\n\n【25】Data on serum neurofilament light chain concentration were analyzed with the use of a repeated-measures model after log transformation of the data; the treatment effect is reported as a percentage reduction in neurofilament light chain concentration on the basis of the ratio of geometric means (relative reduction in geometric means with ofatumumab vs. teriflunomide). The annual rate of brain-volume loss was estimated as the marginal slope estimate from a random-coefficient model with random intercept and slope on the basis of assessments of the percentage change from baseline in brain volume performed at month 12, month 24, and at the end of the trial. The primary end point and key secondary end points used analysis methods that handle missing data under missing-at-random assumptions. Empirical evidence for data missing at random is presented in Table S2 and Figures S2 and S3, together with sensitivity analyses under missing-not-at-random assumptions for the primary and key secondary disability-related end points .\n\n【26】The safety population included all the patients who received trial drugs. Safety data were collected during the treatment period (screening to end of trial) and the safety follow-up period until a patient’s last visit. After the last dose of trial drug, patients were followed for at least 9 months. Adverse events that occurred during the treatment period were reported from the first dose and up to 100 days (approximately 5 times the half-life of ofatumumab) after permanent trial-drug discontinuation, and all serious adverse events that were reported up to the last visit by the last patient were analyzed. Safety end points are reported for the individual and combined trials.\n\n【27】Results\n-------\n\n【28】Patients\n--------\n\n【29】Table 1. Demographic and Disease Characteristics of the Patients at Baseline (Full Analysis Set).\n\n【30】From October 2016 through March 2018, a total of 1882 patients were enrolled at 385 sites in 37 countries: 927 in ASCLEPIOS I (465 assigned to ofatumumab and 462 to teriflunomide) and 955 in ASCLEPIOS II (481 assigned to ofatumumab and 474 to teriflunomide). The median time in trial was 1.6 years (1.5 years in ASCLEPIOS I and 1.6 years in ASCLEPIOS II). More than 30% of the patients had a time in trial longer than 2 years . Individual times in trial and times to trial-drug discontinuation and trial discontinuation are presented in Figures S2 and S3. The demographic and disease characteristics of the patients at baseline were similar in the two trials and in the treatment groups . In ASCLEPIOS I, the trial was completed by 89.5% of the patients in the ofatumumab group and by 81.4% of those in the teriflunomide group. In ASCLEPIOS II, the corresponding percentages were 82.5% and 82.1%. Screening, randomization, and follow-up are summarized in Figure S4.\n\n【31】Efficacy\n--------\n\n【32】### _Primary End Point_\n\n【33】Table 2. Clinical, MRI, and Biomarker End Points (Full Analysis Set).\n\n【34】In ASCLEPIOS I, the adjusted annualized relapse rate was 0.11 with ofatumumab and 0.22 with teriflunomide (difference, −0.11; 95% confidence interval \\[CI\\], −0.16 to −0.06; P<0.001). The corresponding rates in ASCLEPIOS II were 0.10 and 0.25 (difference, −0.15; 95% CI, −0.20 to −0.09; P<0.001) .\n\n【35】### _Disability-Related End Points_\n\n【36】Figure 1. Confirmed Disability Worsening and Improvement.\n\n【37】Shown are Kaplan–Meier estimates of the percentages of patients with disability worsening confirmed at 3 months  and at 6 months  and of patients with disability improvement (i.e., lessening of disability) confirmed at 6 months  in time-to-event analyses in the combined trial populations. Disability worsening confirmed at 3 months or 6 months was defined as an increase from baseline in the Expanded Disability Status Scale (EDSS) score (on a scale from 0 to 10.0, with higher scores indicating worse disability) that was sustained for at least 3 or 6 months. For patients with a baseline EDSS score of 0, an increase in the EDSS score of at least 1.5 points was required; for patients with a baseline EDSS score of 1.0 to 5.0, the criterion was an increase of at least 1.0 point; and for patients with a baseline EDSS score of at least 5.5 points, the criterion was an increase of at least 0.5 points. Disability improvement confirmed at 6 months was defined as a decrease from baseline in the EDSS score that was sustained for at least 6 months. For patients with baseline EDSS scores of 2.0 to 6.0 points, a decrease of at least 1.0 point was required; for patients with baseline EDSS scores of 6.5 to 9.0 points, a decrease of at least 0.5 points was required. The numbers shown on the curves represent Kaplan–Meier estimates of the risk of the event at 24 months (marked by the vertical dashed line). The insets show the same data on an expanded y axis.\n\n【38】In the meta-analysis of both trials, the percentage of patients (Kaplan–Meier estimate at month 24) with disability worsening confirmed at 3 months was 10.9% with ofatumumab and 15.0% with teriflunomide (hazard ratio, 0.66; 95% CI, 0.50 to 0.86; P=0.002) . The percentage of patients with disability worsening confirmed at 6 months was 8.1% with ofatumumab and 12.0% with teriflunomide (hazard ratio, 0.68; 95% CI, 0.50 to 0.92; P=0.01) . Corresponding percentages of patients with disability improvement confirmed at 6 months from both trials were 11.0% with ofatumumab and 8.1% with teriflunomide (hazard ratio, 1.35; 95% CI, 0.95 to 1.92; P=0.09) . The effect of ofatumumab on confirmed disability worsening was consistent across the two trials, as was the absence of a significant between-group difference in confirmed disability improvement .\n\n【39】### _MRI-Related End Points_\n\n【40】In ASCLEPIOS I, the mean number of gadolinium-enhancing lesions per T1-weighted MRI scan was 0.01 with ofatumumab and 0.45 with teriflunomide (97% lower number of lesions with ofatumumab, P<0.001); in ASCLEPIOS II, the corresponding numbers were 0.03 and 0.51, respectively (94% lower with ofatumumab, P<0.001) . In ASCLEPIOS I, the mean number of new or enlarging lesions per year on T2-weighted MRI was 0.72 with ofatumumab and 4.00 with teriflunomide (82% lower number of lesions with ofatumumab, P<0.001); corresponding values in ASCLEPIOS II were 0.64 and 4.15, respectively (85% lower with ofatumumab, P<0.001) . The annual rate of brain-volume loss did not differ significantly between the ofatumumab group and the teriflunomide group (−0.28% with ofatumumab and −0.35% with teriflunomide in ASCLEPIOS I and −0.29% with ofatumumab and −0.35% with teriflunomide in ASCLEPIOS II) .\n\n【41】### _Serum Neurofilament Light Chain Concentration_\n\n【42】In ASCLEPIOS I, the serum neurofilament light chain concentration was lower in the ofatumumab group than in the teriflunomide group by 7% at month 3 (P=0.01), by 27% at month 12, and by 23% at month 24. Corresponding differences in ASCLEPIOS II were 11% (P<0.001), 26%, and 24% . Adjusted annualized mean rates of new or enlarging lesions on T2-weighted MRI according to quartiles of neurofilament light chain concentration at baseline are presented in Table S6 and Figure S7.\n\n【43】Safety\n------\n\n【44】### _Adverse Events_\n\n【45】Table 3. Adverse Events (Safety Population).\n\n【46】Adverse events up to 100 days after the last administration of a trial drug, serious adverse events up to the last visit by the last patient, adverse events leading to treatment discontinuation, and deaths are summarized in Table 3 . In the combined analyses, 791 of 946 patients (83.6%) in the ofatumumab group reported an adverse event, as compared with 788 of 936 patients (84.2%) in the teriflunomide group. Adverse events that occurred in at least 10% of the patients treated with ofatumumab were injection-related reactions, nasopharyngitis, headache, injection-site reaction, upper respiratory tract infection, and urinary tract infection; events that occurred in at least 10% of those treated with teriflunomide were nasopharyngitis, injection-related reactions, alopecia, upper respiratory tract infection, headache, and diarrhea . Serious adverse events were reported in 9.1% of the patients treated with ofatumumab and 7.9% of those treated with teriflunomide. One death occurred in the teriflunomide group (aortic dissection) during the post-treatment follow-up period.\n\n【47】### _Infections_\n\n【48】Infections and infestations were reported in 488 patients (51.6%) who received ofatumumab and 493 (52.7%) who received teriflunomide. Infections reported in 10% or more of the patients in either group across both trials were nasopharyngitis (18.0% with ofatumumab and 16.7% with teriflunomide), upper respiratory tract infection (10.3% and 12.8%, respectively), and urinary tract infection (10.3% and 8.3%, respectively). The percentage of patients who reported a serious infection was 2.5% with ofatumumab and 1.8% with teriflunomide. The percentage of patients who reported a herpesvirus-associated infection was 4.9% in the ofatumumab group and 4.2% in the teriflunomide group. All herpesvirus-associated infections were mild (CTCAE grade 1) or moderate (grade 2), resolved while patients continued therapy, and did not lead to treatment discontinuation. Bronchitis was reported in 2.5% of the patients treated with ofatumumab and in 3.5% of those treated with teriflunomide; corresponding percentages for pneumonia were 0.3% and 0.7%, respectively. Appendicitis was reported in 8 patients who received ofatumumab and in 2 who received teriflunomide. No opportunistic infections were reported .\n\n【49】### _Injection-Related Reactions_\n\n【50】At least one injection-related systemic reaction, defined as systemic reactions occurring within 24 hours after injection , was reported in 20.2% of the patients who received ofatumumab and in 15.0% of those given placebo injections in the teriflunomide group (for details on injection-related premedication, see Tables S8 and S9). Injection-site reactions occurred in 10.9% and 5.6% of patients who received ofatumumab or placebo injections, respectively. Most injection-related systemic reactions (e.g., headache, flushing, and “other”) occurred at the first injection (14.4% and 7.5% among the patients who received ofatumumab or placebo-dummy injections, respectively) , were mild or moderate (grades 1 or 2), and were managed without treatment. Two severe (grade 3) injection-related systemic reactions were reported in the ofatumumab group (0.2%), one of which led to drug discontinuation after the first injection (0.1%). No life-threatening or anaphylactoid injection-related reactions (grade 4) were reported. After the fourth injection, 74.4% of patients administered ofatumumab at home.\n\n【51】### _Other Safety Findings_\n\n【52】Five neoplasms (0.5%) occurred in the ofatumumab group (two cases of basal-cell carcinoma and one case each of malignant melanoma in situ, recurrent non-Hodgkin’s lymphoma, and invasive breast carcinoma) and four (0.4%) in the teriflunomide group (two cases of basal-cell carcinoma and one case each of cervix carcinoma and fibrosarcoma) . Findings regarding B-cell depletion and antidrug-binding antibodies are reported in Figures S9 through S11.\n\n【53】Discussion\n----------\n\n【54】In these two simultaneously conducted active-controlled trials involving patients with relapsing multiple sclerosis, both ofatumumab and teriflunomide were associated with low relapse rates. The relapse rate was significantly lower with ofatumumab than with teriflunomide in each of the two trials. In a prespecified meta-analysis of both trials, the percentages of patients with disability worsening confirmed at 3 months or 6 months were lower with ofatumumab than with teriflunomide, but the groups did not differ significantly with respect to confirmed disability improvement. The results of these trials do not permit any inferences to be made about the efficacy of ofatumumab as compared with other drugs for multiple sclerosis that are considered to be more potent than teriflunomide.\n\n【55】Ofatumumab was also superior to teriflunomide in suppressing lesion activity on MRI. Lesion counts on MRI in the teriflunomide groups were higher than those previously reported in one phase 3 trial of teriflunomide as compared with placebo,  which suggests a population with more disease activity overall in the ASCLEPIOS trials, differences in the assessment methods used at the MRI analysis centers,  or both. Ofatumumab lowered serum concentrations of neurofilament light chain, a marker of neuroaxonal damage.  However, despite greater reductions in neurofilament light chain concentrations with ofatumumab than with teriflunomide, change in brain volume did not differ significantly between the two treatments. This discrepancy between two markers of tissue damage needs further analysis. Ofatumumab lowered B-cell numbers during the 4-week loading regimen, and the initial B-cell depletion was maintained by monthly injections.\n\n【56】Injection-related reactions were more frequent with ofatumumab than with placebo injections in the teriflunomide group, particularly with the first injection. Premedication was used for the first injection by less than 70% of the patients, with decreasing usage thereafter. The reason for the observed imbalance in appendicitis as an adverse event with ofatumumab is unknown, and no signal for appendicitis has been observed with ofatumumab treatment in phase 2 studies in multiple sclerosis and other autoimmune indications  or with other anti-CD20 therapies in multiple sclerosis. \n\n【57】Ofatumumab was associated with lower annualized relapse rates than teriflunomide and showed benefit with respect to most secondary clinical and MRI end points but not confirmed disability improvement. Ofatumumab was associated with a higher frequency of injection-related systemic reactions, predominantly with the first injection, than was placebo injection. Larger and longer trials are required to determine the long-term effect and risks of ofatumumab as compared with other disease-modifying treatments, including other anti-CD20 monoclonal antibodies.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "(For more on trial end points, see the Additional Methodology Details section and Safety section in the Supplementary Appendix .)", "content": "【0】Ofatumumab versus Teriflunomide in Multiple Sclerosis\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Ofatumumab, a subcutaneous anti-CD20 monoclonal antibody, selectively depletes B cells. Teriflunomide, an oral inhibitor of pyrimidine synthesis, reduces T-cell and B-cell activation. The relative effects of these two drugs in patients with multiple sclerosis are not known.\n\n【3】Methods\n-------\n\n【4】In two double-blind, double-dummy, phase 3 trials, we randomly assigned patients with relapsing multiple sclerosis to receive subcutaneous ofatumumab (20 mg every 4 weeks after 20-mg loading doses at days 1, 7, and 14) or oral teriflunomide (14 mg daily) for up to 30 months. The primary end point was the annualized relapse rate. Secondary end points included disability worsening confirmed at 3 months or 6 months, disability improvement confirmed at 6 months, the number of gadolinium-enhancing lesions per T1-weighted magnetic resonance imaging (MRI) scan, the annualized rate of new or enlarging lesions on T2-weighted MRI, serum neurofilament light chain levels at month 3, and change in brain volume.\n\n【5】Results\n-------\n\n【6】Overall, 946 patients were assigned to receive ofatumumab and 936 to receive teriflunomide; the median follow-up was 1.6 years. The annualized relapse rates in the ofatumumab and teriflunomide groups were 0.11 and 0.22, respectively, in trial 1 (difference, −0.11; 95% confidence interval \\[CI\\], −0.16 to −0.06; P<0.001) and 0.10 and 0.25 in trial 2 (difference, −0.15; 95% CI, −0.20 to −0.09; P<0.001). In the pooled trials, the percentage of patients with disability worsening confirmed at 3 months was 10.9% with ofatumumab and 15.0% with teriflunomide (hazard ratio, 0.66; P=0.002); the percentage with disability worsening confirmed at 6 months was 8.1% and 12.0%, respectively (hazard ratio, 0.68; P=0.01); and the percentage with disability improvement confirmed at 6 months was 11.0% and 8.1% (hazard ratio, 1.35; P=0.09). The number of gadolinium-enhancing lesions per T1-weighted MRI scan, the annualized rate of lesions on T2-weighted MRI, and serum neurofilament light chain levels, but not the change in brain volume, were in the same direction as the primary end point. Injection-related reactions occurred in 20.2% in the ofatumumab group and in 15.0% in the teriflunomide group (placebo injections). Serious infections occurred in 2.5% and 1.8% of the patients in the respective groups.\n\n【7】Conclusions\n-----------\n\n【8】Among patients with multiple sclerosis, ofatumumab was associated with lower annualized relapse rates than teriflunomide. \n\n【9】Introduction\n------------\n\n【10】The pathophysiology of multiple sclerosis involves B cells. Anti-CD20 monoclonal antibodies that induce B-cell depletion, such as rituximab and ocrelizumab, are effective disease-modifying therapies for multiple sclerosis.  Ofatumumab, a fully human antibody that is used to treat chronic leukemia, binds to a region distinct from that of other anti-CD20 antibodies, including the smaller and the larger loop of CD20 receptors.  In experimental models, a high binding affinity and slow off-rate (slow dissociation of the binding between ofatumumab and the CD20 receptor in B cells) result in efficient B-cell lysis, mediated through complement-dependent and, to a lesser extent, antibody-dependent cytotoxicity.  In patients with multiple sclerosis, ofatumumab can be given at lower doses  than those studied in chronic lymphocytic leukemia and rheumatoid arthritis,  and ofatumumab can be administered subcutaneously by the patient after initial doses are given under medical supervision.  Experimental models have shown that there may be more direct access to lymph nodes through the lymphatic system with subcutaneous administration than with intravenous infusion,  but this has not been tested under clinical conditions. On treatment cessation, B-cell repletion and reconstitution of humoral immunity have been reported to occur faster with ofatumumab than with other intravenously administered B-cell–targeted therapies. \n\n【11】Teriflunomide, an oral disease-modifying therapy for relapsing multiple sclerosis, inhibits pyrimidine synthesis, reducing T-cell and B-cell activation.  According to the results of one comparative prospective trial  and a network meta-analysis,  the efficacy of teriflunomide to reduce annualized relapse rates is similar to that of interferons and glatiramer acetate, but according to observational studies  it is probably inferior to other oral and monoclonal antibody treatments for multiple sclerosis. We report the results of two phase 3, randomized, double-blind, double-dummy, active-controlled clinical trials of identical design, which assessed the efficacy and safety of subcutaneous ofatumumab as compared with oral teriflunomide.\n\n【12】Methods\n-------\n\n【13】Trial Oversight\n---------------\n\n【14】The ASCLEPIOS I and II trials were designed by the sponsor (Novartis Pharma) in consultation with the steering committee. The investigators collected data, which were analyzed by the sponsor. The investigators, the sponsor, and the steering committee were unaware of treatment assignments throughout the trials. An independent data monitoring committee reviewed the safety of treatment using regular analyses performed by independent statisticians, who were not involved in the conduct of the trials. The manuscript was drafted with medical writing assistance funded by the sponsor. All the authors, including those employed by Novartis, had full access to the data and were involved in the critical review of all drafts of the manuscript. All the authors vouch for the accuracy and completeness of the data, the accurate reporting of adverse events, and the fidelity of the trials to the protocols . There were confidentiality agreements in place between the authors and the sponsor. Novartis supplied the trial drugs and placebo. The trials were conducted in accordance with the International Conference on Harmonisation guidelines for Good Clinical Practice  and the principles of the Declaration of Helsinki.  The protocol was approved by an institutional review board or ethics committee at each trial site. All the patients or their legal representatives provided written informed consent before commencing trial-related procedures.\n\n【15】Patients\n--------\n\n【16】Eligibility criteria at screening included an age of 18 to 55 years; a diagnosis of multiple sclerosis (according to the 2010 revised McDonald criteria  ) with a relapsing–remitting course or a secondary progressive course with disease activity (according to the criteria of Lublin et al.  ); an Expanded Disability Status Scale (EDSS) score of 0 to 5.5 (scores range from 0 to 10.0, with higher scores indicating greater disability  ); at least one relapse in the year before screening, at least two relapses in the 2 years before screening, or at least one lesion detected with the use of gadolinium enhancement (gadolinium-enhancing lesion) on magnetic resonance imaging (MRI) in the year before randomization; and a neurologically stable condition for at least 1 month before randomization.\n\n【17】Trial Design\n------------\n\n【18】ASCLEPIOS I and II were randomized, double-blind, double-dummy, active-controlled, multicenter trials of identical design that were conducted concurrently. Patients, centers, and investigators could participate in only one of the trials. The trials featured a blinded sample-size reestimation to adjust the sample size and trial duration on the basis of a predefined overall minimum event rate. Each trial was powered for the primary end point (annualized relapse rate); the combined trials provided the required sample size and power for the preplanned meta-analysis of disability worsening confirmed at 3 months or 6 months. Eligible patients were randomly assigned in a  ratio through interactive response technology to receive ofatumumab at a dose of 20 mg subcutaneously every 4 weeks after 20-mg loading doses at days 1, 7, and 14 or oral teriflunomide at a dose of 14 mg once daily, for up to 30 months. Patients in the ofatumumab group also received oral placebo and patients in the teriflunomide group also received subcutaneous placebo corresponding to the active drug in the other group. Patients received their first subcutaneous injection at the trial site, which was administered by a health care provider (investigator, trial nurse, or trial coordinator). On days 7 and 14 and at month 1, patients returned to the site to administer the injection themselves under the supervision of trial staff, who provided training on the correct method. The patient’s ability to administer the injection had to be demonstrated and documented before administration at home after month 1 was permitted. Randomization was stratified according to geographic region and subtype of multiple sclerosis. <mark>(For more on trial design, see the Additional Methodology Details section in the Supplementary Appendix .)</mark>\n\n【19】End Points\n----------\n\n【20】The primary end point was the annualized relapse rate up to the end of the trial. The annualized relapse rate was defined as the number of confirmed relapses of multiple sclerosis per year, according to prespecified criteria. Secondary clinical end points were disability worsening confirmed at 3 months, disability worsening confirmed at 6 months, and disability improvement (i.e., lessening of disability) confirmed at 6 months; a prespecified meta-analysis of these end points used the combined data from both trials. Secondary MRI end points included the number of gadolinium-enhancing lesions per T1-weighted MRI scan, the number of new or enlarging lesions on T2-weighted MRI per year, and the annual rate of brain-volume loss . A secondary biomarker end point was the serum neurofilament light chain concentration at month 3 and beyond, analyzed centrally by Navigate BioPharma using single-molecule-array immunoassay technology. Exploratory secondary end points included the relationship between neurofilament light chain concentration at baseline and the formation of new or enlarging lesions on T2-weighted MRI or brain-volume loss. Adverse events were recorded at all visits and graded according to the Common Terminology Criteria for Adverse Events (CTCAE).  (For more on trial end points, see the Additional Methodology Details section and Safety section in the Supplementary Appendix .)\n\n【21】Statistical Analysis\n--------------------\n\n【22】We calculated that a sample size of 900 patients per trial would provide greater than 90% power in each trial to detect a 40% lower annualized relapse rate with ofatumumab than with teriflunomide. In the combined data from both trials, a sample of 900 patients per trial (i.e. a total of 1800 patients) would provide 90% power and 80% power to detect a 38.6% lower risk of disability worsening confirmed at 3 months and at 6 months, respectively, with ofatumumab than with teriflunomide. Sample size could be increased to a maximum of 1250 patients per trial, and the end of the trials was declared on the basis of a statistical projection when sufficient events had accumulated to power the analysis for the primary end point and the two end points of disability worsening. \n\n【23】Efficacy analyses were carried out according to the intention-to-treat principle. Data on the annualized relapse rate were analyzed with the use of a negative binomial-regression model, with an offset for time spent in the trial in years to adjust for varying treatment durations among patients. The type I error was controlled by a statistical testing procedure, with seven prespecified secondary end points tested; disability worsening confirmed at 3 months or 6 months and disability improvement confirmed at 6 months were tested in preplanned meta-analyses of the combined trials only if the primary null hypothesis for the annualized relapse rate was rejected in both trials independently. Other secondary end points were tested in hierarchical sequential order in each trial (number of gadolinium-enhancing lesions per T1-weighted MRI scan, annualized rate of new or enlarging lesions on T2-weighted MRI, serum neurofilament light chain concentration, and annual rate of brain-volume loss) as long as all preceding null hypotheses could be rejected .\n\n【24】Data from disability-related end points were analyzed with the use of a Cox proportional-hazards model, stratified according to trial. Numbers of gadolinium-enhancing lesions on T1-weighted MRI and new or enlarging lesions on T2-weighted MRI were assessed with the use of negative binomial-regression models; for analysis of data on gadolinium-enhancing lesions on T1-weighted MRI, the number of available MRI scans was used as an offset; for lesions on T2-weighted MRI, the time between the last available scan and baseline scan was used as an offset.\n\n【25】Data on serum neurofilament light chain concentration were analyzed with the use of a repeated-measures model after log transformation of the data; the treatment effect is reported as a percentage reduction in neurofilament light chain concentration on the basis of the ratio of geometric means (relative reduction in geometric means with ofatumumab vs. teriflunomide). The annual rate of brain-volume loss was estimated as the marginal slope estimate from a random-coefficient model with random intercept and slope on the basis of assessments of the percentage change from baseline in brain volume performed at month 12, month 24, and at the end of the trial. The primary end point and key secondary end points used analysis methods that handle missing data under missing-at-random assumptions. Empirical evidence for data missing at random is presented in Table S2 and Figures S2 and S3, together with sensitivity analyses under missing-not-at-random assumptions for the primary and key secondary disability-related end points .\n\n【26】The safety population included all the patients who received trial drugs. Safety data were collected during the treatment period (screening to end of trial) and the safety follow-up period until a patient’s last visit. After the last dose of trial drug, patients were followed for at least 9 months. Adverse events that occurred during the treatment period were reported from the first dose and up to 100 days (approximately 5 times the half-life of ofatumumab) after permanent trial-drug discontinuation, and all serious adverse events that were reported up to the last visit by the last patient were analyzed. Safety end points are reported for the individual and combined trials.\n\n【27】Results\n-------\n\n【28】Patients\n--------\n\n【29】Table 1. Demographic and Disease Characteristics of the Patients at Baseline (Full Analysis Set).\n\n【30】From October 2016 through March 2018, a total of 1882 patients were enrolled at 385 sites in 37 countries: 927 in ASCLEPIOS I (465 assigned to ofatumumab and 462 to teriflunomide) and 955 in ASCLEPIOS II (481 assigned to ofatumumab and 474 to teriflunomide). The median time in trial was 1.6 years (1.5 years in ASCLEPIOS I and 1.6 years in ASCLEPIOS II). More than 30% of the patients had a time in trial longer than 2 years . Individual times in trial and times to trial-drug discontinuation and trial discontinuation are presented in Figures S2 and S3. The demographic and disease characteristics of the patients at baseline were similar in the two trials and in the treatment groups . In ASCLEPIOS I, the trial was completed by 89.5% of the patients in the ofatumumab group and by 81.4% of those in the teriflunomide group. In ASCLEPIOS II, the corresponding percentages were 82.5% and 82.1%. Screening, randomization, and follow-up are summarized in Figure S4.\n\n【31】Efficacy\n--------\n\n【32】### _Primary End Point_\n\n【33】Table 2. Clinical, MRI, and Biomarker End Points (Full Analysis Set).\n\n【34】In ASCLEPIOS I, the adjusted annualized relapse rate was 0.11 with ofatumumab and 0.22 with teriflunomide (difference, −0.11; 95% confidence interval \\[CI\\], −0.16 to −0.06; P<0.001). The corresponding rates in ASCLEPIOS II were 0.10 and 0.25 (difference, −0.15; 95% CI, −0.20 to −0.09; P<0.001) .\n\n【35】### _Disability-Related End Points_\n\n【36】Figure 1. Confirmed Disability Worsening and Improvement.\n\n【37】Shown are Kaplan–Meier estimates of the percentages of patients with disability worsening confirmed at 3 months  and at 6 months  and of patients with disability improvement (i.e., lessening of disability) confirmed at 6 months  in time-to-event analyses in the combined trial populations. Disability worsening confirmed at 3 months or 6 months was defined as an increase from baseline in the Expanded Disability Status Scale (EDSS) score (on a scale from 0 to 10.0, with higher scores indicating worse disability) that was sustained for at least 3 or 6 months. For patients with a baseline EDSS score of 0, an increase in the EDSS score of at least 1.5 points was required; for patients with a baseline EDSS score of 1.0 to 5.0, the criterion was an increase of at least 1.0 point; and for patients with a baseline EDSS score of at least 5.5 points, the criterion was an increase of at least 0.5 points. Disability improvement confirmed at 6 months was defined as a decrease from baseline in the EDSS score that was sustained for at least 6 months. For patients with baseline EDSS scores of 2.0 to 6.0 points, a decrease of at least 1.0 point was required; for patients with baseline EDSS scores of 6.5 to 9.0 points, a decrease of at least 0.5 points was required. The numbers shown on the curves represent Kaplan–Meier estimates of the risk of the event at 24 months (marked by the vertical dashed line). The insets show the same data on an expanded y axis.\n\n【38】In the meta-analysis of both trials, the percentage of patients (Kaplan–Meier estimate at month 24) with disability worsening confirmed at 3 months was 10.9% with ofatumumab and 15.0% with teriflunomide (hazard ratio, 0.66; 95% CI, 0.50 to 0.86; P=0.002) . The percentage of patients with disability worsening confirmed at 6 months was 8.1% with ofatumumab and 12.0% with teriflunomide (hazard ratio, 0.68; 95% CI, 0.50 to 0.92; P=0.01) . Corresponding percentages of patients with disability improvement confirmed at 6 months from both trials were 11.0% with ofatumumab and 8.1% with teriflunomide (hazard ratio, 1.35; 95% CI, 0.95 to 1.92; P=0.09) . The effect of ofatumumab on confirmed disability worsening was consistent across the two trials, as was the absence of a significant between-group difference in confirmed disability improvement .\n\n【39】### _MRI-Related End Points_\n\n【40】In ASCLEPIOS I, the mean number of gadolinium-enhancing lesions per T1-weighted MRI scan was 0.01 with ofatumumab and 0.45 with teriflunomide (97% lower number of lesions with ofatumumab, P<0.001); in ASCLEPIOS II, the corresponding numbers were 0.03 and 0.51, respectively (94% lower with ofatumumab, P<0.001) . In ASCLEPIOS I, the mean number of new or enlarging lesions per year on T2-weighted MRI was 0.72 with ofatumumab and 4.00 with teriflunomide (82% lower number of lesions with ofatumumab, P<0.001); corresponding values in ASCLEPIOS II were 0.64 and 4.15, respectively (85% lower with ofatumumab, P<0.001) . The annual rate of brain-volume loss did not differ significantly between the ofatumumab group and the teriflunomide group (−0.28% with ofatumumab and −0.35% with teriflunomide in ASCLEPIOS I and −0.29% with ofatumumab and −0.35% with teriflunomide in ASCLEPIOS II) .\n\n【41】### _Serum Neurofilament Light Chain Concentration_\n\n【42】In ASCLEPIOS I, the serum neurofilament light chain concentration was lower in the ofatumumab group than in the teriflunomide group by 7% at month 3 (P=0.01), by 27% at month 12, and by 23% at month 24. Corresponding differences in ASCLEPIOS II were 11% (P<0.001), 26%, and 24% . Adjusted annualized mean rates of new or enlarging lesions on T2-weighted MRI according to quartiles of neurofilament light chain concentration at baseline are presented in Table S6 and Figure S7.\n\n【43】Safety\n------\n\n【44】### _Adverse Events_\n\n【45】Table 3. Adverse Events (Safety Population).\n\n【46】Adverse events up to 100 days after the last administration of a trial drug, serious adverse events up to the last visit by the last patient, adverse events leading to treatment discontinuation, and deaths are summarized in Table 3 . In the combined analyses, 791 of 946 patients (83.6%) in the ofatumumab group reported an adverse event, as compared with 788 of 936 patients (84.2%) in the teriflunomide group. Adverse events that occurred in at least 10% of the patients treated with ofatumumab were injection-related reactions, nasopharyngitis, headache, injection-site reaction, upper respiratory tract infection, and urinary tract infection; events that occurred in at least 10% of those treated with teriflunomide were nasopharyngitis, injection-related reactions, alopecia, upper respiratory tract infection, headache, and diarrhea . Serious adverse events were reported in 9.1% of the patients treated with ofatumumab and 7.9% of those treated with teriflunomide. One death occurred in the teriflunomide group (aortic dissection) during the post-treatment follow-up period.\n\n【47】### _Infections_\n\n【48】Infections and infestations were reported in 488 patients (51.6%) who received ofatumumab and 493 (52.7%) who received teriflunomide. Infections reported in 10% or more of the patients in either group across both trials were nasopharyngitis (18.0% with ofatumumab and 16.7% with teriflunomide), upper respiratory tract infection (10.3% and 12.8%, respectively), and urinary tract infection (10.3% and 8.3%, respectively). The percentage of patients who reported a serious infection was 2.5% with ofatumumab and 1.8% with teriflunomide. The percentage of patients who reported a herpesvirus-associated infection was 4.9% in the ofatumumab group and 4.2% in the teriflunomide group. All herpesvirus-associated infections were mild (CTCAE grade 1) or moderate (grade 2), resolved while patients continued therapy, and did not lead to treatment discontinuation. Bronchitis was reported in 2.5% of the patients treated with ofatumumab and in 3.5% of those treated with teriflunomide; corresponding percentages for pneumonia were 0.3% and 0.7%, respectively. Appendicitis was reported in 8 patients who received ofatumumab and in 2 who received teriflunomide. No opportunistic infections were reported .\n\n【49】### _Injection-Related Reactions_\n\n【50】At least one injection-related systemic reaction, defined as systemic reactions occurring within 24 hours after injection , was reported in 20.2% of the patients who received ofatumumab and in 15.0% of those given placebo injections in the teriflunomide group (for details on injection-related premedication, see Tables S8 and S9). Injection-site reactions occurred in 10.9% and 5.6% of patients who received ofatumumab or placebo injections, respectively. Most injection-related systemic reactions (e.g., headache, flushing, and “other”) occurred at the first injection (14.4% and 7.5% among the patients who received ofatumumab or placebo-dummy injections, respectively) , were mild or moderate (grades 1 or 2), and were managed without treatment. Two severe (grade 3) injection-related systemic reactions were reported in the ofatumumab group (0.2%), one of which led to drug discontinuation after the first injection (0.1%). No life-threatening or anaphylactoid injection-related reactions (grade 4) were reported. After the fourth injection, 74.4% of patients administered ofatumumab at home.\n\n【51】### _Other Safety Findings_\n\n【52】Five neoplasms (0.5%) occurred in the ofatumumab group (two cases of basal-cell carcinoma and one case each of malignant melanoma in situ, recurrent non-Hodgkin’s lymphoma, and invasive breast carcinoma) and four (0.4%) in the teriflunomide group (two cases of basal-cell carcinoma and one case each of cervix carcinoma and fibrosarcoma) . Findings regarding B-cell depletion and antidrug-binding antibodies are reported in Figures S9 through S11.\n\n【53】Discussion\n----------\n\n【54】In these two simultaneously conducted active-controlled trials involving patients with relapsing multiple sclerosis, both ofatumumab and teriflunomide were associated with low relapse rates. The relapse rate was significantly lower with ofatumumab than with teriflunomide in each of the two trials. In a prespecified meta-analysis of both trials, the percentages of patients with disability worsening confirmed at 3 months or 6 months were lower with ofatumumab than with teriflunomide, but the groups did not differ significantly with respect to confirmed disability improvement. The results of these trials do not permit any inferences to be made about the efficacy of ofatumumab as compared with other drugs for multiple sclerosis that are considered to be more potent than teriflunomide.\n\n【55】Ofatumumab was also superior to teriflunomide in suppressing lesion activity on MRI. Lesion counts on MRI in the teriflunomide groups were higher than those previously reported in one phase 3 trial of teriflunomide as compared with placebo,  which suggests a population with more disease activity overall in the ASCLEPIOS trials, differences in the assessment methods used at the MRI analysis centers,  or both. Ofatumumab lowered serum concentrations of neurofilament light chain, a marker of neuroaxonal damage.  However, despite greater reductions in neurofilament light chain concentrations with ofatumumab than with teriflunomide, change in brain volume did not differ significantly between the two treatments. This discrepancy between two markers of tissue damage needs further analysis. Ofatumumab lowered B-cell numbers during the 4-week loading regimen, and the initial B-cell depletion was maintained by monthly injections.\n\n【56】Injection-related reactions were more frequent with ofatumumab than with placebo injections in the teriflunomide group, particularly with the first injection. Premedication was used for the first injection by less than 70% of the patients, with decreasing usage thereafter. The reason for the observed imbalance in appendicitis as an adverse event with ofatumumab is unknown, and no signal for appendicitis has been observed with ofatumumab treatment in phase 2 studies in multiple sclerosis and other autoimmune indications  or with other anti-CD20 therapies in multiple sclerosis. \n\n【57】Ofatumumab was associated with lower annualized relapse rates than teriflunomide and showed benefit with respect to most secondary clinical and MRI end points but not confirmed disability improvement. Ofatumumab was associated with a higher frequency of injection-related systemic reactions, predominantly with the first injection, than was placebo injection. Larger and longer trials are required to determine the long-term effect and risks of ofatumumab as compared with other disease-modifying treatments, including other anti-CD20 monoclonal antibodies.", "index": 10287, "show": true, "start": 10274, "end": 10403, "province": ["文本干净度", "无关文本"], "isEdit": false}]}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-14 00:23:36", "grab_time": "2024-08-13 23:43:37"}
{"id": 2234475, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "49b064ab-e19b-43ed-b526-433024e13c0b", "title": "Medical Progress: Prometheus's Vulture and the Stem-Cell Promise", "text": "【0】Medical Progress: Prometheus's Vulture and the Stem-Cell Promise\nEmbryonic stem cells have been the focus of intense study over the past two decades. Embryonic stem cells originate from undetermined early embryos, with no possible history of differentiation, whereas the provenance of adult stem cells found in mature tissues is far less well understood. The possibility that a population of reserve stem cells, perhaps set aside during gestation, might be coerced into renewed regenerative service later in life holds great promise. This review considers the status of stem-cell research.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 16:41:33", "endTime": "2024/08/13 16:42:38", "cost": 64.302}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 00:42:38", "grab_time": "2024-08-13 00:41:33"}
{"id": 2234474, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "910fce12-fc3a-4eb5-bb03-e5432575900a", "title": "Aerosolized Pentamidine for Prophylaxis against ", "text": "【0】Aerosolized Pentamidine for Prophylaxis against \nAbstract\n--------\n\n【1】Background and Methods.\n-----------------------\n\n【2】_Pneumocystis carinii_ pneumonia (PCP) is the most frequent life-threatening opportunistic infection associated with human immunodeficiency virus (HIV) infection. To assess the possible value of aerosolized-pentamidine prophylaxis in different doses, a controlled clinical trial was begun in 1987 with 408 subjects at 12 treatment centers. The participants were randomly assigned to receive 30 mg of pentamidine every two weeks, 150 mg every two weeks, or 300 mg every four weeks.\n\n【3】Results.\n--------\n\n【4】Eighteen months after randomization, the subjects in the 300-mg arm had had 8 confirmed episodes of PCP while receiving treatment, as compared with 22 in the 30-mg arm (P = 0.0008). The 150-mg arm had intermediate results but ones not significantly different from those of the 300-mg arm. Participants with previous episodes of PCP and CD4-cell counts less than 200 per cubic millimeter were at the highest risk for PCP.\n\n【5】Conclusions.\n------------\n\n【6】Aerosolized pentamidine was effective for prophylaxis against PCP in patients infected with HIV, according to the dose and schedule of administration. It and zidovudine were well tolerated together and had independent prophylactic benefits. \n\n【7】Introduction\n------------\n\n【8】_Pneumocystis carinii_ pneumonia (PCP) is the most frequent life-threatening opportunistic infection leading to the diagnosis of the acquired immunodeficiency syndrome (AIDS), having affected at least 70,000 persons in the United States since 1981.  In patients with human immunodeficiency virus (HIV) infection, PCP is the most frequent cause of death.  In other immunosuppressed patients and patients with AIDS who have Kaposi's sarcoma, prophylaxis with trimethoprim–sulfamethoxazole has been successful in preventing PCP.  <sup><a>4 </a></sup> \n\n【9】In HIV-infected patients, adverse effects of trimethoprim–sulfamethoxazole, parenteral pentamidine, and pyrimethamine—sulfadoxine have limited the long-term administration of these drugs.  In contrast, aerosolized pentamidine can be delivered directly to the alveolar space, where _P. carinii_ infection is usually concentrated.  It has an unusually long tissue half-life in the lung, with low systemic drug levels and toxicity.  <sup><a>9 </a></sup>  Like other prophylactic agents, aerosolized pentamidine is effective in increased dosages for treatment of acute PCP.  <sup><a>12 </a></sup>  <sup><a>14 </a></sup> \n\n【10】When this trial was initiated, aerosolized-pentamidine therapy was becoming a community standard of practice as a result of encouraging early reports from uncontrolled trials. A controlled trial of adequate size and duration was needed to assess the efficacy and safety of this treatment.\n\n【11】Methods\n-------\n\n【12】Study Population\n----------------\n\n【13】The study involved a prospective, randomized, unblinded comparison of three dosages of aerosolized pentamidine over an 18-month period. Randomization was blocked in time with random block sizes and stratified into three groups, according to the participants' history of HIV complications. The three strata included participants with at least one previous episode of PCP (the previous-PCP stratum), those with Kaposi's sarcoma who had never had PCP (the Kaposi's sarcoma stratum), and those with AIDS or AIDS-related complex but no history of PCP or Kaposi's sarcoma (the other-conditions stratum). Participants were excluded if they had had severe asthma, an anaphylactic reaction to pentamidine, or previous prophylaxis with aerosolized pentamidine or if they were currently (within the previous two weeks) using agents wilh known or likely efficacy against _P. carinii_ .\n\n【14】Participants were enrolled at 12 treatment centers in the San Francisco Bay area. Health care providers al these centers enrolled participants by contacting the data center, which provided randomization numbers and assigned one of the following treatment doses: 30 mg of aerosolized pentamidine every two weeks, 150 mg every two weeks, or 300 mg every four weeks. Each stratum had a separate set of sealed cards, with treatments assigned in random blocks of three and six. Informed consent for treatment and follow-up was obtained at the first treatment visit.\n\n【15】Treatment Method\n----------------\n\n【16】Pentamidine isethionate was reconstituted in 6 ml of sterile water and administered for 35 to 40 minutes in a Respirgard II nebulizer (Marquest, Englewood, Colo.), either at a flow rate of 5 to 7 liters per minute from a pressure-compensated flowmeter attached to a 344.5-kPa (50-psi) source of dry gas or at a pressure of 151.6 to 172.2 kPa (22 to 25 psi) from a Bunn BA 400 air compressor (John Bunn, Tonawanda, N.Y.).  Each treatment was supervised by a respiratory therapist, who noted any immediate adverse effects and administered a bronchodilator if needed for severe coughing or bronchospasm.\n\n【17】Each participant was followed from the first treatment, on or about July 1, 1987, until death or December 31, 1988. Six of 408 participants were lost to follow-up but were not considered ineligible for this reason. Participants were questioned at base line and at each visit about concomitant medications, intercurrent illnesses, and symptoms. Status was determined on the basis of information from the participants, their physicians, hospital records, microbiology departments, and county death records.\n\n【18】Definition of Terms\n-------------------\n\n【19】PCP episodes were considered to be occurrences of pneumonitis that were clinically consistent with acute PCP, including those in which the participants may or may not have had histologic confirmation but either responded to autipneinnocystis therapy or died without confirmation of another pulmonary diagnosis. Confirmed PCP episodes were defined as episodes for which there was histologic confirmation of the diagnosis from samples of induced sputum or specimens obtained by bronchoscopy or open-lung biopsy. Cases of pneumonitis in which bronchoscopy was negative were considered not to involve PCP. Deaths due to PCP were defined as deaths that occurred during treatment for acute PCP.\n\n【20】Participants were considered to be \"eligible\" until 60 days after they had discontinued use of the study drug, unless they were found to be taking a prohibited medication at the time of randomization (17 patients), had received previous prophylaxis with aerosolized pentamidine (10), were HIV-negative (1), or either had a PCP episode (12) or died within the first 28 days of the study (2). Patients in whom PCP developed within the first 28 days probably already had the infection at enrollment, For this reason, they were eliminated from all analyses of eligible participants. Six were randomly assigned to the 30-mg dose, four to the 150-mg dose, and two to the 300-mg dose of aerosolized pentamidine. Eight were in the previous-PCP stratum, one in the Kaposi's sarcoma stratum, and three in the other-conditions stratum.\n\n【21】Data Analysis\n-------------\n\n【22】The intention-to-treat analysis included all 408 participants who took the study drug and all end points, whether these occurred while the participants were taking the study medication or not. Although this analysis estimates efficacy conservatively, it protects against possible bias created by the exclusion of ineligible participants and differential withdrawal from the study drug. All the analyses of mortality used the intention-to-treat rule.\n\n【23】Within the total number of participants, data on a subgroup of 366 eligible participants were analyzed. For this analysis, episodes of PCP that occurred more than 60 days after the last treatment were not counted as having occurred during the study and were censored. The analysis of confirmed episodes of PCP included only those for which a histologic diagnosis was secured.\n\n【24】The hypothesis was tested in each pair of doses with a Bonferroni adjustment of the P value, yielding three planned comparisons (30 mg vs. 150 mg, 30 mg vs. 300 mg, and 150 mg vs. 300 mg). Two interim analyses and a final analysis were performed with the method of O'Brien and Fleming, yielding P values of 0.0006, 0.015, and 0.047, respectively.  Thus, the Bonferroni-adjusted P value for the significance of the final comparisons between any pair of doses was 0.016. Measures of significance are reported as unadjusted P values.\n\n【25】Differences between doses were tested with the log-rank statistic of the Kaplan–Meier product-limit estimates with use of the Proc Lifetest of SAS. In addition, the Cox proportional-hazards regression model was performed with BMDP (L2) to estimate the effects of covariates.\n\n【26】Results\n-------\n\n【27】Study Population\n----------------\n\n【28】Table 1. Characteristics of the Participants at Entry into the Study, According to the Randomized Treatment Dose.\n\n【29】Four hundred forty-one persons were randomized. Thirty-three of these were never treated with the study drug (10 in the 30-mg arm, 13 in the 150-mg arm, and 10 in the 300-mg arm) and were not included in any of the analyses. These participants withdrew from the study before their first visit to a treatment center and before consenting to follow-up. Of the 408 study participants treated, 237 were in the previous-PCP stratum, 55 in the Kaposi's sarcoma stratum, and 116 in the other-conditions stratum .\n\n【30】All but three participants were men. Their ages ranged from 20 to 62 years (mean, 37.7). Their HIV-related diagnoses included disseminated infection with _Mycobacterium avium-intrellulare_ , cryptococcal meningitis, central nervous system toxoplasmosis, lymphadenopathy, oral candidiasis, hairy leukoplakia, and herpesvirus infections. These conditions were evenly distributed among the treatment groups . In addition to the 55 participants in the Kaposi's sarcoma stratum, 52 participants in the previous-PCP stratum had Kaposi's sarcoma. The participants with a history of PCP started the study an average of 135 days after the most recent episode (range, 13 to 1011; median, 74). This interval did not differ significantly among the randomized groups.\n\n【31】Although base-line CD4-cell counts were not recorded as part of the protocol, a subsequent review of medical records revealed CD4 counts obtained within one month of entry into the study in 128 participants (35 in the Kaposi's sarcoma stratum and 93 in the other-conditions stratum). The CD4-cell counts for these participants ranged from 8 to 676 per cubic millimeter (mean, 160.8; median, 128) and did not differ significantly among randomized groups.\n\n【32】The most frequent medication taken concomitantly was zidovudine, taken by 214 participants (52 percent) at the start of the study. Another 81 participants (20 percent) started zidovudine therapy during the study. Other medications frequently taken concomitantly or previously were acyclovir (94 participants, 23 percent), clotrimazole (59 participants, 15 percent) and ketoconazole (15 participants, 4 percent). Previous use of drugs for prophylaxis was reported by 61 participants (15 percent); 29 participants (17 receiving concomitant prophylaxis and 10 who had previously received aerosolized pentamidine) were disqualified from analysis.\n\n【33】Study Outcome\n-------------\n\n【34】Table 2. Participants' Outcomes at the Conclusion ot the Study.\n\n【35】The study began July 1, 1987, and ended December 31, 1988. One hundred six participants (26 percent) completed the study without reaching a study end point. The 30-mg dosage arm had the fewest participants completing the study, primarily because there were more PCP events in this arm .\n\n【36】One hundred one episodes of PCP were documented during the study, including 26 that occurred more than 60 days after the discontinuation of treatment. Seventy-eight occurred in the previous-PCP stratum, 8 in the Kaposi's sarcoma stratum, and 15 in the other-conditions stratum. Twenty-five episodes were not histologically confirmed. Sixty-two of the 101 episodes occurred while the participants were involved in the Study (i.e., more than 28 days after the start of treatment and fewer than 60 days after the last administration of aerosolized pentamidine).\n\n【37】One hundred sixty participants died; for 43 of these, death was the first study end point. Nineteen deaths were due to PCP. Sixteen were associated with a first episode of PCP after the start of the study, and three with second or third episodes.\n\n【38】One hundred eighty-six participants were withdrawn from the study bin followed to the end of the trial. Six were lost to follow-up. The most common reasons for discontinuation were noncompliance, other protocol violations, dose increase, and dose decrease . Noncompliance was defined as a treatment gap of more than two months. The duration of aerosolized-pentamidine treatment for all participants ranged from 1 to 536 days (median, 212).\n\n【39】Prevention of PCP\n-----------------\n\n【40】Table 3. PCP Events, According to Dose of Aerosolized Pentamidine and Eligibility Status. Figure 1.  Figure 1. Percentages of 366 Eligible Participants Who Remained Free of Confirmed PCP during Prophylaxis with Aerosolized Pentamidine (Kaplan–Meier Estimates).\n\n【41】P values for the comparisons between dosage arms were as follows: 30 mg vs. 300 mg, 0.0008; 30 mg vs. 150 mg, 0.10; and 150 mg vs. 300 mg, 0.08. Values were obtained with use of the log-rank statistic.Figure 2.  Figure 2. Percentages of 208 Eligible Participants with Previous Episodes of PCP Who Remained Free of Confirmed PCP during Prophylaxis with Aerosolized Pentamidine (Kaplan–Meier Estimates).\n\n【42】P values for the comparisons between dosage arms were as follows: 30 mg vs. 300 mg, 0.002; 30 mg vs. 150 mg, 0.03; 150 mg vs. 300 mg, 0.29. Values were obtained with use of the log-rank statistic.\n\n【43】The 300-mg dosage arm had the fewest PCP episodes, whether analyzed according to the intentionto-treat or the eligible-participant rule . Kaplan–Meier plots of the proportion of participants in the study remaining free of PCP while taking the study drug showed a widening difference in effectiveness when the 30-mg dosage arm was compared wilh the 300-mg arm over time . The comparison of the 30-mg arm with the 300-mg arm by the log-rank statistic showed a statistically significant difference at all levels of the analysis .\n\n【44】Table 4. Estimates of the Relative Hazard of PCP, According to Cox Regression Analysis.\\*\n\n【45】The Cox proportional-hazards regression model estimated the dose response for aerosolized pentamidine with control for base-line covariates . These included study stratum, treatment center, zidovudine use, and time since previous PCP. The 300-mg group had a significantly lower hazard of PCP according to either intention-to-treat or eligible-participant analysis. The same results were obtained in the previous-PCP stratum alone. The 150-mg dose was consistently less effective than the 300-mg dose when both were compared with the 30-mg dose, although the difference was never statistically significant.\n\n【46】Zidovudine use independently reduced the risk of PCP twofold in the Cox model. Increased time since the occurrence of previous PCP also predicted an increased risk independently in the Cox model. Participants starting therapy within three months of an episode had less than half the hazard of PCP of those starting later, suggesting improved efficacy with earlier initiation of prophylaxis. PCP relapses occurred after a median of 240 days in participants starting prophylaxis within three months, as compared with 143 days in those starting later after the previous episode.\n\n【47】Figure 3. Primary Prophylaxis: Relation between Pretreatment CD4 Count and Development of PCP during the Study.\n\n【48】Cell counts, obtained from a review of medical records, were collected within one month of entry into the study in 128 participants in all dosage arms. The horizontal line denotes the CD4 level at which prophylaxis is recommended.\n\n【49】A CD4 count below 200 cells per cubic millimeter was associated with a relative risk of PCP of 2.6 (95 percent confidence interval, 0.62 to 11.2) in participants without previous PCP . PCP developed in 2 of the 39 participants with initial CD4 counts above 200 per cubic millimeter (5.1 percent), as compared with 12 of the 89 participants who had initial CD4 counts under 200 per cubic millimeter (13 percent).\n\n【50】Mortality\n---------\n\n【51】Figure 4. Survival among the 408 Participants (Kaplan–Meier Estimates).\n\n【52】P values for the comparisons between dosage arms were as follows: 30 mg vs. 300 mg, 0.33; 30 mg vs. 150 mg, 0.73; and 150 mg vs. 300 mg, 0.54.\n\n【53】Mortality from all causes did not differ significantly among the three treatment arms . There was little power to detect a dose response for mortality from PCP, since PCP was the cause of only 11.9 percent of all deaths (19 of 160). Forty-one percent of all deaths were caused by opportunistic infections with organisms other than _P. carinii_ . Mortality was higher in the previous-PCP (53 percent) stratum than in the Kaposi's sarcoma (36 percent) or other-conditions (13 percent) stratum. The participants who had never taken zidovudine had a significantly higher mortality (67 percent) than those who had taken this drug (28 percent). The case fatality rate for the first acute episode of PCP after randomization was 15.8 percent (16 of 101 episodes of PCP). There were no significant differences among dosage arms. At autopsy 11 months after stopping the study and 7 months after his last dose of aerosolized pentamidine (received off study), one participant was found to have calcified granulomas in the liver and spleen that contained _P. carinii_ . He had died of a wasting syndrome, and the contribution of the extrapulmonary pneumocystis was not clear.\n\n【54】Adverse Experiences\n-------------------\n\n【55】Table 5. Incidence of Adverse Respiratory Reactions in the Study Participants.\n\n【56】Respiratory therapists reported that serious coughing occurred in 36 percent of participants and wheezing in 11 percent. The previous-PCP stratum reported a significantly higher incidence of cough with the administration of aerosolized pentamidine (43 percent). Wheezing occurred in significantly more participants in the 150-mg and 300-mg dosage arms but did not differ in incidence across strata. Although it occurred commonly, cough interrupted only 0.5 percent of all treatments and required the discontinuation of only 0.3 percent . Fourteen percent of the participants used bronchodilators at least once; the use of these agents was more common in the 150-mg and 300-mg dosage arms.\n\n【57】Twenty-three participants (5.6 percent) discontinued aerosolized-pentamidine treatment because of adverse experiences. In nine (2.2 percent), the adverse experiences were directly associated with treatment. Bronchospasm and cough developed in four, and the following conditions developed in one patient each: dizziness and lightheadedness; upper respiratory symptoms and lip numbness; diaphoresis, unsteadiness, and nausea; gagging; and a rash that recurred on rechallenge. One participant stopped the study medication after a single treatment because of interstitial pneumonitis, the cause of which was unknown, but the condition was noted to have been present before the start of aerosolized-pentamidine therapy. Ten participants withdrew because of concurrent illnesses or infections related to HIV, and four withdrew after pneumothoraxes.\n\n【58】Pneumothorax occurred in 21 participants treated with aerosolized pentamidine. (Two occurred more than four months after the last treatment.) Eight were spontaneous, four caused by invasive procedures, six associated with acute PCP, and three with bacterial pneumonia. There was no difference in frequency of occurrence among treatment arms . No pneumothorax occurred during a treatment. Only two of the participants with pneumothorax had no previous or concomitant PCP; one pneumothorax was precipitated by a transbronchial biopsy.\n\n【59】Discussion\n----------\n\n【60】PCP is the leading cause of death from opportunistic infections in patients with HIV infection. Sixty-three percent of patients with AIDS have PCP as their index diagnosis, and over 80 percent of all patients with AIDS have at least one episode.  Early diagnosis and treatment lower the acute case fatality rate, but death still occurs in 15 to 30 percent of episodes. Recovery from any single episode of PCP does not confer immunity from another bout. By the time second episodes occur, many patients have become intolerant of the short list of drugs with proved efficacy against acute PCP. Pulmonary parenchymal fibrosis is common after PCP, and there is progressive damage to pulmonary function with successive infections. Therefore, successful prophylaxis, primary and secondary, is critical to the prolongation of survival in patients with AIDS. Zidovudine prolongs life after PCP  but does not prevent subsequent episodes. \n\n【61】Trimethoprim–sulfamethoxazole is well tolerated and prevents PCP in children with leukemia.  <sup>, </sup>  Although primary prophylaxis with trimethoprim–sulfamethoxazole and leucovorin was successful in patients with Kaposi's sarcoma as compared with no treatment,  adverse reactions occurred in 50 percent of participants and necessitated the discontinuation of treatment in 13 percent. With previous exposure, patients with AIDS are often intolerant of trimethoprim–sulfamethoxazole, and one placebo-controlled, randomized, double-blind trial was stopped because of the high incidence of such intolerance.  Other medications likely to be effective for PCP prophylaxis include dapsone, pyrimethamine—sulfadoxine (Fansidar), and parenteral pentamidine  <sup><a>21 </a></sup>  ; these are now undergoing evaluation.\n\n【62】The choice of a dose–response design to study prophylaxis with aerosolized pentamidine was suggested by reference to a consecutive series of patients treated with 30 mg every two weeks  as compared with historical controls.  Although there were less than half the expected number of PCP episodes, there were also enough \"breakthrough\" episodes to warrant a study to determine both optimal treatment dosage and interval.\n\n【63】The administration of aerosolized pentamidine in three dosage arms (30 mg every two weeks, 150 mg every two weeks, and 300 mg every four weeks) was compared by the log-rank statistic of the Kaplan–Meier curves and with Cox proportional-hazards regression models. In the Kaplan–Meier analyses of the time to the occurrence of PCP, 300 mg given every four weeks was consistently superior to 30 mg given every two weeks. The 150-mg arm was superior to the 30-mg arm, but less so than the 300-mg arm. The Cox relative hazard of 300 mg as compared with 30 mg for PCP events in eligible participants was 0.26; for 150 mg as compared with 30 mg, the relative hazard was 0.58.\n\n【64】Patients wilh a previous episode of PCP (those receiving secondary prophylaxis) had the highest risk of PCP. The superiority of the 300-mg dose was observed in this stratum alone. A significant dose response was not found for primary prophylaxis in the two other strata, most likely because the small number of events did not provide adequate power. The Cox model for intention to treat estimated the risk of PCP in the primary-prophylaxis strata at 0.26 to 0.33, as compared with the risk in the secondary-prophylaxis stratum. Both epidemiologic studies and our results showed an increased risk for participants receiving primary prophylaxis who have CD4 counts below 200 cells per cubic millimeter. \n\n【65】Although the incidence of pulmonary side effects was high, their severity was low. Only 2.2 percent of the participants withdrew from the study regimen because of respiratory side effects attributed to aerosolized pentamidine. The most frequent adverse experience was cough, reported by 36 percent of the participants at some time during the study. Cough resulted in study discontinuation in only 1 percent, and it required the interruption of treatment in only 0.5 percent of all participants. There were eight participants (2.0 percent) with pneumothoraxes of unknown cause. Although a relation of these events to treatment with aerosolized pentamidine cannot be excluded, they did not occur during treatment, nor was their incidence higher among the participants in the higher-dosage arms.\n\n【66】Despite the low rates of adverse reactions requiring discontinuation, this study did not eliminate the possibility of long-term systemic or pulmonary toxicity of aerosolized pentamidine. Extrapulmonary pneumocystis, which may become more common with prophylactic therapy directed solely at the lungs, was found at autopsy in one participant.\n\n【67】For effective prophylaxis, a patient must be able to tolerate both the prophylactic agent and zidovudine. Many sulfa drugs have adverse hematologic effects that require frequent monitoring and dose reduction of the sulfa drug, the zidovudine, or both. Aerosolized pentamidine, with its low systemic absorption, avoids this problem. Aerosolized pentamidine and zidovudine were well tolerated together in this study. This finding confirms the observation of Girard et al.,  who found benefit from combining aerosolized pentamidine and zidovudine.\n\n【68】Among the participants with a history of PCP, those who started prophylaxis more than three months after the last PCP episode had a relative hazard of 2.3 for a subsequent episode, as compared with those who started prophylaxis earlier. This suggests that patients should begin prophylaxis immediately after the completion of short-term therapy for PCP.\n\n【69】Aerosolized pentamidine is an effective method of prophylaxis for HIV-infected patients at high risk for PCP. Adverse experiences due to the drug are fewer and less severe than those occurring with systemic regimens. Further prospective randomized trials are needed to determine whether higher doses provide more efficacy without additional adverse experiences. Trials comparing aerosolized pentamidine with systemic agents would clarify the relative safety and efficacy of the two routes of administration and the relation of aerosolized pentamidine to extrapulmonary pneumocystosis. The combination of prophylaxis and antiretroviral therapy may prove to prevent most episodes of PCP in patients with HIV infection.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": " 4 ", "content": "【0】Aerosolized Pentamidine for Prophylaxis against \nAbstract\n--------\n\n【1】Background and Methods.\n-----------------------\n\n【2】_Pneumocystis carinii_ pneumonia (PCP) is the most frequent life-threatening opportunistic infection associated with human immunodeficiency virus (HIV) infection. To assess the possible value of aerosolized-pentamidine prophylaxis in different doses, a controlled clinical trial was begun in 1987 with 408 subjects at 12 treatment centers. The participants were randomly assigned to receive 30 mg of pentamidine every two weeks, 150 mg every two weeks, or 300 mg every four weeks.\n\n【3】Results.\n--------\n\n【4】Eighteen months after randomization, the subjects in the 300-mg arm had had 8 confirmed episodes of PCP while receiving treatment, as compared with 22 in the 30-mg arm (P = 0.0008). The 150-mg arm had intermediate results but ones not significantly different from those of the 300-mg arm. Participants with previous episodes of PCP and CD4-cell counts less than 200 per cubic millimeter were at the highest risk for PCP.\n\n【5】Conclusions.\n------------\n\n【6】Aerosolized pentamidine was effective for prophylaxis against PCP in patients infected with HIV, according to the dose and schedule of administration. It and zidovudine were well tolerated together and had independent prophylactic benefits. \n\n【7】Introduction\n------------\n\n【8】_Pneumocystis carinii_ pneumonia (PCP) is the most frequent life-threatening opportunistic infection leading to the diagnosis of the acquired immunodeficiency syndrome (AIDS), having affected at least 70,000 persons in the United States since 1981.  In patients with human immunodeficiency virus (HIV) infection, PCP is the most frequent cause of death.  In other immunosuppressed patients and patients with AIDS who have Kaposi's sarcoma, prophylaxis with trimethoprim–sulfamethoxazole has been successful in preventing PCP.  <sup><a>4 </a></sup> \n\n【9】In HIV-infected patients, adverse effects of trimethoprim–sulfamethoxazole, parenteral pentamidine, and pyrimethamine—sulfadoxine have limited the long-term administration of these drugs.  In contrast, aerosolized pentamidine can be delivered directly to the alveolar space, where _P. carinii_ infection is usually concentrated.  It has an unusually long tissue half-life in the lung, with low systemic drug levels and toxicity.  <sup><a>9 </a></sup>  Like other prophylactic agents, aerosolized pentamidine is effective in increased dosages for treatment of acute PCP.  <sup><a>12 </a></sup>  <sup><a>14 </a></sup> \n\n【10】When this trial was initiated, aerosolized-pentamidine therapy was becoming a community standard of practice as a result of encouraging early reports from uncontrolled trials. A controlled trial of adequate size and duration was needed to assess the efficacy and safety of this treatment.\n\n【11】Methods\n-------\n\n【12】Study Population\n----------------\n\n【13】The study involved a prospective, randomized, unblinded comparison of three dosages of aerosolized pentamidine over an 18-month period. Randomization was blocked in time with random block sizes and stratified into three groups, according to the participants' history of HIV complications. The three strata included participants with at least one previous episode of PCP (the previous-PCP stratum), those with Kaposi's sarcoma who had never had PCP (the Kaposi's sarcoma stratum), and those with AIDS or AIDS-related complex but no history of PCP or Kaposi's sarcoma (the other-conditions stratum). Participants were excluded if they had had severe asthma, an anaphylactic reaction to pentamidine, or previous prophylaxis with aerosolized pentamidine or if they were currently (within the previous two weeks) using agents wilh known or likely efficacy against _P. carinii_ .\n\n【14】Participants were enrolled at 12 treatment centers in the San Francisco Bay area. Health care providers al these centers enrolled participants by contacting the data center, which provided randomization numbers and assigned one of the following treatment doses: 30 mg of aerosolized pentamidine every two weeks, 150 mg every two weeks, or 300 mg every four weeks. Each stratum had a separate set of sealed cards, with treatments assigned in random blocks of three and six. Informed consent for treatment and follow-up was obtained at the first treatment visit.\n\n【15】Treatment Method\n----------------\n\n【16】Pentamidine isethionate was reconstituted in 6 ml of sterile water and administered for 35 to 40 minutes in a Respirgard II nebulizer (Marquest, Englewood, Colo.), either at a flow rate of 5 to 7 liters per minute from a pressure-compensated flowmeter attached to a 344.5-kPa (50-psi) source of dry gas or at a pressure of 151.6 to 172.2 kPa (22 to 25 psi) from a Bunn BA 400 air compressor (John Bunn, Tonawanda, N.Y.).  Each treatment was supervised by a respiratory therapist, who noted any immediate adverse effects and administered a bronchodilator if needed for severe coughing or bronchospasm.\n\n【17】Each participant was followed from the first treatment, on or about July 1, 1987, until death or December 31, 1988. Six of 408 participants were lost to follow-up but were not considered ineligible for this reason. Participants were questioned at base line and at each visit about concomitant medications, intercurrent illnesses, and symptoms. Status was determined on the basis of information from the participants, their physicians, hospital records, microbiology departments, and county death records.\n\n【18】Definition of Terms\n-------------------\n\n【19】PCP episodes were considered to be occurrences of pneumonitis that were clinically consistent with acute PCP, including those in which the participants may or may not have had histologic confirmation but either responded to autipneinnocystis therapy or died without confirmation of another pulmonary diagnosis. Confirmed PCP episodes were defined as episodes for which there was histologic confirmation of the diagnosis from samples of induced sputum or specimens obtained by bronchoscopy or open-lung biopsy. Cases of pneumonitis in which bronchoscopy was negative were considered not to involve PCP. Deaths due to PCP were defined as deaths that occurred during treatment for acute PCP.\n\n【20】Participants were considered to be \"eligible\" until 60 days after they had discontinued use of the study drug, unless they were found to be taking a prohibited medication at the time of randomization (17 patients), had received previous prophylaxis with aerosolized pentamidine (10), were HIV-negative (1), or either had a PCP episode (12) or died within the first 28 days of the study (2). Patients in whom PCP developed within the first 28 days probably already had the infection at enrollment, For this reason, they were eliminated from all analyses of eligible participants. Six were randomly assigned to the 30-mg dose, four to the 150-mg dose, and two to the 300-mg dose of aerosolized pentamidine. Eight were in the previous-PCP stratum, one in the Kaposi's sarcoma stratum, and three in the other-conditions stratum.\n\n【21】Data Analysis\n-------------\n\n【22】The intention-to-treat analysis included all 408 participants who took the study drug and all end points, whether these occurred while the participants were taking the study medication or not. Although this analysis estimates efficacy conservatively, it protects against possible bias created by the exclusion of ineligible participants and differential withdrawal from the study drug. All the analyses of mortality used the intention-to-treat rule.\n\n【23】Within the total number of participants, data on a subgroup of 366 eligible participants were analyzed. For this analysis, episodes of PCP that occurred more than 60 days after the last treatment were not counted as having occurred during the study and were censored. The analysis of confirmed episodes of PCP included only those for which a histologic diagnosis was secured.\n\n【24】The hypothesis was tested in each pair of doses with a Bonferroni adjustment of the P value, yielding three planned comparisons (30 mg vs. 150 mg, 30 mg vs. 300 mg, and 150 mg vs. 300 mg). Two interim analyses and a final analysis were performed with the method of O'Brien and Fleming, yielding P values of 0.0006, 0.015, and 0.047, respectively.  Thus, the Bonferroni-adjusted P value for the significance of the final comparisons between any pair of doses was 0.016. Measures of significance are reported as unadjusted P values.\n\n【25】Differences between doses were tested with the log-rank statistic of the Kaplan–Meier product-limit estimates with use of the Proc Lifetest of SAS. In addition, the Cox proportional-hazards regression model was performed with BMDP (L2) to estimate the effects of covariates.\n\n【26】Results\n-------\n\n【27】Study Population\n----------------\n\n【28】Table 1. Characteristics of the Participants at Entry into the Study, According to the Randomized Treatment Dose.\n\n【29】Four hundred forty-one persons were randomized. Thirty-three of these were never treated with the study drug (10 in the 30-mg arm, 13 in the 150-mg arm, and 10 in the 300-mg arm) and were not included in any of the analyses. These participants withdrew from the study before their first visit to a treatment center and before consenting to follow-up. Of the 408 study participants treated, 237 were in the previous-PCP stratum, 55 in the Kaposi's sarcoma stratum, and 116 in the other-conditions stratum .\n\n【30】All but three participants were men. Their ages ranged from 20 to 62 years (mean, 37.7). Their HIV-related diagnoses included disseminated infection with _Mycobacterium avium-intrellulare_ , cryptococcal meningitis, central nervous system toxoplasmosis, lymphadenopathy, oral candidiasis, hairy leukoplakia, and herpesvirus infections. These conditions were evenly distributed among the treatment groups . In addition to the 55 participants in the Kaposi's sarcoma stratum, 52 participants in the previous-PCP stratum had Kaposi's sarcoma. The participants with a history of PCP started the study an average of 135 days after the most recent episode (range, 13 to 1011; median, 74). This interval did not differ significantly among the randomized groups.\n\n【31】Although base-line CD4-cell counts were not recorded as part of the protocol, a subsequent review of medical records revealed CD4 counts obtained within one month of entry into the study in 128 participants (35 in the Kaposi's sarcoma stratum and 93 in the other-conditions stratum). The CD4-cell counts for these participants ranged from 8 to 676 per cubic millimeter (mean, 160.8; median, 128) and did not differ significantly among randomized groups.\n\n【32】The most frequent medication taken concomitantly was zidovudine, taken by 214 participants (52 percent) at the start of the study. Another 81 participants (20 percent) started zidovudine therapy during the study. Other medications frequently taken concomitantly or previously were acyclovir (94 participants, 23 percent), clotrimazole (59 participants, 15 percent) and ketoconazole (15 participants, 4 percent). Previous use of drugs for prophylaxis was reported by 61 participants (15 percent); 29 participants (17 receiving concomitant prophylaxis and 10 who had previously received aerosolized pentamidine) were disqualified from analysis.\n\n【33】Study Outcome\n-------------\n\n【34】Table 2. Participants' Outcomes at the Conclusion ot the Study.\n\n【35】The study began July 1, 1987, and ended December 31, 1988. One hundred six participants (26 percent) completed the study without reaching a study end point. The 30-mg dosage arm had the fewest participants completing the study, primarily because there were more PCP events in this arm .\n\n【36】One hundred one episodes of PCP were documented during the study, including 26 that occurred more than 60 days after the discontinuation of treatment. Seventy-eight occurred in the previous-PCP stratum, 8 in the Kaposi's sarcoma stratum, and 15 in the other-conditions stratum. Twenty-five episodes were not histologically confirmed. Sixty-two of the 101 episodes occurred while the participants were involved in the Study (i.e., more than 28 days after the start of treatment and fewer than 60 days after the last administration of aerosolized pentamidine).\n\n【37】One hundred sixty participants died; for 43 of these, death was the first study end point. Nineteen deaths were due to PCP. Sixteen were associated with a first episode of PCP after the start of the study, and three with second or third episodes.\n\n【38】One hundred eighty-six participants were withdrawn from the study bin followed to the end of the trial. Six were lost to follow-up. The most common reasons for discontinuation were noncompliance, other protocol violations, dose increase, and dose decrease . Noncompliance was defined as a treatment gap of more than two months. The duration of aerosolized-pentamidine treatment for all participants ranged from 1 to 536 days (median, 212).\n\n【39】Prevention of PCP\n-----------------\n\n【40】Table 3. PCP Events, According to Dose of Aerosolized Pentamidine and Eligibility Status. Figure 1.  Figure 1. Percentages of 366 Eligible Participants Who Remained Free of Confirmed PCP during Prophylaxis with Aerosolized Pentamidine (Kaplan–Meier Estimates).\n\n【41】P values for the comparisons between dosage arms were as follows: 30 mg vs. 300 mg, 0.0008; 30 mg vs. 150 mg, 0.10; and 150 mg vs. 300 mg, 0.08. Values were obtained with use of the log-rank statistic.Figure 2.  Figure 2. Percentages of 208 Eligible Participants with Previous Episodes of PCP Who Remained Free of Confirmed PCP during Prophylaxis with Aerosolized Pentamidine (Kaplan–Meier Estimates).\n\n【42】P values for the comparisons between dosage arms were as follows: 30 mg vs. 300 mg, 0.002; 30 mg vs. 150 mg, 0.03; 150 mg vs. 300 mg, 0.29. Values were obtained with use of the log-rank statistic.\n\n【43】The 300-mg dosage arm had the fewest PCP episodes, whether analyzed according to the intentionto-treat or the eligible-participant rule . Kaplan–Meier plots of the proportion of participants in the study remaining free of PCP while taking the study drug showed a widening difference in effectiveness when the 30-mg dosage arm was compared wilh the 300-mg arm over time . The comparison of the 30-mg arm with the 300-mg arm by the log-rank statistic showed a statistically significant difference at all levels of the analysis .\n\n【44】Table 4. Estimates of the Relative Hazard of PCP, According to Cox Regression Analysis.\\*\n\n【45】The Cox proportional-hazards regression model estimated the dose response for aerosolized pentamidine with control for base-line covariates . These included study stratum, treatment center, zidovudine use, and time since previous PCP. The 300-mg group had a significantly lower hazard of PCP according to either intention-to-treat or eligible-participant analysis. The same results were obtained in the previous-PCP stratum alone. The 150-mg dose was consistently less effective than the 300-mg dose when both were compared with the 30-mg dose, although the difference was never statistically significant.\n\n【46】Zidovudine use independently reduced the risk of PCP twofold in the Cox model. Increased time since the occurrence of previous PCP also predicted an increased risk independently in the Cox model. Participants starting therapy within three months of an episode had less than half the hazard of PCP of those starting later, suggesting improved efficacy with earlier initiation of prophylaxis. PCP relapses occurred after a median of 240 days in participants starting prophylaxis within three months, as compared with 143 days in those starting later after the previous episode.\n\n【47】Figure 3. Primary Prophylaxis: Relation between Pretreatment CD4 Count and Development of PCP during the Study.\n\n【48】Cell counts, obtained from a review of medical records, were collected within one month of entry into the study in 128 participants in all dosage arms. The horizontal line denotes the CD4 level at which prophylaxis is recommended.\n\n【49】A CD4 count below 200 cells per cubic millimeter was associated with a relative risk of PCP of 2.6 (95 percent confidence interval, 0.62 to 11.2) in participants without previous PCP . PCP developed in 2 of the 39 participants with initial CD4 counts above 200 per cubic millimeter (5.1 percent), as compared with 12 of the 89 participants who had initial CD4 counts under 200 per cubic millimeter (13 percent).\n\n【50】Mortality\n---------\n\n【51】Figure 4. Survival among the 408 Participants (Kaplan–Meier Estimates).\n\n【52】P values for the comparisons between dosage arms were as follows: 30 mg vs. 300 mg, 0.33; 30 mg vs. 150 mg, 0.73; and 150 mg vs. 300 mg, 0.54.\n\n【53】Mortality from all causes did not differ significantly among the three treatment arms . There was little power to detect a dose response for mortality from PCP, since PCP was the cause of only 11.9 percent of all deaths (19 of 160). Forty-one percent of all deaths were caused by opportunistic infections with organisms other than _P. carinii_ . Mortality was higher in the previous-PCP (53 percent) stratum than in the Kaposi's sarcoma (36 percent) or other-conditions (13 percent) stratum. The participants who had never taken zidovudine had a significantly higher mortality (67 percent) than those who had taken this drug (28 percent). The case fatality rate for the first acute episode of PCP after randomization was 15.8 percent (16 of 101 episodes of PCP). There were no significant differences among dosage arms. At autopsy 11 months after stopping the study and 7 months after his last dose of aerosolized pentamidine (received off study), one participant was found to have calcified granulomas in the liver and spleen that contained _P. carinii_ . He had died of a wasting syndrome, and the contribution of the extrapulmonary pneumocystis was not clear.\n\n【54】Adverse Experiences\n-------------------\n\n【55】Table 5. Incidence of Adverse Respiratory Reactions in the Study Participants.\n\n【56】Respiratory therapists reported that serious coughing occurred in 36 percent of participants and wheezing in 11 percent. The previous-PCP stratum reported a significantly higher incidence of cough with the administration of aerosolized pentamidine (43 percent). Wheezing occurred in significantly more participants in the 150-mg and 300-mg dosage arms but did not differ in incidence across strata. Although it occurred commonly, cough interrupted only 0.5 percent of all treatments and required the discontinuation of only 0.3 percent . Fourteen percent of the participants used bronchodilators at least once; the use of these agents was more common in the 150-mg and 300-mg dosage arms.\n\n【57】Twenty-three participants (5.6 percent) discontinued aerosolized-pentamidine treatment because of adverse experiences. In nine (2.2 percent), the adverse experiences were directly associated with treatment. Bronchospasm and cough developed in four, and the following conditions developed in one patient each: dizziness and lightheadedness; upper respiratory symptoms and lip numbness; diaphoresis, unsteadiness, and nausea; gagging; and a rash that recurred on rechallenge. One participant stopped the study medication after a single treatment because of interstitial pneumonitis, the cause of which was unknown, but the condition was noted to have been present before the start of aerosolized-pentamidine therapy. Ten participants withdrew because of concurrent illnesses or infections related to HIV, and four withdrew after pneumothoraxes.\n\n【58】Pneumothorax occurred in 21 participants treated with aerosolized pentamidine. (Two occurred more than four months after the last treatment.) Eight were spontaneous, four caused by invasive procedures, six associated with acute PCP, and three with bacterial pneumonia. There was no difference in frequency of occurrence among treatment arms . No pneumothorax occurred during a treatment. Only two of the participants with pneumothorax had no previous or concomitant PCP; one pneumothorax was precipitated by a transbronchial biopsy.\n\n【59】Discussion\n----------\n\n【60】PCP is the leading cause of death from opportunistic infections in patients with HIV infection. Sixty-three percent of patients with AIDS have PCP as their index diagnosis, and over 80 percent of all patients with AIDS have at least one episode.  Early diagnosis and treatment lower the acute case fatality rate, but death still occurs in 15 to 30 percent of episodes. Recovery from any single episode of PCP does not confer immunity from another bout. By the time second episodes occur, many patients have become intolerant of the short list of drugs with proved efficacy against acute PCP. Pulmonary parenchymal fibrosis is common after PCP, and there is progressive damage to pulmonary function with successive infections. Therefore, successful prophylaxis, primary and secondary, is critical to the prolongation of survival in patients with AIDS. Zidovudine prolongs life after PCP  but does not prevent subsequent episodes. \n\n【61】Trimethoprim–sulfamethoxazole is well tolerated and prevents PCP in children with leukemia.  <sup>, </sup>  Although primary prophylaxis with trimethoprim–sulfamethoxazole and leucovorin was successful in patients with Kaposi's sarcoma as compared with no treatment,  adverse reactions occurred in 50 percent of participants and necessitated the discontinuation of treatment in 13 percent. With previous exposure, patients with AIDS are often intolerant of trimethoprim–sulfamethoxazole, and one placebo-controlled, randomized, double-blind trial was stopped because of the high incidence of such intolerance.  Other medications likely to be effective for PCP prophylaxis include dapsone, pyrimethamine—sulfadoxine (Fansidar), and parenteral pentamidine  <sup><a>21 </a></sup>  ; these are now undergoing evaluation.\n\n【62】The choice of a dose–response design to study prophylaxis with aerosolized pentamidine was suggested by reference to a consecutive series of patients treated with 30 mg every two weeks  as compared with historical controls.  Although there were less than half the expected number of PCP episodes, there were also enough \"breakthrough\" episodes to warrant a study to determine both optimal treatment dosage and interval.\n\n【63】The administration of aerosolized pentamidine in three dosage arms (30 mg every two weeks, 150 mg every two weeks, and 300 mg every four weeks) was compared by the log-rank statistic of the Kaplan–Meier curves and with Cox proportional-hazards regression models. In the Kaplan–Meier analyses of the time to the occurrence of PCP, 300 mg given every four weeks was consistently superior to 30 mg given every two weeks. The 150-mg arm was superior to the 30-mg arm, but less so than the 300-mg arm. The Cox relative hazard of 300 mg as compared with 30 mg for PCP events in eligible participants was 0.26; for 150 mg as compared with 30 mg, the relative hazard was 0.58.\n\n【64】Patients wilh a previous episode of PCP (those receiving secondary prophylaxis) had the highest risk of PCP. The superiority of the 300-mg dose was observed in this stratum alone. A significant dose response was not found for primary prophylaxis in the two other strata, most likely because the small number of events did not provide adequate power. The Cox model for intention to treat estimated the risk of PCP in the primary-prophylaxis strata at 0.26 to 0.33, as compared with the risk in the secondary-prophylaxis stratum. Both epidemiologic studies and our results showed an increased risk for participants receiving primary prophylaxis who have CD4 counts below 200 cells per cubic millimeter. \n\n【65】Although the incidence of pulmonary side effects was high, their severity was low. Only 2.2 percent of the participants withdrew from the study regimen because of respiratory side effects attributed to aerosolized pentamidine. The most frequent adverse experience was cough, reported by 36 percent of the participants at some time during the study. Cough resulted in study discontinuation in only 1 percent, and it required the interruption of treatment in only 0.5 percent of all participants. There were eight participants (2.0 percent) with pneumothoraxes of unknown cause. Although a relation of these events to treatment with aerosolized pentamidine cannot be excluded, they did not occur during treatment, nor was their incidence higher among the participants in the higher-dosage arms.\n\n【66】Despite the low rates of adverse reactions requiring discontinuation, this study did not eliminate the possibility of long-term systemic or pulmonary toxicity of aerosolized pentamidine. Extrapulmonary pneumocystis, which may become more common with prophylactic therapy directed solely at the lungs, was found at autopsy in one participant.\n\n【67】For effective prophylaxis, a patient must be able to tolerate both the prophylactic agent and zidovudine. Many sulfa drugs have adverse hematologic effects that require frequent monitoring and dose reduction of the sulfa drug, the zidovudine, or both. Aerosolized pentamidine, with its low systemic absorption, avoids this problem. Aerosolized pentamidine and zidovudine were well tolerated together in this study. This finding confirms the observation of Girard et al.,  who found benefit from combining aerosolized pentamidine and zidovudine.\n\n【68】Among the participants with a history of PCP, those who started prophylaxis more than three months after the last PCP episode had a relative hazard of 2.3 for a subsequent episode, as compared with those who started prophylaxis earlier. This suggests that patients should begin prophylaxis immediately after the completion of short-term therapy for PCP.\n\n【69】Aerosolized pentamidine is an effective method of prophylaxis for HIV-infected patients at high risk for PCP. Adverse experiences due to the drug are fewer and less severe than those occurring with systemic regimens. Further prospective randomized trials are needed to determine whether higher doses provide more efficacy without additional adverse experiences. Trials comparing aerosolized pentamidine with systemic agents would clarify the relative safety and efficacy of the two routes of administration and the relation of aerosolized pentamidine to extrapulmonary pneumocystosis. The combination of prophylaxis and antiretroviral therapy may prove to prevent most episodes of PCP in patients with HIV infection.", "index": 503, "show": true, "start": 503, "end": 506, "province": ["文本干净度", "页码/数字"], "isEdit": false, "comment": "全文句末的无关数字"}]}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-14 00:19:03", "grab_time": "2024-08-13 23:04:29"}
{"id": 2234473, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "32bf1aa9-a8c8-4d9d-ab62-5075ea87d12a", "title": "Obstructive Sleep Apnea", "text": "【0】Obstructive Sleep Apnea\nA 43-year-old man presents with heavy snoring; his bed partner reports that he sometimes stops breathing while he sleeps. He has hypertension controlled by medication but is otherwise healthy. He admits to feeling sleepy at times when he drives, although he has not had any motor vehicle accidents. His body-mass index is 33, and he has a large neck circumference (46 cm). How should he be evaluated and treated?", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:47:20", "endTime": "2024/08/14 14:47:27", "cost": 6.459}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 22:47:26", "grab_time": "2024-08-13 22:47:19"}
{"id": 2234472, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "16c660a2-c629-487d-8cbf-e2724dafbfcc", "title": "Enrolling Pregnant Women in Research — Lessons from the H1N1 Influenza Pandemic", "text": "【0】Enrolling Pregnant Women in Research — Lessons from the H1N1 Influenza Pandemic\nArticle\n-------\n\n【1】The global H1N1 influenza pandemic disproportionately affected pregnant women, drawing attention to the fact that although they need safe and effective medical treatment, they have always been a marginalized study population. Antiviral agents for treating influenza have been available in the United States for more than 10 years and are widely prescribed for pregnant women. Despite the understanding that physiological changes associated with pregnancy (e.g., changes in renal and hepatic function) can markedly alter pharmacokinetics, pharmacokinetic studies have not routinely been conducted in this population. Not only could the lack of these data result in incorrect dosing and ineffective or subtherapeutic treatment for pregnant women, but inadequate dosing could also potentially accelerate the development of drug resistance and negatively affect the general usefulness of antiviral treatments during a pandemic. In the early 1990s, the Food and Drug Administration (FDA) removed restrictions on, and actually began encouraging, the inclusion of women of “child-bearing potential” in clinical studies. We would argue that it is not only permissible but also imperative that pregnant women be judiciously included in research. \n\n【2】Pregnant women are an important study subpopulation; more than 4 million women in the United States, and 131 million women worldwide, give birth annually. A prescription-database study showed that about 64% of pregnant women in the United States are given prescriptions for one or more medications (excluding vitamins and minerals) for chronic medical conditions or for acute problems that arise during pregnancy.  Despite these medical needs, clinical studies are rarely conducted in pregnant women. Prescribing decisions are therefore generally not evidence based, a failing that results in inadequately treated medical conditions, the exposure of the fetus to drug therapies at doses that may not even confer benefits to the mother, or treatment that carries undefined risks. For example, preliminary evidence that the higher complication rate associated with H1N1 influenza in pregnant women may be due to the use of inadequate doses of oseltamivir has led some researchers to suggest using higher doses in severely ill pregnant women infected with the H1N1 virus.  In another example, a 2007 study (partially funded by the FDA's Office of Women's Health) suggested that serum levels of amoxicillin that are adequate to prevent anthrax may be unachievable during pregnancy because of altered renal function. \n\n【3】The importance of studying subpopulations that have previously been excluded from research is undeniable. Before the passage of legislation intended to encourage pediatric research (the Pediatric Research Equity Act \\[PREA\\] and the Best Pharmaceuticals for Children Act \\[BPCA\\]), children were therapeutic orphans, as pregnant women are now. Studies conducted in the pediatric population since the enactment of these laws have shown that many assumptions that had been made about extrapolating conclusions regarding dosing, safety, and efficacy were incorrect or only partially correct; in 2008 and 2009 alone, pediatric studies conducted under the BPCA and the PREA resulted in 92 labeling changes for the pediatric use of drugs. Pediatric research is also expanding our understanding of the best ways to study vulnerable populations, to design studies that leverage preexisting data, and to determine what additional data are needed. Similar legislation for pregnant women may be appropriate if their exclusion from research cannot be otherwise rectified.\n\n【4】Therapeutic options for pregnant women should be informed by scientifically rigorous data on the efficacy and safety of each medication, just as they are for nonpregnant patients. Without data to guide risk–benefit assessments and prescribing information, some physicians are reluctant to recommend medications to their pregnant patients, who, in turn, are hesitant to take even necessary medications. The failure to properly treat a pregnant woman's condition can negatively affect not only her well-being, but also that of her fetus. Ironically, the effort to protect the fetus from research-related risks by excluding pregnant women from research places both women and their fetuses at greater risk from unstudied clinical interventions and may also result in a dearth of therapeutic options specifically developed for pregnant women.\n\n【5】Even among experts who agree that it is appropriate to study pregnant women — under certain conditions that safeguard the mother and the developing fetus — there is still debate about the timing of their inclusion in studies and the appropriateness of retaining women in clinical trials after they become pregnant. Some experts take the position that excluding pregnant women from research is actually unethical. In general, the ethical acceptability of studying pregnant women depends largely on the medical or scientific necessity of the study (e.g., it seems critical to study drugs that are already widely prescribed for use in pregnant women) and on the minimization of risks to the woman and the fetus (e.g., by focusing on marketed drugs with known safety profiles) .\n\n【6】Strategies for risk mitigation may include waiting to study pregnant women until adequate preclinical studies (e.g., developmental toxicology studies) have been completed and a safety database that includes information on nonpregnant women has been established. In addition, clinical trials involving pregnant women in which the study drug is administered as part of the protocol should include pregnancy monitoring (e.g., ultrasonography and fetal heart monitoring) and stopping criteria on which to base the withdrawal of an individual subject or early cessation of the whole trial.\n\n【7】Well-controlled, randomized clinical trials, the scientific standard for biomedical research, are most often used to support the claim that a drug meets the statutory and regulatory standards for efficacy and safety. For new drugs, however, participation of pregnant women in phase 3 clinical trials will require review of the study protocol and justification on a case-by-case basis. Circumstances that would argue for such participation include the study of conditions for which there are no other available effective therapies (e.g., endemic infections) and cases in which a drug is being developed specifically to treat pregnancy-related conditions.\n\n【8】In circumstances in which conducting randomized, controlled trials would be ethically unacceptable, there may be other methods of obtaining information about the use of pharmacotherapies in pregnant women. For example, if pharmacokinetic studies were performed in pregnant women whose physicians have already prescribed for them the drug in question, the research-related risks would be limited to those associated with the requisite blood sampling. In addition, cohort studies that enroll pregnant women who are already using a drug (e.g., exposure-registry studies that prospectively collect data on pregnancy and infant outcomes) provide opportunities for the collection of data without exposing the woman or the fetus to new research risks.\n\n【9】The fact that the H1N1 influenza pandemic caused higher morbidity and mortality among pregnant women than in the general population underscores the medical community's urgent need for data regarding the safe and effective use of medications during pregnancy. The complexity of studying the effects of medications in pregnant women should not stifle efforts to obtain scientifically rigorous data to guide the therapeutic use of pharmaceuticals in this population.\n\n【10】Correction of the underrepresentation of pregnant women in drug research is long overdue. Physicians can support these efforts by encouraging their pregnant patients to enroll in studies so that useful data can be gathered. Patients, advocacy groups, and professional organizations can raise awareness and press for needed research and policies to support the conduct of well-designed clinical studies of drugs to be used in pregnancy. Change often occurs in response to a crisis; the public health impact of the H1N1 pandemic should be the driving force in changing our culture and our thinking about conducting studies of pregnant women.\n\n【11】Circumstances in Which Inclusion of Pregnant Women in Clinical Studies Is Ethically Acceptable.\n-----------------------------------------------------------------------------------------------\n\n【12】Randomized clinical trials\n\n【13】Case-by-case review for acceptability for the study\n\n【14】No other available effective therapies for treatment of a serious or life-threatening condition (e.g., in pregnant women with drug resistance, drug intolerance, contraindication, or drug allergy)\n\n【15】Pregnant women already using the drug or class of drugs in the post-marketing setting, plus an established safety profile\n\n【16】Drug being developed specifically to treat pregnancy-related conditions\n\n【17】Pharmacokinetic studies\n\n【18】Pregnant women using the drug for therapeutic reasons\n\n【19】Pregnant women enrolled in phase 3 clinical trials of a drug on the basis of therapeutic need, a circumstance in which collection of pharmacokinetic data during pregnancy should be part of the study\n\n【20】Exposure-registry studies\\*\n\n【21】Pregnant women using the drug for therapeutic reasons (in which case pregnant women could be classified for enrollment according to the specific drug therapy being used or the medical condition of interest)\n\n【22】\\* To learn more about, or to enroll a patient in, a pregnancy-exposure registry, see www.fda.gov/ScienceResearch/SpecialTopics/WomensHealthResearch/ucm134844.htm . opens in new tab .", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "【22】* To learn more about, or to enroll a patient in, a pregnancy-exposure registry, see www.fda.gov/ScienceResearch/SpecialTopics/WomensHealthResearch/ucm134844.htm . opens in new tab .", "content": "【0】Enrolling Pregnant Women in Research — Lessons from the H1N1 Influenza Pandemic\nArticle\n-------\n\n【1】The global H1N1 influenza pandemic disproportionately affected pregnant women, drawing attention to the fact that although they need safe and effective medical treatment, they have always been a marginalized study population. Antiviral agents for treating influenza have been available in the United States for more than 10 years and are widely prescribed for pregnant women. Despite the understanding that physiological changes associated with pregnancy (e.g., changes in renal and hepatic function) can markedly alter pharmacokinetics, pharmacokinetic studies have not routinely been conducted in this population. Not only could the lack of these data result in incorrect dosing and ineffective or subtherapeutic treatment for pregnant women, but inadequate dosing could also potentially accelerate the development of drug resistance and negatively affect the general usefulness of antiviral treatments during a pandemic. In the early 1990s, the Food and Drug Administration (FDA) removed restrictions on, and actually began encouraging, the inclusion of women of “child-bearing potential” in clinical studies. We would argue that it is not only permissible but also imperative that pregnant women be judiciously included in research. \n\n【2】Pregnant women are an important study subpopulation; more than 4 million women in the United States, and 131 million women worldwide, give birth annually. A prescription-database study showed that about 64% of pregnant women in the United States are given prescriptions for one or more medications (excluding vitamins and minerals) for chronic medical conditions or for acute problems that arise during pregnancy.  Despite these medical needs, clinical studies are rarely conducted in pregnant women. Prescribing decisions are therefore generally not evidence based, a failing that results in inadequately treated medical conditions, the exposure of the fetus to drug therapies at doses that may not even confer benefits to the mother, or treatment that carries undefined risks. For example, preliminary evidence that the higher complication rate associated with H1N1 influenza in pregnant women may be due to the use of inadequate doses of oseltamivir has led some researchers to suggest using higher doses in severely ill pregnant women infected with the H1N1 virus.  In another example, a 2007 study (partially funded by the FDA's Office of Women's Health) suggested that serum levels of amoxicillin that are adequate to prevent anthrax may be unachievable during pregnancy because of altered renal function. \n\n【3】The importance of studying subpopulations that have previously been excluded from research is undeniable. Before the passage of legislation intended to encourage pediatric research (the Pediatric Research Equity Act \\[PREA\\] and the Best Pharmaceuticals for Children Act \\[BPCA\\]), children were therapeutic orphans, as pregnant women are now. Studies conducted in the pediatric population since the enactment of these laws have shown that many assumptions that had been made about extrapolating conclusions regarding dosing, safety, and efficacy were incorrect or only partially correct; in 2008 and 2009 alone, pediatric studies conducted under the BPCA and the PREA resulted in 92 labeling changes for the pediatric use of drugs. Pediatric research is also expanding our understanding of the best ways to study vulnerable populations, to design studies that leverage preexisting data, and to determine what additional data are needed. Similar legislation for pregnant women may be appropriate if their exclusion from research cannot be otherwise rectified.\n\n【4】Therapeutic options for pregnant women should be informed by scientifically rigorous data on the efficacy and safety of each medication, just as they are for nonpregnant patients. Without data to guide risk–benefit assessments and prescribing information, some physicians are reluctant to recommend medications to their pregnant patients, who, in turn, are hesitant to take even necessary medications. The failure to properly treat a pregnant woman's condition can negatively affect not only her well-being, but also that of her fetus. Ironically, the effort to protect the fetus from research-related risks by excluding pregnant women from research places both women and their fetuses at greater risk from unstudied clinical interventions and may also result in a dearth of therapeutic options specifically developed for pregnant women.\n\n【5】Even among experts who agree that it is appropriate to study pregnant women — under certain conditions that safeguard the mother and the developing fetus — there is still debate about the timing of their inclusion in studies and the appropriateness of retaining women in clinical trials after they become pregnant. Some experts take the position that excluding pregnant women from research is actually unethical. In general, the ethical acceptability of studying pregnant women depends largely on the medical or scientific necessity of the study (e.g., it seems critical to study drugs that are already widely prescribed for use in pregnant women) and on the minimization of risks to the woman and the fetus (e.g., by focusing on marketed drugs with known safety profiles) .\n\n【6】Strategies for risk mitigation may include waiting to study pregnant women until adequate preclinical studies (e.g., developmental toxicology studies) have been completed and a safety database that includes information on nonpregnant women has been established. In addition, clinical trials involving pregnant women in which the study drug is administered as part of the protocol should include pregnancy monitoring (e.g., ultrasonography and fetal heart monitoring) and stopping criteria on which to base the withdrawal of an individual subject or early cessation of the whole trial.\n\n【7】Well-controlled, randomized clinical trials, the scientific standard for biomedical research, are most often used to support the claim that a drug meets the statutory and regulatory standards for efficacy and safety. For new drugs, however, participation of pregnant women in phase 3 clinical trials will require review of the study protocol and justification on a case-by-case basis. Circumstances that would argue for such participation include the study of conditions for which there are no other available effective therapies (e.g., endemic infections) and cases in which a drug is being developed specifically to treat pregnancy-related conditions.\n\n【8】In circumstances in which conducting randomized, controlled trials would be ethically unacceptable, there may be other methods of obtaining information about the use of pharmacotherapies in pregnant women. For example, if pharmacokinetic studies were performed in pregnant women whose physicians have already prescribed for them the drug in question, the research-related risks would be limited to those associated with the requisite blood sampling. In addition, cohort studies that enroll pregnant women who are already using a drug (e.g., exposure-registry studies that prospectively collect data on pregnancy and infant outcomes) provide opportunities for the collection of data without exposing the woman or the fetus to new research risks.\n\n【9】The fact that the H1N1 influenza pandemic caused higher morbidity and mortality among pregnant women than in the general population underscores the medical community's urgent need for data regarding the safe and effective use of medications during pregnancy. The complexity of studying the effects of medications in pregnant women should not stifle efforts to obtain scientifically rigorous data to guide the therapeutic use of pharmaceuticals in this population.\n\n【10】Correction of the underrepresentation of pregnant women in drug research is long overdue. Physicians can support these efforts by encouraging their pregnant patients to enroll in studies so that useful data can be gathered. Patients, advocacy groups, and professional organizations can raise awareness and press for needed research and policies to support the conduct of well-designed clinical studies of drugs to be used in pregnancy. Change often occurs in response to a crisis; the public health impact of the H1N1 pandemic should be the driving force in changing our culture and our thinking about conducting studies of pregnant women.\n\n【11】Circumstances in Which Inclusion of Pregnant Women in Clinical Studies Is Ethically Acceptable.\n-----------------------------------------------------------------------------------------------\n\n【12】Randomized clinical trials\n\n【13】Case-by-case review for acceptability for the study\n\n【14】No other available effective therapies for treatment of a serious or life-threatening condition (e.g., in pregnant women with drug resistance, drug intolerance, contraindication, or drug allergy)\n\n【15】Pregnant women already using the drug or class of drugs in the post-marketing setting, plus an established safety profile\n\n【16】Drug being developed specifically to treat pregnancy-related conditions\n\n【17】Pharmacokinetic studies\n\n【18】Pregnant women using the drug for therapeutic reasons\n\n【19】Pregnant women enrolled in phase 3 clinical trials of a drug on the basis of therapeutic need, a circumstance in which collection of pharmacokinetic data during pregnancy should be part of the study\n\n【20】Exposure-registry studies\\*\n\n【21】Pregnant women using the drug for therapeutic reasons (in which case pregnant women could be classified for enrollment according to the specific drug therapy being used or the medical condition of interest)\n\n【22】\\* To learn more about, or to enroll a patient in, a pregnancy-exposure registry, see www.fda.gov/ScienceResearch/SpecialTopics/WomensHealthResearch/ucm134844.htm . opens in new tab .", "index": -1, "show": true, "start": -1, "end": 185, "province": ["文本干净度", "无关文本"], "isEdit": false}], "startTime": "2024/08/13 18:13:30", "endTime": "2024/08/13 18:15:42", "cost": 131.751}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 02:15:42", "grab_time": "2024-08-13 02:13:30"}
{"id": 2234471, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "7654537e-7aee-486f-ac3f-f8d05c5f885f", "title": "Benefits and Risks of Iron Interventions in Infants in Rural Bangladesh", "text": "【0】Benefits and Risks of Iron Interventions in Infants in Rural Bangladesh\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Universal provision of iron supplements (drops or syrup) or multiple micronutrient powders to young children in low-to-middle-income countries where anemia is prevalent is recommended by the World Health Organization and widely implemented. The functional benefits and safety of these interventions are unclear.\n\n【3】Methods\n-------\n\n【4】Download a PDF of the Research Summary .\n\n【5】We conducted a three-group, double-blind, double-dummy, individually randomized, placebo-controlled trial to assess the immediate and medium-term benefits and risks of 3 months of daily supplementation with iron syrup or iron-containing multiple micronutrient powders, as compared with placebo, in 8-month-old children in rural Bangladesh. The primary outcome was cognitive development, as assessed by the cognitive composite score on the Bayley Scales of Infant and Toddler Development, third edition, immediately after completion of the assigned 3-month regimen; scores range from 55 to 145, with higher scores indicating better cognitive performance. Secondary outcomes included the cognitive composite score at 9 months after completion of the assigned regimen; behavioral, language, and motor development, as well as growth and hematologic markers, immediately after completion and at 9 months after completion; and safety.\n\n【6】Results\n-------\n\n【7】We randomly assigned 3300 infants to receive iron syrup (1101 infants), multiple micronutrient powders (1099), or placebo (1100) daily. After completion of the assigned 3-month regimen, no apparent effect on the cognitive composite score was observed with iron syrup as compared with placebo (mean between-group difference in change in score from baseline, −0.30 points; 95% confidence interval \\[CI\\], −1.08 to 0.48) or with multiple micronutrient powders as compared with placebo (mean between-group difference in change in score from baseline, 0.23 points; 95% CI, −0.55 to 1.00). No apparent effect on any other developmental or growth outcome was observed immediately after completion of the assigned regimen or at 9 months after completion. At 9 months after completion of the assigned regimen, the prevalences of anemia, iron deficiency, and iron deficiency anemia increased in all three trial groups but remained lower among the children who received iron syrup or multiple micronutrient powders than among those who received placebo. The risk of serious adverse events and incidence of symptoms of infection were similar in the three trial groups.\n\n【8】Conclusions\n-----------\n\n【9】In this trial involving infants in Bangladesh, 3 months of daily supplementation with iron syrup or multiple micronutrient powders did not appear to have an effect on child development or other functional outcomes as compared with placebo. \n\n【10】Introduction\n------------\n\n【11】 QUICK TAKE  \nIron Interventions in Infants in Rural Bangladesh  \n\n【12】Among children younger than 5 years of age worldwide, nearly 40% are anemic, most of whom reside in low-to-middle-income countries. This burden is highest in the World Health Organization (WHO) regions of South-East Asia and Africa, where anemia affects 49.0% and 60.2% of this age group, respectively.  Iron deficiency is considered to be the main cause of anemia in the public health context.  The WHO recommends that all children 6 to 23 months of age in regions with prevalent anemia receive iron through either home-based fortification of complementary foods with iron-containing multiple micronutrient powders (packets of lipid-encapsulated iron with other micronutrients that are sprinkled onto weaning foods)  or iron supplements in the form of drops or syrup. \n\n【13】Prevention and treatment of iron deficiency and anemia in infancy have been considered essential to improving developmental outcomes (particularly cognitive development) in children. Although observational studies link anemia in children younger than 5 years of age to adverse developmental outcomes,  few randomized, controlled trials have assessed the immediate and sustained effects of iron interventions on cognitive, language, motor, or behavioral development, well-being, or growth in this age group.  Infection-related adverse effects, including increased rates of diarrhea  and malaria,  have been identified in trials of iron interventions in children who reside in areas where exposure to pathogens is intense. Although iron interventions are being scaled up (more than 18 million children across 61 countries received multiple micronutrient powders in 2018 <sup><a>12 </a></sup> ), there is inadequate high-quality evidence regarding the benefits and safety of such interventions as a public health strategy for children in low-to-middle-income countries. We aimed to determine whether iron interventions (consistent with WHO anemia-prevention guidelines)  in infants produce meaningful beneficial or harmful clinical outcomes and whether iron syrup and multiple micronutrient powders produce differential effects.\n\n【14】Methods\n-------\n\n【15】Trial Design and Oversight\n--------------------------\n\n【16】We conducted a three-group, double-blind, double-dummy, individually randomized, placebo-controlled trial (Benefits and Risks of Iron Interventions in Young Children \\[BRISC\\]) to assess immediate and medium-term benefits and risks of 3 months of daily supplementation with iron syrup or multiple micronutrient powders in 8-month-old children. The trial protocol was approved by ethics committees at the International Center for Diarrheal Disease Research, Bangladesh, and Melbourne Health, Australia, and by the Government of Bangladesh Directorate General of Drug Administration, and the trial was overseen by an independent data safety and monitoring board.\n\n【17】Parents or guardians of the participants provided written informed consent before both screening and enrollment in the trial. The statistical analysis plan, included with the protocol , was finalized before unblinding of the regimen assignments.  The first, penultimate, and last authors designed the trial, oversaw its implementation, and vouch for the accuracy and completeness of the data; the third and third-to-last authors analyzed the data; and the other authors collected the data. The first author wrote the initial draft of the manuscript, and all authors approved the final version for submission. There were no agreements regarding confidentiality of the data among the sponsor (the University of Melbourne), authors, and participating institutions.\n\n【18】Participants\n------------\n\n【19】The trial took place in Rupganj Upazila, Narayanganj District, Bangladesh, a rural area 35 km northeast of Dhaka covering 235 km <sup>2 </sup> and comprising approximately 82,000 households. The Upazila is divided into administrative units known as unions, of which we selected three (Rupganj, Golakandail, and Bhulta) for the trial. We undertook house-to-house enumeration of the entire study area to identify potentially eligible children. We screened children 7.5 to 8.5 months of age. Children with marked anemia (a hemoglobin level of <8.0 g per deciliter), current febrile illness, severe acute malnutrition, a known inherited red-cell disorder or previous transfusion, or known developmental delay were excluded. Bangladesh has areas where groundwater iron levels are high, which may affect iron intake  ; however, the study area had generally low levels of iron in the groundwater. Furthermore, iron levels in drinking water were tested at screening, and children were excluded if the level exceeded 1 mg per liter.\n\n【20】Randomization and Masking\n-------------------------\n\n【21】After written informed consent was obtained and baseline data were collected, the children underwent randomization. An independent statistician prepared a computer-generated randomization list with block randomization, stratified according to union and the sex of the child, to link sequential participant identification numbers to trial groups; a hard-copy list was used for randomization in the field. The list of participant identification numbers with associated trial-group assignments was held by the independent statistician until the database was locked for analysis.\n\n【22】Trial-Group Assignments\n-----------------------\n\n【23】The participants were randomly assigned to receive 12.5 mg of elemental iron as ferrous sulfate syrup daily  plus placebo packets of multiple micronutrient powders that contained maltodextrin alone; packets of multiple micronutrient powders that contained 12.5 mg of iron as ferrous fumarate, 0.3 mg of vitamin A, 30 mg of vitamin C, 0.16 mg of folic acid, 5 mg of zinc, and maltodextrin  plus placebo syrup; or placebo syrup and placebo packets. The iron syrup, multiple micronutrient powders, and placebo products were taken daily. The iron syrup (purchased from ACME Laboratories) was administered through a syringe marked with the required volume, and the multiple micronutrient powders (donated by Renata) were sprinkled onto complementary foods. These interventions met the WHO recommendations.  The active agents and placebo were packaged identically and could be distinguished only by a finely printed, multidigit batch number. The iron content of active agents and placebo was independently tested at the International Center for Diarrheal Disease Research, Bangladesh. The trial drugs and placebo were initially administered at the time of randomization, when proper use of the products was demonstrated.\n\n【24】Outcome Assessment\n------------------\n\n【25】Data were entered in the field on handheld devices and uploaded to an SQL database. Children underwent detailed assessments at baseline, at the completion of the assigned 3-month regimen (up to 7 days before or 14 days after completion), and at 9 months after completion (with a window of ±14 days). During the intervention period, trained local data collectors visited the participants at home weekly to assess medical complications and adherence and to replenish trial drugs or placebo. Data collectors also visited the participants monthly during the postintervention period to assess medical complications.\n\n【26】Assessments of cognitive, behavioral, language, and motor development were conducted, anthropometric variables (crown–heel length, weight, and head circumference) were measured at least in duplicate by two trained persons, and z scores were calculated with the use of the 2006 WHO Child Growth Standards.  Sociodemographic and nutrition data were collected, and home stimulation was assessed with the use of the family care indicators tool  at baseline, immediately after completion of the assigned 3-month regimen, and at 9 months after completion. Venous blood samples of up to 3 ml were collected, and hemoglobin levels were measured with a HemoCue 301+ device (HemoCue). Serum was separated and frozen for analysis of ferritin and C-reactive protein levels.\n\n【27】The primary trial outcome was cognitive development, as assessed by the cognitive composite score on the Bayley Scales of Infant and Toddler Development, third edition (Bayley-III), immediately after completion of the assigned 3-month regimen. Using a locally adapted Bayley-III tool, trained testers, who had a master’s degree in psychology or social sciences, evaluated each infant in the presence of the mother (or another caregiver if the mother was unavailable) in a quiet environment outside the family home.  The Bayley-III is a reference clinical and research tool for comprehensive assessment of neurodevelopment in early childhood that uses a structured set of tasks to assess function across various domains and takes approximately 1 hour to administer; scores range from 55 to 145 for cognitive development and from 45 to 155 for language and motor development, with higher scores indicating better performance (in U.S. populations, the standardized mean \\[±SD\\] score is 100±15). \n\n【28】Key secondary outcomes were the Bayley-III cognitive composite score at 9 months after completion of the assigned regimen, the Bayley-III language composite and motor composite scores, length-for-age and weight-for-age z scores, hemoglobin level, and iron stores (measured as the ferritin level), each of which was assessed immediately after completion of the assigned regimen and at 9 months after completion. Other secondary outcomes were behavior (as assessed with the use of Wolke’s Behavior Rating Scale), temperament, anemia (defined as a hemoglobin level of <11 g per deciliter), iron deficiency (defined as a ferritin level of <12 μg per liter or <30 μg per liter if the C-reactive protein level was >5 mg per liter),  and iron deficiency anemia (concurrent anemia and iron deficiency), each of which was assessed immediately after completion of the assigned regimen and at 9 months after completion.\n\n【29】The quality of the Bayley-III measurements was monitored. Before the trial was initiated, intraobserver reliability for Bayley-III ratings ranged from 0.81 to 0.99 and interobserver reliability from 0.99 to 1 among the testers, except for one who had not performed as well as the other testers initially but was retrained before continuing involvement. During the trial, 9% of tests were observed by another tester: interobserver reliability ranged from 0.96 to 1 . Performance of testers was accounted for in alternative analyses of Bayley-III scores by incorporating rater and the interaction between rater and visit in the model.\n\n【30】During home visits, mothers or caregivers were asked whether the child had symptoms of infection (i.e., diarrhea \\[defined as at least 3 loose or liquid stools per day\\], bloody diarrhea, vomiting, fever, or cough or breathing difficulty) and the number of days in the previous week (during the intervention period) or previous 2 weeks (during the follow-up period) that they had occurred. Parents or caregivers could seek medical care for their infant from government or private providers; the receipt of such care was recorded as an unplanned clinic visit. Safety outcomes were symptoms of infection that were reported during home visits, as well as unplanned clinic visits and hospitalizations that were reported at any time; records of hospitalizations and deaths were confirmed by the trial pediatrician, who was also available to provide free advice for the participating families.\n\n【31】Statistical Analysis\n--------------------\n\n【32】We determined that a sample size of 3300 participants (1100 per group) would provide 80% power to detect a 2-point difference in cognitive composite score between each active intervention group and the placebo group immediately after completion of the assigned regimen, assuming a standard deviation of 15 points, a 20% loss to follow-up, and a two-sided type I error rate of 5%. With a Bonferroni-corrected two-sided alpha level of 0.025 for the comparisons between iron syrup and placebo and between multiple micronutrient powders and placebo, the trial would have at least 80% power to reject at least one of the two primary null hypotheses (no difference between iron syrup and placebo or between multiple micronutrient powders and placebo with respect to the primary outcome immediately after completion of the assigned regimen). In our previous systematic review of the effects of iron supplementation on cognitive development in young children, we estimated that iron supplementation would result in a 1.65-point higher cognitive composite score than placebo at the end of the intervention  ; differences in the cognitive composite score of between 2 and 3 points in favor of iron supplementation have been reported in previous underpowered population trials.  The current trial was thus powered to detect a minimum effect size of a 2-point between-group difference in the cognitive composite score immediately after completion of the assigned regimen; a 2-point difference is probably smaller than a clinically meaningful effect.\n\n【33】Analyses were performed according to the intention-to-treat principle and followed a prespecified statistical analysis plan.  The cognitive composite score at 3 months (primary outcome) was analyzed with the use of a likelihood-based longitudinal data analysis model by Liang and Zeger,  with the randomization stratification factors union and sex of the child as covariates, and unstructured variance–covariance among repeated measurements (the Stata code used for analysis is provided in Text S1 in the Supplementary Appendix ). Similar analyses were applied to the key secondary outcomes of Bayley-III language composite and motor composite scores, length-for-age z score, weight-for-age z score, hemoglobin level, and log-transformed ferritin level, as well as the secondary outcomes of weight-for-length z score and head circumference. Secondary outcomes of stunting (length-for-age z score of less than −2), underweight (weight-for-age z score of less than −2), wasting (weight-for-length z score of less than −2), anemia, iron deficiency, and iron deficiency anemia were analyzed with the use of a Poisson regression model with a random intercept for the participant and robust error variance. Infection outcomes during the intervention period (number of days with a parent-reported symptom of infection) and follow-up period (number of days with a parent-reported symptom of infection during the last 14 days of each month) were analyzed with the use of a negative binomial regression model for each period separately with offset for time at risk. The multiple testing strategy consisted of testing the two primary null hypotheses at a significance level of 2.5%; testing the key secondary hypotheses involving the same comparisons was conditional on the rejection of the primary null hypotheses. \n\n【34】Additional analyses of primary, key secondary, and secondary outcomes included covariate-adjusted analyses for baseline imbalance and a per-protocol analysis of participants with at least 70% adherence, to which we applied the previously described multiple-testing approach. The likelihood-based longitudinal analysis model was fitted under the missing-at-random assumption. An analysis based on a pattern-mixture model was performed for the primary outcome to assess sensitivity to data missing not at random.  Nine prespecified subgroup analyses of the primary and key secondary outcomes and three post hoc subgroup analyses of parent-reported symptoms of infection and clinic visits (according to baseline status with respect to anemia, iron deficiency, and iron deficiency anemia) were conducted to assess heterogeneity of the differences among the active interventions and placebo. Analyses were performed with the use of Stata/SE software, version 15.1 (StataCorp).\n\n【35】Results\n-------\n\n【36】Trial Population\n----------------\n\n【37】Table 1. Household and Child Characteristics at Baseline.\n\n【38】Between July 6, 2017, and February 20, 2019, a total of 3300 children were enrolled and underwent randomization . Follow-up was completed on February 10, 2020; unblinding of the data was delayed because of restrictions related to coronavirus disease 2019.  Baseline household and child characteristics were similar across trial groups . At baseline, 1428 of 3188 children (44.8%) had anemia, 852 of 3080 (27.7%) had iron deficiency, and 594 of 3080 (19.3%) had iron deficiency anemia. Median adherence to iron syrup, multiple micronutrient powders, and placebo was 86.8%, 86.8%, and 87.9%, respectively ; 73.1% of children consumed at least 70% of their assigned active agent or placebo.\n\n【39】Child Development\n-----------------\n\n【40】Table 2. Efficacy of Iron Interventions Immediately after Completion of the 3-Month Regimen and at 9 Months after Completion (Intention-to-Treat Population).\n\n【41】Among the 3300 children who had undergone randomization, 2885 (87.4%) were assessed for the primary outcome immediately after completion of the assigned 3-month regimen. Loss to follow-up was similar among the trial groups. No apparent effect on the cognitive composite score was observed with iron syrup as compared with placebo (mean between-group difference in change in score from baseline, −0.30 points; 95% confidence interval \\[CI\\], −1.08 to 0.48) or with multiple micronutrient powders as compared with placebo (mean between-group difference in change in score from baseline, 0.23 points; 95% CI, −0.55 to 1.00) . No evidence of a difference in cognitive composite score was found with iron syrup as compared with multiple micronutrient powders (mean between-group difference in change in score from baseline, −0.52 points; 95% CI, −1.31 to 0.26). No apparent differences in cognitive composite score were observed among the trial groups at 9 months after completion of the assigned regimen . There were no apparent differences in baseline characteristics between the children with missing cognitive composite scores and those with at least 70% adherence to the assigned regimen . The absence of an evident effect of an active intervention on the primary outcome was confirmed with alternative models that accounted for missing data, baseline anemia, tester, and adherence .\n\n【42】Neither iron syrup nor multiple micronutrient powders improved motor or language development, child behavior (Wolke’s Behavioral Rating Scale), or temperament, either immediately after completion of the assigned regimen or at 9 months after completion . Measurements of child growth (length-for-age z score, weight-for-age z score, weight-for-length z score, and head circumference) did not differ significantly among the three groups either immediately after completion of the assigned regimen or at 9 months after completion , and these results were similar in additional analyses .\n\n【43】Hematologic Outcomes\n--------------------\n\n【44】The effects of the assigned regimens on hematologic outcomes immediately after completion of the assigned regimen and at 9 months after completion are shown in Table 2 . Among the 3300 participants who had undergone randomization, data on the venous hemoglobin level were available for 2094 (63.5%) immediately after completion of the assigned regimen and for 2104 (63.8%) at 9 months after completion. Three months of supplementation with iron syrup or multiple micronutrient powders resulted in a lower prevalence of anemia than placebo (prevalence ratio with iron syrup vs. placebo, 0.48 \\[95% CI, 0.41 to 0.56\\], and with multiple micronutrient powders vs. placebo, 0.52 \\[95% CI, 0.45 to 0.60\\]). The prevalence of anemia was similar in the iron-syrup group and the multiple-micronutrient-powder group, with a prevalence ratio of 0.92 (95% CI, 0.76 to 1.11). At 9 months after completion of the assigned regimen, the prevalence of anemia increased in all three trial groups but remained lower among the children who received iron syrup or multiple micronutrient powders than among those who received placebo (prevalence ratio with iron syrup vs. placebo, 0.71 \\[95% CI, 0.61 to 0.82\\], and with multiple micronutrient powders vs. placebo, 0.83 \\[95% CI, 0.72 to 0.95\\]). The prevalences of iron deficiency anemia and iron deficiency were also lower with either active intervention than with placebo . Further analyses confirmed these results .\n\n【45】Safety\n------\n\n【46】Table 3. Safety Outcomes during the Intervention Period (Safety Population).\n\n【47】The percentage of participants with at least one serious adverse event (hospitalization or death) was similar in the three trial groups, as was the percentage of participants who had unplanned clinic visits during the intervention period or immediately after completion of the assigned regimen . Parental reports of symptoms of infection (diarrhea, fever, or respiratory symptoms) were similar in the three trial groups, both during the intervention period and during the follow-up period. Tables S12 through S17 report the results of descriptive post hoc subgroup analyses of safety outcomes according to baseline status with respect to anemia, iron deficiency, and iron deficiency anemia. Neither iron intervention had an effect on the prevalence of corneal lesions (Bitot’s spots) .\n\n【48】Subgroup Analyses\n-----------------\n\n【49】Figure 1. Subgroup Analyses of the Treatment Effect on the Cognitive Composite Score Immediately after Completion of the Assigned Regimen According to Baseline Characteristics.\n\n【50】The cognitive composite scores on the Bayley Scales of Infant and Toddler Development, third edition, were analyzed in the intention-to-treat population with the use of a likelihood-based longitudinal data analysis model that adjusted for union and sex of the child and included subgroup-by-regimen and subgroup-by-visit interactions. The 95% confidence intervals were not adjusted for multiple comparisons. Anemia was defined as a hemoglobin level of less than 11 g per deciliter. Iron deficiency was defined as a ferritin level of less than 12 μg per liter or less than 30 μg per liter if the C-reactive protein level was higher than 5 mg per liter. Iron deficiency anemia was defined as concurrent anemia and iron deficiency. Stunting was defined as a length-for-age z score lower than −2. The median total score on the family care indicators tool was 13, on a scale from 0 to 42, with higher scores indicating more activities involving play and reading materials.  The median wealth index score was 0.49; households with a score below 0.49 comprised relatively poorer households, and those with a score above 0.49 relatively wealthier households. The wealth index is derived from an asset-based measure of a household’s living standard calculated from a principal component analysis. Food security was assessed with the use of the Household Food Insecurity Access Scale questionnaire; food-secure status was defined as an answer of “no” or “rarely” to the initial question regarding worry over the previous 4 weeks that the household would not have enough food and an answer of “no” to further questions regarding change in food availability or eating behaviors due to food access. MNPs denote multiple micronutrient powders.\n\n【51】The results of the prespecified subgroup analyses of the primary and key secondary outcomes are provided in Figure 1 and Table S19. There was no evidence of a subgroup effect on the cognitive composite score according to baseline status with respect to anemia or iron deficiency immediately after completion of the assigned regimen  or at 9 months after completion. The increases in hemoglobin and ferritin levels at completion of the assigned regimen were greater among the children who had anemia, iron deficiency, or iron deficiency anemia at baseline, and there was no evidence of a difference between the two iron interventions.\n\n【52】Discussion\n----------\n\n【53】In a rural, low-income, South Asian region where anemia in young children is a severe public health problem, 3 months of daily supplementation with iron syrup or multiple micronutrient powders in 8-month-old infants, as recommended in the WHO guidelines, did not have an effect on the primary outcome of child cognitive development, despite a markedly lower prevalence of anemia or iron deficiency in the active intervention groups than in the placebo group. The iron interventions were not associated with evidence of immediate or sustained improvements in other measures of child development, behavior, temperament, or growth. Reductions in anemia were partly sustained at 9 months after completion of the assigned regimen. Neither intervention was associated with an increase in parental reports of symptoms of infection or clinic visits or hospitalizations, and each led to a similar short-term reduction in the prevalence of anemia or iron deficiency.\n\n【54】The key rationale for preventive iron interventions in young children is the presumed benefit with respect to functional health outcomes,  particularly child development and growth  ; this presumption is based on observational studies that have consistently linked anemia to suboptimal child cognitive development.  However, meta-analyses of randomized, controlled trials evaluating iron supplementation revealed limited and inconclusive data with regard to functional outcomes.  Individual trials were underpowered,  involved patient groups (not populations),  or had an open-label design,  limitations that the current trial was designed to overcome. Given that iron interventions produced sustained improvements in the hemoglobin level and iron stores but did not improve developmental, behavioral, or growth outcomes in the immediate or medium term, our results address this knowledge gap. Our conclusions were consistent across all additional primary intention-to-treat analyses.\n\n【55】We administered the iron syrup and multiple micronutrient powders for 3 months, as recommended by the WHO. Although a longer duration of supplementation may have further increased iron stores, it is uncertain whether this would have had an effect on functional outcomes, because iron deficiency anemia was virtually eliminated after 3 months. Previous studies that involved longer interventions (e.g., 6 months  and 18 months  ) have not shown benefits with respect to cognitive development. In addition, a longer intervention may have exacerbated the risk of diarrhea. Future studies may explore whether prolonged iron interventions in infants can have a benefit with regard to functional outcomes; alternatively, improvement of neurodevelopment in children may require an earlier intervention (e.g., antenatal supplementation). \n\n【56】There are concerns that iron interventions may increase risks of infections, such as those that cause diarrhea.  The rates of parent-reported diarrhea and unplanned clinic visits for diarrhea were not higher in the groups that received iron syrup or multiple micronutrient powders than in the placebo group. Although the subgroup analyses indicated an increased risk of unplanned clinic visits because of diarrhea in nonanemic or non–iron-deficient children while they were receiving iron syrup or multiple micronutrient powders, these findings are not conclusive because the analyses were post hoc, did not include adjustment for multiple comparisons, and showed no significant difference between subgroups.\n\n【57】Our data showed that iron syrup and multiple micronutrient powders were associated with similar adherence, had similar effects in reducing the prevalences of anemia and iron deficiency, and did not differ significantly with respect to functional or infection-related outcomes. The prevalences of anemia, iron deficiency, and iron deficiency anemia were lower among the children in the active intervention groups than among those in the placebo group for up to 9 months after completion of the assigned regimen, although the prevalences in all three groups had increased from the time immediately after completion of the intervention. Repeated cycles of the intervention, which is recommended for multiple micronutrient powders  but not for iron supplements (drops or syrup), may be needed to sustain hematologic responses.\n\n【58】We did not identify an effect on developmental outcomes in subgroups defined according to baseline anemia, iron deficiency, and iron deficiency anemia. These findings inform the rationale for screening and therapy for asymptomatic iron deficiency in children in clinical practice. \n\n【59】The strengths of our trial were that it was designed with cognitive development as the primary outcome, was powered to detect a small effect size, minimized the risk of bias, and ensured high interobserver concordance between assessors. The limitations of our trial were that 36 to 37% of the infants at each postbaseline visit did not have a measurement of the venous hemoglobin concentration for reasons such as unwillingness of the parents to allow collection of a venous blood sample, which limited the data used in the secondary hematologic analyses but not the data used for the primary or other functional outcome analyses. We found no important differences in baseline characteristics between those for whom consent to a blood test was provided and those for whom consent was not provided. Per-protocol analyses were adjusted for key prognostic baseline factors, as were the intention-to-treat analyses; however, bias due to unmeasured postrandomization factors associated with adherence is possible.\n\n【60】In our trial, 3 months of daily supplementation with iron syrup or multiple micronutrient powders in 8-month-old children reduced the prevalence of anemia but did not improve cognitive development or other functional health outcomes immediately after completion of the regimen or at 9 months after completion.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "【4】Download a PDF of the Research Summary .", "content": "【0】Benefits and Risks of Iron Interventions in Infants in Rural Bangladesh\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Universal provision of iron supplements (drops or syrup) or multiple micronutrient powders to young children in low-to-middle-income countries where anemia is prevalent is recommended by the World Health Organization and widely implemented. The functional benefits and safety of these interventions are unclear.\n\n【3】Methods\n-------\n\n【4】Download a PDF of the Research Summary .\n\n【5】We conducted a three-group, double-blind, double-dummy, individually randomized, placebo-controlled trial to assess the immediate and medium-term benefits and risks of 3 months of daily supplementation with iron syrup or iron-containing multiple micronutrient powders, as compared with placebo, in 8-month-old children in rural Bangladesh. The primary outcome was cognitive development, as assessed by the cognitive composite score on the Bayley Scales of Infant and Toddler Development, third edition, immediately after completion of the assigned 3-month regimen; scores range from 55 to 145, with higher scores indicating better cognitive performance. Secondary outcomes included the cognitive composite score at 9 months after completion of the assigned regimen; behavioral, language, and motor development, as well as growth and hematologic markers, immediately after completion and at 9 months after completion; and safety.\n\n【6】Results\n-------\n\n【7】We randomly assigned 3300 infants to receive iron syrup (1101 infants), multiple micronutrient powders (1099), or placebo (1100) daily. After completion of the assigned 3-month regimen, no apparent effect on the cognitive composite score was observed with iron syrup as compared with placebo (mean between-group difference in change in score from baseline, −0.30 points; 95% confidence interval \\[CI\\], −1.08 to 0.48) or with multiple micronutrient powders as compared with placebo (mean between-group difference in change in score from baseline, 0.23 points; 95% CI, −0.55 to 1.00). No apparent effect on any other developmental or growth outcome was observed immediately after completion of the assigned regimen or at 9 months after completion. At 9 months after completion of the assigned regimen, the prevalences of anemia, iron deficiency, and iron deficiency anemia increased in all three trial groups but remained lower among the children who received iron syrup or multiple micronutrient powders than among those who received placebo. The risk of serious adverse events and incidence of symptoms of infection were similar in the three trial groups.\n\n【8】Conclusions\n-----------\n\n【9】In this trial involving infants in Bangladesh, 3 months of daily supplementation with iron syrup or multiple micronutrient powders did not appear to have an effect on child development or other functional outcomes as compared with placebo. \n\n【10】Introduction\n------------\n\n【11】 QUICK TAKE  \nIron Interventions in Infants in Rural Bangladesh  \n\n【12】Among children younger than 5 years of age worldwide, nearly 40% are anemic, most of whom reside in low-to-middle-income countries. This burden is highest in the World Health Organization (WHO) regions of South-East Asia and Africa, where anemia affects 49.0% and 60.2% of this age group, respectively.  Iron deficiency is considered to be the main cause of anemia in the public health context.  The WHO recommends that all children 6 to 23 months of age in regions with prevalent anemia receive iron through either home-based fortification of complementary foods with iron-containing multiple micronutrient powders (packets of lipid-encapsulated iron with other micronutrients that are sprinkled onto weaning foods)  or iron supplements in the form of drops or syrup. \n\n【13】Prevention and treatment of iron deficiency and anemia in infancy have been considered essential to improving developmental outcomes (particularly cognitive development) in children. Although observational studies link anemia in children younger than 5 years of age to adverse developmental outcomes,  few randomized, controlled trials have assessed the immediate and sustained effects of iron interventions on cognitive, language, motor, or behavioral development, well-being, or growth in this age group.  Infection-related adverse effects, including increased rates of diarrhea  and malaria,  have been identified in trials of iron interventions in children who reside in areas where exposure to pathogens is intense. Although iron interventions are being scaled up (more than 18 million children across 61 countries received multiple micronutrient powders in 2018 <sup><a>12 </a></sup> ), there is inadequate high-quality evidence regarding the benefits and safety of such interventions as a public health strategy for children in low-to-middle-income countries. We aimed to determine whether iron interventions (consistent with WHO anemia-prevention guidelines)  in infants produce meaningful beneficial or harmful clinical outcomes and whether iron syrup and multiple micronutrient powders produce differential effects.\n\n【14】Methods\n-------\n\n【15】Trial Design and Oversight\n--------------------------\n\n【16】We conducted a three-group, double-blind, double-dummy, individually randomized, placebo-controlled trial (Benefits and Risks of Iron Interventions in Young Children \\[BRISC\\]) to assess immediate and medium-term benefits and risks of 3 months of daily supplementation with iron syrup or multiple micronutrient powders in 8-month-old children. The trial protocol was approved by ethics committees at the International Center for Diarrheal Disease Research, Bangladesh, and Melbourne Health, Australia, and by the Government of Bangladesh Directorate General of Drug Administration, and the trial was overseen by an independent data safety and monitoring board.\n\n【17】Parents or guardians of the participants provided written informed consent before both screening and enrollment in the trial. The statistical analysis plan, included with the protocol , was finalized before unblinding of the regimen assignments.  The first, penultimate, and last authors designed the trial, oversaw its implementation, and vouch for the accuracy and completeness of the data; the third and third-to-last authors analyzed the data; and the other authors collected the data. The first author wrote the initial draft of the manuscript, and all authors approved the final version for submission. There were no agreements regarding confidentiality of the data among the sponsor (the University of Melbourne), authors, and participating institutions.\n\n【18】Participants\n------------\n\n【19】The trial took place in Rupganj Upazila, Narayanganj District, Bangladesh, a rural area 35 km northeast of Dhaka covering 235 km <sup>2 </sup> and comprising approximately 82,000 households. The Upazila is divided into administrative units known as unions, of which we selected three (Rupganj, Golakandail, and Bhulta) for the trial. We undertook house-to-house enumeration of the entire study area to identify potentially eligible children. We screened children 7.5 to 8.5 months of age. Children with marked anemia (a hemoglobin level of <8.0 g per deciliter), current febrile illness, severe acute malnutrition, a known inherited red-cell disorder or previous transfusion, or known developmental delay were excluded. Bangladesh has areas where groundwater iron levels are high, which may affect iron intake  ; however, the study area had generally low levels of iron in the groundwater. Furthermore, iron levels in drinking water were tested at screening, and children were excluded if the level exceeded 1 mg per liter.\n\n【20】Randomization and Masking\n-------------------------\n\n【21】After written informed consent was obtained and baseline data were collected, the children underwent randomization. An independent statistician prepared a computer-generated randomization list with block randomization, stratified according to union and the sex of the child, to link sequential participant identification numbers to trial groups; a hard-copy list was used for randomization in the field. The list of participant identification numbers with associated trial-group assignments was held by the independent statistician until the database was locked for analysis.\n\n【22】Trial-Group Assignments\n-----------------------\n\n【23】The participants were randomly assigned to receive 12.5 mg of elemental iron as ferrous sulfate syrup daily  plus placebo packets of multiple micronutrient powders that contained maltodextrin alone; packets of multiple micronutrient powders that contained 12.5 mg of iron as ferrous fumarate, 0.3 mg of vitamin A, 30 mg of vitamin C, 0.16 mg of folic acid, 5 mg of zinc, and maltodextrin  plus placebo syrup; or placebo syrup and placebo packets. The iron syrup, multiple micronutrient powders, and placebo products were taken daily. The iron syrup (purchased from ACME Laboratories) was administered through a syringe marked with the required volume, and the multiple micronutrient powders (donated by Renata) were sprinkled onto complementary foods. These interventions met the WHO recommendations.  The active agents and placebo were packaged identically and could be distinguished only by a finely printed, multidigit batch number. The iron content of active agents and placebo was independently tested at the International Center for Diarrheal Disease Research, Bangladesh. The trial drugs and placebo were initially administered at the time of randomization, when proper use of the products was demonstrated.\n\n【24】Outcome Assessment\n------------------\n\n【25】Data were entered in the field on handheld devices and uploaded to an SQL database. Children underwent detailed assessments at baseline, at the completion of the assigned 3-month regimen (up to 7 days before or 14 days after completion), and at 9 months after completion (with a window of ±14 days). During the intervention period, trained local data collectors visited the participants at home weekly to assess medical complications and adherence and to replenish trial drugs or placebo. Data collectors also visited the participants monthly during the postintervention period to assess medical complications.\n\n【26】Assessments of cognitive, behavioral, language, and motor development were conducted, anthropometric variables (crown–heel length, weight, and head circumference) were measured at least in duplicate by two trained persons, and z scores were calculated with the use of the 2006 WHO Child Growth Standards.  Sociodemographic and nutrition data were collected, and home stimulation was assessed with the use of the family care indicators tool  at baseline, immediately after completion of the assigned 3-month regimen, and at 9 months after completion. Venous blood samples of up to 3 ml were collected, and hemoglobin levels were measured with a HemoCue 301+ device (HemoCue). Serum was separated and frozen for analysis of ferritin and C-reactive protein levels.\n\n【27】The primary trial outcome was cognitive development, as assessed by the cognitive composite score on the Bayley Scales of Infant and Toddler Development, third edition (Bayley-III), immediately after completion of the assigned 3-month regimen. Using a locally adapted Bayley-III tool, trained testers, who had a master’s degree in psychology or social sciences, evaluated each infant in the presence of the mother (or another caregiver if the mother was unavailable) in a quiet environment outside the family home.  The Bayley-III is a reference clinical and research tool for comprehensive assessment of neurodevelopment in early childhood that uses a structured set of tasks to assess function across various domains and takes approximately 1 hour to administer; scores range from 55 to 145 for cognitive development and from 45 to 155 for language and motor development, with higher scores indicating better performance (in U.S. populations, the standardized mean \\[±SD\\] score is 100±15). \n\n【28】Key secondary outcomes were the Bayley-III cognitive composite score at 9 months after completion of the assigned regimen, the Bayley-III language composite and motor composite scores, length-for-age and weight-for-age z scores, hemoglobin level, and iron stores (measured as the ferritin level), each of which was assessed immediately after completion of the assigned regimen and at 9 months after completion. Other secondary outcomes were behavior (as assessed with the use of Wolke’s Behavior Rating Scale), temperament, anemia (defined as a hemoglobin level of <11 g per deciliter), iron deficiency (defined as a ferritin level of <12 μg per liter or <30 μg per liter if the C-reactive protein level was >5 mg per liter),  and iron deficiency anemia (concurrent anemia and iron deficiency), each of which was assessed immediately after completion of the assigned regimen and at 9 months after completion.\n\n【29】The quality of the Bayley-III measurements was monitored. Before the trial was initiated, intraobserver reliability for Bayley-III ratings ranged from 0.81 to 0.99 and interobserver reliability from 0.99 to 1 among the testers, except for one who had not performed as well as the other testers initially but was retrained before continuing involvement. During the trial, 9% of tests were observed by another tester: interobserver reliability ranged from 0.96 to 1 . Performance of testers was accounted for in alternative analyses of Bayley-III scores by incorporating rater and the interaction between rater and visit in the model.\n\n【30】During home visits, mothers or caregivers were asked whether the child had symptoms of infection (i.e., diarrhea \\[defined as at least 3 loose or liquid stools per day\\], bloody diarrhea, vomiting, fever, or cough or breathing difficulty) and the number of days in the previous week (during the intervention period) or previous 2 weeks (during the follow-up period) that they had occurred. Parents or caregivers could seek medical care for their infant from government or private providers; the receipt of such care was recorded as an unplanned clinic visit. Safety outcomes were symptoms of infection that were reported during home visits, as well as unplanned clinic visits and hospitalizations that were reported at any time; records of hospitalizations and deaths were confirmed by the trial pediatrician, who was also available to provide free advice for the participating families.\n\n【31】Statistical Analysis\n--------------------\n\n【32】We determined that a sample size of 3300 participants (1100 per group) would provide 80% power to detect a 2-point difference in cognitive composite score between each active intervention group and the placebo group immediately after completion of the assigned regimen, assuming a standard deviation of 15 points, a 20% loss to follow-up, and a two-sided type I error rate of 5%. With a Bonferroni-corrected two-sided alpha level of 0.025 for the comparisons between iron syrup and placebo and between multiple micronutrient powders and placebo, the trial would have at least 80% power to reject at least one of the two primary null hypotheses (no difference between iron syrup and placebo or between multiple micronutrient powders and placebo with respect to the primary outcome immediately after completion of the assigned regimen). In our previous systematic review of the effects of iron supplementation on cognitive development in young children, we estimated that iron supplementation would result in a 1.65-point higher cognitive composite score than placebo at the end of the intervention  ; differences in the cognitive composite score of between 2 and 3 points in favor of iron supplementation have been reported in previous underpowered population trials.  The current trial was thus powered to detect a minimum effect size of a 2-point between-group difference in the cognitive composite score immediately after completion of the assigned regimen; a 2-point difference is probably smaller than a clinically meaningful effect.\n\n【33】Analyses were performed according to the intention-to-treat principle and followed a prespecified statistical analysis plan.  The cognitive composite score at 3 months (primary outcome) was analyzed with the use of a likelihood-based longitudinal data analysis model by Liang and Zeger,  with the randomization stratification factors union and sex of the child as covariates, and unstructured variance–covariance among repeated measurements (the Stata code used for analysis is provided in Text S1 in the Supplementary Appendix ). Similar analyses were applied to the key secondary outcomes of Bayley-III language composite and motor composite scores, length-for-age z score, weight-for-age z score, hemoglobin level, and log-transformed ferritin level, as well as the secondary outcomes of weight-for-length z score and head circumference. Secondary outcomes of stunting (length-for-age z score of less than −2), underweight (weight-for-age z score of less than −2), wasting (weight-for-length z score of less than −2), anemia, iron deficiency, and iron deficiency anemia were analyzed with the use of a Poisson regression model with a random intercept for the participant and robust error variance. Infection outcomes during the intervention period (number of days with a parent-reported symptom of infection) and follow-up period (number of days with a parent-reported symptom of infection during the last 14 days of each month) were analyzed with the use of a negative binomial regression model for each period separately with offset for time at risk. The multiple testing strategy consisted of testing the two primary null hypotheses at a significance level of 2.5%; testing the key secondary hypotheses involving the same comparisons was conditional on the rejection of the primary null hypotheses. \n\n【34】Additional analyses of primary, key secondary, and secondary outcomes included covariate-adjusted analyses for baseline imbalance and a per-protocol analysis of participants with at least 70% adherence, to which we applied the previously described multiple-testing approach. The likelihood-based longitudinal analysis model was fitted under the missing-at-random assumption. An analysis based on a pattern-mixture model was performed for the primary outcome to assess sensitivity to data missing not at random.  Nine prespecified subgroup analyses of the primary and key secondary outcomes and three post hoc subgroup analyses of parent-reported symptoms of infection and clinic visits (according to baseline status with respect to anemia, iron deficiency, and iron deficiency anemia) were conducted to assess heterogeneity of the differences among the active interventions and placebo. Analyses were performed with the use of Stata/SE software, version 15.1 (StataCorp).\n\n【35】Results\n-------\n\n【36】Trial Population\n----------------\n\n【37】Table 1. Household and Child Characteristics at Baseline.\n\n【38】Between July 6, 2017, and February 20, 2019, a total of 3300 children were enrolled and underwent randomization . Follow-up was completed on February 10, 2020; unblinding of the data was delayed because of restrictions related to coronavirus disease 2019.  Baseline household and child characteristics were similar across trial groups . At baseline, 1428 of 3188 children (44.8%) had anemia, 852 of 3080 (27.7%) had iron deficiency, and 594 of 3080 (19.3%) had iron deficiency anemia. Median adherence to iron syrup, multiple micronutrient powders, and placebo was 86.8%, 86.8%, and 87.9%, respectively ; 73.1% of children consumed at least 70% of their assigned active agent or placebo.\n\n【39】Child Development\n-----------------\n\n【40】Table 2. Efficacy of Iron Interventions Immediately after Completion of the 3-Month Regimen and at 9 Months after Completion (Intention-to-Treat Population).\n\n【41】Among the 3300 children who had undergone randomization, 2885 (87.4%) were assessed for the primary outcome immediately after completion of the assigned 3-month regimen. Loss to follow-up was similar among the trial groups. No apparent effect on the cognitive composite score was observed with iron syrup as compared with placebo (mean between-group difference in change in score from baseline, −0.30 points; 95% confidence interval \\[CI\\], −1.08 to 0.48) or with multiple micronutrient powders as compared with placebo (mean between-group difference in change in score from baseline, 0.23 points; 95% CI, −0.55 to 1.00) . No evidence of a difference in cognitive composite score was found with iron syrup as compared with multiple micronutrient powders (mean between-group difference in change in score from baseline, −0.52 points; 95% CI, −1.31 to 0.26). No apparent differences in cognitive composite score were observed among the trial groups at 9 months after completion of the assigned regimen . There were no apparent differences in baseline characteristics between the children with missing cognitive composite scores and those with at least 70% adherence to the assigned regimen . The absence of an evident effect of an active intervention on the primary outcome was confirmed with alternative models that accounted for missing data, baseline anemia, tester, and adherence .\n\n【42】Neither iron syrup nor multiple micronutrient powders improved motor or language development, child behavior (Wolke’s Behavioral Rating Scale), or temperament, either immediately after completion of the assigned regimen or at 9 months after completion . Measurements of child growth (length-for-age z score, weight-for-age z score, weight-for-length z score, and head circumference) did not differ significantly among the three groups either immediately after completion of the assigned regimen or at 9 months after completion , and these results were similar in additional analyses .\n\n【43】Hematologic Outcomes\n--------------------\n\n【44】The effects of the assigned regimens on hematologic outcomes immediately after completion of the assigned regimen and at 9 months after completion are shown in Table 2 . Among the 3300 participants who had undergone randomization, data on the venous hemoglobin level were available for 2094 (63.5%) immediately after completion of the assigned regimen and for 2104 (63.8%) at 9 months after completion. Three months of supplementation with iron syrup or multiple micronutrient powders resulted in a lower prevalence of anemia than placebo (prevalence ratio with iron syrup vs. placebo, 0.48 \\[95% CI, 0.41 to 0.56\\], and with multiple micronutrient powders vs. placebo, 0.52 \\[95% CI, 0.45 to 0.60\\]). The prevalence of anemia was similar in the iron-syrup group and the multiple-micronutrient-powder group, with a prevalence ratio of 0.92 (95% CI, 0.76 to 1.11). At 9 months after completion of the assigned regimen, the prevalence of anemia increased in all three trial groups but remained lower among the children who received iron syrup or multiple micronutrient powders than among those who received placebo (prevalence ratio with iron syrup vs. placebo, 0.71 \\[95% CI, 0.61 to 0.82\\], and with multiple micronutrient powders vs. placebo, 0.83 \\[95% CI, 0.72 to 0.95\\]). The prevalences of iron deficiency anemia and iron deficiency were also lower with either active intervention than with placebo . Further analyses confirmed these results .\n\n【45】Safety\n------\n\n【46】Table 3. Safety Outcomes during the Intervention Period (Safety Population).\n\n【47】The percentage of participants with at least one serious adverse event (hospitalization or death) was similar in the three trial groups, as was the percentage of participants who had unplanned clinic visits during the intervention period or immediately after completion of the assigned regimen . Parental reports of symptoms of infection (diarrhea, fever, or respiratory symptoms) were similar in the three trial groups, both during the intervention period and during the follow-up period. Tables S12 through S17 report the results of descriptive post hoc subgroup analyses of safety outcomes according to baseline status with respect to anemia, iron deficiency, and iron deficiency anemia. Neither iron intervention had an effect on the prevalence of corneal lesions (Bitot’s spots) .\n\n【48】Subgroup Analyses\n-----------------\n\n【49】Figure 1. Subgroup Analyses of the Treatment Effect on the Cognitive Composite Score Immediately after Completion of the Assigned Regimen According to Baseline Characteristics.\n\n【50】The cognitive composite scores on the Bayley Scales of Infant and Toddler Development, third edition, were analyzed in the intention-to-treat population with the use of a likelihood-based longitudinal data analysis model that adjusted for union and sex of the child and included subgroup-by-regimen and subgroup-by-visit interactions. The 95% confidence intervals were not adjusted for multiple comparisons. Anemia was defined as a hemoglobin level of less than 11 g per deciliter. Iron deficiency was defined as a ferritin level of less than 12 μg per liter or less than 30 μg per liter if the C-reactive protein level was higher than 5 mg per liter. Iron deficiency anemia was defined as concurrent anemia and iron deficiency. Stunting was defined as a length-for-age z score lower than −2. The median total score on the family care indicators tool was 13, on a scale from 0 to 42, with higher scores indicating more activities involving play and reading materials.  The median wealth index score was 0.49; households with a score below 0.49 comprised relatively poorer households, and those with a score above 0.49 relatively wealthier households. The wealth index is derived from an asset-based measure of a household’s living standard calculated from a principal component analysis. Food security was assessed with the use of the Household Food Insecurity Access Scale questionnaire; food-secure status was defined as an answer of “no” or “rarely” to the initial question regarding worry over the previous 4 weeks that the household would not have enough food and an answer of “no” to further questions regarding change in food availability or eating behaviors due to food access. MNPs denote multiple micronutrient powders.\n\n【51】The results of the prespecified subgroup analyses of the primary and key secondary outcomes are provided in Figure 1 and Table S19. There was no evidence of a subgroup effect on the cognitive composite score according to baseline status with respect to anemia or iron deficiency immediately after completion of the assigned regimen  or at 9 months after completion. The increases in hemoglobin and ferritin levels at completion of the assigned regimen were greater among the children who had anemia, iron deficiency, or iron deficiency anemia at baseline, and there was no evidence of a difference between the two iron interventions.\n\n【52】Discussion\n----------\n\n【53】In a rural, low-income, South Asian region where anemia in young children is a severe public health problem, 3 months of daily supplementation with iron syrup or multiple micronutrient powders in 8-month-old infants, as recommended in the WHO guidelines, did not have an effect on the primary outcome of child cognitive development, despite a markedly lower prevalence of anemia or iron deficiency in the active intervention groups than in the placebo group. The iron interventions were not associated with evidence of immediate or sustained improvements in other measures of child development, behavior, temperament, or growth. Reductions in anemia were partly sustained at 9 months after completion of the assigned regimen. Neither intervention was associated with an increase in parental reports of symptoms of infection or clinic visits or hospitalizations, and each led to a similar short-term reduction in the prevalence of anemia or iron deficiency.\n\n【54】The key rationale for preventive iron interventions in young children is the presumed benefit with respect to functional health outcomes,  particularly child development and growth  ; this presumption is based on observational studies that have consistently linked anemia to suboptimal child cognitive development.  However, meta-analyses of randomized, controlled trials evaluating iron supplementation revealed limited and inconclusive data with regard to functional outcomes.  Individual trials were underpowered,  involved patient groups (not populations),  or had an open-label design,  limitations that the current trial was designed to overcome. Given that iron interventions produced sustained improvements in the hemoglobin level and iron stores but did not improve developmental, behavioral, or growth outcomes in the immediate or medium term, our results address this knowledge gap. Our conclusions were consistent across all additional primary intention-to-treat analyses.\n\n【55】We administered the iron syrup and multiple micronutrient powders for 3 months, as recommended by the WHO. Although a longer duration of supplementation may have further increased iron stores, it is uncertain whether this would have had an effect on functional outcomes, because iron deficiency anemia was virtually eliminated after 3 months. Previous studies that involved longer interventions (e.g., 6 months  and 18 months  ) have not shown benefits with respect to cognitive development. In addition, a longer intervention may have exacerbated the risk of diarrhea. Future studies may explore whether prolonged iron interventions in infants can have a benefit with regard to functional outcomes; alternatively, improvement of neurodevelopment in children may require an earlier intervention (e.g., antenatal supplementation). \n\n【56】There are concerns that iron interventions may increase risks of infections, such as those that cause diarrhea.  The rates of parent-reported diarrhea and unplanned clinic visits for diarrhea were not higher in the groups that received iron syrup or multiple micronutrient powders than in the placebo group. Although the subgroup analyses indicated an increased risk of unplanned clinic visits because of diarrhea in nonanemic or non–iron-deficient children while they were receiving iron syrup or multiple micronutrient powders, these findings are not conclusive because the analyses were post hoc, did not include adjustment for multiple comparisons, and showed no significant difference between subgroups.\n\n【57】Our data showed that iron syrup and multiple micronutrient powders were associated with similar adherence, had similar effects in reducing the prevalences of anemia and iron deficiency, and did not differ significantly with respect to functional or infection-related outcomes. The prevalences of anemia, iron deficiency, and iron deficiency anemia were lower among the children in the active intervention groups than among those in the placebo group for up to 9 months after completion of the assigned regimen, although the prevalences in all three groups had increased from the time immediately after completion of the intervention. Repeated cycles of the intervention, which is recommended for multiple micronutrient powders  but not for iron supplements (drops or syrup), may be needed to sustain hematologic responses.\n\n【58】We did not identify an effect on developmental outcomes in subgroups defined according to baseline anemia, iron deficiency, and iron deficiency anemia. These findings inform the rationale for screening and therapy for asymptomatic iron deficiency in children in clinical practice. \n\n【59】The strengths of our trial were that it was designed with cognitive development as the primary outcome, was powered to detect a small effect size, minimized the risk of bias, and ensured high interobserver concordance between assessors. The limitations of our trial were that 36 to 37% of the infants at each postbaseline visit did not have a measurement of the venous hemoglobin concentration for reasons such as unwillingness of the parents to allow collection of a venous blood sample, which limited the data used in the secondary hematologic analyses but not the data used for the primary or other functional outcome analyses. We found no important differences in baseline characteristics between those for whom consent to a blood test was provided and those for whom consent was not provided. Per-protocol analyses were adjusted for key prognostic baseline factors, as were the intention-to-treat analyses; however, bias due to unmeasured postrandomization factors associated with adherence is possible.\n\n【60】In our trial, 3 months of daily supplementation with iron syrup or multiple micronutrient powders in 8-month-old children reduced the prevalence of anemia but did not improve cognitive development or other functional health outcomes immediately after completion of the regimen or at 9 months after completion.", "index": 456, "show": true, "start": 456, "end": 499, "province": ["文本干净度", "无关文本"], "isEdit": false}]}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-14 00:22:16", "grab_time": "2024-08-13 23:53:22"}
{"id": 2234470, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "96afaeef-3473-4188-b73a-4a45ba5216ad", "title": "Primary Retinal Detachment", "text": "【0】Primary Retinal Detachment\nA 57-year-old man noted flashing lights in his right eye, followed 2 days later by a cluster of dark floaters that mildly interfered with his vision. Over the course of the next week, he noted a progressive loss of the nasal visual field in that eye, with an eventual striking loss of central acuity that prompted him to seek ophthalmologic evaluation. Examination of the fundus with the pupil dilated showed a retinal detachment involving the temporal retina, including the macula. How should his case be managed?", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 17:43:37", "endTime": "2024/08/13 17:43:57", "cost": 19.776}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 01:43:57", "grab_time": "2024-08-13 01:43:37"}
{"id": 2234469, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "d09bb077-5423-4706-be15-b97f7545fdb2", "title": "Blood-Pressure Targets in Comatose Survivors of Cardiac Arrest", "text": "【0】Blood-Pressure Targets in Comatose Survivors of Cardiac Arrest\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Evidence to support the choice of blood-pressure targets for the treatment of comatose survivors of out-of-hospital cardiac arrest who are receiving intensive care is limited.\n\n【3】Methods\n-------\n\n【4】Download a PDF of the Research Summary .\n\n【5】In a double-blind, randomized trial with a 2-by-2 factorial design, we evaluated a mean arterial blood-pressure target of 63 mm Hg as compared with 77 mm Hg in comatose adults who had been resuscitated after an out-of-hospital cardiac arrest of presumed cardiac cause; patients were also assigned to one of two oxygen targets (reported separately). The primary outcome was a composite of death from any cause or hospital discharge with a Cerebral Performance Category (CPC) of 3 or 4 within 90 days (range, 0 to 5, with higher categories indicating more severe disability; a category of 3 or 4 indicates severe disability or coma). Secondary outcomes included neuron-specific enolase levels at 48 hours, death from any cause, scores on the Montreal Cognitive Assessment (range, 0 to 30, with higher scores indicating better cognitive ability) and the modified Rankin scale (range, 0 to 6, with higher scores indicating greater disability) at 3 months, and the CPC at 3 months.\n\n【6】Results\n-------\n\n【7】A total of 789 patients were included in the analysis (393 in the high-target group and 396 in the low-target group). A primary-outcome event occurred in 133 patients (34%) in the high-target group and in 127 patients (32%) in the low-target group (hazard ratio, 1.08; 95% confidence interval \\[CI\\], 0.84 to 1.37; P=0.56). At 90 days, 122 patients (31%) in the high-target group and 114 patients (29%) in the low-target group had died (hazard ratio, 1.13; 95% CI, 0.88 to 1.46). The median CPC was 1 (interquartile range, 1 to 5) in both the high-target group and the low-target group; the corresponding median modified Rankin scale scores were 1 (interquartile range, 0 to 6) and 1 (interquartile range, 0 to 6), and the corresponding median Montreal Cognitive Assessment scores were 27 (interquartile range, 24 to 29) and 26 (interquartile range, 24 to 29). The median neuron-specific enolase level at 48 hours was also similar in the two groups. The percentages of patients with adverse events did not differ significantly between the groups.\n\n【8】Conclusions\n-----------\n\n【9】Targeting a mean arterial blood pressure of 77 mm Hg or 63 mm Hg in patients who had been resuscitated from cardiac arrest did not result in significantly different percentages of patients dying or having severe disability or coma. \n\n【10】Introduction\n------------\n\n【11】 QUICK TAKE  \nBP Targets in Comatose Cardiac Arrest Survivors  \n\n【12】A central part of goal-directed postresuscitation care is maintaining adequate perfusion pressure, but evidence for specific blood-pressure targets is limited.  Blood pressure is actively managed as part of most intensive care protocols to deliver sufficient perfusion pressure to vital organs, such as the brain, heart, and kidneys.  However, after a cardiac arrest, patients often have underlying or concomitant heart disease, and lowering the afterload may facilitate cardiac recovery and possibly survival.  In addition, vasoactive drugs, including catecholamines, are used to keep the mean arterial blood pressure above 65 mm Hg in the majority of comatose patients who have been resuscitated after an out-of-hospital cardiac arrest,  although vasopressor therapy may have adverse effects. \n\n【13】Three small randomized trials have compared the efficacy of two different blood-pressure targets with the use of surrogate end points.  The results of the trials were neutral, and none were powered to evaluate clinical end points and safety. \n\n【14】We recently developed a method for performing double-blind prospective trials of blood-pressure targets in patients in intensive care  and have used this method in the Blood Pressure and Oxygenation Targets in Post Resuscitation Care (BOX) trial. We tested whether a higher (77 mm Hg) or lower (63 mm Hg) target mean arterial blood pressure would be superior in preventing death or severe anoxic brain injury in comatose survivors of out-of-hospital cardiac arrest.\n\n【15】Methods\n-------\n\n【16】Trial Design\n------------\n\n【17】In the BOX trial, an investigator-initiated, dual-center, randomized trial with a 2-by-2 factorial design, we assigned comatose patients who had been resuscitated after an out-of-hospital cardiac arrest to be treated to meet one of two blood-pressure targets (a double-blind intervention) and to undergo restrictive oxygenation or liberal oxygenation (an open-label intervention) while the patient remained in the intensive care unit (ICU). Randomization was performed from March 2017 through December 2021 at two tertiary cardiac arrest centers in Denmark with the use of a Web-based system, random permuted blocks of sizes 2, 4, and 6, and stratification according to randomization site. Furthermore, patients underwent a subordinate randomization to undergo device-based fever control after the first 24 hours. The results for the oxygen-target intervention are reported separately,  and the results of the assessment of fever control are not included.\n\n【18】Danish legislation permits the immediate inclusion of patients who are unable to provide consent in clinical trials if delayed proxy consent is obtained from a legal representative, most often a relative, and a medical doctor with no relation to the trial. Informed consent from the patient was obtained if the patient regained consciousness, and if the patient died, the need for consent was waived. The protocol  was approved by the Regional Ethics Committee of the Capital Region of Denmark before initiation of the trial. The trial was designed and overseen by the steering committee , data were collected by the authors and analyzed by the first two authors, and the first author wrote the first draft of the manuscript. The authors vouch for the accuracy and completeness of the data and for the fidelity of the trial to the protocol. Additional details of the trial design have been published previously. \n\n【19】Patients\n--------\n\n【20】Adult patients (≥18 years of age) who had been resuscitated after an out-of-hospital cardiac arrest with a presumed cardiac cause were eligible for inclusion if they had a sustained return of spontaneous circulation (i.e., no chest compressions for >20 minutes) and remained comatose (i.e., were not able to obey verbal commands) on arrival at the hospital. Key exclusion criteria included unwitnessed asystole and suspected acute intracranial bleeding or stroke. A complete list of all inclusion and exclusion criteria is provided in the Supplementary Appendix .\n\n【21】Treatment Protocol\n------------------\n\n【22】Patients were treated in accordance with guidelines at the discretion of the treating physician. For the duration of the trial, all patients received temperature control to maintain a temperature of 36°C for 24 hours in accordance with guidelines for comatose patients who had had an out-of-hospital cardiac arrest.  Patients were receiving mechanical ventilation and were sedated, primarily with the use of propofol and fentanyl. Temperature control was achieved with surface cooling (CritiCool and Allon, Belmont Medical Technologies) or with intravenous devices (Thermogard XP and Cool Line Catheter, Zoll). After completion of the 24-hour period of temperature control, the core temperature was gradually increased to normothermia with a rewarming rate of less than 0.5°C per hour, and sedation was tapered. Assessment of neurologic outcomes was performed by the attending physician in accordance with guidelines. \n\n【23】Trial Intervention\n------------------\n\n【24】Clinical staff, investigators, patients, and outcome assessors were unaware of the assigned blood-pressure targets. For all enrolled patients, invasive blood-pressure monitoring with a patient-specific blood-pressure module (M1006B Invasive Blood Pressure Module, Philips) was used for as long as the patient underwent invasive blood-pressure monitoring in the ICU. These modules had been modified for trial use by adjusting the internal calibration to report a blood pressure that was either 10% higher or 10% lower than the actual blood pressure, depending on the assigned blood-pressure target. Thus, by targeting a mean arterial blood pressure of 70 mm Hg in all patients, half the patients would have an actual target mean arterial blood pressure of 63 mm Hg (low-target group) and the other half would have a target mean arterial blood pressure of 77 mm Hg (high-target group).\n\n【25】The offset of the blood-pressure modules was performed at a Core Laboratory at the Technical Department, Rigshospitalet, which had no other part in the trial execution. The patients underwent randomization as soon as possible after arrival at the hospital, usually in the ICU and before invasive monitoring of the systemic arterial pressure was established. After randomization, systemic arterial blood pressure was measured with the trial-specific module only. Other invasive pressure measurements (i.e., central venous pressure or pulmonary artery catheter measurements) were obtained without blinding with modules that had no offset of calibration.\n\n【26】The protocol provided a recommendation for achieving the mean arterial blood pressure of 70 mm Hg in a three-stage approach: volume resuscitation to a central venous pressure of 10 mm Hg, norepinephrine infusion, and the addition of a dopamine infusion for a maximal dose of 10 μg per kilogram of body weight per minute, if needed. Information on the use of vasoactive drugs, including doses, was obtained from electronic ICU databases, and the maximal dose for a given period was captured. The total amount of pharmacologic circulatory support was quantified as the vasopressor–inotropic score (higher scores indicate a higher degree of support)  .\n\n【27】Outcome Measures\n----------------\n\n【28】The primary outcome was a composite of death from any cause or discharge from the hospital with a Cerebral Performance Category (CPC)  of 3 or 4, indicating severe disability or a coma or vegetative state, within 90 days after randomization (categories range from 1 \\[no symptoms\\] to 5 \\[death\\]). For patients who were discharged alive with a CPC of 3 or 4, events were recorded at the time of discharge. Secondary outcomes included death from any cause within 90 days, time to renal-replacement therapy, neuron-specific enolase levels at 48 hours after randomization, the Montreal Cognitive Assessment score  at 3 months, the modified Rankin scale score at 3 months, and the CPC at 3 months.  Scores on the modified Rankin scale range from 0 to 6, with 0 indicating no symptoms, 1 no clinically significant disability, 2 slight disability, 3 moderate disability, 4 moderately severe disability, 5 severe disability, and 6 death. The Montreal Cognitive Assessment tests different types of cognitive abilities and assigns a score between 0 and 30, with a score of 26 or higher being normal. Assessment of the CPC, the modified Rankin scale score, and the Montreal Cognitive Assessment score was performed by trained research personnel. Because of coronavirus disease 2019 (Covid-19) pandemic restrictions, these assessments were performed in a telephone interview or through review of hospital charts for some patients, which excluded the use of the Montreal Cognitive Assessment in these patients.\n\n【29】The adverse events included in this report are bleeding, infection, arrhythmia, electrolyte or metabolic abnormalities, acute kidney injury with renal-replacement therapy, and seizures.  Plasma levels of neuron-specific enolase in patients who were alive at 48 hours were determined by means of electrochemiluminescence (Roche Diagnostics) and with a Cobas analyzer system (Roche Diagnostics) in accordance with the manufacturer’s instructions.\n\n【30】Statistical Analysis\n--------------------\n\n【31】Our previous data indicate that 6-month mortality among hospitalized comatose patients who have been resuscitated after an out-of-hospital cardiac arrest is 33%.  For the estimation of sample size, we assumed that there was no interaction with the oxygenation intervention. Samples of 732 or 846 patients would provide a power of 0.8 or 0.9, respectively, to detect mortality of 28% in one blood-pressure target group and 38% in the other, under the assumption of a two-sided alpha level of 0.05. Therefore, inclusion of a total of 800 patients was planned, with follow-up for all patients continuing until 3 months after the final patient had been enrolled. Global type I error for the trial was 0.05, and the two-sided alpha level for the analysis of the primary outcome was 0.0471 after correction for the two planned interim analyses. The mean between-group difference in blood pressure, norepinephrine dose, and vasopressor–inotropic score during the period from 2 to 48 hours after randomization was calculated in a repeated-measures variance component model.\n\n【32】The primary outcome and the secondary outcomes relating to death from any cause and receipt of renal-replacement therapy were adjusted for site in a proportional-hazards model. The assumption of proportional hazards was fulfilled. Because the statistical analysis plan did not include a provision for correcting for multiplicity, the results for efficacy outcomes other than the primary outcome are reported as point estimates and 95% confidence intervals, and the intervals should not be used in place of a hypothesis test. Event-free survival was assessed in a Kaplan–Meier analysis.\n\n【33】In prespecified subgroup analyses of the primary outcome, we evaluated subgroups based on sex, median age, site, and status with respect to known chronic obstructive pulmonary disease (COPD), hypertension (receipt of antihypertensive drugs) or renal disease (glomerular filtration rate <30 ml per minute per 1.73 m <sup>2 </sup> of body-surface area or current renal-replacement therapy), shockable primary rhythm, and acute ST-segment elevation myocardial infarction. The statistical analysis plan included an analysis of Montreal Cognitive Assessment scores in which missing scores and scores for deceased patients were included as the lowest score measured in the trial population (i.e., 15).  A two-sided P value of less than 0.05 was considered to indicate statistical significance. Statistical analyses were performed with the use of SAS Enterprise statistical software, version 3.8 (SAS Institute).\n\n【34】Results\n-------\n\n【35】Patients\n--------\n\n【36】Table 1. Demographic and Clinical Characteristics of the Patients.\n\n【37】A total of 802 patients were enrolled in the trial from March 2017 through December 2021. The screening and inclusion of patients is shown in Figure S1 in the Supplementary Appendix . Consent was withdrawn for 12 patients (use of data was not allowed), and 1 patient underwent randomization twice, leaving 789 patients in the trial population. Four patients died before the intervention was initiated, and in 2 patients the blood-pressure intervention was stopped by the treating physician because of hemodynamic instability; all 6 of these patients remained in the analyses. The median time from cardiac arrest to randomization was 146 minutes (interquartile range, 113 to 187). Two non-Danish patients were transferred and lost to follow-up; data for these patients were censored on the day when the modified Rankin scale score and CPC were recorded (on day 12 for one patient and on day 13 for the other). The baseline characteristics of the patients were well balanced in the two blood-pressure target groups .\n\n【38】Blood-Pressure Intervention\n---------------------------\n\n【39】Figure 1. Blood Pressure and Vasopressor Use over the First 48 Hours.\n\n【40】Panel A shows blood-pressure target assignments and mean blood pressure during the first 48 hours after randomization. Panels B and C show norepinephrine doses  and vasopressor–inotropic scores  during the first 48 hours after randomization. The before-randomization (BR) time point is the first available blood-pressure value before randomization, and time 0 is the time of randomization (i.e., the first measurement obtained with the trial-specific blood-pressure module). The high blood-pressure target was 77 mm Hg, and the low blood-pressure target was 63 mm Hg. Values shown are means, and error bars indicate the standard deviation. During the period from 2 to 48 hours after randomization, the mean between-group difference in blood pressure was 10.5 mm Hg (95% CI, 9.9 to 11.2), the mean difference in norepinephrine dose was 0.038 μg per kilogram per minute (95% CI, 0.026 to 0.049), and the mean difference in vasopressor–inotropic score was 3.5 points (95% CI, 2.4 to 4.6). A definition of the vasopressor–inotropic score is provided in the Supplementary Appendix ; higher scores indicate a higher degree of pharmacologic circulatory support.\n\n【41】Separation of the blood-pressure values for the high-target and low-target groups was apparent from the first value measured by the offset blood-pressure module, with a mean difference of 10.7 mm Hg (95% confidence interval \\[CI\\], 10.0 to 11.4) between the groups. The norepinephrine dose and the vasopressor–inotropic score were higher in the high-target group than in the low-target group .\n\n【42】Outcomes and Adverse Events\n---------------------------\n\n【43】Table 2. Outcomes and Adverse Events. Figure 2.  Figure 2. Kaplan–Meier Analysis of the Primary Outcome.\n\n【44】Shown is a plot of the probability of survival free from death from any cause or discharge from hospital with a Cerebral Performance Category score of 3 or 4 up to 90 days after randomization. Data are for the 789 patients in the intention-to-treat population. The inset shows the same data on an enlarged x axis (truncated at 15 days after randomization).Figure 3.  Figure 3. Subgroup Analysis of the Primary Outcome.\n\n【45】Data are for prespecified subgroup analyses of the primary outcome (death from any cause or discharge from the hospital with a Cerebral Performance Category score of 3 or 4). COPD denotes chronic obstructive pulmonary disease, and STEMI ST-segment elevation myocardial infarction.\n\n【46】At 90 days, 133 patients (34%) in the high-target group and 127 patients (32%) in the low-target group had been discharged from the hospital with a CPC of 3 or 4 or had died (hazard ratio, 1.08; 95% CI, 0.84 to 1.37; P=0.56) . A total of 24 patients (3%) had been discharged from the hospital with a CPC of 3 or 4: 11 in the high-target group and 13 in the low-target group. No interaction with the oxygen-target intervention was found (P=0.67). The results appeared to be consistent across most of the prespecified subgroups . A total of 122 of 393 patients (31%) in the high-target group and 114 of 396 patients (29%) in the low-target group died within 90 days . Renal-replacement therapy was initiated within the first 5 days in 41 patients (10%) in the high-target group and 40 patients (10%) in the low-target group (hazard ratio, 1.03; 95% CI, 0.66 to 1.59).\n\n【47】The Montreal Cognitive Assessment score was available for 359 of the 552 patients (65%) who were alive at 3 months. Data on the CPC, modified Rankin scale score, and Montreal Cognitive Assessment score at 3 months and on plasma levels of neuron-specific enolase at 48 hours are summarized in Table 2 . The distributions of results on the CPC and modified Rankin scale are shown in Figure S4. Data on median neuron-specific enolase levels were available for 79% of the patients; the median level was 18 μg per liter (interquartile range, 11 to 37) in the high-target group and 18 μg per liter (interquartile range, 11 to 34) in the low-target group. No significant differences were found in the percentages of patients with adverse events, including infection, arrhythmia, bleeding, and seizures .\n\n【48】Discussion\n----------\n\n【49】In this double-blind, randomized trial comparing two clinically relevant mean arterial blood-pressure targets, we found no significant difference in the percentage of patients who died or were discharged from the hospital with a poor neurologic outcome (CPC of 3 or 4) within 90 days. The results were consistent in the prespecified subgroups.\n\n【50】Our results add to those of two smaller, open-label trials of blood-pressure targets in postresuscitation care in which findings on magnetic resonance imaging of the head  and levels of neuron-specific enolase were used as markers of the extent of neurologic brain injury.  In these two trials, mean pressures of approximately 70 to 74 mm Hg in the lower target range and 84 to 87 mm Hg in the higher target range were attained, and the neuron-specific enolase levels were 20 to 22 μg per liter in one trial  and 42 to 59 μg per liter in the other,  as compared with 35 to 36 μg per liter in the present trial. At 6 months, 70%  and 45%  of the patients in the two trials were alive, as compared with 67% of the patients in the current trial.\n\n【51】Perfusion of the brain depends on the mean arterial pressure and is controlled through cerebrovascular autoregulation to ensure adequate perfusion at varying blood pressures. After an out-of-hospital cardiac arrest, this delicate balance between flow and pressure may be disrupted, with lower perfusion at a given pressure during the first 12 to 24 hours after the cardiac arrest.  Observational data suggest that the mean arterial blood pressure that should be used to secure flow to the postanoxic brain is at least 75 mm Hg,  whereas guidelines suggest that mean arterial pressure should be maintained above 65 mm Hg.  Maintenance of a higher mean arterial pressure in the postresuscitation period may be warranted in patients with preexisting hypertension.  In patients with sepsis, targeting a higher blood pressure has been associated with lower rates of dialysis among those with preexisting hypertension.  Our results do not suggest a benefit of a higher blood-pressure target in the subgroup of patients with known hypertension.\n\n【52】The interaction of preexisting COPD favoring a high blood-pressure target is likely to be spurious and should be interpreted with great caution. In addition, as compared with the lower target, the higher blood-pressure target in our trial was not associated with an increased risk of adverse events. In contrast, a higher blood pressure in patients with sepsis has previously been associated with increased risk of arrhythmia. \n\n【53】Our trial has limitations. The mean difference in blood pressure between the groups was 10.7 mm Hg and therefore was lower than the expected value (14 mm Hg). However, since a clinically significant separation in blood pressure was observed between the groups, and the doses of norepinephrine and vasopressor were substantially higher in the high-target group than in the low-target group, we believe that the trial provides strong evidence for an absence of clinically important differences in the assessed outcomes, although our findings cannot be extrapolated to blood-pressure targets that are higher or lower than those used in this trial. Although the hypothesized treatment effect may be seen as overly optimistic, given the consistency of the results in the two groups, the risk of type 2 error seems low.\n\n【54】Follow-up in our trial was challenging as a result of Covid-19 restrictions, including a temporary pause in research-related follow-up visits and a subsequent reluctance among patients to visit a hospital. As a result, the number of patients available for follow-up visits and assessment of cognitive testing was lower than expected. The number of blood samples in the biobank was also lower than expected, mainly because of delayed initiation of sampling for the biobank at one site.\n\n【55】A strength of our trial is that the results were consistent across the objective outcomes we examined (death, neurologic outcomes, and laboratory findings). Furthermore, our sample size, which was seven times as large as those in previous trials,  and the small number of patients who did not meet screening requirements, the consistency of the eligibility criteria with those used in previous trials, and the double-blinded intervention increase the generalizability of our results and reduce the risk of bias. However, the trial was conducted in only two high-volume cardiac arrest centers and included a population of patients with a high prevalence of acute coronary syndrome and a relatively good prognosis based on risk factors on arrival at the hospital. These aspects of the trial may affect the generalizability of our results.\n\n【56】In this trial, targeting a mean arterial blood pressure of 77 mm Hg as compared with 63 mm Hg in patients who had been resuscitated after an out-of-hospital cardiac arrest did not result in a significant difference in the percentage of patients who died or had severe disability or coma.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "【4】Download a PDF of the Research Summary .", "content": "【0】Blood-Pressure Targets in Comatose Survivors of Cardiac Arrest\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Evidence to support the choice of blood-pressure targets for the treatment of comatose survivors of out-of-hospital cardiac arrest who are receiving intensive care is limited.\n\n【3】Methods\n-------\n\n【4】Download a PDF of the Research Summary .\n\n【5】In a double-blind, randomized trial with a 2-by-2 factorial design, we evaluated a mean arterial blood-pressure target of 63 mm Hg as compared with 77 mm Hg in comatose adults who had been resuscitated after an out-of-hospital cardiac arrest of presumed cardiac cause; patients were also assigned to one of two oxygen targets (reported separately). The primary outcome was a composite of death from any cause or hospital discharge with a Cerebral Performance Category (CPC) of 3 or 4 within 90 days (range, 0 to 5, with higher categories indicating more severe disability; a category of 3 or 4 indicates severe disability or coma). Secondary outcomes included neuron-specific enolase levels at 48 hours, death from any cause, scores on the Montreal Cognitive Assessment (range, 0 to 30, with higher scores indicating better cognitive ability) and the modified Rankin scale (range, 0 to 6, with higher scores indicating greater disability) at 3 months, and the CPC at 3 months.\n\n【6】Results\n-------\n\n【7】A total of 789 patients were included in the analysis (393 in the high-target group and 396 in the low-target group). A primary-outcome event occurred in 133 patients (34%) in the high-target group and in 127 patients (32%) in the low-target group (hazard ratio, 1.08; 95% confidence interval \\[CI\\], 0.84 to 1.37; P=0.56). At 90 days, 122 patients (31%) in the high-target group and 114 patients (29%) in the low-target group had died (hazard ratio, 1.13; 95% CI, 0.88 to 1.46). The median CPC was 1 (interquartile range, 1 to 5) in both the high-target group and the low-target group; the corresponding median modified Rankin scale scores were 1 (interquartile range, 0 to 6) and 1 (interquartile range, 0 to 6), and the corresponding median Montreal Cognitive Assessment scores were 27 (interquartile range, 24 to 29) and 26 (interquartile range, 24 to 29). The median neuron-specific enolase level at 48 hours was also similar in the two groups. The percentages of patients with adverse events did not differ significantly between the groups.\n\n【8】Conclusions\n-----------\n\n【9】Targeting a mean arterial blood pressure of 77 mm Hg or 63 mm Hg in patients who had been resuscitated from cardiac arrest did not result in significantly different percentages of patients dying or having severe disability or coma. \n\n【10】Introduction\n------------\n\n【11】 QUICK TAKE  \nBP Targets in Comatose Cardiac Arrest Survivors  \n\n【12】A central part of goal-directed postresuscitation care is maintaining adequate perfusion pressure, but evidence for specific blood-pressure targets is limited.  Blood pressure is actively managed as part of most intensive care protocols to deliver sufficient perfusion pressure to vital organs, such as the brain, heart, and kidneys.  However, after a cardiac arrest, patients often have underlying or concomitant heart disease, and lowering the afterload may facilitate cardiac recovery and possibly survival.  In addition, vasoactive drugs, including catecholamines, are used to keep the mean arterial blood pressure above 65 mm Hg in the majority of comatose patients who have been resuscitated after an out-of-hospital cardiac arrest,  although vasopressor therapy may have adverse effects. \n\n【13】Three small randomized trials have compared the efficacy of two different blood-pressure targets with the use of surrogate end points.  The results of the trials were neutral, and none were powered to evaluate clinical end points and safety. \n\n【14】We recently developed a method for performing double-blind prospective trials of blood-pressure targets in patients in intensive care  and have used this method in the Blood Pressure and Oxygenation Targets in Post Resuscitation Care (BOX) trial. We tested whether a higher (77 mm Hg) or lower (63 mm Hg) target mean arterial blood pressure would be superior in preventing death or severe anoxic brain injury in comatose survivors of out-of-hospital cardiac arrest.\n\n【15】Methods\n-------\n\n【16】Trial Design\n------------\n\n【17】In the BOX trial, an investigator-initiated, dual-center, randomized trial with a 2-by-2 factorial design, we assigned comatose patients who had been resuscitated after an out-of-hospital cardiac arrest to be treated to meet one of two blood-pressure targets (a double-blind intervention) and to undergo restrictive oxygenation or liberal oxygenation (an open-label intervention) while the patient remained in the intensive care unit (ICU). Randomization was performed from March 2017 through December 2021 at two tertiary cardiac arrest centers in Denmark with the use of a Web-based system, random permuted blocks of sizes 2, 4, and 6, and stratification according to randomization site. Furthermore, patients underwent a subordinate randomization to undergo device-based fever control after the first 24 hours. The results for the oxygen-target intervention are reported separately,  and the results of the assessment of fever control are not included.\n\n【18】Danish legislation permits the immediate inclusion of patients who are unable to provide consent in clinical trials if delayed proxy consent is obtained from a legal representative, most often a relative, and a medical doctor with no relation to the trial. Informed consent from the patient was obtained if the patient regained consciousness, and if the patient died, the need for consent was waived. The protocol  was approved by the Regional Ethics Committee of the Capital Region of Denmark before initiation of the trial. The trial was designed and overseen by the steering committee , data were collected by the authors and analyzed by the first two authors, and the first author wrote the first draft of the manuscript. The authors vouch for the accuracy and completeness of the data and for the fidelity of the trial to the protocol. Additional details of the trial design have been published previously. \n\n【19】Patients\n--------\n\n【20】Adult patients (≥18 years of age) who had been resuscitated after an out-of-hospital cardiac arrest with a presumed cardiac cause were eligible for inclusion if they had a sustained return of spontaneous circulation (i.e., no chest compressions for >20 minutes) and remained comatose (i.e., were not able to obey verbal commands) on arrival at the hospital. Key exclusion criteria included unwitnessed asystole and suspected acute intracranial bleeding or stroke. A complete list of all inclusion and exclusion criteria is provided in the Supplementary Appendix .\n\n【21】Treatment Protocol\n------------------\n\n【22】Patients were treated in accordance with guidelines at the discretion of the treating physician. For the duration of the trial, all patients received temperature control to maintain a temperature of 36°C for 24 hours in accordance with guidelines for comatose patients who had had an out-of-hospital cardiac arrest.  Patients were receiving mechanical ventilation and were sedated, primarily with the use of propofol and fentanyl. Temperature control was achieved with surface cooling (CritiCool and Allon, Belmont Medical Technologies) or with intravenous devices (Thermogard XP and Cool Line Catheter, Zoll). After completion of the 24-hour period of temperature control, the core temperature was gradually increased to normothermia with a rewarming rate of less than 0.5°C per hour, and sedation was tapered. Assessment of neurologic outcomes was performed by the attending physician in accordance with guidelines. \n\n【23】Trial Intervention\n------------------\n\n【24】Clinical staff, investigators, patients, and outcome assessors were unaware of the assigned blood-pressure targets. For all enrolled patients, invasive blood-pressure monitoring with a patient-specific blood-pressure module (M1006B Invasive Blood Pressure Module, Philips) was used for as long as the patient underwent invasive blood-pressure monitoring in the ICU. These modules had been modified for trial use by adjusting the internal calibration to report a blood pressure that was either 10% higher or 10% lower than the actual blood pressure, depending on the assigned blood-pressure target. Thus, by targeting a mean arterial blood pressure of 70 mm Hg in all patients, half the patients would have an actual target mean arterial blood pressure of 63 mm Hg (low-target group) and the other half would have a target mean arterial blood pressure of 77 mm Hg (high-target group).\n\n【25】The offset of the blood-pressure modules was performed at a Core Laboratory at the Technical Department, Rigshospitalet, which had no other part in the trial execution. The patients underwent randomization as soon as possible after arrival at the hospital, usually in the ICU and before invasive monitoring of the systemic arterial pressure was established. After randomization, systemic arterial blood pressure was measured with the trial-specific module only. Other invasive pressure measurements (i.e., central venous pressure or pulmonary artery catheter measurements) were obtained without blinding with modules that had no offset of calibration.\n\n【26】The protocol provided a recommendation for achieving the mean arterial blood pressure of 70 mm Hg in a three-stage approach: volume resuscitation to a central venous pressure of 10 mm Hg, norepinephrine infusion, and the addition of a dopamine infusion for a maximal dose of 10 μg per kilogram of body weight per minute, if needed. Information on the use of vasoactive drugs, including doses, was obtained from electronic ICU databases, and the maximal dose for a given period was captured. The total amount of pharmacologic circulatory support was quantified as the vasopressor–inotropic score (higher scores indicate a higher degree of support)  .\n\n【27】Outcome Measures\n----------------\n\n【28】The primary outcome was a composite of death from any cause or discharge from the hospital with a Cerebral Performance Category (CPC)  of 3 or 4, indicating severe disability or a coma or vegetative state, within 90 days after randomization (categories range from 1 \\[no symptoms\\] to 5 \\[death\\]). For patients who were discharged alive with a CPC of 3 or 4, events were recorded at the time of discharge. Secondary outcomes included death from any cause within 90 days, time to renal-replacement therapy, neuron-specific enolase levels at 48 hours after randomization, the Montreal Cognitive Assessment score  at 3 months, the modified Rankin scale score at 3 months, and the CPC at 3 months.  Scores on the modified Rankin scale range from 0 to 6, with 0 indicating no symptoms, 1 no clinically significant disability, 2 slight disability, 3 moderate disability, 4 moderately severe disability, 5 severe disability, and 6 death. The Montreal Cognitive Assessment tests different types of cognitive abilities and assigns a score between 0 and 30, with a score of 26 or higher being normal. Assessment of the CPC, the modified Rankin scale score, and the Montreal Cognitive Assessment score was performed by trained research personnel. Because of coronavirus disease 2019 (Covid-19) pandemic restrictions, these assessments were performed in a telephone interview or through review of hospital charts for some patients, which excluded the use of the Montreal Cognitive Assessment in these patients.\n\n【29】The adverse events included in this report are bleeding, infection, arrhythmia, electrolyte or metabolic abnormalities, acute kidney injury with renal-replacement therapy, and seizures.  Plasma levels of neuron-specific enolase in patients who were alive at 48 hours were determined by means of electrochemiluminescence (Roche Diagnostics) and with a Cobas analyzer system (Roche Diagnostics) in accordance with the manufacturer’s instructions.\n\n【30】Statistical Analysis\n--------------------\n\n【31】Our previous data indicate that 6-month mortality among hospitalized comatose patients who have been resuscitated after an out-of-hospital cardiac arrest is 33%.  For the estimation of sample size, we assumed that there was no interaction with the oxygenation intervention. Samples of 732 or 846 patients would provide a power of 0.8 or 0.9, respectively, to detect mortality of 28% in one blood-pressure target group and 38% in the other, under the assumption of a two-sided alpha level of 0.05. Therefore, inclusion of a total of 800 patients was planned, with follow-up for all patients continuing until 3 months after the final patient had been enrolled. Global type I error for the trial was 0.05, and the two-sided alpha level for the analysis of the primary outcome was 0.0471 after correction for the two planned interim analyses. The mean between-group difference in blood pressure, norepinephrine dose, and vasopressor–inotropic score during the period from 2 to 48 hours after randomization was calculated in a repeated-measures variance component model.\n\n【32】The primary outcome and the secondary outcomes relating to death from any cause and receipt of renal-replacement therapy were adjusted for site in a proportional-hazards model. The assumption of proportional hazards was fulfilled. Because the statistical analysis plan did not include a provision for correcting for multiplicity, the results for efficacy outcomes other than the primary outcome are reported as point estimates and 95% confidence intervals, and the intervals should not be used in place of a hypothesis test. Event-free survival was assessed in a Kaplan–Meier analysis.\n\n【33】In prespecified subgroup analyses of the primary outcome, we evaluated subgroups based on sex, median age, site, and status with respect to known chronic obstructive pulmonary disease (COPD), hypertension (receipt of antihypertensive drugs) or renal disease (glomerular filtration rate <30 ml per minute per 1.73 m <sup>2 </sup> of body-surface area or current renal-replacement therapy), shockable primary rhythm, and acute ST-segment elevation myocardial infarction. The statistical analysis plan included an analysis of Montreal Cognitive Assessment scores in which missing scores and scores for deceased patients were included as the lowest score measured in the trial population (i.e., 15).  A two-sided P value of less than 0.05 was considered to indicate statistical significance. Statistical analyses were performed with the use of SAS Enterprise statistical software, version 3.8 (SAS Institute).\n\n【34】Results\n-------\n\n【35】Patients\n--------\n\n【36】Table 1. Demographic and Clinical Characteristics of the Patients.\n\n【37】A total of 802 patients were enrolled in the trial from March 2017 through December 2021. The screening and inclusion of patients is shown in Figure S1 in the Supplementary Appendix . Consent was withdrawn for 12 patients (use of data was not allowed), and 1 patient underwent randomization twice, leaving 789 patients in the trial population. Four patients died before the intervention was initiated, and in 2 patients the blood-pressure intervention was stopped by the treating physician because of hemodynamic instability; all 6 of these patients remained in the analyses. The median time from cardiac arrest to randomization was 146 minutes (interquartile range, 113 to 187). Two non-Danish patients were transferred and lost to follow-up; data for these patients were censored on the day when the modified Rankin scale score and CPC were recorded (on day 12 for one patient and on day 13 for the other). The baseline characteristics of the patients were well balanced in the two blood-pressure target groups .\n\n【38】Blood-Pressure Intervention\n---------------------------\n\n【39】Figure 1. Blood Pressure and Vasopressor Use over the First 48 Hours.\n\n【40】Panel A shows blood-pressure target assignments and mean blood pressure during the first 48 hours after randomization. Panels B and C show norepinephrine doses  and vasopressor–inotropic scores  during the first 48 hours after randomization. The before-randomization (BR) time point is the first available blood-pressure value before randomization, and time 0 is the time of randomization (i.e., the first measurement obtained with the trial-specific blood-pressure module). The high blood-pressure target was 77 mm Hg, and the low blood-pressure target was 63 mm Hg. Values shown are means, and error bars indicate the standard deviation. During the period from 2 to 48 hours after randomization, the mean between-group difference in blood pressure was 10.5 mm Hg (95% CI, 9.9 to 11.2), the mean difference in norepinephrine dose was 0.038 μg per kilogram per minute (95% CI, 0.026 to 0.049), and the mean difference in vasopressor–inotropic score was 3.5 points (95% CI, 2.4 to 4.6). A definition of the vasopressor–inotropic score is provided in the Supplementary Appendix ; higher scores indicate a higher degree of pharmacologic circulatory support.\n\n【41】Separation of the blood-pressure values for the high-target and low-target groups was apparent from the first value measured by the offset blood-pressure module, with a mean difference of 10.7 mm Hg (95% confidence interval \\[CI\\], 10.0 to 11.4) between the groups. The norepinephrine dose and the vasopressor–inotropic score were higher in the high-target group than in the low-target group .\n\n【42】Outcomes and Adverse Events\n---------------------------\n\n【43】Table 2. Outcomes and Adverse Events. Figure 2.  Figure 2. Kaplan–Meier Analysis of the Primary Outcome.\n\n【44】Shown is a plot of the probability of survival free from death from any cause or discharge from hospital with a Cerebral Performance Category score of 3 or 4 up to 90 days after randomization. Data are for the 789 patients in the intention-to-treat population. The inset shows the same data on an enlarged x axis (truncated at 15 days after randomization).Figure 3.  Figure 3. Subgroup Analysis of the Primary Outcome.\n\n【45】Data are for prespecified subgroup analyses of the primary outcome (death from any cause or discharge from the hospital with a Cerebral Performance Category score of 3 or 4). COPD denotes chronic obstructive pulmonary disease, and STEMI ST-segment elevation myocardial infarction.\n\n【46】At 90 days, 133 patients (34%) in the high-target group and 127 patients (32%) in the low-target group had been discharged from the hospital with a CPC of 3 or 4 or had died (hazard ratio, 1.08; 95% CI, 0.84 to 1.37; P=0.56) . A total of 24 patients (3%) had been discharged from the hospital with a CPC of 3 or 4: 11 in the high-target group and 13 in the low-target group. No interaction with the oxygen-target intervention was found (P=0.67). The results appeared to be consistent across most of the prespecified subgroups . A total of 122 of 393 patients (31%) in the high-target group and 114 of 396 patients (29%) in the low-target group died within 90 days . Renal-replacement therapy was initiated within the first 5 days in 41 patients (10%) in the high-target group and 40 patients (10%) in the low-target group (hazard ratio, 1.03; 95% CI, 0.66 to 1.59).\n\n【47】The Montreal Cognitive Assessment score was available for 359 of the 552 patients (65%) who were alive at 3 months. Data on the CPC, modified Rankin scale score, and Montreal Cognitive Assessment score at 3 months and on plasma levels of neuron-specific enolase at 48 hours are summarized in Table 2 . The distributions of results on the CPC and modified Rankin scale are shown in Figure S4. Data on median neuron-specific enolase levels were available for 79% of the patients; the median level was 18 μg per liter (interquartile range, 11 to 37) in the high-target group and 18 μg per liter (interquartile range, 11 to 34) in the low-target group. No significant differences were found in the percentages of patients with adverse events, including infection, arrhythmia, bleeding, and seizures .\n\n【48】Discussion\n----------\n\n【49】In this double-blind, randomized trial comparing two clinically relevant mean arterial blood-pressure targets, we found no significant difference in the percentage of patients who died or were discharged from the hospital with a poor neurologic outcome (CPC of 3 or 4) within 90 days. The results were consistent in the prespecified subgroups.\n\n【50】Our results add to those of two smaller, open-label trials of blood-pressure targets in postresuscitation care in which findings on magnetic resonance imaging of the head  and levels of neuron-specific enolase were used as markers of the extent of neurologic brain injury.  In these two trials, mean pressures of approximately 70 to 74 mm Hg in the lower target range and 84 to 87 mm Hg in the higher target range were attained, and the neuron-specific enolase levels were 20 to 22 μg per liter in one trial  and 42 to 59 μg per liter in the other,  as compared with 35 to 36 μg per liter in the present trial. At 6 months, 70%  and 45%  of the patients in the two trials were alive, as compared with 67% of the patients in the current trial.\n\n【51】Perfusion of the brain depends on the mean arterial pressure and is controlled through cerebrovascular autoregulation to ensure adequate perfusion at varying blood pressures. After an out-of-hospital cardiac arrest, this delicate balance between flow and pressure may be disrupted, with lower perfusion at a given pressure during the first 12 to 24 hours after the cardiac arrest.  Observational data suggest that the mean arterial blood pressure that should be used to secure flow to the postanoxic brain is at least 75 mm Hg,  whereas guidelines suggest that mean arterial pressure should be maintained above 65 mm Hg.  Maintenance of a higher mean arterial pressure in the postresuscitation period may be warranted in patients with preexisting hypertension.  In patients with sepsis, targeting a higher blood pressure has been associated with lower rates of dialysis among those with preexisting hypertension.  Our results do not suggest a benefit of a higher blood-pressure target in the subgroup of patients with known hypertension.\n\n【52】The interaction of preexisting COPD favoring a high blood-pressure target is likely to be spurious and should be interpreted with great caution. In addition, as compared with the lower target, the higher blood-pressure target in our trial was not associated with an increased risk of adverse events. In contrast, a higher blood pressure in patients with sepsis has previously been associated with increased risk of arrhythmia. \n\n【53】Our trial has limitations. The mean difference in blood pressure between the groups was 10.7 mm Hg and therefore was lower than the expected value (14 mm Hg). However, since a clinically significant separation in blood pressure was observed between the groups, and the doses of norepinephrine and vasopressor were substantially higher in the high-target group than in the low-target group, we believe that the trial provides strong evidence for an absence of clinically important differences in the assessed outcomes, although our findings cannot be extrapolated to blood-pressure targets that are higher or lower than those used in this trial. Although the hypothesized treatment effect may be seen as overly optimistic, given the consistency of the results in the two groups, the risk of type 2 error seems low.\n\n【54】Follow-up in our trial was challenging as a result of Covid-19 restrictions, including a temporary pause in research-related follow-up visits and a subsequent reluctance among patients to visit a hospital. As a result, the number of patients available for follow-up visits and assessment of cognitive testing was lower than expected. The number of blood samples in the biobank was also lower than expected, mainly because of delayed initiation of sampling for the biobank at one site.\n\n【55】A strength of our trial is that the results were consistent across the objective outcomes we examined (death, neurologic outcomes, and laboratory findings). Furthermore, our sample size, which was seven times as large as those in previous trials,  and the small number of patients who did not meet screening requirements, the consistency of the eligibility criteria with those used in previous trials, and the double-blinded intervention increase the generalizability of our results and reduce the risk of bias. However, the trial was conducted in only two high-volume cardiac arrest centers and included a population of patients with a high prevalence of acute coronary syndrome and a relatively good prognosis based on risk factors on arrival at the hospital. These aspects of the trial may affect the generalizability of our results.\n\n【56】In this trial, targeting a mean arterial blood pressure of 77 mm Hg as compared with 63 mm Hg in patients who had been resuscitated after an out-of-hospital cardiac arrest did not result in a significant difference in the percentage of patients who died or had severe disability or coma.", "index": 311, "show": true, "start": 311, "end": 354, "province": ["文本干净度", "无关文本"], "isEdit": false}]}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-14 00:22:30", "grab_time": "2024-08-13 23:32:01"}
{"id": 2234468, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "38951074-9d10-43a2-99d5-9b8eac293e99", "title": "Randomized Trial of Endoscopic or Open Vein-Graft Harvesting for Coronary-Artery Bypass", "text": "【0】Randomized Trial of Endoscopic or Open Vein-Graft Harvesting for Coronary-Artery Bypass\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】The saphenous-vein graft is the most common conduit for coronary-artery bypass grafting (CABG). The influence of the vein-graft harvesting technique on long-term clinical outcomes has not been well characterized.\n\n【3】Methods\n-------\n\n【4】We randomly assigned patients undergoing CABG at 16 Veterans Affairs cardiac surgery centers to either open or endoscopic vein-graft harvesting. The primary outcome was a composite of major adverse cardiac events, including death from any cause, nonfatal myocardial infarction, and repeat revascularization. Leg-wound complications were also evaluated.\n\n【5】Results\n-------\n\n【6】A total of 1150 patients underwent randomization. Over a median follow-up of 2.78 years, the primary outcome occurred in 89 patients (15.5%) in the open-harvest group and 80 patients (13.9%) in the endoscopic-harvest group (hazard ratio, 1.12; 95% confidence interval \\[CI\\], 0.83 to 1.51; P=0.47). A total of 46 patients (8.0%) in the open-harvest group and 37 patients (6.4%) in the endoscopic-harvest group died (hazard ratio, 1.25; 95% CI, 0.81 to 1.92); myocardial infarctions occurred in 34 patients (5.9%) in the open-harvest group and 27 patients (4.7%) in the endoscopic-harvest group (hazard ratio, 1.27; 95% CI, 0.77 to 2.11), and revascularization occurred in 35 patients (6.1%) in the open-harvest group and 31 patients (5.4%) in the endoscopic-harvest group (hazard ratio, 1.14; 95% CI, 0.70 to 1.85). Leg-wound infections occurred in 18 patients (3.1%) in the open-harvest group and in 8 patients (1.4%) in the endoscopic-harvest group (relative risk, 2.26; 95% CI, 0.99 to 5.15).\n\n【7】Conclusions\n-----------\n\n【8】Among patients undergoing CABG, we did not find a significant difference between open vein-graft harvesting and endoscopic vein-graft harvesting in the risk of major adverse cardiac events. \n\n【9】Introduction\n------------\n\n【10】Despite evidence favoring the use of multiple arterial conduits for coronary-artery bypass grafting (CABG), the greater saphenous vein remains the most commonly used conduit worldwide because of its ready availability and ease of use.  The two main limitations of vein grafts in myocardial revascularization are the high rates of graft failure, leading to a graft patency of approximately 60% at 10 years, and the risk of harvest-site complications (e.g., infections and pain). \n\n【11】Endoscopic vein-graft harvesting is a minimally invasive technique designed to reduce the rate of harvest-site complications. Endoscopic vein-graft harvesting technology was first introduced clinically in the mid-1990s and is currently being used in more than 90% of CABG cases in the United States.  Although the effectiveness of the endoscopic technique in reducing the incidence of leg-wound healing complications is well established, the evidence for its safety is derived from randomized trials of relatively small size, with short follow-up times and limited statistical power to evaluate major adverse cardiac events.  Furthermore, vein-graft patency has been consistently lower with endoscopic harvesting than with nonendoscopic harvesting, possibly because of mechanical factors during procurement (e.g., overstretch injury) performed by inexperienced endoscopic harvesters.  One particularly troubling observational study described both lower graft patency and a near doubling of mortality 18 months after CABG with endoscopic as compared with open vein-graft harvesting.  In the Randomized Endovein Graft Prospective (REGROUP) trial, we assessed the clinical outcomes of open or endoscopic vein-graft harvesting in CABG surgery in a multicenter, randomized trial.\n\n【12】Methods\n-------\n\n【13】Trial Design and Oversight\n--------------------------\n\n【14】We conducted a randomized, intention-to-treat, multicenter trial funded by the Cooperative Studies Program of the Department of Veterans Affairs. The rationale and design of the trial have been published previously.  Cardiac surgery programs at Veterans Affairs medical centers with expertise in performing endoscopic vein-graft harvesting were eligible to participate. An executive committee was responsible for trial oversight. The trial was approved by the institutional review board at each participating center. Patients gave written informed consent before participation.\n\n【15】Patient Population\n------------------\n\n【16】Patients undergoing elective or urgent CABG with cardiopulmonary bypass and cardioplegic arrest and a decision to use at least one vein graft underwent screening for enrollment. Inclusion criteria were an age of 18 years or older and planned elective or urgent (but not emergency) CABG with the use of the median sternotomy approach and a plan to use at least one saphenous vein graft as a conduit. Exclusion criteria were a planned valve procedure in combination with CABG, the presence of moderate or severe valve disease, the presence of hemodynamic instability or cardiogenic shock, enrollment in another therapeutic or interventional study, planned off-pump CABG, a life expectancy of less than 1 year, a history of venous stripping or ligation in the legs, and an inability to provide informed consent.\n\n【17】The Synergy between Percutaneous Coronary Intervention with Taxus and Cardiac Surgery (SYNTAX) score was used to quantify the severity of coronary-artery disease for each trial participant.  The SYNTAX score reflects a comprehensive angiographic assessment of the coronary vasculature, with a score of 22 or less indicating low anatomical complexity, scores of 23 to 32 indicating intermediate anatomical complexity, and scores of more than 32 indicating high anatomical complexity (0 is the lowest score, and there is no upper limit).\n\n【18】Vein-Graft Harvesting Experience and Techniques\n-----------------------------------------------\n\n【19】Only expert endoscopic vein-graft harvesters (e.g., surgeons or physician assistants but not trainees) were invited to participate in the trial. Participating harvesters provided information on their experience (certified by the principal investigator at the site) and had to receive approval to participate from an ad hoc committee chaired by a senior physician assistant in the field of endoscopic harvesting. Minimum expertise was defined as experience with more than 100 endoscopic vein harvesting cases with a certified low (<5%) conversion rate to open harvesting, as part of an established endoscopic vein harvesting program with more than 2 years of experience, as well as similar levels of experience with the open approach. \n\n【20】The use of any endoscopic vein harvesting device approved by the Food and Drug Administration was allowed in the trial; the equipment was purchased by the participating hospitals.  Open harvesting was performed according to the preference at each site. Guideline-directed medical therapy for secondary prevention of cardiovascular events was recommended as described in the Supplementary Appendix . \n\n【21】Randomization and Follow-up\n---------------------------\n\n【22】Before randomization, an experienced vein harvester was identified and assigned to the case. Patients were then randomly assigned to either endoscopic or open vein-graft harvesting, in a  ratio, by means of a telephone call to the Cooperative Studies Program Coordinating Center in Perry Point, Maryland, with the use of an automated system. A block randomization scheme with a random sequence of block sizes was used to ensure a balanced distribution of participants assigned to each harvester and within each medical center. Unless the patient had an urgent medical condition, surgery was scheduled to occur at the earliest possible date on the basis of the availability of the expert harvester and other circumstances at the center.\n\n【23】Participants were actively followed for a minimum of 1 year. Assessments were collected by site research personnel using in-clinic visits, telephone calls, or medical chart review. Assessments occurred at baseline, during surgery, after surgery, at discharge (or 30 days after surgery, if the patient was still hospitalized), at 6 weeks, and every 3 months thereafter until the end of the active follow-up phase and the beginning of the passive follow-up phase (for 2 additional years).\n\n【24】Trial Outcomes\n--------------\n\n【25】The primary outcome was defined as the first occurrence of a major adverse cardiac event (a composite of death from any cause, nonfatal myocardial infarction, or repeat revascularization) in a time-to-event analysis over the active follow-up period of the trial. The primary composite outcome and the individual components of that outcome (as defined in the Supplementary Appendix ) were identified and adjudicated. A clinical-events committee consisting of cardiologists and cardiac surgeons, all of whom were unaware of the treatment assignments, reviewed and adjudicated all major adverse cardiac events, with differences reconciled appropriately. The clinical-events committee further assigned causes of death as cardiac, noncardiac, or unknown on the basis of a review of data from medical records both inside and outside the Veterans Health Administration.\n\n【26】A secondary outcome included major adverse cardiac events at 1 year after surgery. Additional secondary outcomes of major adverse cardiac events at 3 years after surgery and time to major adverse cardiac events over the combined (active and passive) follow-up period have not yet been assessed, because the trial is currently in the passive follow-up period.\n\n【27】Several tertiary and post hoc outcomes were also assessed. The severity of incisional leg pain was assessed at the time of discharge and at approximately 6 weeks after surgery. Leg wounds were also evaluated with the ASEPSIS criteria, which are described in the Supplementary Appendix .  The ASEPSIS criteria include Likert-scale scores for the presence of erythema, serous exudates, purulent exudates, and separation of tissues, as well as assessments of the use of therapeutic interventions including antibiotic treatment, drainage, débridement, and prolongation of the hospital stay. In a post hoc analysis, leg wound infections were adjudicated according to the Centers for Disease Control and Prevention criteria as described in the Supplementary Appendix .  Quality of life was assessed at baseline, 6 weeks, and 1 year with the use of the Veterans RAND 12-item health survey (VR-12) and the Seattle Angina Questionnaire. \n\n【28】Statistical Analysis\n--------------------\n\n【29】We calculated that we would need a total sample of 1150 patients; details are provided in the Supplementary Appendix . Survival-analysis techniques were used to analyze the time to major adverse cardiac events (the primary outcome). Kaplan–Meier nonparametric survival estimates were used to evaluate the unadjusted effect of vein harvesting technique on major adverse cardiac events. Tests of differences of the survival-function estimates across strata (open and endoscopic harvest) were performed with the log-rank test. Multivariable survival analyses applying a Cox proportional-hazards regression model were performed to investigate the effect of vein harvesting technique on the primary outcome, with adjustment for other potentially influential baseline characteristics. A Wei–Lin–Weissfeld model was used to compare multiple times to events (recurrent events) between the groups during active follow-up. Pearson’s chi-square analysis was used to compare the rate of major adverse cardiac events between the groups during the first year of follow-up.\n\n【30】A type I error rate of 0.025 was used for the primary outcome to account for the alpha error assigned to three interim analyses (as described in the Supplementary Appendix ). No adjustment for multiplicity of testing was made; therefore, P values are not reported for outcomes other than the primary outcome. Confidence intervals were two-sided with a 95% confidence level and were not adjusted for multiplicity; therefore, inferences drawn from these intervals regarding secondary and tertiary outcomes may not be reproducible. All statistical analyses were conducted with the use of SAS statistical software, version 9.4 (SAS Institute).\n\n【31】Results\n-------\n\n【32】Patients and Treatment\n----------------------\n\n【33】Figure 1. Enrollment and Randomization.\n\n【34】CABG denotes coronary-artery bypass grafting.Table 1.  Table 1. Characteristics of the Patients at Baseline.\n\n【35】From March 2014 through April 2017, we enrolled 1188 patients at 16 Veterans Affairs cardiac surgery centers in the United States. Of the 1150 patients who underwent randomization, 574 were assigned to open vein-graft harvesting and 576 to endoscopic vein-graft harvesting . The groups were balanced with regard to age, sex, smoking status, race or ethnic group, body-mass index, and coexisting conditions . Medical therapy at baseline and during follow-up is shown in Table S1 in the Supplementary Appendix .\n\n【36】Table 2. Characteristics of the Surgical Procedures and the Patients.\n\n【37】Characteristics of the surgical procedures and the patients are described in Table 2 . The mean (±SD) SYNTAX score was 28.5±11.5 (median, 27). No site used the open “no touch” vein harvesting technique.  The mean vein harvesting time was 61.4±28.7 minutes in the open-harvest group and 57.5±24.4 minutes in the endoscopic-harvest group. Conversion to open harvesting occurred in 5.6% of the patients who had been randomly assigned to the endoscopic-harvest group . A few protocol violations occurred: in 0.5% of the cases, CABG was performed off pump, and in 0.3% of the cases, combined CABG and valve surgery was performed.\n\n【38】Primary and Secondary Outcomes\n------------------------------\n\n【39】Figure 2. Composite Outcome of Death from Any Cause, Myocardial Infarction, or Repeat Revascularization during the Active Follow-up Period.\n\n【40】The inset shows the same data on an enlarged y axis.Table 3.  Table 3. Major Adverse Cardiac Events during Active Follow-up.\n\n【41】The active follow-up period ended in April 2018. The median follow-up duration was 2.78 years (interquartile range, 1.99 to 3.48). During active follow-up, the primary composite outcome of major adverse cardiac events occurred in 89 patients (15.5%) in the open-harvest group and 80 patients (13.9%) in the endoscopic-harvest group (hazard ratio, 1.12; 95% confidence interval \\[CI\\], 0.83 to 1.51; P=0.47) . A total of 46 patients (8.0%) in the open-harvest group and 37 patients (6.4%) in the endoscopic-harvest group died (hazard ratio, 1.25; 95% CI, 0.81 to 1.92) . Causes of death were adjudicated as cardiac, not cardiac, or unknown; these data are provided in Table S2 in the Supplementary Appendix . Myocardial infarction occurred in 34 patients (5.9%) in the open-harvest group and 27 patients (4.7%) in the endoscopic-harvest group (hazard ratio, 1.27; 95% CI, 0.77 to 2.11), and repeat revascularization occurred in 35 patients (6.1%) in the open-harvest group and 31 patients (5.4%) in the endoscopic-harvest group (hazard ratio, 1.14; 95% CI, 0.70 to 1.85).\n\n【42】A multivariable Cox proportional-hazards regression model with adjustment for potentially influential baseline demographic and clinical characteristics of the patients showed no significant difference in risk according to the type of vein harvesting . In an analysis of recurrent major cardiac events after open as compared with endoscopic harvesting, the hazard ratio was 1.29 (95% CI, 1.00 to 1.68) . The 1-year rate of major adverse cardiac events was 8.2% for open harvesting and 7.8% for endoscopic harvesting. The results of competing-risks analyses for myocardial infarction, repeat revascularization, and the composite of myocardial infarction or complete revascularization were similar to those of the primary analyses and are shown in Table S5 in the Supplementary Appendix .\n\n【43】Tertiary Outcomes\n-----------------\n\n【44】Leg-wound infections occurred in 18 patients (3.1%) in the open-harvest group and in 8 patients (1.4%) in the endoscopic-harvest group (absolute difference, 1.7 percentage points; relative risk, 2.26; 95% CI, 0.99 to 5.15). Data on the timing of leg-wound infections are shown in Table S6 in the Supplementary Appendix . Incisional leg pain had little or no effect on functioning at 6 weeks after surgery in 62.2% of the patients in the open-harvest group, as compared with 79.1% of those in the endoscopic-harvest group (relative risk, 0.79; 95% CI, 0.73 to 0.85) . There was no significant difference in quality of life between the groups as assessed with either the VR-12 survey or the Seattle Angina Questionnaire .\n\n【45】Antibiotics were administered at follow-up to 14.4% of the patients in the open-harvest group and in 4.6% of the patients in the endoscopic-harvest group (relative risk, 3.15; 95% CI, 2.06 to 4.82). The percentage of patients who received a visit from a nurse to dress the leg wound at home after discharge from the hospital was 3.7% in the open-harvest group as compared with 1.2% in the endoscopic-harvest group (relative risk 3.03; 95% CI, 1.30 to 7.08). Additional components of the ASEPSIS criteria for wound status are shown in Table S15 in the Supplementary Appendix . Data on the experience of individual vein harvesters, as well as trial outcomes according to center and harvester, are provided in Tables S16 through S19 in the Supplementary Appendix .\n\n【46】Discussion\n----------\n\n【47】In this trial, in which vein-graft harvesting for CABG was performed by operators with documented experience, we did not find any significant difference between open and endoscopic vein-graft harvesting in the rate of major adverse cardiac events over a median follow-up of 2.78 years. We found a trend toward lower rates of major adverse cardiac events in association with the endoscopic technique when recurrent events were compared between the two treatment groups, although longer-term follow-up will be necessary to determine whether this finding is persistent. Endoscopic harvesting resulted in better harvest-site healing than did the open approach, a finding consistent with previous observations.\n\n【48】The conflicting findings regarding the safety profile of endoscopic harvesting that were published during 2009 through 2012, as well as our own data from a preplanned analysis of the Randomized On/Off Bypass (ROOBY) trial, led to the launch of the REGROUP trial in 2013.  An important feature of our trial design is the required high level of expertise of the vein harvesters, for both endoscopic and open harvesting, a characteristic that has not always been a part of previous trial designs.  In fact, a well-founded criticism of previous trials of endoscopic vein-graft harvesting was the lack of information on expertise. The learning curve for vein-graft harvesting is steep, and proficiency is required for good outcomes. Inexperienced operators may cause unnecessary stretching and trauma to the vein graft during harvesting, leading to endothelial injury and possible early vein-graft failure. \n\n【49】The results of our trial are consistent with those of a large observational study involving Medicare patients who underwent CABG at 934 surgical centers participating in the Society of Thoracic Surgeons national database; in that study no significant difference in the long-term rates of major adverse cardiac outcomes were found in association with endoscopic as compared with open vein-graft harvesting.  The safety concern raised by a retrospective analysis of the Project of Ex-vivo Vein Graft Engineering via Transfection IV (PREVENT IV) trial  may be explained by the lack of information on the experience of the endoscopic vein-graft harvesters. Because less experienced harvesters were allowed to participate in their trial, the quality of the conduits could have been compromised, contributing to accelerated vein-graft failure and worse clinical outcomes.\n\n【50】Limitations of our trial included the absence of an imaging evaluation of graft patency. Consequently, some subclinical events may have been overlooked. However, graft patency is an imperfect surrogate for clinical events, and since there was no signal of superior clinical outcomes with open harvesting and a trend toward a lower rate of recurrent events with endoscopic harvesting, it is unlikely that subclinical events related to graft patency would have altered the overall trial results. The trial focused on experienced harvesters, and its results may not apply to other populations. The open “no touch” technique of vein-graft harvesting was not practiced at any site in the study, and therefore the results reflect only outcomes associated with the more traditional technique of open harvesting.  The results reflect experience in a predominantly male population of patients. Off-pump CABG was excluded because of evidence of lower graft patency with this approach; therefore, the results of our trial apply to the on-pump technique with cardioplegic arrest, which remains the most common form of CABG. \n\n【51】In conclusion, our trial did not show a significant difference between endoscopic and open vein-graft harvesting in the rate of major adverse cardiac events among patients undergoing CABG surgery during a follow-up period with a median duration of 2.78 years. The rate of wound complications was lower in the endoscopic-harvest group than in the open-harvest group. Further studies are needed to establish standards for harvester expertise to ensure the safety of patients and effectiveness of the procedure.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 18:05:50", "endTime": "2024/08/13 18:06:27", "cost": 36.721}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:32", "update_time": "2024-08-13 02:06:27", "grab_time": "2024-08-13 02:05:50"}
{"id": 2234467, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "3d693627-288e-4941-9b3b-3808bb8cdc3f", "title": "Biochemical Profile of Uremic Breath", "text": "【0】Biochemical Profile of Uremic Breath\nAbstract\n--------\n\n【1】We attempted to define the substances that contribute to the characteristic \"uremic breath\" of patients with end-stage renal disease. Breath samples from nine patients underwent direct analysis before and after hemodialysis with use of gas chromatography and confirmation by mass spectrometry, and indirectly assessment by an organoleptic panel. Concentrations of secondary and tertiary amines, dimethylamine and trimethylamine were increased, with subsequent reduction after hemodialysis (dimethylamine from 2.00±0.19 \\[S.E.M.\\] to 0.88±0.12 μg per 30 minutes, P<0.001, and trimethylamine from 0.79±0.22 to 0.44±0.15 μg per 30 minutes, P<0.003). Treatment with nonabsorbable antibiotics in two patients reduced both serum and breath amine levels without dialysis. Loss of nitrogen via the breath was not quantitatively important. We conclude that uremic breath reflects the systemic accumulation of potentially toxic volatile metabolites, among which dimethylamine and trimethylamine have been positively identified and correlated with the classic fishy odor.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:26:36", "endTime": "2024/08/14 15:26:45", "cost": 8.95}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 23:26:45", "grab_time": "2024-08-13 23:26:36"}
{"id": 2234466, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "9b2bdc22-12e7-49ad-bb5f-019530216d2a", "title": "A Half-Century of Progress in Health: The National Academy of Medicine at 50: Shaping the Future of Veterans’ Health Care", "text": "【0】A Half-Century of Progress in Health: The National Academy of Medicine at 50: Shaping the Future of Veterans’ Health Care\n### Audio Interview\n\n【1】 Interview with Dr. Linda McCauley on historical and current concerns related to the health of U.S. veterans. \n\n【2】Members of the U.S. military are at risk for a range of combat-related injuries and hazardous exposures, and some chronic health problems can arise years after service. Although there have been important advances in our ability to care for veterans, challenges remain.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:37:54", "endTime": "2024/08/14 15:38:03", "cost": 9.368}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 23:38:03", "grab_time": "2024-08-13 23:37:30"}
{"id": 2234465, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "d178cd6d-d0a0-4ef1-bdf1-8a3f7126d433", "title": "Medical Deferred Action — Living on Borrowed Time", "text": "【0】Medical Deferred Action — Living on Borrowed Time\n### Audio Interview\n\n【1】 Interview with Dr. Lakshmi Ganapathi on threats to medical deferred action. \n\n【2】Eliminating medical deferred action for immigrant children with highly complex conditions or the immigrant parents of U.S.-citizen children with such conditions would be a death sentence. How can physicians stand up to an administration that threatens patients’ lives?", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 18:03:52", "endTime": "2024/08/13 18:05:20", "cost": 88.194}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 02:05:20", "grab_time": "2024-08-13 02:03:52"}
{"id": 2234464, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "267da33d-c52b-490d-898f-02d33c2d99d5", "title": "Reversal of Pacing-Induced Heart Failure by Left Ventricular Apical Pacing", "text": "【0】Reversal of Pacing-Induced Heart Failure by Left Ventricular Apical Pacing\nTo the Editor:\n--------------\n\n【1】Children with congenital complete atrioventricular block often require lifelong pacemaker therapy. Although such therapy restores a normal heart rate, it also results in dyssynchronous left ventricular activation and contraction and compromises left ventricular function.  These effects are most pronounced during right ventricular pacing, the predominant pacing site in children and adults. Eventually, heart failure develops in 6 to 7% of children who undergo long-term right ventricular pacing. \n\n【2】The harmful effects of right ventricular pacing initiated the search for pacing modes that would maintain or restore synchronous activation — in other words, biventricular pacing and alternative single-site ventricular pacing. In previous studies,  we showed that the physiologic apex-to-base sequence of electrical activation during left ventricular apical pacing resulted in a hemodynamic response that was as good as the response with multisite pacing in dogs; we also showed that such activation had favorable acute hemodynamic effects in children. \n\n【3】Figure 1. Changes in the Left Ventricular End-Diastolic Diameter (LVEDD) in the Patient during a 4-Year Period.\n\n【4】Data are expressed as z scores (the number of standard deviations above the average LVEDD value for the corresponding body-surface area).  RV denotes right ventricular, and LV left ventricular.\n\n【5】On the basis of these findings, we used left ventricular apical pacing to treat a 2-year-old girl with congenital complete atrioventricular block and heart failure induced by right ventricular pacing. In this patient, single-chamber right ventricular epicardial pacing had been started 1 day after birth to treat symptomatic bradycardia. During right ventricular pacing, echocardiography showed dyssynchronous left ventricular contraction, which was associated with progressive left ventricular dilatation . After 2 years of right ventricular pacing, rapid deterioration occurred, with the development of congestive heart failure (afterload reduction with lisinopril had been started): the shortening fraction decreased to approximately 20%, and the left ventricular end-diastolic diameter increased precipitously. When the pacemaker was switched off, left ventricular contraction was synchronous, and the shortening fraction increased to 36%, but the ventricular escape rhythm of 40 to 50 beats per minute was not well tolerated, despite additional furosemide treatment.\n\n【6】On initiation of left ventricular apical pacing, the left ventricular function increased immediately, with a shortening fraction of 31%. Echocardiography showed synchronous contraction around the left ventricular short axis. Thereafter, the patient's condition improved, with gradual normalization of the left ventricular end-diastolic diameter; the shortening fraction was maintained at 30 to 35%.\n\n【7】At a visit 20 months after the start of treatment, we assessed the patient's left ventricular function during pacing from various sites (including biventricular pacing) with an atrioventricular delay of 100 msec and during ventricular escape rhythm. During left ventricular apical pacing, biventricular pacing, and ventricular escape rhythm, the results were similar with respect to the ejection fraction (approximately 65%), the shortening fraction (approximately 35%), and delay in septal-to-posterior wall motion (−17 to −45 msec). However, the values deteriorated during right ventricular pacing (50%, 25%, and +311 msec, respectively).\n\n【8】Our finding that the effect of the ventricular pacing site is much more important than the restoration of atrioventricular sequential activation underscores the importance of the proper choice of site for ventricular pacing. Considering the practical advantages of single-site over multisite ventricular pacing, we believe that further studies of single-site left ventricular apical pacing are warranted.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 17:50:50", "endTime": "2024/08/13 18:01:23", "cost": 632.645}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 02:01:23", "grab_time": "2024-08-13 01:50:50"}
{"id": 2234463, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "2a60a032-bbfa-4201-bfcb-438f6a13413b", "title": "Reliever-Triggered Inhaled Glucocorticoid in Black and Latinx Adults with Asthma", "text": "【0】Reliever-Triggered Inhaled Glucocorticoid in Black and Latinx Adults with Asthma\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Black and Latinx patients bear a disproportionate burden of asthma. Efforts to reduce the disproportionate morbidity have been mostly unsuccessful, and guideline recommendations have not been based on studies in these populations.\n\n【3】Methods\n-------\n\n【4】Download a PDF of the Research Summary .\n\n【5】In this pragmatic, open-label trial, we randomly assigned Black and Latinx adults with moderate-to-severe asthma to use a patient-activated, reliever-triggered inhaled glucocorticoid strategy (beclomethasone dipropionate, 80 μg) plus usual care (intervention) or to continue usual care. Participants had one instructional visit followed by 15 monthly questionnaires. The primary end point was the annualized rate of severe asthma exacerbations. Secondary end points included monthly asthma control as measured with the Asthma Control Test (ACT; range, 5 \\[poor\\] to 25 \\[complete control\\]), quality of life as measured with the Asthma Symptom Utility Index (ASUI; range, 0 to 1, with lower scores indicating greater impairment), and participant-reported missed days of work, school, or usual activities. Safety was also assessed.\n\n【6】Results\n-------\n\n【7】Of 1201 adults (603 Black and 598 Latinx), 600 were assigned to the intervention group and 601 to the usual-care group. The annualized rate of severe asthma exacerbations was 0.69 (95% confidence interval \\[CI\\], 0.61 to 0.78) in the intervention group and 0.82 (95% CI, 0.73 to 0.92) in the usual-care group (hazard ratio, 0.85; 95% CI, 0.72 to 0.999; P=0.048). ACT scores increased by 3.4 points (95% CI, 3.1 to 3.6) in the intervention group and by 2.5 points (95% CI, 2.3 to 2.8) in the usual-care group (difference, 0.9; 95% CI, 0.5 to 1.2); ASUI scores increased by 0.12 points (95% CI, 0.11 to 0.13) and 0.08 points (95% CI, 0.07 to 0.09), respectively (difference, 0.04; 95% CI, 0.02 to 0.05). The annualized rate of missed days was 13.4 in the intervention group and 16.8 in the usual-care group (rate ratio, 0.80; 95% CI, 0.67 to 0.95). Serious adverse events occurred in 12.2% of the participants, with an even distribution between the groups.\n\n【8】Conclusions\n-----------\n\n【9】Among Black and Latinx adults with moderate-to-severe asthma, provision of an inhaled glucocorticoid and one-time instruction on its use, added to usual care, led to a lower rate of severe asthma exacerbations. \n\n【10】Introduction\n------------\n\n【11】 QUICK TAKE  \nInhaled Glucocorticoids in Black and Latinx Adults with Asthma  \n\n【12】In the United States, asthma results in considerable illness, including more than 3300 asthma-attributed deaths in adults each year.  Annual costs for asthma in adults total more than $67 billion  and are substantially higher in patients with uncontrolled asthma than in those with controlled asthma.  Owing to a complex array of factors,  Black and Latinx populations bear disproportionate asthma morbidity and mortality.  After adjustment for prevalence, the rates of asthma-related emergency department visits and hospitalizations are higher among Black and Latinx persons than among White persons,  and mortality from asthma is twice as high among Black and Latinx persons as among White persons.  Efforts to improve asthma management and reduce this burden have been labor-intensive, expensive, and variably effective. \n\n【13】Inhaled glucocorticoids are the backbone of asthma-controller therapy. Multiple studies have suggested that in patients with moderate-to-severe asthma, the use of a single inhaler containing a combination of a glucocorticoid and a rapid-onset long-acting β <sub>2 </sub> \\-agonist (LABA), used as a regular, twice-daily maintenance therapy, plus the use of an as-needed reliever therapy (i.e., a single maintenance and reliever therapy \\[SMART\\] strategy), can reduce asthma exacerbations more effectively than the previously more commonly recommended strategy of twice-daily use of the combination product with a short-acting β <sub>2 </sub> \\-agonist as the reliever. Guideline recommendations have recently been updated to reflect such approaches.  However, studies supporting the effectiveness of this strategy that have included substantial proportions of Black or Latinx patients have been limited.\n\n【14】Furthermore, few studies in moderate-to-severe asthma have been conducted in real-world U.S. settings in which patients commonly use nebulized β <sub>2 </sub> \\-agonists as quick-reliever therapy.  The use of nebulizers for quick relief interferes with the supplemental as-needed strategy of SMART, in which patients use combination inhaled glucocorticoid plus LABA instead of a reliever inhaler for acute symptoms, so that inhaled glucocorticoid is delivered each time the patient has symptoms warranting medication use. If patients use nebulizers for relief, they do not receive the intended inhaled glucocorticoid, since they are not using the combination inhaler for relief. Finally, barriers to implementation of the SMART strategy include a caution from the Food and Drug Administration against as-needed use of combination inhaled glucocorticoid plus LABA, the requirement to change the existing controller therapy to the specifically recommended combination inhaled glucocorticoid plus LABA, and varied insurance coverage for this approach. \n\n【15】Considering the disproportionate burden of asthma in Black and Latinx populations, the difficulties in reducing such morbidity, the paucity of data on the effectiveness of interventions specifically investigated in these populations, and the potential barriers to implementation of current recommendations, we conducted the Person Empowered Asthma Relief (PREPARE) trial. We investigated whether one-time instruction in an approach involving as-needed inhaled glucocorticoid (modified from Calhoun et al.,  on the basis of feedback from our patient partners and advisors and the results of a pilot study  ), added to existing therapy, could improve asthma outcomes in Black and Latinx patients with poorly controlled asthma in a trial with minimal exclusion criteria.\n\n【16】Methods\n-------\n\n【17】Trial Design and Oversight\n--------------------------\n\n【18】We conducted this randomized, open-label, pragmatic trial of the addition of a patient-activated, reliever-triggered inhaled glucocorticoid strategy, which we called PARTICS, to usual care in Black and Latinx patients with moderate-to-severe asthma in the continental United States and Puerto Rico. Full details of the trial protocol , which is available with the full text of this article at NEJM.org, have been published previously. \n\n【19】The investigators collaborated with Black and Latinx adults with asthma and with caregivers of persons with asthma (patient partners) and additional advisors. The authors designed the trial, gathered the data with assistance from DARTNet Institute and the Asthma Research Center at Brigham and Women’s Hospital (in Boston), and analyzed the data with the assistance of the Duke Clinical Research Institute (in Durham, NC). The authors vouch for the accuracy and completeness of the data and for the fidelity of the trial to the protocol. The first author wrote the first draft of the manuscript. All the authors made the decision to submit the manuscript for publication. There were no restrictive confidentiality agreements.\n\n【20】Patient Population\n------------------\n\n【21】Adults 18 to 75 years of age with clinician-diagnosed asthma who self-identified as Black or Latinx underwent screening at 19 primary care and specialty clinical organizations; the patients had been approached about participation before or at a clinic visit. All the participants provided written informed consent on a form that had been approved by the institutional review board of Partners HealthCare and local institutional review boards.\n\n【22】Key inclusion criteria were a status of being prescribed daily inhaled glucocorticoids, with or without LABA, and having either uncontrolled asthma (Asthma Control Test \\[ACT\\] score of ≤19 \\[indicating asthma that was not well controlled; scores range from 5 to 25, with lower scores indicating less control; minimal clinically important difference, 3\\]) or at least one participant-reported asthma exacerbation leading to the use of systemic glucocorticoids or overnight hospitalization in the previous year. Former or current smokers were included in the trial, and there were minimal other exclusions.  Patients who were taking regular systemic glucocorticoids were excluded.\n\n【23】Trial Procedures\n----------------\n\n【24】 Site clinicians underwent asthma-treatment training with the Asthma IQ.  The clinician care that was provided during the trial is referred to here as usual care. During the subsequent 15 months, clinicians were free to modify usual care as necessary.\n\n【25】At the only in-person trial visit, participants were randomly assigned in a  ratio either to use a patient-activated, reliever-triggered inhaled glucocorticoid strategy plus usual care (intervention) or to continue usual care. Centralized randomization was stratified according to trial site and race and ethnic group. At this visit, participants received instructions, completed questionnaires, and watched a video that was appropriate to the randomization group. All the trial materials were available in English and Spanish.\n\n【26】All the participants received a trial-specific pouch designed to hold two metered-dose inhalers. Participants in the intervention group received an open-label inhaler that administered a metered dose of 80 μg of beclomethasone dipropionate (QVAR \\[Teva Pharmaceuticals\\]; the QVAR RediHaler was used after December 2018 owing to discontinuation of the QVAR inhaler). Participants who had been using a nebulized quick-reliever received an additional QVAR inhaler to place with their nebulizer. They were instructed to take one puff of inhaled glucocorticoid for each puff of quick-reliever inhaler and five puffs of inhaled glucocorticoid with each quick-reliever nebulization. Participants could request intervention QVAR refills from the trial pharmacy (AssistRx) by means of a toll-free telephone number.\n\n【27】Participants were followed for up to 15 months by means of monthly surveys, which were administered according to participant preference (Internet, telephone, or mail). They received cash compensation for their visit and for completed surveys. In a subgroup of participants, the fraction of exhaled nitric oxide (F e NO) was measured at baseline, and blood eosinophil counts were obtained at baseline or from records of the previous year.\n\n【28】End Points\n----------\n\n【29】End points were selected on the basis of input from patient partners and advisors. These end points included exacerbations, owing to their reported disruptive effect; quality of life; and missed days of work, school, or usual activities. In line with these preferences, the primary end point was the annualized rate of American Thoracic Society–defined severe asthma exacerbations (those that led to the use of systemic glucocorticoids for ≥3 days or to an asthma-related hospitalization).  Severe asthma exacerbations were noted on monthly questionnaires. Central investigators who were unaware of the treatment assignments verified exacerbations by means of site medical records or direct contact with participants.\n\n【30】Prespecified secondary end points included monthly asthma control as measured with the ACT,  preference-based quality of life as measured with the Asthma Symptom Utility Index (ASUI; scores range from 0 to 1, with lower scores indicating greater impairment; minimal clinically important difference, 0.09),  and participant-reported days missed from work, school, or usual activities.  Data on adverse events that resulted in hospitalization or death were obtained by participant report or site report.\n\n【31】Statistical Analysis\n--------------------\n\n【32】Assuming a severe exacerbation rate of 0.4 exacerbations per participant per year  and an annualized loss to follow-up of 25%, we calculated that a sample of 1200 participants (600 per group) would provide the trial with 80% power to detect a 23.5% difference in the exacerbation rate. The timing and frequency of severe asthma exacerbations were compared with the use of the Andersen–Gill adaptation of the time-to-event Cox proportional-hazards model, with stratification according to race and ethnic group and with adjustment for baseline characteristics and for a time-dependent covariate to account for the effects of coronavirus disease 2019 on the rate of severe asthma exacerbations. \n\n【33】All the major between-group treatment comparisons were performed in the intention-to-treat population, which included all the participants who had undergone randomization except for any from a prematurely closed trial site. Details of the analyses of the secondary and exploratory end points are provided in the statistical analysis plan. Statistical analyses were performed with the use of SAS software, version 9.4 (SAS Institute).\n\n【34】A P value of 0.15 or less was prespecified for interaction testing of the effect of the two racial and ethnic groups to permit separate analysis within each group. Missing-data analyses were to be performed if the percent of missing data reached a prespecified threshold of 5%. Results are reported with 95% confidence intervals. The widths of the confidence intervals for secondary, post hoc, and safety analyses have not been adjusted for multiplicity and thus should not be used to infer definitive treatment effects.\n\n【35】Results\n-------\n\n【36】Population and Follow-up\n------------------------\n\n【37】Table 1. Characteristics of the Participants at Baseline.\n\n【38】From November 2017 through March 2021, a total of 1201 participants (603 Black and 598 Latinx) underwent randomization, with 600 participants being assigned to the intervention group and 601 to the usual-care group . A total of 83.7% of the participants were women . Approximately half the participants reported health that was fair to poor with multiple coexisting conditions; 68.8% of the participants had obesity, and approximately 20% were current or former smokers. The ACT and ASUI scores indicated poor asthma control and a clinically significant burden of asthma.  A total of 72.2% of the participants reported having had at least one asthma exacerbation that led to the use of systemic glucocorticoids in the previous year. A total of 71.5% of the participants used combination inhaled glucocorticoid plus LABA, and 66.9% used a nebulizer for quick-reliever therapy; 67.5% of those participants (45.2% of the overall population) reported using at least one nebulizer treatment per week. Among the participants with measurements, 30.1% had a F e NO of at least 30 parts per billion, and 26.6% had a blood eosinophil count of at least 300 per cubic millimeter. The characteristics of the participants according to race and ethnic group are shown in Table S2. The representativeness of the participants is discussed in Table S6.\n\n【39】The median follow-up was 14.9 months in each group. Survey returns did not differ according to treatment group (96.2% of the expected periods in the intervention group and 96.7% of those in the usual-care group).\n\n【40】Adherence to the Intervention\n-----------------------------\n\n【41】Among participants in the intervention group, 81.0% reported using inhaled glucocorticoid with quick-reliever metered-dose inhalers all or most of the time, and 75.7% reported using inhaled glucocorticoid with quick-reliever nebulization all or most of the time. A total of 50.4% of the participants in this group reported using at least four of the instructed five puffs of inhaled glucocorticoid per quick-reliever nebulization.\n\n【42】Primary End Point\n-----------------\n\n【43】Table 2. Primary, Secondary, Post hoc, and Safety Analyses. Figure 1.  Figure 1. Mean Cumulative Number of Severe Asthma Exacerbations per Participant over Time, with Adjusted Hazard Ratio.\n\n【44】Shown are the mean cumulative numbers of severe asthma exacerbations per participant over time. Participants in the intervention group received patient-activated, reliever-triggered inhaled glucocorticoid in addition to usual care. Differences in treatment-group hazards were compared with the use of the Andersen–Gill model with adjustment for prespecified covariates.\n\n【45】The annualized rate of severe asthma exacerbations was 0.69 (95% confidence interval \\[CI\\], 0.61 to 0.78) in the intervention group and 0.82 (95% CI, 0.73 to 0.92) in the usual-care group (hazard ratio, 0.85; 95% CI, 0.72 to 0.999; P=0.048)  . This difference was consistent throughout the duration of the trial . Point estimates from sensitivity analyses of the primary end point were consistent with the overall finding, although not all the results were significant . Primary end-point results according to trial site are shown in Figure S3. The percent of missing data (3%) did not reach the prespecified threshold of 5%, so missing-data analyses were not performed.\n\n【46】Secondary End Points\n--------------------\n\n【47】Figure 2. Mean Changes from Baseline in Asthma-Related Scores.\n\n【48】The least-squares mean differences between treatment groups in the changes from baseline in asthma-related scores were calculated with the use of a mixed model. The Asthma Control Test  is a participant-administered tool for assessing the level of asthma control. Total scores range from 5 to 25, with a score of 20 to 25 indicating well-controlled asthma, a score of 16 to 19 indicating asthma that was not well controlled, and a score of 5 to 15 indicating very poorly controlled asthma; the minimal clinically important difference is 3 points. The Asthma Symptom Utility Index  is a participant-administered tool for assessing preference-based quality of life. The summary score is on a continuous scale, ranging from 0 (worst possible symptoms) to 1 (no symptoms); the minimal clinically important difference is 0.09. 𝙸 bars indicate 95% confidence intervals. The widths of the confidence intervals have not been adjusted for multiplicity and cannot be used to infer treatment effects.\n\n【49】The strategy in the intervention group led to an increase in the ACT scores (minimal clinically important difference, 3 points)  of 3.4 points, as compared with an increase of 2.5 points in the usual-care group (difference, 0.9 points; 95% CI, 0.5 to 1.2) . The intervention strategy also led to an increase in the ASUI score (minimal clinically important difference, 0.09 points)  of 0.12 points, as compared with an increase of 0.08 points in the usual-care group (difference, 0.04 points; 95% CI, 0.02 to 0.05) . Participants in the intervention group had 13.4 annualized days missed of work, school, and usual activities, as compared with 16.8 annualized days missed in the usual-care group (rate ratio, 0.80; 95% CI, 0.67 to 0.95) .\n\n【50】Post hoc and Safety Analyses\n----------------------------\n\n【51】In a post hoc analysis, participants in the intervention group reported a mean 0.75 months per year in which an emergency department or urgent care visit occurred, as compared with 0.90 months per year in the usual-care group (rate ratio, 0.84; 95% CI, 0.68 to 1.03). In the safety analysis, there were 70 asthma-related hospitalizations in the intervention group and 84 in the usual-care group (rate ratio, 0.84; 95% CI, 0.50 to 1.42).\n\n【52】Post hoc analyses of medication use based on participants’ monthly surveys showed that participants in the intervention group used 1.1 extra inhaler containing inhaled glucocorticoid per year as compared with the usual-care group (8.9 vs. 7.8 inhalers per year). Participants in the intervention group also reported fewer refills of the quick-reliever metered-dose inhaler than those in the usual-care group (4.6 vs. 5.6 refills), as well as fewer months in which they used quick-reliever nebulizer (3.6 vs. 5.4 months) .\n\n【53】Subgroup Analyses\n-----------------\n\n【54】Figure 3. Subgroup Analyses of Severe Asthma Exacerbation Outcome.\n\n【55】The forest plot shows the risk of severe asthma exacerbations in selected prespecified subgroups. The widths of the confidence intervals have not been adjusted for multiplicity and cannot be used to infer treatment effects. Race was reported by the participant; those who identified as both Black and Latinx were classified as Latinx. Nonsmokers were those who had not smoked within the previous year and had smoked less than 10 pack-years. The participant’s attitude toward asthma medications was assessed with the Beliefs about Medicines Questionnaire; the “accepting” category indicates that the participant believed the therapy was of high necessity and low concern.  Depressive status was assessed with the Patient Health Questionnaire–2; scores range from 0 to 6, with a score of 3 or higher indicating depression.  The Brief Health Literacy Scale measures participant-reported health literacy and consists of three items. If a participant’s response on any item indicated low or marginal health literacy, the participant was considered to have low or marginal health literacy; otherwise, health literacy was considered to be high.  The body-mass index is the weight in kilograms divided by the square of the height in meters. Participant-reported medication adherence was assessed with the Medication Adherence Report Scale–5 by the calculation of the mean score over the five items. Mean scores range from 1 to 5, with higher scores indicating better adherence.  F e NO denotes fraction of exhaled nitric oxide, LABA long-acting β <sub>2 </sub> \\-agonist, and ppb parts per billion.\n\n【56】Hazard ratios for severe asthma exacerbations in prespecified subgroups are shown in Figure 3 . The hazard ratio for severe exacerbations with the intervention as compared with usual care was 0.77 among Black participants and 0.92 among Latinx participants (P=0.29 for interaction, which exceeded our prespecified limit for stratified analyses).\n\n【57】Serious Adverse Events\n----------------------\n\n【58】Serious adverse events occurred in 12.2% of the participants, with an even distribution across the two groups . Overall, the most common serious adverse events were asthma (in 7.2% of the participants), infection or infestation (in 1.6%), and cardiac events (in 1.5%), all of which were evenly distributed between the two groups. Hospitalization occurred in 11.8% of the participants in the intervention group and in 11.5% of those in the usual-care group. Three deaths occurred in the intervention group and 4 in the usual-care group. None of the deaths were considered by the investigators to be related to asthma.\n\n【59】Discussion\n----------\n\n【60】The disproportionate burden of asthma in underserved populations in the United States persists despite focused interventions.  In the PREPARE trial, we found that an intervention with a single in-person instruction session led to a 15.4% lower risk of severe asthma exacerbations and also reduced asthma symptoms and the number of days of impairment in Black and Latinx participants with moderate-to-severe asthma. Effects of the patient-activated, reliever-triggered inhaled glucocorticoid (PARTICS) intervention persisted over a period of 15 months and were accompanied by reduced quick-reliever use and a reported mean net difference in the use of glucocorticoid-containing inhalers of only 1.1 inhaler per year, according to a post hoc analysis.\n\n【61】The effects of the intervention were consistent across multiple domains of assessment. In the prespecified secondary analyses, the use of the intervention plus usual care appeared to improve asthma control (as assessed on the ACT) and preference-based quality of life (as assessed on the ASUI) by an amount that exceeded the minimal clinically important difference on each measure  and reduced the number of missed days of work, school, and usual activities. In post hoc analyses, these effects were accompanied by an 18% lower incidence of quick-reliever inhaler refills and by 32% fewer months of quick-reliever nebulizer use with the intervention than with usual care, which is important since the frequency of β <sub>2 </sub> \\-agonist quick-reliever use has been associated with mortality among patients with asthma. \n\n【62】The broad entry criteria and design of this trial could have reduced the apparent effectiveness of the patient-activated, reliever-triggered inhaled glucocorticoid strategy. We did not require evidence of bronchodilator responsiveness, we enrolled current and former smokers, and we did not require all participants to have had an exacerbation in the previous year. Application of these criteria to entry would have enriched the trial for a population with a greater response to inhaled glucocorticoids,  a factor that is also suggested by our interaction analysis . Nonetheless, the reduction in severe exacerbations that we observed (calculated to 0.13 fewer exacerbations per person per year) was similar to the mean reduction in asthma exacerbations (weighted according to sample size and study duration) in the 10 studies cited by the 2020 National Asthma Education and Prevention Program Focused Asthma Updates to support its paradigm-changing recommendation of the SMART strategy for severity steps 3 to 4 (i.e., 0.12 severe exacerbations per patient per year).  Post hoc calculations suggest that the effect with our intervention was observed with a minimal increase of 30 μg of inhaled glucocorticoid per day.\n\n【63】In contrast to resource-intensive strategies with varied effectiveness in reducing asthma morbidity among Black and Latinx patients, the patient-activated, reliever-triggered inhaled glucocorticoid strategy appears to be an easy-to-implement strategy that improves outcomes. Participants’ existing asthma treatment was not altered. Participant instruction was provided only once with the aid of a Web-based video; participants were sent monthly surveys regarding medication use, asthma control, and asthma exacerbations. We found that participants with low or marginal health literacy benefited from the addition of the trial intervention to usual care .\n\n【64】Several caveats should be considered in interpreting the trial outcomes. This trial was open-label, and we provided the intervention patient-activated, reliever-triggered inhaled glucocorticoid at no cost, with refills provided by mail on request. However, the mean additional glucocorticoid-containing inhaler use in the intervention group, as compared with the usual-care group, of 1.1 inhaler per year in a post hoc analysis represents a low cost burden to the health care system in light of the potential benefits. Mail-order delivery is likely to be accessible to nearly all patients. Although a placebo effect, as opposed to a trial participation effect, cannot be ruled out, the durability of the effect makes this situation less likely. We did not directly assess adrenal suppression, but given the small mean increase in inhaled glucocorticoid use that was seen in the post hoc analysis and the absence of any major safety signal, clinically significant adverse effects related to inhaled glucocorticoid in this population seem unlikely. Although the lower risk of severe asthma exacerbations with the intervention added to usual care was clinically important, the P value was 0.048.\n\n【65】Finally, although the intervention strategy was effective in a broad population of self-identified Black and Latinx participants, the population included many different ethnic groups , which may differ in asthma morbidity and possibly in responsiveness to this treatment strategy. In addition, women were overrepresented in this trial, and thus our findings may not be as generalizable to men. However, women constitute two thirds of adult patients with asthma  and bear a disproportionate asthma burden, as compared with men. \n\n【66】The mechanism by which the patient-activated, reliever-triggered inhaled glucocorticoid strategy produces its salutary effect is uncertain. We posit, as has been speculated with the SMART strategy, that it relates to the use of inhaled glucocorticoids early in the course of an asthma worsening.  It is possible that full implementation of SMART, as recently advocated by the 2020 National Asthma Education and Prevention Program Focused Asthma Updates  and by the Global Initiative for Asthma, may produce effects that equal or exceed the effects we observed. The SMART strategy offers the advantage of use of a single inhaler for both maintenance and reliever therapy, which potentially simplifies a patient’s regimen. However, as discussed, multiple implementation barriers to SMART exist, including the need to change the patient’s existing asthma therapy. Data on the SMART strategy in Black and Latinx populations or in patients who frequently use nebulized reliever therapy (2.9 times per week in our population) are limited. Use of nebulized reliever therapy can result in a potential failure to trigger extra use of inhaled glucocorticoid as the need for reliever therapy increases. In the United States, patients’ beliefs and preferences  and insurance reimbursement policies make the discontinuation of nebulizer use unlikely in the near future. \n\n【67】Reducing disparities in asthma morbidity in Black and Latinx populations has been difficult. In this trial involving an ethnically diverse population of Black and Latinx patients with moderate-to-severe asthma and multiple coexisting conditions, the provision of inhaled glucocorticoid with instructions for use triggered by quick-reliever use (PARTICS), added to existing usual care, led to a lower risk of severe asthma exacerbations. The outcome was observed after a single visit and appeared to be durable. Such a strategy may be easy to implement in populations with disproportionate asthma morbidity, as we continue to assess the effectiveness of additional interventions in diverse populations.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "【4】Download a PDF of the Research Summary .", "content": "【0】Reliever-Triggered Inhaled Glucocorticoid in Black and Latinx Adults with Asthma\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Black and Latinx patients bear a disproportionate burden of asthma. Efforts to reduce the disproportionate morbidity have been mostly unsuccessful, and guideline recommendations have not been based on studies in these populations.\n\n【3】Methods\n-------\n\n【4】Download a PDF of the Research Summary .\n\n【5】In this pragmatic, open-label trial, we randomly assigned Black and Latinx adults with moderate-to-severe asthma to use a patient-activated, reliever-triggered inhaled glucocorticoid strategy (beclomethasone dipropionate, 80 μg) plus usual care (intervention) or to continue usual care. Participants had one instructional visit followed by 15 monthly questionnaires. The primary end point was the annualized rate of severe asthma exacerbations. Secondary end points included monthly asthma control as measured with the Asthma Control Test (ACT; range, 5 \\[poor\\] to 25 \\[complete control\\]), quality of life as measured with the Asthma Symptom Utility Index (ASUI; range, 0 to 1, with lower scores indicating greater impairment), and participant-reported missed days of work, school, or usual activities. Safety was also assessed.\n\n【6】Results\n-------\n\n【7】Of 1201 adults (603 Black and 598 Latinx), 600 were assigned to the intervention group and 601 to the usual-care group. The annualized rate of severe asthma exacerbations was 0.69 (95% confidence interval \\[CI\\], 0.61 to 0.78) in the intervention group and 0.82 (95% CI, 0.73 to 0.92) in the usual-care group (hazard ratio, 0.85; 95% CI, 0.72 to 0.999; P=0.048). ACT scores increased by 3.4 points (95% CI, 3.1 to 3.6) in the intervention group and by 2.5 points (95% CI, 2.3 to 2.8) in the usual-care group (difference, 0.9; 95% CI, 0.5 to 1.2); ASUI scores increased by 0.12 points (95% CI, 0.11 to 0.13) and 0.08 points (95% CI, 0.07 to 0.09), respectively (difference, 0.04; 95% CI, 0.02 to 0.05). The annualized rate of missed days was 13.4 in the intervention group and 16.8 in the usual-care group (rate ratio, 0.80; 95% CI, 0.67 to 0.95). Serious adverse events occurred in 12.2% of the participants, with an even distribution between the groups.\n\n【8】Conclusions\n-----------\n\n【9】Among Black and Latinx adults with moderate-to-severe asthma, provision of an inhaled glucocorticoid and one-time instruction on its use, added to usual care, led to a lower rate of severe asthma exacerbations. \n\n【10】Introduction\n------------\n\n【11】 QUICK TAKE  \nInhaled Glucocorticoids in Black and Latinx Adults with Asthma  \n\n【12】In the United States, asthma results in considerable illness, including more than 3300 asthma-attributed deaths in adults each year.  Annual costs for asthma in adults total more than $67 billion  and are substantially higher in patients with uncontrolled asthma than in those with controlled asthma.  Owing to a complex array of factors,  Black and Latinx populations bear disproportionate asthma morbidity and mortality.  After adjustment for prevalence, the rates of asthma-related emergency department visits and hospitalizations are higher among Black and Latinx persons than among White persons,  and mortality from asthma is twice as high among Black and Latinx persons as among White persons.  Efforts to improve asthma management and reduce this burden have been labor-intensive, expensive, and variably effective. \n\n【13】Inhaled glucocorticoids are the backbone of asthma-controller therapy. Multiple studies have suggested that in patients with moderate-to-severe asthma, the use of a single inhaler containing a combination of a glucocorticoid and a rapid-onset long-acting β <sub>2 </sub> \\-agonist (LABA), used as a regular, twice-daily maintenance therapy, plus the use of an as-needed reliever therapy (i.e., a single maintenance and reliever therapy \\[SMART\\] strategy), can reduce asthma exacerbations more effectively than the previously more commonly recommended strategy of twice-daily use of the combination product with a short-acting β <sub>2 </sub> \\-agonist as the reliever. Guideline recommendations have recently been updated to reflect such approaches.  However, studies supporting the effectiveness of this strategy that have included substantial proportions of Black or Latinx patients have been limited.\n\n【14】Furthermore, few studies in moderate-to-severe asthma have been conducted in real-world U.S. settings in which patients commonly use nebulized β <sub>2 </sub> \\-agonists as quick-reliever therapy.  The use of nebulizers for quick relief interferes with the supplemental as-needed strategy of SMART, in which patients use combination inhaled glucocorticoid plus LABA instead of a reliever inhaler for acute symptoms, so that inhaled glucocorticoid is delivered each time the patient has symptoms warranting medication use. If patients use nebulizers for relief, they do not receive the intended inhaled glucocorticoid, since they are not using the combination inhaler for relief. Finally, barriers to implementation of the SMART strategy include a caution from the Food and Drug Administration against as-needed use of combination inhaled glucocorticoid plus LABA, the requirement to change the existing controller therapy to the specifically recommended combination inhaled glucocorticoid plus LABA, and varied insurance coverage for this approach. \n\n【15】Considering the disproportionate burden of asthma in Black and Latinx populations, the difficulties in reducing such morbidity, the paucity of data on the effectiveness of interventions specifically investigated in these populations, and the potential barriers to implementation of current recommendations, we conducted the Person Empowered Asthma Relief (PREPARE) trial. We investigated whether one-time instruction in an approach involving as-needed inhaled glucocorticoid (modified from Calhoun et al.,  on the basis of feedback from our patient partners and advisors and the results of a pilot study  ), added to existing therapy, could improve asthma outcomes in Black and Latinx patients with poorly controlled asthma in a trial with minimal exclusion criteria.\n\n【16】Methods\n-------\n\n【17】Trial Design and Oversight\n--------------------------\n\n【18】We conducted this randomized, open-label, pragmatic trial of the addition of a patient-activated, reliever-triggered inhaled glucocorticoid strategy, which we called PARTICS, to usual care in Black and Latinx patients with moderate-to-severe asthma in the continental United States and Puerto Rico. Full details of the trial protocol , which is available with the full text of this article at NEJM.org, have been published previously. \n\n【19】The investigators collaborated with Black and Latinx adults with asthma and with caregivers of persons with asthma (patient partners) and additional advisors. The authors designed the trial, gathered the data with assistance from DARTNet Institute and the Asthma Research Center at Brigham and Women’s Hospital (in Boston), and analyzed the data with the assistance of the Duke Clinical Research Institute (in Durham, NC). The authors vouch for the accuracy and completeness of the data and for the fidelity of the trial to the protocol. The first author wrote the first draft of the manuscript. All the authors made the decision to submit the manuscript for publication. There were no restrictive confidentiality agreements.\n\n【20】Patient Population\n------------------\n\n【21】Adults 18 to 75 years of age with clinician-diagnosed asthma who self-identified as Black or Latinx underwent screening at 19 primary care and specialty clinical organizations; the patients had been approached about participation before or at a clinic visit. All the participants provided written informed consent on a form that had been approved by the institutional review board of Partners HealthCare and local institutional review boards.\n\n【22】Key inclusion criteria were a status of being prescribed daily inhaled glucocorticoids, with or without LABA, and having either uncontrolled asthma (Asthma Control Test \\[ACT\\] score of ≤19 \\[indicating asthma that was not well controlled; scores range from 5 to 25, with lower scores indicating less control; minimal clinically important difference, 3\\]) or at least one participant-reported asthma exacerbation leading to the use of systemic glucocorticoids or overnight hospitalization in the previous year. Former or current smokers were included in the trial, and there were minimal other exclusions.  Patients who were taking regular systemic glucocorticoids were excluded.\n\n【23】Trial Procedures\n----------------\n\n【24】 Site clinicians underwent asthma-treatment training with the Asthma IQ.  The clinician care that was provided during the trial is referred to here as usual care. During the subsequent 15 months, clinicians were free to modify usual care as necessary.\n\n【25】At the only in-person trial visit, participants were randomly assigned in a  ratio either to use a patient-activated, reliever-triggered inhaled glucocorticoid strategy plus usual care (intervention) or to continue usual care. Centralized randomization was stratified according to trial site and race and ethnic group. At this visit, participants received instructions, completed questionnaires, and watched a video that was appropriate to the randomization group. All the trial materials were available in English and Spanish.\n\n【26】All the participants received a trial-specific pouch designed to hold two metered-dose inhalers. Participants in the intervention group received an open-label inhaler that administered a metered dose of 80 μg of beclomethasone dipropionate (QVAR \\[Teva Pharmaceuticals\\]; the QVAR RediHaler was used after December 2018 owing to discontinuation of the QVAR inhaler). Participants who had been using a nebulized quick-reliever received an additional QVAR inhaler to place with their nebulizer. They were instructed to take one puff of inhaled glucocorticoid for each puff of quick-reliever inhaler and five puffs of inhaled glucocorticoid with each quick-reliever nebulization. Participants could request intervention QVAR refills from the trial pharmacy (AssistRx) by means of a toll-free telephone number.\n\n【27】Participants were followed for up to 15 months by means of monthly surveys, which were administered according to participant preference (Internet, telephone, or mail). They received cash compensation for their visit and for completed surveys. In a subgroup of participants, the fraction of exhaled nitric oxide (F e NO) was measured at baseline, and blood eosinophil counts were obtained at baseline or from records of the previous year.\n\n【28】End Points\n----------\n\n【29】End points were selected on the basis of input from patient partners and advisors. These end points included exacerbations, owing to their reported disruptive effect; quality of life; and missed days of work, school, or usual activities. In line with these preferences, the primary end point was the annualized rate of American Thoracic Society–defined severe asthma exacerbations (those that led to the use of systemic glucocorticoids for ≥3 days or to an asthma-related hospitalization).  Severe asthma exacerbations were noted on monthly questionnaires. Central investigators who were unaware of the treatment assignments verified exacerbations by means of site medical records or direct contact with participants.\n\n【30】Prespecified secondary end points included monthly asthma control as measured with the ACT,  preference-based quality of life as measured with the Asthma Symptom Utility Index (ASUI; scores range from 0 to 1, with lower scores indicating greater impairment; minimal clinically important difference, 0.09),  and participant-reported days missed from work, school, or usual activities.  Data on adverse events that resulted in hospitalization or death were obtained by participant report or site report.\n\n【31】Statistical Analysis\n--------------------\n\n【32】Assuming a severe exacerbation rate of 0.4 exacerbations per participant per year  and an annualized loss to follow-up of 25%, we calculated that a sample of 1200 participants (600 per group) would provide the trial with 80% power to detect a 23.5% difference in the exacerbation rate. The timing and frequency of severe asthma exacerbations were compared with the use of the Andersen–Gill adaptation of the time-to-event Cox proportional-hazards model, with stratification according to race and ethnic group and with adjustment for baseline characteristics and for a time-dependent covariate to account for the effects of coronavirus disease 2019 on the rate of severe asthma exacerbations. \n\n【33】All the major between-group treatment comparisons were performed in the intention-to-treat population, which included all the participants who had undergone randomization except for any from a prematurely closed trial site. Details of the analyses of the secondary and exploratory end points are provided in the statistical analysis plan. Statistical analyses were performed with the use of SAS software, version 9.4 (SAS Institute).\n\n【34】A P value of 0.15 or less was prespecified for interaction testing of the effect of the two racial and ethnic groups to permit separate analysis within each group. Missing-data analyses were to be performed if the percent of missing data reached a prespecified threshold of 5%. Results are reported with 95% confidence intervals. The widths of the confidence intervals for secondary, post hoc, and safety analyses have not been adjusted for multiplicity and thus should not be used to infer definitive treatment effects.\n\n【35】Results\n-------\n\n【36】Population and Follow-up\n------------------------\n\n【37】Table 1. Characteristics of the Participants at Baseline.\n\n【38】From November 2017 through March 2021, a total of 1201 participants (603 Black and 598 Latinx) underwent randomization, with 600 participants being assigned to the intervention group and 601 to the usual-care group . A total of 83.7% of the participants were women . Approximately half the participants reported health that was fair to poor with multiple coexisting conditions; 68.8% of the participants had obesity, and approximately 20% were current or former smokers. The ACT and ASUI scores indicated poor asthma control and a clinically significant burden of asthma.  A total of 72.2% of the participants reported having had at least one asthma exacerbation that led to the use of systemic glucocorticoids in the previous year. A total of 71.5% of the participants used combination inhaled glucocorticoid plus LABA, and 66.9% used a nebulizer for quick-reliever therapy; 67.5% of those participants (45.2% of the overall population) reported using at least one nebulizer treatment per week. Among the participants with measurements, 30.1% had a F e NO of at least 30 parts per billion, and 26.6% had a blood eosinophil count of at least 300 per cubic millimeter. The characteristics of the participants according to race and ethnic group are shown in Table S2. The representativeness of the participants is discussed in Table S6.\n\n【39】The median follow-up was 14.9 months in each group. Survey returns did not differ according to treatment group (96.2% of the expected periods in the intervention group and 96.7% of those in the usual-care group).\n\n【40】Adherence to the Intervention\n-----------------------------\n\n【41】Among participants in the intervention group, 81.0% reported using inhaled glucocorticoid with quick-reliever metered-dose inhalers all or most of the time, and 75.7% reported using inhaled glucocorticoid with quick-reliever nebulization all or most of the time. A total of 50.4% of the participants in this group reported using at least four of the instructed five puffs of inhaled glucocorticoid per quick-reliever nebulization.\n\n【42】Primary End Point\n-----------------\n\n【43】Table 2. Primary, Secondary, Post hoc, and Safety Analyses. Figure 1.  Figure 1. Mean Cumulative Number of Severe Asthma Exacerbations per Participant over Time, with Adjusted Hazard Ratio.\n\n【44】Shown are the mean cumulative numbers of severe asthma exacerbations per participant over time. Participants in the intervention group received patient-activated, reliever-triggered inhaled glucocorticoid in addition to usual care. Differences in treatment-group hazards were compared with the use of the Andersen–Gill model with adjustment for prespecified covariates.\n\n【45】The annualized rate of severe asthma exacerbations was 0.69 (95% confidence interval \\[CI\\], 0.61 to 0.78) in the intervention group and 0.82 (95% CI, 0.73 to 0.92) in the usual-care group (hazard ratio, 0.85; 95% CI, 0.72 to 0.999; P=0.048)  . This difference was consistent throughout the duration of the trial . Point estimates from sensitivity analyses of the primary end point were consistent with the overall finding, although not all the results were significant . Primary end-point results according to trial site are shown in Figure S3. The percent of missing data (3%) did not reach the prespecified threshold of 5%, so missing-data analyses were not performed.\n\n【46】Secondary End Points\n--------------------\n\n【47】Figure 2. Mean Changes from Baseline in Asthma-Related Scores.\n\n【48】The least-squares mean differences between treatment groups in the changes from baseline in asthma-related scores were calculated with the use of a mixed model. The Asthma Control Test  is a participant-administered tool for assessing the level of asthma control. Total scores range from 5 to 25, with a score of 20 to 25 indicating well-controlled asthma, a score of 16 to 19 indicating asthma that was not well controlled, and a score of 5 to 15 indicating very poorly controlled asthma; the minimal clinically important difference is 3 points. The Asthma Symptom Utility Index  is a participant-administered tool for assessing preference-based quality of life. The summary score is on a continuous scale, ranging from 0 (worst possible symptoms) to 1 (no symptoms); the minimal clinically important difference is 0.09. 𝙸 bars indicate 95% confidence intervals. The widths of the confidence intervals have not been adjusted for multiplicity and cannot be used to infer treatment effects.\n\n【49】The strategy in the intervention group led to an increase in the ACT scores (minimal clinically important difference, 3 points)  of 3.4 points, as compared with an increase of 2.5 points in the usual-care group (difference, 0.9 points; 95% CI, 0.5 to 1.2) . The intervention strategy also led to an increase in the ASUI score (minimal clinically important difference, 0.09 points)  of 0.12 points, as compared with an increase of 0.08 points in the usual-care group (difference, 0.04 points; 95% CI, 0.02 to 0.05) . Participants in the intervention group had 13.4 annualized days missed of work, school, and usual activities, as compared with 16.8 annualized days missed in the usual-care group (rate ratio, 0.80; 95% CI, 0.67 to 0.95) .\n\n【50】Post hoc and Safety Analyses\n----------------------------\n\n【51】In a post hoc analysis, participants in the intervention group reported a mean 0.75 months per year in which an emergency department or urgent care visit occurred, as compared with 0.90 months per year in the usual-care group (rate ratio, 0.84; 95% CI, 0.68 to 1.03). In the safety analysis, there were 70 asthma-related hospitalizations in the intervention group and 84 in the usual-care group (rate ratio, 0.84; 95% CI, 0.50 to 1.42).\n\n【52】Post hoc analyses of medication use based on participants’ monthly surveys showed that participants in the intervention group used 1.1 extra inhaler containing inhaled glucocorticoid per year as compared with the usual-care group (8.9 vs. 7.8 inhalers per year). Participants in the intervention group also reported fewer refills of the quick-reliever metered-dose inhaler than those in the usual-care group (4.6 vs. 5.6 refills), as well as fewer months in which they used quick-reliever nebulizer (3.6 vs. 5.4 months) .\n\n【53】Subgroup Analyses\n-----------------\n\n【54】Figure 3. Subgroup Analyses of Severe Asthma Exacerbation Outcome.\n\n【55】The forest plot shows the risk of severe asthma exacerbations in selected prespecified subgroups. The widths of the confidence intervals have not been adjusted for multiplicity and cannot be used to infer treatment effects. Race was reported by the participant; those who identified as both Black and Latinx were classified as Latinx. Nonsmokers were those who had not smoked within the previous year and had smoked less than 10 pack-years. The participant’s attitude toward asthma medications was assessed with the Beliefs about Medicines Questionnaire; the “accepting” category indicates that the participant believed the therapy was of high necessity and low concern.  Depressive status was assessed with the Patient Health Questionnaire–2; scores range from 0 to 6, with a score of 3 or higher indicating depression.  The Brief Health Literacy Scale measures participant-reported health literacy and consists of three items. If a participant’s response on any item indicated low or marginal health literacy, the participant was considered to have low or marginal health literacy; otherwise, health literacy was considered to be high.  The body-mass index is the weight in kilograms divided by the square of the height in meters. Participant-reported medication adherence was assessed with the Medication Adherence Report Scale–5 by the calculation of the mean score over the five items. Mean scores range from 1 to 5, with higher scores indicating better adherence.  F e NO denotes fraction of exhaled nitric oxide, LABA long-acting β <sub>2 </sub> \\-agonist, and ppb parts per billion.\n\n【56】Hazard ratios for severe asthma exacerbations in prespecified subgroups are shown in Figure 3 . The hazard ratio for severe exacerbations with the intervention as compared with usual care was 0.77 among Black participants and 0.92 among Latinx participants (P=0.29 for interaction, which exceeded our prespecified limit for stratified analyses).\n\n【57】Serious Adverse Events\n----------------------\n\n【58】Serious adverse events occurred in 12.2% of the participants, with an even distribution across the two groups . Overall, the most common serious adverse events were asthma (in 7.2% of the participants), infection or infestation (in 1.6%), and cardiac events (in 1.5%), all of which were evenly distributed between the two groups. Hospitalization occurred in 11.8% of the participants in the intervention group and in 11.5% of those in the usual-care group. Three deaths occurred in the intervention group and 4 in the usual-care group. None of the deaths were considered by the investigators to be related to asthma.\n\n【59】Discussion\n----------\n\n【60】The disproportionate burden of asthma in underserved populations in the United States persists despite focused interventions.  In the PREPARE trial, we found that an intervention with a single in-person instruction session led to a 15.4% lower risk of severe asthma exacerbations and also reduced asthma symptoms and the number of days of impairment in Black and Latinx participants with moderate-to-severe asthma. Effects of the patient-activated, reliever-triggered inhaled glucocorticoid (PARTICS) intervention persisted over a period of 15 months and were accompanied by reduced quick-reliever use and a reported mean net difference in the use of glucocorticoid-containing inhalers of only 1.1 inhaler per year, according to a post hoc analysis.\n\n【61】The effects of the intervention were consistent across multiple domains of assessment. In the prespecified secondary analyses, the use of the intervention plus usual care appeared to improve asthma control (as assessed on the ACT) and preference-based quality of life (as assessed on the ASUI) by an amount that exceeded the minimal clinically important difference on each measure  and reduced the number of missed days of work, school, and usual activities. In post hoc analyses, these effects were accompanied by an 18% lower incidence of quick-reliever inhaler refills and by 32% fewer months of quick-reliever nebulizer use with the intervention than with usual care, which is important since the frequency of β <sub>2 </sub> \\-agonist quick-reliever use has been associated with mortality among patients with asthma. \n\n【62】The broad entry criteria and design of this trial could have reduced the apparent effectiveness of the patient-activated, reliever-triggered inhaled glucocorticoid strategy. We did not require evidence of bronchodilator responsiveness, we enrolled current and former smokers, and we did not require all participants to have had an exacerbation in the previous year. Application of these criteria to entry would have enriched the trial for a population with a greater response to inhaled glucocorticoids,  a factor that is also suggested by our interaction analysis . Nonetheless, the reduction in severe exacerbations that we observed (calculated to 0.13 fewer exacerbations per person per year) was similar to the mean reduction in asthma exacerbations (weighted according to sample size and study duration) in the 10 studies cited by the 2020 National Asthma Education and Prevention Program Focused Asthma Updates to support its paradigm-changing recommendation of the SMART strategy for severity steps 3 to 4 (i.e., 0.12 severe exacerbations per patient per year).  Post hoc calculations suggest that the effect with our intervention was observed with a minimal increase of 30 μg of inhaled glucocorticoid per day.\n\n【63】In contrast to resource-intensive strategies with varied effectiveness in reducing asthma morbidity among Black and Latinx patients, the patient-activated, reliever-triggered inhaled glucocorticoid strategy appears to be an easy-to-implement strategy that improves outcomes. Participants’ existing asthma treatment was not altered. Participant instruction was provided only once with the aid of a Web-based video; participants were sent monthly surveys regarding medication use, asthma control, and asthma exacerbations. We found that participants with low or marginal health literacy benefited from the addition of the trial intervention to usual care .\n\n【64】Several caveats should be considered in interpreting the trial outcomes. This trial was open-label, and we provided the intervention patient-activated, reliever-triggered inhaled glucocorticoid at no cost, with refills provided by mail on request. However, the mean additional glucocorticoid-containing inhaler use in the intervention group, as compared with the usual-care group, of 1.1 inhaler per year in a post hoc analysis represents a low cost burden to the health care system in light of the potential benefits. Mail-order delivery is likely to be accessible to nearly all patients. Although a placebo effect, as opposed to a trial participation effect, cannot be ruled out, the durability of the effect makes this situation less likely. We did not directly assess adrenal suppression, but given the small mean increase in inhaled glucocorticoid use that was seen in the post hoc analysis and the absence of any major safety signal, clinically significant adverse effects related to inhaled glucocorticoid in this population seem unlikely. Although the lower risk of severe asthma exacerbations with the intervention added to usual care was clinically important, the P value was 0.048.\n\n【65】Finally, although the intervention strategy was effective in a broad population of self-identified Black and Latinx participants, the population included many different ethnic groups , which may differ in asthma morbidity and possibly in responsiveness to this treatment strategy. In addition, women were overrepresented in this trial, and thus our findings may not be as generalizable to men. However, women constitute two thirds of adult patients with asthma  and bear a disproportionate asthma burden, as compared with men. \n\n【66】The mechanism by which the patient-activated, reliever-triggered inhaled glucocorticoid strategy produces its salutary effect is uncertain. We posit, as has been speculated with the SMART strategy, that it relates to the use of inhaled glucocorticoids early in the course of an asthma worsening.  It is possible that full implementation of SMART, as recently advocated by the 2020 National Asthma Education and Prevention Program Focused Asthma Updates  and by the Global Initiative for Asthma, may produce effects that equal or exceed the effects we observed. The SMART strategy offers the advantage of use of a single inhaler for both maintenance and reliever therapy, which potentially simplifies a patient’s regimen. However, as discussed, multiple implementation barriers to SMART exist, including the need to change the patient’s existing asthma therapy. Data on the SMART strategy in Black and Latinx populations or in patients who frequently use nebulized reliever therapy (2.9 times per week in our population) are limited. Use of nebulized reliever therapy can result in a potential failure to trigger extra use of inhaled glucocorticoid as the need for reliever therapy increases. In the United States, patients’ beliefs and preferences  and insurance reimbursement policies make the discontinuation of nebulizer use unlikely in the near future. \n\n【67】Reducing disparities in asthma morbidity in Black and Latinx populations has been difficult. In this trial involving an ethnically diverse population of Black and Latinx patients with moderate-to-severe asthma and multiple coexisting conditions, the provision of inhaled glucocorticoid with instructions for use triggered by quick-reliever use (PARTICS), added to existing usual care, led to a lower risk of severe asthma exacerbations. The outcome was observed after a single visit and appeared to be durable. Such a strategy may be easy to implement in populations with disproportionate asthma morbidity, as we continue to assess the effectiveness of additional interventions in diverse populations.", "index": 384, "show": true, "start": 384, "end": 427, "province": ["文本干净度", "无关文本"], "isEdit": false}]}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-14 00:21:24", "grab_time": "2024-08-13 23:44:03"}
{"id": 2234462, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "1a048175-1719-4f99-a0f1-de76f991c197", "title": "Liver Disease and Common-Bile-Duct Stenosis in Cystic Fibrosis", "text": "【0】Liver Disease and Common-Bile-Duct Stenosis in Cystic Fibrosis\nAbstract\n--------\n\n【1】To determine the incidence of common-bile-duct lesions and their relation to liver disease in cystic fibrosis, we performed hepatobiliary scanning in 50 of 61 patients with cystic fibrosis who had hepatomegaly, abnormal liver function, or both and in 31 of 92 patients with cystic fibrosis who did not have hepatomegaly or abnormal liver function.\n\n【2】Ninety-six percent of the patients with liver disease had evidence of biliary tract obstruction, which was defined cholangiographically as a stricture of the distal common bile duct in the majority of cases. All the patients without liver disease had normal intrahepatic and common-duct excretion of tracer.\n\n【3】Abdominal pain was significantly more common in patients with common-duct obstruction (P<0.001), and enlarged gallbladders occurred only in such patients. Since fasting levels of serum bile acids were elevated in nearly half these patients, irrespective of the severity of their liver disease, serum bile acids may be markers of the severity of the common-duct lesion.\n\n【4】We conclude that strictures of the distal common bile duct are common in patients with cystic fibrosis and liver disease. This association requires further study, since surgical relief of common-duct obstruction may prevent or ameliorate the hepatic complications of cystic fibrosis.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:45:10", "endTime": "2024/08/14 14:46:18", "cost": 68.467}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 22:46:19", "grab_time": "2024-08-13 22:45:10"}
{"id": 2234461, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "b4b07794-29b1-4c9e-bdd7-a00404a9a76f", "title": "Effects of Pay for Performance on the Quality of Primary Care in England", "text": "【0】Effects of Pay for Performance on the Quality of Primary Care in England\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】A pay-for-performance scheme based on meeting targets for the quality of clinical care was introduced to family practice in England in 2004.\n\n【3】Methods\n-------\n\n【4】We conducted an interrupted time-series analysis of the quality of care in 42 representative family practices, with data collected at two time points before implementation of the scheme (1998 and 2003) and at two time points after implementation (2005 and 2007). At each time point, data on the care of patients with asthma, diabetes, or coronary heart disease were extracted from medical records; data on patients' perceptions of access to care, continuity of care, and interpersonal aspects of care were collected from questionnaires. The analysis included aspects of care that were and those that were not associated with incentives.\n\n【5】Results\n-------\n\n【6】Between 2003 and 2005, the rate of improvement in the quality of care increased for asthma and diabetes (P<0.001) but not for heart disease. By 2007, the rate of improvement had slowed for all three conditions (P<0.001), and the quality of those aspects of care that were not associated with an incentive had declined for patients with asthma or heart disease. As compared with the period before the pay-for-performance scheme was introduced, the improvement rate after 2005 was unchanged for asthma or diabetes and was reduced for heart disease (P=0.02). No significant changes were seen in patients' reports on access to care or on interpersonal aspects of care. The level of the continuity of care, which had been constant, showed a reduction immediately after the introduction of the pay-for-performance scheme (P<0.001) and then continued at that reduced level.\n\n【7】Conclusions\n-----------\n\n【8】Against a background of increases in the quality of care before the pay-for-performance scheme was introduced, the scheme accelerated improvements in quality for two of three chronic conditions in the short term. However, once targets were reached, the improvement in the quality of care for patients with these conditions slowed, and the quality of care declined for two conditions that had not been linked to incentives. Continuity of care was reduced after the introduction of the scheme.\n\n【9】Introduction\n------------\n\n【10】In 2004, the U.K. government introduced a pay-for-performance scheme with 136 indicators for family practices. The indicators covered the management of chronic disease, practice organization, and patients' experiences with respect to care.  In 2006, revisions to the scheme added seven new clinical areas, including dementia and chronic kidney disease, and two new indicators of patient access to care .  Payments make up approximately 25% of family practitioners' income, and 99.6% of family practitioners participated in the pay-for-performance scheme, which is voluntary.\n\n【11】We have previously reported on the quality of clinical care in 2005, the year after the pay-for-performance scheme was introduced.  We found a modest acceleration in the rate of improvement in the quality of care for asthma and diabetes but not for heart disease. There had been rapid improvement in the quality of care for all three conditions before the introduction of pay for performance. This article extends these analyses to include performance data in 2007. We used an interrupted time-series analysis to examine trends in the quality of clinical care from 1998 through 2007, a period spanning the introduction of pay for performance. We also report on trends in patient reports on communication with their physician, on access to care, and on continuity of care across the same period.\n\n【12】Methods\n-------\n\n【13】Data Collection\n---------------\n\n【14】Trained research staff abstracted clinical data from the medical records kept by 42 nationally representative family practices. In each practice, data were collected for nonoverlapping random samples of patients (20 in 1998 and 12 each in 2003, 2005, and 2007) who had heart disease, asthma, or diabetes; the data were collected with the use of quality indicators.  The methods used to collect data in 2007 were consistent with the methods used in 1998, 2003, and 2005. \n\n【15】For patient evaluation, a version of the General Practice Assessment Questionnaire  was mailed, with one follow-up reminder, to a random sample of 200 registered adult patients (age, ≥18 years) in each practice.  Rapid access to any doctor within 48 hours was associated with an incentive under the pay-for-performance scheme, and our questionnaire included two items addressing the patient's ability to get an appointment within 48 hours with “any doctor” and with “a particular doctor.” Because of concern that the scheme's focus on clinical indicators might lead practitioners to neglect other aspects of care,  we also analyzed communication with physicians and continuity of care. Communication was assessed by asking seven questions, with the answers scored on a six-point scale ranging from “very poor” to “excellent”; continuity of care was assessed with the use of the same six-point scale and a single question: “How often do you see your usual doctor?” All scores were rescaled to range from 0 to 100. The rate of response to the survey was 38% in 1998, 47% in 2003, 45% in 2005, and 38% in 2007. In all cases, higher scores indicate higher quality of care. The research protocol was approved by the North West Research Ethics Committee.\n\n【16】Statistical Analysis\n--------------------\n\n【17】As we had done previously,  we computed an overall clinical quality score for each patient in 1998, 2003, 2005, and 2007, which was based on the number of indicators for which appropriate care was provided, divided by the number of indicators relevant to that patient. This score represents the percentage, from 0 to 100%, of “necessary” or “indicated” care provided to the patient. Practice-level quality scores were computed as the mean of individual patient scores in each practice. We computed separate quality scores for the subgroups of indicators that were assigned incentives under the pay-for-performance scheme and for the subgroups that were not assigned incentives.\n\n【18】Data on quality of care had been collected in the same practices in 1998.  When a pay-for-performance scheme was announced for commencement in 2004, we designed an interrupted time-series study whereby data on quality of care would be collected at two points before the scheme was introduced (1998 and 2003) and at two points after its introduction (2005 and 2007). We use the term “pre-introduction period” to refer to the period from 1998 through 2003, “introduction period” for 2003 through 2005 (from the year before to the year after the implementation of pay for performance), and “post-introduction period” for 2005 through 2007.\n\n【19】We analyzed the data as an interrupted, or segmented, time series. In this model, the within-practice variation was partitioned into three main components to provide independent tests of the slope in scores for the pre-introduction period (test 1); the change in level during the introduction period, allowing for the trend before pay for performance (test 2); and the change in slope from before to after pay for performance (test 3).  Practice was treated as a random effect, and robust standard-error estimates were used .\n\n【20】The analysis for each outcome measure was conducted in two steps. In step 1, we used the interrupted time-series analysis to look for evidence that pay for performance was having an effect on the trend in scores over time, as indicated by a statistically significant result with respect to either the change in level or the change in slope (tests 2 and 3). The results of these tests determined step 2: if the results of neither test were significant, there was no evidence that pay for performance had affected the preexisting trend and we conducted no further analyses; if the results of either test were significant, there was evidence of an effect and we investigated this further by using the coefficients from the time-series analysis to compare the immediate- and long-term effects of the scheme (i.e., compare the slope during the introduction period with the slope during the post-introduction period) and to estimate the size of the effect on mean quality scores in 2005 and 2007.\n\n【21】We compared the trends in quality scores for the subgroups of indicators associated with incentives and indicators not associated with incentives by means of interactions between indicator set and the changes in level and slope (as defined above) within a regression analysis. If either interaction was significant, we took this as evidence that the trends varied by indicator set and next tested the interaction between indicator set and the change in slope from the introduction period to the post-introduction period.\n\n【22】The quality scores based on medical records and those based on patient evaluation are subject to ceilings of 100%, and many practices achieved this level on at least one indicator. The ceiling necessarily limits any linear trend in improvement, since a score on quality cannot exceed 100%. Analyses were therefore conducted on scores transformed to a logit scale, which has no ceiling, as described previously.  The transformation increases the weight given to score changes near the ceiling or floor — for example, score changes from 97 to 98% and from 55 to 65% are numerically equivalent (0.41) after transformation. However, where possible, results are re-expressed in original units to facilitate interpretation.\n\n【23】To assess the sensitivity of the findings to our statistical assumptions, we varied the method of statistical inference with the use of a bootstrap method, using 1000 bootstrap samples, and we assumed a linear model for the trend by repeating the analysis on untransformed scores (for details see the Supplementary Appendix ). We report any results that differ from those of the primary analysis.\n\n【24】Results\n-------\n\n【25】Coronary Heart Disease\n----------------------\n\n【26】Table 1. Mean Clinical-Quality Scores for 42 Family Practices in 1998, 2003, 2005, and 2007. Table 2. Table 2. Summary of Interrupted Time-Series Analysis. Figure 1.  Figure 1. Mean Scores for the Quality of Care at the Practice Level, 1998–2007.\n\n【27】Panel A shows scores for the quality of care provided for coronary heart disease, asthma, and diabetes. Quality scores range from 0% (no quality indicator was met for any patient) to 100% (all quality indicators were met for all patients). Panel B shows scores for patients' perceptions of communication with physicians, access to care, and continuity of care. Communication was assessed by asking seven questions, with the answers scored on a six-point scale ranging from “very poor” to “excellent”; continuity of care was assessed with the use of the same six-point scale and a single question: “How often do you see your usual doctor?” Access to care was scored as the percentage of patients who reported that they were able to get an appointment within 48 hours. All scores were rescaled to range from 0 to 100.Table 3.  Table 3. Mean Clinical-Quality Scores in 1998, 2003, 2005, and 2007, According to Individual Clinical Indicators.\n\n【28】The quality of care for coronary heart disease had been improving before the pay-for-performance incentives were introduced . The rate of increase was equivalent to an average of 3.5% per annum from 1998 through 2003 (95% confidence interval \\[CI\\], 2.8 to 4.2; P<0.001). In 2005, after the introduction of pay for performance, scores on quality rose slightly, but not significantly, higher than expected, as compared with the trend before the introduction of pay for performance (P=0.06). Subsequently, the rate of improvement dropped below the improvement rates for both the pre-introduction period (P=0.02) and the introduction period (P=0.001), and the overall quality score in 2007 (84.8; 95% CI, 82.2 to 87.4) was similar to that in 2005 (85.0; 95% CI, 83.0 to 87.1) .\n\n【29】Asthma\n------\n\n【30】The quality of care for asthma was improving during the pre-introduction period, at an average rate of 2.0% per annum (95% CI, 0.9 to 3.1; P<0.001), and there was a significant change in the level of quality over and above this trend in 2005 (P<0.001) . However, this accelerated rate of increase was not maintained after 2005 (P=0.001). The trend after 2005 did not differ significantly from the trend before the introduction of pay for performance (P=0.16), although in absolute terms, overall quality hardly changed between 2005 (84.3; 95% CI, 80.6 to 88.1) and 2007 (85.0; 95% CI, 82.2 to 87.8) .\n\n【31】Diabetes\n--------\n\n【32】The quality of care for patients with diabetes was improving in the pre-introduction period, at an average rate of 1.8% per annum (95% CI, 1.1 to 2.4; P<0.001) . Diabetes care, like asthma care, showed a significant change in the level of improvement after the introduction of pay for performance that was well above the preexisting trend (P<0.001). As with asthma care, this accelerated rate of improvement was not maintained after 2005 (P<0.001); instead, the rate fell back to the pre-introduction level (P=0.91) .\n\n【33】Effect of Incentives on Quality Scores\n--------------------------------------\n\n【34】Figure 2. Mean Scores for Clinical Quality at the Practice Level for Aspects of Care for Coronary Heart Disease, Asthma, and Type 2 Diabetes That Were Linked with Incentives and Aspects of Care That Were Not Linked with Incentives, 1998–2007.\n\n【35】Quality scores range from 0% (no quality indicator was met for any patient) to 100% (all quality indicators were met for all patients).\n\n【36】Mean quality scores for aspects of care that were linked to incentives were higher than those for care that was not linked to incentives, and this pattern applied to all conditions at all four time points . Allowing for these overall differences, there were further differences over time in the scores for aspects of care that were linked to incentives as compared with those that were not. For heart disease, the scores for aspects of care that were linked to incentives showed a bigger immediate increase when the pay-for-performance system was introduced (P=0.05), although this trend was not significant as calculated in the linear model (P=0.46). The long-term trends (scores in the post-introduction period vs. scores in the pre-introduction period) did not differ significantly (P=0.06). However, the difference was significant when calculated with the use of the bootstrapping method (P=0.05) or the linear model (P=0.03), and in absolute terms, the mean quality score for aspects of care for heart disease that were not linked to incentives declined after 2005, whereas the quality score for care that was linked to incentives increased. For asthma, the immediate effect of pay for performance did not differ between care that was and care that was not linked with incentives (P=1.00), but the trends subsequently diverged (post-introduction period vs. pre-introduction period, P=0.006; post-introduction period vs. introduction period, P=0.05), with the mean score for care that was not linked to incentives declining after 2005, and the mean score for care that was linked to incentives increasing. Trends in diabetes care did not differ at any time according to whether the care was linked to incentives.\n\n【37】Communication, Waiting Times, and Continuity of Care\n----------------------------------------------------\n\n【38】The percentages of patients able to see a physician within 48 hours, as well as the mean scores on the physician-communication scale, showed no significant changes in trend. Continuity of care declined significantly after the introduction of pay for performance (P<0.001) and remained at this lower level .\n\n【39】Estimated Overall Effect of Pay for Performance\n-----------------------------------------------\n\n【40】For outcomes in which there was evidence that pay for performance altered the trend in quality improvement, we used coefficients from the interrupted time-series analysis to compute estimates of the increase in scores beyond that expected from the trend in the pre-introduction period (back-transforming the results from the logit analysis, with estimated 95% confidence limits). As compared with the expected level of improvement based on the pre-introduction trend, the pay-for-performance scheme was associated with an improvement in the quality of care for diabetes of 7.5 percentage points in 2005 (95% CI, 4.7 to 10.4) and 6.9 percentage points in 2007 (95% CI, 3.8 to 10.0). For asthma, the increase in quality potentially attributable to pay for performance was 9.4 percentage points in 2005 (95% CI, 3.9 to 15.0) and 5.5 percentage points in 2007 (95% CI, −1.0 to 12.1). For heart disease, pay for performance in 2005 was associated with a nonsignificant improvement in quality above the levels expected (2.8 percentage points; 95% CI, −0.1 to 5.8), and in 2007, it was associated with a nonsignificant reduction in quality from that expected (0.8 percentage points; 95% CI, −4.7 to 3.1). The results of patient evaluations of continuity of care were 4.1 percentage points lower than expected in 2005 (95% CI, −6.1 to −2.0) and 4.3 percentage points lower in 2007 (95% CI, −6.9 to −1.6).\n\n【41】Discussion\n----------\n\n【42】We previously found that there were improvements in some aspects of clinical care over and above the underlying trend after the introduction of a pay-for-performance scheme.  Our current findings suggest that although these initial improvements were maintained, for two of the three conditions studied (heart disease and asthma), improvements in the quality of care reached a plateau a year after the scheme's introduction. Allowing for ceiling effects, care for diabetes continued to improve, but it did so at a rate equivalent to that of the rate in the pre-introduction period.\n\n【43】Within these overall trends for care, we found significant differences between aspects of care that were linked to incentives and aspects of care that were not linked to incentives. For asthma and heart disease, we found a significant difference in the effect of pay for performance on these two groups of quality indicators; for both conditions, mean quality scores for aspects of care that were not linked to incentives dropped between 2005 and 2007, whereas mean scores for aspects of care that were linked to incentives continued to increase. This widening gap in quality came on top of already lower levels of care for indicators not linked to incentives.\n\n【44】For all aspects of care — whether associated with incentives or not — and for all three conditions, rates of quality improvement slowed considerably after 2005. There are several possible explanations. The first is that near-maximal scores had been achieved. However, whereas achievement was high for some indicators (e.g., smoking status recorded for more than 98% of patients for all conditions), the logit transformation theoretically eliminates ceiling effects, and we observed the same plateau effect for indicators reflecting lower levels of achievement. A second explanation is that once initial gains had been made, subsequent gains were more difficult to achieve. A third explanation is that the structure of the pay-for-performance scheme did not reward further improvement once targets had been attained. This explanation is supported by the fact that family practices in our study gained, on average, 96.9% of available clinical-quality payment points in 2005 and 97.8% in 2007 (which were similar to the average gains of 97.1% and 97.5%, respectively, for all family practices in England  ) — that is, there was little financial incentive for further improvement. A fourth explanation is that family practitioners had sufficient income and had little personal motivation to improve performance and income further (the target-income hypothesis); this explanation would be consistent with the 30 to 40% gains in family practitioners' net income from the 2002–2003 period to the 2005–2006 period. \n\n【45】Our data cannot be used to ascertain the relative merit of these explanations. However, government negotiators in England appear to endorse the third explanation (too many physicians achieving maximal or near-maximal payments for quality of care). Alterations of the pay-for-performance scheme in 2006 introduced higher thresholds for maximal clinical-quality payments and a wider range of indicators .\n\n【46】This study suggests that continuity of care declined after pay for performance was introduced. One possible explanation is that practices focused on meeting rapid-access targets in which access to any doctor in the practice within 48 hours was linked to incentives but access to a particular physician was not,  making it more difficult for patients to see their own doctor. This could be an unintended and perverse effect of the scheme and is a concern, since continuity is an aspect of family practice that patients value.  Another explanation is that there were increases in the size of practices, and many practices introduced nurse-led clinics for management of individual chronic diseases. Although this may have been an important part of improving the quality of care, it may have made continuity of care harder to achieve.\n\n【47】Other studies suggest that financial incentives result in small improvements in quality.  Our data suggest that the pay-for-performance scheme in England attained its quality-improvement goals but that the pace of improvement was not sustained once these goals had been reached. There may be unintended consequences for aspects of care other than those studied, which may be influenced by differences in the operational details of apparently similar incentive schemes.  An unanticipated benefit of the scheme in England has been a reduction in sociodemographic inequalities in the delivery of health care. \n\n【48】Our study has several limitations. First, the pay-for-performance scheme was introduced throughout the United Kingdom, thereby precluding a controlled trial and making the use of an interrupted time series the best evaluation method available. The only other time-series analysis of the quality of primary care in England suggests that pay for performance has had a more modest effect than that suggested by our results.  Second, because practices were observed at only two time points before the introduction of pay for performance, we cannot say whether the rate of improvement was already accelerating as a result of earlier but still ongoing initiatives. Third, the statistical power of our study was such that only moderate-to-large differences in trend were detectable between indicators that were and those that were not associated with incentives. Fourth, response rates for the patient questionnaire were poor (38 to 47%), although there is no reason to suspect any differences in bias at the four study time points. Finally, we focused on three diseases for which substantial efforts had been made to improve the quality of care before the introduction of the pay-for-performance scheme. Pay for performance might have a greater effect on conditions with lower profiles, including some introduced as the scheme developed (e.g., learning disabilities).\n\n【49】In conclusion, between 1998 and 2007, there were significant improvements in measurable aspects of clinical performance with respect to the care provided for three major chronic diseases. The initial acceleration in the underlying rate of quality improvement after the introduction of pay for performance was not sustained. If the aim of pay for performance is to give providers incentives to attain targets, the scheme achieved that aim. There may have been unintended consequences, including reductions in the quality of some aspects of care not linked to incentives and in the continuity of care.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-14 00:19:28", "grab_time": "2024-08-13 22:54:18"}
{"id": 2234460, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "0e809eed-7186-4f34-8d60-17b98d185111", "title": "Effectiveness of BNT162b2 Vaccine against Critical Covid-19 in Adolescents", "text": "【0】Effectiveness of BNT162b2 Vaccine against Critical Covid-19 in Adolescents\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】The increasing incidence of pediatric hospitalizations associated with coronavirus disease 2019 (Covid-19) caused by the B.1.617.2 (delta) variant of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) in the United States has offered an opportunity to assess the real-world effectiveness of the BNT162b2 messenger RNA vaccine in adolescents between 12 and 18 years of age.\n\n【3】Methods\n-------\n\n【4】Download a PDF of the Research Summary .\n\n【5】We used a case–control, test-negative design to assess vaccine effectiveness against Covid-19 resulting in hospitalization, admission to an intensive care unit (ICU), the use of life-supporting interventions (mechanical ventilation, vasopressors, and extracorporeal membrane oxygenation), or death. Between July 1 and October 25, 2021, we screened admission logs for eligible case patients with laboratory-confirmed Covid-19 at 31 hospitals in 23 states. We estimated vaccine effectiveness by comparing the odds of antecedent full vaccination (two doses of BNT162b2) in case patients as compared with two hospital-based control groups: patients who had Covid-19–like symptoms but negative results on testing for SARS-CoV-2 (test-negative) and patients who did not have Covid-19–like symptoms (syndrome-negative).\n\n【6】Results\n-------\n\n【7】A total of 445 case patients and 777 controls were enrolled. Overall, 17 case patients (4%) and 282 controls (36%) had been fully vaccinated. Of the case patients, 180 (40%) were admitted to the ICU, and 127 (29%) required life support; only 2 patients in the ICU had been fully vaccinated. The overall effectiveness of the BNT162b2 vaccine against hospitalization for Covid-19 was 94% (95% confidence interval \\[CI\\], 90 to 96); the effectiveness was 95% (95% CI, 91 to 97) among test-negative controls and 94% (95% CI, 89 to 96) among syndrome-negative controls. The effectiveness was 98% against ICU admission and 98% against Covid-19 resulting in the receipt of life support. All 7 deaths occurred in patients who were unvaccinated.\n\n【8】Conclusions\n-----------\n\n【9】Among hospitalized adolescent patients, two doses of the BNT162b2 vaccine were highly effective against Covid-19–related hospitalization and ICU admission or the receipt of life support. \n\n【10】Introduction\n------------\n\n【11】 QUICK TAKE  \nEffectiveness of Covid-19 Vaccine in Adolescents  \n\n【12】Understanding the role of vaccination in the prevention of hospitalization for coronavirus disease 2019 (Covid-19), including life-threatening illness, among children can inform vaccination decisions and efforts to improve vaccination coverage. In May 2021, the Food and Drug Administration expanded the emergency use authorization for use of the BNT162b2 messenger RNA (mRNA) vaccine (Pfizer–BioNTech) to include adolescents between 12 and 15 years of age.  This expansion was based on a randomized, placebo-controlled trial that showed a vaccine efficacy of 100% (95% confidence interval \\[CI\\], 75 to 100) against symptomatic Covid-19 among adolescents.  However, in that trial, cases of severe Covid-19 were not observed, given the relatively rare nature of this outcome. In early September 2021, the incidence of pediatric hospitalization caused by the B.1.617.2 (delta) variant of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) reached the highest level during the pandemic.  This surge provided an opportunity to evaluate the real-world effectiveness of the BNT162b2 vaccine against severe Covid-19 in adolescents.\n\n【13】In the Overcoming Covid-19 investigation, we recently reported the interim findings of high effectiveness (93%) for the BNT162b2 vaccine against Covid-19 hospitalization among adolescents between 12 to 18 years of age among 179 case patients at 19 sites in 16 states.  Since the time of that report, we expanded surveillance to 31 sites in 23 states and enrolled an additional 266 patients who had been hospitalized with Covid-19. With a substantial increase in the sample size, we now extend those findings to report the effectiveness of two doses of the BNT162b2 vaccine among adolescents against Covid-19 hospitalization resulting in admission to an intensive care unit (ICU) or in the receipt of other life-supporting interventions.\n\n【14】Methods\n-------\n\n【15】Study Design\n------------\n\n【16】We used a case–control, test-negative design to assess the effectiveness of vaccination against Covid-19 resulting in hospitalization, ICU admission, or life-supporting interventions by comparing the odds of antecedent vaccination among laboratory-confirmed case patients and hospitalized controls without Covid-19.  Evaluations of vaccine effectiveness have commonly used test-negative controls to reduce bias from health care–seeking behavior and to improve logistics.  Estimates of vaccine effectiveness that are generated by the case–control or test-negative design are expressed as percentages and can be interpreted as the fraction of the specified outcome prevented in association with vaccination.  The surveillance protocol and the statistical analysis plan  were reviewed by the Centers for Disease Control and Prevention (CDC) and by the other participating institutions as public health surveillance; this review was conducted in accordance with applicable federal laws and CDC policy.  CDC technical staff members served as coinvestigators and were involved in the study design, participated in the data collection and analysis and in the preparation of the manuscript, and were involved in the decision to submit the manuscript for publication.\n\n【17】Enrollment of Case Patients and Controls\n----------------------------------------\n\n【18】To identify case patients and controls, we conducted active surveillance of adolescents between 12 and 18 years of age who had been admitted to 31 hospitals in 23 states in the CDC-funded Overcoming Covid-19 Network.  The network was funded to evaluate vaccine effectiveness against severe Covid-19 and multisystem inflammatory syndrome in children (MIS-C) in vaccine-eligible participants. After the CDC contract had been awarded, 39 referral health centers for pediatric patients were approached on the basis of their previous experience in the enrollment of patients with Covid-19 or in conducting evaluations of vaccine effectiveness against influenza.  Representatives at 31 centers agreed to participate during this period.\n\n【19】During the surveillance period at each study site, investigators attempted to capture all cases that met the inclusion criteria. All case patients and controls were enrolled regardless of the availability of information regarding their vaccination status. During the period from May 30 through October 25, 2021, investigators began screening for potentially eligible patients through a review of hospital admission logs and electronic medical records. For this report, the hospitalization date of the first enrolled case patient was July 1, when the percentage of fully vaccinated adolescents surpassed 20% in the United States and thus was sufficient for an evaluation of vaccine effectiveness.  The onset of enrollment varied depending on local incidence and ethics approval at the site.\n\n【20】Case patients were selected among adolescents who were hospitalized with Covid-19 as the primary reason for admission or who had a clinical syndrome consistent with acute Covid-19 (one or more symptoms of fever, cough, shortness of breath, loss of taste, loss of smell, gastrointestinal symptoms, respiratory support, or new pulmonary findings on chest imaging). All case patients had positive results for SARS-CoV-2 on reverse transcriptase–polymerase-chain-reaction (RT-PCR) assay or on antigen testing within 10 days after symptom onset or within 72 hours after hospitalization. Results of documented positive tests before admission were accepted in 28 case patients. We excluded 23 adolescents who had received a diagnosis of MIS-C during their current hospitalization .\n\n【21】Because of potential biases related to the selection of controls,  we included two groups of hospitalized patients as controls: those who had negative results for SARS-CoV-2 on RT-PCR assay or antigen testing (test-negative) but who had Covid-19–like symptoms; and those without Covid-19–like symptoms who may or may not have undergone SARS-CoV-2 testing (syndrome-negative). At each site, investigators targeted a case-to-control ratio of approximately  for each of the two control groups. Eligible controls were selected from among patients in closest proximity to the ward where the case patients were hospitalized within 3 weeks after the case patient’s hospitalization date.\n\n【22】Data Collection\n---------------\n\n【23】The parent or guardian of each participant was approached by trained study personnel or electronic medical records on all case patients and controls were reviewed to collect data regarding demographic characteristics, clinical information about the current illness, and SARS-CoV-2 testing history. Parents or guardians were asked about the patient’s Covid-19 vaccination history, including the number of doses and whether the most recent administration had occurred during the previous 14 days, the location where vaccination had occurred, the vaccine manufacturer, and the availability of a Covid-19 vaccination card. Study personnel searched sources, including state vaccination registries, electronic medical records, or other sources (including documentation from pediatricians), to verify reported or unknown vaccination status.\n\n【24】Vaccination Status\n------------------\n\n【25】Patients were considered to have received Covid-19 vaccination based on source documentation or by plausible self-report if vaccination dates and location were provided by a parent or guardian at the time of the interview. Because the mRNA-1273 vaccine (Moderna) and Ad26.COV2.S vaccine (Johnson & Johnson–Janssen) had not been authorized for use in adolescents at the time of study initiation, patients who had received those vaccines were excluded. Patients were categorized as being unvaccinated (no receipt of the BNT162b2 vaccine before illness onset) or vaccinated if the most recent dose (first or second dose of the BNT162b2 vaccine) had been administered at least 14 days before illness onset. Adolescents who had received only one dose of vaccine or who had received a second dose less than 14 days before illness onset were considered to have been partially vaccinated; those who had received two doses at least 14 days before illness onset were considered to have been fully vaccinated. Patients who had received only one dose less than 14 days before illness onset were excluded from the analysis. \n\n【26】Outcomes\n--------\n\n【27】The prespecified primary outcomes were Covid-19 resulting in hospitalization, ICU admission, the receipt of life-supporting interventions, or death. Life support was defined as the receipt of noninvasive or invasive mechanical ventilation, vasoactive infusions, or extracorporeal membrane oxygenation.\n\n【28】Statistical Analysis\n--------------------\n\n【29】We first conducted bivariate analyses to assess for between-group differences in characteristics on the basis of case status (case patients vs. controls) and vaccination status (fully vaccinated vs. unvaccinated). We then constructed logistic-regression models for the prespecified primary outcomes to calculate odds ratios of antecedent vaccination (fully or partially vaccinated vs. unvaccinated) in case patients as compared with controls, with associated 95% confidence intervals. A priori, we adjusted models for the U.S. Census region, calendar date of admission, age, sex, and race or ethnic group.  To evaluate clustering according to hospital, we also included the hospital as a random effect in mixed-effects regression models, an analysis that did not substantially alter the results. Using a change-in-estimate approach, we assessed other potential confounding factors (the presence of underlying health conditions, specific underlying conditions, and the score on the Social Vulnerability Index) that were not included in the final models because these factors did not change the odds ratio for vaccination by more than 5%. \n\n【30】We calculated vaccine effectiveness against the primary outcomes by comparing the odds of full vaccination against Covid-19 among case patients and controls using the equation for vaccine effectiveness of (1– adjusted odds ratio)×100, as determined from logistic-regression models. We used Firth logistic regression (a penalized likelihood–based method) for models with fewer than five vaccinated case patients.  Preplanned subgroup analyses included effectiveness against Covid-19 hospitalization according to age group (12 to 15 years vs. 16 to 18 years) and protection of partial vaccination with the BNT162b2 vaccine against Covid-19 hospitalization. We computed effectiveness separately with each control group and overall with the two control groups combined. The widths of the confidence intervals have not been adjusted for multiplicity, so the intervals should not be used to infer vaccine effectiveness for the subgroup analyses. All statistical analyses were performed with the use of SAS software, version 9.4 (SAS Institute).\n\n【31】Results\n-------\n\n【32】Characteristics of the Participants\n-----------------------------------\n\n【33】Figure 1. Study Enrollment and Outcomes (July 1–October 25, 2021).\n\n【34】Among the case patients between 12 and 18 years of age who were hospitalized with coronavirus disease 2019 (Covid-19), 37 patients who had a positive result on SARS-CoV-2 testing but were admitted to the hospital for a non–Covid-19 reason were excluded from the analyses. Patients were described as having been fully vaccinated if they had received a second dose of the BNT162b2 vaccine at least 14 days before the onset of illness. Patients were described as having been partially vaccinated if they had received the first dose of the BNT162b2 vaccine at least 14 days before illness onset. Among the 777 control patients, 383 had received negative results on SARS-CoV-2 testing (test-negative) and 394 had no Covid-19 symptoms (syndrome-negative).\n\n【35】Between May 30 and October 25, 2021, a total of 1376 eligible case patients and controls underwent screening; of these patients, 154 were excluded. Exclusions included 41 patients who were admitted to the hospital in May or June when vaccination coverage was low, 35 who had received the first dose of vaccine less than 14 days before illness onset, 37 with a positive SARS-CoV-2 test who were admitted for reasons other than Covid-19 symptoms , 23 who had received a diagnosis of MIS-C, 8 who had undergone SARS-CoV-2 testing more than 10 days after illness onset or more than 72 hours after hospitalization, 2 who had unknown vaccination status, and 8 who had received a non-BNT162b2 vaccine .\n\n【36】Table 1. Characteristics of Hospitalized Case Patients and Controls and Vaccination Status at Baseline.\n\n【37】The primary analysis included 1222 vaccinated and unvaccinated patients (445 case patients and 777 controls). Among the controls, 383 (49%) were test-negative for SARS-CoV-2, and 394 (51%) were syndrome-negative. Among the case patients, the median age was 16 years, 74% had at least one underlying condition (including obesity), and 70% attended an in-person school . Among the controls, the median age was 15 years, 70% had at least one underlying condition, and 70% attended an in-person school. Case patients more frequently resided in areas with higher scores on the Social Vulnerability Index (median score, 0.64) than controls (median score, 0.58). (The Social Vulnerability Index ranges from 0 to 1.0, with higher scores indicating greater social vulnerability.) Underlying conditions, which included obesity, were common, both among adolescents who were vaccinated (73%) and those who were unvaccinated (71%). Respiratory and endocrine disorders were more prevalent among case patients (33% and 16%, respectively) than among controls (23% and 11%, respectively); neurologic or neuromuscular disorders and immunosuppressive or autoimmune disorders were more prevalent among controls (22% and 12%, respectively) than among case patients (13% and 5%, respectively).\n\n【38】Of the 299 case and control patients who were classified as having been fully vaccinated, 288 (96%) had verified documentation of full vaccination. Among the 445 case patients with available vaccination data, only 17 (4%) had been fully vaccinated, 1 (<1%) had been partially vaccinated, and 427 (96%) were unvaccinated. In contrast, among 777 controls with available vaccination data, 282 (36%) had been fully vaccinated, 54 (7%) had been partially vaccinated, and 441 (57%) were unvaccinated .\n\n【39】Table 2. Clinical Outcomes and Covid-19 Severity among Hospitalized Case Patients, According to Vaccination Status.\n\n【40】Of the 445 case patients, 180 (40%) were admitted to the ICU, and 127 (29%) critically ill case patients received life-supporting interventions during hospitalization, including 13 patients (3%) who received extracorporeal membrane oxygenation and 7 (2%) who died . Two case patients who were admitted to the ICU (1 who had an immunosuppressive disorder and 1 who was healthy) had been fully vaccinated. The remaining 178 case patients who were admitted to the ICU, including 126 of 127 patients who required life-supporting interventions and the 7 who died, were unvaccinated. Among 425 case patients with available hospital discharge data, the median length of hospital stay was 5 days (interquartile range \\[IQR\\], 2 to 7) among unvaccinated case patients and 4 days (IQR, 1 to 5) among vaccinated case patients.\n\n【41】Vaccine Effectiveness\n---------------------\n\n【42】Figure 2. Effectiveness of the BNT162b2 Vaccine against Covid-19 Hospitalization in the Study Population.\n\n【43】Shown is the effectiveness of the BNT162b2 vaccine against Covid-19 hospitalization in all the case patients as compared with each of the two control groups (test-negative and syndrome-negative) and in the two control groups combined. Vaccine effectiveness was calculated as (1−adjusted odds ratio) × 100, in which the odds ratio is the odds of vaccination (fully or partially vaccinated vs. unvaccinated as referent group) in Covid-19 case patients as compared with control patients.\n\n【44】The effectiveness of the BNT162b2 vaccine against Covid-19 hospitalization was 94% (95% CI, 90 to 96) in analyses involving both control groups combined; the effectiveness was 95% (95% CI, 91 to 97) in the analysis involving test-negative controls and 94% (95% CI, 89 to 96) in the analysis involving syndrome-negative controls . The vaccine effectiveness was 98% (95% CI, 93 to 99) against Covid-19 requiring ICU care and 98% (95% CI, 92 to 100) against Covid-19 requiring life support. In subgroup analyses, the effectiveness of two doses of the vaccine against Covid-19 hospitalization was similar in various age groups: 95% (95% CI, 88 to 97) among 251 case patients between 12 and 15 years of age and 94% (95% CI, 88 to 97) among 193 case patients between 16 and 18 years of age.\n\n【45】The effectiveness of partial vaccination was 97% (95% CI, 86 to 100). However, it is important to note that the median time between the last vaccine dose and the onset of Covid-like symptoms in case patients was 30 days in 1 partially vaccinated adolescent and 90 days (IQR, 53 to 126 days) among fully vaccinated adolescents. The effectiveness against hospitalization among patients with a positive SARS-CoV-2 test who did not have Covid-19 as the primary cause for hospitalization was 78% (95% CI, 48 to 91) .\n\n【46】Discussion\n----------\n\n【47】In this multicenter evaluation conducted in 31 hospitals across 23 U.S. states, we compared 445 case patients between 12 and 18 years of age who were hospitalized with Covid-19 with 777 control patients without Covid-19. Despite eligibility for Covid-19 vaccination, 96% of the patients who were hospitalized with Covid-19 and 99% of those who received life support had not been fully vaccinated. We found that vaccination with two doses of the BNT162b2 mRNA vaccine reduced the risk of hospitalization from Covid-19 by 94% among adolescents between 12 and 18 years of age in the United States. Vaccination averted nearly all Covid-19 cases requiring life support and leading to death in this cohort of hospitalized adolescents. Of the 13 patients who received extracorporeal membrane oxygenation and 7 who died, all were unvaccinated.\n\n【48】These findings are consistent with efficacy data from the BNT162b2 clinical trial involving adolescents between 12 and 15 years of age, which showed vaccine efficacy of 100% (95% CI, 75 to 100) against nonhospitalized Covid-19 illness (i.e., any infection in which patients were not hospitalized).  In that trial, efficacy was based on the detection of no Covid-19 cases among 1005 participants who had received the BNT162b2 vaccine, as compared with 16 cases in 978 participants (1.6%) who had received placebo. No children with severe cases or cases resulting in hospitalization were observed in either group in the trial, which meant that the trial did not have sufficient power to assess vaccine efficacy against Covid-19 hospitalization or severe Covid-19. Postmarketing evaluations from Israel also showed that the BNT162b2 vaccine was highly effective against SARS-CoV-2 infection and nonhospitalized Covid-19 in adolescents between 12 and 18 years of age, but the data did not include sufficient cases to examine the effectiveness against Covid-19 hospitalization or severe disease.  A U.S. cohort study involving participants from Kaiser Permanente Southern California showed effectiveness against Covid-19 hospitalization of 81% for fully vaccinated patients between 12 and 15 years of age; however, that study was conducted through August 2021 and assessed only 45 cases, which resulted in wide 95% confidence intervals (–55 to 98). \n\n【49】The high vaccine efficacy against infection in the BNT162b2 clinical trial in children between the ages of 12 and 15 years suggests that vaccination should also prevent postinfection disease progression leading to hospitalization. However, postauthorization monitoring of effectiveness is also necessary as vaccines are introduced in order to understand vaccine performance in real-world settings.  Vaccine protection may differ in adolescents with underlying medical conditions, who are overrepresented in hospitalized settings and are often excluded from clinical trials.  Vaccine efficacy against new variants  and according to the interval since vaccination  could also vary. In our current study, a high percentage of case patients had underlying conditions (74%), but it is important to note that 26% were previously healthy. A disproportionate number of patients were Black (24%) or Hispanic (25%), populations that are at higher risk for Covid-19 than White children in the United States.  Patients with underlying conditions and those from minority populations were underrepresented in the BNT162b2 clinical trial among adolescents between 12 and 15 years of age.  Despite these differences in the characteristics of patients and the high prevalence of underlying medical conditions (including obesity) in our study cohort, we observed that vaccination was associated with an overall risk reduction of 94% for Covid-19 hospitalization and 98% for ICU admission or life-threatening Covid-19 illness. In addition, the median duration of follow-up in this analysis was longer (90 days) than that in the earlier BNT162b2 clinical trial (60 days). Despite the high level of protection afforded by vaccination  and the documented severity of Covid-19 in adolescents,  only 39% of the controls in our study were fully vaccinated against Covid-19. These data suggest that efforts to improve vaccination coverage among all adolescents, especially those at highest risk for severe Covid-19,  could markedly decrease the risk of severe Covid-19 among adolescents in the United States.\n\n【50】Our study has certain limitations. We did not have sufficient sequencing results to assess vaccine effectiveness directly against specific variants; however, more than 96% of the circulating variants during the evaluation period were delta.  Findings from urban health centers in this study may not be generalizable to patients with less severe disease who may present at nonurban hospitals. We also observed a high percentage of case patients (56%) from the southern United States, where Covid-19 transmission was high during this period. This study only assessed the effectiveness of the BNT162b2 vaccine, which was most widely available for adolescents in the United States during the study period. The effectiveness of a single dose of vaccine was high, but the duration of protection from one dose is unknown. It should be noted that the effectiveness of partial versus full vaccination in this study cannot be directly compared because of the between-group differences in the interval since vaccination. In case patients, the median interval between the first dose and illness onset was only 30 days (as compared with 90 days after the second dose), which indicates that most partially vaccinated adolescents were hospitalized between dose 1 and 2. Finally, because the vaccination of children between 12 and 15 years of age was initiated in May 2021, an evaluation of the duration of protection was not possible.\n\n【51】In this real-world evaluation of the effectiveness of the BNT162b2 mRNA vaccine in adolescents between 12 and 18 years of age in the United States, when the delta variant was predominant, we found that the vaccine was highly effective against Covid-19 hospitalization and critical illness, including among patients with underlying risk factors for severe illness. Vaccination averted nearly all life-threatening Covid-19 illness in this age group.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 18:25:50", "endTime": "2024/08/13 18:35:46", "cost": 595.381}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 02:35:46", "grab_time": "2024-08-13 02:25:51"}
{"id": 2234459, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "65419159-17b6-49a1-824f-8fad5ac3e45d", "title": "Reversed Pulsus Paradoxus", "text": "【0】Reversed Pulsus Paradoxus\nAbstract\n--------\n\n【1】The term \"reversed pulsus paradoxus\" may be used to describe an inspiratory rise of the arterial systolic and diastolic pressures, presumably related to an inspiratory increase in left ventricular stroke output. We have observed a reversed pulsus paradoxus in three unrelated clinical circumstances: idiopathic hypertrophic subaortic stenosis, isorhythmic ventricular rhythms and during intermittent inspiratory positive-pressure breathing in the presence of left ventricular failure. These unusual respiration-related fluctuations of blood pressure must be differentiated from the usual pulsus paradoxus of cardiac tamponade.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:27:05", "endTime": "2024/08/14 15:27:29", "cost": 24.52}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 23:27:29", "grab_time": "2024-08-13 23:27:04"}
{"id": 2234458, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "9f136a5e-5079-438e-a16c-4913c79bf82e", "title": "X-Linked Dilated Cardiomyopathy", "text": "【0】X-Linked Dilated Cardiomyopathy\nAbstract\n--------\n\n【1】To study the inheritance of idiopathic dilated cardiomyopathy, we investigated a large kindred in which 11 young male members had definite or possible evidence of the disorder. The five affected males for whom we had complete clinical data survived for 5 to 12 months after the onset of symptoms, which occurred early in life (ages 15 to 21 years). In six other males, clinical data were incomplete but suggested possible cardiomyopathy.\n\n【2】Three mothers of affected males were given a diagnosis of definite, and two of possible, late-onset dilated cardiomyopathy. These women presented in their 40s with atypical chest pain, and progressive congestive heart failure developed gradually over a period of 10 or more years.\n\n【3】X-linked inheritance of dilated cardiomyopathy is suggested in this family by the early onset in males, late onset in females, and no evidence of male-to-male transmission. The late onset of the disease in females, in contrast to the early onset in hemizygous males, is compatible with heterozygosity for the mutant allele. Since most cases of genetically lethal X-linked syndromes appear to be sporadic, for every case of \"idiopathic\" dilated cardiomyopathy in which X-linked inheritance can be confirmed from family information, it is possible that there are several nonfamilial cases due to a mutation at the same locus.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 17:04:03", "endTime": "2024/08/13 17:04:15", "cost": 12.391}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 01:04:15", "grab_time": "2024-08-13 01:04:03"}
{"id": 2234457, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "7edc9ac1-a1c7-415f-9274-1b2158eabced", "title": "Routine Fogarty Thrombectomy in Arterial Catheterization", "text": "【0】Routine Fogarty Thrombectomy in Arterial Catheterization\nAbstract\n--------\n\n【1】Routine use of the Fogarty embolectomy catheter after cardiac catheterization through a brachial arteriotomy in 25 patients was associated with a decline in major and minor complications from 28 to 4 per cent, whereas the proportion of unchanged or improved peripheral pulses increased from 55 to 80 per cent. Thrombus was found in 56 per cent, suggesting that decreased or absent arterial pulsation after cardiac catheterization, frequently attributed to \"vasospasm,\" may result from thrombus formation with subsequent lysis. The simplicity and efficacy of the Fogarty technic in preventing this complication recommend its use whenever arterial catheterization is performed through an arteriotomy.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:08:49", "endTime": "2024/08/14 15:08:57", "cost": 7.704}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 23:08:57", "grab_time": "2024-08-13 23:08:49"}
{"id": 2234456, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "5ff0fb31-ffe1-46ec-b595-b6b437c7ea41", "title": "A Newly Recognized Fastidious Gram-Negative Pathogen as a Cause of Fever and Bacteremia", "text": "【0】A Newly Recognized Fastidious Gram-Negative Pathogen as a Cause of Fever and Bacteremia\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】We identified a motile, curved, gram-negative bacillus as the cause of persistent fever and bacteremia in two patients with symptomatic human immunodeficiency virus infection. The same organism was subsequently recovered from a bone marrow—transplant recipient with septicemia and from two immunocompetent persons with week-long febrile illnesses. All the patients recovered after antimicrobial therapy.\n\n【3】Methods and Results.\n--------------------\n\n【4】Primary cultures of blood processed by centrifugation after blood-cell lysis yielded adherent, white, iridescent, morphologically heterogeneous colonies in 5 to 15 days. Subcultures grew in four days on chocolate, charcoal—yeast extract, or blood agar. The organisms stained weakly with safranin and were not acid-fast. Fluorescent-antibody tests for legionella and francisella were negative. Biochemical reactivity was minimal and difficult to ascertain. Agar-dilution testing revealed in vitro susceptibility to most antimicrobial agents tested. The cellular fatty acid composition of the isolates was similar, resembling that of _Rochalimaea quintana_ or brucella species, but not _Helicobacter pylori_ or species of campylobacter or legionella. As resolved by gel electrophoresis, cell-membrane preparations of all isolates contained similar proteins, with patterns that differed from that of _R. quintana_ . Patterns of digestion of DNA from all isolates by _Eco_ RV restriction endonuclease were virtually identical and also differed from that of _R. quintana_ . On immunodiffusion, serum from one convalescent patient produced a line of identity with sonicates of all five isolates.\n\n【5】Conclusions.\n------------\n\n【6】This pathogen may have been unidentified until now because of its slow growth, broad susceptibility to antimicrobial agents, and possible requirement of blood-cell lysis for recovery in culture. It should be sought as a cause of unexplained fever, especially in persons with defective cell-mediated immunity. \n\n【7】Introduction\n------------\n\n【8】THE pathogenic potential of uncommon microorganisms may be recognized first in immunocompromised hosts, in whom they cause opportunistic infection. Subsequently, some such organisms may be found to cause illness in normal hosts as well. We describe a newly identified, highly fastidious microorganism that caused bacteremic illness in three immunocompromised hosts, and was then isolated as the cause of a similar illness in two normal hosts.\n\n【9】Case Reports\n------------\n\n【10】Table 1. Epidemiologic and Clinical Characteristics of the Patients at Presentation.\\*\n\n【11】Two illustrative case reports are provided. Pertinent data regarding all patients are given in Table 1 .\n\n【12】Patient 1\n---------\n\n【13】A 31-year-old man infected with human immunodeficiency virus (HIV) was seen with a fever (temperature to 40.8°C), chills, sweats, and weight loss in November 1986. Fever persisted despite empirical therapy with erythromycin and then cephalexin. A chest radiograph revealed no active disease. Sputum examinations revealed no malignant cells or potential pathogens. Blood cultures were negative after a 48-hour incubation. Fever remitted during two weeks of empirical treatment with oral trimethoprim–sulfamethoxazole but recurred after its discontinuation.\n\n【14】Examination in January 1987 revealed fever (temperature, 38.3°C), marked cachexia, and weakness. He had pancytopenia, lymphopenia, and hypoxemia. Liver enzyme levels in serum were elevated. Bronchoscopy revealed no pathogens or histopathologic features. Empirical treatment with parenteral trimethoprim–sulfamethoxazole induced severe nausea and was soon stopped. Hepatomegaly was the sole abnormality detected by computed tomography of the head and abdomen. Liver biopsy disclosed normal architecture with interspersed granulomata. Aspiration and biopsy of bone marrow revealed dyserythropoiesis without megaloblastic or microcytic changes. No organisms were seen in or cultured from liver or marrow. The results of lumbar puncture and cardiac sonography were normal. Studies for antibodies to brucella, tularemia, and fungi were negative; cultures of urine and the bully coat for cytomegalovirus were also negative.\n\n【15】After 15 days of incubation, a culture of blood subjected to blood-cell lysis and then centrifugation (lysis—centrifugation) grew a curved gram-negative bacillus. Two cultures obtained six days after the first also grew the same organism after a long incubation. Parenteral erythromycin therapy was begun, and the fever declined slowly over a two-week period. Five weeks later, the fever recurred despite renewed treatment with oral erythromycin, but further blood cultures were negative. Norfloxacin was substituted, and fever remitted permanently during the four weeks of therapy. Further blood cultures were negative.\n\n【16】The patient died less than a year later of progressive HIV-related neurologic disease and disseminated _Mycobacterium kansasii_ infection.\n\n【17】Patient 5\n---------\n\n【18】A 40-year-old woman presented in August 1989 with a four-day history of fever (temperature to 39.4°C), chills, sweating, nausea, vomiting, frontal headache, back pain, and weight loss. Examination disclosed fever (temperature, 38.8°C), liver tenderness to percussion, and lower-extremity petechiae. She had thrombocytopenia, granulocytosis, and mild lymphopenia, but hemoglobin levels and coagulation and serum-chemistry profiles were normal. Aspiration and examination of bone marrow demonstrated increased numbers of megakaryocytes. Cerebrospinal fluid was normal. Autoantibody screening was negative, and complement levels were normal. Serologic testing revealed high antibody titers to Epstein–Barr virus and cytomegalovirus, but negative reactions for HIV, brucella species, _Francisella tularensis, Rickettsia rickettsii,_ and _Ehrlichia canis_ (serum samples obtained during the acute phase of the disease and during convalescence were used to test for the last two microorganisms). Urine cultures were negative for bacteria and cytomegalovirus. Blood for culturing was drawn once on hospital days 1 and 2 and twice on day 4, when the patient was still febrile. A 10-day course of oral tetracycline was started on day 4. The fever subsided in 24 hours, and platelet counts soon returned to normal.\n\n【19】After incubation periods of 10 to 14 days, all lysis—centrifugation blood cultures yielded a curved gram-negative bacillus. All biphasic blood cultures had been negative when discarded after seven days. The patient has remained well on follow-up.\n\n【20】Methods\n-------\n\n【21】Isolation and Characterization\n------------------------------\n\n【22】Blood was inoculated into 10-ml lysis—centrifugation tubes (Isolator, Dupont, Wilmington, Del.) for Patients 1, 2, and 3. Culture sets consisting of a biphasic medium (Septi-chek, Roche Diagnostics, Nutley, N.J.) and a lysis—centrifugation tube were used for Patients 4 and 5. Biphasic cultures were kept for seven days. Cultures derived by centrifugation after blood-cell lysis were plated on fresh medium, including chocolate agar (proteose peptone number 3 agar base) and sheep's-blood agar (Columbia blood agar base), and incubated at 35°C in 5 percent carbon dioxide for at least 14 days. Suspect colonies were subcultured on heart-infusion rabbit-blood agar.\n\n【23】Motility was determined by microscopical examination of saline wet-mount preparations. Catalase testing was done with 3 percent hydrogen peroxide. The oxidase test was performed with _O_ \\-paraphenylene-diamine (Marion Scientific, Kansas City, Mo.). Further biochemical testing was attempted with both conventional  and commercially available (Micro-Scan, Baxter-Travenol, Sacramento, Calif.; API Rapid-Strep, Analytab Products, Plainview, N.Y.) approaches. The Centers for Disease Control in Atlanta further evaluated isolates 1, 2, and 3.\n\n【24】Direct fluorescent antibody testing for _Legionella pneumophila_ groups 1 through 6 and _L. micdadei_ conjugate A (with use of a commercial kit, Wampole Laboratories, Cranbury, N.J.) and for _F. tularensis_ (with use of a reagent provided by the Centers for Disease Control) was performed. Susceptibility testing was done with single concentrations of antimicrobial agents incorporated in chocolate agar (prepared from GC medium base).  The following concentrations (in milligrams per liter) of antimicrobial agents were used: penicillin, 0.12; ampicillin, 2.0; aztreonam, 8.0; gentamicin, 4.0; tobramycin, 4.0; trimethoprim–sulfamethoxazole, 2.0 and 40, respectively; norfloxacin, 4.0; ciprofloxacin, 2.0; chloramphenicol, 8.0; erythromycin, 0.5; rifampin, 2.0; tetracycline, 4.0; and vancomycin, 4.0. Sensitivity to nalidixic acid and cephalothin was determined by disk diffusion with 30-μg disks.\n\n【25】Analyses of Whole-Cell Fatty Acids\n----------------------------------\n\n【26】Cultures of each isolate and of strains of _Helicobacter pylori,_ formerly _Campylobacter pylori_  (strain 7878, American Type Culture Collection \\[ATCC\\], Rockville, Md.), and _Rochalimaea quintana_ (ATCC strain RV358) were harvested after a seven-day incubation at 35°C in 5 percent carbon dioxide on plates containing heart-infusion 5 percent rabbit-blood agar. Fatty acid methyl esters were made and chromatographed according to the techniques developed by Miller and Berger.  Fatty acid methyl ester profiles were identified by a computer-assisted comparison of the retention times of the specimens with that of a standard quantitative mixture of fatty acid methyl esters (Microbial-ID, Newark, Del.).\n\n【27】Preparation of Cell-Membrane Proteins\n-------------------------------------\n\n【28】A modification of a technique for the isolation of outer-membrane proteins from _Haemophilus influenzae_ was used.  Bacteria grown after a one-week incubation on chocolate agar at 37°C in 5 percent carbon dioxide were suspended in HEPES buffer and sonicated at 70 W in 15-second bursts until the solution was clear. After centrifugation at 1700× _g_ , the remaining supernatant was ultracentrifuged at 100,000× _g_ . The resultant pellet was resuspended in HEPES buffer with 1 percent sodium lauroylsarcosine and, after a 30-minute incubation at room temperature, ultracentrifuged. The final gelatinous pellet of cell-membrane protein was resuspended in distilled water and stored at -70°C after colorimetric measurement of protein content (Bio-Rad, Richmond, Calif.).\n\n【29】Electrophoresis\n---------------\n\n【30】Sodium dodecyl sulfate–polyacrylamide-gel electrophoresis was performed with a resolving gel with a gradient of 7.5 to 15 percent and a 4 percent stacking gel. Samples containing 2 to 3 μg of cell-membrane protein were run in each lane, with molecular-weight standards in adjacent lanes. Electrophoresis was performed at 15 mA per gel in a water-cooled chamber and was halted when the tracking dye reached the lower edge of the gel. The resolving gel was then fixed and stained with silver. \n\n【31】Patterns of DNA Digestion by Restriction Endonuclease\n-----------------------------------------------------\n\n【32】The technique of van Ketel et al.  was used for restriction-endonuclease digestion. Bacteria grown as for the preparation of cell-membrane protein were suspended, incubated with lysozyme for 30 minutes, and then lysed with 1 percent sodium dodecyl sulfate for 15 minutes before overnight digestion with pronase (Sigma, St. Louis). Nucleic acids were twice extracted with phenol—chloroform—isoamyl alcohol :1), precipitated overnight in ethanol at -20°C, and centrifuged. The washed pellet was resuspended and incubated with RNase (Sigma) for one hour. DNA purification was completed with an additional extraction with phenol—chloroform—isoamyl alcohol, followed by chloroform extraction and overnight precipitation in ethanol. A total of 4 μg of each DNA specimen was digested for two hours with 40 units of _Eco_ RV (Bethesda Research Laboratories, Gaithersburg, Md.). Digests loaded onto a 0.7 percent agarose gel were electrophoresed overnight at 40 V, stained with ethidium bromide, and transilluminated with ultraviolet A for observation.\n\n【33】Immunodiffusion Studies\n-----------------------\n\n【34】Serum samples obtained from Patients 2, 3, and 5 at least a month after the resolution of their febrile illnesses were stored at -20°C. No earlier serum samples were used. Aliquots were thawed and placed in the central wells of agarose immunodiffusion plates. The peripheral wells contained whole-cell sonicates of suspensions of isolates 1 through 5 and, as controls, supernatant from a broth culture of _Staphylococcus aureus_ (ATCC strain 29213) or a whole-cell sonicate of a suspension of _R. quintana_ . A control plate contained serum from a patient with _S. aureus_ bacteremia in the center well and the same peripheral-well contents as in the first plate. The plates were incubated in a humidified container at 37°C for a week, then viewed by transmitted indirect lighting.\n\n【35】Results\n-------\n\n【36】Isolates were recovered by extended incubation of lysis—centrifugation blood cultures . Where there were paired lysis—centrifugation and biphasic cultures, two or more lysis—centrifugation cultures were positive in each case, whereas no biphasic cultures yielded organisms during the seven days they were incubated.\n\n【37】Subcultures from primary culture plates grew in four days at 35 or 37°C in 5 to 10 percent carbon dioxide (but not at 30 or 42°C or in the absence of oxygen or carbon dioxide) on chocolate, charcoal—yeast extract, or blood agar. Rabbit blood supported growth better than sheep's blood. Growth was best on fresh chocolate agar and poor on medium more than three weeks old. Hemin disks (0.01 or 0.1 percent) enhanced growth on older mediums. Satellite growth occurred around micrococcus species and _S. aureus_ but not _Escherichia coli_ or _Pseudomonas aeruginosa_ . Growth was absent on Thayer Martin or campylobacter blood agar, or on agar lacking heme compounds, including mediums for mycobacteria and MacConkey agar.\n\n【38】Figure 1. Gram Stain of a Clinical Isolate, Revealing Fine, Curved, Lightly Staining Gram-Negative Rods (×610).\n\n【39】Adherent white iridescent colonies were morphologically heterogeneous. The colonies consisted of small, slightly curved gram-negative rods  measuring 0.6 by 1.0 μm on electron microscopy. The morphologic features suggested a species of campylobacter. When mounted in saline, all isolates displayed twitching motility that was especially notable with short forms. Attempts to stain flagella were unsatisfactory because of the autoadherence of the colonies. Flagella were not seen on electron microscopy. Organisms stained poorly with safranin and were non—acid-fast. Fluorescent antibody tests for legionella species and _F. tularensis_ were negative.\n\n【40】Isolate 1 was weakly catalase-positive, but isolates 2 through 5 were catalase-negative; none of them were oxidase-positive. Inadequate growth made all attempts at further biochemical characterization equivocal; all other tests — response to triple sugar iron agar and other measures of carbohydrate fermentation or oxidation, nitrate reduction, salt tolerance, and hippurate hydrolysis — were negative. The CDC found that the organism was oxidase-positive according to Kovac's method,  but otherwise confirmed our findings pertaining to motility and the lack of other discernible biochemical activities. No classification of the organisms could be made.\n\n【41】All isolates were susceptible in vitro to cephalothin, aztreonam, trimethoprim–sulfamethoxazole, chloramphenicol, erythromycin, aminoglycosides, fluoroquinolones, and rifampin. All were resistant to nalidixic acid. Isolate 1 was resistant to penicillin and ampicillin (because of the production of beta-lactamase), as well as to vancomycin. Isolate 2 was resistant to tetracycline.\n\n【42】Table 2. Cellular Fatty Acid Composition of Isolates 1 through 5, Brucella, Rochalimaea, Helicobacter, Campylobacter, and Legionella.\n\n【43】The whole-cell fatty acid composition of each isolate was determined as an alternative approach to biochemical characterization. The proportions of fatty acids were similar for all isolates (octadecenoic acid, 48 to 58 percent; octadecanoic acid, 21 to 26 percent; and hexadecanoic acid, 16 to 23 percent), closely resembling those of _R. quintana_ and somewhat like those of brucella species,  but unlike those of H. _pylori,_ campylobacter species,  <sup>, </sup>  or legionella species  .\n\n【44】Figure 2. Sodium Dodecyl Sulfate–Polyacrylamide-Gel Electrophoresis of Preparations of Cell-Membrane Protein (Silver Stain).\n\n【45】There is great similarity in the protein patterns of the isolates from Patients 1 through 5, whereas the pattern of _R. quintana_ is very different. The first and eighth lanes contain molecular-weight (MW) standards.Figure 3.  Figure 3. DNA-Fingerprint Study.\n\n【46】Lane 1 contains DNA from a lambda phage (as an endonuclease quality control); lane 2, _R. quintana_ ; and lanes 3, 4, 5, 6, and 7, clinical isolates 1, 2, 3, 4, and 5, respectively, after _Eco_ RV cleavage, agarose electrophoresis, and staining with ethidium bromide under ultraviolet A transillumination. The patterns of the clinical isolates are virtually identical and distinct from that of _R. quintana_ .\n\n【47】For all isolates, preparations of cell-membrane protein resolved by sodium dodecyl sulfate–polyacrylamide-gel electrophoresis contained similar major bands between 31 and 42 kd and minor bands at 19 kd and between 45 and 150 kd — a pattern that differed from that of _R. quintana_ . Patterns of EcoRV-produced DNA cleavage of all isolates were virtually identical and differed from that of _R. quintana_ .\n\n【48】Figure 4. Immunodiffusion Study.\n\n【49】A serum sample obtained during convalescence from Patient 2 was placed in the center well. Whole-cell sonicates of isolates from Patients 1 through 4 and _S. aureus_ (Sa) were placed in the peripheral wells. A line of identity connects all the clinical isolates. No immunoprecipitation occurred with _S. aureus_ .\n\n【50】By immunodiffusion, serum samples obtained during convalescence from Patient 2, who had a prolonged febrile illness, produced a line of identity with all five isolates (shown in Fig. 4 with isolates 1 through 4) but did not react with _R. quintana_ or _S. aureus_ . Serum samples obtained during convalescence from Patients 3 and 5, who had febrile illnesses lasting a week or less, and serum from a patient with _S. aureus_ bacteremia did not react with any of the isolates or control organisms. In addition, a human serum specimen reactive with _E. canis_ (at a dilution of  by indirect immunofluorescence) did not immunoprecipitate with isolates 1 and 2.\n\n【51】Discussion\n----------\n\n【52】We have isolated a previously unrecognized pathogen that caused bacteremic disease in five patients, three with immunologic dysfunction and two without. The organism is a highly fastidious, slender, curved, gram-negative motile bacillus that forms heterogeneous colonies under microaerophilic conditions. It requires an extended incubation for primary isolation from lysis—centrifugation blood cultures. It was susceptible in vitro to most antimicrobial agents tested. Highly similar concentrations of total cellular fatty acid, profiles of cell-membrane protein, and DNA-cleavage patterns were demonstrated among the isolates, and the antigenic identity of the isolates was shown by immunoprecipitation with serum samples obtained during convalescence from one patient.\n\n【53】The isolation of this bacterium resulted from laboratory practices designed to enhance the detection of disseminated pathogens, such as mycobacteria  <sup><a>14 </a></sup>  and _Histoplasma capsulatum,_  by lengthening the routine maintenance of plates of lysis—centrifugation cultures to at least two weeks. Before 1989 at the Oklahoma Medical Center, a routine blood culture from an adult consisted of inoculation of the specimen into a pair of conventional broth bottles. Lysis—centrifugation cultures were available by request when indicated. This was the case for Patients 1 through 3. In 1989 the routine blood-culture system for adults was changed to include one lysis—centrifugation tube and one biphasic culture to maximize microbial recovery. \n\n【54】This pathogen may have been previously unrecognized because of its fastidious nature. Its low frequency of isolation is underscored by the fact that 6096 lysis—centrifugation blood cultures were processed at the Oklahoma Medical Center in 1989. Recognition also may have been retarded by the widespread use of antimicrobial agents, since it is broadly susceptible to most common agents.\n\n【55】Although sharing characteristics with pathogens such as _R. quintana, Brucella canis,_ and _H. pylori,_ this organism is clearly different. _R. quintana,_ the cause of trench fever and the only known species of rickettsia cultivable on artificial medium,  had a fatty acid profile most similar to that of our isolates. The chief difference was a ratio of C to C of greater than 1.0 for _R. quintana_ and less than 1.0 for the isolates from the patients. However, _R. quintana_ grew faster than our isolates and had substantially different colonial and microscopic morphologic features, profile of cell-membrane protein, and DNA-cleavage pattern.\n\n【56】No epidemiologic or clinical clues have suggested the environmental origin of this pathogen or the mechanism by which infection occurred. None of the patients knew each other. Their illnesses were sporadic, and they came from diverse areas of Oklahoma. All but one used water from municipal water supplies, and the well water used by the fifth patient did not harbor the organism. Some had healthy domestic pets. None recalled exposure to ticks or wild animals — a key issue in the light of the high rates of rickettsial diseases (Rocky Mountain spotted fever and human ehrlichiosis) in Oklahoma  and the similarity of this organism to _R. quintana_ .\n\n【57】No portal of infection was evident. Patients had normal chest examinations and radiographs. None had meningeal signs; cerebrospinal fluid was normal in the two who underwent lumbar puncture. Only one had skin lesions — petechiae resulting from platelet consumption. One patient with hepatomegaly and abnormal liver function had granulomata within normal liver architecture, but no organisms were found by special staining or culture. Results of urinalyses were normal; urine cultures were negative.\n\n【58】Responses to therapy differed notably. Before their presentation at our hospital, both the HIV-infected patients had received courses of antimicrobial agents to which their isolates ultimately demonstrated susceptibility in vitro, yet they remained febrile and had persistent bacteremia. Treatment lasting at least a month appeared to be necessary to eradicate the fever, although the organisms could no longer be cultured after the institution of antimicrobial therapy at our hospital. Septicemia developed in the bone marrow—transplant recipient who had been treated with steroids despite long-term therapy with an antimicrobial agent to which her isolate also was susceptible in vitro. However, she had a very prompt response to therapy with other agents. The immunocompetent hosts, who had febrile illnesses lasting several days, also had prompt disappearance of their symptoms within days of starting antimicrobial therapy.\n\n【59】Although the immunodiffusion technique was useful in demonstrating the antigenic similarity of the isolates, it was able to detect an antibody response only in the patient with prolonged fever (and likely prolonged antigenic exposure). Countercurrent immunoelectrophoresis was attempted with whole-cell sonicates of the five isolates, as well as of a clinical isolate of _R. quintana_ and the ATCC type strain (VR-358). All yielded lines of precipitation with serum samples obtained during convalescence from Patients 2, 3, and 5; however, indistinguishable lines of precipitation also developed with several randomly selected serum samples from patients with bacteremia due to other organisms. This suggests that one or more ubiquitous antigens may resemble or be shared by the clinical isolates. Preliminary immunoblot studies using cell-membrane proteins as antigens have suggested to us that some normal human serum specimens also contain antibodies reactive with antigens of this organism.\n\n【60】Since this paper's submission, we have seen a previously healthy 30-year-old man in whom fever developed after a tick bite. He was initially treated empirically with tetracycline, and his symptoms disappeared. A lysis—centrifugation culture of blood obtained after his fever recurred in association with headache, photophobia, confusion, myalgia, and arthralgia yielded the organism described above (9 colony-forming units per milliliter) after eight days of incubation. The results of computed tomography of the brain and an examination of the cerebrospinal fluid were normal. The patient became afebrile after one dose of ceftriaxone and a day of parenteral chloramphenicol, and he completed treatment with oral doxycycline. A case of aseptic meningitis and persistent bacteremic illness due to an organism morphologically and biochemically comparable to the one described in this paper has since been described in a 30-year-old man after exposure to ticks in Arkansas. \n\n【61】In summary, we have identified a pathogen capable of causing febrile illness associated with persistent bacteremia in immunocompromised and immunocompetent hosts. Its recognition in the laboratory is based on optimal handling of lysis—centrifugation blood cultures. It differs from previously described pathogens, and its prevalence, habitat, and mechanism of pathogenesis remain undetermined. It should be sought in the setting of cryptogenic fever, especially in persons with defective cell-mediated immunity.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-14 00:20:48", "grab_time": "2024-08-13 23:35:30"}
{"id": 2234455, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "0356b8d6-0711-4053-9a2e-b0f22db226cb", "title": "Global, Regional, and National Burden of Rheumatic Heart Disease, 1990–2015", "text": "【0】Global, Regional, and National Burden of Rheumatic Heart Disease, 1990–2015\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Rheumatic heart disease remains an important preventable cause of cardiovascular death and disability, particularly in low-income and middle-income countries. We estimated global, regional, and national trends in the prevalence of and mortality due to rheumatic heart disease as part of the 2015 Global Burden of Disease study.\n\n【3】Methods\n-------\n\n【4】We systematically reviewed data on fatal and nonfatal rheumatic heart disease for the period from 1990 through 2015. Two Global Burden of Disease analytic tools, the Cause of Death Ensemble model and DisMod-MR 2.1, were used to produce estimates of mortality and prevalence, including estimates of uncertainty.\n\n【5】Results\n-------\n\n【6】We estimated that there were 319,400 (95% uncertainty interval, 297,300 to 337,300) deaths due to rheumatic heart disease in 2015. Global age-standardized mortality due to rheumatic heart disease decreased by 47.8% (95% uncertainty interval, 44.7 to 50.9) from 1990 to 2015, but large differences were observed across regions. In 2015, the highest age-standardized mortality due to and prevalence of rheumatic heart disease were observed in Oceania, South Asia, and central sub-Saharan Africa. We estimated that in 2015 there were 33.4 million (95% uncertainty interval, 29.7 million to 43.1 million) cases of rheumatic heart disease and 10.5 million (95% uncertainty interval, 9.6 million to 11.5 million) disability-adjusted life-years due to rheumatic heart disease globally.\n\n【7】Conclusions\n-----------\n\n【8】We estimated the global disease prevalence of and mortality due to rheumatic heart disease over a 25-year period. The health-related burden of rheumatic heart disease has declined worldwide, but high rates of disease persist in some of the poorest regions in the world. \n\n【9】Introduction\n------------\n\n【10】 QUICK TAKE  \nWhat is the Global Burden of Rheumatic Heart Disease?  \n\n【11】Rheumatic heart disease is a sequela of acute rheumatic fever,  which is usually a disease of poverty associated with overcrowding, poor sanitation, and other social determinants of poor health.  The near elimination of acute rheumatic fever and reduction in the rates of rheumatic heart disease in high-income countries during the late 20th century was attributed in part to improvements in socioeconomic conditions and the widespread use of penicillin G benzathine to treat streptococcal pharyngitis.  The remaining burden of rheumatic heart disease is found mostly in low-income and middle-income countries and among immigrants and older adults in high-income countries. \n\n【12】Guidelines for the prevention and treatment of acute rheumatic fever and rheumatic heart disease were originally released by the World Health Organization (WHO) more than 60 years ago.  Many countries have had striking reductions in mortality related to acute rheumatic fever and rheumatic heart disease; these reductions can be credited to the implementation of control programs and improvements to health systems.  Despite these improvements, high prevalences of and mortality due to rheumatic heart disease continue to be reported in many regions, including Africa, South Asia, and the Pacific Islands. \n\n【13】There is increasing interest in the burden of rheumatic heart disease, driven in part by the availability of echocardiography-based screening in areas in which the condition is endemic and a growing need to meet benchmarks in cardiovascular health.  The WHO and World Heart Federation have called for a 25% reduction in mortality due to cardiovascular causes, including rheumatic heart disease, by the year 2025.  As part of the 2015 Global Burden of Disease study (GBD 2015), we estimated the global, regional, and national burden of rheumatic heart disease for the years 1990 through 2015.\n\n【14】Methods\n-------\n\n【15】Strategy for Estimating Mortality Due to Rheumatic Heart Disease\n----------------------------------------------------------------\n\n【16】The overall objectives, methods, and organization of GBD 2015 have been reported previously.\n\n【17】We identified rheumatic heart disease–specific deaths from vital registration systems using codes from the _International Classification of Diseases, 9th Revision_ (ICD-9) and _10th Revision_ (ICD-10) . In total, 10,049 site-years of vital registration data from 132 countries were used. Deaths attributed to ill-defined or nonspecific causes (e.g., “heart disease, unspecified” \\[ICD-10 code I51.9\\]) or intermediate causes (i.e., causes, such as “heart failure” \\[ICD-10 code I50\\], that are not the underlying disease that initiated the chain of events leading to death) were reassigned to accepted causes of death, including rheumatic heart disease, with the use of algorithms developed for GBD 2015.  We performed a sensitivity analysis in which we evaluated uncertainty in the reassignment to rheumatic heart disease of deaths that had originally been coded to left heart failure, the ICD-10 code most commonly reassigned to rheumatic heart disease.\n\n【18】The GBD 2015 Cause of Death Ensemble model was used to produce estimates of the fraction of deaths caused by rheumatic heart disease according to age, sex, and location for each year from 1980 through 2015. Separate Ensemble models were run for each sex and for two levels of data availability. Country-level covariates associated with rheumatic heart disease were included to inform the models. These covariates were the proportion of the population under 30 years of age, years of education per capita, income per capita, the proportion of children under 5 years of age with low body weight for age (i.e., >2 standard deviations below the WHO standard weight-for-age curve), access to health care (a summary variable based on principal-component analysis of several health services indicators), the proportion of the population with access to improved water sources (as defined by the WHO–UNICEF Joint Monitoring Program for Water Supply and Sanitation \\[JMP\\]), the proportion of the population with access to improved sanitation (as defined by the JMP), sociodemographic index (a summary indicator derived from measures of income per capita, educational attainment, and fertility), and a summary exposure variable for rheumatic heart disease (a measure of risk-weighted prevalence of exposure).\n\n【19】The results obtained with the ensemble models were then adjusted to account for secular trends in mortality due to human immunodeficiency virus–acquired immunodeficiency syndrome (HIV–AIDS), which biases death estimates in countries with a high HIV–AIDS burden. Finally, the model results were adjusted by scaling them within the fraction of deaths due to all cardiovascular diseases and all deaths. Age-standardized mortality was calculated with the use of the direct method and a 2015 world reference population based on United Nations Population Division data updated for GBD 2015. Years of life lost were calculated by multiplying the number of deaths due to rheumatic heart disease in each age group by the global standard remaining life expectancy at the mean age at death for persons who die in each age group. \n\n【20】Strategy for Estimating the Prevalence of Rheumatic Heart Disease\n-----------------------------------------------------------------\n\n【21】We performed a systematic literature review for data on rheumatic heart disease incidence, prevalence, and case fatality rate. Data were identified primarily from community-based cross-sectional and cohort studies and nationally representative hospital administrative data sets. Our case definition was rheumatic heart disease identified by a clinician, with or without echocardiographic confirmation, that would require antibiotic prophylaxis or medical or surgical treatment.  We excluded studies that reported only the results of echocardiographic screening without clinical confirmation or expert interpretation. We did not use estimates of rates of “borderline” rheumatic heart disease (i.e., minor abnormalities revealed by echocardiography that could represent normal variation in the structure of the aortic or mitral valve). \n\n【22】Figure 1. Classification of Countries as Having an Endemic or Nonendemic Pattern of Rheumatic Heart Disease.\n\n【23】A country was classified as having an endemic pattern of disease if its estimated childhood mortality due to rheumatic heart disease was greater than 0.15 deaths per 100,000 population among children 5 to 9 years of age. ATG denotes Antigua and Barbuda, BRB Barbados, COM Comoros, DMA Dominica, E. Med. eastern Mediterranean region, FJI Fiji, FSM Federated States of Micronesia, GRD Grenada, KIR Kiribati, LCA Saint Lucia, MDV Maldives, MHL Marshall Islands, MLT Malta, MUS Mauritius, SGP Singapore, SLB Solomon Islands, SYC Seychelles, TLS Timor-Leste, TON Tonga, TTO Trinidad and Tobago, VCT Saint Vincent and the Grenadines, VUT Vanuatu, W. Africa West Africa, and WSM Samoa.\n\n【24】We considered countries to have one of two patterns of rheumatic heart disease: endemic, with high mortality and prevalence among children, and nonendemic, with low mortality and prevalence among children and predominance at older ages, when the delayed sequelae of rheumatic heart disease occur . Because of the differences between these disease patterns, countries with each pattern were modeled separately. Endemicity was defined on the basis of estimates of mortality due to rheumatic heart disease from GBD 2015, with a threshold of 0.15 deaths per 100,000 population among children 5 to 9 years of age in 2015. After expert review of country assignments, Kenya and Nicaragua were reclassified as having an endemic pattern of disease on the basis of studies that showed a high prevalence of childhood rheumatic heart disease in these countries. Estimates of prevalence on a global level were based on a combination of the endemic and nonendemic models, under the assumption that very few cases of asymptomatic rheumatic heart disease exist among young people in countries with a nonendemic pattern.\n\n【25】We separately modeled the prevalence of symptomatic heart failure due to rheumatic heart disease. We estimated the prevalence of heart failure due to any cause for each location, age, sex, and year, then assigned cases to 20 specific causes, relying on published and administrative data on the causes of heart failure and rates of mortality due to these causes. Heart failure was estimated as mild, moderate, or severe with the use of Medical Expenditure Panel Survey data on patient-reported quality of life among persons with heart failure. \n\n【26】All data were analyzed with the use of a Bayesian mixed-effects meta-regression tool (designated DisMod-MR 2.1) that was developed for the GBD study.  DisMod-MR 2.1 is a compartmental model that consists of three states — susceptible, diseased, and dead — with state transitions determined by the rates of incidence, remission, excess mortality, and other-cause mortality.  Differential equations with appropriate boundary conditions ensure consistency among all disease parameters in the model. The tool uses an offset log-normal model with fixed effects for study characteristics (i.e., design factors) that deviate from a predetermined reference and for location-specific covariates (income and the summary exposure variable).\n\n【27】To make predictions for all countries, estimates were made in an analytical cascade from the world to 7 super-regions, then to 21 world regions, and then to 195 countries and territories. This cascade took advantage of the assumption that geographic proximity influences patterns of disease prevalence for rheumatic heart disease. Information from higher levels in the cascade were used as prior distributions at the next level. Uncertainty intervals were taken as the 2.5th and 97.5th percentiles of the posterior distribution.\n\n【28】Years lived with disability were estimated by multiplying the number of cases by disability weights developed for the GBD studies.  For asymptomatic rheumatic heart disease, we used a disability weight that represented a healthy person with the need for long-term medication use (prophylactic antibiotic therapy). For heart failure, we used disability weights representing New York Heart Association class II, III, or IV symptoms. Years of life lost and years lived with disability were summed to obtain the number of disability-adjusted life-years due to rheumatic heart disease. \n\n【29】Data Availability\n-----------------\n\n【30】Figure 2. Classification of Countries According to the Availability of Data on Fatal and Nonfatal Cases of Rheumatic Heart Disease.\n\n【31】The availability of data on fatal and nonfatal cases of rheumatic heart disease varied widely across countries and regions. Figure 2 shows the types of data (on fatal cases, nonfatal cases, or both) available according to country. Figure S2 in the Supplementary Appendix shows the amount of available data for both modeling processes according to region and year. Data on fatal or nonfatal cases were available from most countries. For sub-Saharan Africa, data were available from only 14 countries. We also relied on country-specific covariates from all countries and geospatial modeling, as described above, to develop estimates of prevalence and mortality for countries without data on rheumatic heart disease.\n\n【32】Results\n-------\n\n【33】Mortality Due to Rheumatic Heart Disease\n----------------------------------------\n\n【34】Figure 3. Total Reported Deaths Assigned to Rheumatic Heart Disease and Intermediate or Nonspecific Causes of Death Reassigned to Rheumatic Heart Disease, 1990–2014.\n\n【35】Rheumatic heart disease–specific deaths were identified from vital registration systems with the use of codes from the _International Classification of Diseases, 9th Revision_ (ICD-9) and _10th Revision_ (ICD-10) . Deaths attributed to ill-defined or nonspecific causes (e.g., “heart disease, unspecified” \\[ICD-10 code I51.9\\]) or intermediate causes (e.g., “heart failure” \\[ICD-10 code I50\\]) were reassigned to accepted causes of death, including rheumatic heart disease, with the use of algorithms developed for the Global Burden of Disease study for 2015. The increase in the number of deaths in 2008 is due to the inclusion of the China Mortality Registration and Reporting System starting in 2008. The decrease in intermediate or indeterminate coded deaths in 2014 is due to a delay in the receipt of data from vital registration data systems that had higher proportions of indeterminate or intermediate death codes.\n\n【36】Figure 3 shows the raw numbers of global deaths that were coded to rheumatic heart disease and to indeterminate or intermediate cause-of-death codes that were reassigned to rheumatic heart disease, according to year. The increase in the number of deaths in 2008 is due to the addition of data from the China Mortality Registration and Reporting System.\n\n【37】The cause-of-death codes that were most commonly reassigned to rheumatic heart disease were left heart failure and right heart failure, which accounted for 25.5% and 5.3%, respectively, of deaths from rheumatic heart disease after reassignments had been made. Detailed results of the sensitivity analyses performed to assess the uncertainty in reassignment of deaths due to left heart failure are provided in the Supplementary Appendix .\n\n【38】On the basis of results derived from the ensemble models, we estimated that there were 347,500 deaths (95% uncertainty interval, 328,300 to 367,100) from rheumatic heart disease in 1990 and 319,400 deaths (95% uncertainty interval, 297,300 to 337,300) in 2015, a decrease of 8.1% (95% uncertainty interval, 2.7 to 13.5). Global age-standardized mortality from rheumatic heart disease decreased from 9.2 deaths per 100,000 population (95% uncertainty interval, 8.7 to 9.7) in 1990 to 4.8 deaths per 100,000 population (95% uncertainty interval, 4.4 to 5.1) in 2015, a decrease of 47.8% (95% uncertainty interval, 44.7 to 50.9). An estimated 77% and 82% of the deaths in 1990 and 2015, respectively, occurred in locations with an endemic disease pattern.\n\n【39】Figure 4. Age-Standardized Mortality Due to and Prevalence of Rheumatic Heart Disease According to World Region in 1990 and 2015.\n\n【40】I bars represent 95% uncertainty intervals.\n\n【41】Patterns of mortality due to rheumatic heart disease varied significantly according to world region in 2015. The largest number of deaths occurred in East Asia and South Asia. The highest age-standardized death rates occurred in Oceania, South Asia, and central sub-Saharan Africa, the only regions where the 95% uncertainty intervals in 1990 and 2015 overlap .\n\n【42】In 2015, the countries with the highest estimated numbers of deaths due to rheumatic heart disease were India (119,100 deaths), China (72,600), and Pakistan (18,900). The highest estimated age-standardized death rates — more than 10 deaths per 100,000 population — were in the Solomon Islands, Pakistan, Papua New Guinea, Kiribati, Vanuatu, Fiji, India, Federated States of Micronesia, Marshall Islands, Central African Republic, and Lesotho.\n\n【43】Prevalence of Rheumatic Heart Disease\n-------------------------------------\n\n【44】We estimated that in 2015 a total of 33,194,900 cases (95% uncertainty interval, 29,466,400 to 42,905,600) of rheumatic heart disease occurred in countries with an endemic pattern of disease and 221,600 cases (95% uncertainty interval, 205,800 to 238,300) occurred in countries with a nonendemic pattern. The estimated age-standardized prevalence of rheumatic heart disease in 2015 was 444 cases per 100,000 population for countries with an endemic pattern and 3.4 cases per 100,000 population for countries with a nonendemic pattern. Between 1990 and 2015, the age-standardized prevalence declined significantly in several regions . In 2015, the age-standardized prevalence remained highest in Oceania, followed by central sub-Saharan Africa and South Asia. In 2015, the countries with the largest estimated numbers of cases of rheumatic heart disease were India (13.17 million cases), China (7.07 million), Pakistan (2.25 million), Indonesia (1.18 million), and the Democratic Republic of the Congo (805,000), together accounting for 73% of global cases. Twenty countries with an endemic pattern of disease had an age-standardized prevalence exceeding 1%.\n\n【45】Number of Cases of Heart Failure among Cases of Rheumatic Heart Disease\n-----------------------------------------------------------------------\n\n【46】We estimated that there were 156,900 cases (95% uncertainty interval, 103,400 to 212,500) of mild heart failure, 129,500 cases (95% uncertainty interval, 93,700 to 170,300) of moderate heart failure, and 352,400 cases (95% uncertainty interval, 302,300 to 405,300) of severe heart failure due to rheumatic heart disease in 1990. For 2015, our estimates were 295,300 cases (95% uncertainty interval, 194,100 to 401,400) of mild heart failure, 243,700 cases (95% uncertainty interval, 176,600 to 320,900) of moderate heart failure, and 663,000 cases (95% uncertainty interval, 566,800 to 763,900) of severe heart failure, which represents an 88% increase in the number of cases overall.\n\n【47】Summary Measures of Health\n--------------------------\n\n【48】Figure 5. Age-Standardized Disability-Adjusted Life-Years Due to Rheumatic Heart Disease per 100,000 Population, 2015.\n\n【49】The number of disability-adjusted life-years due to rheumatic heart disease in 2015 was 10,513,200 (95% uncertainty interval, 9,611,000 to 11,514,500), accounting for 0.43% of global disability-adjusted life-years due to any cause. The global rate of disability-adjusted life-years due to rheumatic heart disease in 2015 was 142.6 per 100,000 population (95% uncertainty interval, 130.4 to 156.2). The highest age-standardized rates were found in Oceania, South Asia, and Africa . Most disability-adjusted life-years due to rheumatic heart disease were the result of years of life lost (84.9%), which indicated that premature death was a larger driver of total health loss from rheumatic heart disease than was years of life lived with disability.\n\n【50】Discussion\n----------\n\n【51】We used multiple sources of data and epidemiologic modeling techniques to estimate the global prevalence of and mortality due to rheumatic heart disease over a 25-year period. Over this interval, the health-related burden of rheumatic heart disease declined in most countries, but the condition persisted in some of the poorest regions in the world. We estimate that 10 persons per 1000 population living in South Asia and central sub-Saharan Africa and 15 persons per 1000 population in Oceania were living with rheumatic heart disease in the year 2015.\n\n【52】Rheumatic heart disease is a consequence of untreated streptococcal pharyngitis, and its major antecedents are the factors that influence the transmission of this infection, including access to high-quality health care and social determinants of health.  At the national level, progress — or lack thereof — in addressing social determinants such as education and income has tracked closely with mortality due to rheumatic heart disease. \n\n【53】In addition to impeding the effective prevention of acute rheumatic fever, social and economic factors may also make the management of chronic rheumatic heart disease more difficult. Lifelong treatment options for rheumatic heart disease, although effective, place large demands on health systems.  Major shortfalls in medical and surgical care for rheumatic heart disease have been documented in countries where the condition is endemic, even at tertiary centers. \n\n【54】We adjusted our mortality input data by reassigning codes for intermediate or indeterminate causes of death, including heart failure, and this adjustment substantially increased the estimates of the number of deaths due to rheumatic heart disease. Advances in methods for handling cause-of-death codes are an important component of improved estimates of mortality due to rheumatic heart disease. At the same time, it is likely that some deaths from stroke and endocarditis are miscoded, so we cannot estimate how many of the 6.3 million cases of stroke and 85,000 deaths from endocarditis that were estimated for 2015 were actually the result of underlying rheumatic heart disease. \n\n【55】Our estimates of disease prevalence are similar to those in a recent meta-analysis of screening studies in which the overall prevalence of rheumatic heart disease in low-income and middle-income countries was shown to range from 2.7 cases per 1000 population (for “clinically manifest” disease) to 21.1 cases per 1000 population (for “clinically silent” disease).  Among subclinical cases of rheumatic heart disease that are detected through echocardiographic screening (termed “borderline” rheumatic heart disease), some may progress to definite rheumatic heart disease, whereas others may regress. To date, only a few small prospective studies have evaluated the progression of borderline disease.  Our prevalence estimates would have been higher if we had included borderline cases in our model; however, current data do not support this approach, because it is unclear how this condition should be managed clinically. \n\n【56】It is possible that our estimates for some locations were biased upward by the use of studies of prevalence that were conducted in subnational areas with an endemic pattern of disease. Yet most of these studies focus on schoolchildren, among whom rheumatic heart disease might be less common than in the total population.  To clarify these issues, future prevalence studies should sample more broadly and screen persons beyond school-aged children. It is also possible that some middle-income countries (e.g., in Latin America, where our estimates are comparatively low) will have subpopulations that differ from the national average in their patterns of disease (i.e., endemic vs. nonendemic).  Future work on disease burden at the state or provincial level will be required to address this discrepancy. Finally, our analysis was limited to English-language studies.\n\n【57】Better data for low-income and middle-income countries are needed to guide policies for the control of rheumatic heart disease. In our analysis, we used epidemiologic modeling techniques to provide estimates for countries for which data were insufficient. However, further improvements in estimates of the burden of rheumatic heart disease will require new research in three areas: the extent of misclassification in death certification, prevalence among adults in low-income and middle-income countries, and rates of nonfatal outcomes and excess mortality in longitudinal studies involving persons with rheumatic heart disease. Improvements in the measurement of the burden of rheumatic heart disease will assist in planning for its control and will help identify countries where further investments are needed.\n\n【58】In summary, we estimated the global disease prevalence of and mortality due to rheumatic heart disease over a 25-year period. The health-related burden of rheumatic heart disease has declined worldwide, but the condition persists in some of the poorest regions in the world.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 16:43:40", "endTime": "2024/08/13 16:46:16", "cost": 155.841}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 00:46:16", "grab_time": "2024-08-13 00:43:40"}
{"id": 2234454, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "9d6f856c-c4e0-4836-98d5-b8b7f4b54cf7", "title": "Extrahepatic Manifestations of Chronic HCV Infection", "text": "【0】Extrahepatic Manifestations of Chronic HCV Infection\nHepatitis C virus infection is associated with nonhepatic diseases, including mixed cryoglobulinemic vasculitis, B-cell lymphoma, cardiovascular diseases, type 2 diabetes, and renal dysfunction. Direct-acting antiviral agents that cure the underlying infection are associated with a reduced incidence of most of these diseases.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:34:59", "endTime": "2024/08/14 15:37:08", "cost": 129.355}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 23:37:08", "grab_time": "2024-08-13 23:34:58"}
{"id": 2234453, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "3ed53874-2d69-477e-860e-6b47cb861e2b", "title": "Cholestyramine Promotes Receptor-Mediated Low-Density-Lipoprotein Catabolism", "text": "【0】Cholestyramine Promotes Receptor-Mediated Low-Density-Lipoprotein Catabolism\nAbstract\n--------\n\n【1】We studied the influence of cholestyramine (24 g per day) on receptor-mediated and receptor-independent low-density-lipoprotein catabolism in five women with heterozygous familial hypercholesterolemia. Cholestyramine lowered the level of circulating low-density-lipoprotein apoprotein by doubling (P<0.01) its fractional clearance via the receptor path, but fractional catabolism by the receptor-independent route remained unchanged. Moreover, although the absolute rate of catabolism of the apoprotein was not affected by treatment, the amounts handled by each pathway altered. Catabolism via the physiologically controllable receptor route increased by 71 per cent (P<0.05), but there was a 12 per cent drop in clearance by the nonreceptor pathway. These data demonstrate the utility of cholestyramine in promoting low-density-lipoprotein catabolism via its specific physiologic clearance pathway. They also show that heterozygotes with familial hypercholesterolemia can increase the activity of their low-density-lipoprotein receptors when presented with an appropriate stimulus.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:23:59", "endTime": "2024/08/14 15:24:04", "cost": 4.807}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 23:24:04", "grab_time": "2024-08-13 23:23:59"}
{"id": 2234452, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "d09428d2-5d4d-4f0c-a84f-2bc3c3287481", "title": "Natural History of Lactic Acidosis after Grand-Mal Seizures — A Model for the Study of an Anion-Gap Acidosis Not Associated with Hyperkalemia", "text": "【0】Natural History of Lactic Acidosis after Grand-Mal Seizures — A Model for the Study of an Anion-Gap Acidosis Not Associated with Hyperkalemia\nAbstract\n--------\n\n【1】To define the time course of the metabolic acidosis that follows a single grand-mal seizure, we obtained serial blood samples from eight consecutive patients. Immediately after a seizure, the mean (± S.E.M.) venous lactate concentration was 12.7±1.0 meq per liter, the mean carbon dioxide content 17.1±1.1 mmol per liter, and the mean arterial pH 7.14±0.06. Sixty minutes later their values were 6.6±0.7 meq per liter (P<0.005), 23.6±1.1 mmol per liter (P<0.005) and 7.38±0.04 (P<0.005) respectively. The spontaneous resolution of the acidosis was due, in large part, to the metabolism of lactate and to the concomitant removal of hydrogen ion. There was no change in the serum potassium concentration, despite the development of a severe systemic acidemia and the subsequent return to normal of the pH. We suggest that the patient with seizures may serve as a unique model of lactic acidosis.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:40:47", "endTime": "2024/08/14 14:40:59", "cost": 12.71}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 22:40:59", "grab_time": "2024-08-13 22:40:47"}
{"id": 2234451, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "60e6b80d-267c-4804-8c55-5cef0172cb94", "title": "Acute Myeloblastic Leukemia and Hypercalcemia — A Case of Probable Ectopic Parathyroid Hormone Production", "text": "【0】Acute Myeloblastic Leukemia and Hypercalcemia — A Case of Probable Ectopic Parathyroid Hormone Production\nAbstract\n--------\n\n【1】We studied a patient with acute myeloblastic leukemia, hypercalcemia, hypophosphatemia and inappropriately elevated serum parathyroid hormone levels to define the mechanism of the hypercalcemia. On six occasions during two years, hypercalcemia occurred in conjunction with relapses of leukemia. Each time, serum calcium decreased to normal levels in parallel with reduction of the leukemic mass. During two periods of hypercalcemia, immunoreactive parathyroid hormone values were abnormally high. In addition, hormone was detected in vitro after short-term incubation of the leukemic cells (after 24 hours, the patient's cells produced 129 pg of PTH per milliliter, whereas myeloblasts from a normocalcemic patient with leukemia produced only 33 pg). In freezethawing experiments, 39 pg of parathyroid hormone was released from 1 X 10 <sup>8 </sup> of the patient's myeloblasts; no hormone was released from the normocalcemic cells. These findings suggest that the hypercalcemia resulted from ectopic parathyroid hormone production by leukemic cells.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 18:36:57", "endTime": "2024/08/13 18:37:00", "cost": 3.106}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 02:37:00", "grab_time": "2024-08-13 02:36:37"}
{"id": 2234450, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "6a2bac90-7a01-4ae2-8a6b-299b69398cb2", "title": "Percutaneous Indwelling Radial-Artery Catheters for Monitoring Cardiovascular Function — Prospective Study of the Risk of Thrombosis and Infection", "text": "【0】Percutaneous Indwelling Radial-Artery Catheters for Monitoring Cardiovascular Function — Prospective Study of the Risk of Thrombosis and Infection\nAbstract\n--------\n\n【1】Percutaneous central arterial catheterizations were performed at the first radial-artery site in 492 (92 per cent) of 536 insertion attempts in patients in an intensive-care unit. The high success rate was attributed to placement by skilled nurse technicians and use of a simplified catheter device.\n\n【2】The mean duration of catheterization was 3.4 days (range, one to 25 days). With use of a continuous flush system, only five catheters became nonfunctional. Hypotension, use of vasoconstrictive agents and prolonged catheterization were associated with complete arterial occlusion in three study patients who required thrombectomies. Partial occlusions, detected by Doppler ultrasonic flowmeter, occurred in 19.3 per cent.\n\n【3】No local or systemic infections could be definitely related to arterial catheters. Results of 200 arterial catheter-tip cultures were positive in eight cases (4 per cent), but none of these were judged to be a primary source of clinical infection.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 10:08:59", "endTime": "2024/08/14 10:09:05", "cost": 5.973}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 18:09:05", "grab_time": "2024-08-13 18:08:58"}
{"id": 2234449, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "187a5e26-9a11-494f-8f67-d8e57b7d677d", "title": "mRNA Covid-19 Vaccines in Pregnant Women", "text": "【0】mRNA Covid-19 Vaccines in Pregnant Women\nArticle\n-------\n\n【1】After Emergency Use Authorization was granted for the messenger RNA (mRNA) vaccines BNT162b2 (Pfizer–BioNTech) and mRNA-1273 (Moderna), persons at the highest risk for coronavirus disease 2019 (Covid-19)–related illness and death were prioritized for vaccination.  Among these were pregnant women, yet they had been excluded from initial vaccine trials. Pregnant women and their clinicians were left to weigh the documented risks of Covid-19 infection against the unknown safety risks of vaccination in deciding whether to receive the vaccine.\n\n【2】Before the vaccine rollout, multiple cohort studies documented that pregnant women were at greater risk than nonpregnant women for severe disease after Covid-19 infection, resulting in intensive care unit admission, mechanical ventilation, and death.  Pregnant women with coexisting illnesses such as diabetes, hypertension, and obesity were recognized to be at even greater risk.  Studies also showed an increased risk of pregnancy complications — including preterm birth, cesarean delivery, and preeclampsia — associated with Covid-19 infection during pregnancy.  Therefore, clinicians relied on developmental and reproductive animal data from Moderna that showed no safety concerns, and there was no biologically plausible reason that the mRNA technology would be harmful in pregnancy. Pregnant women were counseled to consider the available evidence and make personal decisions about vaccination in the absence of human safety data.\n\n【3】In this issue of the _Journal_ , Shimabukuro et al.  provide much-needed preliminary data on the safety of these vaccines in pregnancy on the basis of the v-safe surveillance system and pregnancy registry. V-safe, a new smartphone-based surveillance system from the Centers for Disease Control and Prevention that is available to all Covid-19 vaccine recipients, sends text messages to assess general health and pregnancy status during a period of 12 months after vaccination. Persons who identify as pregnant can enroll in the v-safe pregnancy registry, which contacts participants by telephone to answer in-depth questions.\n\n【4】The report by Shimabukuro et al. includes safety results for 35,691 v-safe participants 16 to 54 years of age who identified as pregnant and the first 3958 participants who enrolled in the v-safe pregnancy registry. In both cohorts, 54% of the participants received the Pfizer–BioNTech vaccine and 46% received the Moderna vaccine. The age distribution, status with respect to race and ethnic group, and timing of the first dose were similar with each vaccine. Among v-safe participants, 86.5% had a known pregnancy at the time of vaccination, and 13.5% reported a positive pregnancy test after vaccination. Among v-safe pregnancy registry participants, 28.6% received vaccine in the first trimester, 43.3% in the second trimester, and 25.7% in the third trimester.\n\n【5】Among 827 registry participants who reported a completed pregnancy, 104 experienced spontaneous abortions and 1 had a stillbirth. A total of 712 pregnancies (86.1%) resulted in a live birth, mostly among participants who received their first vaccination dose in the third trimester. Among live-born infants, the incidences of preterm birth (9.4%), small size for gestational age (3.2%), and congenital anomalies (2.2%) were consistent with those expected on the basis of published literature. There were no neonatal deaths. These are reassuring data based on reports from pregnant women mostly vaccinated in the third trimester.\n\n【6】In addition, rates of local and systemic reactions after vaccination among v-safe participants who identified as pregnant were similar to those in a larger group of nonpregnant women, which suggests that the physiologic changes in pregnancy do not materially affect such reactions. The most common side effect was injection-site pain, with fatigue, headache, and myalgia reported substantially more often after the second dose. Fever was reported in a small number of people after the first dose and in approximately a third of recipients after the second dose.\n\n【7】Given that there was a relatively small number of completed pregnancies and that live births were typically after vaccination in the third trimester, Shimabukuro et al. acknowledge the limitations in their ability to draw conclusions about spontaneous abortions, congenital anomalies, and other potential rare neonatal outcomes. Despite these limitations, this report provides important information that was not previously available.\n\n【8】With the pandemic ongoing and pregnant women at high risk for serious illness if infected with Covid-19, vaccination is a critical prevention strategy. The dearth of safety information about pregnancy, which existed at a time when thousands of pregnant women were grappling with decisions about vaccination, highlights the importance of recent efforts to enroll pregnant women in trials, including ongoing vaccine trials; a trial is currently under way to study the effects of the BNT162b2 vaccine in pregnant women and their infants .\n\n【9】It is notable that as of April 26, 2021, more than 100,000 pregnant women reported having received a Covid-19 vaccination and yet only a small fraction (4.7%) have enrolled in the v-safe pregnancy registry.  This situation underscores the urgent need not only to include pregnant women in clinical trials, but also to invest in public health surveillance systems for pregnancy, involving much larger numbers of women. To prepare for the next pandemic and improve health outcomes for pregnant women more generally, it is past time to invest in maternal health surveillance and research.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:49:30", "endTime": "2024/08/14 15:49:49", "cost": 19.196}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 23:49:49", "grab_time": "2024-08-13 23:49:29"}
{"id": 2234448, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "f6ca5d77-5ff4-4428-a7b0-347db699441e", "title": "Anatomic Assessment of Operability by the Saphenous-Vein Bypass Operation in Coronary-Artery Disease", "text": "【0】Anatomic Assessment of Operability by the Saphenous-Vein Bypass Operation in Coronary-Artery Disease\nAbstract\n--------\n\n【1】The distribution of obstructive coronary-artery lesions was studied in 300 hearts at autopsy to assess the potential of aortocoronary bypass. A vessel with a proximal obstructive lesion occupying more than 50 per cent of the coronary lumen and with a distal arterial segment suitable for anastomosis was regarded as operable. In general the obstructive lesions were proximal and multifocal. In the 300 hearts, 576 vessels were stenosed. Thus, 1.92 lesions per heart were encountered. The distal arterial segments were suitable for an anastomosis in 266 hearts. In 185 subjects all the obstructive lesions could have been bypassed, but in 81 only partial correction of the flow deficit would have been feasible. In 88 per cent of the hearts and 67 per cent of the lesions, the pattern of coronary-artery disease provided a favorable anatomic setting for the aortocoronary saphenous bypass operation.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:14:01", "endTime": "2024/08/14 15:18:18", "cost": 256.767}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 23:18:18", "grab_time": "2024-08-13 23:14:01"}
{"id": 2234447, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "9a2edfae-f313-499e-91b0-cb97828ef3ea", "title": "Transcatheter Mitral-Valve Repair in Patients with Heart Failure", "text": "【0】Transcatheter Mitral-Valve Repair in Patients with Heart Failure\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Among patients with heart failure who have mitral regurgitation due to left ventricular dysfunction, the prognosis is poor. Transcatheter mitral-valve repair may improve their clinical outcomes.\n\n【3】Methods\n-------\n\n【4】At 78 sites in the United States and Canada, we enrolled patients with heart failure and moderate-to-severe or severe secondary mitral regurgitation who remained symptomatic despite the use of maximal doses of guideline-directed medical therapy. Patients were randomly assigned to transcatheter mitral-valve repair plus medical therapy (device group) or medical therapy alone (control group). The primary effectiveness end point was all hospitalizations for heart failure within 24 months of follow-up. The primary safety end point was freedom from device-related complications at 12 months; the rate for this end point was compared with a prespecified objective performance goal of 88.0%.\n\n【5】Results\n-------\n\n【6】Of the 614 patients who were enrolled in the trial, 302 were assigned to the device group and 312 to the control group. The annualized rate of all hospitalizations for heart failure within 24 months was 35.8% per patient-year in the device group as compared with 67.9% per patient-year in the control group (hazard ratio, 0.53; 95% confidence interval \\[CI\\], 0.40 to 0.70; P<0.001). The rate of freedom from device-related complications at 12 months was 96.6% (lower 95% confidence limit, 94.8%; P<0.001 for comparison with the performance goal). Death from any cause within 24 months occurred in 29.1% of the patients in the device group as compared with 46.1% in the control group (hazard ratio, 0.62; 95% CI, 0.46 to 0.82; P<0.001).\n\n【7】Conclusions\n-----------\n\n【8】Among patients with heart failure and moderate-to-severe or severe secondary mitral regurgitation who remained symptomatic despite the use of maximal doses of guideline-directed medical therapy, transcatheter mitral-valve repair resulted in a lower rate of hospitalization for heart failure and lower all-cause mortality within 24 months of follow-up than medical therapy alone. The rate of freedom from device-related complications exceeded a prespecified safety threshold. \n\n【9】Introduction\n------------\n\n【10】 QUICK TAKE  \nMitral-Valve Repair in Heart Failure  \n\n【11】In patients with heart failure and left ventricular dilatation, mitral regurgitation may develop as a result of the geometric dislocation of the papillary muscles and chordae tendineae, impairing coaptation of the mitral leaflets.  Such secondary (functional) mitral regurgitation increases the severity of volume overload and has been strongly associated with decreased quality of life, an increased rate of hospitalization for heart failure, and shortened survival.  Guideline-directed medical therapy and cardiac resynchronization therapy may provide symptomatic relief, improve left ventricular function, and in some patients, lessen the severity of mitral regurgitation.  However, whether the correction of secondary mitral regurgitation improves the prognosis among patients with heart failure is unknown. Although mitral-valve surgery is curative for primary (degenerative) mitral regurgitation, neither surgical repair nor surgical replacement of the mitral valve has been shown to lower the rate of hospitalization or death associated with secondary mitral regurgitation, and both procedures confer a substantial risk of complications.  Thus, most patients with heart failure and secondary mitral regurgitation are treated conservatively,  and this high-risk group has few therapeutic alternatives.\n\n【12】Reduction of the severity of mitral regurgitation may be accomplished percutaneously by approximation of the anterior and posterior mitral leaflets, a procedure that leads to formation of a double-orifice valve.  In the randomized Endovascular Valve Edge-to-Edge Repair Study (EVEREST) II, transcatheter mitral-leaflet approximation with the MitraClip device (Abbott) was safer than surgical mitral-valve repair but was not as effective in reducing the severity of mitral regurgitation.  However, device-based and surgical mitral-valve repair were associated with similar outcomes in the small subgroup of patients with secondary mitral regurgitation.  We therefore conducted a randomized trial to evaluate the safety and effectiveness of transcatheter mitral-leaflet approximation in patients with heart failure and secondary mitral regurgitation who remained symptomatic despite the use of guideline-directed medical therapy.\n\n【13】Methods\n-------\n\n【14】Trial Design\n------------\n\n【15】Details about the design of the Cardiovascular Outcomes Assessment of the MitraClip Percutaneous Therapy for Heart Failure Patients with Functional Mitral Regurgitation (COAPT) trial have been published previously.  In brief, the COAPT trial was a multicenter, randomized, controlled, parallel-group, open-label trial of transcatheter mitral-valve repair with the MitraClip device in symptomatic patients with heart failure and moderate-to-severe or severe mitral regurgitation.\n\n【16】The trial was sponsored by Abbott. The protocol , available at NEJM.org, was designed by the principal investigators and the sponsor in accordance with the principles delineated by the Mitral Valve Academic Research Consortium.  The protocol was approved by the investigational review board at each participating center, and all the patients provided written informed consent. The sponsor participated in site selection and management and in data analysis. The principal investigators had unrestricted access to the data, wrote the manuscript, and vouch for the accuracy and completeness of the data and analyses and for the fidelity of the trial to the protocol.\n\n【17】Enrollment, Randomization, and Follow-up\n----------------------------------------\n\n【18】Eligible patients had ischemic or nonischemic cardiomyopathy with a left ventricular ejection fraction of 20 to 50%, had moderate-to-severe (grade 3+) or severe (grade 4+) secondary mitral regurgitation that was confirmed at an echocardiographic core laboratory before enrollment, and remained symptomatic (New York Heart Association \\[NYHA\\] functional class II, III, or IVa \\[ambulatory\\]) despite the use of stable maximal doses of guideline-directed medical therapy and cardiac resynchronization therapy (if appropriate), which were administered in accordance with guidelines of professional societies. A complete list of enrollment criteria is provided in Table S1 in the Supplementary Appendix .  At each site, patients were assessed by a heart team that consisted of a heart-failure specialist, an interventional cardiologist, and a cardiothoracic surgeon with expertise in mitral-valve disease. The interventional cardiologist confirmed that the patient was anatomically eligible for device implantation, and the cardiothoracic surgeon determined that mitral-valve surgery was not appropriate. A central eligibility committee confirmed that the patient met all the enrollment criteria (including use of maximal doses of guideline-directed medical therapy), confirmed that mitral-valve surgery would not be performed, and categorized the patient’s risk of surgery-related complications or death, with high risk defined as a Society of Thoracic Surgeons (STS) score for the risk of death within 30 days after mitral-valve replacement of 8% or higher (on a scale of 0.4 to 98.1%, with higher percentages indicating greater risk) or the presence of features that portend an extremely high risk of operative stroke or death.\n\n【19】Enrolled patients were randomly assigned, in a  ratio, to undergo transcatheter mitral-valve repair, to be performed within 14 days after randomization, and receive guideline-directed medical therapy (device group) or to receive guideline-directed medical therapy alone (control group). Randomization was stratified according to trial site and cause of cardiomyopathy (ischemic or nonischemic) and was performed with random block sizes of 2, 4, or 6. Details about the trial device and implantation procedure have been published previously and are provided in the Supplementary Appendix .  Details about the trial assessments are shown in Table S2 in the Supplementary Appendix . Clinical follow-up, which is ongoing, was to be performed at 1 week and at 1, 6, 12, 18, and 24 months after the implantation procedure in the device group and after a visit with the site heart-failure specialist in the control group (either of which would occur within 14 days after randomization) and then annually through 5 years. Follow-up assessments include periodic echocardiography, 6-minute walk tests (with longer distances indicating more preserved functional capacity and a 10% relative change from the baseline value indicating a minimally significant difference), and assessments of quality-of-life measures, including the NYHA functional class and the Kansas City Cardiomyopathy Questionnaire (KCCQ) score (on a scale of 0 to 100, with higher scores indicating better quality of life and a difference of 5 points indicating a minimally significant difference). Assessment for the primary effectiveness end point was to be performed through 2 years, with a minimum of 1 year of follow-up in all patients. Crossover was not to be permitted before 2 years of follow-up.\n\n【20】End Points\n----------\n\n【21】The definitions of the primary and secondary end points for hypothesis testing are provided in Tables S3 and S4 in the Supplementary Appendix . The primary effectiveness end point was all hospitalizations for heart failure within 24 months of follow-up, including recurrent events in patients with more than one event. The primary safety end point was freedom from device-related complications at 12 months. A device-related complication was defined as any occurrence of single-leaflet device attachment, embolization of the device, endocarditis that led to surgery, mitral stenosis (as confirmed by the echocardiographic core laboratory) that led to mitral-valve surgery, implantation of a left ventricular assist device, heart transplantation, or any other device-related event that led to nonelective cardiovascular surgery. Adverse events were adjudicated by an independent events committee with the use of source documents. Ventricular volumes and function, the severity of stenosis, and the severity of mitral regurgitation (with grade 0 indicating none, 1+ mild, 2+ moderate, 3+ moderate-to-severe, and 4+ severe) were assessed at the independent echocardiographic core laboratory. \n\n【22】Statistical Analysis\n--------------------\n\n【23】Details about the event-rate assumptions and power analyses have been published previously.  Analysis of the primary effectiveness end point of all hospitalizations for heart failure was performed with a joint frailty model to account for correlated events and the competing risk of death.  Assuming an annualized rate of all hospitalizations for heart failure of 42.0% per patient-year in the device group and 60.0% per patient-year in the control group, a 12-month mortality of 22.0% and 27.0%, respectively, and a 12-month attrition rate of 7.5%, we calculated that a sample of 610 patients would provide the trial with 80% power, at a one-sided alpha level of 0.05, to show the superiority of device-based treatment over medical therapy alone with regard to the annualized rate of all hospitalizations for heart failure within 24 months. Hazard ratios and two-sided 95% confidence intervals were also calculated with the joint frailty model. Analysis of the primary safety end point of freedom from device-related complications was performed with the asymptotic z test; the event-free rate was estimated with the Kaplan–Meier method and the standard error was estimated with the Greenwood method.  We calculated that a sample of 305 patients in the device group would provide the trial with more than 95% power, at a one-sided alpha level of 0.05, to show that the rate of freedom from device-related complications at 12 months was higher than a prespecified objective performance goal of 88.0% . If the hypotheses for both primary end points were met, then analyses of 10 secondary end points that the trial was powered to assess were to be performed in a prespecified hierarchical order to control for multiple comparisons . \n\n【24】All effectiveness analyses were performed from the time of randomization in the intention-to-treat population. The primary safety analysis was performed in the safety population, which consisted of all patients in the device group in whom device implantation was attempted. Sensitivity analyses were performed in the per-protocol and as-treated populations. Detailed descriptions of these populations are provided in the Supplementary Appendix .\n\n【25】For analyses of time to first event, event rates were compared with a Cox regression model. Categorical variables were compared with Fisher’s exact test. Continuous variables were compared with t tests or the Wilcoxon rank–sum test for nonnormally distributed data. An analysis of covariance model was used to compare mean changes in continuous variables from baseline to follow-up between groups. A sensitivity analysis with multiple imputation was performed to account for missing data.  For the analysis of superiority, a two-sided P value of less than 0.05 was considered to indicate statistical significance. All statistical analyses were performed with SAS software, version 9.4 (SAS Institute).\n\n【26】Results\n-------\n\n【27】Patients and Treatments\n-----------------------\n\n【28】Table 1. Characteristics of the Patients at Baseline.\n\n【29】From December 27, 2012, through June 23, 2017, a total of 614 patients at 78 centers in the United States and Canada were enrolled in the trial; 302 were randomly assigned to the device group and 312 to the control group . The baseline characteristics of the patients in the two trial groups were well matched . Among all the patients, the mean (±SD) age was 72.2±11.2 years, 36.0% were women, and 36.5% had received previous cardiac resynchronization therapy. The cause of cardiomyopathy was ischemic in 60.7% of the patients and nonischemic in 39.3%. The mean left ventricular ejection fraction was 31.3±9.3%, and the mitral regurgitation grade was 3+ in 52.2% of the patients and 4+ in 47.8%. The mean STS score for the risk of death within 30 days after mitral-valve replacement was 8.2±5.9%. The central eligibility committee determined that 69.2% of the patients were at high risk for surgery-related complications or death and 30.8% were not.\n\n【30】Device implantation was attempted in 293 of the 302 patients (97.0%) in the device group, with 1 or more clips implanted in 287 patients (98.0% of the 293 patients in whom implantation was attempted; 95.0% of all 302 patients in the device group) and a mean of 1.7±0.7 clips implanted per patient (range, 1 to 4) . Among the 260 patients in whom echocardiography was performed at the time of discharge, the mitral regurgitation grade was 1+ or lower in 214 patients (82.3%), 2+ in 33 patients (12.7%), 3+ in 9 patients (3.5%), and 4+ in 4 patients (1.5%). In the device group, the 30-day rates of death and stroke were 2.3% and 0.7%, respectively, and no patients underwent mitral-valve surgery. Details about medication use are provided in Tables S6 and S7 in the Supplementary Appendix . Major changes in medications during follow-up were infrequent in the two trial groups.\n\n【31】Primary and Secondary End Points\n--------------------------------\n\n【32】Table 2. Primary and Secondary End Points. Figure 1.  Figure 1. Primary Effectiveness and Safety End Points and Death.\n\n【33】Panel A shows the cumulative incidence of the primary effectiveness end point of all hospitalizations for heart failure within 24 months of follow-up among patients who underwent transcatheter mitral-valve repair and received guideline-directed medical therapy (device group) and among those who received guideline-directed medical therapy alone (control group). The data shown here do not account for the competing risk of death, which was considered in the joint frailty model. A total of 160 hospitalizations for heart failure occurred in 92 patients in the device group, and a total of 283 hospitalizations for heart failure occurred in 151 patients in the control group. Panel B shows the rate of the primary safety end point of freedom from device-related complications at 12 months among the 293 patients in whom device implantation was attempted, as compared with an objective performance goal. Panel C shows time-to-event curves for all-cause mortality in the device group and the control group.\n\n【34】Data collection for this analysis ended on August 3, 2018, when the last enrolled patient had completed 1 year of follow-up. A total of 97.7% of the patients in the device group and 94.2% in the control group had data available for 1 year of follow-up; the median follow-up was 22.7 months (interquartile range, 12.4 to 24.0) and 16.5 months (interquartile range, 10.1 to 24.0), respectively . The results for the primary and secondary end points that the trial was powered to assess are shown in Table 2 , and in Tables S8 through S18 in the Supplementary Appendix . One or more hospitalizations for heart failure occurred during follow-up in 92 of the patients in the device group and in 151 in the control group. The total number of hospitalizations for heart failure within 24 months was 160 in the device group and 283 in the control group . The annualized rate of all hospitalizations for heart failure was 35.8% per patient-year in the device group as compared with 67.9% per patient-year in the control group (hazard ratio, 0.53; 95% confidence interval \\[CI\\], 0.40 to 0.70; P<0.001). The number needed to treat to prevent 1 hospitalization for heart failure within 24 months was 3.1 (95% CI, 1.9 to 7.9). The rate of freedom from device-related complications at 12 months was 96.6% (lower 95% confidence limit, 94.8%), a rate that exceeded the objective performance goal of 88.0% for the primary safety end point (P<0.001) . The results of analyses performed in the per-protocol and as-treated populations were similar to the results of the primary effectiveness and safety analyses .\n\n【35】Hypothesis testing was positive for the 10 prespecified secondary end points that the trial was powered to assess. All-cause mortality within 24 months was significantly lower with device-based treatment than with medical therapy alone (29.1% vs. 46.1%; hazard ratio, 0.62; 95% CI, 0.46 to 0.82; P<0.001) . The number needed to treat to save one life within 24 months was 5.9 (95% CI, 3.9 to 11.7). In addition, quality of life (as assessed by the KCCQ and by determination of the NYHA functional class) was significantly better, functional capacity (as measured by the 6-minute walk test) was more preserved, and mitral regurgitation and left ventricular remodeling (as measured by mitral regurgitation grade and left ventricular end-diastolic volume) were less severe with device-based treatment than with medical therapy alone. The results for the primary and secondary end points were consistent after accounting for missing data with multiple imputation .\n\n【36】Additional Outcome Measures\n---------------------------\n\n【37】Table 3. Adverse Events within 24 Months in the Intention-to-Treat Population. Figure 2.  Figure 2. Subgroup Analyses of Hospitalization for Heart Failure within 24 Months.\n\n【38】Shown are annualized estimates of all hospitalizations for heart failure within 24 months of follow-up across subgroups. The median value was used as a cutoff for age (median, 74 years), left ventricular ejection fraction (median, 30%), and left ventricular end-diastolic volume (median, 181 ml). For the additional cutoff for left ventricular ejection fraction, a value of 40% or less indicates the presence of heart failure with reduced ejection fraction and a value of more than 40% the presence of heart failure with preserved ejection fraction, two different diseases associated with different prognoses and treatments. Society of Thoracic Surgeons (STS) scores for the risk of death within 30 days after mitral-valve replacement range from 0.4 to 98.1%, with higher percentages indicating greater risk. The risk of surgery-related complications or death was determined by the central eligibility committee, with high risk defined as an STS score for the risk of death within 30 days after mitral-valve replacement of 8% or higher or the presence of features that portend an extremely high risk of operative stroke or death. NYHA denotes New York Heart Association.\n\n【39】Data on adverse events are shown in Table 3 , and in Table S19 and Figures S3 through S6 in the Supplementary Appendix . The 24-month risk of the composite of death from any cause or hospitalization for heart failure was significantly lower in the device group than in the control group, as was the 24-month risk of hospitalization for any cause. The lower rate of hospitalization for heart failure in the device group was robust after adjustment for differences between the trial groups in medications used for heart failure at baseline (hazard ratio, 0.55; 95% CI, 0.42 to 0.73; P<0.001), as was the lower mortality (hazard ratio, 0.65; 95% CI, 0.49 to 0.86; P=0.003). The rate of implantation of a left ventricular assist device or heart transplantation during follow-up was lower in the device group than the control group. The lower rates of hospitalization for heart failure, death, and the composite of death or hospitalization for heart failure in the device group were consistent across all the examined subgroups . There were no significant interactions between the trial group and these events according to age, sex, the severity of mitral regurgitation, left ventricular function or volume, the cause of cardiomyopathy, or the risk of surgery-related complications or death at baseline.\n\n【40】Discussion\n----------\n\n【41】The COAPT trial evaluated the safety and effectiveness of transcatheter mitral-valve repair in patients with heart failure and moderate-to-severe or severe secondary mitral regurgitation who remained symptomatic despite the use of maximal doses of guideline-directed medical therapy. In this trial, device-based treatment resulted in a significantly lower rate of hospitalization for heart failure, lower mortality, and better quality of life and functional capacity within 24 months of follow-up than medical therapy alone. In addition, the rate of freedom from device-related complications with transcatheter mitral-valve repair exceeded a prespecified objective performance goal. The benefits were consistent across numerous subgroups, including patients who had ischemic and nonischemic cardiomyopathy and those who were and were not at high risk for surgery-related complications or death, and the benefits were independent of the mitral regurgitation grade and left ventricular volume and function at baseline.\n\n【42】The MitraClip device used in this trial was approved by the Food and Drug Administration in 2013 for the treatment of primary mitral regurgitation in patients who are at a prohibitive risk for surgery-related complications or death. Approval was based on uncontrolled registry data that showed symptomatic improvements,  and in the United States, the device is principally used for this indication.  However, outside the United States, the device is more often used to treat secondary mitral regurgitation in patients with heart failure.  The prognosis among patients with heart failure and secondary mitral regurgitation is very poor; in this trial, approximately two thirds of such patients died or were hospitalized for heart failure within 2 years despite the use of guideline-directed medical therapy. Transcatheter mitral-leaflet approximation led to a decrease in the severity of secondary mitral regurgitation; this is presumably the mechanism behind the improvements in prognosis, quality of life, and functional capacity among patients who received device-based treatment. Of note, the lower rate of hospitalization for heart failure with device-based treatment emerged within 30 days after treatment. The lower mortality predominantly emerged more than 1 year after treatment, a delayed response consistent with long-term benefits from a durable decrease in the severity of left ventricular volume overload.\n\n【43】The clip implantation rate of 98% and the immediate achievement of a mitral regurgitation grade of 2+ or lower in 95% of the patients in the device group in this trial were substantially better than those outcomes among lower-risk patients in the early EVEREST II trial,  findings that probably reflect operators’ increased experience with implantation and improved echocardiographic guidance. The decrease in the severity of mitral regurgitation that was associated with transcatheter mitral-leaflet approximation was also durable over time. Among surviving patients in the device group, the mitral regurgitation grade at 2 years was 3+ or higher in only 0.9% and was 2+ or higher in only 22.8%. In contrast, a previous randomized trial evaluated the effectiveness of a downsized annuloplasty ring in patients who had secondary ischemic mitral regurgitation of similar severity to that seen in this trial; among surviving patients who were treated with the downsized annuloplasty ring, the mitral regurgitation grade at 2 years was 3+ or higher in 14.0% and was 2+ or higher in 58.8%. \n\n【44】Some limitations of this trial should be noted. First, because the MitraClip device is visible on imaging studies, the investigators were aware of the trial-group assignments. Efforts to mitigate bias included rigorous protocol-specified procedures to standardize guideline-directed medical therapy and the use of an independent events committee and a central echocardiographic core laboratory. The robustness of the lower rate of hospitalization for heart failure and the lower mortality in the device group, coupled with consistent decreases in the severity of mitral regurgitation and improvements in quality of life and functional capacity in that group, supports the validity of the principal findings. Nonetheless, potential bias cannot be completely ruled out. Second, the median follow-up was longer in the device group than in the control group, in part because of the lower mortality in the device group. However, withdrawal from the trial was more frequent in the control group. The principal results were consistent after imputation for missing data. Third, agents that affect the renin–angiotensin axis were by chance used more frequently at baseline in the device group. The principal findings were robust after adjustment for these differences. Fourth, long-term follow-up, which is to be ongoing through 5 years, is necessary to fully characterize the safety and effectiveness of the device. The results of this analysis apply to treatment of secondary mitral regurgitation with mitral-leaflet approximation as tested in this trial; whether other transcatheter-based or surgical approaches would have similar results is uncertain. Finally, all enrolled patients were symptomatic (NYHA class II, III, or IVa \\[ambulatory\\]) despite the use of maximal doses of guideline-directed medical therapy (with more than one third of patients having undergone cardiac resynchronization therapy) and had moderate-to-severe or severe mitral regurgitation, a left ventricular ejection fraction of 20 to 50%, and frequent coexisting conditions. Whether the device would have similar benefits in patients who are less or more critically ill or in those with less severe mitral regurgitation is unknown.\n\n【45】In conclusion, among patients with heart failure and moderate-to-severe or severe secondary mitral regurgitation who remained symptomatic despite the use of maximal doses of guideline-directed medical therapy, transcatheter mitral-valve repair resulted in a lower rate of hospitalization for heart failure, lower mortality, and better quality of life and functional capacity within 24 months of follow-up than medical therapy alone, and the prespecified goal for freedom from device-related complications was met.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-14 00:21:14", "grab_time": "2024-08-13 23:41:27"}
{"id": 2234446, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "191bfbe0-a223-4443-8ac6-015f8d2e37b3", "title": "The Transparent Baby Bag — A Shield against Heat Loss", "text": "【0】The Transparent Baby Bag — A Shield against Heat Loss\nAbstract\n--------\n\n【1】Swaddling of newborn infants in double-layered, clear-plastic bags with a head shield allowed less heat loss than a radiant heater alone. Protection against heat loss is increased if the plastic bag is combined with a radiant heater. This protection is accomplished without severe compromise of either visualization or handling of the infant.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 16:33:48", "endTime": "2024/08/13 16:36:09", "cost": 141.279}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 00:36:09", "grab_time": "2024-08-13 00:33:47"}
{"id": 2234445, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "99ca3f96-8582-4d56-aa9e-9371825a456f", "title": "Holding Up", "text": "【0】Holding Up\nArticle\n-------\n\n【1】_How are you holding up?_\n\n【2】This question has become my pandemic refrain, the way I begin all my virtual visits these days. I imagine Atlas, a Titan condemned to forever hold up the heavens after losing in battle to the invincible Greek god Zeus: knees bent, back hunched, arms raised above his head as he staggers under the planet’s weight. Or Varaha, the boar, one of the 10 avatars of the Hindu god Vishnu. When the demon Hiranyaksha dragged the Earth to the bottom of the sea, Varaha fought for a thousand years, slayed the demon, and rescued the world by hoisting it bravely on his tusks.\n\n【3】At present, the world is especially heavy. As a primary care doctor seeing patients with a range of lived experiences, I cannot know, until I ask, the burdens they carry. In one afternoon, I receive a variety of responses.\n\n【4】“I’m blessed,” a 59-year-old accountant and single mother tells me, brightly. Her daughter is home from college, on a long hiatus due to Covid-19. They take morning walks together and toss salads for lunch. With the loving company and healthful routine, she has lost 10 pounds and lowered her blood pressure.\n\n【5】“We can’t complain,” says a 78-year-old husband and the father of two adult children. He is a professor of Latin American studies, and though he can’t take his usual fieldwork trip this summer, he has been cooking with his wife and seeing his grandchildren for socially distant visits on the porch.\n\n【6】“Much better, now,” confides a 23-year-old law student for whom the isolation triggered a numbing depression. Today, she feels more herself after starting medication and therapy as well as establishing a routine.\n\n【7】Amid expressions of gratitude, relief, and silver linings, I never know when I’ll walk into a minefield. Even the tidy preparation of an archivist cannot ready me for such moments.\n\n【8】My next patient is a 48-year-old woman. I haven’t met her before, though she has known my preceptor for a long while. The note says “Telephone visit,” so I make myself coffee and grab a biscuit as fuel. Perusing her chart, I observe the trend of her glycated hemoglobin level, which has climbed steadily, like the suspenseful opening to a roller-coaster, _click, click, click_ . Her kidneys are beginning to show signs of strain.\n\n【9】I check her insurance, determining which of the newer diabetes agents she would qualify for. And I mentally plan the speech with which I will convince her of the importance of weekly injections to help control her sugars and lose weight — the mechanism, benefits, side effects of dulaglutide are all at the tip of my tongue.\n\n【10】“How are you holding up?” I begin, my pace quicker than usual. I am eager to begin counseling her on chronic disease management.\n\n【11】The voice on the other end is muffled. Did she hear the question? Is it a poor connection?\n\n【12】I try again. “How are you and your family holding up during the pandemic?”\n\n【13】She pauses. Soon, I will realize, she is rearranging words to see what she can bear to say aloud. But the unspeakable runs through the fabric of things; it cannot be ironed out.\n\n【14】Slowly, the words emerge through static. “Okay, considering. It gets a little easier each day. But still, I can’t sleep.”\n\n【15】I wonder if I have missed something. “Who lives at home with you?”\n\n【16】“My children, my grandson, one of my sisters,” she says.\n\n【17】Only then do I find out that she lost her husband, aunt, and uncle to Covid-19 last month, in one fell swoop. My telephone visit for diabetes management takes an unimaginable turn into the bowels of her grief. I express condolences, though any words feel hollow. I learn about her husband’s extended hospital stay, ending with a week on a ventilator, and her inability to see him before he died. Just a week before he was infected with Covid, he was working, laughing with his children, eating with relish the meals she cooked for him. I hear about her aunt’s decline in a nursing facility, infection overwhelming her weak body and then taking hold of the loving husband who had stayed by her side. We discuss the patient’s paralyzing insomnia; trazodone is no match for her loss.\n\n【18】She is gracious, shepherding me through a catastrophe that has become her accustomed world this past month. We speak softly for 40 minutes and make a plan to touch base soon. Then, still stunned, I hang up the phone. By now my coffee is lukewarm. The biscuit is reduced to crumbs — I had been shredding it with my fingers as we spoke.\n\n【19】There is no space for the magnitude of this woman’s loss at the dining table where I work — in this place where sunlight pours in at a slant, trees are heavy with blossoms that shake in the breeze, and I hear the tinkling sound of laughter as a neighbor’s child careens down the street on her bike. Even across the tiny city of Boston, we are living in different worlds, one carved out by her immense grief, the other by my privilege and relative safety. How can I chart a path between our coordinates?\n\n【20】In the 16th century, the Flemish cartographer Gerardus Mercator published a collection of maps, a two-dimensional distortion of the globe that allowed navigators to easily plot a straight-line course between two points of constant bearing. Now, finally, sailors could traverse the oceans. On his schema, Mercator printed an image of Atlas the Titan. Atlas (from Greek via Latin, “to suffer, endure, bear”) thus came to mean a collection of maps — whether of planets, countries, or bodies — as well as the first cervical vertebra that holds up the human skull.\n\n【21】When _How are you?_ feels untenable, I ask _How are you holding up?_ The question anticipates intensity, challenge, or a recent experience of pain. It assumes, too, that care transpires in continuity — “holding” reflects life as an ongoing blur of time rather than distinct moments neatly punctuated by medical visits. The phone call or visit ends, but patients’ stories linger — each one a shiny pebble in a vast quarry, but collectively weighty, they glint in the light of recollection as I turn them over and over again in my mind.\n\n【22】In Bengali, when the load is lessened, we say _Halka laglo_ , “I feel lighter.” So when I step unwittingly into the minefield of another’s grief, an occurrence that has become far more common these days, I envision my task as one of holding up. It is my privilege (and burden) as a physician to carry stories. Atlas the Titan was condemned to hold the world up by himself for eternity; Varaha the divine boar was celebrated for his solo rescue of the planet. But I am not alone. My patients’ tenacity, their tenderness, buoys me up between visits. My colleagues’ grit and grace under pressure inspire me to persist. My family is my refuge, the container for both my tears and my laughter. In the devastation wrought by Covid-19, we all hold up or fall apart together. That medicine is accompaniment — bearing others’ sorrow, walking the bumpy path alongside them — feels truer now than ever.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-14 00:18:41", "grab_time": "2024-08-13 22:45:12"}
{"id": 2234444, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "55942d17-7d33-4e86-a81a-a626ac96c2f2", "title": "Brief Report: Recognition of Acute Myocarditis Masquerading as Acute Myocardial Infarction", "text": "【0】Brief Report: Recognition of Acute Myocarditis Masquerading as Acute Myocardial Infarction\nIntroduction\n------------\n\n【1】Myocarditis occasionally masquerades as acute myocardial infarction because patients may present with severe chest pain, electrocardiographic changes, and elevated serum levels of creatine kinase. In patients with normal coronary arteries who presumably died of acute myocardial infarction, myocarditis has been reported as an incidental abnormality at autopsy  . Although there have been anecdotal clinical reports of myocarditis mimicking myocardial infarction in patients with normal coronary arteries, this association has almost always relied on a demonstration of diffuse electrocardiographic abnormalities or a preceding viral illness in young patients with few coronary risk factors  . In most cases no definitive diagnosis was sought after the patient was found to have normal coronary arteries, and the presence of myocarditis in this setting has only rarely been documented during life by endomyocardial biopsy  . The ability to recognize myocarditis in patients presumed to have myocardial infarction would be valuable because abnormal ventricular function generally resolves rapidly in such patients and their long-term outcome is usually good  .\n\n【2】From 1984 to 1991, 164 patients at our institution underwent antimyosin myocardial scintigraphy and right ventricular endomyocardial biopsy for suspected myocarditis. A review of their clinical presentations revealed that eight patients had been admitted to the coronary care unit with an initial diagnosis of acute myocardial infarction based on prolonged chest pain and electrocardiographic abnormalities diagnostic of ischemia. The fact that these eight patients were found to have normal coronary arteries later in their hospital stay led us to suspect that they may have had myocarditis. This report describes the clinical presentations of these eight patients and the adjunctive use of myocardial scintigraphy with antimyosin antibody in making the diagnosis of myocarditis. The antimyosin scans in these patients were compared with images obtained from 45 patients with acute myocardial infarction and angiographic evidence of coronary artery occlusion.\n\n【3】Case Reports\n------------\n\n【4】Patients with Myocarditis Mimicking Myocardial Infarction\n---------------------------------------------------------\n\n【5】### _Clinical Presentation_\n\n【6】Table 1. Clinical Characteristics of the Patients.\n\n【7】The study group comprised four men and four women (age, 26 to 70 years; mean ±SE, 51 ±6) . Five patients had two or three coronary risk factors, two had one risk factor, and the remaining patient had none. No patient was febrile at the time of admission or during hospitalization, although two had an antecedent viral illness of the upper respiratory tract. Because a diagnosis of myocarditis was not considered initially by the patients' physicians, viral antibody titers were not serially evaluated.\n\n【8】All eight patients experienced severe, nonpleuritic precordial pain of sudden onset indistinguishable from that of acute myocardial infarction. One patient arrived at the hospital in cardiogenic shock, and cardiogenic shock developed in another in the hospital. The other six patients had no clinical features suggestive of left ventricular failure. Electrocardiographic changes in the ST segments and T waves were observed in the anterior leads in four patients and the inferior leads in one, with no evidence of reciprocal changes in the ST segments. The electrocardiographic abnormalities were diffuse (i.e., extended beyond a single vascular distribution) in two patients. One patient had left bundle-branch block. Peak serum creatine kinase levels were elevated in six of the eight patients (range, 150 to 1518 units per liter). The MB isoenzyme fractions ranged from 4 to 22 percent (normal values are given in Table 1 ).\n\n【9】After admission, five patients continued to have intractable or recurrent episodes of chest pain despite therapy directed at reversing ischemia. In all eight patients, the electrocardiographic changes failed to evolve in a pattern typical of acute myocardial infarction. Serum enzyme levels in one patient indicated mild but persistent release of creatine kinase. All eight patients underwent coronary angiography because of recurrent chest pain or doubts about the initial diagnosis of myocardial infarction due to coronary artery disease.\n\n【10】### _Coronary Angiography and Left Ventriculography_\n\n【11】All eight patients had normal coronary arteries on angiography. Coronary artery spasm was not observed in two patients who had spontaneous chest pain during angiography or in one other patient who underwent a challenge test with the vasoconstrictor ergonovine. Left ventriculography revealed normal wall motion in three patients, and three patients had global left ventricular hypokinesia. Two patients had strikingly abnormal regional wall motion inconsistent with ischemia in a single coronary artery territory: one had dyskinesia of the mid-anterolateral wall, with normal contraction of the remaining ventricular regions, and the other had impairment of most of the left ventricle ranging from akinesia to dyskinesia, except for normally contracting basal and apical segments. The left ventricular ejection fractions were normal in Patients 2, 3, 4, and 8 (55 to 72 percent)  and low in the remaining four patients (34 to 46 percent).\n\n【12】All eight patients underwent a right ventricular endomyocardial biopsy (performed and interpreted as previously described  ) and indium-111-labeled antimyosin-antibody imaging  to evaluate the possibility that myocarditis was causing the cardiac problem.\n\n【13】### _Antimyosin Scintigraphy and Endomyocardial Biopsy_\n\n【14】Monoclonal antimyosin antibody (500 μg, R11D10 Fab, Centocor, Malvern, Pa.) coupled to diethylenetriamine pentaacetic acid was radiolabeled with  In (1.8 mCi) and administered through a peripheral vein after informed consent had been obtained. Planar images (anterior and left anterior oblique, 60 to 70 degrees) and tomographic images (reconstructed into transverse, sagittal, and coronal projections) were obtained with a gamma camera (medium-energy collimator) 48 hours after the administration of the radiotracer  . Antimyosin scans were interpreted as positive when there was evidence of the uptake of tracer in the planar image and at least two of the three tomographic reconstructions. Scans were considered negative when no uptake of tracer was demonstrated in either the planar or tomographic images. The scans were analyzed without knowledge of the patients' identities and clinical or histologic findings. The use of antimyosin scintigraphy for the detection of acute myocardial infarction and myocarditis has been approved by our institutional research and radiation-safety boards.\n\n【15】Figure 1. Antimyosin Scintigram  and Endomyocardial-Biopsy Specimen  Showing Evidence of Myocarditis in Patient 1.\n\n【16】Panel A shows diffuse, global uptake of radiolabeled antimyosin antibody by the left ventricle (large arrows) in an anterior planar image. The apical region has been relatively spared (small arrows). This patient's left ventriculogram showed impairment of the whole ventricle ranging from akinesia to dyskinesia, except for a normally contracting base and apex. Hepatic activity (L) reflects the normal distribution of  In-labeled antimyosin antibody. In Panel B, a photomicrograph of an endomyocardial-biopsy sample reveals the central focus (arrow) of interstitial mononuclear inflammatory infiltrate associated with necrotic myocytes (hematoxylin and eosin, x60).\n\n【17】Antimyosin myocardial scintigraphy revealed diffuse, heterogeneous, and global left ventricular uptake in seven patients (Patients 1 through 7) . Diffuse uptake was occasionally associated with marked regional variability (i.e., more intense uptake in particular regions) that did not correspond to a single coronary artery territory. Of the seven patients with positive scans, three (Patients 1, 2, and 3) had biopsy specimens positive for myocarditis . Although the fourth patient's initial endomyocardial biopsy was nondiagnostic, he returned five months later with shortness of breath; a second biopsy revealed myocarditis, and an antimyosin scan was also positive. The biopsy specimen of Patient 5 showed nonspecific interstitial fibrosis and myocytic hypertrophy (despite a mild, persistent increase in serum creatine kinase and a positive scan). The clinical condition of this patient deteriorated over the next three months, and congestive heart failure developed. A follow-up antimyosin scan revealed more intense diffuse left ventricular uptake than did the initial scan. A follow-up biopsy showed focal lymphocytic myocarditis. Thus, the initial antimyosin scan detected myocytic necrosis before there was clinical evidence of heart failure and despite the fact that the biopsy evidence was inconclusive. The sixth and seventh patients with positive scans had borderline myocarditis, according to defined histologic criteria  .\n\n【18】The biopsy samples from Patient 8  revealed focal myocarditis with lymphocytic and eosinophilic infiltration and endomyocardial fibrosis. Her antimyosin scan showed faint uptake of antibody in the planar images and predominantly posterobasal localization in the sagittal images. Because the uptake of antimyosin antibody could not be confirmed in the other tomographic reconstructions, the results of this patient's scan were considered equivocal.\n\n【19】### _Treatment and Follow-up_\n\n【20】At the time of the most recent assessment, the study group had been followed for 5 to 77 months (mean ±SE, 34 ±12). The six patients with biopsy evidence of myocarditis received prednisone and azathioprine. Of the four patients with normal left ventricular ejection fractions on initial examination, two (Patients 2 and 8) continued to have normal systolic function and remained asymptomatic . No follow-up data on the ejection fraction were available for the other two patients (Patients 3 and 4). Of the four patients who initially had impaired systolic left ventricular function, one died of congestive heart failure after nine months (Patient 5). The remaining three (two of whom were admitted in cardiogenic shock) were asymptomatic, and their ejection fractions had returned to normal at the most recent assessment (Patients 1, 6, and 7).\n\n【21】Electrocardiographic abnormalities persisted for more than one year in four patients (Patients 1, 2, 7, and 8) and until death in Patient 5 and virtually disappeared within six months in Patient 4. Follow-up electrocardiograms were not available for Patients 3 and 6.\n\n【22】Patients with Myocardial Infarction\n-----------------------------------\n\n【23】Antimyosin myocardial scans were also obtained in 45 patients with acute myocardial infarction and angiographic evidence of coronary occlusion. All 45 patients arrived at the emergency room with chest pain and electrocardiographic changes typical of myocardial infarction. In all patients, the electrocardiographic changes and enzyme elevations evolved typically. Coronary angiography performed at the time of admission showed occlusion of the left anterior descending artery in 23 patients, the left circumflex artery in 6 patients, and the right coronary artery in 16 patients. All 45 patients received thrombolytic therapy; perfusion was reestablished in 37.\n\n【24】Figure 2. Localized Uptake of Antimyosin Antibody in Acute Myocardial Infarction.\n\n【25】In Panel A, intense, discrete, localized uptake of antimyosin antibody (arrows) is associated with a large, acute anterior myocardial infarct in an anterior view. The midportion of the left anterior descending coronary artery was occluded beyond the first diagonal and septal arteries. L denotes liver. In Panel B, there is discrete uptake of radiolabeled antimyosin antibody in the inferior region (black arrow) of the left ventricle in a patient with an occluded right coronary artery. No uptake of antimyosin antibody is visible in the region of the left anterior descending coronary artery (white arrows).\n\n【26】The uptake of antimyosin antibody in these patients was intense, discrete, and localized and was evident within 24 hours after injection . Scintigraphically defined regions of myocytic necrosis conformed to territories of occluded coronary arteries and correlated with electrocardiographic abnormalities. There was no uptake in the normal coronary artery territories, and no diffuse or global uptake.\n\n【27】Discussion\n----------\n\n【28】All eight patients in our study presented with prolonged chest pain, which occurred suddenly, leading to an erroneous initial diagnosis of acute myocardial infarction. Although their hospital courses were usually associated with recurrent or intractable chest pain, there was no further evolution of the electrocardiographic changes indicative of ischemia. Coronary arteriography was performed to determine the extent and location of the coronary artery disease. The atypical evolution of illness in these eight patients, along with findings of normal coronary arteries and inexplicable abnormalities of left ventricular wall motion, led to the consideration of a primary myopathic process. Antimyosin myocardial scintigraphy or right ventricular endomyocardial biopsy subsequently demonstrated the presence of myocarditis in all eight patients.\n\n【29】Antimyosin antibody binds specifically to myocardial cells whose sarcolemma has lost its integrity  . Scintigraphic examination with this antibody has been used for the noninvasive detection of myocytic necrosis associated with acute myocardial infarction, with a sensitivity and specificity of over 90 percent  . Since myocytic necrosis is an essential component of myocarditis,  almost all patients with biopsy-proved myocarditis have an abnormal antimyosin scan (sensitivity, 83 to 100 percent)  . Although the specificity of antimyosin scintigraphy for myocarditis is 53 to 58 percent, almost all normal antimyosin scans are associated with a biopsy negative for myocarditis (negative predictive value, 92 to 100 percent). The high sensitivity and high negative predictive value of a normal antimyosin scan make it a useful screening tool for patients with suspected myocarditis  .\n\n【30】Myocytic necrosis in myocarditis is associated with a pattern of antimyosin-antibody uptake distinctly different from that of myocardial infarction. Myocarditis is usually characterized by diffuse, faint, and heterogeneous uptake of antimyosin antibody , because myocytic necrosis in this illness is typically multifocal. Acute myocardial infarction, on the other hand, is almost always characterized by intense, localized uptake of antibody in the region of an occluded coronary vessel . Intense, localized uptake of antimyosin antibody also occasionally occurs in myocarditis, but it is invariably associated with diffuse and global uptake of antibody.\n\n【31】Although an endomyocardial biopsy is the standard procedure for diagnosing myocarditis, our results demonstrate that antimyosin scintigraphy can be of substantial diagnostic usefulness in patients with presumed myocardial infarction but normal coronary arteries. In this context, diffuse myocytic necrosis beyond a coronary territory detected by antimyosin scintigraphy would indicate a strong likelihood of myocarditis. On the other hand, a pattern of antimyosin-antibody uptake conforming to an individual coronary vascular distribution despite the presence of normal coronary arteries would indicate other causes of nonatherosclerotic coronary artery disease, such as spasm or coronary embolism. A normal antimyosin scan would exclude both acute myocardial infarction and myocarditis.\n\n【32】This small series seems to confirm that myocarditis can masquerade as acute myocardial infarction. After the presence of normal coronary arteries has been confirmed in a patient presumed to have myocardial infarction, this alternative diagnosis should be considered if there is evidence of myocardial damage that does not conform to a particular coronary vascular distribution. The presence of diffuse myocardial involvement can be indicated by widespread electrocardiographic or wall-motion abnormalities. A diffusely positive antimyosin scan provides additional corroboration of a myopathic rather than an ischemic process.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 10:47:00", "endTime": "2024/08/14 10:51:33", "cost": 272.822}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 18:51:33", "grab_time": "2024-08-13 18:46:59"}
{"id": 2234443, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "0ed91a51-ee15-41ab-a138-4dbd688c0aa1", "title": "Neutralization Escape by SARS-CoV-2 Omicron Subvariants BA.2.12.1, BA.4, and BA.5", "text": "【0】Neutralization Escape by SARS-CoV-2 Omicron Subvariants BA.2.12.1, BA.4, and BA.5\nTo the Editor:\n--------------\n\n【1】Figure 1. Omicron Subvariant Mutations and Neutralizing Antibody Responses.\n\n【2】Panel A shows the lineage of mutations that have been identified in the omicron BA.1, BA.2, BA.2.12.1, and BA.4 or BA.5 subvariants of SARS-CoV-2, as compared with the reference WA1/2020 isolate. BA.4 and BA.5 have identical sequences of the spike protein and thus have been grouped together. FP denotes fusion peptide, HR1 heptad repeat 1, HR2 heptad repeat 2, NTD N-terminal domain, RBD receptor-binding domain, RBM receptor-binding motif, SD1 subdomain 1, and SD2 subdomain 2. Panel B shows neutralizing antibody titers as determined by luciferase-based pseudovirus neutralization assays in samples obtained from 27 participants 6 months after receipt of the two-dose BNT162b2 messenger RNA vaccine series and 2 weeks after the third (booster) dose. Panel C shows neutralizing antibody titers in participants who had been infected with the BA.1 or BA.2 subvariant. All the infected participants had been vaccinated except for 1 participant who had a negative neutralizing antibody titer. In 9 participants, two or three time points after infection are shown. Neutralizing antibody titers were measured against the SARS-CoV-2 reference isolate WA1/2020 and the omicron BA.1, BA.2, BA.2.12.1, and BA.4 or BA.5 subvariants. In Panels B and C, medians (black bars) are shown numerically, and factor differences from other subvariants are indicated; the dashed horizontal line indicates the lower limit of detection for the assay.\n\n【3】In recent months, multiple lineages of the omicron (B.1.1.529) variant of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) have emerged,  with subvariants BA.1 and BA.2 showing substantial escape from neutralizing antibodies.  Subvariant BA.2.12.1 is now the dominant strain in the United States, and BA.4 and BA.5 are dominant in South Africa . Subvariants BA.4 and BA.5 have identical sequences of the spike protein.\n\n【4】We evaluated neutralizing antibody titers against the reference WA1/2020 isolate of SARS-CoV-2 along with omicron subvariants BA.1, BA.2, BA.2.12.1, and BA.4 or BA.5 in 27 participants who had been vaccinated and boosted with messenger RNA vaccine BNT162b2 (Pfizer–BioNTech) and in 27 participants who had been infected with the BA.1 or BA.2 subvariant a median of 29 days earlier (range, 2 to 113) . In the vaccine cohort, participants were excluded if they had a history of SARS-CoV-2 infection or a positive result on nucleocapsid serologic analysis or if they had received another vaccine against coronavirus disease 2019 (Covid-19) or an immunosuppressive medication.\n\n【5】Six months after the initial two BNT162b2 immunizations, the median neutralizing antibody pseudovirus titer was 124 against WA1/2020 but less than 20 against all the tested omicron subvariants . Two weeks after administration of the booster dose, the median neutralizing antibody titer increased substantially, to 5783 against the WA1/2020 isolate, 900 against the BA.1 subvariant, 829 against the BA.2 subvariant, 410 against the BA.2.12.1 subvariant, and 275 against the BA.4 or BA.5 subvariant. These data show that as compared with the response against the WA1/2020 isolate, the neutralizing antibody titer was lower by a factor of 6.4 against BA.1, by a factor of 7.0 against BA.2, by a factor of 14.1 against BA.2.12.1, and by a factor of 21.0 against BA.4 or BA.5. In addition, as compared with the median neutralizing antibody titer against the BA.1 subvariant, the median titer was lower by a factor of 2.2 against the BA.2.12.1 subvariant and by a factor of 3.3 against the BA.4 or BA.5 subvariant.\n\n【6】Among the participants who had been infected with the BA.1 or BA.2 subvariant of omicron, all but one had been vaccinated against Covid-19. Because of the variation in sampling after the onset of infection, some samples may not reflect peak neutralizing antibody titers . Among the participants with a history of Covid-19, the median neutralizing antibody titer was 11,050 against the WA1/2020 isolate, 1740 against the BA.1 subvariant, 1910 against the BA.2 subvariant, 1150 against the BA.2.12.1 subvariant, and 590 against the BA.4 or BA.5 subvariant . These data show that as compared with the WA1/2020 isolate, the median neutralizing antibody titer was lower by a factor of 6.4 against BA.1, by a factor of 5.8 against BA.2, by a factor of 9.6 against BA.2.12.1, and by a factor of 18.7 against BA.4 or BA.5. In addition, as compared with the median titers against the BA.1 subvariant, the median titer was lower by a factor of 1.5 against the BA.2.12.1 subvariant and by a factor of 2.9 against the BA.4 or BA.5 subvariant.\n\n【7】These data show that the BA.2.12.1, BA.4, and BA.5 subvariants substantially escape neutralizing antibodies induced by both vaccination and infection. Moreover, neutralizing antibody titers against the BA.4 or BA.5 subvariant and (to a lesser extent) against the BA.2.12.1 subvariant were lower than titers against the BA.1 and BA.2 subvariants, which suggests that the SARS-CoV-2 omicron variant has continued to evolve with increasing neutralization escape. These findings provide immunologic context for the current surges caused by the BA.2.12.1, BA.4, and BA.5 subvariants in populations with high frequencies of vaccination and BA.1 or BA.2 infection.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-14 00:22:06", "grab_time": "2024-08-13 23:52:29"}
{"id": 2234442, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "b86b9a87-eebc-4d2a-8ca2-b1f6a3b6cb34", "title": "Cigarette Smoking and the Risk of Endometrial Cancer", "text": "【0】Cigarette Smoking and the Risk of Endometrial Cancer\nAbstract\n--------\n\n【1】Because of evidence of reduced estrogen excretion in the urine of women who smoke cigarettes and evidence linking estrogen levels to the risk of cancer of the female reproductive system, we evaluated the risk of endometrial cancer in relation to cigarette use in a hospital-based case–control study of 510 women with endometrial cancer (cases) and 727 women with other cancers (controls).\n\n【2】The rate-ratio estimate (relative risk) for current smokers as compared with women who had never smoked was 0.7 (95 per cent confidence interval, 0.5 to 1.0), and for former smokers the estimate was 0.9 (0.6 to 1.2). For women currently smoking 25 or more cigarettes per day, the rate-ratio estimate was 0.5 (0.3 to 0.8). The effect of current smoking of at least 25 cigarettes per day appeared to be confined to postmenopausal women, among whom the estimate was 0.5 (0.2 to 0.9). Among premenopausal women the estimate was 0.9 (0.4 to 2.2), but the difference between these two estimates could have been due to chance.\n\n【3】The data suggest that women who smoke heavily may have a lower risk of endometrial cancer than nonsmokers. The present findings do not have direct public health importance since cigarettes, overall, have serious deleterious effects. However, if these results are confirmed, elucidation of the underlying mechanisms whereby smoking reduces the risk would be of interest and might be useful in the development of strategies for preventing endometrial cancer.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 18:01:42", "endTime": "2024/08/13 18:03:05", "cost": 83.119}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 02:03:05", "grab_time": "2024-08-13 02:01:42"}
{"id": 2234441, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "411f1862-c04c-461e-b32f-086dd7838899", "title": "The Risk of Subsequent Transmission of Hemophilus Influenzae Type B Disease among Children in Day Care", "text": "【0】The Risk of Subsequent Transmission of Hemophilus Influenzae Type B Disease among Children in Day Care\nAbstract\n--------\n\n【1】To determine the risk of _Hemophilus influenzae_ type b disease among children attending day-care facilities who were exposed to a primary case of invasive hemophilus disease, we conducted a two-year (August 1982 through July 1984) statewide prospective study involving active surveillance for _H. influenzae_ disease and a 60-day follow-up of the children's day-care contacts. We identified 185 patients with primary invasive hemophilus type b disease who were under six years of age and who attended a total of 195 day-care facilities (centers or private homes). There were 4102 children in attendance at these day-care facilities when the primary cases occurred; 4034 (98 percent) were followed for 60 days or more after the onset of illness in the patients with primary disease. A total of 2612 children were considered classroom contacts of the patients with primary disease, because they were cared for in the same home or the same room in a larger facility, but they were not siblings of the index patients. Of these classroom contacts, 370 from 0 to 23 months of age and 716 from 24 to 47 months of age did not receive rifampin chemoprophylaxis. We could confirm no subsequent _H. influenzae_ disease among contacts.\n\n【2】Our results suggest that the risk of subsequent hemophilus disease in contacts of patients in day-care facilities is significantly lower than that previously reported for siblings and day-care contacts.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:40:05", "endTime": "2024/08/14 14:40:28", "cost": 23.511}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 22:40:28", "grab_time": "2024-08-13 22:40:05"}
{"id": 2234440, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "a1c51671-9c23-490f-af88-f6dbbcfb2238", "title": "A Serious Adverse Event after Successful Gene Therapy for X-Linked Severe Combined Immunodeficiency", "text": "【0】A Serious Adverse Event after Successful Gene Therapy for X-Linked Severe Combined Immunodeficiency\nTo the Editor:\n--------------\n\n【1】We recently reported (April 18 issue)  the sustained correction of X-linked severe combined immunodeficiency disease by ex vivo, retrovirally mediated transfer of the γ _c_ gene into CD34+ cells in four of five patients with the disease. These results have since been confirmed in four additional patients with typical X-linked severe combined immunodeficiency. Of the first four successfully treated patients, three continue to do well up to 3.6 years after gene therapy, whereas a serious adverse event occurred in the fourth patient. At a routine checkup 30 months after gene therapy, lymphocytosis consisting of a monoclonal population of Vγ9/Vδ1, γ/δ T cells of mature phenotype was detected. One proviral integration site was found, located on the short arm of chromosome 11 within the _LMO-2_ locus, as determined with the use of linear-amplification mediated polymerase-chain-reaction analysis.  This proviral integration within the _LMO-2_ locus was associated with aberrant expression of the LMO-2 transcript in the monoclonal T-cell population. Aberrant expression of _LMO-2_ has been reported in acute lymphoblastic leukemia arising from T cells with α/β receptors, usually with the chromosomal translocation t(11;14).  Tests for replication-competent retrovirus were repeatedly negative in our patient's lymphocytes.\n\n【2】Between 30 and 34 months after gene therapy, the patient's lymphocyte count rose to 300,000 per cubic millimeter, and hepatosplenomegaly developed. Further investigations showed the presence of a t(6;13) translocation, which had not been detected 30 months after the therapy. Treatment with a chemotherapy regimen based on a high-risk protocol for acute lymphocytic leukemia (a protocol of the Dutch Childhood Leukemia Study Group) was initiated and has resulted, to date, in a dramatic reduction in the abnormal cells.\n\n【3】We interpret these findings as the consequence of the insertional mutagenesis event, a risk that is potentially associated with retrovirally mediated gene transfer and that has previously been considered to be very low in humans.  For this reason, a thorough reassessment of the potential risk of retrovirally mediated gene therapy is warranted. It is likely that additional factors may have contributed to the adverse event in our patient, including a varicella–zoster virus infection five months before clinically detectable lymphoproliferation, which may have stimulated immune reactivity of the γ/δ T-cell clone, or a selective growth advantage conferred by γc expression in the transduced cells. Genetic predisposing factors for childhood cancer are also possible, since medulloblastomas have developed in the proband's sister and a first-degree relative.\n\n【4】We have proposed to the French regulatory authorities a halt to our trial until further evaluation of the causes of this adverse event and a careful reassessment of the risks and benefits of continuing our study of gene therapy in patients with X-linked severe combined immunodeficiency can be completed. The latter will include a comparison with the outcome of the only available alternative therapy, haploidentical stem-cell transplantation.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 09:53:32", "endTime": "2024/08/14 10:03:24", "cost": 591.662}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 18:03:24", "grab_time": "2024-08-13 02:37:48"}
{"id": 2234439, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "05632da3-f383-4d7a-9025-94ef229b8b2e", "title": "Profile of Specific Antibodies to the SARS-Associated Coronavirus", "text": "【0】Profile of Specific Antibodies to the SARS-Associated Coronavirus\nTo the Editor:\n--------------\n\n【1】A novel coronavirus called the severe acute respiratory syndrome (SARS)–associated coronavirus (CoV) has been identified as the causal agent of SARS.  To understand the humoral immunity to this virus, we studied the profile of IgM and IgG antibody responses to SARS-CoV. IgM and IgG antibodies were analyzed by an indirect enzyme-linked immunosorbent assay in 20 patients with SARS from week 1 of their illness to week 12 and in 103 healthy contacts.\n\n【2】Figure 1. Changing Titers of IgM and IgG Antibodies to the SARS-Associated Coronavirus from the Onset of Illness through the Convalescent Phase.\n\n【3】IgM and IgG were measured at weeks 1, 2, 3, 4, 8, and 12; the mean IgG titer was  at week 2,  at week 3,  at week 4,  at week 8, and  at week 12. The mean IgM titer was  at week 2,  at week 3,  at week 4, and  at week 8. The cutoff value for a positive result was , and patients with negative results were considered to have a titer of 0 for the calculation of the mean titer.\n\n【4】All 20 patients tested negative for IgM and IgG at week 1 after the onset of symptoms. Of these patients, 16 tested positive for IgM and 17 tested positive for IgG at week 2 . All 20 patients were IgG-positive after week 3 and continued to have high levels of IgG up to three months after the onset of symptoms. The IgG titers were low at the beginning of week 2 (mean\\. with the cutoff for a positive result being , increased to an average of  at week 3, and peaked at  at week 12. The IgM titers peaked during the acute or early convalescent phase and then declined with IgM disappearing by the end of week 12. All 103 healthy contacts tested negative for IgM and IgG.\n\n【5】Our results suggest that 100 percent of patients had antibody responses to SARS-CoV during the convalescent phase. The SARS-specific IgG antibody persisted for a long time, but the SARS-specific IgM remained measurable for a much shorter period, suggesting that IgG antibody to SARS-CoV may represent the primary humoral immune response protecting patients against SARS. The profile of antibodies against SARS-CoV was consistent with common findings with regard to acute viral infectious diseases such as hepatitis A.  The profile of anti-SARS antibodies may be helpful in the diagnosis and in epidemiologic surveys. The presence of high titers of IgG antibody to SARS-CoV in the patients at the convalescent stage also suggests that a live attenuated or inactivated vaccine for active immunization and a concentrated human SARS-specific IgG antibody for passive immunization could be developed for the treatment of SARS.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-14 00:21:41", "grab_time": "2024-08-13 23:49:07"}
{"id": 2234438, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "dadd960f-f851-497a-b5b7-32c59c1776e0", "title": "Celecoxib for the Prevention of Sporadic Colorectal Adenomas", "text": "【0】Celecoxib for the Prevention of Sporadic Colorectal Adenomas\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Studies showing that drugs that inhibit cyclooxygenase-2 (COX-2) reduce the number of colorectal adenomas in animals and patients with familial adenomatous polyposis suggest that COX-2 inhibitors may also prevent sporadic colorectal neoplasia.\n\n【3】Methods\n-------\n\n【4】We randomly assigned patients who had adenomas removed before study entry to receive placebo (679 patients) or 200 mg (685 patients) or 400 mg (671 patients) of celecoxib twice daily. Randomization was stratified for the use of low-dose aspirin. Follow-up colonoscopies were performed at one and three years after randomization. The occurrence of newly detected colorectal adenomas was compared among the groups with the life-table extension of the Mantel–Haenszel test.\n\n【5】Results\n-------\n\n【6】Follow-up colonoscopies were completed at year 1 in 89.5 percent of randomized patients, and at year 3 in 75.7 percent. The estimated cumulative incidence of the detection of one or more adenomas by year 3 was 60.7 percent for patients receiving placebo, as compared with 43.2 percent for those receiving 200 mg of celecoxib twice a day (risk ratio, 0.67; 95 percent confidence interval, 0.59 to 0.77; P<0.001) and 37.5 percent for those receiving 400 mg of celecoxib twice a day (risk ratio, 0.55; 95 percent confidence interval, 0.48 to 0.64; P<0.001). Serious adverse events occurred in 18.8 percent of patients in the placebo group, as compared with 20.4 percent of those in the low-dose celecoxib group (risk ratio, 1.1; 95 percent confidence interval, 0.9 to 1.3; P=0.5) and 23.0 percent of those in the high-dose group (risk ratio, 1.2; 95 percent confidence interval, 1.0 to 1.5; P=0.06). As compared with placebo, celecoxib was associated with an increased risk of cardiovascular events (risk ratio for the low dose, 2.6; 95 percent confidence interval, 1.1 to 6.1; and risk ratio for the high dose, 3.4; 95 percent confidence interval, 1.5 to 7.9).\n\n【7】Conclusions\n-----------\n\n【8】These findings indicate that celecoxib is an effective agent for the prevention of colorectal adenomas but, because of potential cardiovascular events, cannot be routinely recommended for this indication. \n\n【9】Introduction\n------------\n\n【10】Colorectal cancer is a common malignant condition, responsible for approximately 150,000 new patients and approximately 55,000 deaths per year in the United States alone.  Despite these statistics, colorectal cancer is one of the most preventable cancers. Most colorectal cancers develop from precursor adenomas, which can be identified and removed during a screening colonoscopy. This procedure may lower the rates of death due to colorectal cancer by as much as 30 to 40 percent.  The aim of chemoprevention is to use pharmacologic agents to augment the benefits of colonoscopic polypectomy by inhibiting early stages of tumorigenesis, thereby preventing malignant transformation of precursor adenomas.\n\n【11】A remarkable concordance of data from more than 40 observational studies suggests that nonsteroidal antiinflammatory drugs (NSAIDs) reduce the incidence of colorectal adenomas, colorectal cancer, and deaths from colorectal cancer.  The effects of NSAIDs have been confirmed in randomized trials showing that aspirin has a modest chemopreventive effect on sporadic colorectal adenomas.  A leading hypothesis explaining this result is based on the presence of tumorigenic cyclooxygenase-2 (COX-2) within adenomas but not in normal intestinal tissue. COX-2 mediates the production of prostaglandin E <sub>2 </sub> (PGE <sub>2 </sub> ) in epithelial tissues, resulting in activation of signaling pathways that promote cell proliferation and inhibit cell death.  Selective COX-2 inhibitors, such as celecoxib, were originally developed for the treatment of pain and inflammation. In patients with familial adenomatous polyposis, celecoxib (Celebrex) also showed antitumor activity.  We conducted a randomized trial to determine whether celecoxib also prevents sporadic colorectal adenomas.\n\n【12】Methods\n-------\n\n【13】Study Design\n------------\n\n【14】The Adenoma Prevention with Celecoxib (APC) trial was a randomized, placebo-controlled trial to test whether celecoxib reduces the occurrence of endoscopically detected colorectal adenomas. We tested the safety and antitumor efficacy of 200 mg of celecoxib twice daily, 400 mg of celecoxib twice daily, and placebo. The randomization was stratified on the basis of the use or nonuse of low-dose aspirin (325 mg or less every other day or 162.5 mg or less every day) and clinical site. The trial involved 91 clinical sites (72 in the United States, 8 in Australia, 10 in Canada, and 1 in the United Kingdom). The study protocol was approved by the human-subjects committee at each site. All patients provided written informed consent before enrollment. An independent data and safety monitoring board reviewed safety data monthly and efficacy data twice a year. All study colonoscopies were performed by gastroenterologists associated with the APC trial. The APC trial was funded by the National Cancer Institute and by Pfizer, through a clinical trials agreement with the National Cancer Institute. The APC trial was a cooperative effort led by a study steering committee composed of the lead principal investigator, the National Cancer Institute project officer, and a representative from Pfizer. The steering committee of the APC trial directed all aspects of the study, including its design, data gathering, data analysis, and manuscript preparation. The authors vouch for the completeness and veracity of the data and data analysis.\n\n【15】Recruitment and Randomization\n-----------------------------\n\n【16】Staff at the clinical sites identified eligible study participants by reviewing colonoscopy records during a recruitment period from November 1999 to March 2002. Participants ranged from 31 to 88 years of age at enrollment and had recently undergone colonoscopic removal of colorectal adenomas and had a high risk of recurrent adenomas on the basis of a history of either multiple adenomas or removal of a single adenoma more than 5 mm in diameter. Within six months before enrollment, eligible patients underwent complete colonoscopy with removal of all polyps, one or more of which was a histologically confirmed adenoma.\n\n【17】Patients were willing to abstain from long-term use of NSAIDs (defined as more than 21 days of use per year) or COX-2 inhibitors, excluding low-dose aspirin, for the duration of the study. Patients not taking aspirin at baseline were required to abstain from taking it during the trial.\n\n【18】Exclusion criteria included a history of familial adenomatous polyposis, hereditary nonpolyposis colon cancer, inflammatory bowel disease, or large-bowel resection other than appendectomy. Other exclusion criteria included a history of a renal or hepatic disorder, a clinically significant bleeding disorder, or treatment for a gastrointestinal ulcer in the month before study entry. Patients were ineligible if they had used NSAIDs or aspirin at doses of more than 325 mg every other day at least three times a week during the two months before randomization or if they had received treatment with oral or intravenous corticosteroids for more than two weeks during the six months before randomization.\n\n【19】Figure 1. Eligibility, Enrollment, and Follow-up.\n\n【20】Patients who violated study entry criteria were those for whom the presence of an adenoma on colonoscopy at baseline could not be confirmed. Patients who withdrew consent for study participation included those who withdrew from the study for nonmedical reasons, those who failed to complete a post-randomization colonoscopy for nonmedical reasons, or those who did not adhere to the protocol for other reasons. Adherence to the use of study medication was calculated as the duration of use in days, divided by 1095. Because of rounding, not all percentages total 100.\n\n【21】A total of 2457 potential participants entered a 30-day placebo run-in period during which they were required to have at least 80 percent adherence to medication use, as measured by pill counts, in order to proceed to randomization . During this time, a central study pathologist reviewed baseline adenomas to confirm study eligibility; subsequently, 2035 patients were stratified according to clinical site and the use or nonuse of low-dose aspirin and were randomly assigned to treatment by means of an interactive voice-response system.\n\n【22】Study Treatment\n---------------\n\n【23】Study medication was distributed in capsules containing 100 mg of celecoxib for the 685 patients assigned to 200 mg twice daily, 200 mg of celecoxib for the 671 patients assigned to 400 mg twice daily, or placebo for the remaining 679 patients. Each capsule was identical in appearance. Patients were provided medication at six-month intervals and were instructed to take two capsules with food in the morning and in the evening each day. Open-label low-dose aspirin was supplied for patients already taking aspirin, and acetaminophen was supplied for the treatment of minor pain and febrile illnesses. In compliance with a recommendation by the data and safety monitoring board, which was based on an analysis revealing that patients taking celecoxib were at increased risk for cardiovascular events, study treatment was discontinued on December 17, 2004, before all patients had completed three years of treatment. \n\n【24】Assessment of End Points and Follow-up\n--------------------------------------\n\n【25】All primary efficacy analyses were performed on an intention-to-treat basis, with primary end points determined for all patients by means of follow-up colonoscopies, regardless of whether the patient adhered to the treatment regimen. The primary efficacy end point was the detection of an adenoma during a post-randomization colonoscopy. One secondary end point was the detection of advanced adenomas, defined as adenomas having any of the following characteristics: a diameter of at least 1 cm according to endoscopic measurement, villous or tubulovillous histologic appearance, high-grade dysplasia, intramucosal carcinoma, or invasive cancer. Other secondary end points included the number of adenomas, the size of the largest adenoma, and the adenoma burden (the sum of the diameter of all adenomas).\n\n【26】A complete physical examination, including clinical laboratory tests (i.e., complete blood count, serum chemical analysis, and urinalysis) and determination of vital signs, was performed at baseline and one and three years after randomization. Patients were contacted every two months to report use of concomitant medication and adverse events. During these discussions, patients were also counseled to avoid nonprotocol use of aspirin and NSAIDs.\n\n【27】A study investigator performed a complete colonoscopy with visualization of the cecum and endoscopic removal of all polyps one and three years after randomization. In cases of inadequate bowel preparation or failure to reach the cecum, year 1 colonoscopies were repeated at the discretion of the investigator, and year 3 colonoscopies were repeated within six weeks after the incomplete examination. A central study pathologist examined in a blinded fashion all polyps removed during these colonoscopies. If the central study pathologist and the institutional pathologist disagreed, polyps were examined by an independent, adjudicating pathologist who was unaware of the previous histologic diagnosis and whose opinion resolved the discrepancy. Adverse events reported by investigators were classified according to criteria from the Medical Dictionary for Regulatory Activities (MedDRA), version 8.1. Serious adverse events were reported to a study monitor within 24 hours after identification by personnel at the clinical site.\n\n【28】Statistical Analysis\n--------------------\n\n【29】The trial was designed with a statistical power of 96 percent to detect a 35 percent reduction in the relative risk from a placebo incidence of 40 percent  in the proportion of patients in whom adenomas were detected during a three-year follow-up period at the 0.025 (two-sided) level of significance for each celecoxib group as compared with the placebo group. Power calculations assumed a dropout rate of up to 40 percent and were adjusted for use or nonuse of aspirin. The primary end point of the detection of an adenoma and the secondary end point of the detection of advanced adenomas were compared for each treatment group with the use of the Mantel–Cox test, which is a life-table extension of the Mantel–Haenszel statistic with stratification for aspirin use or nonuse at baseline.  The Mantel–Cox procedure also provides a summary risk ratio, which is the weighted average of the relative risk over the two intervals and two aspirin strata.  Patients with no follow-up colonoscopy were excluded from both intervals. A patient with a colonoscopy at year 3 but with no colonoscopy at year 1 was included in the analysis through year 1, with the assumption that the patient had no adenoma by year 1, and was then included in the analysis through year 3 according to the findings of the colonoscopy at year 3. The analyses at year 3 excluded patients with an adenoma at the year 1 colonoscopy and patients with no adenoma at year 1 and no colonoscopy at year 3.\n\n【30】Investigator-reported adverse events were analyzed in total and according to prespecified categories to describe renal and hypertensive disorders, gastrointestinal ulceration and hemorrhage, and cardiovascular disorders. The analyses included all events occurring after the first dose of study medication. Patients with the end point of an adverse event were defined as those who had at least one of the adverse events during the course of the study, and the risk ratio was estimated on the basis of the relative risk (adjusted for aspirin use).\n\n【31】An additional analysis separately examined serious cardiovascular events, since these events were considered to be of the greatest clinical importance. These serious adverse events were then adjudicated and analyzed by an independent cardiovascular safety team, as reported previously, and updated for the current report with the use of final study data.  The outcome of a serious adverse event was based on a time-to-event analysis, and the Cox proportional hazards model was used to assess the risk ratio. There were no formal interim analyses of efficacy. All reported P values for safety analyses are two-sided and not adjusted for multiple testing. All analyses were performed with SAS software, version 8 or higher.\n\n【32】Results\n-------\n\n【33】Table 1. Baseline Characteristics of the Patients.\n\n【34】Baseline variables were similar across all treatment groups . Risk factors for adverse events, such as a history of cardiovascular disease, smoking, or diabetes, were also balanced among treatment groups. Colonoscopic end points were assessed in 1822 of 2035 patients who had undergone randomization (89.5 percent); 1541 patients (75.7 percent) completed the examination at year 3 . Before assessment of the end points, 10.5 percent of the patients withdrew from the study. This includes 1.2 percent of patients who had undergone randomization but were lost to follow-up before a study colonoscopy was performed. Patients who did not complete the study were relatively evenly distributed among the treatment groups .\n\n【35】Patients who did not adhere to the use of the study drug for any reason remained in the study until the scheduled completion time for the determination of the end points, in keeping with the intention-to-treat principle. Approximately two thirds of participants adhered to the treatment regimen at least 80 percent of the time, with no significant difference among the treatment groups . Because of an increased incidence of cardiovascular events in the two groups treated with celecoxib, use of the study medication by patients who had undergone randomization was discontinued on December 17, 2004, in compliance with the recommendations of the data and safety monitoring board. At that time, 1762 patients (86.6 percent) had completed three years of treatment. Of the 273 patients who still had one to three months remaining of planned use of the study drug, 199 (72.9 percent) underwent study colonoscopy at year 3, and these data were used in the primary efficacy analyses.\n\n【36】Table 2. Risk of Adenomas.\n\n【37】The primary efficacy analysis considered adenomas detected at any time after randomization . A small percentage of polyps removed (1.4 percent) were not retrieved and could not be examined. In the placebo group, 354 patients had at least one adenoma, as did 252 patients in the group receiving 200 mg of celecoxib twice daily, and 213 patients in the group receiving 400 mg of celecoxib twice daily. The estimated cumulative incidence of the detection of one or more adenomas was 60.7 percent in the placebo group, 43.2 percent in the group receiving 200 mg of celecoxib twice daily, and 37.5 percent in the group receiving 400 mg of celecoxib twice daily. This corresponds to a risk ratio of 0.67 (95 percent confidence interval, 0.59 to 0.77) in the 200-mg group and 0.55 (95 percent confidence interval, 0.48 to 0.64) in the 400-mg group.\n\n【38】Celecoxib therapy was associated with a reduced number of advanced adenomas; 99 patients in the placebo group had at least one advanced adenoma during the three-year period, as compared with 44 patients in the group receiving 200 mg of celecoxib twice daily and 35 patients in the group receiving 400 mg of celecoxib twice daily. The estimated cumulative incidence of advanced adenomas was 17.2 percent for patients receiving placebo, 7.8 percent for those treated with 200 mg of celecoxib twice daily, and 6.3 percent for those treated with 400 mg of celecoxib twice daily, corresponding to a risk ratio of 0.43 (95 percent confidence interval, 0.31 to 0.61) in the 200-mg group and 0.34 (95 percent confidence interval, 0.24 to 0.50) in the 400-mg group. Subgroup analyses according to the use or nonuse of low-dose aspirin yielded similar results .\n\n【39】Figure 2. Summary of Efficacy Results during the Three-Year Post-Randomization Period.\n\n【40】For the 2035 patients who underwent randomization, Panel A represents the estimated cumulative incidence of adenomas or advanced adenomas detected during the three years after randomization. The highest point of each bar indicates the proportion of patients with any adenoma detected, and the lower section of each bar indicates the proportion with advanced adenomas. For all adenomas, P<0.001 for the comparison with placebo for both drug doses. Advanced lesions were identified in 17.2 percent of patients taking placebo, 7.8 percent of patients taking 200 mg of celecoxib twice daily, and 6.3 percent of patients taking 400 mg of celecoxib twice daily. Panel B shows the mean (±SE) treatment-associated reduction in adenoma burden (defined as the sum of the diameter of all adenomas) among all 819 patients in whom recurrent adenomas were detected during the three years after randomization. \n\n【41】During the three-year study, the adenoma burden was smaller among patients given celecoxib than among those given placebo. Patients receiving placebo had a mean (±SE) adenoma burden of 1.3±0.1 cm, as compared with 1.0±0.1 cm among patients receiving 200 mg of celecoxib twice daily (P=0.004) and 0.9±0.1 cm among those receiving 400 mg of celecoxib twice daily (P=0.002) .\n\n【42】Clinical variables measured during physical examinations during the study showed increased blood pressure among patients in the celecoxib groups, with a change from baseline to year 3 in mean blood pressure of −1.6/−3.0 mm Hg in the placebo group, +1.0/−1.2 mm Hg in patients assigned to 200 mg of celecoxib twice daily, and +3.6/−1.0 mm Hg in patients assigned to 400 mg of celecoxib twice daily (P<0.001 and P=0.01 for the comparison of the combined celecoxib groups with the placebo group for systolic and diastolic blood pressure, respectively). No drug-associated change was observed in serum levels of creatinine, alanine aminotransferase, or hemoglobin.\n\n【43】Table 3. Incidence of Adverse Events after Randomization.\n\n【44】At least one adverse event was reported in 617 patients in the placebo group (91.3 percent), 645 of those receiving 200 mg of celecoxib twice daily (94.4 percent), and 635 of those receiving 400 mg of celecoxib twice daily (94.9 percent) . At least one serious adverse event was reported in 18.8 percent of the patients in the placebo group, as compared with 20.4 percent of those receiving 200 mg of celecoxib twice daily (risk ratio, 1.1; 95 percent confidence interval, 0.9 to 1.3; P=0.5), and 23.0 percent of those receiving 400 mg of celecoxib twice daily (risk ratio, 1.2; 95 percent confidence interval, 1.0 to 1.5; P=0.06) . One patient in the placebo group had grade 3 bleeding after the polypectomy — a serious complication resulting from a study colonoscopy.\n\n【45】Nonadjudicated investigator-reported renal and hypertensive disorders, gastrointestinal ulceration and hemorrhage, and cardiovascular disorders were analyzed separately. No consistent dose-related trend toward an increased incidence of renal and hypertensive disorders or gastrointestinal ulceration and hemorrhage was observed, although aspirin users assigned to receive celecoxib showed a trend toward increased gastrointestinal ulceration and hemorrhage.\n\n【46】Cardiovascular adverse events among participants in the APC trial have been reported previously, according to a prespecified analysis of adjudicated serious adverse events,  and were updated with the final study data . This analysis indicated an increased risk of serious cardiovascular complications (i.e., death from cardiovascular causes, nonfatal myocardial infarction, stroke, or heart failure) among those receiving celecoxib, with risk ratios of 2.6 (95 percent confidence interval, 1.1 to 6.1) and 3.4 (95 percent confidence interval, 1.5 to 7.9) for the low-dose and high-dose cohorts, respectively. The absolute magnitude of risk was greatest for patients with a history of cardiovascular events at baseline, although no relation between cardiovascular events at baseline and during the study was observed in patients receiving celecoxib. Patients who entered the study with a history of myocardial infarction, stroke, congestive heart failure, or angina had a 3.0 percent incidence of serious cardiovascular events if they took placebo and an 8.8 percent incidence if they took celecoxib at either dose (risk ratio for the comparison with placebo, 3.0; 95 percent confidence interval, 0.9 to 10.4). Among patients without these risk factors at baseline, 0.7 percent of those in the placebo group had a serious cardiovascular event, as compared with 2.1 percent of those in either celecoxib group (risk ratio, 3.0; 95 percent confidence interval, 1.0 to 8.7). The adjudicated analysis of data pertaining to serious adverse events agreed substantially with nonadjudicated investigator reports of serious adverse events related to cardiovascular disorders.\n\n【47】Discussion\n----------\n\n【48】Previous attempts to modify the risk of sporadic adenomas through dietary interventions have been largely unsuccessful,  although calcium and vitamin D supplementation demonstrated a slight benefit.  Randomized trials of aspirin showed a more substantial chemopreventive effect, with reductions of approximately 20 percent among patients in whom recurrent adenomas developed.  These findings are tempered somewhat by the observation in one study that low-dose, but not high-dose, aspirin had an antitumor effect.  We studied a cohort at high risk for colorectal tumors, as evidenced by a 60.7 percent incidence of newly detected adenomas in the placebo group during the three-year period and a 17.2 percent incidence of advanced lesions. Treatment with a 400-mg dose of celecoxib twice daily for three years reduced the incidence of recurrent adenomas of any type by 45 percent and of high-risk lesions by 66 percent. The effect was confirmed by a similarly designed independent study, the PreSAP Trial, described by Arber et al. elsewhere in this issue of the _Journal_ .  Patients in the APC trial who took aspirin in addition to celecoxib did not show greater chemopreventive benefit than those who took celecoxib alone.\n\n【49】We did not directly assess the effect of celecoxib on colorectal cancer. In the context of a program of surveillance colonoscopy to detect and remove premalignant adenomas, the benefit of celecoxib in the prevention of colorectal cancer is still unknown, and further research is necessary to develop a successful chemopreventive regimen. To optimize the benefit, studies should focus on persons who are at the highest risk for colorectal cancer, since celecoxib was particularly effective in preventing advanced lesions. Colorectal cancer takes many years to develop, and celecoxib causes regression, in addition to suppression, of established adenomas.  Thus, additional investigations should address the value of various dosing schedules, considering the dose-related effects on the prevention of adenomas and on adverse events.\n\n【50】Selective COX-2 inhibitors were developed as a safer alternative to nonselective NSAIDs, with respect to gastrointestinal bleeding. These agents preferentially inhibit COX-2, an inducible enzyme mediating inflammation and tumorigenesis, and not COX-1, the constitutively expressed enzyme responsible for protective mechanisms in the gastric mucosa and renal vasculature. Selective COX-2 inhibitors have fewer effects on gastric mucosa or platelet function than do the nonselective NSAIDs and, as a result, may be associated with fewer ulcers and hemorrhagic complications.  In general, our results are consistent with these assertions, although the combination of aspirin and celecoxib may be associated with more gastrointestinal ulceration and hemorrhagic events than is placebo.\n\n【51】Previously, we reported the results of a cardiovascular analysis conducted of the APC trial while the treatment portion of the study was still under way.  The data were analyzed on an intention-to-treat basis and included adjudicated serious cardiovascular events, and the analysis revealed an increased risk among patients taking celecoxib of a combined end point including myocardial infarction, stroke, congestive heart failure, or death due to cardiovascular disease. The updated adjudicated analysis reported here, which includes one additional event in the low-dose celecoxib group, also shows a dose-related increased cardiovascular risk associated with celecoxib. Not surprisingly, subgroup analyses suggested that the absolute risk of cardiovascular events was greatest among patients with a history of cardiovascular events at baseline, but the risk ratio did not differ significantly among those with and those without cardiovascular events at baseline. In addition, blood pressure increased with the use of celecoxib, suggesting that changes in vascular tone may predispose patients to cardiovascular events.\n\n【52】In summary, the use of celecoxib by patients at high risk for colorectal neoplasia significantly reduced the proportion of patients with adenomas detected during a three-year study. This trial documented prevention of premalignant adenomas with celecoxib but was not designed to assess effectiveness of the drug for the prevention of colorectal cancer, and no claims about its use in this regard can be made from our data. Safety analyses confirmed previous reports of an increased incidence of serious cardiovascular events. If future study of celecoxib for the chemoprevention of colorectal cancer is pursued, the potential addition of this drug to an optimal endoscopic surveillance program must be weighed against the known risk of serious cardiovascular events.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-14 00:14:18", "grab_time": "2024-08-13 23:29:55"}
{"id": 2234437, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "fbd50b83-b7f9-4133-a1be-6eb007d793b2", "title": "Sciatica", "text": "【0】Sciatica\nPain that extends from the buttock down the course of the sciatic nerve is common. Nearly 85% of cases are associated with a disk disorder. The causes, assessment, and management of sciatica are discussed.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:50:28", "endTime": "2024/08/14 14:50:34", "cost": 6.141}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 22:50:34", "grab_time": "2024-08-13 22:49:45"}
{"id": 2234436, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "66aad4c3-0184-475c-8b28-73ff00e09b8b", "title": "Medical Progress: Polycystic Ovary Syndrome", "text": "【0】Medical Progress: Polycystic Ovary Syndrome\nThe polycystic ovary syndrome is one of the most common hormonal disorders affecting women. It has multiple components — reproductive, metabolic, and cardiovascular — with health implications for the patient's entire life span. This review addresses current concepts regarding the diagnosis, cause, and treatment of the condition.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:49:32", "endTime": "2024/08/14 14:49:39", "cost": 6.715}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 22:49:38", "grab_time": "2024-08-13 22:49:31"}
{"id": 2234435, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "f493aa3e-7479-47ae-a604-2b1e8171d0d0", "title": "Efficacy of Convalescent Plasma in Relation to Dose of Ebola Virus Antibodies", "text": "【0】Efficacy of Convalescent Plasma in Relation to Dose of Ebola Virus Antibodies\nTo the Editor:\n--------------\n\n【1】We previously reported the results of a nonrandomized, controlled trial that compared survival among patients with Ebola virus (EBOV) disease who were treated with convalescent plasma with survival among historical controls. Although no safety concerns were identified, efficacy was not shown.  Notably, the levels of total anti-EBOV IgG and neutralizing antibodies in the infused plasma were unknown at the time of administration.  We now report on the association between the amount of total anti-EBOV IgG and neutralizing antibodies received and patient survival and on the changes in the amount of EBOV in their blood 24 hours after transfusion, expressed as the change in the cycle-threshold value in the polymerase-chain-reaction (PCR) analysis. The cycle-threshold value is the number of cycles required for the fluorescence signal to cross the threshold for a positive result on the EBOV PCR assay; lower values indicate higher viral loads.\n\n【2】Figure 1. Titers of Total IgG and Neutralizing Antibodies against the Ebola Virus (EBOV) in Plasma from Convalescent Donors, Distribution of Total-Antibody Doses Given to Patients, Odds Ratios for Death between Days 3 and 16, and Changes in Cycle-Threshold Value after Transfusion.\n\n【3】Panel A shows the distribution of titers of total anti-EBOV IgG and neutralizing antibodies against EBOV in 85 donations from 58 convalescent donors whose plasma was used in the trial. ND denotes not detected. Panel B shows the distribution of the total dose of antibodies administered to patients with EBOV disease. To calculate the total dose that a patient received, the volume of the plasma unit was multiplied by the corresponding optical-density value from the enzyme-linked immunosorbent assay (for total anti-EBOV IgG) or antibody titer (for neutralizing antibodies); the sum of this measure for all plasma units that a patient received represented the estimated total-antibody dose. The total dose of neutralizing antibodies has been divided by a factor of 10. Infused plasma in which no antibodies were detected were allocated a zero dose in the estimation of the total dose. The dashed lines show the cutoff for the lowest-dose group of estimated antibody dose, and the corresponding solid lines show the cutoff for the middle-dose group (Spearman’s rho=0.425; P<0.001). Panel C shows the adjusted odds ratio for death between days 3 and 16 after diagnosis among 71 patients 16 years of age or older. The analysis used the lowest-dose group as the reference group, with adjustment for age and pretransfusion cycle-threshold value. I bars indicate 95% confidence intervals. Patients who died before day 3 after the diagnosis of EBOV disease were excluded.  In a test for association assuming a linear trend, after adjustment for age and cycle threshold, P=0.21 for IgG and P=0.32 for neutralizing antibodies. Panel D shows the change in EBOV cycle-threshold values from before to after transfusion among 83 patients 16 years of age or older. The analysis used the lowest-dose group as the reference group, with adjustment for age and pretransfusion cycle-threshold value. The cycle-threshold value is the number of cycles required for the fluorescence signal to cross the threshold for a positive result on the EBOV polymerase-chain-reaction assay; lower values indicate higher viral loads. I bars indicate 95% confidence intervals. More patients were included in this analysis than in the mortality analysis . In tests for heterogeneity between the dose groups (with adjustment for age and pretransfusion cycle-threshold value), P=0.02 for IgG and P=0.82 for neutralizing antibodies. In a test for a linear trend (with adjustment for age and pretransfusion cycle-threshold values), P=0.06 for IgG and P=0.69 for neutralizing antibodies.\n\n【4】The level of antibodies in the 85 donations was determined by means of an enzyme-linked immunosorbent assay (ELISA) and a plaque-neutralization assay . ELISA titers for 94% of the donations were at least . In the 50% plaque-neutralizing activity assay, most donations (75%) had a titer of  or , and only 4 (5%) had a titer of  . For each patient, a total-antibody dose was calculated by multiplying the volume of convalescent plasma infused by the EBOV antibody titer in the donation. The analysis was restricted to adults, because the dosing of convalescent plasma was done differently in children.\n\n【5】Patients were categorized into one of three equally sized groups on the basis of the estimated total-antibody dose . By chance, the pretransfusion cycle-threshold values were lowest in the highest-dose group for IgG and in the middle-dose group for neutralizing antibodies, and there was significant imbalance in the neutralizing-antibodies dose groups . Adjusting for age and pretransfusion cycle-threshold value, we observed lower mortality with higher IgG doses and higher mortality with higher doses of neutralizing antibodies, but neither of these associations was significant . The change in cycle-threshold values from before to after transfusion differed significantly according to IgG dose group (P=0.02). However, there was little difference between the two higher-dose groups  and only weak evidence of a linear trend overall (P=0.06). No association was apparent with the dose of neutralizing antibodies.\n\n【6】In conclusion, most patients received plasma with anti-EBOV IgG antibodies, but levels of neutralizing antibodies were low in many donations. The dose of IgG antibodies showed an association with larger increases in cycle-threshold values after transfusion but no significant association with mortality. Neither outcome showed an association with the estimated doses of neutralizing antibodies received. Further studies are needed to assess the effectiveness of an antibody dose higher than the doses used in this study, the antibody measure that best correlates with virologic and clinical outcomes, and the potential mechanism and clinical effect of viral clearance by anti-EBOV IgG antibodies.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 18:05:22", "endTime": "2024/08/13 18:05:27", "cost": 5.178}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 02:05:28", "grab_time": "2024-08-13 02:05:22"}
{"id": 2234434, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "c214a436-81a9-4b17-a57a-8426dd84e911", "title": "Nesiritide — Not Verified", "text": "【0】Nesiritide — Not Verified\nArticle\n-------\n\n【1】### Audio Interview\n\n【2】 Interview with Eric J. Topol, who calls into question the use of nesiritide for heart failure. \n\n【3】How can a drug that is associated with higher rates of both renal dysfunction and death than placebo — and that costs 50 times as much as standard therapies and for which there are no meaningful data on relevant clinical end points — be given to more than 600,000 patients and be promoted throughout the United States for serial outpatient use, an indication not listed on the label?  The answer to this question can be discerned, at least in part, from a review of the clinical development and marketing of nesiritide: recombinant human brain natriuretic peptide.\n\n【4】On May, 17, 2005, the _New York Times_ reported that tens of thousands of patients around the country are receiving nesiritide treatment once or more per week, over a period of several months, for what is described as an outpatient “tune-up.” This application of nesiritide — which costs approximately $500 per dose, as compared with less than $10 for nitroglycerin or nitroprusside — is the subject of an aggressive marketing campaign by the manufacturer, Scios, which is encouraging physicians to start their own “infusion centers” for whose services they can bill Medicare as if they were providing chemotherapy. But when nesiritide was approved by the Food and Drug Administration (FDA) in 2001, it was designated for the treatment of acute, decompensated congestive heart failure. Moreover, it had apparent safety problems — and no proven clinical advantage over existing treatments in terms of the key end points of improved survival and prevention of subsequent hospitalizations.\n\n【5】In a 2000 report, Colucci and colleagues concluded that “nesiritide would be a valuable addition to the initial treatment of patients admitted to the hospital for decompensated congestive heart failure.”  But their placebo-controlled, dose-ranging trial was focused on short-term monitoring of the pulmonary-capillary wedge pressure. Follow-up data on these subjects, which were not part of the study design as reported in that article, suggested that nesiritide may have had an adverse effect on 30-day mortality, which was 7.1 percent in the nesiritide group, as compared with 4.8 percent in the placebo group (P=0.62).  Over this longer period of follow-up, the incidence of substantial deterioration of renal function was more than three times as high among patients treated with nesiritide as among those given placebo (P=0.04). \n\n【6】The data from that trial were reviewed by an FDA advisory panel in January 1999. Despite the panel's recommendation that the drug be approved for the reduction of pulmonary-capillary wedge pressure, the FDA decided that more data were required. A larger trial, Vasodilatation in the Management of Acute Congestive Heart Failure (VMAC), was conducted in 498 hospitalized patients who had dyspnea at rest.  Nesiritide was compared with intravenous nitroglycerin or placebo. Since there were statistically significant improvements in both the reduction of pulmonary-capillary wedge pressure (a difference of 4 mm Hg) and the self-reported dyspnea rating with nesiritide as compared with placebo, nesiritide was considered to have met the efficacy criteria. The study did not demonstrate any benefit of nesiritide over nitroglycerin in terms of death or the need for repeated hospitalization within 30 days. At a subsequent meeting, in May 2001, the majority of the advisory panel recommended granting approval for nesiritide, and in August 2001, the FDA formally approved this drug for commercial use.\n\n【7】The VMAC trial raised a number of concerns about nesiritide. Only 30 percent of the patients received furosemide or intravenous diuretics before enrollment, although use of these agents is a standard approach to acute decompensated heart failure. The dose of nitroglycerin was not titrated aggressively, and because of the monitoring of the pulmonary-capillary wedge pressure, the “double-blind” assessment was compromised. The length of stay in the hospital was greater among patients who received nesiritide than among those given nitroglycerin (10.0 vs. 8.1 days, P=0.008).  An elevation of more than 0.5 mg per deciliter (44.2 μmol per liter) in the serum creatinine level occurred in 27 percent of the patients in the nesiritide group, as compared with 21 percent of the controls (P=0.11).  There was no increase in urine output with nesiritide, and subsequent studies have shown that this drug does not have a natriuretic or diuretic effect in patients with decompensated heart failure. Furthermore, the rate of death at 30 days was 8.6 percent in the nesiritide group, as compared with 5.5 percent among the controls (relative risk, 1.56; 95 percent confidence interval, 0.75 to 3.24; P=0.20).  Indeed, the FDA approval went forward despite an internal reviewer's critical point that VMAC did not rule out a 50 percent increase in the risk of death. A meta-analysis also suggests that the use of nesiritide is associated with an increased frequency of abnormal renal function. \n\n【8】 Mortality at 30 Days among Patients Treated with Nesiritide as Compared with Controls in Randomized Trials.\n\n【9】The relative risk of death with nesiritide as compared with placebo was 1.81 (95 percent confidence interval, 1.02 to 3.27; P=0.04) in the analysis by Sackner-Bernstein et al.   and 1.26 (95 percent confidence interval, 0.80 to 2.00; P=0.33) in the analysis by Scios .\n\n【10】There have been two different analyses of the effects of nesiritide treatment on mortality, the most important end point in a randomized trial of an intervention for heart failure . In one of them, Sackner-Bernstein et al. pooled data from the three trials involving patients whose baseline treatment regimen was not required to include inotropes and for which 30-day mortality data were available. According to this analysis, there was an 81 percent increase in the death rate with nesiritide as compared with placebo.  In contrast, Scios analyzed seven trials that had 30-day mortality data, including trials involving open-label and outpatient use, but did not take into consideration the baseline treatment regimen. The company reported a 24 percent increase in mortality (P=0.33), and this figure was incorporated into a revised package insert in April 2005.\n\n【11】Even in the face of such findings, however, the manufacturer has been actively promoting the use of nesiritide. It has set up a toll-free telephone hotline for “Natrecor Reimbursement Support” and has published a 46-page “Natrecor Reimbursement and Billing Guide.” The guide provides physicians with specific Medicare code numbers to be used in billing for a professional fee for nesiritide infusion ($172 for the first hour, $39 for each additional hour, and $408 for eight hours of observation), as one would for chemotherapy. The company justifies this billing practice by noting that the codes for chemotherapy administration include “substances such as monoclonal antibody agents and other biologic response modifiers.”\n\n【12】Notwithstanding the fact that only one small, open-label feasibility study has been conducted, outpatient nesiritide use has become widespread, fulfilling sales objectives for the manufacturer and bringing in revenue for physicians. The overall sales figure for nesiritide is projected to be $700 million for 2005, nearly double last year's tally; it represents payment for more than 1.4 million treatments. Given that nearly 10 times as much drug is used for serial administration in outpatients as for the one-time use in hospitalized patients, much of this growth clearly stems from the off-label “tune-up” application.\n\n【13】The nesiritide story reflects some recurring themes: in other recent cases, too, major safety problems have been uncovered after a drug has been approved. Nesiritide was approved on the basis of a single trial in which surrogate end points were assessed three hours after administration. In cardiovascular medicine, we learned long ago that therapies directed at surrogate end points — such as the suppression of premature ventricular contractions or, for inotropic agents, an improved ejection fraction — can be associated with excess deaths. With the low threshold set for regulatory approval, the FDA did not demand appropriate warnings on the label regarding an increased risk of death or worsened renal function and did not require the performance of trials that would have provided definitive verification of the safety and efficacy of nesiritide.\n\n【14】We practice medicine in an era in which there is one pharmaceutical-company representative for every five physicians and in which companies will stretch the limits in their marketing of drugs. The boundary lines that previously separated industry from the FDA and academia have unfortunately become blurred. Interestingly, the European Agency for the Evaluation of Medicinal Products, the counterpart of the FDA, has still not approved nesiritide and awaits the results of a trial involving 1900 patients before it will even consider doing so. \n\n【15】In my view, nesiritide has not yet met the minimal criteria for safety and efficacy. Until a trial definitively proves that this drug reduces the risk of death or repeated hospitalization for heart failure, there will be questions about the appropriateness of the drug's use or even commercial availability. We need a tune-up of our procedures to eliminate indiscriminate use of drugs, such as nesiritide, when there is not proper evidence of their safety.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:32:06", "endTime": "2024/08/14 15:32:39", "cost": 32.633}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 23:32:39", "grab_time": "2024-08-13 23:32:06"}
{"id": 2234433, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "c58098b6-a6e3-41df-b8d0-c4c6d26ff29b", "title": "Concomitant Tricuspid Repair in Patients with Degenerative Mitral Regurgitation", "text": "【0】Concomitant Tricuspid Repair in Patients with Degenerative Mitral Regurgitation\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Tricuspid regurgitation is common in patients with severe degenerative mitral regurgitation. However, the evidence base is insufficient to inform a decision about whether to perform tricuspid-valve repair during mitral-valve surgery in patients who have moderate tricuspid regurgitation or less-than-moderate regurgitation with annular dilatation.\n\n【3】Methods\n-------\n\n【4】Download a PDF of the Research Summary .\n\n【5】We randomly assigned 401 patients who were undergoing mitral-valve surgery for degenerative mitral regurgitation to receive a procedure with or without tricuspid annuloplasty (TA). The primary 2-year end point was a composite of reoperation for tricuspid regurgitation, progression of tricuspid regurgitation by two grades from baseline or the presence of severe tricuspid regurgitation, or death.\n\n【6】Results\n-------\n\n【7】Patients who underwent mitral-valve surgery plus TA had fewer primary-end-point events than those who underwent mitral-valve surgery alone (3.9% vs. 10.2%) (relative risk, 0.37; 95% confidence interval \\[CI\\], 0.16 to 0.86; P=0.02). Two-year mortality was 3.2% in the surgery-plus-TA group and 4.5% in the surgery-alone group (relative risk, 0.69; 95% CI, 0.25 to 1.88). The 2-year prevalence of progression of tricuspid regurgitation was lower in the surgery-plus-TA group than in the surgery-alone group (0.6% vs. 6.1%; relative risk, 0.09; 95% CI, 0.01 to 0.69). The frequencies of major adverse cardiac and cerebrovascular events, functional status, and quality of life were similar in the two groups at 2 years, although the incidence of permanent pacemaker implantation was higher in the surgery-plus-TA group than in the surgery-alone group (14.1% vs. 2.5%; rate ratio, 5.75; 95% CI, 2.27 to 14.60).\n\n【8】Conclusions\n-----------\n\n【9】Among patients undergoing mitral-valve surgery, those who also received TA had a lower incidence of a primary-end-point event than those who underwent mitral-valve surgery alone at 2 years, a reduction that was driven by less frequent progression to severe tricuspid regurgitation. Tricuspid repair resulted in more frequent permanent pacemaker implantation. Whether reduced progression of tricuspid regurgitation results in long-term clinical benefit can be determined only with longer follow-up. \n\n【10】Introduction\n------------\n\n【11】 QUICK TAKE  \nTricuspid Repair in Patients with Degenerative Mitral Regurgitation  \n\n【12】Tricuspid regurgitation is common among patients undergoing mitral-valve surgery for degenerative mitral regurgitation.  The recommendations for management of tricuspid regurgitation during mitral-valve surgery are based largely on observational data.  There is broad agreement that severe tricuspid regurgitation may not predictably improve after left-sided cardiac surgery and should be addressed during the index procedure. Late reoperation for severe tricuspid regurgitation in patients with right heart failure is associated with high perioperative mortality. \n\n【13】However, the operative management of lesser degrees of tricuspid regurgitation is widely debated. Surgical and medical treatments of left-sided cardiac disease often result in a progressive reduction in the degree of tricuspid regurgitation, with favorable right ventricular reverse remodeling, a decrease in pulmonary-artery pressures, or both.  Mild or moderate tricuspid regurgitation that is not corrected at the time of left-sided cardiac surgery may progress in approximately 25% of patients and result in poorer late survival and functional outcomes. Risk factors for the progression of tricuspid regurgitation include annular dilation measuring 40 mm or more (or 21 mm per square meter) in diameter on preoperative transthoracic echocardiography, the magnitude of right ventricular dysfunction, and the presence of leaflet tethering, pulmonary hypertension, atrial fibrillation, or transvalvular pacing or defibrillator leads. \n\n【14】Several single-center observational studies and a small randomized trial with an unblinded end-point assessment have suggested that concomitant tricuspid-valve repair in patients with moderate tricuspid regurgitation or less-than-moderate (i.e., none, trace, or mild) regurgitation with annular dilatation is associated with less disease progression and better outcomes than conservative management.  Enthusiasm for uniform adoption of tricuspid-valve repair under these circumstances is tempered by concern regarding the excess risk of postoperative conduction disturbances resulting in permanent pacemaker implantation, an increase in cardiopulmonary bypass times, the small chance that tricuspid-valve replacement (rather than annuloplasty repair) may be needed, and the reality that tricuspid regurgitation does not progress in all patients. \n\n【15】Accordingly, there are wide practice variations in the management of less-than-severe tricuspid regurgitation at the time of left-sided cardiac surgery. The frequency of tricuspid-valve repair at the time of mitral-valve surgery ranges from 5 to 75%.  To inform decision making, the Cardiothoracic Surgical Trials Network (CTSN) conducted a multicenter, randomized trial to assess the benefits and risks of tricuspid-valve repair at the time of mitral-valve surgery in patients with moderate or less-than-moderate tricuspid regurgitation who were undergoing surgery for degenerative mitral regurgitation.\n\n【16】Methods\n-------\n\n【17】Trial Design and Oversight\n--------------------------\n\n【18】The trial was conducted at 39 clinical centers in the United States, Canada, and Germany. The progress of the trial was overseen by a coordinating center, an echocardiographic core laboratory, an independent event-adjudication committee, and a data and safety monitoring board appointed by the National Institutes of Health. All the patients provided written informed consent.\n\n【19】All the investigators were responsible for the trial design and data collection; coordinating center investigators vouch for the completeness and accuracy of the data and for the fidelity of the trial to the protocol.\n\n【20】Randomization and Treatment\n---------------------------\n\n【21】Among patients who were scheduled for mitral-valve surgery, we randomly assigned those with either moderate tricuspid regurgitation or less-than-moderate regurgitation with annular dilatation in a  ratio to undergo the surgery with or without tricuspid annuloplasty (TA). Randomization was stratified according to the severity of tricuspid regurgitation and the clinical center. The trial was designed to enroll 400 patients; 1 additional patient underwent randomization before the completion of enrollment. The investigators were unaware of the overall outcome data. End points were assessed at 30 days and at 6, 12, 18, and 24 months; after 24 months, survival was to be evaluated annually up to 60 months.\n\n【22】Patients and Interventions\n--------------------------\n\n【23】The target population included adults undergoing mitral-valve surgery for degenerative mitral regurgitation with either moderate tricuspid regurgitation or less-than-moderate regurgitation with annular dilatation of 40 mm or more (or 21 mm per square meter).  The degree of tricuspid regurgitation was assessed by means of transthoracic echocardiography and verified by the central echocardiographic core laboratory. The selection of the most effective medical therapy was at the discretion of the heart team at each site. Exclusion criteria included evidence of secondary mitral regurgitation, primary tricuspid-valve disease, and suboptimal volume management.\n\n【24】All the patients underwent mitral-valve surgery with the use of a sternotomy or right minithoracotomy. Decisions regarding the use of surgical techniques — including suture placement and the type of prosthetic annuloplasty ring or valve — were at the surgeon’s discretion. However, the protocol specified the use of an approved rigid, incomplete, nonplanar, and undersized (26, 28, or 30 mm) TA ring. \n\n【25】End Points\n----------\n\n【26】The primary end point at 2 years was a composite of reoperation for tricuspid regurgitation, progression of tricuspid regurgitation from baseline by two grades or the presence of severe tricuspid regurgitation, or death, with imputation of missing data. Secondary end points were death, major adverse cardiac and cerebrovascular events (MACCE; a composite of death, stroke, or serious heart-failure events), permanent pacemaker implantation, length of hospital stay, residual tricuspid regurgitation, echocardiographic indexes of right ventricular size and function, New York Heart Association (NYHA) classification, diuretic use, results on a 6-minute walk test, results on a gait-speed test for frailty, quality of life (as measured on the 12-Item Short Form Survey \\[SF-12\\], the Kansas City Cardiomyopathy Questionnaire \\[KCCQ\\], and EuroQol \\[EQ-5D\\]), serious adverse events, rehospitalizations, and cost-effectiveness. The cost-effectiveness analysis and additional echocardiographic studies are ongoing.\n\n【27】Statistical Analysis\n--------------------\n\n【28】The trial used a parallel design with patients randomly assigned to undergo mitral-valve surgery alone or surgery plus TA, with 90% power to detect a 52% relative reduction in the primary end point among those in the surgery-plus-TA group as compared with the surgery-alone group. A two-sided P value of 0.05 was considered to indicate statistical significance. We assumed a 25% failure rate for mitral-valve surgery and 12% for surgery plus TA. One interim analysis was planned but not performed, according to the recommendation of the data and safety monitoring board, since enrollment had been completed and assessments of the primary end point were close to finalization.\n\n【29】All end points were evaluated in the intention-to-treat population. There was no correction of the type I error rate for multiple testing across secondary end points, as prespecified. As such, reported 95% confidence intervals have not been adjusted for multiplicity and do not imply definitive treatment effects.\n\n【30】The primary hypothesis was tested with the use of a log binomial regression model of treatment failure and randomization assignment that was stratified according to the severity of tricuspid regurgitation at baseline. Missing data regarding the primary end point at 2 years were imputed by means of multiple imputation on the assumption that data were missing at random. The imputation model was stratified according to randomization assignment and included age, sex, baseline severity of tricuspid regurgitation, and the degree of tricuspid regurgitation at 6 months and at 12 months. Details regarding the statistical analysis of the primary end point are provided in the Supplementary Appendix .\n\n【31】We used Cox proportional-hazards regression models to analyze the incidence of MACCE and death from any cause at 2 years. Secondary end points, including 30-day mortality, NYHA class, diuretic use, and categorical echocardiographic end points, are reported descriptively. Results on 6-minute walk and gait-speed testing and continuous echocardiographic end points are also reported descriptively as means and standard deviations or medians and interquartile ranges. We assessed the patients’ quality of life during the 2-year trial period using longitudinal linear mixed-effects models. The lengths of stay in the hospital and in the intensive care unit during the index hospitalization were compared separately according to geographic region with the use of the Hodges–Lehmann estimate of location shift. We performed Poisson regression with a robust variance estimate to calculate group differences in the frequencies of serious adverse events and readmissions through 2 years. All analyses were performed with the use of SAS software, version 9.4 (SAS Institute).\n\n【32】Results\n-------\n\n【33】Patients\n--------\n\n【34】Table 1. Characteristics of the Patients at Baseline.\n\n【35】From 2016 through 2018, a total of 5208 patients were screened; 885 were eligible to participate in the trial, and 401 underwent randomization (203 to undergo mitral-valve surgery alone and 198 to undergo surgery plus TA) . The two groups had similar preoperative characteristics at baseline . The core laboratory confirmed moderate tricuspid regurgitation in 149 of 399 patients (37.3%). Right ventricular systolic function was normal in 360 of 398 patients (90.5%), and 121 of 400 patients (30.3%) had NYHA class III or IV heart failure.\n\n【36】Of the 401 patients, mitral-valve repair was performed in 360 (89.8%) and mitral-valve replacement in 41 (10.2%). In TA recipients, the average annuloplasty ring size was 29.0±1.9 mm in men and 27.8±1.6 mm in women. The mean cardiopulmonary bypass time was longer by 33.5 minutes (95% confidence interval \\[CI\\], 20.9 to 46.1) in the surgery-plus-TA group than in the surgery-alone group (166.1±69.3 minutes vs. 132.6±58.8 minutes). On the basis of surgeon judgment and logistics, 4 patients crossed over to undergo the other procedure in the operating room. More than 50% of the patients underwent concomitant procedures, including coronary-artery bypass grafting, atrial fibrillation ablation, left atrial appendage closure, and oversewing of a patent foramen ovale.\n\n【37】Primary End Point\n-----------------\n\n【38】Table 2. Primary End Point.\n\n【39】The primary end point was significantly more frequent among patients in the surgery-alone group (10.2%) than in the surgery-plus-TA group (3.9%) (relative risk, 0.37; 95% CI, 0.16 to 0.86; P=0.02) . Death occurred in 9 of 199 patients (4.5%) in the surgery-alone group and in 6 of 190 (3.2%) in the surgery-plus-TA group (relative risk, 0.69; 95% CI, 0.25 to 1.88). No patients underwent tricuspid-valve reoperation within 2 years after randomization. The percentage of patients who had progression of tricuspid regurgitation at 2 years was higher in the surgery-alone group than in the surgery-plus-TA group (6.1% vs. 0.6%; relative risk, 0.09; 95% CI, 0.01 to 0.69). Most of the patients with progression had severe tricuspid regurgitation, which was present in 10 of 179 patients (5.6%) in the surgery-alone group and in 1 of 179 (0.6%) in the surgery-plus-TA group (relative risk, 0.10; 95% CI, 0.01 to 0.77).\n\n【40】In a post hoc analysis stratified according to the degree of tricuspid regurgitation at baseline, the incidence of a primary-end-point event was higher among the patients in the surgery-alone group than in the surgery-plus-TA group when moderate tricuspid regurgitation was present at baseline but not when tricuspid regurgitation was less than moderate. This difference in outcomes was driven by the progression to severe tricuspid regurgitation at 2 years in the surgery-alone group .\n\n【41】MACCE and Death\n---------------\n\n【42】Figure 1. Overall Survival.\n\n【43】Shown are Kaplan–Meier estimates of overall survival during the 2 years after randomization among patients with moderate or less-than-moderate tricuspid regurgitation who were undergoing mitral-valve surgery alone or surgery with placement of a tricuspid annuloplasty (TA) ring. The inset shows the same data on an expanded y axis. The tick marks indicate censored data.\n\n【44】In the time-to-event analysis of death during the 2-year trial period, we observed no substantial difference in cumulative mortality between the surgery-alone group and the surgery-plus-TA group (hazard ratio, 0.69; 95% CI, 0.24 to 1.93) . Death within 30 days after surgery (perioperative mortality) occurred in 1 of 203 patients (0.5%) in the surgery-alone group and in 2 of 197 (1.0%) in the surgery-plus-TA group. The risk of a MACCE end point within 2 years was also similar in the two groups (hazard ratio, 0.89; 95% CI, 0.49 to 1.63) .\n\n【45】Echocardiographic End Points\n----------------------------\n\n【46】Figure 2. Echocardiographic and Functional Status.\n\n【47】Shown are the distributions of the degree of tricuspid regurgitation , the degree of mitral regurgitation , and the New York Heart Association class  among the patients who were undergoing mitral-valve (MV) surgery alone or MV surgery plus TA during the 2 years after randomization.\n\n【48】The degree of tricuspid regurgitation during a 2-year period is shown in Figure 2A . Moderate or severe tricuspid regurgitation occurred in 45 of 179 patients (25.1%) in the surgery-alone group and in 6 of 179 (3.4%) in the surgery-plus-TA group. The median peak diastolic transtricuspid pressure gradient was 1 mm Hg (interquartile range \\[IQR\\], 1 to 2) in the surgery-alone group and 3 (IQR, 2 to 4) in the surgery-plus-TA group. More than 90% of the patients in both groups had normal right ventricular systolic function, which occurred in 163 of 178 patients (91.6%) in the surgery-alone group and in 162 of 178 (91.0%) in the surgery-plus-TA group. The median left ventricular ejection fraction was 60% (IQR, 56 to 64) in the surgery-alone group and 61% (IQR, 56 to 64) in the surgery-plus-TA group. At 2 years, moderate or severe mitral regurgitation was present in 18 of 178 patients (10.1%) in the surgery-alone group and in 15 of 179 (8.4%) in the surgery-plus-TA group . Post hoc analyses of these end points with reasons for missingness of data and estimates of treatment effect on the basis of multiple imputation are provided in the Supplementary Appendix .\n\n【49】Adverse Events and Hospitalizations\n-----------------------------------\n\n【50】Table 3. Serious Adverse Events.\n\n【51】The overall incidence of serious adverse events was similar in the two groups at 2 years . The rate of heart-failure events was 0.11 per 24 patient-months in the surgery-alone group and 0.07 per 24 patient-months in the surgery-plus-TA group (rate ratio, 0.68; 95% CI, 0.25 to 1.85). Sustained supraventricular arrhythmias requiring drug therapy or cardioversion were more frequent in the surgery-alone group than in the surgery-plus-TA group (rate ratio, 0.70; 95% CI, 0.43 to 1.12). However, cardiac-conduction abnormalities resulting in permanent pacemaker implantation were more frequent in the surgery-plus-TA group than in the surgery-alone group (rate ratio, 5.75; 95% CI, 2.27 to 14.60). The majority of these events occurred during the index hospitalization, with 4 of 5 permanent pacemakers (80.0%) implanted in the surgery-alone group and 22 of 28 (78.6%) implanted in the surgery-plus-TA group before hospital discharge. The most common indication for permanent pacemaker implantation was complete or high-grade atrioventricular block (in 19 of 33 patients \\[57.6%\\]).\n\n【52】The median length of stay during the index hospitalization was 2 days shorter in the surgery-alone group than in the surgery-plus-TA group in the United States (6 days \\[IQR, 5 to 8\\] vs. 8 days \\[IQR, 6 to 9\\]) and in Canada (7 days \\[IQR, 6 to 11\\] vs. 9 days \\[IQR, 7 to 14\\]). In Germany, the length of stay was longer than that in either the United States or Canada and similar in the two treatment groups (11.5 days \\[IQR, 9 to 15\\] vs. 12 days \\[IQR, 9 to 16\\]) . The overall hospital readmission rate per 24 patient-months was 0.65 in the surgery-alone group and 0.56 in the surgery-plus-TA group (rate ratio, 0.86; 95% CI, 0.58 to 1.27) , with similar incidences of readmissions for cardiovascular events (rate ratio, 0.87; 95% CI, 0.52 to 1.43) and heart-failure events (rate ratio, 0.71; 95% CI, 0.18 to 2.71). Post hoc analyses of the time until the first readmission with death as a competing risk also showed similar outcomes in the two groups.\n\n【53】Quality of Life and Functional Status\n-------------------------------------\n\n【54】The outcomes with respect to any measures of quality of life or functional status for patients at 2 years were similar in the two groups . Among survivors, the median improvement in heart-failure symptoms over baseline, as measured on the KCCQ, was 27.2% (IQR, 4.3 to 70.0) in the surgery-alone group and 21.4% (IQR, 6.1 to 57.1) in the surgery-plus-TA group. Figure 2C shows the NYHA classification, which includes data regarding death, over time. Diuretic use at 24 months was similar in the two groups (in 55 of 185 patients \\[29.7%\\] in the surgery-alone group and in 41 of 182 \\[22.5%\\] in the surgery-plus-TA group).\n\n【55】Discussion\n----------\n\n【56】The best treatment approach for patients with moderate or less-than-moderate tricuspid regurgitation at the time of surgery for degenerative mitral regurgitation is uncertain. Current guideline recommendations are based largely on observational data from studies conducted at single surgical centers.  In this international, randomized trial, we found that patients with moderate or less-than-moderate tricuspid regurgitation who were receiving TA at the time of mitral-valve surgery for degenerative mitral regurgitation had a significantly lower 2-year incidence of a composite end point of reoperation for tricuspid regurgitation, progression of tricuspid regurgitation, or death than those undergoing mitral-valve surgery alone (3.9% vs. 10.2%; P=0.02). This difference was driven by a substantially lower incidence of progression of tricuspid regurgitation among patients assigned to receive TA.\n\n【57】Although our trial was not powered to analyze the primary end point according to the severity of tricuspid regurgitation at baseline, in a post hoc analysis, we found that the progression of tricuspid regurgitation occurred almost exclusively in patients with moderate tricuspid regurgitation at baseline and not in those with less-than-moderate regurgitation with annular dilatation. This observation calls into question reliance on the measurement of the tricuspid annular diameter to inform surgical decision making in patients with less-than-moderate tricuspid regurgitation — a question that can be answered only with additional research over a longer time period.\n\n【58】The status with respect to MACCE, functional status, quality of life, heart-failure events, diuretic use, and hospital readmission at 2 years was similar in the two groups, although the rate of permanent pacemaker implantation was substantially higher in recipients of TA, an outcome that should be factored into shared decision making with patients. Moreover, patients who were undergoing mitral-valve surgery alone were more likely to have moderate or severe tricuspid regurgitation at 2 years (25.1%) than those who also received TA (3.4%). However, we observed similar incidences of NYHA class III or IV heart failure (2.8% in the surgery-alone group and 1.1% in the surgery-plus-TA group), as compared with incidences of 33.5% and 26.9%, respectively, at baseline. Overall summary scores for quality of life on the KCCQ, the SF-12 physical and mental health scores, and scores on the EQ-5D and 6-minute walk test were also similar in the two groups. Notably, the 2-year KCCQ scores showed average increases from baseline in both groups that were indicative of clinical improvement that was “large to very large.”  Readmission rates, including for cardiovascular and heart-failure events, were also similar in the two groups.\n\n【59】Although the much higher prevalence of moderate or severe tricuspid regurgitation among the patients who underwent mitral-valve surgery alone did not affect clinical or functional outcomes at 2 years, differences may emerge with longer-term follow-up. Observational studies have suggested that moderate or severe functional tricuspid regurgitation in patients with degenerative mitral regurgitation is an independent long-term risk factor for death.  The incidence of severe tricuspid regurgitation may increase over time after isolated mitral-valve surgery and adversely affect right ventricular function.  The long life expectancy of our relatively young trial population underscores the importance of longer-term follow-up.\n\n【60】The addition of TA increased cardiopulmonary bypass time by 34 minutes on average. However, this difference was not associated with a higher risk of perioperative death, as has been reported in other studies.  Mitral-valve surgery plus TA was associated with a length of stay during the index hospitalization that was 2 days longer than the length of stay with surgery alone in both the United States and Canada. In Germany, the length of hospital stay was generally longer than those in both the United States and Canada but similar in the two treatment groups, which reflects the different incentives embedded in the three health care systems.\n\n【61】An important finding in this trial was the higher incidence of permanent pacemaker implantation in the TA group (14.1% vs. 2.5%), with nearly 80% of procedures occurring during the index hospitalization. The frequency of surgery for atrial fibrillation, a potential confounder, was similar in the two treatment groups. Permanent pacemaker implantation has been associated with the risks of device malfunction, thrombosis, infection, recurrent or progressive tricuspid regurgitation, right ventricular remodeling, and reduced survival.  The use of leadless pacemakers and evolving transcatheter approaches may circumvent some of these issues, and additional study may help in the identification of procedural factors associated with permanent pacemaker implantation. Although the clinical effect of pacemaker implantation was not evident during the 2-year period, longer-term follow-up is needed to gain further insight. In the two treatment groups, recurrent mitral regurgitation could also contribute to late outcomes.\n\n【62】Our trial has several limitations. First, we did not meet our target in recruiting a sufficiently diverse patient population with respect to race or ethnic group. A recent national registry study involving patients who were undergoing mitral-valve surgery indicated that 5.9% were Hispanic and 9.9% were Black, as compared with 2.5% and 4.2%, respectively, among the patients in the United States in our trial .  Efforts to understand why minorities are underrepresented in the surgical population and in clinical trials in general and how to overcome these limitations have become a priority for the CTSN. Second, the composite primary end point included both echocardiographic and clinical outcomes so that a manageable sample size to allow for efficient trial completion could be achieved. However, our choice of progression of tricuspid regurgitation was driven by observational evidence correlating it with the long-term risk of adverse clinical outcomes. Third, the trial was designed to address surgical decision making for patients with either moderate tricuspid regurgitation or less-than-moderate regurgitation with annular dilatation, but it was not powered to draw inferences about these groups individually. Finally, measuring the primary end point at 24 months may not fully capture the clinical effect of progression of tricuspid regurgitation or permanent pacemaker implantation over time. The trial is designed to follow patients for 5 years to assess longer-term clinical outcomes.\n\n【63】The inclusion of TA at the time of mitral-valve surgery resulted in a lower risk of a primary-end-point event at 2 years than surgery alone, a reduction that was driven by less frequent progression to severe tricuspid regurgitation. This reduction in disease progression came at the cost of a higher risk of permanent pacemaker implantation. Otherwise, patients in the two treatment groups had similar outcomes with respect to MACCE, quality of life, functional status, hospital readmission, and death. Follow-up through 5 years to assess net clinical benefit is ongoing.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "【4】Download a PDF of the Research Summary .", "content": "【0】Concomitant Tricuspid Repair in Patients with Degenerative Mitral Regurgitation\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Tricuspid regurgitation is common in patients with severe degenerative mitral regurgitation. However, the evidence base is insufficient to inform a decision about whether to perform tricuspid-valve repair during mitral-valve surgery in patients who have moderate tricuspid regurgitation or less-than-moderate regurgitation with annular dilatation.\n\n【3】Methods\n-------\n\n【4】Download a PDF of the Research Summary .\n\n【5】We randomly assigned 401 patients who were undergoing mitral-valve surgery for degenerative mitral regurgitation to receive a procedure with or without tricuspid annuloplasty (TA). The primary 2-year end point was a composite of reoperation for tricuspid regurgitation, progression of tricuspid regurgitation by two grades from baseline or the presence of severe tricuspid regurgitation, or death.\n\n【6】Results\n-------\n\n【7】Patients who underwent mitral-valve surgery plus TA had fewer primary-end-point events than those who underwent mitral-valve surgery alone (3.9% vs. 10.2%) (relative risk, 0.37; 95% confidence interval \\[CI\\], 0.16 to 0.86; P=0.02). Two-year mortality was 3.2% in the surgery-plus-TA group and 4.5% in the surgery-alone group (relative risk, 0.69; 95% CI, 0.25 to 1.88). The 2-year prevalence of progression of tricuspid regurgitation was lower in the surgery-plus-TA group than in the surgery-alone group (0.6% vs. 6.1%; relative risk, 0.09; 95% CI, 0.01 to 0.69). The frequencies of major adverse cardiac and cerebrovascular events, functional status, and quality of life were similar in the two groups at 2 years, although the incidence of permanent pacemaker implantation was higher in the surgery-plus-TA group than in the surgery-alone group (14.1% vs. 2.5%; rate ratio, 5.75; 95% CI, 2.27 to 14.60).\n\n【8】Conclusions\n-----------\n\n【9】Among patients undergoing mitral-valve surgery, those who also received TA had a lower incidence of a primary-end-point event than those who underwent mitral-valve surgery alone at 2 years, a reduction that was driven by less frequent progression to severe tricuspid regurgitation. Tricuspid repair resulted in more frequent permanent pacemaker implantation. Whether reduced progression of tricuspid regurgitation results in long-term clinical benefit can be determined only with longer follow-up. \n\n【10】Introduction\n------------\n\n【11】 QUICK TAKE  \nTricuspid Repair in Patients with Degenerative Mitral Regurgitation  \n\n【12】Tricuspid regurgitation is common among patients undergoing mitral-valve surgery for degenerative mitral regurgitation.  The recommendations for management of tricuspid regurgitation during mitral-valve surgery are based largely on observational data.  There is broad agreement that severe tricuspid regurgitation may not predictably improve after left-sided cardiac surgery and should be addressed during the index procedure. Late reoperation for severe tricuspid regurgitation in patients with right heart failure is associated with high perioperative mortality. \n\n【13】However, the operative management of lesser degrees of tricuspid regurgitation is widely debated. Surgical and medical treatments of left-sided cardiac disease often result in a progressive reduction in the degree of tricuspid regurgitation, with favorable right ventricular reverse remodeling, a decrease in pulmonary-artery pressures, or both.  Mild or moderate tricuspid regurgitation that is not corrected at the time of left-sided cardiac surgery may progress in approximately 25% of patients and result in poorer late survival and functional outcomes. Risk factors for the progression of tricuspid regurgitation include annular dilation measuring 40 mm or more (or 21 mm per square meter) in diameter on preoperative transthoracic echocardiography, the magnitude of right ventricular dysfunction, and the presence of leaflet tethering, pulmonary hypertension, atrial fibrillation, or transvalvular pacing or defibrillator leads. \n\n【14】Several single-center observational studies and a small randomized trial with an unblinded end-point assessment have suggested that concomitant tricuspid-valve repair in patients with moderate tricuspid regurgitation or less-than-moderate (i.e., none, trace, or mild) regurgitation with annular dilatation is associated with less disease progression and better outcomes than conservative management.  Enthusiasm for uniform adoption of tricuspid-valve repair under these circumstances is tempered by concern regarding the excess risk of postoperative conduction disturbances resulting in permanent pacemaker implantation, an increase in cardiopulmonary bypass times, the small chance that tricuspid-valve replacement (rather than annuloplasty repair) may be needed, and the reality that tricuspid regurgitation does not progress in all patients. \n\n【15】Accordingly, there are wide practice variations in the management of less-than-severe tricuspid regurgitation at the time of left-sided cardiac surgery. The frequency of tricuspid-valve repair at the time of mitral-valve surgery ranges from 5 to 75%.  To inform decision making, the Cardiothoracic Surgical Trials Network (CTSN) conducted a multicenter, randomized trial to assess the benefits and risks of tricuspid-valve repair at the time of mitral-valve surgery in patients with moderate or less-than-moderate tricuspid regurgitation who were undergoing surgery for degenerative mitral regurgitation.\n\n【16】Methods\n-------\n\n【17】Trial Design and Oversight\n--------------------------\n\n【18】The trial was conducted at 39 clinical centers in the United States, Canada, and Germany. The progress of the trial was overseen by a coordinating center, an echocardiographic core laboratory, an independent event-adjudication committee, and a data and safety monitoring board appointed by the National Institutes of Health. All the patients provided written informed consent.\n\n【19】All the investigators were responsible for the trial design and data collection; coordinating center investigators vouch for the completeness and accuracy of the data and for the fidelity of the trial to the protocol.\n\n【20】Randomization and Treatment\n---------------------------\n\n【21】Among patients who were scheduled for mitral-valve surgery, we randomly assigned those with either moderate tricuspid regurgitation or less-than-moderate regurgitation with annular dilatation in a  ratio to undergo the surgery with or without tricuspid annuloplasty (TA). Randomization was stratified according to the severity of tricuspid regurgitation and the clinical center. The trial was designed to enroll 400 patients; 1 additional patient underwent randomization before the completion of enrollment. The investigators were unaware of the overall outcome data. End points were assessed at 30 days and at 6, 12, 18, and 24 months; after 24 months, survival was to be evaluated annually up to 60 months.\n\n【22】Patients and Interventions\n--------------------------\n\n【23】The target population included adults undergoing mitral-valve surgery for degenerative mitral regurgitation with either moderate tricuspid regurgitation or less-than-moderate regurgitation with annular dilatation of 40 mm or more (or 21 mm per square meter).  The degree of tricuspid regurgitation was assessed by means of transthoracic echocardiography and verified by the central echocardiographic core laboratory. The selection of the most effective medical therapy was at the discretion of the heart team at each site. Exclusion criteria included evidence of secondary mitral regurgitation, primary tricuspid-valve disease, and suboptimal volume management.\n\n【24】All the patients underwent mitral-valve surgery with the use of a sternotomy or right minithoracotomy. Decisions regarding the use of surgical techniques — including suture placement and the type of prosthetic annuloplasty ring or valve — were at the surgeon’s discretion. However, the protocol specified the use of an approved rigid, incomplete, nonplanar, and undersized (26, 28, or 30 mm) TA ring. \n\n【25】End Points\n----------\n\n【26】The primary end point at 2 years was a composite of reoperation for tricuspid regurgitation, progression of tricuspid regurgitation from baseline by two grades or the presence of severe tricuspid regurgitation, or death, with imputation of missing data. Secondary end points were death, major adverse cardiac and cerebrovascular events (MACCE; a composite of death, stroke, or serious heart-failure events), permanent pacemaker implantation, length of hospital stay, residual tricuspid regurgitation, echocardiographic indexes of right ventricular size and function, New York Heart Association (NYHA) classification, diuretic use, results on a 6-minute walk test, results on a gait-speed test for frailty, quality of life (as measured on the 12-Item Short Form Survey \\[SF-12\\], the Kansas City Cardiomyopathy Questionnaire \\[KCCQ\\], and EuroQol \\[EQ-5D\\]), serious adverse events, rehospitalizations, and cost-effectiveness. The cost-effectiveness analysis and additional echocardiographic studies are ongoing.\n\n【27】Statistical Analysis\n--------------------\n\n【28】The trial used a parallel design with patients randomly assigned to undergo mitral-valve surgery alone or surgery plus TA, with 90% power to detect a 52% relative reduction in the primary end point among those in the surgery-plus-TA group as compared with the surgery-alone group. A two-sided P value of 0.05 was considered to indicate statistical significance. We assumed a 25% failure rate for mitral-valve surgery and 12% for surgery plus TA. One interim analysis was planned but not performed, according to the recommendation of the data and safety monitoring board, since enrollment had been completed and assessments of the primary end point were close to finalization.\n\n【29】All end points were evaluated in the intention-to-treat population. There was no correction of the type I error rate for multiple testing across secondary end points, as prespecified. As such, reported 95% confidence intervals have not been adjusted for multiplicity and do not imply definitive treatment effects.\n\n【30】The primary hypothesis was tested with the use of a log binomial regression model of treatment failure and randomization assignment that was stratified according to the severity of tricuspid regurgitation at baseline. Missing data regarding the primary end point at 2 years were imputed by means of multiple imputation on the assumption that data were missing at random. The imputation model was stratified according to randomization assignment and included age, sex, baseline severity of tricuspid regurgitation, and the degree of tricuspid regurgitation at 6 months and at 12 months. Details regarding the statistical analysis of the primary end point are provided in the Supplementary Appendix .\n\n【31】We used Cox proportional-hazards regression models to analyze the incidence of MACCE and death from any cause at 2 years. Secondary end points, including 30-day mortality, NYHA class, diuretic use, and categorical echocardiographic end points, are reported descriptively. Results on 6-minute walk and gait-speed testing and continuous echocardiographic end points are also reported descriptively as means and standard deviations or medians and interquartile ranges. We assessed the patients’ quality of life during the 2-year trial period using longitudinal linear mixed-effects models. The lengths of stay in the hospital and in the intensive care unit during the index hospitalization were compared separately according to geographic region with the use of the Hodges–Lehmann estimate of location shift. We performed Poisson regression with a robust variance estimate to calculate group differences in the frequencies of serious adverse events and readmissions through 2 years. All analyses were performed with the use of SAS software, version 9.4 (SAS Institute).\n\n【32】Results\n-------\n\n【33】Patients\n--------\n\n【34】Table 1. Characteristics of the Patients at Baseline.\n\n【35】From 2016 through 2018, a total of 5208 patients were screened; 885 were eligible to participate in the trial, and 401 underwent randomization (203 to undergo mitral-valve surgery alone and 198 to undergo surgery plus TA) . The two groups had similar preoperative characteristics at baseline . The core laboratory confirmed moderate tricuspid regurgitation in 149 of 399 patients (37.3%). Right ventricular systolic function was normal in 360 of 398 patients (90.5%), and 121 of 400 patients (30.3%) had NYHA class III or IV heart failure.\n\n【36】Of the 401 patients, mitral-valve repair was performed in 360 (89.8%) and mitral-valve replacement in 41 (10.2%). In TA recipients, the average annuloplasty ring size was 29.0±1.9 mm in men and 27.8±1.6 mm in women. The mean cardiopulmonary bypass time was longer by 33.5 minutes (95% confidence interval \\[CI\\], 20.9 to 46.1) in the surgery-plus-TA group than in the surgery-alone group (166.1±69.3 minutes vs. 132.6±58.8 minutes). On the basis of surgeon judgment and logistics, 4 patients crossed over to undergo the other procedure in the operating room. More than 50% of the patients underwent concomitant procedures, including coronary-artery bypass grafting, atrial fibrillation ablation, left atrial appendage closure, and oversewing of a patent foramen ovale.\n\n【37】Primary End Point\n-----------------\n\n【38】Table 2. Primary End Point.\n\n【39】The primary end point was significantly more frequent among patients in the surgery-alone group (10.2%) than in the surgery-plus-TA group (3.9%) (relative risk, 0.37; 95% CI, 0.16 to 0.86; P=0.02) . Death occurred in 9 of 199 patients (4.5%) in the surgery-alone group and in 6 of 190 (3.2%) in the surgery-plus-TA group (relative risk, 0.69; 95% CI, 0.25 to 1.88). No patients underwent tricuspid-valve reoperation within 2 years after randomization. The percentage of patients who had progression of tricuspid regurgitation at 2 years was higher in the surgery-alone group than in the surgery-plus-TA group (6.1% vs. 0.6%; relative risk, 0.09; 95% CI, 0.01 to 0.69). Most of the patients with progression had severe tricuspid regurgitation, which was present in 10 of 179 patients (5.6%) in the surgery-alone group and in 1 of 179 (0.6%) in the surgery-plus-TA group (relative risk, 0.10; 95% CI, 0.01 to 0.77).\n\n【40】In a post hoc analysis stratified according to the degree of tricuspid regurgitation at baseline, the incidence of a primary-end-point event was higher among the patients in the surgery-alone group than in the surgery-plus-TA group when moderate tricuspid regurgitation was present at baseline but not when tricuspid regurgitation was less than moderate. This difference in outcomes was driven by the progression to severe tricuspid regurgitation at 2 years in the surgery-alone group .\n\n【41】MACCE and Death\n---------------\n\n【42】Figure 1. Overall Survival.\n\n【43】Shown are Kaplan–Meier estimates of overall survival during the 2 years after randomization among patients with moderate or less-than-moderate tricuspid regurgitation who were undergoing mitral-valve surgery alone or surgery with placement of a tricuspid annuloplasty (TA) ring. The inset shows the same data on an expanded y axis. The tick marks indicate censored data.\n\n【44】In the time-to-event analysis of death during the 2-year trial period, we observed no substantial difference in cumulative mortality between the surgery-alone group and the surgery-plus-TA group (hazard ratio, 0.69; 95% CI, 0.24 to 1.93) . Death within 30 days after surgery (perioperative mortality) occurred in 1 of 203 patients (0.5%) in the surgery-alone group and in 2 of 197 (1.0%) in the surgery-plus-TA group. The risk of a MACCE end point within 2 years was also similar in the two groups (hazard ratio, 0.89; 95% CI, 0.49 to 1.63) .\n\n【45】Echocardiographic End Points\n----------------------------\n\n【46】Figure 2. Echocardiographic and Functional Status.\n\n【47】Shown are the distributions of the degree of tricuspid regurgitation , the degree of mitral regurgitation , and the New York Heart Association class  among the patients who were undergoing mitral-valve (MV) surgery alone or MV surgery plus TA during the 2 years after randomization.\n\n【48】The degree of tricuspid regurgitation during a 2-year period is shown in Figure 2A . Moderate or severe tricuspid regurgitation occurred in 45 of 179 patients (25.1%) in the surgery-alone group and in 6 of 179 (3.4%) in the surgery-plus-TA group. The median peak diastolic transtricuspid pressure gradient was 1 mm Hg (interquartile range \\[IQR\\], 1 to 2) in the surgery-alone group and 3 (IQR, 2 to 4) in the surgery-plus-TA group. More than 90% of the patients in both groups had normal right ventricular systolic function, which occurred in 163 of 178 patients (91.6%) in the surgery-alone group and in 162 of 178 (91.0%) in the surgery-plus-TA group. The median left ventricular ejection fraction was 60% (IQR, 56 to 64) in the surgery-alone group and 61% (IQR, 56 to 64) in the surgery-plus-TA group. At 2 years, moderate or severe mitral regurgitation was present in 18 of 178 patients (10.1%) in the surgery-alone group and in 15 of 179 (8.4%) in the surgery-plus-TA group . Post hoc analyses of these end points with reasons for missingness of data and estimates of treatment effect on the basis of multiple imputation are provided in the Supplementary Appendix .\n\n【49】Adverse Events and Hospitalizations\n-----------------------------------\n\n【50】Table 3. Serious Adverse Events.\n\n【51】The overall incidence of serious adverse events was similar in the two groups at 2 years . The rate of heart-failure events was 0.11 per 24 patient-months in the surgery-alone group and 0.07 per 24 patient-months in the surgery-plus-TA group (rate ratio, 0.68; 95% CI, 0.25 to 1.85). Sustained supraventricular arrhythmias requiring drug therapy or cardioversion were more frequent in the surgery-alone group than in the surgery-plus-TA group (rate ratio, 0.70; 95% CI, 0.43 to 1.12). However, cardiac-conduction abnormalities resulting in permanent pacemaker implantation were more frequent in the surgery-plus-TA group than in the surgery-alone group (rate ratio, 5.75; 95% CI, 2.27 to 14.60). The majority of these events occurred during the index hospitalization, with 4 of 5 permanent pacemakers (80.0%) implanted in the surgery-alone group and 22 of 28 (78.6%) implanted in the surgery-plus-TA group before hospital discharge. The most common indication for permanent pacemaker implantation was complete or high-grade atrioventricular block (in 19 of 33 patients \\[57.6%\\]).\n\n【52】The median length of stay during the index hospitalization was 2 days shorter in the surgery-alone group than in the surgery-plus-TA group in the United States (6 days \\[IQR, 5 to 8\\] vs. 8 days \\[IQR, 6 to 9\\]) and in Canada (7 days \\[IQR, 6 to 11\\] vs. 9 days \\[IQR, 7 to 14\\]). In Germany, the length of stay was longer than that in either the United States or Canada and similar in the two treatment groups (11.5 days \\[IQR, 9 to 15\\] vs. 12 days \\[IQR, 9 to 16\\]) . The overall hospital readmission rate per 24 patient-months was 0.65 in the surgery-alone group and 0.56 in the surgery-plus-TA group (rate ratio, 0.86; 95% CI, 0.58 to 1.27) , with similar incidences of readmissions for cardiovascular events (rate ratio, 0.87; 95% CI, 0.52 to 1.43) and heart-failure events (rate ratio, 0.71; 95% CI, 0.18 to 2.71). Post hoc analyses of the time until the first readmission with death as a competing risk also showed similar outcomes in the two groups.\n\n【53】Quality of Life and Functional Status\n-------------------------------------\n\n【54】The outcomes with respect to any measures of quality of life or functional status for patients at 2 years were similar in the two groups . Among survivors, the median improvement in heart-failure symptoms over baseline, as measured on the KCCQ, was 27.2% (IQR, 4.3 to 70.0) in the surgery-alone group and 21.4% (IQR, 6.1 to 57.1) in the surgery-plus-TA group. Figure 2C shows the NYHA classification, which includes data regarding death, over time. Diuretic use at 24 months was similar in the two groups (in 55 of 185 patients \\[29.7%\\] in the surgery-alone group and in 41 of 182 \\[22.5%\\] in the surgery-plus-TA group).\n\n【55】Discussion\n----------\n\n【56】The best treatment approach for patients with moderate or less-than-moderate tricuspid regurgitation at the time of surgery for degenerative mitral regurgitation is uncertain. Current guideline recommendations are based largely on observational data from studies conducted at single surgical centers.  In this international, randomized trial, we found that patients with moderate or less-than-moderate tricuspid regurgitation who were receiving TA at the time of mitral-valve surgery for degenerative mitral regurgitation had a significantly lower 2-year incidence of a composite end point of reoperation for tricuspid regurgitation, progression of tricuspid regurgitation, or death than those undergoing mitral-valve surgery alone (3.9% vs. 10.2%; P=0.02). This difference was driven by a substantially lower incidence of progression of tricuspid regurgitation among patients assigned to receive TA.\n\n【57】Although our trial was not powered to analyze the primary end point according to the severity of tricuspid regurgitation at baseline, in a post hoc analysis, we found that the progression of tricuspid regurgitation occurred almost exclusively in patients with moderate tricuspid regurgitation at baseline and not in those with less-than-moderate regurgitation with annular dilatation. This observation calls into question reliance on the measurement of the tricuspid annular diameter to inform surgical decision making in patients with less-than-moderate tricuspid regurgitation — a question that can be answered only with additional research over a longer time period.\n\n【58】The status with respect to MACCE, functional status, quality of life, heart-failure events, diuretic use, and hospital readmission at 2 years was similar in the two groups, although the rate of permanent pacemaker implantation was substantially higher in recipients of TA, an outcome that should be factored into shared decision making with patients. Moreover, patients who were undergoing mitral-valve surgery alone were more likely to have moderate or severe tricuspid regurgitation at 2 years (25.1%) than those who also received TA (3.4%). However, we observed similar incidences of NYHA class III or IV heart failure (2.8% in the surgery-alone group and 1.1% in the surgery-plus-TA group), as compared with incidences of 33.5% and 26.9%, respectively, at baseline. Overall summary scores for quality of life on the KCCQ, the SF-12 physical and mental health scores, and scores on the EQ-5D and 6-minute walk test were also similar in the two groups. Notably, the 2-year KCCQ scores showed average increases from baseline in both groups that were indicative of clinical improvement that was “large to very large.”  Readmission rates, including for cardiovascular and heart-failure events, were also similar in the two groups.\n\n【59】Although the much higher prevalence of moderate or severe tricuspid regurgitation among the patients who underwent mitral-valve surgery alone did not affect clinical or functional outcomes at 2 years, differences may emerge with longer-term follow-up. Observational studies have suggested that moderate or severe functional tricuspid regurgitation in patients with degenerative mitral regurgitation is an independent long-term risk factor for death.  The incidence of severe tricuspid regurgitation may increase over time after isolated mitral-valve surgery and adversely affect right ventricular function.  The long life expectancy of our relatively young trial population underscores the importance of longer-term follow-up.\n\n【60】The addition of TA increased cardiopulmonary bypass time by 34 minutes on average. However, this difference was not associated with a higher risk of perioperative death, as has been reported in other studies.  Mitral-valve surgery plus TA was associated with a length of stay during the index hospitalization that was 2 days longer than the length of stay with surgery alone in both the United States and Canada. In Germany, the length of hospital stay was generally longer than those in both the United States and Canada but similar in the two treatment groups, which reflects the different incentives embedded in the three health care systems.\n\n【61】An important finding in this trial was the higher incidence of permanent pacemaker implantation in the TA group (14.1% vs. 2.5%), with nearly 80% of procedures occurring during the index hospitalization. The frequency of surgery for atrial fibrillation, a potential confounder, was similar in the two treatment groups. Permanent pacemaker implantation has been associated with the risks of device malfunction, thrombosis, infection, recurrent or progressive tricuspid regurgitation, right ventricular remodeling, and reduced survival.  The use of leadless pacemakers and evolving transcatheter approaches may circumvent some of these issues, and additional study may help in the identification of procedural factors associated with permanent pacemaker implantation. Although the clinical effect of pacemaker implantation was not evident during the 2-year period, longer-term follow-up is needed to gain further insight. In the two treatment groups, recurrent mitral regurgitation could also contribute to late outcomes.\n\n【62】Our trial has several limitations. First, we did not meet our target in recruiting a sufficiently diverse patient population with respect to race or ethnic group. A recent national registry study involving patients who were undergoing mitral-valve surgery indicated that 5.9% were Hispanic and 9.9% were Black, as compared with 2.5% and 4.2%, respectively, among the patients in the United States in our trial .  Efforts to understand why minorities are underrepresented in the surgical population and in clinical trials in general and how to overcome these limitations have become a priority for the CTSN. Second, the composite primary end point included both echocardiographic and clinical outcomes so that a manageable sample size to allow for efficient trial completion could be achieved. However, our choice of progression of tricuspid regurgitation was driven by observational evidence correlating it with the long-term risk of adverse clinical outcomes. Third, the trial was designed to address surgical decision making for patients with either moderate tricuspid regurgitation or less-than-moderate regurgitation with annular dilatation, but it was not powered to draw inferences about these groups individually. Finally, measuring the primary end point at 24 months may not fully capture the clinical effect of progression of tricuspid regurgitation or permanent pacemaker implantation over time. The trial is designed to follow patients for 5 years to assess longer-term clinical outcomes.\n\n【63】The inclusion of TA at the time of mitral-valve surgery resulted in a lower risk of a primary-end-point event at 2 years than surgery alone, a reduction that was driven by less frequent progression to severe tricuspid regurgitation. This reduction in disease progression came at the cost of a higher risk of permanent pacemaker implantation. Otherwise, patients in the two treatment groups had similar outcomes with respect to MACCE, quality of life, functional status, hospital readmission, and death. Follow-up through 5 years to assess net clinical benefit is ongoing.", "index": 500, "show": true, "start": 500, "end": 543, "province": ["文本干净度", "无关文本"], "isEdit": false}]}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-14 00:21:05", "grab_time": "2024-08-13 23:14:31"}
{"id": 2234432, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "6e96e147-9969-4d90-b5e1-19c7e72ba5bb", "title": "Influence of the Internal-Mammary-Artery Graft on 10-Year Survival and Other Cardiac Events", "text": "【0】Influence of the Internal-Mammary-Artery Graft on 10-Year Survival and Other Cardiac Events\nAbstract\n--------\n\n【1】We compared patients who received an internal-mammary-artery graft to the anterior descending coronary artery alone or combined with one or more saphenous-vein grafts (n = 2306) with patients who had only saphenous-vein bypass grafts (n = 3625). The 10-year actuarial survival rate among the group receiving the internal-mammary-artery graft, as compared with the group who received the vein grafts (exclusive of hospital deaths), was 93.4 percent versus 88.0 percent (P = 0.05) for those with one-vessel disease; 90.0 percent versus 79.5 percent (P<0.0001) for those with two-vessel disease; and 82.6 percent versus 71.0 percent (P<0.0001) for those with three-vessel disease. After an adjustment for demographic and clinical differences by Cox multivariate analysis, we found that patients who had only vein grafts had a 1.61 times greater risk of death throughout the 10 years, as compared with those who received an internal-mammary-artery graft. In addition, patients who received only vein grafts had 1.41 times the risk of late myocardial infarction (P<0.0001), 1.25 times the risk of hospitalization for cardiac events (P<0.0001), 2.00 times the risk of cardiac reoperation (P<0.0001), and 1.27 times the risk of all late cardiac events (P<0.0001), as compared with patients who received internal-mammary-artery grafts. Internal-mammary-artery grafting for lesions of the anterior descending coronary artery is preferable whenever indicated and technically feasible.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:57:59", "endTime": "2024/08/14 14:58:11", "cost": 12.402}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 22:58:11", "grab_time": "2024-08-13 22:57:58"}
{"id": 2234431, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "9bc63d26-ad38-44bf-a3fa-37f3b3b80bed", "title": "Case 38-2011 — A 34-Year-Old Man with Diarrhea and Weakness", "text": "【0】Case 38-2011 — A 34-Year-Old Man with Diarrhea and Weakness\nA 34-year-old man was admitted to the hospital because of weakness, chronic diarrhea, and weight loss. Initial laboratory evaluation revealed a leukocytosis and hypokalemia. A diagnostic procedure was performed.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:27:42", "endTime": "2024/08/14 15:27:51", "cost": 8.767}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 23:27:51", "grab_time": "2024-08-13 23:27:42"}
{"id": 2234430, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "88841211-17a7-46a9-a75b-a0b0ae2f6138", "title": "Incidence of Unwarranted Implantation of Permanent Cardiac Pacemakers in a Large Medical Population", "text": "【0】Incidence of Unwarranted Implantation of Permanent Cardiac Pacemakers in a Large Medical Population\nAbstract\n\n【1】Because of allegations that the implantation of many permanent cardiac pacemakers has been unjustified, we reviewed the indications for all new pacemakers implanted at 30 hospitals in Philadelphia County between January 1 and June 30, 1983, and paid for by Medicare.\n\n【2】Complete chart data were evaluated for 382 implants. We determined whether the indications for implantation were appropriate and adequately documented on the basis of standard clinical practice. Implants were classified as possibly indicated primarily because of inadequate diagnostic evaluation (63 percent) or inadequate documentation of an accepted indication (36 percent). Implants were classified as not indicated primarily because a rhythm abnormality was incorrectly identified as a justifiable indication (84 percent).\n\n【3】We found that 168 implants (44 percent) were definitely indicated, 137 (36 percent) possibly indicated, and 77 (20 percent) not indicated. Unwarranted implantation was both prevalent (73 percent of hospitals had an incidence of 10 percent or more) and independent of the type of hospital (university teaching, university-affiliated, and community hospitals). The additional tests most often required to clarify the need for a pacemaker in inadequately evaluated cases included electrophysiologic studies (37 percent) and ambulatory monitoring (31 percent).\n\n【4】We conclude that in a large medical population in 1983, the indications for a considerable number of permanent pacemakers were inadequate or incompletely documented.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:52:14", "endTime": "2024/08/14 15:52:24", "cost": 9.999}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 23:52:24", "grab_time": "2024-08-13 23:52:13"}
{"id": 2234429, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "5d5a3e58-71a9-4be9-a5e3-65b94e015a52", "title": "200th Anniversary Article: Therapeutic Evolution and the Challenge of Rational Medicine", "text": "【0】200th Anniversary Article: Therapeutic Evolution and the Challenge of Rational Medicine\nIntroduction\n------------\n\n【1】### Interactive Graphic\n\n【2】 Evolving Therapeutics\n\n【3】Figure 1. Bloodletting in the Early 19th Century.\n\n【4】This caricature by James Gillray (1757–1815) illustrates the common practice of bloodletting (“breathing a vein”) to help cure disease. (Published by H. Humphrey, St. James's Street, London, January 28, 1804.)Figure 2.  Figure 2. The Asafetida Plant.\n\n【5】The resin obtained from this plant, also known as “Devil's dung” because of its putrid odor, was used in a wide variety of therapeutics. A knowledge of botany, including illustrated guides to medicinal plants, was considered essential to medical practice in the early 19th century. (Published by Dr. Woodville, February 1, 1790.)\n\n【6】The first article in the inaugural issue of the _New England Journal of Medicine and Surgery,_ in January 1812, was a treatise on angina pectoris by John Warren, a founding member of Harvard Medical School. Warren's clinical descriptions should still sound familiar to anyone who has treated coronary artery disease. His therapeutic strategies, in contrast, appear downright bizarre. He treated one patient, a “plethoric” clergyman, with stimulants, bloodletting , and topical ether, then with more bloodletting, opium, powerful laxatives, and caustic agents that blistered the skin over his sternum. As the patient's anginal attacks increased in frequency and intensity, Warren tried asafetida  — a botanical resin known as “Devil's dung” for its sulfuric, excremental smell — and additional caustics such as silver nitrate to provoke draining blisters on his thighs and arms. With the clinical picture worsening, Warren sent his patient on a therapeutic voyage to Georgia, “where he passed the winter, and suffered less violent attacks than in a more northern climate” (1812a; see box for cited _Journal_ articles). When the minister returned to Boston and his attacks again intensified, Warren added arsenic and bled him vigorously, to no avail. Before his patient's death, Warren noted that the minister's condition improved somewhat with the use of tobacco.\n\n【7】Seen at a remove of two centuries, Warren's treatments seem excessive, even futile. Apart from opiates — which still have a role in treating severe angina — they have nothing in common with today's cardiovascular therapeutics. Thrombolytic agents, antiplatelet drugs, beta-blockers, stents, and bypass surgery — the mechanisms of which are understood in many cases at a molecular level — have demonstrably improved the patient's odds of surviving and leading a productive life, even after a major heart attack. Yet an examination of the history of therapeutic practice can do more than simply chart our progress over the past two centuries. It can also demonstrate how change occurs in medicine, revealing what has been gained and what opportunities have been lost along the way.\n\n【8】As generations of physicians have sought more rational bases for medical practice, they have swung between the poles of enthusiasm and skepticism. They have sought therapeutic power and confidence by reducing their scope of vision toward more precise targets of intervention and measures of success, sometimes losing sight in the process of the broader significance of therapy within the lives of patients and populations. A historical approach to therapeutics, as examined through the pages of the _Journal,_ can help to redirect our attention toward the practical context in which medicine has evolved.\n\n【9】Therapeutics in Context\n-----------------------\n\n【10】Although many practices of 19th-century physicians sound macabre to us today, it is important to understand that their therapeutics _actually worked_ — within the context of a very different way of thinking about disease and therapeutic efficacy.  Both patients and doctors in 1812 generally believed that health and disease were related to the balance and free flow of the four humors: blood, phlegm, black bile, and yellow bile. They also shared expectations about therapeutics: a remedy should provoke powerful symptoms to restore balance and flow. A patient who was feverish, flushed, and delirious from malaria could be calmed and cooled, at least to the touch, by bleeding. Patients who were convinced that their suffering stemmed from intestinal obstructions were gratified by the voluminous vomiting and diarrhea that emetics and cathartics produced. Moreover, treatments were tailored to individual characteristics, such as age, habits, occupation, and locale.\n\n【11】Humoral therapeutics took a distinctly American turn in the young republic. Warren's seemingly buckshot therapeutic approach evokes caricatures of the practitioner of “heroic medicine,” an approach commonly associated with Philadelphia's Benjamin Rush. Heroic medicine employed dramatic interventions to “shock” the body back into a state of humoral balance and health. The more dire the disease, the more heroic the intervention.\n\n【12】An 1812 article in the _Journal_ advised “copious bleeding” of patients with gunshot wounds — a therapeutic strategy that seems oxymoronic until we recall that physicians' principal concern (once the initial hemorrhage was stayed) lay in preventing suppuration and gangrene. Since these processes were known to follow inflammation and fever, and bloodletting reduced visible signs of both, physicians had a moral imperative to bleed as much as was tolerable in order to save life and limb (1812d). Therapeutic rationality took many forms.\n\n【13】Skepticism, Enthusiasm, and the Therapeutic Imperative\n------------------------------------------------------\n\n【14】The _Journal_ 's inaugural issue featured a largely favorable review of Rush's teachings, along with the lament that “were our knowledge of diseases and their treatment as definite as our acquaintance with the forms and laws of matter; there would be neither doubt nor diversity in medical practice, and mankind would be entitled to reach the allotted period of three score years and ten” (1812c).\n\n【15】Yet doubt and diversity were on the rise. Boston soon became home to a skeptical practice style that directly disparaged Rush's heroic approach. Even in the _Journal_ 's first issue, Jacob Bigelow critiqued the varied rationales justifying existing treatments for burns and appealed for empirical evidence to support the “ _negative mode_ of treating burns, which should consist in letting them alone, or in leaving the process to nature” (1812b). Bigelow would later elaborate his thoughts on the _vis medicatrix naturae,_ the “healing force of nature,” in the oft-cited “Discourse on Self-Limited Diseases” (1835).\n\n【16】Many factors fostered the spread of skepticism about therapeutics during the first half of the 19th century. American doctors admired the work of Pierre Louis and the “numerical method” taught at La Charité Hospital in Paris, where Louis tallied up outcomes in patients with pneumonia who were treated with or without bloodletting and found no measurable difference. The local marketplace played a role as well: “regular” physicians faced competition from homeopaths, hydropaths, naturopaths, eccentrics, and other sectarians who lampooned the traditional devotion to the lancet and offered less painful alternatives. By the _Journal_ 's 50th anniversary, the _vis medicatrix naturae_ had become so central to U.S. therapeutic practice that Harvard's John Ware devoted the first 2 parts of a 21-part series on “General Therapeutics” to explicating the concept (1861). The philosophy of therapeutic skepticism was perhaps most famously articulated by Oliver Wendell Holmes, who remarked in 1860 that “if the whole materia medica, _as now used,_ could be sunk to the bottom of the sea, it would be all the better for mankind — and all the worse for the fishes” (2009).\n\n【17】Though therapeutic skepticism was an animating force in American medicine, its more extreme incarnation, therapeutic nihilism, was never a viable solution for physicians. Doctors could not abandon heroic medicine overnight simply on the basis of numerical “proof” that bloodletting didn't work — for no doctor worthy of the title could morally countenance doing nothing when confronted with suffering patients. Therapeutics, embedded in both matters of proof and matters of practice, could change only as much as medical theory and patient expectations allowed. As Holmes observed, “there is a changeable as well as a permanent element in the art of healing; not merely changeable as diseases vary, or as new remedies are introduced, but changeable by the going out of fashion of special remedies, by the decadence of popular theory from which their fitness was deduced, or other cause not more significant” (2009).\n\n【18】Heroic therapies faded only as physicians shifted their enthusiasm to new interventions — notably, quinine, alcohol, and other purported stimulants — in the mid-to-late 19th century.  Quinine, for instance, became popular as both a specific treatment for malaria and a general “tonic.” Just as cathartics and bleeding made sense to doctors concerned about fever, obstruction, and humoral balance, quinine and other stimulants made sense in a medical world increasingly dominated by consumption and other diseases characterized by loss of vital energies. And mid-19th-century physicians didn't abandon the iconic forms of heroic therapeutics — mercury and the lancet — without a fight. Even as Union Army physicians used less and less calomel in coping with Civil War casualties, they rallied to court-martial the Surgeon General in 1863 after he moved to ban the use of this mercury compound. And even after physicians had tempered their heroic therapies, they remained committed to tailoring remedies to patients' idiosyncrasies.\n\n【19】Therapeutic Revolutions\n-----------------------\n\n【20】By the mid-19th century, however, the focus on patients' particularities began to give way to interest in the specific causes of disease. Motivated by breakthroughs in cellular pathology, pathophysiology, and especially bacteriology, doctors increasingly came to see diseases as specific entities, each with its own specific causes, manifested as characteristic syndromes. This new model prompted doctors to seek therapies tailored to the disease and not the patient.  This transformation, like other “therapeutic revolutions,” took a complex course. Old ideas about therapeutic skepticism and individualization endured, and the promise of new therapies often didn't materialize for decades.\n\n【21】Consider the “revolution” launched by William Morton's 1846 demonstration of ether anesthesia at Massachusetts General Hospital. Described in the _Journal_ on November 18, 1846, ether anesthesia was one of the first significant medical discoveries to cross the Atlantic from west to east and transform medical practice in both North America and Europe (1846). The transformation was, however, neither rapid nor smooth. Anesthesia enabled dramatic innovation in surgery, but it also increased the dangers of surgery. Before the use of antiseptic and aseptic techniques, operative mortality and postoperative infections took a staggering toll, as any Civil War surgeon could recount. Many surgeons, long inured to the pain they inflicted, wondered whether pain relief justified the unknown risks from the new anesthetic agents. Surgical decision making required a delicate “calculus of suffering” in which the surgeon weighed the factors in each case, and the anesthetic “revolution” followed a more halting course than one might imagine. \n\n【22】By the _Journal_ 's centennial in 1912, however, surgeons had mastered aseptic techniques and the rituals of the modern operating room. The _Journal_ abounded with accounts of innovations in abdominal surgery (1912b, 1912c), vascular surgery (1912d), orthopedic surgery (1912e), obstetric and gynecologic surgery (1912g), and thoracic surgery (1912j) that had previously been inconceivable. The revolution in surgery required not just ether but a careful articulation of diverse processes — anesthesia and asepsis, but also the choreography of surgeons, anesthetists, scrub nurses, linens, autoclaves, and redesigned hospitals. Even those revolutions that in retrospect seem most obvious followed a complicated course.\n\n【23】Figure 3. An Ampule Containing Salvarsan, and Its Chemical Structure.\n\n【24】The arsenical compound Salvarsan (widely known as Compound 606) was synthesized and tested by Ehrlich and his assistants and was used to treat syphilis.\n\n【25】A similar story played out in the realm of pharmacotherapy in the early 20th century. During the _Journal_ 's centennial year, there were effusive reports on the innovations in antibacterial chemotherapy emerging from the Berlin laboratory of Paul Ehrlich, who sought a “magic bullet” — a specific therapeutic that would selectively poison a pathogenic microbe while leaving the host unharmed. After 605 failures, the antisyphilitic Compound 606 — Salvarsan — was widely hailed when it was launched (2011a) . By 1912, Salvarsan was available in large quantities to most U.S. physicians and patients.\n\n【26】Salvarsan became an exemplar of the new strategy whereby treatments were tailored not to individual patients but to specific diseases. Yet, revisited today, the 1912 accounts of Salvarsan in the _Journal_ challenge simple interpretations of therapeutic revolution. Doctors struggled to develop safe ways to deliver the intravenous medication (1912i). They lamented that Salvarsan's specificity was more theoretical than empirical: the drug clearly did not work against all cases of syphilis (1912f, 1912h). Its effects were not nearly as specific to _Treponema pallidum_ as had been hoped: patients often had terrible side effects from the arsenical compound. Nor did it transform therapeutic practice overnight: instead of replacing mercury with Salvarsan, many doctors used the new drug alongside calomel.\n\n【27】Salvarsan also showed the conceptual limits of a reductionist approach to medicine. Syphilis was not simply a collection of signs and symptoms that followed infection by a particular pathogen. It was a complex social phenomenon, involving shame, stigma, and other moral complications associated with sexually transmitted infection.  Although Salvarsan provided relief to some patients, it offered only a partial solution to a complex disease. Preserved in the archives of the _Journal_ for that year are the voices of physicians who worried that too much of traditional practice had been lost in focusing on treating diseases and not patients. Should not students, one author worried, “also be taught the art of relieving, of soothing and comforting those who suffer, and of steadying and supporting those who walk in the valley of the shadow?” (1912a).\n\n【28】Therapeutic Skepticism Revisited\n--------------------------------\n\n【29】Pharmaceutical progress accelerated dramatically between the 1940s and the 1960s. Even in the context of other 20th-century therapeutic revolutions — such as psychoanalysis and cardiac surgery — the midcentury surge in pharmaceutical therapy stands out. More than 4500 new drug products entered the U.S. market in the 1950s as industry churned out new classes of therapeutic agents: broad-spectrum antibiotics, antidiabetic agents, antihypertensives, antipsychotics, antidepressants, and cholesterol-lowering medications. Of every dollar spent on pharmaceuticals in 1961, 70 cents went to drugs that had been unavailable just 10 years earlier (1962a).\n\n【30】Figure 4. A 1960 Advertisement for Tain.\n\n【31】The combination antibiotic Tain was advertised for the treatment of colds, which by the early 1960s was already considered inappropriate by infectious disease experts.\n\n【32】This new enthusiasm provoked new forms of skepticism. By the _Journal_ 's sesquicentennial year, Louis Goodman and other clinical pharmacologists echoed Holmes in bemoaning the “therapeutic jungle” of the 1950s wonder drugs. Other critics were concerned by what they saw as the “brainwashing” of clinicians by pharmaceutical marketing . These concerns were reflected in televised hearings on the marketing practices of the prescription-drug industry orchestrated by Senator Estes Kefauver from 1959 to 1962. The _Journal_ offered blow-by-blow coverage of the hearings, focusing on the need for the Food and Drug Administration to formally adjudicate therapeutic efficacy and transform the research and development process (1960a, 1960b, 1961a, 1961b, 1961c).\n\n【33】However, passage of the Kefauver–Harris Amendments of 1962, which gave rise to the structure of phase 1, 2, and 3 clinical trials for demonstrating therapeutic efficacy, owed as much to the thalidomide tragedy as to Kefauver's efforts. The horrors of thalidomide, the sedative–antinauseant that caused limb-reduction malformations in children of women who took the drug while pregnant, extended beyond the drug itself (2011b); as a _Journal_ editorial noted, given the furious pace of pharmaceutical development, marketing, and consumption, “only continued and increasing vigilance can prevent the experience from being repeated” (1962b). Outside the medical profession, thalidomide would inspire even more nihilistic perspectives, embodied in popular works such as Morton Mintz's _The Therapeutic Nightmare_ and Ivan Illich's _Medical Nemesis_ . The specter of iatrogenesis these books invoked continues to haunt practice, from thalidomide to Vioxx, from DES to Avandia.\n\n【34】Extending this renaissance of skepticism, some questioned the overall role of medicine itself in improving public health. In 1962, the physician-demographer Thomas McKeown published an analysis of the decline of tuberculosis in England and Wales.  Noting that the decline had begun before the bacillus was discovered and had nearly concluded before streptomycin was developed, McKeown argued that modern therapeutics had been falsely credited with public health improvements that could be better explained by secular changes in nutrition and standards of living. Similarly, those attempting to bring the benefits of modern tuberculosis drugs to impoverished populations in the 1960s realized that drugs were necessary but not sufficient for transforming health — a lesson that would be relearned through global efforts to treat malaria, tuberculosis, and HIV infection in the 21st century (2006). \n\n【35】Recontextualizing Therapeutics\n------------------------------\n\n【36】From the leeches, lancets, and purgatives of the early 1800s to today's targeted molecular medicines, doctors have constantly sought new and better therapies. Yet the evolution of the field of therapeutics has not been linear, and none of the therapeutic revolutions of the past two centuries have been immediate or complete. Rather, our field's progress owes as much to changing forms of therapeutic skepticism as to changing forms of therapeutic enthusiasm.\n\n【37】As the locus of disease has narrowed from the afflicted person to the molecular mechanism, and the target of magic bullets has followed suit, physicians have faced regular reminders of the limits of the reductionist approach. The history of therapeutics offers a space to reflect on these more subtle logics of medical knowledge and practice, restoring our appreciation for the breadth of the physician's task and the complexity of our mission.\n\n【38】Historical _Journal_ Articles Cited.\n------------------------------------\n\n【39】_New England Journal of Medicine and Surgery, and the Collateral Branches of Science_\n\n【40】1812a. Warren J. Remarks on angina pectoris. -11\\. opens in new tab\n\n【41】1812b. Bigelow J. Observations and experiments on the treatment of injuries occasioned by fire and heated substances. -64\\. opens in new tab\n\n【42】1812c. Sixteen introductory lectures, to courses of lectures upon the institutes and practice of medicine, with a syllabus of the latter. To which are added, two lectures upon the pleasures of the senses and of the mind, with an inquiry into their proximate cause. Delivered in the University of Pennsylvania. By Benjamin Rush, M.D. Philadelphia; Bradford and Innskeep, 1811. (Book review.) -6\\. opens in new tab\n\n【43】1812d. On gun-shot wounds. -58\\. opens in new tab\n\n【44】_Boston Medical and Surgical Journal_\n\n【45】1835\\. Dr. Bigelow's discourse. -5\\. opens in new tab\n\n【46】1846\\. Bigelow HJ. Insensibility during surgical operations produced by inhalation. -17\\. opens in new tab\n\n【47】1861\\. Ware J. Lectures on general therapeutics. -97\\. opens in new tab\n\n【48】1912a. Worcester A. Past and present methods in the practice of medicine. -64\\. opens in new tab\n\n【49】1912b. Clinical lectures on the acute abdomen. By William Henry Battle. New York: William Wood and Co., 1911. (Book review.) \\. opens in new tab\n\n【50】1912c. Morse GW. Three unusual cases of appendicitis. -9\\. opens in new tab\n\n【51】1912d. Blood vessel surgery and its application. By A.C. Guthrie. New York: Longmans, Green, and Co., 1912. (Book review)\\. opens in new tab\n\n【52】1912e. Osgood RB, Soutter R, Bucholz H, Danforth MS. Report of progress in orthopedic surgery. -8\\. opens in new tab\n\n【53】1912f. Post A. The present status of Salvarsan. -3\\. opens in new tab\n\n【54】1912g. Newell FS. Indications for the major obstetrical operations. -9\\. opens in new tab\n\n【55】1912h. Boos WF. The Salvarsan–calomel treatment of syphilis. -93\\. opens in new tab\n\n【56】1912i. McGurn WJ. A new device for the safe and certain administration of Salvarsan. -9\\. opens in new tab\n\n【57】1912j. Balboni GM. The treatment of pulmonary tuberculosis by artificial pneumothorax, according to the method of Forlanini — with a report of twenty-one cases. -33\\. opens in new tab\n\n【58】_New England Journal of Medicine_\n\n【59】1960a. Perles of great price\\. opens in new tab\n\n【60】1960b. The life of trade. -8\\. opens in new tab\n\n【61】1961a. Dowling HF. The pharmaceutical industry and the doctor. -9\\. opens in new tab\n\n【62】1961b. Senator Kefauver presents his bill. -3\\. opens in new tab\n\n【63】1961c. Ethical drugs — reflections on the inquiry. -6\\. opens in new tab\n\n【64】1962a. New products parade\\. opens in new tab\n\n【65】1962b. A sleep but no forgetting. -8\\. opens in new tab\n\n【66】2006\\. Kim JY, Farmer P. AIDS in 2006 — moving toward one world, one hope? -7\\. opens in new tab\n\n【67】2009\\. Bryan CS, Podolsky SH. Dr. Holmes at 200 — the spirit of skepticism. -7\\. opens in new tab\n\n【68】2011a. Sepkowitz KA. One hundred years of Salvarsan. -3\\. opens in new tab\n\n【69】2011b. Avorn J. Learning about the safety of drugs — A half-century of evolution. -3\\. opens in new tab", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "【38】Historical Journal Articles Cited.\n【39】New England Journal of Medicine and Surgery, and the Collateral Branches of Science\n\n【40】1812a. Warren J. Remarks on angina pectoris. -11. opens in new tab\n\n【41】1812b. Bigelow J. Observations and experiments on the treatment of injuries occasioned by fire and heated substances. -64. opens in new tab\n\n【42】1812c. Sixteen introductory lectures, to courses of lectures upon the institutes and practice of medicine, with a syllabus of the latter. To which are added, two lectures upon the pleasures of the senses and of the mind, with an inquiry into their proximate cause. Delivered in the University of Pennsylvania. By Benjamin Rush, M.D. Philadelphia; Bradford and Innskeep, 1811. (Book review.) -6. opens in new tab\n\n【43】1812d. On gun-shot wounds. -58. opens in new tab\n\n【44】Boston Medical and Surgical Journal\n\n【45】1835. Dr. Bigelow’s discourse. -5. opens in new tab\n\n【46】1846. Bigelow HJ. Insensibility during surgical operations produced by inhalation. -17. opens in new tab\n\n【47】1861. Ware J. Lectures on general therapeutics. -97. opens in new tab\n\n【48】1912a. Worcester A. Past and present methods in the practice of medicine. -64. opens in new tab\n\n【49】1912b. Clinical lectures on the acute abdomen. By William Henry Battle. New York: William Wood and Co., 1911. (Book review.) . opens in new tab\n\n【50】1912c. Morse GW. Three unusual cases of appendicitis. -9. opens in new tab\n\n【51】1912d. Blood vessel surgery and its application. By A.C. Guthrie. New York: Longmans, Green, and Co., 1912. (Book review). opens in new tab\n\n【52】1912e. Osgood RB, Soutter R, Bucholz H, Danforth MS. Report of progress in orthopedic surgery. -8. opens in new tab\n\n【53】1912f. Post A. The present status of Salvarsan. -3. opens in new tab\n\n【54】1912g. Newell FS. Indications for the major obstetrical operations. -9. opens in new tab\n\n【55】1912h. Boos WF. The Salvarsan–calomel treatment of syphilis. -93. opens in new tab\n\n【56】1912i. McGurn WJ. A new device for the safe and certain administration of Salvarsan. -9. opens in new tab\n\n【57】1912j. Balboni GM. The treatment of pulmonary tuberculosis by artificial pneumothorax, according to the method of Forlanini — with a report of twenty-one cases. -33. opens in new tab\n\n【58】New England Journal of Medicine\n\n【59】1960a. Perles of great price. opens in new tab\n\n【60】1960b. The life of trade. -8. opens in new tab\n\n【61】1961a. Dowling HF. The pharmaceutical industry and the doctor. -9. opens in new tab\n\n【62】1961b. Senator Kefauver presents his bill. -3. opens in new tab\n\n【63】1961c. Ethical drugs — reflections on the inquiry. -6. opens in new tab\n\n【64】1962a. New products parade. opens in new tab\n\n【65】1962b. A sleep but no forgetting. -8. opens in new tab\n\n【66】2006. Kim JY, Farmer P. AIDS in 2006 — moving toward one world, one hope? -7. opens in new tab\n\n【67】2009. Bryan CS, Podolsky SH. Dr. Holmes at 200 — the spirit of skepticism. -7. opens in new tab\n\n【68】2011a. Sepkowitz KA. One hundred years of Salvarsan. -3. opens in new tab\n\n【69】2011b. Avorn J. Learning about the safety of drugs — A half-century of evolution. -3. opens in new tab\n\n\n备注\n【3】Figure 1.\n\n文本干净度 / 无关文本\n\n", "content": "【0】200th Anniversary Article: Therapeutic Evolution and the Challenge of Rational Medicine\nIntroduction\n------------\n\n【1】### Interactive Graphic\n\n【2】 Evolving Therapeutics\n\n<mark>【3】Figure 1. </mark>Bloodletting in the Early 19th Century.\n\n【4】This caricature by James Gillray (1757–1815) illustrates the common practice of bloodletting (“breathing a vein”) to help cure disease. (Published by H. Humphrey, St. James's Street, London, January 28, 1804.)Figure 2.  Figure 2. The Asafetida Plant.\n\n【5】The resin obtained from this plant, also known as “Devil's dung” because of its putrid odor, was used in a wide variety of therapeutics. A knowledge of botany, including illustrated guides to medicinal plants, was considered essential to medical practice in the early 19th century. (Published by Dr. Woodville, February 1, 1790.)\n\n【6】The first article in the inaugural issue of the _New England Journal of Medicine and Surgery,_ in January 1812, was a treatise on angina pectoris by John Warren, a founding member of Harvard Medical School. Warren's clinical descriptions should still sound familiar to anyone who has treated coronary artery disease. His therapeutic strategies, in contrast, appear downright bizarre. He treated one patient, a “plethoric” clergyman, with stimulants, bloodletting , and topical ether, then with more bloodletting, opium, powerful laxatives, and caustic agents that blistered the skin over his sternum. As the patient's anginal attacks increased in frequency and intensity, Warren tried asafetida  — a botanical resin known as “Devil's dung” for its sulfuric, excremental smell — and additional caustics such as silver nitrate to provoke draining blisters on his thighs and arms. With the clinical picture worsening, Warren sent his patient on a therapeutic voyage to Georgia, “where he passed the winter, and suffered less violent attacks than in a more northern climate” (1812a; see box for cited _Journal_ articles). When the minister returned to Boston and his attacks again intensified, Warren added arsenic and bled him vigorously, to no avail. Before his patient's death, Warren noted that the minister's condition improved somewhat with the use of tobacco.\n\n【7】Seen at a remove of two centuries, Warren's treatments seem excessive, even futile. Apart from opiates — which still have a role in treating severe angina — they have nothing in common with today's cardiovascular therapeutics. Thrombolytic agents, antiplatelet drugs, beta-blockers, stents, and bypass surgery — the mechanisms of which are understood in many cases at a molecular level — have demonstrably improved the patient's odds of surviving and leading a productive life, even after a major heart attack. Yet an examination of the history of therapeutic practice can do more than simply chart our progress over the past two centuries. It can also demonstrate how change occurs in medicine, revealing what has been gained and what opportunities have been lost along the way.\n\n【8】As generations of physicians have sought more rational bases for medical practice, they have swung between the poles of enthusiasm and skepticism. They have sought therapeutic power and confidence by reducing their scope of vision toward more precise targets of intervention and measures of success, sometimes losing sight in the process of the broader significance of therapy within the lives of patients and populations. A historical approach to therapeutics, as examined through the pages of the _Journal,_ can help to redirect our attention toward the practical context in which medicine has evolved.\n\n【9】Therapeutics in Context\n-----------------------\n\n【10】Although many practices of 19th-century physicians sound macabre to us today, it is important to understand that their therapeutics _actually worked_ — within the context of a very different way of thinking about disease and therapeutic efficacy.  Both patients and doctors in 1812 generally believed that health and disease were related to the balance and free flow of the four humors: blood, phlegm, black bile, and yellow bile. They also shared expectations about therapeutics: a remedy should provoke powerful symptoms to restore balance and flow. A patient who was feverish, flushed, and delirious from malaria could be calmed and cooled, at least to the touch, by bleeding. Patients who were convinced that their suffering stemmed from intestinal obstructions were gratified by the voluminous vomiting and diarrhea that emetics and cathartics produced. Moreover, treatments were tailored to individual characteristics, such as age, habits, occupation, and locale.\n\n【11】Humoral therapeutics took a distinctly American turn in the young republic. Warren's seemingly buckshot therapeutic approach evokes caricatures of the practitioner of “heroic medicine,” an approach commonly associated with Philadelphia's Benjamin Rush. Heroic medicine employed dramatic interventions to “shock” the body back into a state of humoral balance and health. The more dire the disease, the more heroic the intervention.\n\n【12】An 1812 article in the _Journal_ advised “copious bleeding” of patients with gunshot wounds — a therapeutic strategy that seems oxymoronic until we recall that physicians' principal concern (once the initial hemorrhage was stayed) lay in preventing suppuration and gangrene. Since these processes were known to follow inflammation and fever, and bloodletting reduced visible signs of both, physicians had a moral imperative to bleed as much as was tolerable in order to save life and limb (1812d). Therapeutic rationality took many forms.\n\n【13】Skepticism, Enthusiasm, and the Therapeutic Imperative\n------------------------------------------------------\n\n【14】The _Journal_ 's inaugural issue featured a largely favorable review of Rush's teachings, along with the lament that “were our knowledge of diseases and their treatment as definite as our acquaintance with the forms and laws of matter; there would be neither doubt nor diversity in medical practice, and mankind would be entitled to reach the allotted period of three score years and ten” (1812c).\n\n【15】Yet doubt and diversity were on the rise. Boston soon became home to a skeptical practice style that directly disparaged Rush's heroic approach. Even in the _Journal_ 's first issue, Jacob Bigelow critiqued the varied rationales justifying existing treatments for burns and appealed for empirical evidence to support the “ _negative mode_ of treating burns, which should consist in letting them alone, or in leaving the process to nature” (1812b). Bigelow would later elaborate his thoughts on the _vis medicatrix naturae,_ the “healing force of nature,” in the oft-cited “Discourse on Self-Limited Diseases” (1835).\n\n【16】Many factors fostered the spread of skepticism about therapeutics during the first half of the 19th century. American doctors admired the work of Pierre Louis and the “numerical method” taught at La Charité Hospital in Paris, where Louis tallied up outcomes in patients with pneumonia who were treated with or without bloodletting and found no measurable difference. The local marketplace played a role as well: “regular” physicians faced competition from homeopaths, hydropaths, naturopaths, eccentrics, and other sectarians who lampooned the traditional devotion to the lancet and offered less painful alternatives. By the _Journal_ 's 50th anniversary, the _vis medicatrix naturae_ had become so central to U.S. therapeutic practice that Harvard's John Ware devoted the first 2 parts of a 21-part series on “General Therapeutics” to explicating the concept (1861). The philosophy of therapeutic skepticism was perhaps most famously articulated by Oliver Wendell Holmes, who remarked in 1860 that “if the whole materia medica, _as now used,_ could be sunk to the bottom of the sea, it would be all the better for mankind — and all the worse for the fishes” (2009).\n\n【17】Though therapeutic skepticism was an animating force in American medicine, its more extreme incarnation, therapeutic nihilism, was never a viable solution for physicians. Doctors could not abandon heroic medicine overnight simply on the basis of numerical “proof” that bloodletting didn't work — for no doctor worthy of the title could morally countenance doing nothing when confronted with suffering patients. Therapeutics, embedded in both matters of proof and matters of practice, could change only as much as medical theory and patient expectations allowed. As Holmes observed, “there is a changeable as well as a permanent element in the art of healing; not merely changeable as diseases vary, or as new remedies are introduced, but changeable by the going out of fashion of special remedies, by the decadence of popular theory from which their fitness was deduced, or other cause not more significant” (2009).\n\n【18】Heroic therapies faded only as physicians shifted their enthusiasm to new interventions — notably, quinine, alcohol, and other purported stimulants — in the mid-to-late 19th century.  Quinine, for instance, became popular as both a specific treatment for malaria and a general “tonic.” Just as cathartics and bleeding made sense to doctors concerned about fever, obstruction, and humoral balance, quinine and other stimulants made sense in a medical world increasingly dominated by consumption and other diseases characterized by loss of vital energies. And mid-19th-century physicians didn't abandon the iconic forms of heroic therapeutics — mercury and the lancet — without a fight. Even as Union Army physicians used less and less calomel in coping with Civil War casualties, they rallied to court-martial the Surgeon General in 1863 after he moved to ban the use of this mercury compound. And even after physicians had tempered their heroic therapies, they remained committed to tailoring remedies to patients' idiosyncrasies.\n\n【19】Therapeutic Revolutions\n-----------------------\n\n【20】By the mid-19th century, however, the focus on patients' particularities began to give way to interest in the specific causes of disease. Motivated by breakthroughs in cellular pathology, pathophysiology, and especially bacteriology, doctors increasingly came to see diseases as specific entities, each with its own specific causes, manifested as characteristic syndromes. This new model prompted doctors to seek therapies tailored to the disease and not the patient.  This transformation, like other “therapeutic revolutions,” took a complex course. Old ideas about therapeutic skepticism and individualization endured, and the promise of new therapies often didn't materialize for decades.\n\n【21】Consider the “revolution” launched by William Morton's 1846 demonstration of ether anesthesia at Massachusetts General Hospital. Described in the _Journal_ on November 18, 1846, ether anesthesia was one of the first significant medical discoveries to cross the Atlantic from west to east and transform medical practice in both North America and Europe (1846). The transformation was, however, neither rapid nor smooth. Anesthesia enabled dramatic innovation in surgery, but it also increased the dangers of surgery. Before the use of antiseptic and aseptic techniques, operative mortality and postoperative infections took a staggering toll, as any Civil War surgeon could recount. Many surgeons, long inured to the pain they inflicted, wondered whether pain relief justified the unknown risks from the new anesthetic agents. Surgical decision making required a delicate “calculus of suffering” in which the surgeon weighed the factors in each case, and the anesthetic “revolution” followed a more halting course than one might imagine. \n\n【22】By the _Journal_ 's centennial in 1912, however, surgeons had mastered aseptic techniques and the rituals of the modern operating room. The _Journal_ abounded with accounts of innovations in abdominal surgery (1912b, 1912c), vascular surgery (1912d), orthopedic surgery (1912e), obstetric and gynecologic surgery (1912g), and thoracic surgery (1912j) that had previously been inconceivable. The revolution in surgery required not just ether but a careful articulation of diverse processes — anesthesia and asepsis, but also the choreography of surgeons, anesthetists, scrub nurses, linens, autoclaves, and redesigned hospitals. Even those revolutions that in retrospect seem most obvious followed a complicated course.\n\n【23】Figure 3. An Ampule Containing Salvarsan, and Its Chemical Structure.\n\n【24】The arsenical compound Salvarsan (widely known as Compound 606) was synthesized and tested by Ehrlich and his assistants and was used to treat syphilis.\n\n【25】A similar story played out in the realm of pharmacotherapy in the early 20th century. During the _Journal_ 's centennial year, there were effusive reports on the innovations in antibacterial chemotherapy emerging from the Berlin laboratory of Paul Ehrlich, who sought a “magic bullet” — a specific therapeutic that would selectively poison a pathogenic microbe while leaving the host unharmed. After 605 failures, the antisyphilitic Compound 606 — Salvarsan — was widely hailed when it was launched (2011a) . By 1912, Salvarsan was available in large quantities to most U.S. physicians and patients.\n\n【26】Salvarsan became an exemplar of the new strategy whereby treatments were tailored not to individual patients but to specific diseases. Yet, revisited today, the 1912 accounts of Salvarsan in the _Journal_ challenge simple interpretations of therapeutic revolution. Doctors struggled to develop safe ways to deliver the intravenous medication (1912i). They lamented that Salvarsan's specificity was more theoretical than empirical: the drug clearly did not work against all cases of syphilis (1912f, 1912h). Its effects were not nearly as specific to _Treponema pallidum_ as had been hoped: patients often had terrible side effects from the arsenical compound. Nor did it transform therapeutic practice overnight: instead of replacing mercury with Salvarsan, many doctors used the new drug alongside calomel.\n\n【27】Salvarsan also showed the conceptual limits of a reductionist approach to medicine. Syphilis was not simply a collection of signs and symptoms that followed infection by a particular pathogen. It was a complex social phenomenon, involving shame, stigma, and other moral complications associated with sexually transmitted infection.  Although Salvarsan provided relief to some patients, it offered only a partial solution to a complex disease. Preserved in the archives of the _Journal_ for that year are the voices of physicians who worried that too much of traditional practice had been lost in focusing on treating diseases and not patients. Should not students, one author worried, “also be taught the art of relieving, of soothing and comforting those who suffer, and of steadying and supporting those who walk in the valley of the shadow?” (1912a).\n\n【28】Therapeutic Skepticism Revisited\n--------------------------------\n\n【29】Pharmaceutical progress accelerated dramatically between the 1940s and the 1960s. Even in the context of other 20th-century therapeutic revolutions — such as psychoanalysis and cardiac surgery — the midcentury surge in pharmaceutical therapy stands out. More than 4500 new drug products entered the U.S. market in the 1950s as industry churned out new classes of therapeutic agents: broad-spectrum antibiotics, antidiabetic agents, antihypertensives, antipsychotics, antidepressants, and cholesterol-lowering medications. Of every dollar spent on pharmaceuticals in 1961, 70 cents went to drugs that had been unavailable just 10 years earlier (1962a).\n\n【30】Figure 4. A 1960 Advertisement for Tain.\n\n【31】The combination antibiotic Tain was advertised for the treatment of colds, which by the early 1960s was already considered inappropriate by infectious disease experts.\n\n【32】This new enthusiasm provoked new forms of skepticism. By the _Journal_ 's sesquicentennial year, Louis Goodman and other clinical pharmacologists echoed Holmes in bemoaning the “therapeutic jungle” of the 1950s wonder drugs. Other critics were concerned by what they saw as the “brainwashing” of clinicians by pharmaceutical marketing . These concerns were reflected in televised hearings on the marketing practices of the prescription-drug industry orchestrated by Senator Estes Kefauver from 1959 to 1962. The _Journal_ offered blow-by-blow coverage of the hearings, focusing on the need for the Food and Drug Administration to formally adjudicate therapeutic efficacy and transform the research and development process (1960a, 1960b, 1961a, 1961b, 1961c).\n\n【33】However, passage of the Kefauver–Harris Amendments of 1962, which gave rise to the structure of phase 1, 2, and 3 clinical trials for demonstrating therapeutic efficacy, owed as much to the thalidomide tragedy as to Kefauver's efforts. The horrors of thalidomide, the sedative–antinauseant that caused limb-reduction malformations in children of women who took the drug while pregnant, extended beyond the drug itself (2011b); as a _Journal_ editorial noted, given the furious pace of pharmaceutical development, marketing, and consumption, “only continued and increasing vigilance can prevent the experience from being repeated” (1962b). Outside the medical profession, thalidomide would inspire even more nihilistic perspectives, embodied in popular works such as Morton Mintz's _The Therapeutic Nightmare_ and Ivan Illich's _Medical Nemesis_ . The specter of iatrogenesis these books invoked continues to haunt practice, from thalidomide to Vioxx, from DES to Avandia.\n\n【34】Extending this renaissance of skepticism, some questioned the overall role of medicine itself in improving public health. In 1962, the physician-demographer Thomas McKeown published an analysis of the decline of tuberculosis in England and Wales.  Noting that the decline had begun before the bacillus was discovered and had nearly concluded before streptomycin was developed, McKeown argued that modern therapeutics had been falsely credited with public health improvements that could be better explained by secular changes in nutrition and standards of living. Similarly, those attempting to bring the benefits of modern tuberculosis drugs to impoverished populations in the 1960s realized that drugs were necessary but not sufficient for transforming health — a lesson that would be relearned through global efforts to treat malaria, tuberculosis, and HIV infection in the 21st century (2006). \n\n【35】Recontextualizing Therapeutics\n------------------------------\n\n【36】From the leeches, lancets, and purgatives of the early 1800s to today's targeted molecular medicines, doctors have constantly sought new and better therapies. Yet the evolution of the field of therapeutics has not been linear, and none of the therapeutic revolutions of the past two centuries have been immediate or complete. Rather, our field's progress owes as much to changing forms of therapeutic skepticism as to changing forms of therapeutic enthusiasm.\n\n【37】As the locus of disease has narrowed from the afflicted person to the molecular mechanism, and the target of magic bullets has followed suit, physicians have faced regular reminders of the limits of the reductionist approach. The history of therapeutics offers a space to reflect on these more subtle logics of medical knowledge and practice, restoring our appreciation for the breadth of the physician's task and the complexity of our mission.\n\n【38】Historical _Journal_ Articles Cited.\n------------------------------------\n\n【39】_New England Journal of Medicine and Surgery, and the Collateral Branches of Science_\n\n【40】1812a. Warren J. Remarks on angina pectoris. -11\\. opens in new tab\n\n【41】1812b. Bigelow J. Observations and experiments on the treatment of injuries occasioned by fire and heated substances. -64\\. opens in new tab\n\n【42】1812c. Sixteen introductory lectures, to courses of lectures upon the institutes and practice of medicine, with a syllabus of the latter. To which are added, two lectures upon the pleasures of the senses and of the mind, with an inquiry into their proximate cause. Delivered in the University of Pennsylvania. By Benjamin Rush, M.D. Philadelphia; Bradford and Innskeep, 1811. (Book review.) -6\\. opens in new tab\n\n【43】1812d. On gun-shot wounds. -58\\. opens in new tab\n\n【44】_Boston Medical and Surgical Journal_\n\n【45】1835\\. Dr. Bigelow's discourse. -5\\. opens in new tab\n\n【46】1846\\. Bigelow HJ. Insensibility during surgical operations produced by inhalation. -17\\. opens in new tab\n\n【47】1861\\. Ware J. Lectures on general therapeutics. -97\\. opens in new tab\n\n【48】1912a. Worcester A. Past and present methods in the practice of medicine. -64\\. opens in new tab\n\n【49】1912b. Clinical lectures on the acute abdomen. By William Henry Battle. New York: William Wood and Co., 1911. (Book review.) \\. opens in new tab\n\n【50】1912c. Morse GW. Three unusual cases of appendicitis. -9\\. opens in new tab\n\n【51】1912d. Blood vessel surgery and its application. By A.C. Guthrie. New York: Longmans, Green, and Co., 1912. (Book review)\\. opens in new tab\n\n【52】1912e. Osgood RB, Soutter R, Bucholz H, Danforth MS. Report of progress in orthopedic surgery. -8\\. opens in new tab\n\n【53】1912f. Post A. The present status of Salvarsan. -3\\. opens in new tab\n\n【54】1912g. Newell FS. Indications for the major obstetrical operations. -9\\. opens in new tab\n\n【55】1912h. Boos WF. The Salvarsan–calomel treatment of syphilis. -93\\. opens in new tab\n\n【56】1912i. McGurn WJ. A new device for the safe and certain administration of Salvarsan. -9\\. opens in new tab\n\n【57】1912j. Balboni GM. The treatment of pulmonary tuberculosis by artificial pneumothorax, according to the method of Forlanini — with a report of twenty-one cases. -33\\. opens in new tab\n\n【58】_New England Journal of Medicine_\n\n【59】1960a. Perles of great price\\. opens in new tab\n\n【60】1960b. The life of trade. -8\\. opens in new tab\n\n【61】1961a. Dowling HF. The pharmaceutical industry and the doctor. -9\\. opens in new tab\n\n【62】1961b. Senator Kefauver presents his bill. -3\\. opens in new tab\n\n【63】1961c. Ethical drugs — reflections on the inquiry. -6\\. opens in new tab\n\n【64】1962a. New products parade\\. opens in new tab\n\n【65】1962b. A sleep but no forgetting. -8\\. opens in new tab\n\n【66】2006\\. Kim JY, Farmer P. AIDS in 2006 — moving toward one world, one hope? -7\\. opens in new tab\n\n【67】2009\\. Bryan CS, Podolsky SH. Dr. Holmes at 200 — the spirit of skepticism. -7\\. opens in new tab\n\n【68】2011a. Sepkowitz KA. One hundred years of Salvarsan. -3\\. opens in new tab\n\n【69】2011b. Avorn J. Learning about the safety of drugs — A half-century of evolution. -3\\. opens in new tab", "index": 19465, "show": true, "start": 19452, "end": 22608, "province": ["文本干净度", "无关文本"], "isEdit": false}]}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-14 00:21:00", "grab_time": "2024-08-13 23:38:57"}
{"id": 2234428, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "029ec347-c810-4b7a-a0fc-e3b07e0a9b54", "title": "Single-Dose Nirsevimab for Prevention of RSV in Preterm Infants", "text": "【0】Single-Dose Nirsevimab for Prevention of RSV in Preterm Infants\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Respiratory syncytial virus (RSV) is the most common cause of lower respiratory tract infection in infants, and a need exists for prevention of RSV in healthy infants. Nirsevimab is a monoclonal antibody with an extended half-life that is being developed to protect infants for an entire RSV season with a single intramuscular dose.\n\n【3】Methods\n-------\n\n【4】In this trial conducted in both northern and southern hemispheres, we evaluated nirsevimab for the prevention of RSV-associated lower respiratory tract infection in healthy infants who had been born preterm (29 weeks 0 days to 34 weeks 6 days of gestation). We randomly assigned the infants in a  ratio to receive nirsevimab, at a dose of 50 mg in a single intramuscular injection, or placebo at the start of an RSV season. The primary end point was medically attended RSV-associated lower respiratory tract infection through 150 days after administration of the dose. The secondary efficacy end point was hospitalization for RSV-associated lower respiratory tract infection through 150 days after administration of the dose.\n\n【5】Results\n-------\n\n【6】From November 2016 through November 2017, a total of 1453 infants were randomly assigned to receive nirsevimab (969 infants) or placebo (484 infants) at the start of the RSV season. The incidence of medically attended RSV-associated lower respiratory tract infection was 70.1% lower (95% confidence interval \\[CI\\], 52.3 to 81.2) with nirsevimab prophylaxis than with placebo (2.6% \\[25 infants\\] vs. 9.5% \\[46 infants\\]; P<0.001) and the incidence of hospitalization for RSV-associated lower respiratory tract infection was 78.4% lower (95% CI, 51.9 to 90.3) with nirsevimab than with placebo (0.8% \\[8 infants\\] vs. 4.1% \\[20 infants\\]; P<0.001). These differences were consistent throughout the 150-day period after the dose was administered and across geographic locations and RSV subtypes. Adverse events were similar in the two trial groups, with no notable hypersensitivity reactions.\n\n【7】Conclusions\n-----------\n\n【8】A single injection of nirsevimab resulted in fewer medically attended RSV-associated lower respiratory tract infections and hospitalizations than placebo throughout the RSV season in healthy preterm infants. \n\n【9】Introduction\n------------\n\n【10】 QUICK TAKE  \nPreventing RSV in Preterm Infants  \n\n【11】Respiratory syncytial virus (RSV) is the most common cause of lower respiratory tract disease and hospitalizations for respiratory illness among infants and young children, resulting in largely predictable annual epidemics worldwide.  RSV is a leading cause of infant deaths, primarily in low-income and middle-income countries.  During the first year of life, infants with a primary RSV infection are at risk for a severe lower respiratory tract infection.  Preterm infants, as well as young children with chronic lung disease of prematurity or congenital heart disease, are at particularly high risk. \n\n【12】Preventing RSV illnesses in all infants is a major public health priority,  but despite more than 50 years of attempts at vaccine development  and extensive ongoing clinical research, there is no safe and effective RSV vaccine.  Passive RSV antibody approaches have been effective in clinical studies.  RSV prophylaxis is currently available as a specific RSV immune globulin G (palivizumab \\[Synagis\\]), administered in five monthly injections, that is licensed for infants who are at highest risk for serious RSV sequelae.  Further restrictive recommendations have been issued by local and national bodies,  limiting prophylaxis to less than 2% of the annual U.S. birth cohort.  Currently, there is no approved RSV prophylaxis for healthy infants. Because the only approved treatment for RSV infection (ribavirin) is difficult to deliver and has limited efficacy,  the standard of care for patients with serious RSV illness is supportive management of the condition. There is a need for RSV prophylaxis in healthy infants.\n\n【13】Nirsevimab, a recombinant human immune globulin G1 kappa monoclonal antibody, binds the highly conserved site 0 epitope present on the prefusion conformation of the RSV fusion protein.  The enhanced neutralizing activity of nirsevimab as compared with palivizumab  and a modification of the Fc region to promote extension of the half-life  support a vaccine-like strategy to protect infants from RSV with doses administered once per RSV season (which typically spans 5 months of the fall and winter). We evaluated a single dose of nirsevimab prophylaxis in healthy preterm infants entering their first RSV season.\n\n【14】Methods\n-------\n\n【15】Participants\n------------\n\n【16】Participants were healthy infants who had been born preterm (gestational age of 29 weeks 0 days through 34 weeks 6 days) and who were 1 year of age or younger and entering their first full RSV season. European Union participants had to be 8 months of age or younger. Participants were excluded if they met local, national, or American Academy of Pediatrics  recommended guidelines to receive RSV prophylaxis, had an acute illness at the time of randomization, had previously had an RSV infection, or had received palivizumab or any other investigational RSV monoclonal antibody or vaccine, including maternal vaccines (i.e., a vaccine administered to the mother during pregnancy). \n\n【17】Trial Design and Oversight\n--------------------------\n\n【18】Participants were randomly assigned, in a  ratio, to receive one intramuscular injection of 50 mg of nirsevimab or normal saline placebo during a 2-month period immediately before the RSV season. Randomization was stratified by hemisphere (northern or southern) and by age (≤3 months, >3 months to ≤6 months, or >6 months). Participants were monitored for medically attended respiratory illnesses for 150 days after nirsevimab or placebo was administered: by telephone every 2 weeks and in person during trial site visits on days 8, 31, 91, and 151, as well as on day 361 after administration of the dose . Monitoring was performed by site investigators, or if the children were treated elsewhere, their medical records were reviewed by site investigators. If a participant received medical attention at a location other than the trial site, the parents were instructed to take the participant to the trial site for an evaluation of the respiratory illness.\n\n【19】This trial was conducted at 164 sites in 23 countries and was performed in accordance with the provisions of the Declaration of Helsinki and Good Clinical Practice guidelines of the International Conference on Harmonisation. Enrollment by trial site is shown in Table S1. Each site had approval from an institutional review board or ethics committee, and appropriate written informed consent was obtained for each participant. The trial was designed by MedImmune/AstraZeneca, and funding was provided by MedImmune/AstraZeneca and Sanofi Pasteur. Data were collected by clinical investigators and analyzed by AstraZeneca employees. Agreements requiring authors to maintain data confidentiality were in place between AstraZeneca and the authors. The authors made the decision to submit the manuscript for publication and vouch for the accuracy and completeness of the data and for the fidelity of the trial to the protocol. The first author wrote the first draft with assistance from professional medical writers funded by AstraZeneca.\n\n【20】End Points\n----------\n\n【21】The primary end point was medically attended RSV-associated lower respiratory tract infection (inpatient or outpatient) through 150 days after nirsevimab or placebo was administered, and the secondary efficacy end point was hospitalization due to this condition during the same period. The incidence of lower respiratory tract infection of any cause and of respiratory-related hospitalization for any cause was also captured.\n\n【22】Participants who were brought to a health care provider for a respiratory illness (inpatient or outpatient) were evaluated for the occurrence of RSV-associated lower respiratory tract infection. All incidents of medically attended lower respiratory tract infection were evaluated by site investigators, who were unaware of the group assignments, who examined the participants or reviewed their medical reports (if a child had been seen by a provider who was not a trial investigator), and the evaluations were reviewed by trial monitors for completeness and accuracy. According to the prespecified case definition, a lower respiratory tract infection was included in our analysis if an RSV test performed at the central laboratory (Viracor Eurofins Clinical Diagnostics) was positive, a physical examination indicated involvement of the lower respiratory tract, and there was at least one indicator of clinical severity .  A nasopharyngeal sample from participants who had a lower respiratory tract infection or who were hospitalized for any respiratory infection was obtained for testing at the central laboratory. The test was a real-time, reverse-transcriptase–polymerase-chain-reaction (RT-PCR) in vitro diagnostic assay (Lyra RSV + hMPV, Quidel) that had received U.S. Food and Drug Administration clearance and a European Certificate of Conformity (known as the CE mark). After RSV detection by real-time RT-PCR, RSV A and RSV B subtypes were determined by nucleotide sequencing of a 270 bp region of the RSV G gene second hypervariable region and comparison of the sequence to A and B reference strains . Results were included in the analysis if the sample was obtained between 7 days before and 14 days after the participant’s initial visit to a health care provider.\n\n【23】Prespecified analyses of the primary and secondary end points were performed in subgroups defined according to hemisphere, age, sex, race, gestational age, and siblings (twins or triplets) enrolled in the trial. The burden on utilization of health care resources, which included the severity of illness during hospitalization, was an exploratory end point.\n\n【24】Data on adverse events that occurred during the trial period were collected. The adverse events were graded by severity according to the National Cancer Institute Common Terminology Criteria for Adverse Events and assessed for association with the investigational product throughout the trial.\n\n【25】To determine the pharmacokinetics of nirsevimab and the incidence of antidrug antibodies, as described previously,  serum samples were collected before nirsevimab or placebo was administered; on days 91, 151, and 361 after doses were administered; and when participants were hospitalized for respiratory illnesses. A positive titer for antinirsevimab antibody was defined as a titer of  or more. The effect of antidrug antibodies on the pharmacokinetics and efficacy of nirsevimab and their association with adverse events that occurred during treatment were assessed.\n\n【26】Statistical Analyses\n--------------------\n\n【27】Efficacy analyses were performed in the intention-to-treat population (all participants who underwent randomization) according to the randomized treatment assignment. Safety analyses were based on the as-treated population (participants who received any investigational product) according to the investigational product received. The sample size, which we selected to evaluate safety and benefit in the population of preterm infants before proceeding to term infants, had more than 99% power to detect a 70% lower relative risk of medically attended RSV-associated lower respiratory tract infection with nirsevimab than with placebo, at a two-sided significance level of 0.05, under the assumption of an 8% event rate in the placebo group.\n\n【28】Primary and secondary efficacy end points were analyzed with the use of a Poisson regression model with robust variance  as the primary analysis model. The primary end-point analysis included two randomization stratification factors: hemisphere and age. To control for the overall type I error at a significance level of 0.05, a hierarchical approach was used; the secondary end point would be tested only if statistical significance for the primary end point was shown. For participants who did not have an RSV-associated lower respiratory tract infection and were not followed through 150 days after administration of the dose, their event status was considered missing and was imputed with the observed event rate in the placebo group, with repeated imputation. \n\n【29】Data analyses were conducted with SAS software, version 9.4 (SAS Institute). Pharmacokinetic end points were estimated by noncompartmental analysis with Phoenix 64 WinNonlin, version 6.3 (Pharsight).\n\n【30】Results\n-------\n\n【31】Participants\n------------\n\n【32】Table 1. Characteristics of the Participants at Baseline.\n\n【33】Between November 3, 2016, and December 1, 2017, a total of 1453 participants underwent randomization (969 to the nirsevimab group and 484 to the placebo group), and 1447 (966 in the nirsevimab group and 481 in the placebo group) received injections . In the two groups combined, 97.5% of the participants (1417 participants) who underwent randomization completed the 150-day efficacy period; 94.2% (913) of those randomly assigned to nirsevimab and 93.8% (454) of those randomly assigned to placebo completed the entire 360-day follow-up . Baseline characteristics were similar in the two groups .\n\n【34】Efficacy\n--------\n\n【35】Table 2. Medically Attended Lower Respiratory Tract Infection and Hospitalization Associated with Respiratory Syncytial Virus (RSV) through 150 Days after Dose. Figure 1.  Figure 1. Lower Respiratory Tract Infections (LRTIs) and Hospitalizations Associated with Respiratory Syncytial Virus (RSV).\n\n【36】Kaplan–Meier curves from a time-to-event analysis show estimates of the proportion of participants who were free from a medically attended RSV-associated LRTI  and the proportion who were not hospitalized for that infection . The hazard ratio was obtained from a stratified proportional-hazards model with two stratification factors (age at time of random assignment and northern or southern hemisphere). In each panel, the inset shows the same data on an enlarged y axis. Tick marks indicate censored data.\n\n【37】Medically attended RSV-associated lower respiratory tract infection occurred in 2.6% of the participants (25 participants) in the nirsevimab group and in 9.5% (46) in the placebo group. Hospitalization for this condition occurred in 0.8% of those in the nirsevimab group (8 participants) and in 4.1% (20) in the placebo group. The incidence of medically attended RSV-associated lower respiratory tract infection was 70.1% lower (95% confidence interval \\[CI\\], 52.3 to 81.2) with nirsevimab than with placebo (P<0.001). The incidence of hospitalization for this condition was 78.4% lower (95% CI, 51.9 to 90.3) with nirsevimab than with placebo (P<0.001) . Over the entire 150-day efficacy period after administration of the dose, infants who received nirsevimab had a lower risk of medically attended RSV-associated lower respiratory tract infection than infants who received placebo (hazard ratio, 0.26; 95% CI, 0.16 to 0.43), as well as a lower risk of hospitalization for this condition (hazard ratio, 0.19; 95% CI, 0.08 to 0.44) . RSV-associated lower respiratory tract infections occurred with placebo throughout the 150 days after administration of the dose, but the incidence decreased as the RSV season ended. The separation in event rates between nirsevimab and placebo recipients expanded throughout the 150 days after administration of the dose . Subgroup analyses according to hemisphere, age at randomization, sex, race, gestational age, and enrolled siblings showed consistent efficacy favoring nirsevimab .\n\n【38】Of participants hospitalized because of RSV infection, all those who were admitted to the intensive care unit (5 participants) or received assisted ventilation (4 participants) were in the placebo group. Among participants who had medically attended RSV-associated lower respiratory tract infection, fewer nirsevimab recipients (4 \\[16%\\]) than placebo recipients (15 \\[32.6%\\]) received supplemental oxygen .\n\n【39】In 86.3% of the cases of lower respiratory tract infection (391 of 453 incidents) and 86.0% of the hospitalizations (104 of 121 incidents), samples were collected for central RT-PCR testing between 7 days before and 14 days after the initial visit to a health care provider. RSV A and B subtypes were responsible for similar proportions of medically attended RSV-associated lower respiratory tract infections. The incidence of either subtype was lower with nirsevimab than with placebo (RSV A, 1.1% \\[11 participants\\] vs. 5.0% \\[24 participants\\]; RSV B, 1.4% \\[14 participants\\] vs. 4.5% \\[22 participants\\]). Two clinical isolates identified from nirsevimab recipients, both RSV B, had decreased susceptibility to nirsevimab .\n\n【40】Figure 2. Effect of Nirsevimab on All-Cause Respiratory Events in the Intention-to-Treat Population.\n\n【41】Panel A shows the percentage of participants who had any medically attended lower respiratory tract infection or respiratory-related hospitalization (caused by RSV or non-RSV pathogens) through 150 days after administration of nirsevimab or placebo. Panel B shows the percentage of participants with any medically attended RSV- or non-RSV–associated lower respiratory tract infection who had an outpatient visit or hospitalization through 150 days after administration of nirsevimab or placebo.\n\n【42】Medically attended lower respiratory tract infection from any cause through 150 days after the dose occurred in 25.8% of the participants (125 participants) in the placebo group and in 19.7% (191) in the nirsevimab group, representing a 23.5% lower incidence (95% CI, 7.1 to 37.0) in the nirsevimab group . Similarly, a lower rate of hospitalization due to any respiratory illness was observed with nirsevimab than with placebo (5.5% \\[53 participants\\] vs. 9.5% \\[46 participants\\]), representing a 42.5% lower incidence (95% CI, 16.3 to 60.5) in the nirsevimab group . Post hoc time-to-event analyses  further supported the benefit of nirsevimab over placebo in preventing medically attended lower respiratory tract infection from any cause and respiratory-related hospitalization for any cause. Occurrence of non-RSV lower respiratory tract infection was similar in the two groups , which suggests that infection due to other respiratory pathogens was not affected by nirsevimab.\n\n【43】Safety\n------\n\n【44】Table 3. Safety and Adverse Events during the Trial That Occurred in at Least 10% of Participants in Either Group.\n\n【45】The types and frequencies of adverse events that occurred during the trial were similar in the nirsevimab and placebo groups . Serious adverse events were reported in 11.2% (108 of 968) of the participants who received nirsevimab and in 16.9% (81 of 479) of those who received placebo; the investigator considered none to be related to the investigational product.\n\n【46】Most adverse events that occurred during treatment were grade 1 or 2 in severity. Adverse events of grade 3 or higher were reported in 8.0% (77 of 968) of those who received nirsevimab and in 12.5% (60 of 479) of those who received placebo. Occurrences of adverse events relative to dose administration within 1 day after the dose or at 7 days after the dose were similar in the two groups.\n\n【47】Adverse events of special interest were reported in 0.5% (5 of 968) of the participants who received nirsevimab and in 0.6% (3 of 479) of those who received placebo. No anaphylaxis or other notable hypersensitivity reactions were reported. All adverse events of special interest were grade 1 in severity and were considered by the investigator to be related to nirsevimab or placebo; these adverse events were rash (4 participants) and petechiae (1 participant) in the nirsevimab group and rash (3 participants) in the placebo group.\n\n【48】Five deaths occurred through day 361 (two deaths in the nirsevimab group and three in the placebo group); one death in the placebo group occurred after the trial period (day 367). No deaths were known to be due to RSV or were considered by the investigator to be related to nirsevimab or placebo.\n\n【49】Pharmacokinetics\n----------------\n\n【50】The mean (±SD) half-life of nirsevimab was 59.3±9.6 days. On day 151, serum concentrations in 97.9% (833 of 851 infants for whom day-151 serum concentrations were available) of the nirsevimab recipients were above the targeted 90% effective concentration threshold of 6.8 μg per milliliter.  Mean serum concentrations of nirsevimab decayed in proportion to the concentration beyond 91 days without signs of nonlinearity .\n\n【51】Antidrug Antibodies\n-------------------\n\n【52】Postbaseline antidrug antibodies were detected in 5.6% of the participants who received nirsevimab (52 of 929 participants with postbaseline antidrug antibodies that could be evaluated) and in 3.8% of those who received placebo (18 of 469 participants with postbaseline antidrug antibodies that could be evaluated). Serum concentrations of nirsevimab over time were similar in participants who were positive and those who were negative for antidrug antibodies . During the 150-day period after administration of the dose, one nirsevimab recipient who had a medically attended RSV-associated lower respiratory tract infection had antidrug antibodies detected by laboratory testing. The respiratory tract infection occurred on day 46; the only positive antidrug antibody titer  was noted on day 91. There was no notable difference between groups when adverse events occurring during the trial period were analyzed by positive or negative antidrug antibody status.\n\n【53】Discussion\n----------\n\n【54】This trial of a monoclonal antibody with an extended half-life showed that a single intramuscular dose of RSV immunoprophylaxis could protect infants against RSV-associated lower respiratory tract infection requiring medical attention. A single intramuscular injection of nirsevimab at a dose of 50 mg resulted in a lower incidence of medically attended RSV-associated lower respiratory tract infections and hospitalizations (approximately 70% and 80% lower, respectively) than placebo in healthy preterm infants entering their first RSV season. Subgroup analyses of the primary and secondary efficacy end points showed results similar to those of the overall analysis, consistently favoring nirsevimab.\n\n【55】Different definitions of lower respiratory tract infection have been used in RSV immunization studies.  We used a prespecified objective case definition of this condition to allow transnational standardization of the efficacy end point for lower respiratory tract infection.  Of 79 participants who received a confirmed diagnosis of RSV-positive lower respiratory tract infection, 71 (90%) met our case definition. All participants hospitalized with RSV-associated lower respiratory tract infections met the case definition. We observed a lower incidence of medically attended lower respiratory tract infection from any cause and respiratory-related hospitalization for any cause in the nirsevimab group than in the placebo group, with no corresponding increase in non–RSV-associated lower respiratory tract infections, which suggests that preventing RSV infection did not promote emergence of these respiratory infections caused by other respiratory pathogens.\n\n【56】Nirsevimab has greater neutralizing activity and a longer serum half-life than palivizumab. One injection of nirsevimab provided protection for a typical RSV season, whereas monthly injections of palivizumab are required to provide sustained protection during the RSV season.  Palivizumab is indicated and recommended only for the highest-risk infants.  Given the unique characteristics of nirsevimab, including our finding that season-long protection from RSV can be achieved with a single dose, it is currently being evaluated in healthy late-preterm and full-term infants.\n\n【57】Nirsevimab was effective at neutralizing both RSV A and RSV B subtypes. This finding is important because a recent trial of suptavumab , an investigational RSV F site-V specific monoclonal antibody, failed to meet its primary efficacy end point and was not effective in neutralizing the main circulating strain of RSV B.\n\n【58】In this population of healthy infants who had been born preterm, nirsevimab had a safety profile similar to that of placebo. Administering nirsevimab to larger numbers of infants will be necessary to detect possible less-common adverse events. The incidence of suspected hypersensitivity reactions was similar in the nirsevimab group and the placebo group, and there were no cases of anaphylaxis or other notable hypersensitivity reactions. Antidrug antibodies did not appear to have an effect on efficacy or nirsevimab serum concentrations through day 151, nor did they arouse an obvious safety concern through day 361.\n\n【59】A direct comparison of the results of this trial with those involving other anti-RSV monoclonal antibodies and maternal vaccines (vaccines administered during pregnancy) is difficult because of differences in antibody and functional antibody measurement techniques, end points, trial populations, and dosing regimens. Previous studies have shown that an RSV-specific monoclonal antibody, at an effective concentration provided in advance of the RSV season, can reliably reduce the incidence of serious RSV disease in preterm infants, children 24 months of age or younger with chronic lung disease of prematurity or congenital heart disease,  and healthy Native American full-term infants.  Nirsevimab provided protection with a single intramuscular dose, probably owing to its increased potency and extended half-life of 63 to 73 days  as compared with the shorter 19-to-27-day half-life of palivizumab.  On day 151 after a single dose of nirsevimab, most infants had serum concentrations above the target threshold. Although prophylaxis with RSV-specific monoclonal antibodies has been shown to be protective, that has not been the case with maternal RSV antibodies. Efficient transfer of maternal RSV antibodies to infants occurs, but it has failed to confer protection from severe RSV disease. \n\n【60】In this trial of RSV prophylaxis in healthy preterm infants, a single dose of nirsevimab resulted in a lower incidence of medically attended RSV-associated lower respiratory tract infection and of hospitalization than placebo for 150 days — the length of a typical RSV season — after administration of the dose. Nirsevimab had a favorable safety profile, with no notable hypersensitivity reactions.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 18:37:02", "endTime": "2024/08/13 18:37:17", "cost": 14.701}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 02:37:17", "grab_time": "2024-08-13 02:37:02"}
{"id": 2234427, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "42ff5b34-e5d0-4069-88a8-49d7a2600315", "title": "Getting Rid of Stupid Stuff", "text": "【0】Getting Rid of Stupid Stuff\n### Audio Interview\n\n【1】 Interview with Dr. Melinda Ashton on easing the burden of administrative tasks in medicine and helping clinicians find more meaning in their work. \n\n【2】In an effort to reduce unintended burdens for clinicians, leaders at a health system in Hawaii asked all employees to look at their daily documentation experience and report anything in the EHR that they thought was poorly designed, unnecessary, or just plain stupid.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 10:46:44", "endTime": "2024/08/14 10:46:57", "cost": 12.765}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 18:46:57", "grab_time": "2024-08-13 18:46:40"}
{"id": 2234426, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "3364a07c-20d2-4560-a659-80ddb39052a2", "title": "Case 13-2020: A 29-Year-Old Man with High Blood Pressure, Renal Insufficiency, and Hematuria", "text": "【0】Case 13-2020: A 29-Year-Old Man with High Blood Pressure, Renal Insufficiency, and Hematuria\nA 29-year-old man was evaluated because of hypertension, renal insufficiency, and hematuria. He had a blood pressure of 160/102 mm Hg, a urea nitrogen level of 48 mg per deciliter, and a creatinine level of 3.93 mg per deciliter. Examination of urine sediment revealed fine granular casts, dysmorphic red cells, and rare white-cell casts. Diagnostic tests were performed.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:20:25", "endTime": "2024/08/14 15:20:36", "cost": 10.984}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:31", "update_time": "2024-08-13 23:20:36", "grab_time": "2024-08-13 23:20:24"}
{"id": 2234425, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "5ea38a8c-ee18-4b8b-9df4-70ff3c78d1d2", "title": "Electromagnetic Bougienage to Lengthen Esophageal Segments in Congenital Esophageal Atresia", "text": "【0】Electromagnetic Bougienage to Lengthen Esophageal Segments in Congenital Esophageal Atresia\nAbstract\n--------\n\n【1】Some cases of esophageal atresia, either with or without tracheoesophageal fistula, are not suited for primary anastomosis. To avert the need for colon interposition in two such infants, intermittent electromagnetic force was used to pull together \"bullets\" placed in the esophageal ends. This method elongated and enlarged the esophageal segments enough to accomplish their anastomosis later. This approach appears feasible to use for infants whose esophageal malformation does not permit primary repair. It may also be applicable to cases of imperforate anus with a high pouch.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:12:13", "endTime": "2024/08/14 15:12:20", "cost": 6.804}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 23:12:19", "grab_time": "2024-08-13 23:12:11"}
{"id": 2234424, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "45eed483-eb92-4501-a710-2befa1a1d6bd", "title": "Idiopathic Pulmonary Fibrosis", "text": "【0】Idiopathic Pulmonary Fibrosis\nIdiopathic pulmonary fibrosis appears to be increasing in incidence. It requires early recognition and intervention with supportive care and pharmacologic agents to forestall its progression. Lung transplantation may be curative.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:12:02", "endTime": "2024/08/14 15:12:08", "cost": 6.437}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 23:12:08", "grab_time": "2024-08-13 23:12:01"}
{"id": 2234423, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "923911ca-2f66-4f89-8def-bae2e4558c36", "title": "Immunologic Effect of Bivalent mRNA Booster in Patients Undergoing Hemodialysis", "text": "【0】Immunologic Effect of Bivalent mRNA Booster in Patients Undergoing Hemodialysis\nTo the Editor:\n--------------\n\n【1】Booster doses of bivalent messenger RNA (mRNA) vaccines containing the ancestral severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) and the omicron B.1.1.529 (BA.4 and BA.5) variant spike sequences have been strongly recommended for persons at risk for severe sequelae of coronavirus disease 2019 (Covid-19). Patients undergoing hemodialysis have shown inferior humoral immunity against variants despite the receipt of four monovalent vaccine doses. \n\n【2】In this case series, 55 patients undergoing hemodialysis who had received four previous SARS-CoV-2 vaccinations were monitored 6 and 2 weeks before and 2 and 4 weeks after a fifth vaccination with a bivalent mRNA vaccine . Before the fifth vaccination, 18 patients had had previous omicron breakthrough infection that had been confirmed by polymerase-chain-reaction testing, whereas 37 had not had previous omicron breakthrough infection.\n\n【3】Figure 1. Anti-Spike IgG Responses against Omicron BA.4 and BA.5 Subvariants before and after Bivalent mRNA Booster in Patients Undergoing Hemodialysis.\n\n【4】Anti-spike IgG concentrations 6 and 2 weeks before, as well as 2 and 4 weeks after, fifth messenger RNA (mRNA) vaccination in patients with previous B.1.1.529 (omicron) breakthrough infection (open circles) and those with no previous omicron breakthrough infection (triangles) are shown . Connecting lines between the time points indicate matched serum samples. The dashed horizontal line indicates the lower limit of detection (31 binding antibody units \\[BAU\\] per milliliter) in the detection system. Neutralizing activities are presented as serum dilutions for half-maximal infection-neutralization capacities normalized to 10 <sup>7 </sup> viral RNA copies (50% inhibitory concentration \\[IC <sub>50 </sub> \\]) for omicron BA.4  and BA.5 . The anti-spike IgG antibody avidities are shown as relative percentages for three time points . The median value (horizontal line) and interquartile range (whiskers) are shown. P values are given for comparison of the dependent variables between different time points for each group. For comparison between patients with previous omicron breakthrough infection and those with no previous omicron breakthrough infection at each time point, one asterisk denotes P<0.05, two asterisks P<0.01, and three asterisks P<0.001.\n\n【5】From 2 weeks before to 2 weeks after the fifth vaccination, a significant increase by a factor of 2.5 in anti-spike IgG concentrations was stimulated in the patients who had had previous omicron breakthrough infection, and an increase by a factor of 7.3 was stimulated in those who had not had previous omicron breakthrough infection . Patients with previous breakthrough infection had significantly higher anti-spike IgG concentrations and neutralization activities (expressed as 50% inhibitory concentrations)  against BA.4  and BA.5  than those without previous breakthrough infection, both before and after the fifth vaccination. Patients without previous breakthrough infection had significantly increased infection-neutralizing capacity by a factor of 4.9 against BA.4 and by a factor of 3.3 against BA.5 at 2 weeks after vaccination and increased anti-spike IgG avidity by 17% at 4 weeks after vaccination . After the fifth vaccination, neutralization activities against both omicron BA.4 and BA.5 in both groups — those with and those without previous breakthrough infection — positively correlated with anti-spike IgG concentrations, antibody avidity, and neutralization activity before the fifth vaccination , whereas age did not significantly influence the results. A regression analysis that included all study patients showed that the anti-spike IgG concentration after booster vaccination was the most important indicator of high neutralization activity against BA.4 (P=0.008) and BA.5 (P=0.005).\n\n【6】The findings are in accordance with results from clinical studies of bivalent mRNA vaccines in healthy persons that showed a significant rise in anti-spike IgG concentrations.  In particular, patients who did not have previous breakthrough infection immunologically benefited from a bivalent mRNA booster: despite having lower anti-spike IgG concentrations before the fifth vaccination, they had a significant increase after the fifth vaccination, such that their concentrations matched those in persons with hybrid immunity due to omicron breakthrough infection. The high dependency of neutralization activity against omicron BA.4 and BA.5 on baseline anti-spike IgG concentrations and binding activity before booster vaccination corroborates the concept that antibodies should be maintained at high levels by means of periodic vaccinations. The results may be of particular importance for persons at risk for severe disease such as patients undergoing hemodialysis and support recommendations that these patients should receive booster doses of bivalent mRNA vaccines, particularly if they have no hybrid immunity from an omicron breakthrough infection.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 10:59:33", "endTime": "2024/08/14 10:59:49", "cost": 15.69}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 18:59:49", "grab_time": "2024-08-13 18:59:33"}
{"id": 2234422, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "c7923dc5-f74f-4054-acb7-6ab6a0bf3780", "title": "Topical Tretinoin (Retinoic Acid) Treatment for Liver Spots Associated with Photodamage", "text": "【0】Topical Tretinoin (Retinoic Acid) Treatment for Liver Spots Associated with Photodamage\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】The hyperpigmented lesions commonly called liver spots distress patients, in part because such lesions are associated with aging. We investigated their treatment with topical 0.1 percent tretinoin (retinoic acid).\n\n【3】Methods.\n--------\n\n【4】Fifty-eight patients completed a 10-month randomized, double-blind study in which they applied either 0.1 percent tretinoin (n = 28) or vehicle (n = 30) cream daily to the face, upper extremities, or both. Fifteen patients who responded well were then randomly assigned to continue tretinoin therapy or use vehicle alone for six more months. Patients were evaluated by physical examination every month and by analysis of biopsy specimens of lesions obtained at base line and at the end of the 10-month trial.\n\n【5】Results.\n--------\n\n【6】After one month of treatment the patients treated with tretinoin had significant lightening of hyperpigmented lesions as compared with the patients who received vehicle (P<0.002). After 10 months, 20 (83 percent) of the 24 patients with facial lesions who were treated with tretinoin had lightening of these lesions, as compared with 8 (29 percent) of the 28 patients with facial lesions who received vehicle. The results for lesions of the upper extremities were similar. As compared with vehicle, tretinoin caused a significant decrease in the degree of epidermal pigmentation and increases in the degree of compaction of stratum corneum, thickness of the granular cell layer, and epidermal thickness. Reductions in epidermal pigmentation evident on histologic analysis were significantly correlated with the degree of clinical lightening of lesions (r = -0.53, P<0.0001). During the 6-month follow-up study, specifically identified lesions that had disappeared during the first 10 months of tretinoin treatment did not return in any patient, and six of seven patients who continued to use tretinoin had further improvement.\n\n【7】Conclusions.\n------------\n\n【8】Topical 0.1 percent tretinoin significantly improves both clinical and microscopical manifestations of liver spots; these lesions do not return for at least six months after therapy is discontinued. \n\n【9】Introduction\n------------\n\n【10】THE presence of hyperpigmented macules (liver spots) on the face or other exposed areas usually indicates substantial damage due to exposure to sunlight (photodamage). To date, the treatment for such lesions, many of which are actinic lentigines, has been surgery or chemical peeling.  Bleaching agents such as hydroquinones often produce undesirable depigmentation, and opaque cosmetics do not treat the underlying problem.\n\n【11】Tretinoin (retinoic acid) is a potent inhibitor of new melanin production,  and recent studies have suggested that topical therapy with tretinoin may decrease the macular hyperpigmentation.  <sup><a>4 </a></sup>  <sup><a>6 </a></sup>  Therefore, we performed a study specifically designed to evaluate the efficacy of topical tretinoin cream in the treatment of hyperpigmented lesions associated with photodamage; we found that 0.1 percent tretinoin is an effective topical treatment.\n\n【12】Methods\n-------\n\n【13】Patients and Design\n-------------------\n\n【14】Sixty healthy white patients, each with at least four hyperpigmented macules with the clinical characteristics of actinic lentigines, participated in the initial 10-month study of tretinoin or vehicle treatment. At least one of these lesions had to be of sufficient size to allow two separate 2-mm punch-biopsy specimens to be obtained. A total of 24 women and 6 men were treated with tretinoin and 25 women and 5 men were given vehicle. They ranged in age from 36 to 86 years (mean, 67) in the tretinoin group and from 48 to 81 years (mean, 65) in the vehicle group.\n\n【15】None of the patients had used topical or systemic retinoids for six months, any topical medications for at least two weeks, or systemic steroids for one month before the study. Pregnant and nursing women and patients who had received oral psoralen and ultraviolet A radiation were excluded. The protocol, which had been approved by the institutional review board of the University of Michigan Medical Center, and the potential side effects of the treatment were explained to each patient, and all signed informed-consent forms.\n\n【16】A computer-generated code was used for the random assignment of the patients to the treatment groups on the basis of their order of entry into the study. The treatments were either 0.1 percent tretinoin cream (Retin-A, Ortho Pharmaceutical, Raritan, N.J.) or color-matched vehicle cream. All dispensed tubes were identical in appearance; therefore, both the investigators and the patients were unaware of the group to which the patient had been assigned. The sample sizes were chosen to provide a statistical power of approximately 0.80 to detect a difference in overall improvement of at least one half-unit (as defined below) between the two treatment groups at a Type I error rate of 0.05 for a two-tailed hypothesis.\n\n【17】Fifteen of the patients who had a good response during the initial 10-month study (all of whom proved to have received tretinoin) and who wished to participate in an additional 6-month study were randomly assigned to receive either 0.1 percent tretinoin or vehicle cream. In this phase of the study there were five women and three men (age, 36 to 80 years; mean, 66) in the tretinoin group, and five women and two men (age, 46 to 83; mean, 66) in the vehicle group.\n\n【18】Treatment\n---------\n\n【19】The patients applied the study compounds once nightly to the face, arms, forearms, backs of the hands, or any combination of these sites that had hyperpigmented lesions. Initially, a pea-sized amount of cream was used on each affected area. The patients were encouraged to increase gradually the quantity of cream applied until mild erythema or scaling ensued.\n\n【20】The patients were supplied with a mild soap and asked to wash with this or a similar agent at least 20 minutes before applying the study treatment. All patients also received a mild emollient to be used when needed for skin irritation or dryness. They were advised to avoid excessive exposure to the sun or sunlamps during the study. Sunscreen with a protection factor of 15 was provided. They also were instructed to minimize the use of cosmetics, which were not worn during evaluations or photographic sessions. For 24 hours before each evaluation, the patients did not apply any topical preparations, including the study treatment, emollients, or sunscreen.\n\n【21】Clinical Evaluations\n--------------------\n\n【22】Clinical evaluations were performed before treatment, after two and four weeks of treatment, and monthly thereafter. Monthly evaluations were also performed during the six-month extended study. One investigator evaluated the patients at the majority of visits. For each patient, the overall clinical response of each area under treatment was rated by the investigator in terms of changes in color —that is, as much darker, darker, unchanged, lighter, or much lighter. The results for the arms, forearms, and backs of the hands were averaged for each patient and are reported as results for the upper extremities.\n\n【23】In addition to the overall assessment, four hyperpigmented lesions were identified before treatment on the basis of the likelihood of accurately locating these lesions throughout the study, thus allowing us to correlate the clinical and histologic results in the same lesions. Pretreatment photographs aided in locating specific lesions. At each return visit, the degree of hyperpigmentation of each of these lesions was compared with that before treatment, and color was graded by the investigator as much darker, darker, slightly darker, unchanged, slightly lighter, lighter, much lighter, or absent.\n\n【24】The degrees of erythema, scaling, burning or stinging, and pruritus were assessed at all visits with the use of a five-point scale, in which 0 indicated the absence of such symptoms, 1 the presence of mild symptoms, 2 the presence of moderate symptoms, 3 the presence of moderately severe symptoms, and 4 the presence of severe symptoms. A cutaneous reaction was defined as the presence of at least moderate erythema or scaling at two or more visits.\n\n【25】Light-Microscopical Analysis\n----------------------------\n\n【26】Of the four lesions specifically identified in each patient, one of sufficient size was selected to be the site of two full-thickness punch biopsies (each measuring 2 mm in diameter) before and after 10 months of treatment for light-microscopical analysis. Post-treatment biopsy specimens from two patients in the vehicle group were not available because of laboratory errors.\n\n【27】The specimens were fixed in 10 percent neutral-buffered formalin, embedded in paraffin, sectioned, and stained with hematoxylin and eosin. The investigator who analyzed the specimens was not aware of either the patient's treatment or the time of the biopsy. The histologic sections were assessed for the presence of various characteristics with a semiquantitative ordinal five-point scale in half-unit increments, in which 0 indicated the absence of the characteristics and 4 indicated the maximal degree of the characteristics. Epidermal thickness was measured directly.\n\n【28】Photographic Analysis\n---------------------\n\n【29】All data were obtained by direct assessment of patients, and none were derived by assessing photographs. The photographs for documentation of the lesional areas were taken by a professional photographer before and during treatment using standardized positioning and lighting of the patients and film from a single emulsion lot processed by a single professional laboratory. A standard gray card (18 percent reflectance) was included in the first picture during each session to control for any shifts in color or density due to extraneous variables.\n\n【30】Statistical Analysis\n--------------------\n\n【31】Table 1. Mean Clinically Apparent Change in Color after 10 Months of Treatment with Tretinoin or Vehicle, According to the Type of Lesion.\\*\n\n【32】The changes in clinical and histologic measures of the hyperpigmented lesions before and during treatment in the tretinoin and vehicle groups were compared by means of the two-sample t-test. The association between treatment and overall response after 10 and 16 months was made with the chi-square test. The comparison of changes in color of the specifically identified lesions in the two groups was based on the average of the changes in the four lesions; the clinical changes in color of the single lesion that underwent biopsy were analyzed according to histologic diagnosis . In each case, group means were compared by the two-sample t-test. The ratings for change in color, which were initially assigned values ranging from 1 to 8 for computer data entry, were reassigned values ranging from -3 to +4 so that a rating of no change would equal 0. Overall scores were reassigned in the same fashion. These arithmetic adjustments had no effect on the statistical analyses, P values, or conclusions drawn. Correlations between clinical and histologic variables were assessed with Pearson's product-moment correlation coefficient.\n\n【33】All analyses included all patients who could be evaluated; only in Table 1 are patients stratified according to histologic diagnosis. All P values are two-sided. Summary statistics are expressed as means ±SE. Data were analyzed with the Michigan Interactive Data Analysis System (MIDAS, a statistical software package developed by the Center for Statistical Consultation and Research at the University of Michigan).\n\n【34】Results\n-------\n\n【35】Fifty-eight of the 60 patients completed the 10-month study. Two patients in the tretinoin group dropped out, one after two months because of non-compliance and the other after one month because of an exacerbation of atopic dermatitis. Therefore, clinical data for the first 10 months are presented for 30 patients in the vehicle group (28 with facial lesions and 26 with upper-extremity lesions) and 28 in the tretinoin group (24 with facial lesions and 26 with upper-extremity lesions).\n\n【36】Clinical Results\n----------------\n\n【37】### __Overall Scores__\n\n【38】Figure 1. Examples of the Best Responses to Tretinoin Therapy in Three Patients.\n\n【39】Panel A shows a 79-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 additional months of tretinoin (6 mo f/u). Many hyperpigmented lesions had disappeared and others had lightened after 10 months of tretinoin therapy, with continued improvement after 6 additional months of therapy. Panel B shows an 84-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 months of vehicle (6 mo f/u). After 10 months of tretinoin therapy, many brown spots had cleared, and a retinoid reaction had occurred; after 6 months of vehicle, no relapse had occurred. Panels C and D show a 70-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 5 months of no treatment (5 mos. off). All lesions had disappeared after 10 months of treatment and had not reappeared 5 months after tretinoin was stopped.Figure 2.  Figure 2. Overall Efficacy of 10 Months of Treatment with Tretinoin or Vehicle Cream for Hyperpigmented Lesions of the Face and Upper Extremities.\n\n【40】As compared with vehicle, tretinoin caused significant lightening of hyperpigmented lesions of the face (P = 0.0002) and upper extremities (P = 0.0001). Among the patients given tretinoin, 24 had facial lesions and 26 had upper-extremity lesions. Among the patients given vehicle, 28 had facial lesions and 26 had upper-extremity lesions. Not all percentages sum to 100 because of rounding.\n\n【41】After 10 months of treatment, the overall scores demonstrated statistically significant lightening of hyperpigmented facial and upper-extremity lesions in the group receiving tretinoin as compared with the group receiving vehicle . Among the 24 tretinoin-treated patients who had facial lesions, the Figure 1 . Examples of the Best Responses to Tretinoin Therapy in Three Patients. Panel A shows a 79-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 additional months of tretinoin (6 mo f/u). Many hyperpigmented lesions had disappeared and others had lightened after 10 months of tretinoin therapy, with continued improvement after 6 additional months of therapy. Panel B shows an 84-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 months of vehicle (6 mo f/u). After 10 months of tretinoin therapy, many brown spots had cleared, and a retinoid reaction had occurred; after 6 months of vehicle, no relapse had occurred. Panels C and D show a 70-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 5 months of no treatment (5 mos. off). All lesions had disappeared after 10 months of treatment and had not reappeared 5 months after tretinoin was stopped. lesions were much lighter in 10 (42 percent), lighter in 10 (42 percent), and unchanged in 4 (17 percent) after 10 months of therapy. Among the 28 patients with facial lesions who received vehicle, the lesions were much lighter in 2 (7 percent), lighter in 6 (21 percent), and unchanged in 20 (71 percent). Thus, 20 patients in the tretinoin group (83 percent) and 8 patients in the vehicle group (29 percent) had some lightening of facial lesions. Among the 26 tretinoin-treated patients who had upper-extremity lesions, the lesions were much lighter in 6 (23 percent), lighter in 17 (65 percent), and unchanged in 3 (12 percent) after 10 months of therapy. Among the 26 patients with upper-extremity lesions who received vehicle, the lesions were much lighter in 1 (4 percent), lighter in 7 (27 percent), and unchanged in 18 (69 percent). The overall score did not worsen in either group during treatment.\n\n【42】Figure 3. Overall Change in Color in Response to Treatment with Tretinoin (Solid Lines) or Vehicle (Broken Lines).\n\n【43】Circles and error bars indicate means ±SE. Statistically significant and clinically detectable lightening of facial and upper-extremity lesions was evident after four weeks of tretinoin treatment and was maintained for the rest of the study. Asterisks denote a significant difference (P≤0.002) between groups.\n\n【44】A significant overall improvement in the tretinoin group, as compared with the vehicle group, was first attained after one month of therapy (P≤0.002) . An overall improvement of facial and upper-extremity lesions occurred in 44 and 58 percent of patients, respectively, after 1 month of tretinoin treatment, in 75 and 85 percent of patients after 6 months of treatment, and in 83 and 88 percent after 10 months of treatment.\n\n【45】### __Specific Lesions__\n\n【46】When the scores for the four lesions were averaged for each patient, there was a significant improvement in the tretinoin group as compared with the vehicle group after 10 months of treatment (P<0.0001). At the end of the 10-month study, the lesions had lightened in 20 of the 28 patients (71 percent) in the tretinoin group but in only 7 of the 30 patients (23 percent) in the vehicle group. Nine of the 28 patients (32 percent) receiving tretinoin had complete clearing of one or more of these lesions; the mean length of time required for clearance of the lesions was 8 months (range, 5 to 10). None of the lesions completely disappeared in any of the patients who received vehicle.\n\n【47】### __Six-Month Follow-up Study__\n\n【48】Fifteen patients who responded well to treatment in the initial 10-month study were assigned to tretinoin or vehicle for an additional 6 months. When the code was broken, all 15 patients who entered the six-month follow-up study proved to have received tretinoin; randomization at this stage resulted in 8 being assigned to receive tretinoin and 7 vehicle. One patient who was reassigned to the tretinoin group withdrew one month later because of contact dermatitis (proved by patch testing) due to quaternium-15, a preservative in the emollient.\n\n【49】The group reassigned to tretinoin treatment had a further significant overall improvement of lesions located on the face (P = 0.01) and upper extremities (P = 0.0005), as compared with the group assigned to vehicle. In this phase of the study, of six tretinoin-treated patients who had hyperpigmented facial lesions, the lesions were much lighter in two, lighter in three, and unchanged in one, as compared with the results at the end of the 10-month phase. All tretinoin-treated patients with upper-extremity lesions had further lightening of their lesions during this same period. In contrast, there was no change in facial or upper-extremity lesions in patients who received vehicle during the six-month follow-up study.\n\n【50】Four patients who had had complete clearing of at least one of the four identified lesions during the 10-month course of tretinoin maintained these results during the subsequent 6-month course of tretinoin. Of two other patients who had no clearing of any specified lesions during the first 10 months of tretinoin treatment, each had one lesion completely disappear with continued tretinoin treatment during the 6-month follow-up study. Three patients who had at least one lesion resolve during the first 10 months of tretinoin therapy received vehicle for 6 months; none of their lesions returned. The patient who withdrew because of contact dermatitis had no recurrence of lesions after five months without treatment . None of the patients who received vehicle cream had complete clearing of any of the four identified lesions during the six-month follow-up study.\n\n【51】Cutaneous Reactions\n-------------------\n\n【52】During the study the patients reported only cutaneous reactions,  <sup><a>9 </a></sup>  characterized principally by erythema and scaling. Erythema or scaling of at least moderate severity occurred more than once in 23 of the 28 patients receiving tretinoin (82 percent) and in 2 of the 30 patients given vehicle (7 percent) during the initial 10-month study. Five of the seven patients who received tretinoin, but none of the seven patients who received vehicle, had such reactions during the six-month follow-up study.\n\n【53】The rash occurred only in areas that came into contact with the topical medication and varied in intensity and duration among the patients and in any individual patient at different times. Scaling or erythema began one to four weeks after the start of tretinoin treatment. In all cases, the scaling and erythema were most noticeable during the first two months, after which there was a progressive decrease in their severity, frequency, and duration.\n\n【54】The cutaneous reactions improved when emollients were applied more frequently and the amount of study medication used was decreased or treatment was stopped for one to three days. Three patients, two receiving tretinoin and one receiving vehicle, applied 1 percent hydrocortisone cream for a maximum of five days to sites of irritation during the initial phase of the study.\n\n【55】Histologic Results\n------------------\n\n【56】A punch-biopsy specimen of a single lesion in each patient was obtained before and after treatment. The pretreatment biopsy specimens were classified by light microscopy as either actinic lentigines or nonlentiginous lesions (lesions that did not meet the criteria for actinic lentigines) . Both the actinic lentigines and nonlentiginous lesions lightened after treatment with tretinoin cream (P = 0.05 and P = 0.002, respectively) .\n\n【57】Table 2. Histologic Features of Biopsy Specimens Obtained before and after 10 Months of Treatment with Tretinoin or Vehicle.\\* Figure 4.  Figure 4. Histologic Appearance of a Hyperpigmented Lesion before Treatment (Top Panel) and after 10 Months of Treatment with 0.1 Percent Tretinoin (Bottom Panel).\n\n【58】The two specimens are from a single hyperpigmented lesion from the patient shown in Figures 1 C and 1 D (Fontana—Masson stain, ×90). After 10 months of treatment, the degree of epidermal pigmentation decreased markedly.Figure 5.  Figure 5. Relation between Histologic Changes in the Degree of Epidermal Pigmentation and Clinically Apparent Color Changes after 10 Months of Treatment with Tretinoin (N = 28) or Vehicle (N = 28).\n\n【59】The lesions with the best clinical response tended to have the greatest decrease in epidermal pigmentation (the best linear fit is represented by the line; r = -0.53, P<0.0001).\n\n【60】Ten months of topical tretinoin as compared with vehicle treatment resulted in a significant increase in the mean degree of compaction of stratum corneum, the thickness of the granular cell layer, epidermal thickness, the degree of spongiosis (i.e., widening of the spaces between keratinocytes), and the severity of perivascular mononuclear dermal inflammation . Light microscopy of the lesions showed that the degree of epidermal pigmentation decreased by 35 percent in the tretinoin group, whereas it increased by 34 percent in the vehicle group (P = 0.0008) . A reduction in epidermal pigmentation occurred in most tretinoin-treated patients . Histologically discernible changes in epidermal pigmentation were significantly correlated with clinically observable changes in the color of lesions from which biopsy samples were obtained (r = -0.53, P<0.0001) . None of the lesions that had more pigment on microscopical examination appeared darker clinically.\n\n【61】Discussion\n----------\n\n【62】We have demonstrated that 0.1 percent tretinoin cream is an effective treatment for hyperpigmented lesions (liver spots) associated with photodamage. Clinically apparent and statistically significant lightening of hyperpigmented lesions occurred as early as 1 month after the initiation of treatment, and at least one lesion disappeared in 32 percent of the patients during the 10-month treatment. Furthermore, none of the lesions that completely cleared returned during a subsequent six-month period in which vehicle alone was given.\n\n【63】All types of lesions responded to treatment with tretinoin, not just those that proved histologically to be actinic lentigines . Our findings suggest that despite the difficulties involved in diagnosing actinic lentigines clinically,  tretinoin is beneficial for various irregular hyperpigmented macules, regardless of their histologic characteristics. Indeed, previous studies have reported favorable results with tretinoin treatment of some premalignant and malignant neoplasms.  <sup><a>13 </a></sup>  <sup><a>15 </a></sup>  <sup><a>17 </a></sup>  <sup><a>19 </a></sup>  <sup><a>21</a></sup>\n\n【64】Our clinical experience, as well as that of Kligman,  suggests that patients with these skin lesions derive the best results from topical tretinoin when they increase the amount of medication to a point just short of intolerance. Thus, the lack of overall improvement in 17 percent of patients receiving tretinoin may have been due to the use of insufficient quantities of medication. Conversely, some vehicle-treated patients had lightening of their lesions because some improvement may occur with only emollient therapy, avoidance of sunlight, and the use of sunscreens.\n\n【65】None of the patients had adverse reactions that were severe or permanent; previous studies have also demonstrated an excellent safety profile for topical tretinoin.  <sup><a>4 </a></sup>  <sup><a>6 </a></sup>  <sup><a>22 </a></sup> Eighty-two percent of the patients treated with tretinoin and 7 percent of those who received vehicle in the initial 10-month study had a local reaction. Thus, it may have been possible at times to determine whether a patient was receiving tretinoin; however, such side effects were not evident during most of the patient evaluations. To reduce the possibility of bias, we graded all variables in relation to baseline values without referring to the data obtained from any of the other visits. Moreover, our photographic documentation  and the statistically significant histologic findings corroborated the clinical data.\n\n【66】The histologic studies revealed a decrease in epidermal pigmentation in tretinoin-treated lesions that correlated significantly with the degree of clinical lightening; however, there was no change in the number or size of melanocytes. Thus, the epidermis had less pigment after tretinoin therapy, an observation compatible with the work of Orlow et al.,  who showed that tretinoin inhibits induced melanogenesis. The other histologic changes seen in the biopsy specimens, such as epidermal thickening, are characteristic of the action of tretinoin on the skin.  <sup>, </sup>  <sup>, </sup>  Histologically, epidermal pigmentation increased in the group receiving vehicle, probably as a result of ongoing melanogenesis.\n\n【67】In our experience, actinic lentigines and other hyperpigmented lesions associated with photodamage do not completely disappear spontaneously. As a noninvasive therapy, topical 0.1 percent tretinoin cream, coupled with avoidance of the sun and appropriate use of sunscreen, is an effective, nondestructive approach to improving and sometimes clearing these lesions.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": " 9  ", "content": "【0】Topical Tretinoin (Retinoic Acid) Treatment for Liver Spots Associated with Photodamage\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】The hyperpigmented lesions commonly called liver spots distress patients, in part because such lesions are associated with aging. We investigated their treatment with topical 0.1 percent tretinoin (retinoic acid).\n\n【3】Methods.\n--------\n\n【4】Fifty-eight patients completed a 10-month randomized, double-blind study in which they applied either 0.1 percent tretinoin (n = 28) or vehicle (n = 30) cream daily to the face, upper extremities, or both. Fifteen patients who responded well were then randomly assigned to continue tretinoin therapy or use vehicle alone for six more months. Patients were evaluated by physical examination every month and by analysis of biopsy specimens of lesions obtained at base line and at the end of the 10-month trial.\n\n【5】Results.\n--------\n\n【6】After one month of treatment the patients treated with tretinoin had significant lightening of hyperpigmented lesions as compared with the patients who received vehicle (P<0.002). After 10 months, 20 (83 percent) of the 24 patients with facial lesions who were treated with tretinoin had lightening of these lesions, as compared with 8 (29 percent) of the 28 patients with facial lesions who received vehicle. The results for lesions of the upper extremities were similar. As compared with vehicle, tretinoin caused a significant decrease in the degree of epidermal pigmentation and increases in the degree of compaction of stratum corneum, thickness of the granular cell layer, and epidermal thickness. Reductions in epidermal pigmentation evident on histologic analysis were significantly correlated with the degree of clinical lightening of lesions (r = -0.53, P<0.0001). During the 6-month follow-up study, specifically identified lesions that had disappeared during the first 10 months of tretinoin treatment did not return in any patient, and six of seven patients who continued to use tretinoin had further improvement.\n\n【7】Conclusions.\n------------\n\n【8】Topical 0.1 percent tretinoin significantly improves both clinical and microscopical manifestations of liver spots; these lesions do not return for at least six months after therapy is discontinued. \n\n【9】Introduction\n------------\n\n【10】THE presence of hyperpigmented macules (liver spots) on the face or other exposed areas usually indicates substantial damage due to exposure to sunlight (photodamage). To date, the treatment for such lesions, many of which are actinic lentigines, has been surgery or chemical peeling.  Bleaching agents such as hydroquinones often produce undesirable depigmentation, and opaque cosmetics do not treat the underlying problem.\n\n【11】Tretinoin (retinoic acid) is a potent inhibitor of new melanin production,  and recent studies have suggested that topical therapy with tretinoin may decrease the macular hyperpigmentation.  <sup><a>4 </a></sup>  <sup><a>6 </a></sup>  Therefore, we performed a study specifically designed to evaluate the efficacy of topical tretinoin cream in the treatment of hyperpigmented lesions associated with photodamage; we found that 0.1 percent tretinoin is an effective topical treatment.\n\n【12】Methods\n-------\n\n【13】Patients and Design\n-------------------\n\n【14】Sixty healthy white patients, each with at least four hyperpigmented macules with the clinical characteristics of actinic lentigines, participated in the initial 10-month study of tretinoin or vehicle treatment. At least one of these lesions had to be of sufficient size to allow two separate 2-mm punch-biopsy specimens to be obtained. A total of 24 women and 6 men were treated with tretinoin and 25 women and 5 men were given vehicle. They ranged in age from 36 to 86 years (mean, 67) in the tretinoin group and from 48 to 81 years (mean, 65) in the vehicle group.\n\n【15】None of the patients had used topical or systemic retinoids for six months, any topical medications for at least two weeks, or systemic steroids for one month before the study. Pregnant and nursing women and patients who had received oral psoralen and ultraviolet A radiation were excluded. The protocol, which had been approved by the institutional review board of the University of Michigan Medical Center, and the potential side effects of the treatment were explained to each patient, and all signed informed-consent forms.\n\n【16】A computer-generated code was used for the random assignment of the patients to the treatment groups on the basis of their order of entry into the study. The treatments were either 0.1 percent tretinoin cream (Retin-A, Ortho Pharmaceutical, Raritan, N.J.) or color-matched vehicle cream. All dispensed tubes were identical in appearance; therefore, both the investigators and the patients were unaware of the group to which the patient had been assigned. The sample sizes were chosen to provide a statistical power of approximately 0.80 to detect a difference in overall improvement of at least one half-unit (as defined below) between the two treatment groups at a Type I error rate of 0.05 for a two-tailed hypothesis.\n\n【17】Fifteen of the patients who had a good response during the initial 10-month study (all of whom proved to have received tretinoin) and who wished to participate in an additional 6-month study were randomly assigned to receive either 0.1 percent tretinoin or vehicle cream. In this phase of the study there were five women and three men (age, 36 to 80 years; mean, 66) in the tretinoin group, and five women and two men (age, 46 to 83; mean, 66) in the vehicle group.\n\n【18】Treatment\n---------\n\n【19】The patients applied the study compounds once nightly to the face, arms, forearms, backs of the hands, or any combination of these sites that had hyperpigmented lesions. Initially, a pea-sized amount of cream was used on each affected area. The patients were encouraged to increase gradually the quantity of cream applied until mild erythema or scaling ensued.\n\n【20】The patients were supplied with a mild soap and asked to wash with this or a similar agent at least 20 minutes before applying the study treatment. All patients also received a mild emollient to be used when needed for skin irritation or dryness. They were advised to avoid excessive exposure to the sun or sunlamps during the study. Sunscreen with a protection factor of 15 was provided. They also were instructed to minimize the use of cosmetics, which were not worn during evaluations or photographic sessions. For 24 hours before each evaluation, the patients did not apply any topical preparations, including the study treatment, emollients, or sunscreen.\n\n【21】Clinical Evaluations\n--------------------\n\n【22】Clinical evaluations were performed before treatment, after two and four weeks of treatment, and monthly thereafter. Monthly evaluations were also performed during the six-month extended study. One investigator evaluated the patients at the majority of visits. For each patient, the overall clinical response of each area under treatment was rated by the investigator in terms of changes in color —that is, as much darker, darker, unchanged, lighter, or much lighter. The results for the arms, forearms, and backs of the hands were averaged for each patient and are reported as results for the upper extremities.\n\n【23】In addition to the overall assessment, four hyperpigmented lesions were identified before treatment on the basis of the likelihood of accurately locating these lesions throughout the study, thus allowing us to correlate the clinical and histologic results in the same lesions. Pretreatment photographs aided in locating specific lesions. At each return visit, the degree of hyperpigmentation of each of these lesions was compared with that before treatment, and color was graded by the investigator as much darker, darker, slightly darker, unchanged, slightly lighter, lighter, much lighter, or absent.\n\n【24】The degrees of erythema, scaling, burning or stinging, and pruritus were assessed at all visits with the use of a five-point scale, in which 0 indicated the absence of such symptoms, 1 the presence of mild symptoms, 2 the presence of moderate symptoms, 3 the presence of moderately severe symptoms, and 4 the presence of severe symptoms. A cutaneous reaction was defined as the presence of at least moderate erythema or scaling at two or more visits.\n\n【25】Light-Microscopical Analysis\n----------------------------\n\n【26】Of the four lesions specifically identified in each patient, one of sufficient size was selected to be the site of two full-thickness punch biopsies (each measuring 2 mm in diameter) before and after 10 months of treatment for light-microscopical analysis. Post-treatment biopsy specimens from two patients in the vehicle group were not available because of laboratory errors.\n\n【27】The specimens were fixed in 10 percent neutral-buffered formalin, embedded in paraffin, sectioned, and stained with hematoxylin and eosin. The investigator who analyzed the specimens was not aware of either the patient's treatment or the time of the biopsy. The histologic sections were assessed for the presence of various characteristics with a semiquantitative ordinal five-point scale in half-unit increments, in which 0 indicated the absence of the characteristics and 4 indicated the maximal degree of the characteristics. Epidermal thickness was measured directly.\n\n【28】Photographic Analysis\n---------------------\n\n【29】All data were obtained by direct assessment of patients, and none were derived by assessing photographs. The photographs for documentation of the lesional areas were taken by a professional photographer before and during treatment using standardized positioning and lighting of the patients and film from a single emulsion lot processed by a single professional laboratory. A standard gray card (18 percent reflectance) was included in the first picture during each session to control for any shifts in color or density due to extraneous variables.\n\n【30】Statistical Analysis\n--------------------\n\n【31】Table 1. Mean Clinically Apparent Change in Color after 10 Months of Treatment with Tretinoin or Vehicle, According to the Type of Lesion.\\*\n\n【32】The changes in clinical and histologic measures of the hyperpigmented lesions before and during treatment in the tretinoin and vehicle groups were compared by means of the two-sample t-test. The association between treatment and overall response after 10 and 16 months was made with the chi-square test. The comparison of changes in color of the specifically identified lesions in the two groups was based on the average of the changes in the four lesions; the clinical changes in color of the single lesion that underwent biopsy were analyzed according to histologic diagnosis . In each case, group means were compared by the two-sample t-test. The ratings for change in color, which were initially assigned values ranging from 1 to 8 for computer data entry, were reassigned values ranging from -3 to +4 so that a rating of no change would equal 0. Overall scores were reassigned in the same fashion. These arithmetic adjustments had no effect on the statistical analyses, P values, or conclusions drawn. Correlations between clinical and histologic variables were assessed with Pearson's product-moment correlation coefficient.\n\n【33】All analyses included all patients who could be evaluated;<mark> only in Table 1 are patients stratified according to histologic diagnosis.</mark> All P values are two-sided. Summary statistics are expressed as means ±SE. Data were analyzed with the Michigan Interactive Data Analysis System (MIDAS, a statistical software package developed by the Center for Statistical Consultation and Research at the University of Michigan).\n\n【34】Results\n-------\n\n【35】Fifty-eight of the 60 patients completed the 10-month study. Two patients in the tretinoin group dropped out, one after two months because of non-compliance and the other after one month because of an exacerbation of atopic dermatitis. Therefore, clinical data for the first 10 months are presented for 30 patients in the vehicle group (28 with facial lesions and 26 with upper-extremity lesions) and 28 in the tretinoin group (24 with facial lesions and 26 with upper-extremity lesions).\n\n【36】Clinical Results\n----------------\n\n【37】### __Overall Scores__\n\n<mark>【38】Figure 1. </mark>Examples of the Best Responses to Tretinoin Therapy in Three Patients.\n\n【39】Panel A shows a 79-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 additional months of tretinoin (6 mo f/u). Many hyperpigmented lesions had disappeared and others had lightened after 10 months of tretinoin therapy, with continued improvement after 6 additional months of therapy. Panel B shows an 84-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 months of vehicle (6 mo f/u). After 10 months of tretinoin therapy, many brown spots had cleared, and a retinoid reaction had occurred; after 6 months of vehicle, no relapse had occurred. Panels C and D show a 70-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 5 months of no treatment (5 mos. off). All lesions had disappeared after 10 months of treatment and had not reappeared 5 months after tretinoin was stopped<mark>.Figure 2.  Figure 2. </mark>Overall Efficacy of 10 Months of Treatment with Tretinoin or Vehicle Cream for Hyperpigmented Lesions of the Face and Upper Extremities.\n\n【40】As compared with vehicle, tretinoin caused significant lightening of hyperpigmented lesions of the face (P = 0.0002) and upper extremities (P = 0.0001). Among the patients given tretinoin, 24 had facial lesions and 26 had upper-extremity lesions. Among the patients given vehicle, 28 had facial lesions and 26 had upper-extremity lesions. Not all percentages sum to 100 because of rounding.\n\n【41】After 10 months of treatment, the overall scores demonstrated statistically significant lightening of hyperpigmented facial and upper-extremity lesions in the group receiving tretinoin as compared with the group receiving vehicle . Among the 24 tretinoin-treated patients who had facial lesions, <mark>the Figure 1 . </mark>Examples of the Best Responses to Tretinoin Therapy in Three Patients. Panel A shows a 79-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 additional months of tretinoin (6 mo f/u). Many hyperpigmented lesions had disappeared and others had lightened after 10 months of tretinoin therapy, with continued improvement after 6 additional months of therapy. Panel B shows an 84-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 months of vehicle (6 mo f/u). After 10 months of tretinoin therapy, many brown spots had cleared, and a retinoid reaction had occurred; after 6 months of vehicle, no relapse had occurred. Panels C and D show a 70-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 5 months of no treatment (5 mos. off). All lesions had disappeared after 10 months of treatment and had not reappeared 5 months after tretinoin was stopped. lesions were much lighter in 10 (42 percent), lighter in 10 (42 percent), and unchanged in 4 (17 percent) after 10 months of therapy. Among the 28 patients with facial lesions who received vehicle, the lesions were much lighter in 2 (7 percent), lighter in 6 (21 percent), and unchanged in 20 (71 percent). Thus, 20 patients in the tretinoin group (83 percent) and 8 patients in the vehicle group (29 percent) had some lightening of facial lesions. Among the 26 tretinoin-treated patients who had upper-extremity lesions, the lesions were much lighter in 6 (23 percent), lighter in 17 (65 percent), and unchanged in 3 (12 percent) after 10 months of therapy. Among the 26 patients with upper-extremity lesions who received vehicle, the lesions were much lighter in 1 (4 percent), lighter in 7 (27 percent), and unchanged in 18 (69 percent). The overall score did not worsen in either group during treatment.\n\n<mark>【42】Figure 3.</mark> Overall Change in Color in Response to Treatment with Tretinoin (Solid Lines) or Vehicle (Broken Lines).\n\n【43】Circles and error bars indicate means ±SE. Statistically significant and clinically detectable lightening of facial and upper-extremity lesions was evident after four weeks of tretinoin treatment and was maintained for the rest of the study. Asterisks denote a significant difference (P≤0.002) between groups.\n\n【44】A significant overall improvement in the tretinoin group, as compared with the vehicle group, was first attained after one month of therapy (P≤0.002) . An overall improvement of facial and upper-extremity lesions occurred in 44 and 58 percent of patients, respectively, after 1 month of tretinoin treatment, in 75 and 85 percent of patients after 6 months of treatment, and in 83 and 88 percent after 10 months of treatment.\n\n【45】### __Specific Lesions__\n\n【46】When the scores for the four lesions were averaged for each patient, there was a significant improvement in the tretinoin group as compared with the vehicle group after 10 months of treatment (P<0.0001). At the end of the 10-month study, the lesions had lightened in 20 of the 28 patients (71 percent) in the tretinoin group but in only 7 of the 30 patients (23 percent) in the vehicle group. Nine of the 28 patients (32 percent) receiving tretinoin had complete clearing of one or more of these lesions; the mean length of time required for clearance of the lesions was 8 months (range, 5 to 10). None of the lesions completely disappeared in any of the patients who received vehicle.\n\n【47】### __Six-Month Follow-up Study__\n\n【48】Fifteen patients who responded well to treatment in the initial 10-month study were assigned to tretinoin or vehicle for an additional 6 months. When the code was broken, all 15 patients who entered the six-month follow-up study proved to have received tretinoin; randomization at this stage resulted in 8 being assigned to receive tretinoin and 7 vehicle. One patient who was reassigned to the tretinoin group withdrew one month later because of contact dermatitis (proved by patch testing) due to quaternium-15, a preservative in the emollient.\n\n【49】The group reassigned to tretinoin treatment had a further significant overall improvement of lesions located on the face (P = 0.01) and upper extremities (P = 0.0005), as compared with the group assigned to vehicle. In this phase of the study, of six tretinoin-treated patients who had hyperpigmented facial lesions, the lesions were much lighter in two, lighter in three, and unchanged in one, as compared with the results at the end of the 10-month phase. All tretinoin-treated patients with upper-extremity lesions had further lightening of their lesions during this same period. In contrast, there was no change in facial or upper-extremity lesions in patients who received vehicle during the six-month follow-up study.\n\n【50】Four patients who had had complete clearing of at least one of the four identified lesions during the 10-month course of tretinoin maintained these results during the subsequent 6-month course of tretinoin. Of two other patients who had no clearing of any specified lesions during the first 10 months of tretinoin treatment, each had one lesion completely disappear with continued tretinoin treatment during the 6-month follow-up study. Three patients who had at least one lesion resolve during the first 10 months of tretinoin therapy received vehicle for 6 months; none of their lesions returned. The patient who withdrew because of contact dermatitis had no recurrence of lesions after five months without treatment . None of the patients who received vehicle cream had complete clearing of any of the four identified lesions during the six-month follow-up study.\n\n【51】Cutaneous Reactions\n-------------------\n\n【52】During the study the patients reported only cutaneous reactions,  <sup><a>9 </a></sup>  characterized principally by erythema and scaling. Erythema or scaling of at least moderate severity occurred more than once in 23 of the 28 patients receiving tretinoin (82 percent) and in 2 of the 30 patients given vehicle (7 percent) during the initial 10-month study. Five of the seven patients who received tretinoin, but none of the seven patients who received vehicle, had such reactions during the six-month follow-up study.\n\n【53】The rash occurred only in areas that came into contact with the topical medication and varied in intensity and duration among the patients and in any individual patient at different times. Scaling or erythema began one to four weeks after the start of tretinoin treatment. In all cases, the scaling and erythema were most noticeable during the first two months, after which there was a progressive decrease in their severity, frequency, and duration.\n\n【54】The cutaneous reactions improved when emollients were applied more frequently and the amount of study medication used was decreased or treatment was stopped for one to three days. Three patients, two receiving tretinoin and one receiving vehicle, applied 1 percent hydrocortisone cream for a maximum of five days to sites of irritation during the initial phase of the study.\n\n【55】Histologic Results\n------------------\n\n【56】A punch-biopsy specimen of a single lesion in each patient was obtained before and after treatment. The pretreatment biopsy specimens were classified by light microscopy as either actinic lentigines or nonlentiginous lesions (lesions that did not meet the criteria for actinic lentigines) . Both the actinic lentigines and nonlentiginous lesions lightened after treatment with tretinoin cream (P = 0.05 and P = 0.002, respectively) .\n\n【57】Table 2. Histologic Features of Biopsy Specimens Obtained before and after 10 Months of Treatment with Tretinoin or Vehicle.\\* Figure 4.  Figure 4. Histologic Appearance of a Hyperpigmented Lesion before Treatment (Top Panel) and after 10 Months of Treatment with 0.1 Percent Tretinoin (Bottom Panel).\n\n【58】The two specimens are from a single hyperpigmented lesion from the patient shown in Figures 1 C and 1 D (Fontana—Masson stain, ×90). After 10 months of treatment, the degree of epidermal pigmentation decreased markedly.Figure 5.  Figure 5. Relation between Histologic Changes in the Degree of Epidermal Pigmentation and Clinically Apparent Color Changes after 10 Months of Treatment with Tretinoin (N = 28) or Vehicle (N = 28).\n\n【59】The lesions with the best clinical response tended to have the greatest decrease in epidermal pigmentation (the best linear fit is represented by the line; r = -0.53, P<0.0001).\n\n【60】Ten months of topical tretinoin as compared with vehicle treatment resulted in a significant increase in the mean degree of compaction of stratum corneum, the thickness of the granular cell layer, epidermal thickness, the degree of spongiosis (i.e., widening of the spaces between keratinocytes), and the severity of perivascular mononuclear dermal inflammation . Light microscopy of the lesions showed that the degree of epidermal pigmentation decreased by 35 percent in the tretinoin group, whereas it increased by 34 percent in the vehicle group (P = 0.0008) . A reduction in epidermal pigmentation occurred in most tretinoin-treated patients . Histologically discernible changes in epidermal pigmentation were significantly correlated with clinically observable changes in the color of lesions from which biopsy samples were obtained (r = -0.53, P<0.0001) . None of the lesions that had more pigment on microscopical examination appeared darker clinically.\n\n【61】Discussion\n----------\n\n【62】We have demonstrated that 0.1 percent tretinoin cream is an effective treatment for hyperpigmented lesions (liver spots) associated with photodamage. Clinically apparent and statistically significant lightening of hyperpigmented lesions occurred as early as 1 month after the initiation of treatment, and at least one lesion disappeared in 32 percent of the patients during the 10-month treatment. Furthermore, none of the lesions that completely cleared returned during a subsequent six-month period in which vehicle alone was given.\n\n【63】All types of lesions responded to treatment with tretinoin, not just those that proved histologically to be actinic lentigines . Our findings suggest that despite the difficulties involved in diagnosing actinic lentigines clinically,  tretinoin is beneficial for various irregular hyperpigmented macules, regardless of their histologic characteristics. Indeed, previous studies have reported favorable results with tretinoin treatment of some premalignant and malignant neoplasms.  <sup><a>13 </a></sup>  <sup><a>15 </a></sup>  <sup><a>17 </a></sup>  <sup><a>19 </a></sup>  <sup><a>21</a></sup>\n\n【64】Our clinical experience, as well as that of Kligman,  suggests that patients with these skin lesions derive the best results from topical tretinoin when they increase the amount of medication to a point just short of intolerance. Thus, the lack of overall improvement in 17 percent of patients receiving tretinoin may have been due to the use of insufficient quantities of medication. Conversely, some vehicle-treated patients had lightening of their lesions because some improvement may occur with only emollient therapy, avoidance of sunlight, and the use of sunscreens.\n\n【65】None of the patients had adverse reactions that were severe or permanent; previous studies have also demonstrated an excellent safety profile for topical tretinoin.  <sup><a>4 </a></sup>  <sup><a>6 </a></sup>  <sup><a>22 </a></sup> Eighty-two percent of the patients treated with tretinoin and 7 percent of those who received vehicle in the initial 10-month study had a local reaction. Thus, it may have been possible at times to determine whether a patient was receiving tretinoin; however, such side effects were not evident during most of the patient evaluations. To reduce the possibility of bias, we graded all variables in relation to baseline values without referring to the data obtained from any of the other visits. Moreover, our photographic documentation  and the statistically significant histologic findings corroborated the clinical data.\n\n【66】The histologic studies revealed a decrease in epidermal pigmentation in tretinoin-treated lesions that correlated significantly with the degree of clinical lightening; however, there was no change in the number or size of melanocytes. Thus, the epidermis had less pigment after tretinoin therapy, an observation compatible with the work of Orlow et al.,  who showed that tretinoin inhibits induced melanogenesis. The other histologic changes seen in the biopsy specimens, such as epidermal thickening, are characteristic of the action of tretinoin on the skin.  <sup>, </sup>  <sup>, </sup>  Histologically, epidermal pigmentation increased in the group receiving vehicle, probably as a result of ongoing melanogenesis.\n\n【67】In our experience, actinic lentigines and other hyperpigmented lesions associated with photodamage do not completely disappear spontaneously. As a noninvasive therapy, topical 0.1 percent tretinoin cream, coupled with avoidance of the sun and appropriate use of sunscreen, is an effective, nondestructive approach to improving and sometimes clearing these lesions.", "index": 20019, "show": true, "start": 19941, "end": 19945, "province": ["文本干净度", "页码/数字"], "isEdit": false}, {"text": " 4   6   22  ", "content": "【0】Topical Tretinoin (Retinoic Acid) Treatment for Liver Spots Associated with Photodamage\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】The hyperpigmented lesions commonly called liver spots distress patients, in part because such lesions are associated with aging. We investigated their treatment with topical 0.1 percent tretinoin (retinoic acid).\n\n【3】Methods.\n--------\n\n【4】Fifty-eight patients completed a 10-month randomized, double-blind study in which they applied either 0.1 percent tretinoin (n = 28) or vehicle (n = 30) cream daily to the face, upper extremities, or both. Fifteen patients who responded well were then randomly assigned to continue tretinoin therapy or use vehicle alone for six more months. Patients were evaluated by physical examination every month and by analysis of biopsy specimens of lesions obtained at base line and at the end of the 10-month trial.\n\n【5】Results.\n--------\n\n【6】After one month of treatment the patients treated with tretinoin had significant lightening of hyperpigmented lesions as compared with the patients who received vehicle (P<0.002). After 10 months, 20 (83 percent) of the 24 patients with facial lesions who were treated with tretinoin had lightening of these lesions, as compared with 8 (29 percent) of the 28 patients with facial lesions who received vehicle. The results for lesions of the upper extremities were similar. As compared with vehicle, tretinoin caused a significant decrease in the degree of epidermal pigmentation and increases in the degree of compaction of stratum corneum, thickness of the granular cell layer, and epidermal thickness. Reductions in epidermal pigmentation evident on histologic analysis were significantly correlated with the degree of clinical lightening of lesions (r = -0.53, P<0.0001). During the 6-month follow-up study, specifically identified lesions that had disappeared during the first 10 months of tretinoin treatment did not return in any patient, and six of seven patients who continued to use tretinoin had further improvement.\n\n【7】Conclusions.\n------------\n\n【8】Topical 0.1 percent tretinoin significantly improves both clinical and microscopical manifestations of liver spots; these lesions do not return for at least six months after therapy is discontinued. \n\n【9】Introduction\n------------\n\n【10】THE presence of hyperpigmented macules (liver spots) on the face or other exposed areas usually indicates substantial damage due to exposure to sunlight (photodamage). To date, the treatment for such lesions, many of which are actinic lentigines, has been surgery or chemical peeling.  Bleaching agents such as hydroquinones often produce undesirable depigmentation, and opaque cosmetics do not treat the underlying problem.\n\n【11】Tretinoin (retinoic acid) is a potent inhibitor of new melanin production,  and recent studies have suggested that topical therapy with tretinoin may decrease the macular hyperpigmentation.  <sup><a>4 </a></sup>  <sup><a>6 </a></sup>  Therefore, we performed a study specifically designed to evaluate the efficacy of topical tretinoin cream in the treatment of hyperpigmented lesions associated with photodamage; we found that 0.1 percent tretinoin is an effective topical treatment.\n\n【12】Methods\n-------\n\n【13】Patients and Design\n-------------------\n\n【14】Sixty healthy white patients, each with at least four hyperpigmented macules with the clinical characteristics of actinic lentigines, participated in the initial 10-month study of tretinoin or vehicle treatment. At least one of these lesions had to be of sufficient size to allow two separate 2-mm punch-biopsy specimens to be obtained. A total of 24 women and 6 men were treated with tretinoin and 25 women and 5 men were given vehicle. They ranged in age from 36 to 86 years (mean, 67) in the tretinoin group and from 48 to 81 years (mean, 65) in the vehicle group.\n\n【15】None of the patients had used topical or systemic retinoids for six months, any topical medications for at least two weeks, or systemic steroids for one month before the study. Pregnant and nursing women and patients who had received oral psoralen and ultraviolet A radiation were excluded. The protocol, which had been approved by the institutional review board of the University of Michigan Medical Center, and the potential side effects of the treatment were explained to each patient, and all signed informed-consent forms.\n\n【16】A computer-generated code was used for the random assignment of the patients to the treatment groups on the basis of their order of entry into the study. The treatments were either 0.1 percent tretinoin cream (Retin-A, Ortho Pharmaceutical, Raritan, N.J.) or color-matched vehicle cream. All dispensed tubes were identical in appearance; therefore, both the investigators and the patients were unaware of the group to which the patient had been assigned. The sample sizes were chosen to provide a statistical power of approximately 0.80 to detect a difference in overall improvement of at least one half-unit (as defined below) between the two treatment groups at a Type I error rate of 0.05 for a two-tailed hypothesis.\n\n【17】Fifteen of the patients who had a good response during the initial 10-month study (all of whom proved to have received tretinoin) and who wished to participate in an additional 6-month study were randomly assigned to receive either 0.1 percent tretinoin or vehicle cream. In this phase of the study there were five women and three men (age, 36 to 80 years; mean, 66) in the tretinoin group, and five women and two men (age, 46 to 83; mean, 66) in the vehicle group.\n\n【18】Treatment\n---------\n\n【19】The patients applied the study compounds once nightly to the face, arms, forearms, backs of the hands, or any combination of these sites that had hyperpigmented lesions. Initially, a pea-sized amount of cream was used on each affected area. The patients were encouraged to increase gradually the quantity of cream applied until mild erythema or scaling ensued.\n\n【20】The patients were supplied with a mild soap and asked to wash with this or a similar agent at least 20 minutes before applying the study treatment. All patients also received a mild emollient to be used when needed for skin irritation or dryness. They were advised to avoid excessive exposure to the sun or sunlamps during the study. Sunscreen with a protection factor of 15 was provided. They also were instructed to minimize the use of cosmetics, which were not worn during evaluations or photographic sessions. For 24 hours before each evaluation, the patients did not apply any topical preparations, including the study treatment, emollients, or sunscreen.\n\n【21】Clinical Evaluations\n--------------------\n\n【22】Clinical evaluations were performed before treatment, after two and four weeks of treatment, and monthly thereafter. Monthly evaluations were also performed during the six-month extended study. One investigator evaluated the patients at the majority of visits. For each patient, the overall clinical response of each area under treatment was rated by the investigator in terms of changes in color —that is, as much darker, darker, unchanged, lighter, or much lighter. The results for the arms, forearms, and backs of the hands were averaged for each patient and are reported as results for the upper extremities.\n\n【23】In addition to the overall assessment, four hyperpigmented lesions were identified before treatment on the basis of the likelihood of accurately locating these lesions throughout the study, thus allowing us to correlate the clinical and histologic results in the same lesions. Pretreatment photographs aided in locating specific lesions. At each return visit, the degree of hyperpigmentation of each of these lesions was compared with that before treatment, and color was graded by the investigator as much darker, darker, slightly darker, unchanged, slightly lighter, lighter, much lighter, or absent.\n\n【24】The degrees of erythema, scaling, burning or stinging, and pruritus were assessed at all visits with the use of a five-point scale, in which 0 indicated the absence of such symptoms, 1 the presence of mild symptoms, 2 the presence of moderate symptoms, 3 the presence of moderately severe symptoms, and 4 the presence of severe symptoms. A cutaneous reaction was defined as the presence of at least moderate erythema or scaling at two or more visits.\n\n【25】Light-Microscopical Analysis\n----------------------------\n\n【26】Of the four lesions specifically identified in each patient, one of sufficient size was selected to be the site of two full-thickness punch biopsies (each measuring 2 mm in diameter) before and after 10 months of treatment for light-microscopical analysis. Post-treatment biopsy specimens from two patients in the vehicle group were not available because of laboratory errors.\n\n【27】The specimens were fixed in 10 percent neutral-buffered formalin, embedded in paraffin, sectioned, and stained with hematoxylin and eosin. The investigator who analyzed the specimens was not aware of either the patient's treatment or the time of the biopsy. The histologic sections were assessed for the presence of various characteristics with a semiquantitative ordinal five-point scale in half-unit increments, in which 0 indicated the absence of the characteristics and 4 indicated the maximal degree of the characteristics. Epidermal thickness was measured directly.\n\n【28】Photographic Analysis\n---------------------\n\n【29】All data were obtained by direct assessment of patients, and none were derived by assessing photographs. The photographs for documentation of the lesional areas were taken by a professional photographer before and during treatment using standardized positioning and lighting of the patients and film from a single emulsion lot processed by a single professional laboratory. A standard gray card (18 percent reflectance) was included in the first picture during each session to control for any shifts in color or density due to extraneous variables.\n\n【30】Statistical Analysis\n--------------------\n\n【31】Table 1. Mean Clinically Apparent Change in Color after 10 Months of Treatment with Tretinoin or Vehicle, According to the Type of Lesion.\\*\n\n【32】The changes in clinical and histologic measures of the hyperpigmented lesions before and during treatment in the tretinoin and vehicle groups were compared by means of the two-sample t-test. The association between treatment and overall response after 10 and 16 months was made with the chi-square test. The comparison of changes in color of the specifically identified lesions in the two groups was based on the average of the changes in the four lesions; the clinical changes in color of the single lesion that underwent biopsy were analyzed according to histologic diagnosis . In each case, group means were compared by the two-sample t-test. The ratings for change in color, which were initially assigned values ranging from 1 to 8 for computer data entry, were reassigned values ranging from -3 to +4 so that a rating of no change would equal 0. Overall scores were reassigned in the same fashion. These arithmetic adjustments had no effect on the statistical analyses, P values, or conclusions drawn. Correlations between clinical and histologic variables were assessed with Pearson's product-moment correlation coefficient.\n\n【33】All analyses included all patients who could be evaluated;<mark> only in Table 1 are patients stratified according to histologic diagnosis.</mark> All P values are two-sided. Summary statistics are expressed as means ±SE. Data were analyzed with the Michigan Interactive Data Analysis System (MIDAS, a statistical software package developed by the Center for Statistical Consultation and Research at the University of Michigan).\n\n【34】Results\n-------\n\n【35】Fifty-eight of the 60 patients completed the 10-month study. Two patients in the tretinoin group dropped out, one after two months because of non-compliance and the other after one month because of an exacerbation of atopic dermatitis. Therefore, clinical data for the first 10 months are presented for 30 patients in the vehicle group (28 with facial lesions and 26 with upper-extremity lesions) and 28 in the tretinoin group (24 with facial lesions and 26 with upper-extremity lesions).\n\n【36】Clinical Results\n----------------\n\n【37】### __Overall Scores__\n\n<mark>【38】Figure 1. </mark>Examples of the Best Responses to Tretinoin Therapy in Three Patients.\n\n【39】Panel A shows a 79-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 additional months of tretinoin (6 mo f/u). Many hyperpigmented lesions had disappeared and others had lightened after 10 months of tretinoin therapy, with continued improvement after 6 additional months of therapy. Panel B shows an 84-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 months of vehicle (6 mo f/u). After 10 months of tretinoin therapy, many brown spots had cleared, and a retinoid reaction had occurred; after 6 months of vehicle, no relapse had occurred. Panels C and D show a 70-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 5 months of no treatment (5 mos. off). All lesions had disappeared after 10 months of treatment and had not reappeared 5 months after tretinoin was stopped<mark>.Figure 2.  Figure 2. </mark>Overall Efficacy of 10 Months of Treatment with Tretinoin or Vehicle Cream for Hyperpigmented Lesions of the Face and Upper Extremities.\n\n【40】As compared with vehicle, tretinoin caused significant lightening of hyperpigmented lesions of the face (P = 0.0002) and upper extremities (P = 0.0001). Among the patients given tretinoin, 24 had facial lesions and 26 had upper-extremity lesions. Among the patients given vehicle, 28 had facial lesions and 26 had upper-extremity lesions. Not all percentages sum to 100 because of rounding.\n\n【41】After 10 months of treatment, the overall scores demonstrated statistically significant lightening of hyperpigmented facial and upper-extremity lesions in the group receiving tretinoin as compared with the group receiving vehicle . Among the 24 tretinoin-treated patients who had facial lesions, <mark>the Figure 1 . </mark>Examples of the Best Responses to Tretinoin Therapy in Three Patients. Panel A shows a 79-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 additional months of tretinoin (6 mo f/u). Many hyperpigmented lesions had disappeared and others had lightened after 10 months of tretinoin therapy, with continued improvement after 6 additional months of therapy. Panel B shows an 84-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 months of vehicle (6 mo f/u). After 10 months of tretinoin therapy, many brown spots had cleared, and a retinoid reaction had occurred; after 6 months of vehicle, no relapse had occurred. Panels C and D show a 70-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 5 months of no treatment (5 mos. off). All lesions had disappeared after 10 months of treatment and had not reappeared 5 months after tretinoin was stopped. lesions were much lighter in 10 (42 percent), lighter in 10 (42 percent), and unchanged in 4 (17 percent) after 10 months of therapy. Among the 28 patients with facial lesions who received vehicle, the lesions were much lighter in 2 (7 percent), lighter in 6 (21 percent), and unchanged in 20 (71 percent). Thus, 20 patients in the tretinoin group (83 percent) and 8 patients in the vehicle group (29 percent) had some lightening of facial lesions. Among the 26 tretinoin-treated patients who had upper-extremity lesions, the lesions were much lighter in 6 (23 percent), lighter in 17 (65 percent), and unchanged in 3 (12 percent) after 10 months of therapy. Among the 26 patients with upper-extremity lesions who received vehicle, the lesions were much lighter in 1 (4 percent), lighter in 7 (27 percent), and unchanged in 18 (69 percent). The overall score did not worsen in either group during treatment.\n\n<mark>【42】Figure 3.</mark> Overall Change in Color in Response to Treatment with Tretinoin (Solid Lines) or Vehicle (Broken Lines).\n\n【43】Circles and error bars indicate means ±SE. Statistically significant and clinically detectable lightening of facial and upper-extremity lesions was evident after four weeks of tretinoin treatment and was maintained for the rest of the study. Asterisks denote a significant difference (P≤0.002) between groups.\n\n【44】A significant overall improvement in the tretinoin group, as compared with the vehicle group, was first attained after one month of therapy (P≤0.002) . An overall improvement of facial and upper-extremity lesions occurred in 44 and 58 percent of patients, respectively, after 1 month of tretinoin treatment, in 75 and 85 percent of patients after 6 months of treatment, and in 83 and 88 percent after 10 months of treatment.\n\n【45】### __Specific Lesions__\n\n【46】When the scores for the four lesions were averaged for each patient, there was a significant improvement in the tretinoin group as compared with the vehicle group after 10 months of treatment (P<0.0001). At the end of the 10-month study, the lesions had lightened in 20 of the 28 patients (71 percent) in the tretinoin group but in only 7 of the 30 patients (23 percent) in the vehicle group. Nine of the 28 patients (32 percent) receiving tretinoin had complete clearing of one or more of these lesions; the mean length of time required for clearance of the lesions was 8 months (range, 5 to 10). None of the lesions completely disappeared in any of the patients who received vehicle.\n\n【47】### __Six-Month Follow-up Study__\n\n【48】Fifteen patients who responded well to treatment in the initial 10-month study were assigned to tretinoin or vehicle for an additional 6 months. When the code was broken, all 15 patients who entered the six-month follow-up study proved to have received tretinoin; randomization at this stage resulted in 8 being assigned to receive tretinoin and 7 vehicle. One patient who was reassigned to the tretinoin group withdrew one month later because of contact dermatitis (proved by patch testing) due to quaternium-15, a preservative in the emollient.\n\n【49】The group reassigned to tretinoin treatment had a further significant overall improvement of lesions located on the face (P = 0.01) and upper extremities (P = 0.0005), as compared with the group assigned to vehicle. In this phase of the study, of six tretinoin-treated patients who had hyperpigmented facial lesions, the lesions were much lighter in two, lighter in three, and unchanged in one, as compared with the results at the end of the 10-month phase. All tretinoin-treated patients with upper-extremity lesions had further lightening of their lesions during this same period. In contrast, there was no change in facial or upper-extremity lesions in patients who received vehicle during the six-month follow-up study.\n\n【50】Four patients who had had complete clearing of at least one of the four identified lesions during the 10-month course of tretinoin maintained these results during the subsequent 6-month course of tretinoin. Of two other patients who had no clearing of any specified lesions during the first 10 months of tretinoin treatment, each had one lesion completely disappear with continued tretinoin treatment during the 6-month follow-up study. Three patients who had at least one lesion resolve during the first 10 months of tretinoin therapy received vehicle for 6 months; none of their lesions returned. The patient who withdrew because of contact dermatitis had no recurrence of lesions after five months without treatment . None of the patients who received vehicle cream had complete clearing of any of the four identified lesions during the six-month follow-up study.\n\n【51】Cutaneous Reactions\n-------------------\n\n【52】During the study the patients reported only cutaneous reactions, <mark> 9  </mark>p><a>9 </a></sup>  characterized principally by erythema and scaling. Erythema or scaling of at least moderate severity occurred more than once in 23 of the 28 patients receiving tretinoin (82 percent) and in 2 of the 30 patients given vehicle (7 percent) during the initial 10-month study. Five of the seven patients who received tretinoin, but none of the seven patients who received vehicle, had such reactions during the six-month follow-up study.\n\n【53】The rash occurred only in areas that came into contact with the topical medication and varied in intensity and duration among the patients and in any individual patient at different times. Scaling or erythema began one to four weeks after the start of tretinoin treatment. In all cases, the scaling and erythema were most noticeable during the first two months, after which there was a progressive decrease in their severity, frequency, and duration.\n\n【54】The cutaneous reactions improved when emollients were applied more frequently and the amount of study medication used was decreased or treatment was stopped for one to three days. Three patients, two receiving tretinoin and one receiving vehicle, applied 1 percent hydrocortisone cream for a maximum of five days to sites of irritation during the initial phase of the study.\n\n【55】Histologic Results\n------------------\n\n【56】A punch-biopsy specimen of a single lesion in each patient was obtained before and after treatment. The pretreatment biopsy specimens were classified by light microscopy as either actinic lentigines or nonlentiginous lesions (lesions that did not meet the criteria for actinic lentigines) . Both the actinic lentigines and nonlentiginous lesions lightened after treatment with tretinoin cream (P = 0.05 and P = 0.002, respectively) .\n\n【57】Table 2. Histologic Features of Biopsy Specimens Obtained before and after 10 Months of Treatment with Tretinoin or Vehicle.\\* Figure 4.  Figure 4. Histologic Appearance of a Hyperpigmented Lesion before Treatment (Top Panel) and after 10 Months of Treatment with 0.1 Percent Tretinoin (Bottom Panel).\n\n【58】The two specimens are from a single hyperpigmented lesion from the patient shown in Figures 1 C and 1 D (Fontana—Masson stain, ×90). After 10 months of treatment, the degree of epidermal pigmentation decreased markedly.Figure 5.  Figure 5. Relation between Histologic Changes in the Degree of Epidermal Pigmentation and Clinically Apparent Color Changes after 10 Months of Treatment with Tretinoin (N = 28) or Vehicle (N = 28).\n\n【59】The lesions with the best clinical response tended to have the greatest decrease in epidermal pigmentation (the best linear fit is represented by the line; r = -0.53, P<0.0001).\n\n【60】Ten months of topical tretinoin as compared with vehicle treatment resulted in a significant increase in the mean degree of compaction of stratum corneum, the thickness of the granular cell layer, epidermal thickness, the degree of spongiosis (i.e., widening of the spaces between keratinocytes), and the severity of perivascular mononuclear dermal inflammation . Light microscopy of the lesions showed that the degree of epidermal pigmentation decreased by 35 percent in the tretinoin group, whereas it increased by 34 percent in the vehicle group (P = 0.0008) . A reduction in epidermal pigmentation occurred in most tretinoin-treated patients . Histologically discernible changes in epidermal pigmentation were significantly correlated with clinically observable changes in the color of lesions from which biopsy samples were obtained (r = -0.53, P<0.0001) . None of the lesions that had more pigment on microscopical examination appeared darker clinically.\n\n【61】Discussion\n----------\n\n【62】We have demonstrated that 0.1 percent tretinoin cream is an effective treatment for hyperpigmented lesions (liver spots) associated with photodamage. Clinically apparent and statistically significant lightening of hyperpigmented lesions occurred as early as 1 month after the initiation of treatment, and at least one lesion disappeared in 32 percent of the patients during the 10-month treatment. Furthermore, none of the lesions that completely cleared returned during a subsequent six-month period in which vehicle alone was given.\n\n【63】All types of lesions responded to treatment with tretinoin, not just those that proved histologically to be actinic lentigines . Our findings suggest that despite the difficulties involved in diagnosing actinic lentigines clinically,  tretinoin is beneficial for various irregular hyperpigmented macules, regardless of their histologic characteristics. Indeed, previous studies have reported favorable results with tretinoin treatment of some premalignant and malignant neoplasms.  <sup><a>13 </a></sup>  <sup><a>15 </a></sup>  <sup><a>17 </a></sup>  <sup><a>19 </a></sup>  <sup><a>21</a></sup>\n\n【64】Our clinical experience, as well as that of Kligman,  suggests that patients with these skin lesions derive the best results from topical tretinoin when they increase the amount of medication to a point just short of intolerance. Thus, the lack of overall improvement in 17 percent of patients receiving tretinoin may have been due to the use of insufficient quantities of medication. Conversely, some vehicle-treated patients had lightening of their lesions because some improvement may occur with only emollient therapy, avoidance of sunlight, and the use of sunscreens.\n\n【65】None of the patients had adverse reactions that were severe or permanent; previous studies have also demonstrated an excellent safety profile for topical tretinoin.  <sup><a>4 </a></sup>  <sup><a>6 </a></sup>  <sup><a>22 </a></sup> Eighty-two percent of the patients treated with tretinoin and 7 percent of those who received vehicle in the initial 10-month study had a local reaction. Thus, it may have been possible at times to determine whether a patient was receiving tretinoin; however, such side effects were not evident during most of the patient evaluations. To reduce the possibility of bias, we graded all variables in relation to baseline values without referring to the data obtained from any of the other visits. Moreover, our photographic documentation  and the statistically significant histologic findings corroborated the clinical data.\n\n【66】The histologic studies revealed a decrease in epidermal pigmentation in tretinoin-treated lesions that correlated significantly with the degree of clinical lightening; however, there was no change in the number or size of melanocytes. Thus, the epidermis had less pigment after tretinoin therapy, an observation compatible with the work of Orlow et al.,  who showed that tretinoin inhibits induced melanogenesis. The other histologic changes seen in the biopsy specimens, such as epidermal thickening, are characteristic of the action of tretinoin on the skin.  <sup>, </sup>  <sup>, </sup>  Histologically, epidermal pigmentation increased in the group receiving vehicle, probably as a result of ongoing melanogenesis.\n\n【67】In our experience, actinic lentigines and other hyperpigmented lesions associated with photodamage do not completely disappear spontaneously. As a noninvasive therapy, topical 0.1 percent tretinoin cream, coupled with avoidance of the sun and appropriate use of sunscreen, is an effective, nondestructive approach to improving and sometimes clearing these lesions.", "index": 25610, "show": true, "start": 25519, "end": 25532, "province": ["文本干净度", "页码/数字"], "isEdit": false}, {"text": "  13   15   17   19   21", "content": "【0】Topical Tretinoin (Retinoic Acid) Treatment for Liver Spots Associated with Photodamage\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】The hyperpigmented lesions commonly called liver spots distress patients, in part because such lesions are associated with aging. We investigated their treatment with topical 0.1 percent tretinoin (retinoic acid).\n\n【3】Methods.\n--------\n\n【4】Fifty-eight patients completed a 10-month randomized, double-blind study in which they applied either 0.1 percent tretinoin (n = 28) or vehicle (n = 30) cream daily to the face, upper extremities, or both. Fifteen patients who responded well were then randomly assigned to continue tretinoin therapy or use vehicle alone for six more months. Patients were evaluated by physical examination every month and by analysis of biopsy specimens of lesions obtained at base line and at the end of the 10-month trial.\n\n【5】Results.\n--------\n\n【6】After one month of treatment the patients treated with tretinoin had significant lightening of hyperpigmented lesions as compared with the patients who received vehicle (P<0.002). After 10 months, 20 (83 percent) of the 24 patients with facial lesions who were treated with tretinoin had lightening of these lesions, as compared with 8 (29 percent) of the 28 patients with facial lesions who received vehicle. The results for lesions of the upper extremities were similar. As compared with vehicle, tretinoin caused a significant decrease in the degree of epidermal pigmentation and increases in the degree of compaction of stratum corneum, thickness of the granular cell layer, and epidermal thickness. Reductions in epidermal pigmentation evident on histologic analysis were significantly correlated with the degree of clinical lightening of lesions (r = -0.53, P<0.0001). During the 6-month follow-up study, specifically identified lesions that had disappeared during the first 10 months of tretinoin treatment did not return in any patient, and six of seven patients who continued to use tretinoin had further improvement.\n\n【7】Conclusions.\n------------\n\n【8】Topical 0.1 percent tretinoin significantly improves both clinical and microscopical manifestations of liver spots; these lesions do not return for at least six months after therapy is discontinued. \n\n【9】Introduction\n------------\n\n【10】THE presence of hyperpigmented macules (liver spots) on the face or other exposed areas usually indicates substantial damage due to exposure to sunlight (photodamage). To date, the treatment for such lesions, many of which are actinic lentigines, has been surgery or chemical peeling.  Bleaching agents such as hydroquinones often produce undesirable depigmentation, and opaque cosmetics do not treat the underlying problem.\n\n【11】Tretinoin (retinoic acid) is a potent inhibitor of new melanin production,  and recent studies have suggested that topical therapy with tretinoin may decrease the macular hyperpigmentation.  <sup><a>4 </a></sup>  <sup><a>6 </a></sup>  Therefore, we performed a study specifically designed to evaluate the efficacy of topical tretinoin cream in the treatment of hyperpigmented lesions associated with photodamage; we found that 0.1 percent tretinoin is an effective topical treatment.\n\n【12】Methods\n-------\n\n【13】Patients and Design\n-------------------\n\n【14】Sixty healthy white patients, each with at least four hyperpigmented macules with the clinical characteristics of actinic lentigines, participated in the initial 10-month study of tretinoin or vehicle treatment. At least one of these lesions had to be of sufficient size to allow two separate 2-mm punch-biopsy specimens to be obtained. A total of 24 women and 6 men were treated with tretinoin and 25 women and 5 men were given vehicle. They ranged in age from 36 to 86 years (mean, 67) in the tretinoin group and from 48 to 81 years (mean, 65) in the vehicle group.\n\n【15】None of the patients had used topical or systemic retinoids for six months, any topical medications for at least two weeks, or systemic steroids for one month before the study. Pregnant and nursing women and patients who had received oral psoralen and ultraviolet A radiation were excluded. The protocol, which had been approved by the institutional review board of the University of Michigan Medical Center, and the potential side effects of the treatment were explained to each patient, and all signed informed-consent forms.\n\n【16】A computer-generated code was used for the random assignment of the patients to the treatment groups on the basis of their order of entry into the study. The treatments were either 0.1 percent tretinoin cream (Retin-A, Ortho Pharmaceutical, Raritan, N.J.) or color-matched vehicle cream. All dispensed tubes were identical in appearance; therefore, both the investigators and the patients were unaware of the group to which the patient had been assigned. The sample sizes were chosen to provide a statistical power of approximately 0.80 to detect a difference in overall improvement of at least one half-unit (as defined below) between the two treatment groups at a Type I error rate of 0.05 for a two-tailed hypothesis.\n\n【17】Fifteen of the patients who had a good response during the initial 10-month study (all of whom proved to have received tretinoin) and who wished to participate in an additional 6-month study were randomly assigned to receive either 0.1 percent tretinoin or vehicle cream. In this phase of the study there were five women and three men (age, 36 to 80 years; mean, 66) in the tretinoin group, and five women and two men (age, 46 to 83; mean, 66) in the vehicle group.\n\n【18】Treatment\n---------\n\n【19】The patients applied the study compounds once nightly to the face, arms, forearms, backs of the hands, or any combination of these sites that had hyperpigmented lesions. Initially, a pea-sized amount of cream was used on each affected area. The patients were encouraged to increase gradually the quantity of cream applied until mild erythema or scaling ensued.\n\n【20】The patients were supplied with a mild soap and asked to wash with this or a similar agent at least 20 minutes before applying the study treatment. All patients also received a mild emollient to be used when needed for skin irritation or dryness. They were advised to avoid excessive exposure to the sun or sunlamps during the study. Sunscreen with a protection factor of 15 was provided. They also were instructed to minimize the use of cosmetics, which were not worn during evaluations or photographic sessions. For 24 hours before each evaluation, the patients did not apply any topical preparations, including the study treatment, emollients, or sunscreen.\n\n【21】Clinical Evaluations\n--------------------\n\n【22】Clinical evaluations were performed before treatment, after two and four weeks of treatment, and monthly thereafter. Monthly evaluations were also performed during the six-month extended study. One investigator evaluated the patients at the majority of visits. For each patient, the overall clinical response of each area under treatment was rated by the investigator in terms of changes in color —that is, as much darker, darker, unchanged, lighter, or much lighter. The results for the arms, forearms, and backs of the hands were averaged for each patient and are reported as results for the upper extremities.\n\n【23】In addition to the overall assessment, four hyperpigmented lesions were identified before treatment on the basis of the likelihood of accurately locating these lesions throughout the study, thus allowing us to correlate the clinical and histologic results in the same lesions. Pretreatment photographs aided in locating specific lesions. At each return visit, the degree of hyperpigmentation of each of these lesions was compared with that before treatment, and color was graded by the investigator as much darker, darker, slightly darker, unchanged, slightly lighter, lighter, much lighter, or absent.\n\n【24】The degrees of erythema, scaling, burning or stinging, and pruritus were assessed at all visits with the use of a five-point scale, in which 0 indicated the absence of such symptoms, 1 the presence of mild symptoms, 2 the presence of moderate symptoms, 3 the presence of moderately severe symptoms, and 4 the presence of severe symptoms. A cutaneous reaction was defined as the presence of at least moderate erythema or scaling at two or more visits.\n\n【25】Light-Microscopical Analysis\n----------------------------\n\n【26】Of the four lesions specifically identified in each patient, one of sufficient size was selected to be the site of two full-thickness punch biopsies (each measuring 2 mm in diameter) before and after 10 months of treatment for light-microscopical analysis. Post-treatment biopsy specimens from two patients in the vehicle group were not available because of laboratory errors.\n\n【27】The specimens were fixed in 10 percent neutral-buffered formalin, embedded in paraffin, sectioned, and stained with hematoxylin and eosin. The investigator who analyzed the specimens was not aware of either the patient's treatment or the time of the biopsy. The histologic sections were assessed for the presence of various characteristics with a semiquantitative ordinal five-point scale in half-unit increments, in which 0 indicated the absence of the characteristics and 4 indicated the maximal degree of the characteristics. Epidermal thickness was measured directly.\n\n【28】Photographic Analysis\n---------------------\n\n【29】All data were obtained by direct assessment of patients, and none were derived by assessing photographs. The photographs for documentation of the lesional areas were taken by a professional photographer before and during treatment using standardized positioning and lighting of the patients and film from a single emulsion lot processed by a single professional laboratory. A standard gray card (18 percent reflectance) was included in the first picture during each session to control for any shifts in color or density due to extraneous variables.\n\n【30】Statistical Analysis\n--------------------\n\n【31】Table 1. Mean Clinically Apparent Change in Color after 10 Months of Treatment with Tretinoin or Vehicle, According to the Type of Lesion.\\*\n\n【32】The changes in clinical and histologic measures of the hyperpigmented lesions before and during treatment in the tretinoin and vehicle groups were compared by means of the two-sample t-test. The association between treatment and overall response after 10 and 16 months was made with the chi-square test. The comparison of changes in color of the specifically identified lesions in the two groups was based on the average of the changes in the four lesions; the clinical changes in color of the single lesion that underwent biopsy were analyzed according to histologic diagnosis . In each case, group means were compared by the two-sample t-test. The ratings for change in color, which were initially assigned values ranging from 1 to 8 for computer data entry, were reassigned values ranging from -3 to +4 so that a rating of no change would equal 0. Overall scores were reassigned in the same fashion. These arithmetic adjustments had no effect on the statistical analyses, P values, or conclusions drawn. Correlations between clinical and histologic variables were assessed with Pearson's product-moment correlation coefficient.\n\n【33】All analyses included all patients who could be evaluated;<mark> only in Table 1 are patients stratified according to histologic diagnosis.</mark> All P values are two-sided. Summary statistics are expressed as means ±SE. Data were analyzed with the Michigan Interactive Data Analysis System (MIDAS, a statistical software package developed by the Center for Statistical Consultation and Research at the University of Michigan).\n\n【34】Results\n-------\n\n【35】Fifty-eight of the 60 patients completed the 10-month study. Two patients in the tretinoin group dropped out, one after two months because of non-compliance and the other after one month because of an exacerbation of atopic dermatitis. Therefore, clinical data for the first 10 months are presented for 30 patients in the vehicle group (28 with facial lesions and 26 with upper-extremity lesions) and 28 in the tretinoin group (24 with facial lesions and 26 with upper-extremity lesions).\n\n【36】Clinical Results\n----------------\n\n【37】### __Overall Scores__\n\n<mark>【38】Figure 1. </mark>Examples of the Best Responses to Tretinoin Therapy in Three Patients.\n\n【39】Panel A shows a 79-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 additional months of tretinoin (6 mo f/u). Many hyperpigmented lesions had disappeared and others had lightened after 10 months of tretinoin therapy, with continued improvement after 6 additional months of therapy. Panel B shows an 84-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 months of vehicle (6 mo f/u). After 10 months of tretinoin therapy, many brown spots had cleared, and a retinoid reaction had occurred; after 6 months of vehicle, no relapse had occurred. Panels C and D show a 70-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 5 months of no treatment (5 mos. off). All lesions had disappeared after 10 months of treatment and had not reappeared 5 months after tretinoin was stopped<mark>.Figure 2.  Figure 2. </mark>Overall Efficacy of 10 Months of Treatment with Tretinoin or Vehicle Cream for Hyperpigmented Lesions of the Face and Upper Extremities.\n\n【40】As compared with vehicle, tretinoin caused significant lightening of hyperpigmented lesions of the face (P = 0.0002) and upper extremities (P = 0.0001). Among the patients given tretinoin, 24 had facial lesions and 26 had upper-extremity lesions. Among the patients given vehicle, 28 had facial lesions and 26 had upper-extremity lesions. Not all percentages sum to 100 because of rounding.\n\n【41】After 10 months of treatment, the overall scores demonstrated statistically significant lightening of hyperpigmented facial and upper-extremity lesions in the group receiving tretinoin as compared with the group receiving vehicle . Among the 24 tretinoin-treated patients who had facial lesions, <mark>the Figure 1 . </mark>Examples of the Best Responses to Tretinoin Therapy in Three Patients. Panel A shows a 79-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 additional months of tretinoin (6 mo f/u). Many hyperpigmented lesions had disappeared and others had lightened after 10 months of tretinoin therapy, with continued improvement after 6 additional months of therapy. Panel B shows an 84-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 months of vehicle (6 mo f/u). After 10 months of tretinoin therapy, many brown spots had cleared, and a retinoid reaction had occurred; after 6 months of vehicle, no relapse had occurred. Panels C and D show a 70-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 5 months of no treatment (5 mos. off). All lesions had disappeared after 10 months of treatment and had not reappeared 5 months after tretinoin was stopped. lesions were much lighter in 10 (42 percent), lighter in 10 (42 percent), and unchanged in 4 (17 percent) after 10 months of therapy. Among the 28 patients with facial lesions who received vehicle, the lesions were much lighter in 2 (7 percent), lighter in 6 (21 percent), and unchanged in 20 (71 percent). Thus, 20 patients in the tretinoin group (83 percent) and 8 patients in the vehicle group (29 percent) had some lightening of facial lesions. Among the 26 tretinoin-treated patients who had upper-extremity lesions, the lesions were much lighter in 6 (23 percent), lighter in 17 (65 percent), and unchanged in 3 (12 percent) after 10 months of therapy. Among the 26 patients with upper-extremity lesions who received vehicle, the lesions were much lighter in 1 (4 percent), lighter in 7 (27 percent), and unchanged in 18 (69 percent). The overall score did not worsen in either group during treatment.\n\n<mark>【42】Figure 3.</mark> Overall Change in Color in Response to Treatment with Tretinoin (Solid Lines) or Vehicle (Broken Lines).\n\n【43】Circles and error bars indicate means ±SE. Statistically significant and clinically detectable lightening of facial and upper-extremity lesions was evident after four weeks of tretinoin treatment and was maintained for the rest of the study. Asterisks denote a significant difference (P≤0.002) between groups.\n\n【44】A significant overall improvement in the tretinoin group, as compared with the vehicle group, was first attained after one month of therapy (P≤0.002) . An overall improvement of facial and upper-extremity lesions occurred in 44 and 58 percent of patients, respectively, after 1 month of tretinoin treatment, in 75 and 85 percent of patients after 6 months of treatment, and in 83 and 88 percent after 10 months of treatment.\n\n【45】### __Specific Lesions__\n\n【46】When the scores for the four lesions were averaged for each patient, there was a significant improvement in the tretinoin group as compared with the vehicle group after 10 months of treatment (P<0.0001). At the end of the 10-month study, the lesions had lightened in 20 of the 28 patients (71 percent) in the tretinoin group but in only 7 of the 30 patients (23 percent) in the vehicle group. Nine of the 28 patients (32 percent) receiving tretinoin had complete clearing of one or more of these lesions; the mean length of time required for clearance of the lesions was 8 months (range, 5 to 10). None of the lesions completely disappeared in any of the patients who received vehicle.\n\n【47】### __Six-Month Follow-up Study__\n\n【48】Fifteen patients who responded well to treatment in the initial 10-month study were assigned to tretinoin or vehicle for an additional 6 months. When the code was broken, all 15 patients who entered the six-month follow-up study proved to have received tretinoin; randomization at this stage resulted in 8 being assigned to receive tretinoin and 7 vehicle. One patient who was reassigned to the tretinoin group withdrew one month later because of contact dermatitis (proved by patch testing) due to quaternium-15, a preservative in the emollient.\n\n【49】The group reassigned to tretinoin treatment had a further significant overall improvement of lesions located on the face (P = 0.01) and upper extremities (P = 0.0005), as compared with the group assigned to vehicle. In this phase of the study, of six tretinoin-treated patients who had hyperpigmented facial lesions, the lesions were much lighter in two, lighter in three, and unchanged in one, as compared with the results at the end of the 10-month phase. All tretinoin-treated patients with upper-extremity lesions had further lightening of their lesions during this same period. In contrast, there was no change in facial or upper-extremity lesions in patients who received vehicle during the six-month follow-up study.\n\n【50】Four patients who had had complete clearing of at least one of the four identified lesions during the 10-month course of tretinoin maintained these results during the subsequent 6-month course of tretinoin. Of two other patients who had no clearing of any specified lesions during the first 10 months of tretinoin treatment, each had one lesion completely disappear with continued tretinoin treatment during the 6-month follow-up study. Three patients who had at least one lesion resolve during the first 10 months of tretinoin therapy received vehicle for 6 months; none of their lesions returned. The patient who withdrew because of contact dermatitis had no recurrence of lesions after five months without treatment . None of the patients who received vehicle cream had complete clearing of any of the four identified lesions during the six-month follow-up study.\n\n【51】Cutaneous Reactions\n-------------------\n\n【52】During the study the patients reported only cutaneous reactions, <mark> 9  </mark>p><a>9 </a></sup>  characterized principally by erythema and scaling. Erythema or scaling of at least moderate severity occurred more than once in 23 of the 28 patients receiving tretinoin (82 percent) and in 2 of the 30 patients given vehicle (7 percent) during the initial 10-month study. Five of the seven patients who received tretinoin, but none of the seven patients who received vehicle, had such reactions during the six-month follow-up study.\n\n【53】The rash occurred only in areas that came into contact with the topical medication and varied in intensity and duration among the patients and in any individual patient at different times. Scaling or erythema began one to four weeks after the start of tretinoin treatment. In all cases, the scaling and erythema were most noticeable during the first two months, after which there was a progressive decrease in their severity, frequency, and duration.\n\n【54】The cutaneous reactions improved when emollients were applied more frequently and the amount of study medication used was decreased or treatment was stopped for one to three days. Three patients, two receiving tretinoin and one receiving vehicle, applied 1 percent hydrocortisone cream for a maximum of five days to sites of irritation during the initial phase of the study.\n\n【55】Histologic Results\n------------------\n\n【56】A punch-biopsy specimen of a single lesion in each patient was obtained before and after treatment. The pretreatment biopsy specimens were classified by light microscopy as either actinic lentigines or nonlentiginous lesions (lesions that did not meet the criteria for actinic lentigines) . Both the actinic lentigines and nonlentiginous lesions lightened after treatment with tretinoin cream (P = 0.05 and P = 0.002, respectively) .\n\n【57】Table 2. Histologic Features of Biopsy Specimens Obtained before and after 10 Months of Treatment with Tretinoin or Vehicle.\\* Figure 4.  Figure 4. Histologic Appearance of a Hyperpigmented Lesion before Treatment (Top Panel) and after 10 Months of Treatment with 0.1 Percent Tretinoin (Bottom Panel).\n\n【58】The two specimens are from a single hyperpigmented lesion from the patient shown in Figures 1 C and 1 D (Fontana—Masson stain, ×90). After 10 months of treatment, the degree of epidermal pigmentation decreased markedly.Figure 5.  Figure 5. Relation between Histologic Changes in the Degree of Epidermal Pigmentation and Clinically Apparent Color Changes after 10 Months of Treatment with Tretinoin (N = 28) or Vehicle (N = 28).\n\n【59】The lesions with the best clinical response tended to have the greatest decrease in epidermal pigmentation (the best linear fit is represented by the line; r = -0.53, P<0.0001).\n\n【60】Ten months of topical tretinoin as compared with vehicle treatment resulted in a significant increase in the mean degree of compaction of stratum corneum, the thickness of the granular cell layer, epidermal thickness, the degree of spongiosis (i.e., widening of the spaces between keratinocytes), and the severity of perivascular mononuclear dermal inflammation . Light microscopy of the lesions showed that the degree of epidermal pigmentation decreased by 35 percent in the tretinoin group, whereas it increased by 34 percent in the vehicle group (P = 0.0008) . A reduction in epidermal pigmentation occurred in most tretinoin-treated patients . Histologically discernible changes in epidermal pigmentation were significantly correlated with clinically observable changes in the color of lesions from which biopsy samples were obtained (r = -0.53, P<0.0001) . None of the lesions that had more pigment on microscopical examination appeared darker clinically.\n\n【61】Discussion\n----------\n\n【62】We have demonstrated that 0.1 percent tretinoin cream is an effective treatment for hyperpigmented lesions (liver spots) associated with photodamage. Clinically apparent and statistically significant lightening of hyperpigmented lesions occurred as early as 1 month after the initiation of treatment, and at least one lesion disappeared in 32 percent of the patients during the 10-month treatment. Furthermore, none of the lesions that completely cleared returned during a subsequent six-month period in which vehicle alone was given.\n\n【63】All types of lesions responded to treatment with tretinoin, not just those that proved histologically to be actinic lentigines . Our findings suggest that despite the difficulties involved in diagnosing actinic lentigines clinically,  tretinoin is beneficial for various irregular hyperpigmented macules, regardless of their histologic characteristics. Indeed, previous studies have reported favorable results with tretinoin treatment of some premalignant and malignant neoplasms.  <sup><a>13 </a></sup>  <sup><a>15 </a></sup>  <sup><a>17 </a></sup>  <sup><a>19 </a></sup>  <sup><a>21</a></sup>\n\n【64】Our clinical experience, as well as that of Kligman,  suggests that patients with these skin lesions derive the best results from topical tretinoin when they increase the amount of medication to a point just short of intolerance. Thus, the lack of overall improvement in 17 percent of patients receiving tretinoin may have been due to the use of insufficient quantities of medication. Conversely, some vehicle-treated patients had lightening of their lesions because some improvement may occur with only emollient therapy, avoidance of sunlight, and the use of sunscreens.\n\n【65】None of the patients had adverse reactions that were severe or permanent; previous studies have also demonstrated an excellent safety profile for topical tretinoin. <mark> 4   6   22  </mark>a></sup>  <sup><a>6 </a></sup>  <sup><a>22 </a></sup> Eighty-two percent of the patients treated with tretinoin and 7 percent of those who received vehicle in the initial 10-month study had a local reaction. Thus, it may have been possible at times to determine whether a patient was receiving tretinoin; however, such side effects were not evident during most of the patient evaluations. To reduce the possibility of bias, we graded all variables in relation to baseline values without referring to the data obtained from any of the other visits. Moreover, our photographic documentation  and the statistically significant histologic findings corroborated the clinical data.\n\n【66】The histologic studies revealed a decrease in epidermal pigmentation in tretinoin-treated lesions that correlated significantly with the degree of clinical lightening; however, there was no change in the number or size of melanocytes. Thus, the epidermis had less pigment after tretinoin therapy, an observation compatible with the work of Orlow et al.,  who showed that tretinoin inhibits induced melanogenesis. The other histologic changes seen in the biopsy specimens, such as epidermal thickening, are characteristic of the action of tretinoin on the skin.  <sup>, </sup>  <sup>, </sup>  Histologically, epidermal pigmentation increased in the group receiving vehicle, probably as a result of ongoing melanogenesis.\n\n【67】In our experience, actinic lentigines and other hyperpigmented lesions associated with photodamage do not completely disappear spontaneously. As a noninvasive therapy, topical 0.1 percent tretinoin cream, coupled with avoidance of the sun and appropriate use of sunscreen, is an effective, nondestructive approach to improving and sometimes clearing these lesions.", "index": 24747, "show": true, "start": 24656, "end": 24680, "province": ["文本干净度", "页码/数字"], "isEdit": false}, {"text": " on the skin.  ,   ,   Histologically, ", "content": "【0】Topical Tretinoin (Retinoic Acid) Treatment for Liver Spots Associated with Photodamage\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】The hyperpigmented lesions commonly called liver spots distress patients, in part because such lesions are associated with aging. We investigated their treatment with topical 0.1 percent tretinoin (retinoic acid).\n\n【3】Methods.\n--------\n\n【4】Fifty-eight patients completed a 10-month randomized, double-blind study in which they applied either 0.1 percent tretinoin (n = 28) or vehicle (n = 30) cream daily to the face, upper extremities, or both. Fifteen patients who responded well were then randomly assigned to continue tretinoin therapy or use vehicle alone for six more months. Patients were evaluated by physical examination every month and by analysis of biopsy specimens of lesions obtained at base line and at the end of the 10-month trial.\n\n【5】Results.\n--------\n\n【6】After one month of treatment the patients treated with tretinoin had significant lightening of hyperpigmented lesions as compared with the patients who received vehicle (P<0.002). After 10 months, 20 (83 percent) of the 24 patients with facial lesions who were treated with tretinoin had lightening of these lesions, as compared with 8 (29 percent) of the 28 patients with facial lesions who received vehicle. The results for lesions of the upper extremities were similar. As compared with vehicle, tretinoin caused a significant decrease in the degree of epidermal pigmentation and increases in the degree of compaction of stratum corneum, thickness of the granular cell layer, and epidermal thickness. Reductions in epidermal pigmentation evident on histologic analysis were significantly correlated with the degree of clinical lightening of lesions (r = -0.53, P<0.0001). During the 6-month follow-up study, specifically identified lesions that had disappeared during the first 10 months of tretinoin treatment did not return in any patient, and six of seven patients who continued to use tretinoin had further improvement.\n\n【7】Conclusions.\n------------\n\n【8】Topical 0.1 percent tretinoin significantly improves both clinical and microscopical manifestations of liver spots; these lesions do not return for at least six months after therapy is discontinued. \n\n【9】Introduction\n------------\n\n【10】THE presence of hyperpigmented macules (liver spots) on the face or other exposed areas usually indicates substantial damage due to exposure to sunlight (photodamage). To date, the treatment for such lesions, many of which are actinic lentigines, has been surgery or chemical peeling.  Bleaching agents such as hydroquinones often produce undesirable depigmentation, and opaque cosmetics do not treat the underlying problem.\n\n【11】Tretinoin (retinoic acid) is a potent inhibitor of new melanin production,  and recent studies have suggested that topical therapy with tretinoin may decrease the macular hyperpigmentation.  <sup><a>4 </a></sup>  <sup><a>6 </a></sup>  Therefore, we performed a study specifically designed to evaluate the efficacy of topical tretinoin cream in the treatment of hyperpigmented lesions associated with photodamage; we found that 0.1 percent tretinoin is an effective topical treatment.\n\n【12】Methods\n-------\n\n【13】Patients and Design\n-------------------\n\n【14】Sixty healthy white patients, each with at least four hyperpigmented macules with the clinical characteristics of actinic lentigines, participated in the initial 10-month study of tretinoin or vehicle treatment. At least one of these lesions had to be of sufficient size to allow two separate 2-mm punch-biopsy specimens to be obtained. A total of 24 women and 6 men were treated with tretinoin and 25 women and 5 men were given vehicle. They ranged in age from 36 to 86 years (mean, 67) in the tretinoin group and from 48 to 81 years (mean, 65) in the vehicle group.\n\n【15】None of the patients had used topical or systemic retinoids for six months, any topical medications for at least two weeks, or systemic steroids for one month before the study. Pregnant and nursing women and patients who had received oral psoralen and ultraviolet A radiation were excluded. The protocol, which had been approved by the institutional review board of the University of Michigan Medical Center, and the potential side effects of the treatment were explained to each patient, and all signed informed-consent forms.\n\n【16】A computer-generated code was used for the random assignment of the patients to the treatment groups on the basis of their order of entry into the study. The treatments were either 0.1 percent tretinoin cream (Retin-A, Ortho Pharmaceutical, Raritan, N.J.) or color-matched vehicle cream. All dispensed tubes were identical in appearance; therefore, both the investigators and the patients were unaware of the group to which the patient had been assigned. The sample sizes were chosen to provide a statistical power of approximately 0.80 to detect a difference in overall improvement of at least one half-unit (as defined below) between the two treatment groups at a Type I error rate of 0.05 for a two-tailed hypothesis.\n\n【17】Fifteen of the patients who had a good response during the initial 10-month study (all of whom proved to have received tretinoin) and who wished to participate in an additional 6-month study were randomly assigned to receive either 0.1 percent tretinoin or vehicle cream. In this phase of the study there were five women and three men (age, 36 to 80 years; mean, 66) in the tretinoin group, and five women and two men (age, 46 to 83; mean, 66) in the vehicle group.\n\n【18】Treatment\n---------\n\n【19】The patients applied the study compounds once nightly to the face, arms, forearms, backs of the hands, or any combination of these sites that had hyperpigmented lesions. Initially, a pea-sized amount of cream was used on each affected area. The patients were encouraged to increase gradually the quantity of cream applied until mild erythema or scaling ensued.\n\n【20】The patients were supplied with a mild soap and asked to wash with this or a similar agent at least 20 minutes before applying the study treatment. All patients also received a mild emollient to be used when needed for skin irritation or dryness. They were advised to avoid excessive exposure to the sun or sunlamps during the study. Sunscreen with a protection factor of 15 was provided. They also were instructed to minimize the use of cosmetics, which were not worn during evaluations or photographic sessions. For 24 hours before each evaluation, the patients did not apply any topical preparations, including the study treatment, emollients, or sunscreen.\n\n【21】Clinical Evaluations\n--------------------\n\n【22】Clinical evaluations were performed before treatment, after two and four weeks of treatment, and monthly thereafter. Monthly evaluations were also performed during the six-month extended study. One investigator evaluated the patients at the majority of visits. For each patient, the overall clinical response of each area under treatment was rated by the investigator in terms of changes in color —that is, as much darker, darker, unchanged, lighter, or much lighter. The results for the arms, forearms, and backs of the hands were averaged for each patient and are reported as results for the upper extremities.\n\n【23】In addition to the overall assessment, four hyperpigmented lesions were identified before treatment on the basis of the likelihood of accurately locating these lesions throughout the study, thus allowing us to correlate the clinical and histologic results in the same lesions. Pretreatment photographs aided in locating specific lesions. At each return visit, the degree of hyperpigmentation of each of these lesions was compared with that before treatment, and color was graded by the investigator as much darker, darker, slightly darker, unchanged, slightly lighter, lighter, much lighter, or absent.\n\n【24】The degrees of erythema, scaling, burning or stinging, and pruritus were assessed at all visits with the use of a five-point scale, in which 0 indicated the absence of such symptoms, 1 the presence of mild symptoms, 2 the presence of moderate symptoms, 3 the presence of moderately severe symptoms, and 4 the presence of severe symptoms. A cutaneous reaction was defined as the presence of at least moderate erythema or scaling at two or more visits.\n\n【25】Light-Microscopical Analysis\n----------------------------\n\n【26】Of the four lesions specifically identified in each patient, one of sufficient size was selected to be the site of two full-thickness punch biopsies (each measuring 2 mm in diameter) before and after 10 months of treatment for light-microscopical analysis. Post-treatment biopsy specimens from two patients in the vehicle group were not available because of laboratory errors.\n\n【27】The specimens were fixed in 10 percent neutral-buffered formalin, embedded in paraffin, sectioned, and stained with hematoxylin and eosin. The investigator who analyzed the specimens was not aware of either the patient's treatment or the time of the biopsy. The histologic sections were assessed for the presence of various characteristics with a semiquantitative ordinal five-point scale in half-unit increments, in which 0 indicated the absence of the characteristics and 4 indicated the maximal degree of the characteristics. Epidermal thickness was measured directly.\n\n【28】Photographic Analysis\n---------------------\n\n【29】All data were obtained by direct assessment of patients, and none were derived by assessing photographs. The photographs for documentation of the lesional areas were taken by a professional photographer before and during treatment using standardized positioning and lighting of the patients and film from a single emulsion lot processed by a single professional laboratory. A standard gray card (18 percent reflectance) was included in the first picture during each session to control for any shifts in color or density due to extraneous variables.\n\n【30】Statistical Analysis\n--------------------\n\n【31】Table 1. Mean Clinically Apparent Change in Color after 10 Months of Treatment with Tretinoin or Vehicle, According to the Type of Lesion.\\*\n\n【32】The changes in clinical and histologic measures of the hyperpigmented lesions before and during treatment in the tretinoin and vehicle groups were compared by means of the two-sample t-test. The association between treatment and overall response after 10 and 16 months was made with the chi-square test. The comparison of changes in color of the specifically identified lesions in the two groups was based on the average of the changes in the four lesions; the clinical changes in color of the single lesion that underwent biopsy were analyzed according to histologic diagnosis . In each case, group means were compared by the two-sample t-test. The ratings for change in color, which were initially assigned values ranging from 1 to 8 for computer data entry, were reassigned values ranging from -3 to +4 so that a rating of no change would equal 0. Overall scores were reassigned in the same fashion. These arithmetic adjustments had no effect on the statistical analyses, P values, or conclusions drawn. Correlations between clinical and histologic variables were assessed with Pearson's product-moment correlation coefficient.\n\n【33】All analyses included all patients who could be evaluated;<mark> only in Table 1 are patients stratified according to histologic diagnosis.</mark> All P values are two-sided. Summary statistics are expressed as means ±SE. Data were analyzed with the Michigan Interactive Data Analysis System (MIDAS, a statistical software package developed by the Center for Statistical Consultation and Research at the University of Michigan).\n\n【34】Results\n-------\n\n【35】Fifty-eight of the 60 patients completed the 10-month study. Two patients in the tretinoin group dropped out, one after two months because of non-compliance and the other after one month because of an exacerbation of atopic dermatitis. Therefore, clinical data for the first 10 months are presented for 30 patients in the vehicle group (28 with facial lesions and 26 with upper-extremity lesions) and 28 in the tretinoin group (24 with facial lesions and 26 with upper-extremity lesions).\n\n【36】Clinical Results\n----------------\n\n【37】### __Overall Scores__\n\n<mark>【38】Figure 1. </mark>Examples of the Best Responses to Tretinoin Therapy in Three Patients.\n\n【39】Panel A shows a 79-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 additional months of tretinoin (6 mo f/u). Many hyperpigmented lesions had disappeared and others had lightened after 10 months of tretinoin therapy, with continued improvement after 6 additional months of therapy. Panel B shows an 84-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 months of vehicle (6 mo f/u). After 10 months of tretinoin therapy, many brown spots had cleared, and a retinoid reaction had occurred; after 6 months of vehicle, no relapse had occurred. Panels C and D show a 70-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 5 months of no treatment (5 mos. off). All lesions had disappeared after 10 months of treatment and had not reappeared 5 months after tretinoin was stopped<mark>.Figure 2.  Figure 2. </mark>Overall Efficacy of 10 Months of Treatment with Tretinoin or Vehicle Cream for Hyperpigmented Lesions of the Face and Upper Extremities.\n\n【40】As compared with vehicle, tretinoin caused significant lightening of hyperpigmented lesions of the face (P = 0.0002) and upper extremities (P = 0.0001). Among the patients given tretinoin, 24 had facial lesions and 26 had upper-extremity lesions. Among the patients given vehicle, 28 had facial lesions and 26 had upper-extremity lesions. Not all percentages sum to 100 because of rounding.\n\n【41】After 10 months of treatment, the overall scores demonstrated statistically significant lightening of hyperpigmented facial and upper-extremity lesions in the group receiving tretinoin as compared with the group receiving vehicle . Among the 24 tretinoin-treated patients who had facial lesions, <mark>the Figure 1 . </mark>Examples of the Best Responses to Tretinoin Therapy in Three Patients. Panel A shows a 79-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 additional months of tretinoin (6 mo f/u). Many hyperpigmented lesions had disappeared and others had lightened after 10 months of tretinoin therapy, with continued improvement after 6 additional months of therapy. Panel B shows an 84-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 6 months of vehicle (6 mo f/u). After 10 months of tretinoin therapy, many brown spots had cleared, and a retinoid reaction had occurred; after 6 months of vehicle, no relapse had occurred. Panels C and D show a 70-year-old woman before treatment (wk 0), after 10 months of tretinoin (wk 40), and after 5 months of no treatment (5 mos. off). All lesions had disappeared after 10 months of treatment and had not reappeared 5 months after tretinoin was stopped. lesions were much lighter in 10 (42 percent), lighter in 10 (42 percent), and unchanged in 4 (17 percent) after 10 months of therapy. Among the 28 patients with facial lesions who received vehicle, the lesions were much lighter in 2 (7 percent), lighter in 6 (21 percent), and unchanged in 20 (71 percent). Thus, 20 patients in the tretinoin group (83 percent) and 8 patients in the vehicle group (29 percent) had some lightening of facial lesions. Among the 26 tretinoin-treated patients who had upper-extremity lesions, the lesions were much lighter in 6 (23 percent), lighter in 17 (65 percent), and unchanged in 3 (12 percent) after 10 months of therapy. Among the 26 patients with upper-extremity lesions who received vehicle, the lesions were much lighter in 1 (4 percent), lighter in 7 (27 percent), and unchanged in 18 (69 percent). The overall score did not worsen in either group during treatment.\n\n<mark>【42】Figure 3.</mark> Overall Change in Color in Response to Treatment with Tretinoin (Solid Lines) or Vehicle (Broken Lines).\n\n【43】Circles and error bars indicate means ±SE. Statistically significant and clinically detectable lightening of facial and upper-extremity lesions was evident after four weeks of tretinoin treatment and was maintained for the rest of the study. Asterisks denote a significant difference (P≤0.002) between groups.\n\n【44】A significant overall improvement in the tretinoin group, as compared with the vehicle group, was first attained after one month of therapy (P≤0.002) . An overall improvement of facial and upper-extremity lesions occurred in 44 and 58 percent of patients, respectively, after 1 month of tretinoin treatment, in 75 and 85 percent of patients after 6 months of treatment, and in 83 and 88 percent after 10 months of treatment.\n\n【45】### __Specific Lesions__\n\n【46】When the scores for the four lesions were averaged for each patient, there was a significant improvement in the tretinoin group as compared with the vehicle group after 10 months of treatment (P<0.0001). At the end of the 10-month study, the lesions had lightened in 20 of the 28 patients (71 percent) in the tretinoin group but in only 7 of the 30 patients (23 percent) in the vehicle group. Nine of the 28 patients (32 percent) receiving tretinoin had complete clearing of one or more of these lesions; the mean length of time required for clearance of the lesions was 8 months (range, 5 to 10). None of the lesions completely disappeared in any of the patients who received vehicle.\n\n【47】### __Six-Month Follow-up Study__\n\n【48】Fifteen patients who responded well to treatment in the initial 10-month study were assigned to tretinoin or vehicle for an additional 6 months. When the code was broken, all 15 patients who entered the six-month follow-up study proved to have received tretinoin; randomization at this stage resulted in 8 being assigned to receive tretinoin and 7 vehicle. One patient who was reassigned to the tretinoin group withdrew one month later because of contact dermatitis (proved by patch testing) due to quaternium-15, a preservative in the emollient.\n\n【49】The group reassigned to tretinoin treatment had a further significant overall improvement of lesions located on the face (P = 0.01) and upper extremities (P = 0.0005), as compared with the group assigned to vehicle. In this phase of the study, of six tretinoin-treated patients who had hyperpigmented facial lesions, the lesions were much lighter in two, lighter in three, and unchanged in one, as compared with the results at the end of the 10-month phase. All tretinoin-treated patients with upper-extremity lesions had further lightening of their lesions during this same period. In contrast, there was no change in facial or upper-extremity lesions in patients who received vehicle during the six-month follow-up study.\n\n【50】Four patients who had had complete clearing of at least one of the four identified lesions during the 10-month course of tretinoin maintained these results during the subsequent 6-month course of tretinoin. Of two other patients who had no clearing of any specified lesions during the first 10 months of tretinoin treatment, each had one lesion completely disappear with continued tretinoin treatment during the 6-month follow-up study. Three patients who had at least one lesion resolve during the first 10 months of tretinoin therapy received vehicle for 6 months; none of their lesions returned. The patient who withdrew because of contact dermatitis had no recurrence of lesions after five months without treatment . None of the patients who received vehicle cream had complete clearing of any of the four identified lesions during the six-month follow-up study.\n\n【51】Cutaneous Reactions\n-------------------\n\n【52】During the study the patients reported only cutaneous reactions, <mark> 9  </mark>p><a>9 </a></sup>  characterized principally by erythema and scaling. Erythema or scaling of at least moderate severity occurred more than once in 23 of the 28 patients receiving tretinoin (82 percent) and in 2 of the 30 patients given vehicle (7 percent) during the initial 10-month study. Five of the seven patients who received tretinoin, but none of the seven patients who received vehicle, had such reactions during the six-month follow-up study.\n\n【53】The rash occurred only in areas that came into contact with the topical medication and varied in intensity and duration among the patients and in any individual patient at different times. Scaling or erythema began one to four weeks after the start of tretinoin treatment. In all cases, the scaling and erythema were most noticeable during the first two months, after which there was a progressive decrease in their severity, frequency, and duration.\n\n【54】The cutaneous reactions improved when emollients were applied more frequently and the amount of study medication used was decreased or treatment was stopped for one to three days. Three patients, two receiving tretinoin and one receiving vehicle, applied 1 percent hydrocortisone cream for a maximum of five days to sites of irritation during the initial phase of the study.\n\n【55】Histologic Results\n------------------\n\n【56】A punch-biopsy specimen of a single lesion in each patient was obtained before and after treatment. The pretreatment biopsy specimens were classified by light microscopy as either actinic lentigines or nonlentiginous lesions (lesions that did not meet the criteria for actinic lentigines) . Both the actinic lentigines and nonlentiginous lesions lightened after treatment with tretinoin cream (P = 0.05 and P = 0.002, respectively) .\n\n【57】Table 2. Histologic Features of Biopsy Specimens Obtained before and after 10 Months of Treatment with Tretinoin or Vehicle.\\* Figure 4.  Figure 4. Histologic Appearance of a Hyperpigmented Lesion before Treatment (Top Panel) and after 10 Months of Treatment with 0.1 Percent Tretinoin (Bottom Panel).\n\n【58】The two specimens are from a single hyperpigmented lesion from the patient shown in Figures 1 C and 1 D (Fontana—Masson stain, ×90). After 10 months of treatment, the degree of epidermal pigmentation decreased markedly.Figure 5.  Figure 5. Relation between Histologic Changes in the Degree of Epidermal Pigmentation and Clinically Apparent Color Changes after 10 Months of Treatment with Tretinoin (N = 28) or Vehicle (N = 28).\n\n【59】The lesions with the best clinical response tended to have the greatest decrease in epidermal pigmentation (the best linear fit is represented by the line; r = -0.53, P<0.0001).\n\n【60】Ten months of topical tretinoin as compared with vehicle treatment resulted in a significant increase in the mean degree of compaction of stratum corneum, the thickness of the granular cell layer, epidermal thickness, the degree of spongiosis (i.e., widening of the spaces between keratinocytes), and the severity of perivascular mononuclear dermal inflammation . Light microscopy of the lesions showed that the degree of epidermal pigmentation decreased by 35 percent in the tretinoin group, whereas it increased by 34 percent in the vehicle group (P = 0.0008) . A reduction in epidermal pigmentation occurred in most tretinoin-treated patients . Histologically discernible changes in epidermal pigmentation were significantly correlated with clinically observable changes in the color of lesions from which biopsy samples were obtained (r = -0.53, P<0.0001) . None of the lesions that had more pigment on microscopical examination appeared darker clinically.\n\n【61】Discussion\n----------\n\n【62】We have demonstrated that 0.1 percent tretinoin cream is an effective treatment for hyperpigmented lesions (liver spots) associated with photodamage. Clinically apparent and statistically significant lightening of hyperpigmented lesions occurred as early as 1 month after the initiation of treatment, and at least one lesion disappeared in 32 percent of the patients during the 10-month treatment. Furthermore, none of the lesions that completely cleared returned during a subsequent six-month period in which vehicle alone was given.\n\n【63】All types of lesions responded to treatment with tretinoin, not just those that proved histologically to be actinic lentigines . Our findings suggest that despite the difficulties involved in diagnosing actinic lentigines clinically,  tretinoin is beneficial for various irregular hyperpigmented macules, regardless of their histologic characteristics. Indeed, previous studies have reported favorable results with tretinoin treatment of some premalignant and malignant neoplasms.<mark>  13   15   17   19   21</mark> <sup><a>15 </a></sup>  <sup><a>17 </a></sup>  <sup><a>19 </a></sup>  <sup><a>21</a></sup>\n\n【64】Our clinical experience, as well as that of Kligman,  suggests that patients with these skin lesions derive the best results from topical tretinoin when they increase the amount of medication to a point just short of intolerance. Thus, the lack of overall improvement in 17 percent of patients receiving tretinoin may have been due to the use of insufficient quantities of medication. Conversely, some vehicle-treated patients had lightening of their lesions because some improvement may occur with only emollient therapy, avoidance of sunlight, and the use of sunscreens.\n\n【65】None of the patients had adverse reactions that were severe or permanent; previous studies have also demonstrated an excellent safety profile for topical tretinoin. <mark> 4   6   22  </mark>a></sup>  <sup><a>6 </a></sup>  <sup><a>22 </a></sup> Eighty-two percent of the patients treated with tretinoin and 7 percent of those who received vehicle in the initial 10-month study had a local reaction. Thus, it may have been possible at times to determine whether a patient was receiving tretinoin; however, such side effects were not evident during most of the patient evaluations. To reduce the possibility of bias, we graded all variables in relation to baseline values without referring to the data obtained from any of the other visits. Moreover, our photographic documentation  and the statistically significant histologic findings corroborated the clinical data.\n\n【66】The histologic studies revealed a decrease in epidermal pigmentation in tretinoin-treated lesions that correlated significantly with the degree of clinical lightening; however, there was no change in the number or size of melanocytes. Thus, the epidermis had less pigment after tretinoin therapy, an observation compatible with the work of Orlow et al.,  who showed that tretinoin inhibits induced melanogenesis. The other histologic changes seen in the biopsy specimens, such as epidermal thickening, are characteristic of the action of tretinoin on the skin.  <sup>, </sup>  <sup>, </sup>  Histologically, epidermal pigmentation increased in the group receiving vehicle, probably as a result of ongoing melanogenesis.\n\n【67】In our experience, actinic lentigines and other hyperpigmented lesions associated with photodamage do not completely disappear spontaneously. As a noninvasive therapy, topical 0.1 percent tretinoin cream, coupled with avoidance of the sun and appropriate use of sunscreen, is an effective, nondestructive approach to improving and sometimes clearing these lesions.", "index": 26877, "show": true, "start": 26760, "end": 26799, "province": ["格式规范性", "多余标点"], "isEdit": false}]}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-14 00:23:11", "grab_time": "2024-08-13 23:40:18"}
{"id": 2234421, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "27677aac-6051-4496-b988-b2ef2361cc21", "title": "Focused Cardiac Ultrasonography for Left Ventricular Systolic Function", "text": "【0】Focused Cardiac Ultrasonography for Left Ventricular Systolic Function\nThis video presents a practical method for conducting focused cardiac ultrasonography, a qualitative or semiquantitative means of assessing cardiac size, structure, and function at the bedside. The video shows how to perform visual assessment of left ventricular systolic function.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:50:42", "endTime": "2024/08/14 15:50:45", "cost": 3.385}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 23:50:45", "grab_time": "2024-08-13 23:50:41"}
{"id": 2234420, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "bfac314a-ba5c-43a1-aa56-e6aee8fd16b2", "title": "Associated Focal and Segmental Glomerulosclerosis in the Acquired Immunodeficiency Syndrome", "text": "【0】Associated Focal and Segmental Glomerulosclerosis in the Acquired Immunodeficiency Syndrome\nAbstract\n--------\n\n【1】Of the 92 patients with the acquired immunodeficiency syndrome (AIDS) who were seen at our institution over a two-year period, 9 acquired the nephrotic syndrome (urinary protein >3.5 g per 24 hours) and 2 had azotemia with lesser amounts of urinary protein. Five of these 11 patients had a history of intravenous-heroin addiction, but in the remaining six, there were no known predisposing factors for nephropathy. In nine patients (including the six non-addicts) the course of renal disease was marked by rapid progression to severe uremia. Renal tissue examined by biopsy in seven patients and at autopsy in three revealed focal and segmental glomerulosclerosis with intraglomerular deposition of IgM and C3. In the 11th patient, renal biopsy revealed an increase in mesangial matrix and cells, with deposition of IgG and C3 consistent with a mild immune-complex glomerulonephritis, and severe interstitial nephritis. We conclude that focal and segmental glomerulosclerosis may be associated with AIDS and suggest that rapid deterioration to uremia may characterize this renal disease.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 18:23:17", "endTime": "2024/08/13 18:25:40", "cost": 142.885}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 02:25:41", "grab_time": "2024-08-13 02:23:17"}
{"id": 2234419, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "860290c8-983f-4f9a-a601-21857361c53b", "title": "Case 8-2018: A 55-Year-Old Woman with Shock and Labile Blood Pressure", "text": "【0】Case 8-2018: A 55-Year-Old Woman with Shock and Labile Blood Pressure\nA 55-year-old woman presented with cardiogenic shock. Echocardiography revealed a left ventricular ejection fraction of 15% and apical ballooning; angiography revealed normal coronary arteries. She had episodes of hypotension and hypertension. A diagnosis was made.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "A diagnosis was made.", "content": "【0】Case 8-2018: A 55-Year-Old Woman with Shock and Labile Blood Pressure\nA 55-year-old woman presented with cardiogenic shock. Echocardiography revealed a left ventricular ejection fraction of 15% and apical ballooning; angiography revealed normal coronary arteries. She had episodes of hypotension and hypertension. A diagnosis was made.", "index": 317, "show": true, "start": 317, "end": 338, "province": ["语义有效性", "语义不完整"], "isEdit": false}], "startTime": "2024/08/14 14:55:20", "endTime": "2024/08/14 14:55:46", "cost": 25.981}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 22:55:47", "grab_time": "2024-08-13 22:55:20"}
{"id": 2234418, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "540359fc-4582-4da5-958b-27036de919d6", "title": "West Nile Virus among Blood Donors in the United States, 2003 and 2004", "text": "【0】West Nile Virus among Blood Donors in the United States, 2003 and 2004\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】West Nile virus first appeared in the United States in 1999 and has since spread throughout the contiguous states, resulting in thousands of cases of disease. By 2002, it was clear that the virus could be transmitted by blood transfusion, and by the middle of 2003, essentially all blood donations were being tested for West Nile virus RNA with the use of investigational nucleic acid amplification tests; testing was performed on individual samples or on “minipools” of up to 16 donations.\n\n【3】Methods\n-------\n\n【4】We analyzed data from the West Nile virus testing program of the American Red Cross for 2003 and 2004 to identify geographic and temporal trends. In areas with a high incidence of infection, individual donations were tested to increase the sensitivity of testing. Donors with reactive results participated in follow-up studies to confirm the original reactivity and to assess the natural history of infection.\n\n【5】Results\n-------\n\n【6】Routine testing in 2003 and 2004 identified 540 donations that were positive for West Nile virus RNA, of which 362 (67 percent) were IgM-antibody–negative and most likely infectious. Of the 540 positive donations, 148 (27 percent) were detectable only by testing of individual donations, but only 15 of the 148 (10 percent) were negative for IgM antibody. The overall frequencies of RNA-positive donations during the epidemic periods were 1.49 per 10,000 donations in 2003 and 0.44 per 10,000 in 2004. In 2004, 52 percent of the positive donations were from donors in four counties in southern California.\n\n【7】Conclusions\n-----------\n\n【8】Rapid implementation of a nucleic acid amplification test led to the prospective identification of 519 donors who were positive for West Nile virus RNA and the removal of more than 1000 potentially infectious related components from the blood supply of the Red Cross. No cases of transfusion-transmitted infection were confirmed among recipients of the tested blood.\n\n【9】Introduction\n------------\n\n【10】Although West Nile virus was first isolated in 1937 from a patient in Uganda,  it was not seen in the Western Hemisphere until 1999, when 62 cases of West Nile virus encephalitis were reported.  Biggerstaff and Petersen estimated that, during the peak of the 1999 outbreak in Queens, New York, the maximal and mean risks of transmission of West Nile virus by blood transfusion were 2.7 and 1.8 per 10,000 units, respectively.  In September 2002, the Centers for Disease Control and Prevention (CDC) announced that three of four recipients of transplanted organs from a single donor had acquired meningoencephalitis and were positive for West Nile virus. The fourth recipient was subsequently confirmed to have West Nile virus infection. The organ donor acquired West Nile virus infection through the transfusion of blood from 63 donors two days before organ harvest.  Subsequently, 23 cases of transfusion-transmitted West Nile virus infection were confirmed in 2002.  As a result, on September 20, 2002, major blood organizations, diagnostic companies, the CDC, the American Association of Blood Banks, and the Food and Drug Administration (FDA) agreed that blood-screening tests for West Nile virus RNA were needed by the 2003 season of West Nile virus infection. The FDA provided guidance for the assessment of donor suitability and the safety of blood and blood products in cases of known or suspected West Nile virus infection in October 2002,  with revisions in May 2003 <sup><a>9 </a></sup> and April 2005. \n\n【11】In the United States, routine screening of blood donors for West Nile virus RNA started in the summer (June through August) of 2003. We describe the results of the American Red Cross program of laboratory testing in 2003 and 2004 and compare the yield in those years with the preclinical yield obtained in 2002.  The dynamics of viral replication, the serologic profiles of seroconverting donors, and the associated clinical symptoms in infected donors are reported in detail elsewhere. \n\n【12】Methods\n-------\n\n【13】Selection and Qualification of Test Kits\n----------------------------------------\n\n【14】In 2002, a total of 383 retrieved units of frozen plasma, including plasma corresponding to blood components transfused to 11 of the 23 patients with confirmed transfusion-transmitted infection,  were tested with the use of five different investigational and research-based assays for West Nile virus RNA and three research-based or FDA-cleared assays for viral IgM antibody.  On the basis of these studies, the Gen-Probe Procleix West Nile virus assay (Gen-Probe and Chiron) was deemed qualified for routine screening of blood donations involving “minipools” of 16 samples. In this test, West Nile virus–specific RNA is amplified by transcription-mediated amplification. Also on the basis of these studies, the qualitative and quantitative polymerase-chain-reaction (PCR) assays (National Genetics Institute) and IgM antibody test (Abbott Laboratories) were selected for use in confirmation and follow-up studies.\n\n【15】Sample Collection and Laboratory Testing\n----------------------------------------\n\n【16】Plasma samples to be screened for West Nile virus RNA were obtained from the collected Plasma-Preparation Tubes (Becton Dickinson) used for routine screening for human immunodeficiency virus type 1 (HIV-1) RNA and hepatitis C virus RNA.  Testing for West Nile virus was performed under an FDA-approved Investigational New Drug application. All studies were approved by the institutional review board of the American Red Cross.\n\n【17】Routine screening for West Nile virus RNA of minipools of plasma from 16 donations was implemented on June 23, 2003, and is ongoing at five American Red Cross laboratories. The testing process is identical to that used for routine screening of blood for HIV-1 and hepatitis C virus RNA.  Samples from reactive minipools were tested individually to determine which were reactive. Routine nucleic acid amplification testing of individual donations was substituted for minipool testing in areas in which reactive donations exceeded the defined threshold.  In 2003, nucleic acid amplification testing of individual donations was also retrospectively performed on samples collected in Nebraska that had been nonreactive on minipool testing to determine whether any reactive donations had gone undetected with the use of minipool testing.\n\n【18】All reactive samples and samples of the corresponding plasma components manufactured from the index donations were further tested for West Nile virus RNA by transcription-mediated amplification and PCR. Samples from the retrieved plasma components from donors with reactive samples on nucleic acid amplification testing in 2003 were tested for IgM antibodies to the virus. Manufacture of the Abbott IgM assay was discontinued in 2004; the use of another test was necessary. Thus, beginning in 2004, FDA-cleared assays for West Nile virus IgM and IgG antibodies (Focus Diagnostics) were used.  Use of this IgM assay required multiplication of the cutoff value by a correction factor of 0.67 and coupling of the assay with the company's IgG assay so that sensitivity was similar to that of the Abbott IgM assay. Donations that were positive for West Nile virus RNA on minipool or individual nucleic acid amplification testing were considered to be confirmed if the index donation sample, retrieved plasma-component sample, or donor follow-up samples were reactive on repeated nucleic acid amplification testing (transcription-mediated amplification or PCR), were positive for West Nile virus–specific antibodies, or met both criteria. The viral loads (expressed as the number of copies of West Nile virus RNA per milliliter) of PCR-positive index or follow-up samples were determined. According to the manufacturers, the 50 percent detection rate of transcription-mediated amplification is 3 to 4 copies per milliliter, and the sensitivity of the qualitative PCR is 5 copies per milliliter; the sensitivity of quantitative PCR is 100 copies per milliliter.\n\n【19】Approach to Blood Donors, Components, and Recipients\n----------------------------------------------------\n\n【20】Donors with either confirmed positive or false positive results on nucleic acid amplification tests for West Nile virus RNA were notified, and they were prevented from making further donations according to FDA guidelines.  Demographic information about these donors (including ZIP Code of residence, sex, and age and whether they were first-time or repeat donors) was collected for analysis. Donors with reactive specimens who provided written informed consent participated in the follow-up study by providing additional blood samples for repeated RNA and antibody testing.\n\n【21】On identification of an RNA-reactive donation, all components associated with the index donation were quarantined and the plasma unit was retrieved for further testing. We traced recipients of transfused components from confirmed positive index donations identified through retrospective nucleic acid amplification testing of individual donations in 2003.\n\n【22】Study Design and Analysis\n-------------------------\n\n【23】The authors are jointly responsible for the study design, the integrity and analysis of the data, and the content of the article. Data on nucleic acid amplification testing were collected and verified by an independent clinical-research organization (Medical Marketing Consultants).\n\n【24】Results\n-------\n\n【25】Prevalence of West Nile Virus among Blood Donors, 2002 through 2004\n-------------------------------------------------------------------\n\n【26】Table 1. Results of Tests of Blood Donations for West Nile Virus.\n\n【27】Studies conducted on samples collected in September 2002 from six areas with a high incidence of West Nile virus infection yielded a confirmed positive rate of 0.095 percent, or 1 in 1057 samples.  This rate, even late in the 2002 season, remained high and similar to the average risks of transfusion-transmitted West Nile virus infection estimated by the CDC for 2002 for the same metropolitan areas.  Table 1 shows the prevalence rates of West Nile virus infection in 2002 in comparison with the rates in 2003 and 2004.\n\n【28】In 2003, the first confirmed positive donation was identified on June 26 in Los Angeles from a donor who had returned from a trip to Colorado on the day before donation. The last positive donation was identified on December 1 in Georgia. Overall, 436 confirmed positive donations were identified from a total of 2,935,249 donations screened, for a rate of 0.015 percent, or 1 in 6732 . Of these positive donations, 328 (75 percent) were collected from Kansas and Nebraska residents, for a combined rate of 0.68 percent, or 1 in 147, which was 45 times as high as the systemwide rate.\n\n【29】The first confirmed positive donor in 2004 was identified on June 16 in Phoenix, Arizona, and the last was identified on October 16 in Los Angeles. During this period, 104 confirmed positive donations were identified from a total of 2,386,630 screened, for a rate of 0.004 percent, or 1 in 22,948 . Of these positive donations, 54 (52 percent) were identified from residents of four southern California counties (Los Angeles, Orange, Riverside, and San Bernardino), for a rate of 0.064 percent, or 1 in 1566, which was 16 times as high as the systemwide rate.\n\n【30】Figure 1. Numbers of U.S. Blood Donors Who Were Confirmed to Be Positive for West Nile Virus RNA in 2002, 2003, and 2004, According to the Week of Collection.\n\n【31】Data on 2002 totals are from Stramer et al.  The weekly totals for 2002 were adjusted for the number of donations tested during the four-week study.\n\n【32】Figure 1 shows the frequency of confirmed positive donors identified in 2002, 2003, and 2004, according to week of donation. Although all positive donors in both 2003 and 2004 were identified between June and December, the peak season for 2003 was from mid-August to mid-September, whereas for 2004, the peak season started in late July and continued through late September, but at a lower frequency. The absence of any West Nile virus RNA–positive donations during the week before the initiation of prospective screening in 2003 (from retrospective testing of samples retained from the prior week that had been frozen) suggests that the onset of routine screening preceded the 2003 epidemic.\n\n【33】Our data indicate that the areas of highest incidence of confirmed positive donors moved westward from 2002 to 2004. The Cleveland and Detroit metropolitan areas had higher rates in September 2002 than at any time during 2003 and 2004. Kansas and Nebraska had higher rates in 2003 than in 2004, and southern California had the highest rates in 2004. These findings are in agreement with the pattern of clinical cases reported to the CDC. \n\n【34】Development of the Trigger for Nucleic Acid Amplification Testing of Individual Donations\n-----------------------------------------------------------------------------------------\n\n【35】On the basis of data obtained in 2002, we found that there was one potentially infectious (RNA-positive, IgM-negative) sample detectable only by nucleic acid amplification testing of individual donations for every four such samples detected by minipool testing.  For 2003 and 2004, we therefore chose to initiate testing of individual donations in any blood-collection region after the identification of four RNA-positive donations and consequent calculation of a detection frequency of 1 in 1000 (the epidemic frequency documented in 2002 <sup><a>11,19 </a></sup> ), on the basis of the date of collection of the first reactive donation. Once nucleic acid amplification testing of individual donations had been initiated, a seven-day period with no RNA-reactive donations was required before a collection region could revert to the use of minipool testing.\n\n【36】Nucleic Acid Amplification Testing and IgM and IgG Testing of Individual Donations\n----------------------------------------------------------------------------------\n\n【37】In 2003, 30,501 Red Cross donations from Kansas residents (August 19 to September 27) and Nebraska residents (August 25 to October 4) underwent individual nucleic acid amplification testing. Prospective testing identified 181 confirmed positive donations. Of these, 96 (53 percent) were nonreactive at a  dilution, of which 88 (92 percent) were IgM-positive and 8 (8 percent) were IgM-negative. In addition, as requested by the FDA, individual nucleic acid amplification testing was performed retrospectively on frozen samples from 18,049 donations collected from July 10 (the date of the first confirmed positive donation identified by minipool testing) to August 22 from donors who lived in Nebraska to determine whether donations that were nonreactive on minipool testing and had therefore been released for transfusion would be identified as reactive on testing of individual donations. This retrospective evaluation identified 21 additional confirmed positive donations: 19 were IgM-positive samples and 2 were IgM-negative samples. During the same period, minipool testing had previously identified 80 confirmed positive donations (or 79 percent of the total detected during this period): 7 were IgM-positive samples and 73 were IgM-negative samples.\n\n【38】Figure 2. IgM and IgG Antibody Status of Blood Donors Who Were Confirmed to Be Positive for West Nile Virus RNA on Prospective Screening in 2003 and 2004, According to the Week of Collection.\n\n【39】In 2003 , IgM antibody testing was performed by Abbott Laboratories; in 2004 , IgM and IgG antibody testing was performed by Focus Technologies with the use of a reduced cutoff value (the standard cutoff value was multiplied by a correction factor of 0.67).\n\n【40】Overall, 117 of the 436 confirmed positive donations identified in 2003 (27 percent) were detected only by individual nucleic acid amplification testing (although this may be an underestimate, since not all donations were tested by this method), and of these 117, 10 (9 percent) were IgM-negative . Of the remaining 319 donations that were reactive on minipool testing, 283 (89 percent) were IgM-negative . For the 143 IgM-positive donations, the median viral load was below 100 copies per milliliter (range, less than 5 to 14,000), as compared with 5800 copies per milliliter (range, less than 5 to 580,000) for the 293 IgM-negative donations (P<0.001 by the Wilcoxon rank-sum test). Donations that were positive for West Nile virus RNA and IgM were identified more frequently as the season progressed .\n\n【41】In 2004, the trigger for nucleic acid amplification testing of individual donations was reached for collections tested by the Red Cross in three areas: southern California (July 25 to October 8), Kansas (September 12 to 27), and Arkansas (August 28 to September 6), for a total of 92,460 donations tested individually. No reactive donations were identified by individual testing of Arkansas donors. However, 48 of 54 confirmed positive donations from southern California residents (89 percent) and 3 of 7 confirmed positive donations from Kansas residents (43 percent) were identified during the period of individual testing, for a combined positive rate of 0.056 percent, or 1 in 1791 donations. Of the 51 confirmed positive donations identified by nucleic acid amplification testing of individual donations, 31 (61 percent) were nonreactive on minipool testing. These 31 donations represented 30 percent of the total 104 positive donations identified in 2004; 26 (84 percent) were positive for IgM or IgG, and 5 (16 percent) were negative for IgM and IgG . Figure 2B shows that the identification of confirmed positive donations with IgM or IgG antibody reactivity increased as the 2004 season progressed; this increase was less than that observed for 2003. For the 35 IgM- or IgG-positive donations, the median viral load was below 100 copies per milliliter (range, less than 5 to 47,000), as compared with 3200 copies per milliliter (range, less than 5 to 160,000) for the 69 IgM- and IgG-negative donations (P<0.001 by the Wilcoxon rank-sum test).\n\n【42】In both 2003 and 2004, two thirds of all viremic donors were negative for West Nile virus antibody, according to two different IgM-antibody testing strategies: the Abbott Laboratories IgM assay  and the Focus Technologies IgM and IgG assays .\n\n【43】Demographic Characteristics of Donors\n-------------------------------------\n\n【44】Table 2. Demographic Characteristics of Blood Donors with Reactive Nucleic Acid Amplification Tests.\n\n【45】Among the confirmed positive donors, as compared with the group of donors with false positive results, there were more male than female donors in 2002,  2003, and 2004 . In 2003, 50 percent of the overall donor population of the American Red Cross was male. Combining the confirmed positive donors from 2002 through 2004, 13 percent were first-time donors, with a mean age of 46 years (range, 16 to 83). These observations did not differ significantly from those observed for the donors with false positive test results.\n\n【46】Follow-up of Donors and Recipients\n----------------------------------\n\n【47】In 2003, 350 of 415 confirmed positive donors identified prospectively participated in the follow-up study, of whom 335 (96 percent) were IgM-positive or seroconverted during follow-up. Of 186 donors who participated in long-term follow-up, 166 (89 percent) retained specific IgM reactivity for 100 days or longer. However, of the 17 of 46 confirmed positive donors identified in 2002 for whom follow-up data were available,  10 (59 percent) had IgM reactivity for more than 398 days, consistent with the observations of Roehrig and coworkers.  Of 104 confirmed positive donors identified in 2004, 82 (79 percent) participated in follow-up studies.\n\n【48】Only two recipients of donations confirmed to be positive on retrospective testing of individual donations in 2003 could be identified and consented to follow-up studies. Both were seronegative for West Nile virus and had had no reported symptoms associated with West Nile virus infection during the year after transfusion. In the case of both recipients, the transfused component was IgM-positive and had an RNA level that was too low to quantitate. In contrast, a 2002 recipient of an IgM-negative unit with a viral load of 6300 copies per milliliter had West Nile virus–related symptoms and antibody seroconversion.  Although these numbers are small, the data are consistent with reports of seroconversion and disease related to West Nile virus infection only among recipients of viremic, IgM-negative blood components. \n\n【49】Discussion\n----------\n\n【50】In 2002, transfusion-transmitted West Nile virus infection was confirmed in 23 recipients of blood components, with the true number of transmissions believed to be much higher. By early summer of 2003, blood-collection agencies had implemented blood-donor testing for West Nile virus RNA, identifying and reporting a total of 1041 RNA-positive donations to the CDC through Arbonet for the 2003 and 2004 seasons.  The Red Cross program identified 540 of these viremic donations, of which 362 (67 percent) were negative for West Nile virus antibodies and likely infectious. The major epidemic focus in 2003 was the upper Plains states, moving to the Southwest in 2004. Most important, on the basis of prospective screening for West Nile virus RNA performed in 2003 and 2004 in our program, 1023 components manufactured from 519 prospectively screened viremic donations were not released for use and therefore not transfused.\n\n【51】Screening of blood donations for West Nile virus RNA was initiated in minipools of 16 samples, leading to concern that donations with low-level viremia might escape detection.  Our data from the 2002 West Nile virus season suggested that, at the height of the epidemic, there might be one viremic donation undetectable by minipool testing for every four that were detected. Accordingly, in areas with a high prevalence of RNA-positive donations (i.e., more than 1 in 1000 samples), we initiated nucleic acid amplification testing of individual donations after identifying a total of four RNA-positive donations on minipool testing in any given blood-collection region. This policy was supported by the observation of West Nile virus infections associated with the transfusion of blood units with RNA levels that could not be detected by minipool testing.  In addition, the effectiveness of this evidence-based trigger is demonstrated by the absence of any confirmed cases of transfusion-transmitted West Nile virus infection associated with blood components from our system in 2003 and 2004. An assessment of the effectiveness of various trigger strategies has been published elsewhere.  The continued use of a trigger strategy for the screening of blood donations for West Nile virus appears justified in order to focus available resources at times and locations of peak incidence. In contrast, at times and locations in which there are few or no identified viremic donations, minipool screening provides adequate safety.\n\n【52】Through careful follow-up studies of all RNA-reactive donors, we were able to establish the natural history of West Nile virus infection, finding that IgM antibodies against the virus were detectable about 11 days after the detection of viral RNA on minipool testing (13 days after the detection of viral RNA on testing of individual samples), followed rapidly by the appearance of IgG antibodies.  The transmission of West Nile virus through transfusion has not been linked to an RNA-positive component that is also positive for IgM or IgG antibodies against the virus. Although we identified 148 viremic donations that were detectable only by nucleic acid amplification testing of individual donations, only 15 of them (10 percent), or 1 in 9400 samples, were IgM-negative and thus represent the earliest stages of donor infection. Therefore, in programs dependent on trigger strategies, careful, real-time monitoring is critical; in the absence of timely system readiness and monitoring, breakthrough infection has been documented. \n\n【53】The vast majority of the yield of nucleic acid amplification testing of individual donations was IgM-positive, demonstrating the long duration of positivity for IgM antibody in the presence of low-level viremia. It is likely that such donations would be noninfectious, especially in the presence of high titers of IgM and IgG, but studies to confirm this possibility have not been performed. Studies tracing recipients of blood components generally have a low yield, and our study is no exception; however, two recipients of IgM-positive, viremic blood components had no evidence of West Nile virus infection, in contrast to recipients who received IgM-negative, viremic units. \n\n【54】In future years, will the need to screen blood donors for West Nile virus continue? We have now seen three West Nile virus epidemic seasons in the United States, with an expanding geographic range of viremic blood donors and clinical infections. The number of reported cases of West Nile virus neuroinvasive disease peaked in 2002 and 2003 (2946 and 2866 cases, respectively  ) and decreased (to 1108 cases) in 2004.  This same trend was observed by our identification of 436 viremic blood donors in 2003 and of 104 in 2004, as well as by the total number of viremic blood donors reported to the CDC during these years (818 and 223, respectively).  West Nile virus infection may eventually follow the same pattern as St. Louis encephalitis, with only infrequent, localized recurrences.\n\n【55】To our knowledge, the implementation of nationwide testing for West Nile virus RNA has been the most rapidly instituted test-based intervention in the history of transfusion safety, taking only about nine months from the decision to develop a test to its implementation. The program is a model of cooperation among public health agencies, regulators, manufacturers, and the blood-supply system.  It is to be hoped that this process will be effectively replicated should there be a similar outbreak in the future.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:34:38", "endTime": "2024/08/14 14:40:16", "cost": 338.156}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 22:40:16", "grab_time": "2024-08-13 22:34:37"}
{"id": 2234417, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "56bb1dc5-8b49-467a-a426-22745c8b64fe", "title": "Pesticide-like Poisoning from a Prescription Drug", "text": "【0】Pesticide-like Poisoning from a Prescription Drug\nTo the Editor:\n--------------\n\n【1】Acetylcholinesterase inhibitors have long been known for their use as pesticides. Since the 1990s, acetylcholinesterase-inhibiting pharmaceuticals (donepezil, tacrine, galantamine, and rivastigmine) have been used to treat Alzheimer's disease; they are currently being investigated as a treatment for dementia associated with Parkinson's disease in adults  and with Tourette's syndrome and autistic and attention deficit–hyperactivity disorders in children.  Wider use of this class of medications for a broader variety of disorders increases the possibility of pesticide-like poisoning from a prescribed medication. We report a case of such poisoning.\n\n【2】A healthy 11-month-old girl (weight, 7.5 kg) presented to a pediatric hospital with rapid onset of general weakness during a period of several hours. The infant had been discharged from the same hospital three days earlier after undergoing intravenous rehydration for gastroenteritis. On arrival at the second visit, she was hypotonic, hyporeflexic, and had miosis and a weak cry. She had had no diarrhea, wet diapers, or lacrimation. Neurology was consulted; a workup was initiated to rule out botulism and Guillain–Barré syndrome. The levels of electrolytes, blood urea nitrogen, creatinine, and glucose and the complete blood count were normal, as were the results of liver-function tests, electrocardiography, urinalysis, computed tomography of the head, and lumbar-puncture studies. There was no family history of myasthenia gravis or neuromuscular disorders. The family did not keep plants in the home, and they did not use rodenticides. Since it was winter in New England, there was no outdoor exposure to insecticides. Further questioning revealed that the patient's mother had found the child chewing a capsule containing rivastigmine, a drug taken by the grandmother, earlier in the day, but because of history-taking and language problems (the family was first-generation Vietnamese), the connection was not initially made between the drug exposure and the child's symptoms.\n\n【3】Rivastigmine is a centrally acting carbamate derivative and a reversible inhibitor of acetylcholinesterase that produces a self-limited cholinergic constellation of signs and symptoms consistent with a specific drug class or xenobiotic poisoning that rarely lasts more than 24 hours. Muscarinic effects may be treated with atropine and nicotinic effects with oximes such as pralidoxime. However, muscarinic effects are often absent in children,  as was the case with our patient, and the administration of oximes does not appear to speed recovery from nicotinic effects in such cases.  Our patient improved with supportive care alone, and by 24 hours after she had ingested the drug, she was sitting without assistance; by 48 hours, she had regained her normal strength and was discharged.\n\n【4】Our patient had notable, predominantly nicotinic cholinergic effects after exposure to a nonpesticide carbamate acetylcholinesterase inhibitor intended for the treatment of memory-impaired adults. As the use of this class of drugs becomes more widespread, we want to alert clinicians to consider such exposure when evaluating weakness of rapid onset or any case of pesticide-like poisoning in which pesticide exposure is unlikely.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 16:27:09", "endTime": "2024/08/13 16:28:07", "cost": 58.37}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 00:28:07", "grab_time": "2024-08-13 00:27:09"}
{"id": 2234416, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "30d05f7d-1a15-4a3b-a171-964758012fa0", "title": "Effect of Passive Smoking on Angina Pectoris", "text": "【0】Effect of Passive Smoking on Angina Pectoris\nAbstract\n--------\n\n【1】The effect of passive smoking on exercise-induced angina in a well ventilated and in an unventilated room was evaluated in 10 patients with angina. Patients exposed to 15 cigarettes smoked within two hours in a well ventilated room or an unventilated room increased their resting heart rate, systolic and diastolic blood pressure, and venous carboxyhemoglobin and decreased their heart rate and systolic blood pressure at angina. Patients exposed to passive smoking in an unventilated room had a larger increase in resting heart rate, systolic and diastolic blood pressure, and venous carboxyhemoglobin and a greater reduction in heart rate and systolic blood pressure at angina. The duration of exercise until angina was decreased 22 per cent after passive smoking in a well ventilated room (P<0.001), and decreased 38 per cent after passive smoking in an unventilated room (P<0.001). Passive smoking aggravates angina pectoris.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:37:11", "endTime": "2024/08/14 15:37:25", "cost": 14.215}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 23:37:26", "grab_time": "2024-08-13 23:37:11"}
{"id": 2234415, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "4862708d-19b0-43c3-98b2-239986470d20", "title": "Low-Carbohydrate-Diet Score and the Risk of Coronary Heart Disease in Women", "text": "【0】Low-Carbohydrate-Diet Score and the Risk of Coronary Heart Disease in Women\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Low-carbohydrate diets have been advocated for weight loss and to prevent obesity, but the long-term safety of these diets has not been determined.\n\n【3】Methods\n-------\n\n【4】We evaluated data on 82,802 women in the Nurses' Health Study who had completed a validated food-frequency questionnaire. Data from the questionnaire were used to calculate a low-carbohydrate-diet score, which was based on the percentage of energy as carbohydrate, fat, and protein (a higher score reflects a higher intake of fat and protein and a lower intake of carbohydrate). The association between the low-carbohydrate-diet score and the risk of coronary heart disease was examined.\n\n【5】Results\n-------\n\n【6】During 20 years of follow-up, we documented 1994 new cases of coronary heart disease. After multivariate adjustment, the relative risk of coronary heart disease comparing highest and lowest deciles of the low-carbohydrate-diet score was 0.94 (95% confidence interval \\[CI\\], 0.76 to 1.18; P for trend=0.19). The relative risk comparing highest and lowest deciles of a low-carbohydrate-diet score on the basis of the percentage of energy from carbohydrate, animal protein, and animal fat was 0.94 (95% CI, 0.74 to 1.19; P for trend=0.52), whereas the relative risk on the basis of the percentage of energy from intake of carbohydrates, vegetable protein, and vegetable fat was 0.70 (95% CI, 0.56 to 0.88; P for trend=0.002). A higher glycemic load was strongly associated with an increased risk of coronary heart disease (relative risk comparing highest and lowest deciles, 1.90; 95% CI, 1.15 to 3.15; P for trend=0.003).\n\n【7】Conclusions\n-----------\n\n【8】Our findings suggest that diets lower in carbohydrate and higher in protein and fat are not associated with increased risk of coronary heart disease in women. When vegetable sources of fat and protein are chosen, these diets may moderately reduce the risk of coronary heart disease.\n\n【9】Introduction\n------------\n\n【10】Obesity in the United States has reached epidemic proportions. Leading research and medical societies advocate a low-fat, high-carbohydrate, energy-deficient diet to manage weight.  Despite these recommendations, diets high in fat and protein and low in carbohydrate remain popular, and several best-selling books endorse this strategy for weight loss. \n\n【11】The long-term safety of carbohydrate-restricted diets remains controversial. Most such diets tend to encourage increased consumption of animal products and therefore often contain high amounts of saturated fat and cholesterol. This may cause unfavorable changes in serum lipid levels and increase the risk of coronary heart disease. Several professional organizations have cautioned against the use of low-carbohydrate diets. \n\n【12】We devised a system to classify women who participated in the Nurses' Health Study according to their relative levels of fat, protein, and carbohydrate intake and created a simple summary score designated the “low-carbohydrate-diet score.” We then examined prospectively the association between the low-carbohydrate-diet score and the risk of coronary heart disease in this cohort.\n\n【13】Methods\n-------\n\n【14】Study Population\n----------------\n\n【15】The Nurses' Health Study was initiated in 1976, when 121,700 female registered nurses 30 to 55 years of age completed a mailed questionnaire. Since 1976, information on disease status and lifestyle factors has been collected from this same cohort every 2 years. Diet was assessed by means of a semiquantitative food-frequency questionnaire in 1980, 1984, 1986, 1990, 1994, and 1998; 98,462 women completed the 1980 questionnaire.\n\n【16】For this investigation we excluded all women at baseline who left 10 or more food items blank or had implausibly high (>3500 kcal) or low (<500 kcal) daily energy intakes on the food-frequency questionnaire. We further excluded women with a history of diabetes, cancer, or cardiovascular disease before 1980, because these diagnoses may cause alterations in diet. After these exclusions, 82,802 women remained in this investigation. The study was approved by the Human Research Committee of Brigham and Women's Hospital in Boston; the completion of the self-administered questionnaire was considered to imply informed consent.\n\n【17】Assessment of Diet and Glycemic Load\n------------------------------------\n\n【18】The 1980 food-frequency questionnaire included 61 food items and was revised in 1984 to include about twice that number.  Study participants reported average frequency of consumption of specific foods throughout the previous year. The validity and reproducibility of the questionnaire have been documented elsewhere. \n\n【19】To calculate the intake of specific foods, a commonly used portion size for each food was specified (e.g., one egg or one slice of bread) and participants were asked how often, on average, during the previous year they had consumed that amount. The possible responses ranged from never or less than once per month to six or more times per day.\n\n【20】Nutrient values were computed by multiplying the frequency of consumption of each food by the nutrient content of the portion and then adding these products across all food items. All food-composition values were obtained from the Harvard University food-composition database, which was derived from U.S. Department of Agriculture sources  and supplemented with information from the manufacturer. The validity of estimated nutrient intake as assessed by the questionnaire has previously been evaluated with the use of multiple diet records. The correlation between the 1986 questionnaire and the average of six 1-week diet records collected in 1980 and 1986 was 0.73 for carbohydrate, 0.67 for total fat, and 0.56 for protein. \n\n【21】The method used to assess glycemic load in the Nurses' Health Study has been described elsewhere.  Briefly, we calculated the total dietary glycemic load by multiplying the carbohydrate content of each food by its glycemic index (the glycemic index of glucose is 100) and then multiplied this value by the frequency of consumption and summed these values for all foods. Dietary glycemic load, therefore, represents both the quality and quantity of carbohydrate consumed. Each unit of glycemic load represents the equivalent blood glucose–raising effect of 1 g of pure glucose.\n\n【22】Calculation of the Low-Carbohydrate-Diet Score\n----------------------------------------------\n\n【23】Table 1. Criteria for Determining the Low-Carbohydrate-Diet Score.\n\n【24】We divided the study participants into 11 strata each of fat, protein, and carbohydrate intake, expressed as a percentage of energy . For fat and protein, women in the highest stratum received 10 points for that macronutrient, women in the next stratum received 9 points, and so on down to women in the lowest stratum, who received 0 points. For carbohydrate, the order of the strata was reversed; those with the lowest carbohydrate intake received 10 points and those with the highest carbohydrate intake received 0 points. We used the percentage of energy consumed instead of absolute intake to reduce bias due to underreporting of food consumption and to represent dietary composition.\n\n【25】The points for each of the three macronutrients were then summed to create the overall diet score, which ranged from 0 (the lowest fat and protein intake and the highest carbohydrate intake) to 30 (the highest protein and fat intake and the lowest carbohydrate intake). Therefore, the higher the score, the more closely the participant's diet followed the pattern of a low-carbohydrate diet. Thus, the score was termed the “low-carbohydrate-diet score.”\n\n【26】We also created two additional low-carbohydrate-diet scores. One was calculated according to the percentage of energy as carbohydrate, the percentage of energy as animal protein, and the percentage of energy as animal fat, and the other was calculated according to the percentage of energy as carbohydrate, the percentage of energy as vegetable protein, and the percentage of energy as vegetable fat .\n\n【27】Measurement of Nondietary Factors\n---------------------------------\n\n【28】In 1976, women provided information regarding parental history of myocardial infarction. Beginning in 1976, participants also provided information every 2 years on the use of postmenopausal hormones, smoking status, body weight, and other covariates. They provided information on aspirin use repeatedly throughout the follow-up. The correlation coefficient between self-reported body weight and measured weight was 0.96.  Physical activity was assessed in 1980, 1982, 1986, 1988, 1992, 1996, and 1998, and we calculated the cumulative average number of hours per week spent in moderate or vigorous physical activity. \n\n【29】Outcome\n-------\n\n【30】The outcome of this study was incident coronary heart disease, including nonfatal myocardial infarctions or fatal coronary events. Each participant contributed follow-up time from the date of returning the 1980 questionnaire to the date of the first end point (death or nonfatal myocardial infarction) or until the censoring date of June 1, 2000.\n\n【31】We requested permission to examine the medical records of all participants who reported a diagnosis of coronary heart disease on one of the follow-up questionnaires that were completed every two years. A myocardial infarction was considered to be confirmed if it met the World Health Organization criteria of symptoms and either typical electrocardiographic changes or elevated cardiac-enzyme levels.  Infarctions that necessitated a hospital admission and for which confirmatory information was obtained by interview or letter but for which no medical records were available were designated as probable and were included in the analysis.\n\n【32】Deaths were identified from state vital records and the National Death Index or reported by the participants' next of kin or the U.S. Postal Service.  Fatal coronary heart disease was confirmed by an examination of autopsy or hospital records, by a listing of coronary heart disease as the cause of death on the death certificate, and by the availability of evidence of previous coronary heart disease. Those deaths in which coronary heart disease was the underlying cause on the death certificate but for which no medical records were available were designated as deaths from presumed coronary disease.\n\n【33】Statistical Analysis\n--------------------\n\n【34】We divided women into 10 categories (deciles) according to their low-carbohydrate-diet score. To represent long-term intake and reduce measurement error, we calculated the cumulative average low-carbohydrate-diet score based on the information from the 1980, 1984, 1986, 1990, 1994, and 1998 questionnaires.  For example, the low-carbohydrate-diet score from the 1980 questionnaire was related to the incidence of coronary heart disease between 1980 and 1984, and the low-carbohydrate-diet score from the average of the 1980 and 1984 questionnaires was related to the incidence of coronary heart disease between 1984 and 1986. Incidence rates for coronary heart disease were calculated by dividing cases by the person-years of follow-up for each decile of the low-carbohydrate-diet score. Relative risks of coronary heart disease were calculated by dividing the rate of occurrence of coronary heart disease in each decile by the rate in the first (lowest) decile. We used Cox proportional-hazards models  to adjust for potentially confounding variables. Because low-carbohydrate diets may decrease subsequent energy intake,  we did not control for total energy intake in multivariate models. However, further adjustment for caloric intake was performed in a secondary analysis. We also examined the association between each macronutrient and the risk of coronary heart disease in multivariate nutrient-density models.  All P values are two-sided.\n\n【35】Results\n-------\n\n【36】Table 2. Characteristics of the Participants in 1990 According to the Low-Carbohydrate-Diet Scores.\n\n【37】The cumulative average low-carbohydrate-diet score ranged from a median of 5.0 in the 1st decile to a median of 26.0 in the 10th decile . The mean daily carbohydrate intake ranged from 234.4 g in the 1st decile to 116.7 g in the 10th decile. At the midpoint of follow-up (1990), women who had a higher score were more likely to smoke and had a higher body-mass index, a lower dietary glycemic load, a lower caloric intake, and a higher intake of saturated fat. On average, body-mass index increased by approximately 2.5 units from baseline to the end of follow-up, regardless of the low-carbohydrate-diet score.\n\n【38】Because the Nurses' Health Study did not routinely collect data on blood lipid levels, the effect of a low-carbohydrate diet on lipids could not be assessed for the entire study cohort. However, a subgroup of women from the study (466 women) had blood drawn in 1990 for determinations of lipid levels. In this subgroup, the low-carbohydrate-diet score was not associated with the total cholesterol level or with the levels of high-density lipoprotein (HDL) cholesterol or low-density lipoprotein (LDL) cholesterol after adjustment for age, smoking status, and other covariates. The low-carbohydrate-diet score was inversely associated with the triglyceride level (126.5 mg per deciliter in the lowest quintile and 99.3 mg per deciliter in the highest quintile of the low-carbohydrate-diet score, P for trend=0.05).\n\n【39】Table 3. Relative Risk of Coronary Heart Disease in Women According to Low-Carbohydrate-Diet Score.\n\n【40】During 20 years of follow-up (1,584,042 person-years), we documented 1994 cases of coronary heart disease. In age-adjusted analyses, the relative risk comparing women in the 10th decile with those in the 1st decile of the low-carbohydrate-diet score was 1.29 (95% confidence interval \\[CI\\], 1.04 to 1.60). After further adjustment for smoking status, the relative risk of coronary heart disease was 1.11 (95% CI, 0.89 to 1.38) comparing women in the same deciles of the low-carbohydrate-diet score (P for trend=0.54) . After controlling for potential confounders, the relative risk was 0.94 (95% CI, 0.76 to 1.18; P for trend=0.19). Further adjustment for total calories did not appreciably alter the results (relative risk, 0.96; 95% CI, 0.77 to 1.20; P for trend=0.27). When body-mass index was removed from the multivariate model, the results did not change significantly.\n\n【41】In stratified analyses, there was no evidence that the relationship between the low-carbohydrate-diet score and coronary heart disease was modified as a result of body-mass index, level of physical activity, smoking status, or the presence or absence of diabetes, hypertension, or hypercholesterolemia. Specific data on blood lipid levels were not available for most of the cohort. As a result, it was not feasible to adjust or stratify our analysis for this factor.\n\n【42】We also created a second low-carbohydrate-diet score according to the percentages of energy from carbohydrate, animal protein, and animal fat . The multivariate relative risk of coronary heart disease was 0.94 (95% CI, 0.74 to 1.19) for the comparison of the 10th with the 1st decile (P for trend=0.52) . We also created a third low-carbohydrate-diet score according to the percentages of energy from carbohydrate, vegetable protein, and vegetable fat . For the comparison of the 10th with the 1st decile, the multivariate relative risk of coronary heart disease was 0.70 (95% CI, 0.56 to 0.88; P for trend=0.002) .\n\n【43】Table 4. Relative Risk of Coronary Heart Disease in Women According to Consumption of Macronutrients.\n\n【44】We examined the association between coronary heart disease and each macronutrient separately . Total carbohydrate intake was associated with a moderately increased risk of coronary heart disease (P for trend for the comparison of the 10th decile with the 1st decile=0.06). For the comparison of the 10th with the 1st decile, there was a significant direct association between dietary glycemic load and coronary heart disease (relative risk, 1.90; 95% CI, 1.15 to 3.15; P for trend=0.003). The overall dietary glycemic index had a direct association with the risk of coronary heart disease (relative risk comparing extreme deciles, 1.19; 95% CI, 0.91 to 1.55; P for trend=0.04). There was a significant inverse association between vegetable-fat consumption and the risk of coronary heart disease (relative risk comparing extreme deciles, 0.75; 95% CI, 0.57 to 0.98; P for trend=0.006). Total fat, animal fat, total protein, animal protein, and vegetable protein were not significantly associated with the risk of coronary heart disease according to multivariate analyses.\n\n【45】Discussion\n----------\n\n【46】We found that after taking into account confounding variables (especially smoking status), a low-carbohydrate diet was not associated with a risk of coronary heart disease in this large prospective cohort of women. In fact, when vegetable sources of fat and protein were chosen, the low-carbohydrate-diet score was associated with a moderately lower risk of coronary heart disease than when animal sources were chosen.\n\n【47】The 20-year follow-up incorporating updated dietary data and the large number of women in the study provided adequate power for this study. We reduced the measurement error in assessing long-term diet in this analysis with the use of repeated measures of diet during the follow-up. Although we adjusted for many known risk factors, we cannot completely exclude the possibility of residual or unmeasured confounding, because of the observational nature of the study.\n\n【48】Few people in our cohort followed the strict version of the Atkins low-carbohydrate-diet program long-term.  However, the amount of carbohydrate in the highest category of carbohydrate intake in our cohort (<29.3% of calories) was similar to that consumed by participants in the clinical trials of low-carbohydrate diets.  When preset cutoff points were used with more extreme variation in macronutrients (<20% of diet as carbohydrate, >50% of diet as fat, and >27% of diet as protein), our results did not change significantly.\n\n【49】The low-carbohydrate-diet score did not have a significant long-term effect on weight. On average, body-mass index increased by approximately 2.5 units from baseline to the end of follow-up, regardless of the score. Since the participants in the Nurses' Health Study did not necessarily subscribe to a low-carbohydrate diet for the specific purpose of weight loss, this result is not unexpected. However, it does indicate that the effects of the low-carbohydrate-diet score on outcomes in this analysis were not mediated by weight loss.\n\n【50】Any assessment of the association between the low-carbohydrate-diet score and a risk of coronary heart disease must take each macronutrient into consideration. Different types of fat appear to have different effects on the risk of coronary heart disease. In epidemiologic studies, saturated  and trans  fats have been associated with an increased risk of coronary heart disease, and polyunsaturated and monounsaturated fats with decreased risk.  Total dietary fat, however, has not been associated with a risk of coronary heart disease. In the Women's Health Initiative, a low-fat dietary pattern was not associated with a reduced risk of coronary heart disease during an 8-year follow-up.  Therefore, the increase in total fat that is common among women who follow low-carbohydrate diets would not be expected to increase the risk of coronary heart disease. \n\n【51】In low-carbohydrate diets, dietary protein usually increases at the expense of carbohydrate. In our previous analyses, we found that a moderately high protein intake was significantly associated with a slightly reduced risk of coronary heart disease.  In this study, however, only vegetable protein was associated with a significantly reduced risk in age-adjusted analyses, and this association became nonsignificant in multivariate analyses.\n\n【52】Another possible explanation for the null association between a low-carbohydrate-diet score and the risk of coronary heart disease relates to the amount and quality of carbohydrate present in the diet.  A low-carbohydrate diet tends to have a lower dietary glycemic index and glycemic load than a high-carbohydrate diet. In a 10-year prospective analysis of the Nurses' Health Study, Liu et al. found a relative risk of coronary heart disease of 1.98 (95% CI, 1.41 to 2.77) for the comparison between the fifth and the first quintile of dietary glycemic load.  In our investigation, we found that the direct association between glycemic load and coronary heart disease was much stronger than the association between carbohydrate and coronary heart disease, probably because glycemic load reflects both the quantity and quality of carbohydrates.\n\n【53】In a meta-analysis of five randomized trials comparing a low-carbohydrate diet with a low-fat diet for at least 6 months, the low-carbohydrate diet was found to have a beneficial effect on HDL cholesterol and triglyceride levels but an adverse effect on total cholesterol and LDL cholesterol levels.  However, none of the trials have a sufficiently large sample size or a sufficiently long duration of follow-up to be used to study the outcomes of coronary heart disease. In our study, data on lipid levels were available for only a small subgroup of participants. In this group, the low-carbohydrate-diet score was not associated with total cholesterol, HDL cholesterol, or LDL cholesterol levels but was inversely associated with the triglyceride level. Therefore, it is not clear whether these findings are applicable to any low-carbohydrate diet that has an adverse effect on serum lipid levels.\n\n【54】Proponents of low-carbohydrate diets assert that ketogenesis (the production of ketone bodies) is an important component of the overall effects of such diets.  We were not able to measure ketogenesis in this investigation. Our investigation also did not address other possible adverse consequences of a low-carbohydrate diet in terms of a decline in renal function, osteoporosis, a decrease in micronutrient and fiber intake, and the risk of malignant conditions. We have observed previously in a subgroup of the Nurses' Health Study that dietary protein was not associated with a decline in renal function in women with normal renal function but may accelerate such a decline in women who have mild renal insufficiency.  Therefore, the long-term effects of high protein intake on renal function should be investigated further, especially among people with compromised renal function, such as those with diabetes or renal disease.\n\n【55】In conclusion, diets lower in carbohydrate and higher in protein and fat were not associated with an increased risk of coronary heart disease in this cohort of women. When vegetable sources of fat and protein were chosen, these diets were related to a lower risk of coronary heart disease.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-14 00:18:49", "grab_time": "2024-08-13 22:46:25"}
{"id": 2234414, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "9a298b63-53ac-4976-b901-407d7775e4a2", "title": "Meningococcal B Vaccine and Meningococcal Carriage in Adolescents in Australia", "text": "【0】Meningococcal B Vaccine and Meningococcal Carriage in Adolescents in Australia\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】The meningococcal group B vaccine 4CMenB is a new, recombinant protein-based vaccine that is licensed to protect against invasive group B meningococcal disease. However, its role in preventing transmission and, therefore, inducing population (herd) protection is uncertain.\n\n【3】Methods\n-------\n\n【4】We used cluster randomization to assign, according to school, students in years 10 to 12 (age, 15 to 18 years) in South Australia to receive 4CMenB vaccination either at baseline (intervention) or at 12 months (control). The primary outcome was oropharyngeal carriage of disease-causing _Neisseria meningitidis_ (group A, B, C, W, X, or Y) in students in years 10 and 11, as identified by polymerase-chain-reaction assays for _PorA_ (encoding porin protein A) and _N. meningitidis_ genogroups. Secondary outcomes included carriage prevalence and acquisition of all _N. meningitidis_ and individual disease-causing genogroups. Risk factors for carriage were assessed at baseline.\n\n【5】Results\n-------\n\n【6】A total of 237 schools participated. During April through June 2017, a total of 24,269 students in years 10 and 11 and 10,220 students in year 12 were enrolled. At 12 months, there was no difference in the prevalence of carriage of disease-causing _N. meningitidis_ between the vaccination group (2.55%; 326 of 12,746) and the control group (2.52%; 291 of 11,523) (adjusted odds ratio, 1.02; 95% confidence interval \\[CI\\], 0.80 to 1.31; P=0.85). There were no significant differences in the secondary carriage outcomes. At baseline, the risk factors for carriage of disease-causing _N. meningitidis_ included later year of schooling (adjusted odds ratio for year 12 vs. year 10, 2.75; 95% CI, 2.03 to 3.73), current upper respiratory tract infection (adjusted odds ratio, 1.35; 95% CI, 1.12 to 1.63), cigarette smoking (adjusted odds ratio, 1.91; 95% CI, 1.29 to 2.83), water-pipe smoking (adjusted odds ratio, 1.82; 95% CI, 1.30 to 2.54), attending pubs or clubs (adjusted odds ratio, 1.54; 95% CI, 1.28 to 1.86), and intimate kissing (adjusted odds ratio, 1.65; 95% CI, 1.33 to 2.05). No vaccine safety concerns were identified.\n\n【7】Conclusions\n-----------\n\n【8】Among Australian adolescents, the 4CMenB vaccine had no discernible effect on the carriage of disease-causing meningococci, including group B. \n\n【9】Introduction\n------------\n\n【10】Invasive meningococcal disease, caused by _Neisseria meningitidis_ , is an important cause of disease and death worldwide, owing to difficulties in early diagnosis, a rapid clinical progression, and a high case fatality rate.  The most important meningococcal disease–associated capsular groups are A, B, C, W, X, and Y, with group B disease predominating in many high-income countries, including Australia.  Infants and adolescents are especially affected by meningococcal disease, and many countries are considering the implementation of meningococcal B vaccine programs.  A program involving administration of the meningococcal B vaccine 4CMenB (Bexsero, GlaxoSmithKline) in infants that was introduced in the United Kingdom in 2015 has been shown to protect of infants and toddlers for at least 2 years, following a two-dose priming schedule plus a booster at 1 year. \n\n【11】Exposure to _N. meningitidis_ is common in the general population, leading to asymptomatic pharyngeal carriage, which may be transient or long term.  Age influences carriage, with an increase in carriage prevalence from 15 years of age to a peak at approximately 19 years, probably owing to increases in the numbers and closeness of social contacts and behavior.  Meningococcal disease is a rare outcome of infection, and the relationship between carriage and risk of disease is incompletely understood.  Given that carriage and transmission rates are higher among adolescents than in other age groups, a reduction in carriage prevalence among adolescents could provide indirect protection to unvaccinated persons, including infants. \n\n【12】Conjugate polysaccharide vaccines can induce mucosal respiratory responses that interfere with acquisition of carriage of several meningococcal capsular groups (e.g., group C and group W).  However, the same cannot be assumed for the protein and outer membrane vesicle antigens in meningococcal B vaccines, which, unlike capsular polysaccharides, vary antigenically among the circulating strains that express them. The South Australian meningococcal B vaccine carriage study “B Part of It” examined the effect of 4CMenB, a multiantigen vaccine designed to control group B meningococcal disease, on the carriage of disease-causing meningococci in adolescent students in order to inform the design of meningococcal vaccine programs and the assessment of cost-effectiveness globally. \n\n【13】Methods\n-------\n\n【14】Trial Design and Oversight\n--------------------------\n\n【15】 The trial was designed and overseen by an independent scientific advisory committee and was managed by the University of Adelaide. GlaxoSmithKline provided a research grant to fund the trial and provided 4CMenB vaccine free of charge. Employees of GlaxoSmithKline contributed to the trial conception, the protocol, and the interpretation of results but played no role in the data collection or analysis.\n\n【16】The protocol was approved by the Women’s and Children’s Health Network Human Research Ethics Committee.  The trial was performed in accordance with the Declaration of Helsinki and with the Good Clinical Practice guidelines of the International Council for Harmonisation of Technical Requirements for Pharmaceuticals for Human Use. The authors assume responsibility for the accuracy and completeness of the data and vouch for the fidelity of the trial to the protocol.\n\n【17】Participants\n------------\n\n【18】All 260 secondary schools in South Australia were invited to participate, with oropharyngeal swabbing and vaccination of students provided through the school immunization program, which was managed by the Immunisation Section of SA Health. Each school year level in South Australia comprises 19,000 to 20,000 students. All secondary school students in years 10, 11, and 12 (approximately 15 to 18 years of age) in 2017 were eligible to participate if they provided written informed consent (for those ≥18 years of age or older; those <18 years of age provided assent, with written informed consent obtained from a parent or guardian), were available at school to undergo at least the first oropharyngeal swabbing, and were willing to adhere to the trial procedures. Students were ineligible if they had received 4CMenB previously, had previously had an anaphylactic reaction to any component of the vaccine, or were known to be pregnant.\n\n【19】Because year 12 is the final year of schooling in Australia, the trial was designed to include the 12-month results of oropharyngeal swabbing only in students who were in years 10 and 11 in the first year of the study in order to provide data for the primary-outcome analysis. Students in year 12 contributed to the baseline analysis of risk factors for carriage because they were likely to have the highest carriage rates and also in an effort to reduce any possible effect of the vaccine on carriage due to the mixing of unimmunized year 12 students with immunized year 10 and 11 students at schools assigned to the vaccination group.\n\n【20】Outcomes\n--------\n\n【21】The primary outcome was the prevalence of carriage of any disease-causing genogroup of _N. meningitidis_ (A, B, C, W, X, or Y) at 12 months. Secondary outcomes were the prevalence of carriage at 12 months of each individual genogroup (A, B, C, W, X, and Y) and of any _N. meningitidis_ and the acquisition of carriage (i.e., negative status at baseline and positive status at 12 months) of disease-causing genogroups and of any _N. meningitidis_ . In addition to comparisons of the randomized groups, a further objective of the trial was to identify the characteristics associated with baseline carriage of disease-causing genogroups and any _N. meningitidis_ .\n\n【22】Randomization and Blinding\n--------------------------\n\n【23】Schools were randomly assigned to the intervention group (in which students received two doses of 4CMenB 2 months apart) or the control group (in which students received 4CMenB vaccination after the 12-month oropharyngeal swab). Stratification factors were school size (<60, 60 to 119, and ≥120 students per year level) and school socioeconomic status, as measured by the Index of Community Socio-Educational Advantage (ICSEA; scores range from approximately 500 to 1300, with higher scores indicating more educational advantage; the categories for this study were as follows: <970 \\[low\\], 970 to 1020 \\[medium\\], and >1020 \\[high\\]).  The randomization schedule was generated by an independent statistician using Stata software, version 14. School staff and students were unaware of their group assignments until the day of the first trial visit . Laboratory personnel and investigators were unaware of the group assignments for the duration of the trial.\n\n【24】Trial Processes\n---------------\n\n【25】Written informed consent was obtained from a parent or guardian with assent obtained from the student (for those <18 years of age), or written informed consent was obtained from the student (for those ≥18 years of age). Participants completed a questionnaire to obtain information on characteristics relevant to meningococcal carriage (e.g., smoking history, household size, and recent antibiotic use) at each swab visit at school and were provided with an A$20 iTunes gift card on questionnaire completion. All the collected data were securely stored in a database held by Adelaide Health Technology Assessment at the University of Adelaide.\n\n【26】Oropharyngeal swabs were obtained by nurses using a standardized technique of wiping a flocculated swab across the posterior oropharynx from one tonsillar area to the other. Swabs were placed immediately in a transport medium (skim milk, tryptone, glucose, and glycerine; Thermo Fisher Scientific), placed in a portable cooler, and delivered to a central laboratory (SA Pathology). On receipt of the samples, DNA was extracted with the use of Roche MagNA Pure analyzers, followed by polymerase-chain-reaction (PCR) screening for the presence of specific meningococcal DNA. An assay specific for the detection of _PorA_ (encoding porin protein A) was used because of its high sensitivity to and specificity for all pharyngeal carriage of _N. meningitidis_ .  Samples with a positive result for _PorA_ on PCR were genogrouped according to group-specific PCR results (genogroups A, B, C, W, X, and Y) and subsequently cultured for neisseria species on selective agar with incubation in 5% carbon dioxide at 35°C. Plates were examined daily up to 72 hours for the presence of _N. meningitidis_ . All isolates were identified by means of standard diagnostic laboratory methods, including oxidase reaction, matrix-assisted laser desorption–ionization with time-of-flight mass spectrometry, and a further genogrouping PCR assay.  Samples and isolates were classified as not able to be grouped if the capsule biosynthesis genes for these genogroups were not detected.\n\n【27】Statistical Analysis\n--------------------\n\n【28】Assuming a carriage prevalence of 8% in the unvaccinated cohort,  we calculated that a sample of 12,160 participants in each group would provide the trial with 90% power to detect a 20% relative lower risk of carriage (6.4% vs. 8%) among vaccinated participants (at a two-tailed alpha of 0.05). If enrollment or trial completion were lower than expected, the trial would still have 80% power, provided that swab results at 12 months were obtained for at least 8970 participants per group. These calculations incorporated a design effect of 2.19, on the basis of an average of 120 students per school and an intraclass correlation coefficient estimate of 0.01. \n\n【29】Analyses were undertaken according to a prespecified statistical analysis plan. Data were analyzed according to the randomized group of the student’s school (intention-to-treat principle). A sensitivity per-protocol analysis of the primary outcome was also conducted; this analysis included students in the vaccination group who received two doses of 4CMenB and students in the control group who did not receive 4CMenB before the 12-month follow-up.\n\n【30】The primary outcome of carriage of disease-causing _N. meningitidis_ genogroups detected by PCR at 12 months was compared between groups with the use of logistic regression, with generalized estimating equations used to account for clustering at the school level. The difference in carriage between groups was expressed as an odds ratio with a 95% confidence interval. Adjustment was made for the student’s baseline carriage and randomization strata (school size and ICSEA category). Secondary carriage outcomes were also compared between groups with the use of logistic generalized estimating equations. Missing data on the carriage outcomes were addressed with the use of multiple imputation, with imputation performed separately for the two randomized groups with the use of chained equations.  In planned subgroup analyses of the primary and secondary outcomes, the effect of the 4CMenB vaccine was examined separately in metropolitan and rural schools and in students in year 10 and year 11; on the basis of the number of interaction tests, one significant test (P<0.05) would be expected by chance alone. No adjustment was made for multiple hypothesis testing, so P values are provided only for the primary outcome and for interaction tests in subgroup analyses. All the analyses were performed with the use of SAS software, version 9.4, and Stata software, version 15.\n\n【31】Results\n-------\n\n【32】Characteristics of the Participants\n-----------------------------------\n\n【33】Figure 1. Consent, Randomization, and Follow-up of the Participants.\n\n【34】Written informed consent was obtained from a parent or guardian with assent obtained from the student (for those <18 years of age), or written informed consent was obtained from the student (for those ≥18 years of age).\n\n【35】A total of 34,489 students in year 10, 11, or 12 were enrolled between April 1 and June 30, 2017, from 237 participating schools. A total of 24,269 students in years 10 and 11 (12,746 students in the vaccination group and 11,523 in the control group) contributed data for the primary-outcome analysis . A total of 10,220 students in year 12 contributed to the analysis of risk factors for carriage. Primary-outcome data were available for 21,126 students (87.0%) after the withdrawal of 43 students and loss to follow-up of 3100 students .\n\n【36】Table 1. Baseline Characteristics of the Students in Years 10 and 11, According to Trial Group.\n\n【37】The characteristics of the participants at baseline were similar in the two groups . In the vaccination group, 99.9% of the students received the first dose of 4CMenB, and 97.7% received the second dose.\n\n【38】Primary Outcome\n---------------\n\n【39】Table 2. Analysis of Primary and Secondary Outcomes for _N. meningitidis_ Carriage and Acquisition at 12 Months with the Use of Multiple Imputation.\n\n【40】There was no significant difference in carriage prevalence of disease-causing _N. meningitidis_ between the vaccination group (326 of 12,746 students \\[2.55%\\]) and the control group (291 of 11,523 students \\[2.52%\\]) in the intention-to-treat analysis at 12 months (difference, 0.03 percentage points; adjusted odds ratio, 1.02; 95% confidence interval \\[CI\\], 0.80 to 1.31; P=0.85) . The adjusted intraclass correlation coefficient for the primary outcome was 0.005. There was little evidence of an effect of treatment when the analysis was restricted to complete cases, under a per-protocol or post hoc Bayesian analysis, or in sensitivity analyses that used the missing-data mechanism .\n\n【41】Secondary Outcomes\n------------------\n\n【42】There were no significant between-group differences in any of the prespecified secondary outcomes regarding carriage . In a post hoc analysis, the risk of nongroupable _N. meningitidis_ was 29% lower in the vaccination group than in the control group (1.65% vs. 2.23%; adjusted odds ratio, 0.71; 95% CI, 0.54 to 0.91). Unimputed results were similar for all outcomes .\n\n【43】Risk Factors for Carriage\n-------------------------\n\n【44】Table 3. Risk Factors for Carriage of Disease-Causing Genogroup at Baseline in Students in Year 10, 11, or 12.\n\n【45】The risk factors for carriage of disease-causing _N. meningitidis_ for all students enrolled in year 10, 11, or 12 included the following: later year of schooling (adjusted odds ratio for year 12 vs. year 10, 2.75; 95% CI, 2.03 to 3.73), current upper respiratory tract infection (adjusted odds ratio, 1.35; 95% CI, 1.12 to 1.63), cigarette smoking in the past week (adjusted odds ratio, 1.91; 95% CI, 1.29 to 2.83), water-pipe smoking in the past week (adjusted odds ratio, 1.82; 95% CI, 1.30 to 2.54), attending pubs or clubs in the past week (adjusted odds ratio, 1.54; 95% CI, 1.28 to 1.86), participation in intimate kissing in the past week (adjusted odds ratio, 1.65; 95% CI, 1.33 to 2.05), and being white (adjusted odds ratio for Asian vs. white race, 0.50; 95% CI, 0.31 to 0.80) . The risk factors associated with carriage prevalence of any meningococci were similar, with the additional results that students of Aboriginal or Torres Strait Islander ethnicity had almost double the carriage prevalence as that among white students (6.72% vs. 3.66%; adjusted odds ratio, 1.49; 95% CI, 1.07 to 2.06) and boarding students were at higher risk than day students (adjusted odds ratio, 2.10; 95% CI, 1.16 to 3.80) .\n\n【46】Overall vaccine coverage (percentage of students who received the vaccine) among South Australian students was 62% (students in years 10 and 11 enrolled in the trial, divided by the total number of students in years 10 and 11). Vaccine coverage was at least 50% in 82% of the participating schools (89 of 109 schools) that had been randomly assigned to the vaccination group. There was no association between vaccine coverage and outcomes in schools in the vaccination group regarding carriage of disease-causing _N. meningitidis_ (odds ratio per 1-percentage-point increase in coverage, 1.01; 95% CI, 0.995 to 1.02) or any _N. meningitidis_ (odds ratio, 1.00; 95% CI, 0.99 to 1.01).\n\n【47】Subgroup Analyses According to Randomization Strata\n---------------------------------------------------\n\n【48】Primary and secondary outcomes stratified according to school location (metropolitan or rural) and school year level (year 10 or 11) provided evidence of effect modification according to school location for the carriage of disease-causing meningococcal disease genogroups and all genogroups and for the acquisition of disease-causing genogroups . Post hoc tests revealed increased carriage (adjusted odds ratio, 1.49; 95% CI, 1.03 to 2.15) and acquisition (adjusted odds ratio, 1.50; 95% CI, 1.03 to 2.18) of disease-causing genogroups in rural schools and decreased overall carriage in metropolitan schools (adjusted odds ratio, 0.73; 95% CI, 0.58 to 0.93) in the vaccination group. However, these results should be interpreted with caution given the large numbers of interaction tests. There was no evidence of effect modification according to year level.\n\n【49】Disease Effect and Safety\n-------------------------\n\n【50】There were no cases of meningococcal B disease in this trial population during the trial period (2017–2018) and no cases to date (as of December 27, 2019), as compared with 12 cases among students 15 to 18 years of age from the period 2015–2016.  After the administration of 58,639 doses, 193 adverse events were reported in 187 students (187 of 58,639 \\[0.32%\\]), of which 9 were serious adverse events . The most common adverse events reported were injection-site reactions (126 events), headache (99), and nausea (61).\n\n【51】Discussion\n----------\n\n【52】This cluster-randomized, controlled trial provided evidence that 4CMenB had no effect on the carriage of disease-causing meningococci (including group B) in adolescents. These results have informed policies regarding control of meningococcal disease, assessments of cost-effectiveness of 4CMenB immunization programs globally, and the design of the next generation of meningococcal B vaccines. Our findings differ from those regarding group A and C polysaccharide conjugate vaccines, in which an effect on carriage rates has been seen in observational studies assessing the effect of population-based vaccination programs.  Conjugate vaccine programs that achieve high coverage in adolescents have provided evidence of indirect protection to other age groups, thus reducing the need for vaccination of infants. \n\n【53】The lack of effect of 4CMenB on carriage of disease-causing meningococci emphasizes the need for direct protection of those at highest risk for meningococcal disease. Because the incidence of meningococcal disease peaks among preschool children and adolescents, it is important to consider vaccination for direct protection in these age groups. In South Australia, where 4CMenB is estimated to cover 90% of disease-causing isolates,  a program was implemented as of October 1, 2018, to vaccinate those at highest risk, including infants, toddlers (1 to 3 years of age), and adolescents and young adults (15 to 20 years of age).  It will be important to monitor the effect of the vaccine in this population-based program.\n\n【54】Our findings are consistent with those of a previous study, in which a small reduction in carriage of strains expressing groups C, W, or Y was attributed mostly to a reduction in group Y carriage with no effect on group B carriage.  The observed reduction in non–disease-causing meningococci in our trial may reflect an effect on unencapsulated meningococci, in which vaccine-type outer membrane proteins are potentially more exposed. Whole-genome sequencing and Bexsero Antigen Sequence Typing analysis of all isolates may assist in determining predictive coverage.\n\n【55】Smaller observational studies assessing the effect of 4CMenB and MenB-FHbp (Trumenba, Pfizer) in university outbreaks in the United States have also shown no significant effect on carriage.  Combined with our findings, these observations have implications for outbreak-control protocols. Although 4CMenB may reduce the risk of late cases in such outbreaks, it is unlikely to reduce transmission; therefore, antibiotics remain necessary to offer rapid elimination of carriage. Preexposure vaccination for those entering settings where the risk of outbreaks is high is likely to be a more effective use of the vaccine.\n\n【56】Important aspects of the trial design include randomization at the school level; a real-world setting, because students were enrolled at an age at which meningococcal vaccine programs are introduced to prevent invasive disease; a short enrollment period; the high retention of students in the trial; and high adherence to the trial protocol.\n\n【57】A limitation of the trial was the lower-than-anticipated prevalence of carriage of disease-causing _N. meningitidis_ among adolescents at 12 months. Despite this, the 95% confidence interval for the primary outcome in the intention-to-treat analysis did not contain odds ratios less than 0.80, the value approximating our smallest clinically important difference. Similarly, per-protocol and post hoc Bayesian sensitivity analyses of the primary outcome provided little support for a clinically important effect of 4CMenB on carriage , although the lower boundary of the 95% confidence interval in the per-protocol analysis was marginally less than 0.80. These results, along with the negative findings on secondary outcomes regarding carriage, suggest that 4CMenB was ineffective in reducing carriage of disease-causing _N. meningitidis_ .\n\n【58】The trial was also limited by the fact that we used a single outcome measure of carriage after vaccination at 12 months, but this was chosen to reduce seasonal variation and to ensure that any reduction in carriage was sustained at least until 1 year after vaccination. Underestimation of the effect of vaccine on disease-causing or all meningococci due to moderate coverage rates is possible, and unvaccinated students may serve as a source of ongoing transmission. However, vaccine coverage of approximately 65% is realistic for vaccine programs involving students in high schools, and there was no association between school-level coverage and carriage.\n\n【59】In conclusion, our results did not show an effect of 4CMenB on carriage of disease-causing meningococci in a program involving adolescents that had moderate-to-high vaccine coverage.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:36:25", "endTime": "2024/08/14 14:36:59", "cost": 34.37}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 22:36:59", "grab_time": "2024-08-13 22:36:25"}
{"id": 2234413, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "06a83a54-3c4d-4a36-81a5-70069f490235", "title": "Human Papillomavirus Vaccination", "text": "【0】Human Papillomavirus Vaccination\nHPV is a common sexually transmitted virus; oncogenic types lead to HPV-attributable cancers. Vaccines are highly effective for preventing HPV vaccine–type infection, precancers, and other attributable conditions.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:53:00", "endTime": "2024/08/14 14:53:07", "cost": 7.731}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 22:53:08", "grab_time": "2024-08-13 22:53:00"}
{"id": 2234412, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "d4a2b168-c5bb-4aee-be23-79cedea2e340", "title": "Mechanisms of Disease: Aldosterone in Congestive Heart Failure", "text": "【0】Mechanisms of Disease: Aldosterone in Congestive Heart Failure\nThe potent mineralocorticoid aldosterone has a multifaceted role in the pathogenesis of congestive heart failure. In addition to its contribution to salt and water retention, it also promotes organ fibrosis. Although angiotensin-converting–enzyme inhibitors have important therapeutic benefit in heart failure, they do not eliminate the effects of aldosterone. Thus, recent studies have underscored the value of aldosterone-receptor antagonists, such as spironolactone, in the treatment of chronic heart failure. This review article gives an in-depth update on the mechanisms of action of aldosterone and their implications for therapy.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:24:06", "endTime": "2024/08/14 15:24:13", "cost": 7.309}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 23:24:13", "grab_time": "2024-08-13 23:24:05"}
{"id": 2234411, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "3ee4af88-58a3-48d8-b540-9cf293c5eb54", "title": "Community-Acquired Pneumonia", "text": "【0】Community-Acquired Pneumonia\nTreatment of community-acquired pneumonia typically involves either a respiratory fluoroquinolone or a combination of cephalosporin and a macrolide. Initial broad-spectrum antibiotic therapy should be targeted to patients selected according to risk factors or existing disease.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:27:06", "endTime": "2024/08/14 15:27:13", "cost": 6.837}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 23:27:13", "grab_time": "2024-08-13 23:27:06"}
{"id": 2234410, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "d2f06c06-020d-476a-a122-e161b8d27873", "title": "The FDA and Tobacco Regulation", "text": "【0】The FDA and Tobacco Regulation\n*   Related Articles\n\n【1】To the Editor:\n--------------\n\n【2】The American Heart Association enthusiastically supports the editorial by Curfman et al. (Sept. 4 issue)  on a bill that would grant authority to the Food and Drug Administration to regulate tobacco products. We believe that this legislation has several strengths; it would require full disclosure of the ingredients in tobacco products, reduce the burden of tobacco-related illnesses, and especially limit underage smoking. Each day, about 4000 people 12 to 17 years of age will try a cigarette for the first time, and an estimated 1140 persons in this age group become daily smokers.  According to a U.S. Surgeon General's report, about 80% of people who use tobacco begin to do so before 18 years of age.  A major curtailment of underage tobacco use may be the greatest potential public health benefit of this legislation. As the incoming president of the American Heart Association, I applaud the position of the _Journal_ editors and join with them in expressing unequivocal support for this legislation.\n\n【3】Clyde Yancy, M.D.  \nAmerican Heart Association, Dallas, TX 75231\n\n【4】3 References\n\n【5】1.  1\\. Curfman GD, Morrissey S, Drazen JM. The FDA and tobacco regulation. N Engl J Med 2008 ;359: 1056 \\- 1057\n\n【6】    *   Free Full Text\n    *   Web of Science . opens in new tab\n    *   Medline . opens in new tab\n    Google Scholar . opens in new tab\n2.  2\\. Office of Applied Studies. Results from the 2005 National Survey on Drug Use and Health: national findings. NSDUH series H-30. Rockville, MD: Substance Abuse and Mental Health Services Administration, 2006. (DHHS publication no. SMA 06-4194.)\n\n【7】    Google Scholar . opens in new tab\n3.  3\\. National Center for Chronic Disease Prevention and Health Promotion, Office on Smoking and Health. Preventing tobacco use among young people. Washington, DC: Government Printing Office, 1994.\n\n【8】    Google Scholar . opens in new tab", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "【3】Clyde Yancy, M.D.\n\nAmerican Heart Association, Dallas, TX 75231\n\n【4】3 References\n\n【5】1.  1. Curfman GD, Morrissey S, Drazen JM. The FDA and tobacco regulation. N Engl J Med 2008 ;359: 1056 - 1057\n\n【6】    *   Free Full Text\n\nWeb of Science . opens in new tab\nMedline . opens in new tab\nGoogle Scholar . opens in new tab\n2. Office of Applied Studies. Results from the 2005 National Survey on Drug Use and Health: national findings. NSDUH series H-30. Rockville, MD: Substance Abuse and Mental Health Services Administration, 2006. (DHHS publication no. SMA 06-4194.)\n【7】    Google Scholar . opens in new tab\n\n3.  3. National Center for Chronic Disease Prevention and Health Promotion, Office on Smoking and Health. Preventing tobacco use among young people. Washington, DC: Government Printing Office, 1994.\n\n【8】    Google Scholar . opens in new tab", "content": "【0】The FDA and Tobacco Regulation\n*   Related Articles\n\n【1】To the Editor:\n--------------\n\n【2】The American Heart Association enthusiastically supports the editorial by Curfman et al. (Sept. 4 issue)  on a bill that would grant authority to the Food and Drug Administration to regulate tobacco products. We believe that this legislation has several strengths; it would require full disclosure of the ingredients in tobacco products, reduce the burden of tobacco-related illnesses, and especially limit underage smoking. Each day, about 4000 people 12 to 17 years of age will try a cigarette for the first time, and an estimated 1140 persons in this age group become daily smokers.  According to a U.S. Surgeon General's report, about 80% of people who use tobacco begin to do so before 18 years of age.  A major curtailment of underage tobacco use may be the greatest potential public health benefit of this legislation. As the incoming president of the American Heart Association, I applaud the position of the _Journal_ editors and join with them in expressing unequivocal support for this legislation.\n\n【3】Clyde Yancy, M.D.  \nAmerican Heart Association, Dallas, TX 75231\n\n【4】3 References\n\n【5】1.  1\\. Curfman GD, Morrissey S, Drazen JM. The FDA and tobacco regulation. N Engl J Med 2008 ;359: 1056 \\- 1057\n\n【6】    *   Free Full Text\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n2.  2\\. Office of Applied Studies. Results from the 2005 National Survey on Drug Use and Health: national findings. NSDUH series H-30. Rockville, MD: Substance Abuse and Mental Health Services Administration, 2006. (DHHS publication no. SMA 06-4194.)\n\n【7】    Google Scholar . opens in new tab\n3.  3\\. National Center for Chronic Disease Prevention and Health Promotion, Office on Smoking and Health. Preventing tobacco use among young people. Washington, DC: Government Printing Office, 1994.\n\n【8】    Google Scholar . opens in new tab", "index": 1104, "show": true, "start": 1104, "end": 1954, "province": ["文本干净度", "无关文本"], "isEdit": false}, {"text": "Related Articles", "content": "【0】The FDA and Tobacco Regulation\n*   Related Articles\n\n【1】To the Editor:\n--------------\n\n【2】The American Heart Association enthusiastically supports the editorial by Curfman et al. (Sept. 4 issue)  on a bill that would grant authority to the Food and Drug Administration to regulate tobacco products. We believe that this legislation has several strengths; it would require full disclosure of the ingredients in tobacco products, reduce the burden of tobacco-related illnesses, and especially limit underage smoking. Each day, about 4000 people 12 to 17 years of age will try a cigarette for the first time, and an estimated 1140 persons in this age group become daily smokers.  According to a U.S. Surgeon General's report, about 80% of people who use tobacco begin to do so before 18 years of age.  A major curtailment of underage tobacco use may be the greatest potential public health benefit of this legislation. As the incoming president of the American Heart Association, I applaud the position of the _Journal_ editors and join with them in expressing unequivocal support for this legislation.\n\n<mark>【3】Clyde Yancy, M.D.\n\nAmerican Heart Association, Dallas, TX 75231\n\n【4】3 References\n\n【5】1.  1. Curfman GD, Morrissey S, Drazen JM. The FDA and tobacco regulation. N Engl J Med 2008 ;359: 1056 - 1057\n\n【6】    *   Free Full Text\n\nWeb of Science . opens in new tab\nMedline . opens in new tab\nGoogle Scholar . opens in new tab\n2. Office of Applied Studies. Results from the 2005 National Survey on Drug Use and Health: national findings. NSDUH series H-30. Rockville, MD: Substance Abuse and Mental Health Services Administration, 2006. (DHHS publication no. SMA 06-4194.)\n【7】    Google Scholar . opens in new tab\n\n3.  3. National Center for Chronic Disease Prevention and Health Promotion, Office on Smoking and Health. Preventing tobacco use among young people. Washington, DC: Government Printing Office, 1994.\n\n【8】    Google Scholar . opens in new tab</mark>opens in new tab", "index": 38, "show": true, "start": 38, "end": 54, "province": ["文本干净度", "无关文本"], "isEdit": false}], "startTime": "2024/08/14 10:56:11", "endTime": "2024/08/14 10:59:29", "cost": 197.231}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 18:59:29", "grab_time": "2024-08-13 18:56:11"}
{"id": 2234409, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "50d618db-6604-49c6-a050-e4142236f167", "title": "Humoral Immune Response to SARS-CoV-2 in Iceland", "text": "【0】Humoral Immune Response to SARS-CoV-2 in Iceland\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Little is known about the nature and durability of the humoral immune response to infection with severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2).\n\n【3】Methods\n-------\n\n【4】We measured antibodies in serum samples from 30,576 persons in Iceland, using six assays (including two pan-immunoglobulin \\[pan-Ig\\] assays), and we determined that the appropriate measure of seropositivity was a positive result with both pan-Ig assays. We tested 2102 samples collected from 1237 persons up to 4 months after diagnosis by a quantitative polymerase-chain-reaction (qPCR) assay. We measured antibodies in 4222 quarantined persons who had been exposed to SARS-CoV-2 and in 23,452 persons not known to have been exposed.\n\n【5】Results\n-------\n\n【6】Of the 1797 persons who had recovered from SARS-CoV-2 infection, 1107 of the 1215 who were tested (91.1%) were seropositive; antiviral antibody titers assayed by two pan-Ig assays increased during 2 months after diagnosis by qPCR and remained on a plateau for the remainder of the study. Of quarantined persons, 2.3% were seropositive; of those with unknown exposure, 0.3% were positive. We estimate that 0.9% of Icelanders were infected with SARS-CoV-2 and that the infection was fatal in 0.3%. We also estimate that 56% of all SARS-CoV-2 infections in Iceland had been diagnosed with qPCR, 14% had occurred in quarantined persons who had not been tested with qPCR (or who had not received a positive result, if tested), and 30% had occurred in persons outside quarantine and not tested with qPCR.\n\n【7】Conclusions\n-----------\n\n【8】Our results indicate that antiviral antibodies against SARS-CoV-2 did not decline within 4 months after diagnosis. We estimate that the risk of death from infection was 0.3% and that 44% of persons infected with SARS-CoV-2 in Iceland were not diagnosed by qPCR.\n\n【9】Introduction\n------------\n\n【10】Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), causing coronavirus disease 2019 (Covid-19), emerged in December 2019.  Seroconversion of most patients with Covid-19 occurs between 7 and 14 days after diagnosis.  A study of 61,000 persons in Spain showed that 5% of the population had formed antibodies against the spike and nucleoproteins and that approximately one third of infected persons were asymptomatic.  It was suggested that a substantial fraction of those infected become antibody-negative early in the convalescence period.  Several studies have reported a higher prevalence  and levels  of SARS-CoV-2 antibodies in severely ill patients than in those with no or mild symptoms.\n\n【11】The infection fatality risk of SARS-CoV-2 is difficult to estimate because the total number of diagnosed and undiagnosed cases is needed as the denominator. The infection fatality risk was reported as 0.4% in a small German town after carnival festivities,  0.6% on the Diamond Princess cruise ship,  and 0.66% in China. \n\n【12】Well-validated serologic assays for SARS-CoV-2 are urgently needed. Several small comparative studies of commercial SARS-CoV-2 antibody assays have been published.  A highly specific assay is required for screening populations with a low seroprevalence, such as that in Iceland.\n\n【13】The first case of SARS-CoV-2 infection in Iceland was confirmed on February 28, 2020, and by April 30 the epidemic had to a large extent receded.  During this period, 1797 cases were diagnosed by quantitative polymerase-chain-reaction (qPCR), in contrast with only 13 new cases diagnosed between April 30 and June 15. Testing by qPCR has been extensive in Iceland: 15% of the population (54,436 persons) had been tested with qPCR by June 15.\n\n【14】Figure 1. Schematic Overview of the Eight Sample Groups Used in the Study.\n\n【15】The eight sample groups are shown in the upper boxes, and the arrows within the upper boxes indicate the main utility of each sample collection. The two lower boxes describe the six assays that were used; the arrows outside the boxes show which assays were used for the two collection types (not positive by quantitative polymerase-chain-reaction assay \\[non–qPCR-positive\\] and qPCR-positive). For the Health Care group, samples were obtained during a visit to the health care system. For the Quarantine group, all samples were obtained on completion of quarantine. The two groups of samples from persons who tested qPCR-positive were obtained at different times during the course of the disease: the Hospitalized group consists of samples obtained during hospitalization, and the Recovered group consists of samples obtained after recovery. ECLIA denotes electrochemiluminescence immunoassay, and ELISA enzyme-linked immunosorbent assay.\n\n【16】The aim of this study was to assess SARS-CoV-2 seroprevalence in the population of Iceland and to assess longitudinal changes in antibody levels within the first 4 months after SARS-CoV-2 infection and how the changes correlate with sex, age, existing phenotypes, and Covid-19 symptoms. We screened for SARS-Cov-2 reactive serum antibodies, using six different assays, in two groups of qPCR-positive persons and six groups of persons who had not been tested with qPCR or who had been tested and received negative results .\n\n【17】Methods\n-------\n\n【18】Ethical Considerations\n----------------------\n\n【19】The study was approved by the National Bioethics Committee of Iceland. The Health Care sample collection was performed on behalf of Icelandic health authorities in agreement with the Act no. 19/1997 on Health Security and Communicable Diseases . opens in new tab . Participants who were part of the other sample collections provided written informed consent.\n\n【20】Antibody Measurements\n---------------------\n\n【21】We measured SARS-CoV-2–specific antibodies in up to 30,576 persons with six established assays, targeting pan-immunoglobulin (pan-Ig: IgM, IgG, and IgA) antibodies against the nucleoprotein (N) (Roche); pan-Ig antibodies against the receptor binding domain (RBD) in the S1 subunit of the spike protein (pan-Ig anti–S1-RBD) (Wantai); IgM and IgG antibodies against N (IgM anti-N and IgG anti-N) (EDI/Eagle); and IgG and IgA against the S1 subunit of the spike protein (IgG anti-S1 and IgA anti-S1) (Euroimmun). Thresholds for positivity were supplied by the assay manufacturers. We used the two pan-Ig antibody assays to evaluate seroprevalence, requiring positive results for both assays for a test result to be considered positive . To quantify antibody levels among qPCR-positive persons, we assayed antibodies against SARS-CoV-2 using IgG anti-N, IgM anti-N, IgG anti-S1, and IgA anti-S1.\n\n【22】Sample Collection\n-----------------\n\n【23】We measured antibodies in two groups of qPCR-positive Icelanders and in six groups who had not been qPCR-tested or who had been tested and had received a negative result . We collected samples from a group of hospitalized qPCR-positive persons and invited all qPCR-positive persons who had recovered from infection to donate samples, both shortly after recovery and again approximately 3 months after recovery (a total of 2102 samples from 1237 persons). We used two groups of samples collected before the pandemic (in 2017 and in early 2020) to evaluate assay specificity and to determine when the pandemic reached Iceland. We collected samples from quarantined persons who had not tested qPCR-positive to evaluate infection during quarantine and the effect of exposure type on the probability of infection. We used three groups of samples collected from persons who had neither tested qPCR-positive nor been quarantined to evaluate seroprevalence outside quarantine and the spread of the virus in Iceland (the Health Care, Reykjavik, and Vestmannaeyjar sample groups, totaling 23,452 persons).\n\n【24】Estimation of Infection Rate\n----------------------------\n\n【25】The largest of these six groups, the Health Care group, was enriched for older people. To estimate seroprevalence, we weighted this sample by region, sex, and age in the population . To estimate the number of infected Icelanders, we added together the number of qPCR-positive persons, the number of quarantined persons times the estimated seroprevalence in this group, and the number of persons outside quarantine times the estimated seroprevalence outside quarantine. We estimated the percentage of Icelanders infected by dividing the number of infected persons by the number of Icelanders. We estimated the infection fatality risk by dividing the number of deaths from Covid-19 by the number of infected persons.\n\n【26】Antibody Levels, Age, Sex, and Clinical Characteristics\n-------------------------------------------------------\n\n【27】We tested for associations of age, sex, preexisting conditions (27 phenotypes), and clinical outcome (35 characteristics) with antibody titers (for each of the six assays) in the most recent samples obtained from persons in the Recovered group. We recoded categorical clinical characteristics with their ordinal number in the analysis.\n\n【28】Statistical Analysis\n--------------------\n\n【29】We used a likelihood ratio method . opens in new tab to calculate confidence intervals of fractions with the Clopper–Pearson exact method when the estimated fraction was 0 or 1. To test for association between each clinical characteristic and antibody levels, we performed multiple regression analyses with the phenotype as a covariate and quantile normalized antibody levels as a response, adjusting for age, age squared, sex, and time since qPCR diagnosis, excluding the age and sex covariates when testing for association with age and sex, respectively. We quantile-normalized the antibody levels by ranking the levels and transforming them, using the inverse normal transform of the rank divided by one plus the number of observations. Effects estimates were reported in terms of standard deviations of antibody levels. We derived P values and confidence intervals from standard errors estimated by the multiple regression. We used Bonferroni correction to determine significance, with a threshold for significance of P<\\[0.05÷6(2+27+35)\\]=0.00013. For effects of the exposure type on the probability of infection among quarantined persons, we used logistic regression to estimate the confidence intervals of odds ratios. We did not adjust confidence intervals for multiple testing.\n\n【30】Results\n-------\n\n【31】Specificity of SARS-CoV-2 Antibody Assays\n-----------------------------------------\n\n【32】Both assays measuring pan-Ig antibodies had low numbers of false positives among samples collected in 2017: there were 0 and 1 false positives for the two assays among 472 samples, results that compared favorably with those obtained with the single IgM anti-N and IgG anti-N assays . Because of the low prevalence of SARS-CoV-2 infection in Iceland, we required positive results from both pan-Ig antibody assays for a sample to be considered seropositive . None of the samples collected in early 2020 group were seropositive, which indicates that the virus had not spread widely in Iceland before February 2020.\n\n【33】SARS-CoV-2 Antibodies among qPCR-Positive Persons\n-------------------------------------------------\n\n【34】Figure 2. Antibody Prevalence and Titers among qPCR-Positive Cases as a Function of Time since Diagnosis by qPCR.\n\n【35】Shown are the percentages of samples positive for both pan-Ig antibody assays and the antibody titers. Red denotes the count or percentage of samples among persons during their hospitalization (249 samples from 48 persons), and blue denotes the count or percentage of samples among persons after they were declared recovered (1853 samples from 1215 persons). Vertical bars denote 95% confidence intervals. The dashed lines indicated the thresholds for a test to be declared positive. OD denotes optical density, and RBD receptor binding domain.Table 1.  Table 1. Prevalence of SARS-CoV-2 Antibodies by Sample Collection as Measured by Two Pan-Ig Antibody Assays.\n\n【36】Twenty-five days after diagnosis by qPCR, more than 90% of samples from recovered persons tested positive with both pan-Ig antibody assays, and the percentage of persons testing positive remained stable thereafter . Hospitalized persons seroconverted more frequently and quickly after qPCR diagnosis than did nonhospitalized persons . Of 1215 persons who had recovered (on the basis of results for the most recently obtained sample from persons for whom we had multiple samples), 1107 were seropositive (91.1%; 95% confidence interval \\[CI\\], 89.4 to 92.6) . Since some diagnoses may have been made on the basis of false positive qPCR results, we determined that 91.1% represents the lower bound of sensitivity of the combined pan-Ig tests for the detection of SARS-CoV-2 antibodies among recovered persons.\n\n【37】Table 2. Results of Repeated Pan-Ig Antibody Tests among Recovered qPCR-Diagnosed Persons.\n\n【38】Among the 487 recovered persons with two or more samples, 19 (4%) had different pan-Ig antibody test results at different time points . It is notable that of the 22 persons with an early sample that tested negative for both pan-Ig antibodies, 19 remained negative at the most recent test date (again, for both antibodies). One person tested positive for both pan-Ig antibodies in the first test and negative for both in the most recent test.\n\n【39】The longitudinal changes in antibody levels among recovered persons were consistent with the cross-sectional results ; antibody levels were higher in the last sample than in the first sample when the antibodies were measured with the two pan-Ig assays, slightly lower than in the first sample when measured with IgG anti-N and IgG anti-S1 assays, and substantially lower than in the first sample when measured with IgM anti-N and IgA anti-S1 assays.\n\n【40】IgG anti-N, IgM anti-N, IgG anti-S1, and IgA anti-S1 antibody levels were correlated among the qPCR-positive persons . Antibody levels measured with both pan-Ig antibody assays increased over the first 2 months after qPCR diagnosis and remained at a plateau over the next 2 months of the study. IgM anti-N antibody levels increased rapidly soon after diagnosis and then fell rapidly and were generally not detected after 2 months. IgA anti-S1 antibodies decreased 1 month after diagnosis and remained detectable thereafter. IgG anti-N and anti-S1 antibody levels increased during the first 6 weeks after diagnosis and then decreased slightly.\n\n【41】SARS-CoV-2 Infection in Quarantine\n----------------------------------\n\n【42】Table 3. SARS-CoV-2 Infection among Quarantined Persons According to Exposure Type and Presence of Symptoms.\n\n【43】Of the 1797 qPCR-positive Icelanders, 1088 (61%) were in quarantine when SARS-CoV-2 infection was diagnosed by qPCR. We tested for antibodies among 4222 quarantined persons who had not tested qPCR-positive (they had received a negative result by qPCR or had simply not been tested). Of those 4222 quarantined persons, 97 (2.3%; 95% CI, 1.9 to 2.8) were seropositive . Those with household exposure were 5.2 (95% CI, 3.3 to 8.0) times more likely to be seropositive than those with other types of exposure ; similarly, a positive result by qPCR for those with household exposure was 5.2 (95% CI, 4.5 to 6.1) times more likely than for those with other types of exposure. When these two sets of results (qPCR-positive and seropositive) were combined, we calculated that 26.6% of quarantined persons with household exposure and 5.0% of quarantined persons without household exposure were infected. Those who had symptoms during quarantine were 3.2 (95% CI, 1.7 to 6.2) times more likely to be seropositive and 18.2 times (95% CI, 14.8 to 22.4) more likely to test positive with qPCR than those without symptoms.\n\n【44】We also tested persons in two regions of Iceland affected by cluster outbreaks. In a SARS-CoV-2 cluster in Vestfirdir, 1.4% of residents were qPCR-positive and 10% of residents were quarantined. We found that none of the 326 persons outside quarantine who had not been tested by qPCR (or who tested negative) were seropositive. In a cluster in Vestmannaeyjar, 2.3% of residents were qPCR-positive and 13% of residents were quarantined. Of the 447 quarantined persons who had not received a qPCR-positive result, 4 were seropositive (0.9%; 95% CI, 0.3 to 2.1). Of the 663 outside quarantine in Vestmannaeyjar, 3 were seropositive (0.5%; 95% CI, 0.1 to 0.2%).\n\n【45】SARS-CoV-2 Seroprevalence in Iceland\n------------------------------------\n\n【46】None of the serum samples collected from 470 healthy Icelanders between February 18 and March 9, 2020, tested positive for both pan-Ig antibodies, although four were positive for the pan-Ig anti-N assay (0.9%), a finding that suggests that the virus had not spread widely in Iceland before March 9.\n\n【47】Of the 18,609 persons tested for SARS-CoV-2 antibodies through contact with the Icelandic health care system for reasons other than Covid-19, 39 were positive for both pan-Ig antibody assays (estimated seroprevalence by weighting the sample on the basis of residence, sex, and 10-year age category, 0.3%; 95% CI, 0.2 to 0.4). There were regional differences in the percentages of qPCR-positive persons across Iceland that were roughly proportional to the percentage of people quarantined . However, after exclusion of the qPCR-positive and quarantined persons, the percentage of persons who tested positive for SARS-CoV-2 antibodies did not correlate with the percentage of those who tested positive by qPCR. The estimated seroprevalence in the random sample collection from Reykjavik (0.4%; 95% CI, 0.3 to 0.6) was similar to that in the Health Care group (0.3%; 95% CI, 0.2 to 0.4) .\n\n【48】We calculate that 0.5% of the residents of Iceland have tested positive with qPCR. The 2.3% with SARS-CoV-2 seroconversion among persons in quarantine extrapolates to 0.1% of Icelandic residents. On the basis of this finding and the seroprevalence from the Health Care group, we estimate that 0.9% (95% CI, 0.8 to 0.9) of the population of Iceland has been infected by SARS-CoV-2. Approximately 56% of all SARS-CoV-2 infections were therefore diagnosed by qPCR, 14% occurred in quarantine without having been diagnosed with qPCR, and the remaining 30% of infections occurred outside quarantine and were not detected by qPCR.\n\n【49】Deaths from Covid-19 in Iceland\n-------------------------------\n\n【50】In Iceland, 10 deaths have been attributed to Covid-19, which corresponds to 3 deaths per 100,000 nationwide. Among the qPCR-positive cases, 0.6% (95% CI, 0.3 to 1.0) were fatal. Using the 0.9% prevalence of SARS-CoV-2 infection in Iceland as the denominator, however, we calculate an infection fatality risk of 0.3% (95% CI, 0.2 to 0.6). Stratified by age, the infection fatality risk was substantially lower in those 70 years old or younger (0.1%; 95% CI, 0.0 to 0.3) than in those over 70 years of age (4.4%; 95% CI, 1.9 to 8.4) .\n\n【51】Age, Sex, Clinical Characteristics, and Antibody Levels\n-------------------------------------------------------\n\n【52】Table 4. Association of Existing Conditions and Covid-19 Severity with SARS-CoV-2 Antibody Levels among Recovered Persons.\n\n【53】SARS-CoV-2 antibody levels were higher in older people and in those who were hospitalized . Pan-Ig anti–S1-RBD and IgA anti-S1 levels were lower in female persons. Of the preexisting conditions, and after adjustment for multiple testing, we found that body-mass index, smoking status, and use of antiinflammatory medication were associated with SARS-CoV-2 antibody levels. Body-mass index correlated positively with antibody levels; smokers and users of antiinflammatory medication had lower antibody levels. With respect to clinical characteristics, antibody levels were most strongly associated with hospitalization and clinical severity, followed by clinical symptoms such as fever, maximum temperature reading, cough, and loss of appetite. Severity of these individual symptoms, with the exception of loss of energy, was associated with higher antibody levels.\n\n【54】Discussion\n----------\n\n【55】We estimate that during the first wave of the SARS-CoV-2 pandemic, the incidence of infection in Iceland was 0.9% (95% CI, 0.8 to 0.9) and the infection fatality risk was 0.3% (95% CI, 0.2 to 0.6). Our estimate of the infection fatality risk is lower than but consistent with estimates described by others.  We estimate that of the infected persons, 56% had cases previously diagnosed by qPCR, 14% had been in quarantine (but either had not been qPCR-tested or had tested negative), and 30% neither were known to be qPCR-positive nor had been placed in quarantine. We therefore conclude that, despite extensive screening by qPCR, a substantial fraction of infections were not detected, which indicates that many infected persons did not have substantial symptoms.\n\n【56】The case fatality risk is straightforward to estimate but may differ across countries and over time. An accurate calculation of infection fatality risk requires an accurate estimate of the number of infections, both diagnosed and undiagnosed. In Iceland, the high percentage of infections identified through qPCR (56%) as compared with that of other countries (for example, approximately 9% in Spain  ) renders a commensurately accurate estimate of the total number of infections.\n\n【57】Each of the pan-Ig SARS-CoV-2 antibody assays that we used has high specificity (99.8%, according to the manufacturers’ literature), which raises the question of whether using a single pan-Ig assay would have sufficed. One sample obtained in 2017 was positive on only one pan-Ig antibody assay, a finding that supports the use of two separate assays to determine seroprevalence, if the infection rate is below 1%, as in Iceland.\n\n【58】By April 30, a total of 20,766 Icelanders had been placed in quarantine. Of the 1797 Icelanders who tested positive by qPCR, 1088 (61%) were in quarantine when tested. Despite substantial qPCR testing of persons in quarantine, 2.3% of persons in quarantine who did not receive qPCR-positive result (i.e., a diagnosis of infection) developed SARS-CoV-2 antibodies. Household exposure was more likely to lead to infection than other types of exposure, which suggests that people who share a household with an infected person should not have contact during quarantine and that contacts of household members should be quarantined. Seroprevalence in the two regional hot spots (Vestfirdir and Vestmannaeyjar) was absent or low outside quarantine, which indicates that most infections were detected by qPCR screening and that quarantine, social distancing, contact tracing, and limits on public gatherings were effective in limiting spread.\n\n【59】Over 90% of qPCR-positive persons tested positive with both pan-Ig SARS-CoV-2 antibody assays and remained seropositive 120 days after diagnosis, with no decrease of antibody levels as detected by the two pan-Ig assays. We observed some diminution of antibody titer with some of the single-Ig assays. Previous smaller studies reported reduction of IgG antibodies against the N protein and a peptide representing the S protein within 21 to 28 days  and against trimeric S protein within 56 days  after a positive test by qPCR. These discrepancies may be explained partly by differences in the specificity and sensitivity of the assays used as well as differences in the design and performance of the semiquantitative assays used, including the antigen targeted and the analytic sensitivity and range, as well as differences in the study populations. For example, because of widespread qPCR testing and screening, it is likely that the Icelandic qPCR-positive persons were healthy, as compared with the participants in other studies. Repeated SARS-CoV-2 exposure is unlikely to affect the persistence of antibody levels in Iceland, given the low prevalence of infection. Comparative studies using validated quantitative SARS-CoV-2 antibody assays are needed; those described in the published literature are based on small sample sizes. \n\n【60】Of the 22 recovered persons who had a negative result (using the combined pan-Ig antibody tests) for an early sample and who had another sample tested at least a month later, 19 (86%) received a second negative result. Thus, either some persons infected by SARS-CoV-2 produce no antibodies or undetectable levels of antibodies reactive to the S1 and N proteins, even 3 months after infection, or some qPCR delivered false positive results.\n\n【61】Among recovered persons, antibody levels are higher in older persons and in those more severely affected by SARS-CoV-2 infection. Women, who tend to become less sick than men, had lower antibody levels in two spike protein antibody assays. SARS-CoV-2 antibody levels were lower in smokers. Smoking increases the probability of severe Covid-19 illness among young adults,  and smoking has been reported to increase the expression of ACE2,  the receptor for cellular entry of the SARS-CoV-2 virus.\n\n【62】The humoral immune response is critical for the clearance of cytopathic viruses and is generally important for the prevention of viral reinfection.  A relationship between a humoral immune response to SARS-CoV-2 infection and protection against reinfection by this virus has been shown in rhesus macaques  but has yet to be established in humans. Regardless of the relationship or lack thereof between seropositivity against SARS-CoV-2 and protection against reinfection, the low SARS-CoV-2 antibody seroprevalence in Iceland indicates that the Icelandic population is vulnerable to a second wave of infection.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-14 00:13:19", "grab_time": "2024-08-13 23:16:47"}
{"id": 2234408, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "976d9f34-af56-4b52-80f6-daeb24cbb447", "title": "Pregnant Women and the Ebola Crisis", "text": "【0】Pregnant Women and the Ebola Crisis\nArticle\n-------\n\n【1】On August 1, 2018, the Ministry of Health of the Democratic Republic of Congo (DRC) reported the emergence of another Ebola virus outbreak, the 10th in the DRC since the virus was discovered in 1976. As of November 13, 2018, there were 341 cases and 215 deaths, making this the world’s third-largest Ebola outbreak to date.  The public health community learned several lessons when West Africa experienced the largest-ever Ebola outbreak beginning in 2014, which ultimately included 28,000 cases and caused 11,000 deaths. Current prevention and control measures have benefited from these lessons and are directed toward a coordinated response, including improvements in cross-border surveillance, laboratory capacity, case management, infection control at health facilities, culturally sensitive safe burials, and psychosocial care, as well as inclusion of vaccination as a control measure. However, according to available documents, issues related to pregnant women have been largely ignored in these efforts.\n\n【2】Even after the large 2014–2016 Ebola outbreak, our knowledge of Ebola virus disease (EVD) in pregnancy remains severely limited. During previous outbreaks, surveillance systems have not consistently recorded pregnancy status, which reduced the capacity for monitoring outcomes in pregnant women and their newborns. In prior outbreaks, public health organizations have primarily relied on anecdotal reports, with limited formal data collection, to document the effects of EVD on pregnancy. Pregnancy data are essential for developing evidence-based recommendations for the care of Ebola-infected pregnant women. In a major outbreak response, which must prioritize outbreak-control activities, data collection focuses on the information most needed to improve the emergency response. Documentation of pregnancy status is needed for all women of reproductive age who are seen as part of case-investigation and contact-tracing efforts, as well as for those evaluated at Ebola treatment units, holding centers, and hospitals. Ideally, urine pregnancy testing would be performed, but that could be challenging in these emergency settings; at a minimum, self-reported pregnancy status should be recorded.\n\n【3】Careful assessment of maternal and infant outcome measures before, during, and after an Ebola outbreak could ensure that obstetrical care does not deteriorate because of overwhelming burdens on the delivery system. Such assessment will require strengthening of national maternal and neonatal mortality surveillance systems and close monitoring of data on preterm deliveries and fetal and neonatal deaths. Measures of health care utilization such as the proportion of women receiving adequate prenatal care and the proportion of births attended by skilled health personnel are important in documenting the overall effects of an outbreak on health care systems.\n\n【4】Though data are limited, the available information regarding pregnancy during Ebola outbreaks provides a reason for concern. Women appear to have higher Ebola infection rates than men; perhaps they tend to become infected when caring for sick family members, or perhaps they have increased susceptibility. Although data from past outbreaks revealed a case-fatality rate among pregnant women as high as 90%, more recent data suggest that the risk of death among EVD-infected pregnant women might be similar to that among nonpregnant women.  Additional data are needed, however, to better characterize outcomes.\n\n【5】EVD infection during pregnancy also threatens the fetus: in nearly all cases, EVD in pregnant women has resulted in miscarriage, stillbirth, or neonatal death.  Maternal morbidity and mortality from obstetrical and nonobstetrical conditions (e.g., HIV or malaria) can increase during and after outbreaks because of deterioration of general health services in combination with hospital closings due to the fear of nosocomial transmission or to staff shortages, which increase barriers to care, and diminished trust in the health care system.  Obstetrical units may also amplify the spread of EVD, given the high risks associated with potential massive exposures to body fluids during delivery and delays in virus recognition that result in additional contact exposures. Indeed, in the current DRC outbreak, nosocomial transmission was traced to a cesarean delivery in an infected woman.\n\n【6】Given these hazards for pregnant women and obstetrical health care workers, we need protocols to reduce the transmission risk and to improve maternal and fetal outcomes. To date, pregnant women have been overlooked in some key EVD treatment guidelines. For example, recommendations for supportive care for patients admitted to Ebola treatment units developed by a multidisciplinary panel did not include recommendations for pregnancy management; instead, pregnant women were classified as a vulnerable population for which more research is needed.  To address this gap, clinicians with expertise in critical care during pregnancy and those with experience caring for critically ill patients with EVD could be assembled to review available data and develop consensus guidelines. These guidelines, informed by the best available evidence and expert opinion, could then be piloted in the current outbreak, with outcomes systematically recorded and analyzed.\n\n【7】Vaccination has been central to the current outbreak-control efforts, with more than 25,000 doses of experimental vaccine provided, but pregnant women are not reaping the potential benefits. Limited data are available on the use of the Ebola vaccine in pregnant women because they were excluded from nearly all vaccine clinical trials. The World Health Organization has therefore recommended against vaccinating pregnant women, a stance that some commentators have suggested violates women’s autonomy.  In contrast, according to information on ClinicalTrials.gov, some clinical trials of experimental treatments have enrolled pregnant women, providing evidence that pregnant women can be safely included in clinical trials during an outbreak. We believe that pregnant women need to be given the opportunity to be included in clinical trials for experimental Ebola vaccines and treatments, after discussion of the potential risks and benefits, if they are to benefit from these interventions in the future. \n\n【8】The dearth of relevant data also restricts our understanding of appropriate care for women who have previously been infected with EVD. Prolonged viral persistence has been documented in immunologically protected sites (e.g., testes and eye) in EVD survivors. A recent report raised concern that the immunomodulation associated with pregnancy could increase the risk of persistence or recrudescence of Ebola virus in the postpartum period.  Research is needed to understand such risks as well as the effects of a history of EVD on health care delivery. After previous outbreaks, EVD survivors have reported major barriers to resuming normal lives after recovery, such as emotional distress, discrimination, health issues including cognitive and mental health disorders, and difficulty regaining their livelihoods. For women of reproductive age, concerns about reemergence during or after pregnancy might amplify these barriers.\n\n【9】Finally, effective family planning services are fundamental in the setting of Ebola. Strengthened contraceptive care in regions of current or recent outbreaks could reduce the potential effects of unplanned pregnancy. Unfortunately, unmet contraceptive needs in the DRC coupled with high fertility rates could further challenge a health care system already overwhelmed by an EVD outbreak.\n\n【10】Despite compelling evidence supporting the need to address pregnancy issues when planning for and responding to current and future Ebola outbreaks, many needs remain unmet. Moreover, Ebola has highlighted the vulnerability of health care systems. If maternal health services were strengthened, with prioritization of and investment in maintaining monitoring and quality care during an outbreak, countries could potentially prevent the deterioration of obstetrical care that has plagued health systems facing other outbreaks. Sadly, we remain unprepared to care for pregnant women in the context of Ebola.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:24:27", "endTime": "2024/08/14 15:24:46", "cost": 19.119}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 23:24:46", "grab_time": "2024-08-13 23:24:27"}
{"id": 2234407, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "f205ab09-2dff-48d9-af38-5ecaf3174a0a", "title": "Molecular Basis of Different Forms of Metachromatic Leukodystrophy", "text": "【0】Molecular Basis of Different Forms of Metachromatic Leukodystrophy\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】Metachromatic leukodystrophy is an autosomal recessive inherited lysosomal storage disorder caused by a deficiency of arylsulfatase A. Three forms of the disease can be distinguished according to severity and the age at onset: late infantile (1 to 2 years), juvenile (3 to 16), and adult (>16).\n\n【3】Methods and Results.\n--------------------\n\n【4】To understand the molecular basis of the different forms of the disease, we analyzed arylsulfatase A alleles associated with metachromatic leukodystrophy. Two alleles (termed I and A) were Identified and accounted for about half of all arylsulfatase A alleles among 68 patients with metachromatic leukodystrophy whom we examined. Sufficient information was available for 66 of the patients to allow classification of their disease. Of the six instances of homozygosity for allele I, all were associated with the late-infantile form of the disease; of the eight instances of homozygosity for allele A, five were associated with the adult form and three with the juvenile form. When both alleles were present, the juvenile form resulted (seven of seven instances). Heterozygosity for allele I (with the other allele unknown) is usually associated with late-infantile disease, and heterozygosity for allele A with a later onset of the disease. The clinical variability can be explained by the different levels of residual arylsulfatase A activity associated with these genotypes.\n\n【5】Conclusions.\n------------\n\n【6】Like many lysosomal storage disorders, metachromatic leukodystrophy shows clinical heterogeneity that seems to reflect genetic heterogeneity. One of the known alleles (allele I) is associated with earlier and more severe disease than the other (allele A). \n\n【7】Introduction\n------------\n\n【8】ARYLSULFATASE A is a lysosomal enzyme inL volved in the degradation of cerebroside sulfate, a polar glycolipid that is found mainly as a component of the myelin sheaths of the nervous system. Deficiency of arylsulfatase A results in metachromatic leukodystrophy, a lysosomal storage disease characterized by the accumulation of cerebroside sulfate.  The storage of sulfatide mainly affects the nervous system, where it is associated with progressive demyelination and loss of white matter. Clinically, there may be neurologic symptoms, such as weakness, ataxia, progressive spastic tetraparesis, optic atrophy, and dementia. In older patients psychiatric symptoms may precede the neurologic manifestations. The age of onset ranges from less than two years to the third or fourth decade of life. Three forms of metachromatic leukodystrophy can be distinguished according to the age at onset: late infantile (1 to 2 years), juvenile (3 to 16), and adult (>16). The late-infantile form is fatal within a few years, whereas the course of the juvenile and adult forms is more protracted. The incidence of metachromatic leukodystrophy among whites is estimated to be 1 in 40,000, suggesting a frequency of 0.5 percent for metachromatic leukodystrophy alleles.  Approximately 0.5 percent  to 2 percent  <sup>, </sup>  of the population has very low levels of residual arylsulfatase A activity but is asymptomatic. This condition has been called arylsulfatase A pseudodeficiency and is in most cases caused by homozygosity for the arylsulfatase A pseudodeficiency allele. Estimates of the frequency of this allele range from 7.3 percent3 to 15 percent.  <sup>, </sup>  We recently analyzed the mutations in this allele  and found that the low residual activity is due to reduced synthesis of arylsulfatase A, which can be explained by the loss of a polyadenylation signal. However, at least in those who are homozygous for the arylsulfatase A pseudodeficiency allele, enough arylsulfatase A is synthesized to prevent clinically apparent disease.\n\n【9】In this report we describe four genotypes that are combinations of two arylsulfatase A alleles that cause metachromatic leukodystrophy and the pseudodeficiency allele. These genotypes are associated with different levels of residual arylsulfatase A activity —from 0 to approximately 10 percent — and represent the clinical spectrum from the most severely affected children to apparently healthy adults.\n\n【10】Methods\n-------\n\n【11】Amplification of Fragments from Genomic DNA\n-------------------------------------------\n\n【12】Figure 1. Mutations in the Arylsulfatase A Gene.\n\n【13】Boxes indicate exons; solid parts represent translated and hatched parts untranslated regions. Lines depict introns, and triangles potential sites of _N_ \\-glycosylation. ATG and TGA are the initiation codon and termination codon, respectively. A, C, and D are the fragments that were amplified: A and C for allele-specific oligonucleotide hybridization, and C and D for subcloning and sequencing. ON 1 through 5 indicate the binding sites of the oligonucleotides (ON) used for the amplification of DNA . Arrows show the location of the mutations. The mutations and the codons in which they occur are shown. Adjacent sequences are shown for the splice-site mutation.\n\n【14】Procedures used lor the amplification of DNA fragments have been described elsewhere.  For the amplification of fragment D, the elongation time was increased to five minutes. The sequences of oligonucleotides used to amplify the fragments shown in Figure 1 were as follows: for fragment A, oligonucleotide 1 sequence 5′TCGAATTCTGCTGGAGCCAAGTAGCCCT3′ and oligonucleotide 3 sequence 5′GAAAGACTGGAGTTAGCACT3′; for fragment C, oligonucleotide 4 sequence 5′CGGAATTCTTGATGGGGAACTGAGTGAC3′ and oligonucleotide 5 sequence 5′GCGAAGCTTCCTCATTGGTACCACAGG3′; and for fragment D, the sequence of oligonucleotide 1 was the same as that in fragment A and oligonucleotide 2 sequence 5′GAGGATCCCAGTGCAGGAGGCACTGAGG3′. The fragments were subcloned into M13mp18 and M13mp19 and sequenced according to standard techniques. \n\n【15】Hybridization of Allele-Specific Oligonucleotides\n-------------------------------------------------\n\n【16】The genotype of the patients was determined by hybridization of allele-specific oligonucleotides. Fragments A and C  were amplified, blotted onto nylon filters, and hybridized to oligonucleotides end-labeled with \\[  P\\]ATP and T <sub>4 </sub> kinase. The methods used have been described elsewhere.  The sequence of oligonucleotides used to detect the splice-site mutation of allele I was 5′TGGTTCCTACCTGGTCGT3′ (57°C) for the normal allele and 5′TGGTTCCTATCTGGTCGT3′ (57°C) for the mutant allele. The sequence of oligonucleotides used to detect the exchange of leucine for proline at position 426 in allele A was 5′CATAGAGCAGCGGGGGCT3′ (59°C) for the normal allele and 5′CATAGAGCAGCAGGGGCT3′ (59°C) for the mutant allele. (Values in parentheses indicate the temperatures at which the filters were washed to give an allele-specific signal.)\n\n【17】Transfection and Western Blot Analysis\n--------------------------------------\n\n【18】Transfection of the arylsulfatase A complementary DNA (cDNA) into baby-hamster kidney cells was performed as described elsewhere.  Western blot analysis and treatment of cultured human fibroblasts with carbobenzoxy Phe-Ala diazomethylketone were carried out as described elsewhere.  <sup>, </sup> \n\n【19】Results\n-------\n\n【20】Identification of Mutations in the Arylsulfatase A Gene\n-------------------------------------------------------\n\n【21】The arylsulfatase A gene has been characterized recently.  It can be amplified in two overlapping fragments . To identify the molecular defects in metachromatic leukodystrophy, we amplified the arylsulfatase A gene of a patient with juvenile onset of the disease. The amplified fragments were subcloned into M13mp18 and M13mp19 and sequenced in both directions.\n\n【22】Two different metachromatic leukodystrophy alleles were identified in this patient. One allele — designated allele I — differed in three positions from the published gene sequence for arylsulfatase A: a G → T transversion changing tryptophan at position 193 to cysteine, a C → G transversion changing threonine at position 391 to serine, and a G → A transition destroying the splice donor site of exon 2 by changing the classic exon-intron boundary consensus sequence AG gt... to AG at.... The exchange of serine for threonine at position 391 is a polymorphism that was found in the DNA of four of eight healthy controls (unpublished data).\n\n【23】The exchange of cysteine for tryptophan at position 193 was introduced into the arylsulfatase A cDNA  by site-directed mutagenesis, and a mutated cDNA was transiently expressed in baby-hamster kidney cells after transfection. The arylsulfatase A activity measured in the transfected cells was comparable to that in cells transfected with wild-type cDNA, indicating that the exchange of cysteine for tryptophan at position 193 is functionally silent. Of the three changes found in allele I, only the loss of the splice donor site was considered to be of relevance for metachromatic leukodystrophy.\n\n【24】The second metachromatic leukodystrophy allele —designated allele A — differed from the published arylsulfatase A sequence in one position: a C → T transition causing the change of proline at position 426 to leucine. The introduction of this mutation into the arylsulfatase A cDNA and its expression in baby-hamster kidney cells led to a small increase in the activity of arylsulfatase A in the transfected cells. Three independent transfection experiments showed that this increase was only 3 percent (range, 2 to 5) of that observed in cells transfected with the normal arylsulfatase A cDNA. Metachromatic leukodystrophy allele A thus codes for low residual arylsulfatase A activity.\n\n【25】Frequencies of Alleles I and A among Patients with Metachromatic Leukodystrophy\n-------------------------------------------------------------------------------\n\n【26】Fragments A and C  were amplified from the DNA of 68 patients affected with different clinical forms of the disease, and the frequencies of alleles I and A were determined by allele-specific oligonucleotide hybridization. Of the 68 patients, 50 carried at least one of the two metachromatic leukodystrophy alleles (I or A). Twenty-three patients were homozygous for either allele I or allele A or heterozygous for both alleles. In 18 patients neither allele I nor allele A was found. In total, 37 I alleles and 36 A alleles were found. Thus, the two alleles accounted for about half of all arylsulfatase A alleles in this fairly typical selection of patients with metachromatic leukodystrophy.\n\n【27】Distribution of Alleles I and A among Patients with Different Clinical Forms of Metachromatic Leukodystrophy\n------------------------------------------------------------------------------------------------------------\n\n【28】Table 1. Genotypes and Clinical Form of Metachromatic Leukodystrophy in 68 Patients.\n\n【29】Sufficient information was available for 66 of the patients with metachromatic leukodystrophy to allow classification of their disease as late infantile, juvenile, or adult. Table 1 shows the correlation between the genotype and the clinical form of the disease. All six patients with metachromatic leukodystrophy who were homozygous for allele I (loss of the splice donor site of exon 2) had the late-infantile form, whereas five of the patients who were homozygous for allele A (substitution of leucine for proline at position 426) had the adult form and three had the juvenile form. Among the patients with juvenile-onset metachromatic leukodystrophy, seven had both allele I and allele A. The I allele was found in combination with an unidentified allele in 14 patients with the late-infantile form, 2 with the juvenile form, and 1 with the adult form of the disease. The A allele was found in combination with an unidentified metachromatic leukodystrophy allele in 10 patients with either the adult or the juvenile form of the disease.\n\n【30】Figure 2. Arylsulfatase A Genotype and Age at Onset of Metachromatic Leukodystrophy.\n\n【31】The arylsulfatase A genotype was plotted against the age at onset of the clinical symptoms in 19 patients for whom such data were available.\n\n【32】These results suggest that homozygosity for allele I predisposes patients to the late-infantile form of metachromatic leukodystrophy, homozygosity for allele A to the adult form, and compound heterozygosity of both alleles to the juvenile form. This is supported by the correlation of the age at onset with the genotype . The age at onset of the disease was known for 19 patients with metachromatic leukodystrophy who had a fully identifiable genotype. In patients who were homozygous for allele I, the disease started around the age of 2 years; in patients who were homozygous for allele A, the onset was between 8 and 22 years (mean, 17.3); and in patients carrying both alleles, the onset was between 4 and 7 years (mean, 5.8).\n\n【33】More complete clinical information was available for five of the six patients with the late-infantile form who were homozygous for allele I. In all cases the initial symptoms were gait disturbances due to muscular hypotonia. In the older patients the first symptoms were either neurologic or psychiatric. A summary of the clinical data for most of the patients with the lateonset form shown in Figure 2 has been presented elsewhere. \n\n【34】Biochemical Characterization of Patients Homozygous for Allele I or Allele A\n----------------------------------------------------------------------------\n\n【35】Patients homozygous for allele I who had late-infantile metachromatic leukodystrophy were characterized biochemically by the absence of arylsulfatase A polypeptides after metabolic labeling of fibroblasts with \\[  S\\]methionine (data not shown). Fibroblasts contain three forms of arylsulfatase A RNA; the smallest, a 2.1-kilobase (kb) species, is efficiently polyadenylated and appears to be the predominant form of messenger RNA used for translation, whereas the two larger forms (3.7 kb and 4.8 kb) are poorly polyadenylated.  We have previously reported that the 2.1-kb species was not detectable and levels of the two larger forms were severely diminished in measurements of total RNA in a patient with metachromatic leukodystrophy who was homozygous for allele I.  We conclude that the deficiency of the splice donor site of exon 2 renders the three forms of arylsulfatase A RNA unstable and that the presence of allele I does not lead to the synthesis of detectable amounts of polypeptides that cross-react with arylsulfatase A.\n\n【36】Figure 3. Molecular Phenotype of Mutant Arylsulfatase A Alleles.\n\n【37】Homogenates from cultured fibroblasts of a patient with metachromatic leukodystrophy who was homozygous for allele A (the substitution of leucine for proline at position 426) underwent Western blot analysis. Lane 1 shows a Western blot of homogenates from untreated fibroblasts, and lane 2 from fibroblasts treated for 14 days with a cysteine proteinase inhibitor (0.8 μmol of carbobenzoxy-Phe-Ala diazomethylketone per liter).  The band specific for arylsulfatase A is indicated by an arrow.\n\n【38】The biochemical phenotype of two patients with the adult form of metachromatic leukodystrophy who proved to be homozygous for allele A in this study was reported earlier.  Incubation of fibroblasts from these patients with inhibitors of cysteine proteinases partially restored the arylsulfatase A activity. The deficiency was thought to result from an increased susceptibility of the mutant arylsulfatase A polypeptides to lysosomal cysteine proteinases.  <sup>, </sup>  The accumulation of arylsulfatase A polypeptides in fibroblasts from a patient homozygous for allele A in response to incubation with a cysteine proteinase inhibitor is shown in Figure 3 . We conclude from these results that the exchange of leucine for proline at position 426 increases the susceptibility of arylsulfatase A to lysosomal cysteine proteinases and results in a severe reduction in the half-life of the mutant polypeptides.\n\n【39】Identification of Compound Heterozygotes for the Arylsulfatase A Pseudodeficiency Allele and Allele I We previously identified the mutations in the arylsulfatase A pseudodeficiency allele.  The gene frequency of this allele is estimated to range from 7.3 to 15 percent, and persons who are homozygous for the pseudodeficiency allele are clinically healthy.  <sup>, </sup>  We have identified two persons with compound heterozygosity for the pseudodeficiency allele and the metachromatic leukodystrophy allele I. The combination of these alleles is expected to reduce arylsulfatase A activity to about 10 percent  of normal. Both persons are in their third decade of life and so far have no symptoms characteristic of metachromatic leukodystrophy.\n\n【40】Discussion\n----------\n\n【41】It is apparent from this study that a clear correlation exists between the arylsulfatase A genotype and the clinical phenotype. The most severe type of metachromatic leukodystrophy, the late-infantile form, is associated with homozygosity for allele I, which does not encode for functional arylsulfatase A polypeptides. One copy of allele A, which encodes for an unstable but active arylsulfatase A, is sufficient to mitigate the clinical course and produce the juvenile form, whereas two copies of this allele allow for the mildest course of the disease, the adult form of metachromatic leukodystrophy. One copy of the arylsulfatase A pseudodeficiency allele is sufficient to sustain a normal phenotype. Although one cannot be certain that symptoms will not develop in these persons very late in life, it seems that the critical threshold is approximately 10 percent residual arylsulfatase A activity. Small variations in residual arylsulfatase A activity may greatly influence the accumulation of its substrates and its clinical manifestation.\n\n【42】Bone marrow transplantation has been proposed as a treatment for metachromatic leukodystrophy. Improvement of the clinical symptoms was recently reported in a girl who had received a bone marrow transplant several years earlier.  Our data support the view that the low levels of enzyme delivered to the brain by the microglial cells derived from the donor's bone marrow may be sufficient to alter the course of the disease. Patients with the juvenile or adult form of metachromatic leukodystrophy should be better candidates for bone marrow transplantation than those with the late-infantile form, because their level of residual arylsulfatase A activity is higher and therefore less enzyme needs to be replaced.\n\n【43】Although the average age at onset is clearly different in the three forms of metachromatic leukodystrophy, there is a remarkable variability among the patients who are homozygous for allele A. This genotype can be found both among patients with the juvenile form and among those with the adult form of the disease. Such variability can occur within a single family10 and suggests the existence of additional loci that can influence the clinical phenotype of metachromatic leukodystrophy. For example, the pattern of expression and activity of lysosomal proteinases may differ from person to person, and this in turn may influence the half-life of the mutant arylsulfatase A protein and explain the variability of the clinical manifestations in adult patients with metachromatic leukodystrophy.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "are clinically healthy.  ,  ", "content": "【0】Molecular Basis of Different Forms of Metachromatic Leukodystrophy\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】Metachromatic leukodystrophy is an autosomal recessive inherited lysosomal storage disorder caused by a deficiency of arylsulfatase A. Three forms of the disease can be distinguished according to severity and the age at onset: late infantile (1 to 2 years), juvenile (3 to 16), and adult (>16).\n\n【3】Methods and Results.\n--------------------\n\n【4】To understand the molecular basis of the different forms of the disease, we analyzed arylsulfatase A alleles associated with metachromatic leukodystrophy. Two alleles (termed I and A) were Identified and accounted for about half of all arylsulfatase A alleles among 68 patients with metachromatic leukodystrophy whom we examined. Sufficient information was available for 66 of the patients to allow classification of their disease. Of the six instances of homozygosity for allele I, all were associated with the late-infantile form of the disease; of the eight instances of homozygosity for allele A, five were associated with the adult form and three with the juvenile form. When both alleles were present, the juvenile form resulted (seven of seven instances). Heterozygosity for allele I (with the other allele unknown) is usually associated with late-infantile disease, and heterozygosity for allele A with a later onset of the disease. The clinical variability can be explained by the different levels of residual arylsulfatase A activity associated with these genotypes.\n\n【5】Conclusions.\n------------\n\n【6】Like many lysosomal storage disorders, metachromatic leukodystrophy shows clinical heterogeneity that seems to reflect genetic heterogeneity. One of the known alleles (allele I) is associated with earlier and more severe disease than the other (allele A). \n\n【7】Introduction\n------------\n\n【8】ARYLSULFATASE A is a lysosomal enzyme inL volved in the degradation of cerebroside sulfate, a polar glycolipid that is found mainly as a component of the myelin sheaths of the nervous system. Deficiency of arylsulfatase A results in metachromatic leukodystrophy, a lysosomal storage disease characterized by the accumulation of cerebroside sulfate.  The storage of sulfatide mainly affects the nervous system, where it is associated with progressive demyelination and loss of white matter. Clinically, there may be neurologic symptoms, such as weakness, ataxia, progressive spastic tetraparesis, optic atrophy, and dementia. In older patients psychiatric symptoms may precede the neurologic manifestations. The age of onset ranges from less than two years to the third or fourth decade of life. Three forms of metachromatic leukodystrophy can be distinguished according to the age at onset: late infantile (1 to 2 years), juvenile (3 to 16), and adult (>16). The late-infantile form is fatal within a few years, whereas the course of the juvenile and adult forms is more protracted. The incidence of metachromatic leukodystrophy among whites is estimated to be 1 in 40,000, suggesting a frequency of 0.5 percent for metachromatic leukodystrophy alleles.  Approximately 0.5 percent  to 2 percent  <sup>, </sup>  of the population has very low levels of residual arylsulfatase A activity but is asymptomatic. This condition has been called arylsulfatase A pseudodeficiency and is in most cases caused by homozygosity for the arylsulfatase A pseudodeficiency allele. Estimates of the frequency of this allele range from 7.3 percent3 to 15 percent.  <sup>, </sup>  We recently analyzed the mutations in this allele  and found that the low residual activity is due to reduced synthesis of arylsulfatase A, which can be explained by the loss of a polyadenylation signal. However, at least in those who are homozygous for the arylsulfatase A pseudodeficiency allele, enough arylsulfatase A is synthesized to prevent clinically apparent disease.\n\n【9】In this report we describe four genotypes that are combinations of two arylsulfatase A alleles that cause metachromatic leukodystrophy and the pseudodeficiency allele. These genotypes are associated with different levels of residual arylsulfatase A activity —from 0 to approximately 10 percent — and represent the clinical spectrum from the most severely affected children to apparently healthy adults.\n\n【10】Methods\n-------\n\n【11】Amplification of Fragments from Genomic DNA\n-------------------------------------------\n\n<mark>【12】Figure 1. </mark>Mutations in the Arylsulfatase A Gene.\n\n【13】Boxes indicate exons; solid parts represent translated and hatched parts untranslated regions. Lines depict introns, and triangles potential sites of _N_ \\-glycosylation. ATG and TGA are the initiation codon and termination codon, respectively. A, C, and D are the fragments that were amplified: A and C for allele-specific oligonucleotide hybridization, and C and D for subcloning and sequencing. ON 1 through 5 indicate the binding sites of the oligonucleotides (ON) used for the amplification of DNA . Arrows show the location of the mutations. The mutations and the codons in which they occur are shown. Adjacent sequences are shown for the splice-site mutation.\n\n【14】Procedures used lor the amplification of DNA fragments have been described elsewhere.  For the amplification of fragment D, the elongation time was increased to five minutes. The sequences of oligonucleotides used to amplify the fragments shown in Figure 1 were as follows: for fragment A, oligonucleotide 1 sequence 5′TCGAATTCTGCTGGAGCCAAGTAGCCCT3′ and oligonucleotide 3 sequence 5′GAAAGACTGGAGTTAGCACT3′; for fragment C, oligonucleotide 4 sequence 5′CGGAATTCTTGATGGGGAACTGAGTGAC3′ and oligonucleotide 5 sequence 5′GCGAAGCTTCCTCATTGGTACCACAGG3′; and for fragment D, the sequence of oligonucleotide 1 was the same as that in fragment A and oligonucleotide 2 sequence 5′GAGGATCCCAGTGCAGGAGGCACTGAGG3′. The fragments were subcloned into M13mp18 and M13mp19 and sequenced according to standard techniques. \n\n【15】Hybridization of Allele-Specific Oligonucleotides\n-------------------------------------------------\n\n【16】The genotype of the patients was determined by hybridization of allele-specific oligonucleotides. Fragments A and C  were amplified, blotted onto nylon filters, and hybridized to oligonucleotides end-labeled with \\[  P\\]ATP and T <sub>4 </sub> kinase. The methods used have been described elsewhere.  The sequence of oligonucleotides used to detect the splice-site mutation of allele I was 5′TGGTTCCTACCTGGTCGT3′ (57°C) for the normal allele and 5′TGGTTCCTATCTGGTCGT3′ (57°C) for the mutant allele. The sequence of oligonucleotides used to detect the exchange of leucine for proline at position 426 in allele A was 5′CATAGAGCAGCGGGGGCT3′ (59°C) for the normal allele and 5′CATAGAGCAGCAGGGGCT3′ (59°C) for the mutant allele. (Values in parentheses indicate the temperatures at which the filters were washed to give an allele-specific signal.)\n\n【17】Transfection and Western Blot Analysis\n--------------------------------------\n\n【18】Transfection of the arylsulfatase A complementary DNA (cDNA) into baby-hamster kidney cells was performed as described elsewhere.  Western blot analysis and treatment of cultured human fibroblasts with carbobenzoxy Phe-Ala diazomethylketone were carried out as described elsewhere.  <sup>, </sup> \n\n【19】Results\n-------\n\n【20】Identification of Mutations in the Arylsulfatase A Gene\n-------------------------------------------------------\n\n【21】The arylsulfatase A gene has been characterized recently.  It can be amplified in two overlapping fragments . To identify the molecular defects in metachromatic leukodystrophy, we amplified the arylsulfatase A gene of a patient with juvenile onset of the disease. The amplified fragments were subcloned into M13mp18 and M13mp19 and sequenced in both directions.\n\n【22】Two different metachromatic leukodystrophy alleles were identified in this patient. One allele — designated allele I — differed in three positions from the published gene sequence for arylsulfatase A: a G → T transversion changing tryptophan at position 193 to cysteine, a C → G transversion changing threonine at position 391 to serine, and a G → A transition destroying the splice donor site of exon 2 by changing the classic exon-intron boundary consensus sequence AG gt... to AG at.... The exchange of serine for threonine at position 391 is a polymorphism that was found in the DNA of four of eight healthy controls (unpublished data).\n\n【23】The exchange of cysteine for tryptophan at position 193 was introduced into the arylsulfatase A cDNA  by site-directed mutagenesis, and a mutated cDNA was transiently expressed in baby-hamster kidney cells after transfection. The arylsulfatase A activity measured in the transfected cells was comparable to that in cells transfected with wild-type cDNA, indicating that the exchange of cysteine for tryptophan at position 193 is functionally silent. Of the three changes found in allele I, only the loss of the splice donor site was considered to be of relevance for metachromatic leukodystrophy.\n\n【24】The second metachromatic leukodystrophy allele —designated allele A — differed from the published arylsulfatase A sequence in one position: a C → T transition causing the change of proline at position 426 to leucine. The introduction of this mutation into the arylsulfatase A cDNA and its expression in baby-hamster kidney cells led to a small increase in the activity of arylsulfatase A in the transfected cells. Three independent transfection experiments showed that this increase was only 3 percent (range, 2 to 5) of that observed in cells transfected with the normal arylsulfatase A cDNA. Metachromatic leukodystrophy allele A thus codes for low residual arylsulfatase A activity.\n\n【25】Frequencies of Alleles I and A among Patients with Metachromatic Leukodystrophy\n-------------------------------------------------------------------------------\n\n【26】Fragments A and C  were amplified from the DNA of 68 patients affected with different clinical forms of the disease, and the frequencies of alleles I and A were determined by allele-specific oligonucleotide hybridization. Of the 68 patients, 50 carried at least one of the two metachromatic leukodystrophy alleles (I or A). Twenty-three patients were homozygous for either allele I or allele A or heterozygous for both alleles. In 18 patients neither allele I nor allele A was found. In total, 37 I alleles and 36 A alleles were found. Thus, the two alleles accounted for about half of all arylsulfatase A alleles in this fairly typical selection of patients with metachromatic leukodystrophy.\n\n【27】Distribution of Alleles I and A among Patients with Different Clinical Forms of Metachromatic Leukodystrophy\n------------------------------------------------------------------------------------------------------------\n\n<mark>【28】Table 1. </mark>Genotypes and Clinical Form of Metachromatic Leukodystrophy in 68 Patients.\n\n【29】Sufficient information was available for 66 of the patients with metachromatic leukodystrophy to allow classification of their disease as late infantile, juvenile, or adult. Table 1 shows the correlation between the genotype and the clinical form of the disease. All six patients with metachromatic leukodystrophy who were homozygous for allele I (loss of the splice donor site of exon 2) had the late-infantile form, whereas five of the patients who were homozygous for allele A (substitution of leucine for proline at position 426) had the adult form and three had the juvenile form. Among the patients with juvenile-onset metachromatic leukodystrophy, seven had both allele I and allele A. The I allele was found in combination with an unidentified allele in 14 patients with the late-infantile form, 2 with the juvenile form, and 1 with the adult form of the disease. The A allele was found in combination with an unidentified metachromatic leukodystrophy allele in 10 patients with either the adult or the juvenile form of the disease.\n\n<mark>【30】Figure 2.</mark> Arylsulfatase A Genotype and Age at Onset of Metachromatic Leukodystrophy.\n\n【31】The arylsulfatase A genotype was plotted against the age at onset of the clinical symptoms in 19 patients for whom such data were available.\n\n【32】These results suggest that homozygosity for allele I predisposes patients to the late-infantile form of metachromatic leukodystrophy, homozygosity for allele A to the adult form, and compound heterozygosity of both alleles to the juvenile form. This is supported by the correlation of the age at onset with the genotype . The age at onset of the disease was known for 19 patients with metachromatic leukodystrophy who had a fully identifiable genotype. In patients who were homozygous for allele I, the disease started around the age of 2 years; in patients who were homozygous for allele A, the onset was between 8 and 22 years (mean, 17.3); and in patients carrying both alleles, the onset was between 4 and 7 years (mean, 5.8).\n\n【33】More complete clinical information was available for five of the six patients with the late-infantile form who were homozygous for allele I. In all cases the initial symptoms were gait disturbances due to muscular hypotonia. In the older patients the first symptoms were either neurologic or psychiatric. A summary of the clinical data for most of the patients with the lateonset form shown in Figure 2 has been presented elsewhere. \n\n【34】Biochemical Characterization of Patients Homozygous for Allele I or Allele A\n----------------------------------------------------------------------------\n\n【35】Patients homozygous for allele I who had late-infantile metachromatic leukodystrophy were characterized biochemically by the absence of arylsulfatase A polypeptides after metabolic labeling of fibroblasts with \\[  S\\]methionine (data not shown). Fibroblasts contain three forms of arylsulfatase A RNA; the smallest, a 2.1-kilobase (kb) species, is efficiently polyadenylated and appears to be the predominant form of messenger RNA used for translation, whereas the two larger forms (3.7 kb and 4.8 kb) are poorly polyadenylated.  We have previously reported that the 2.1-kb species was not detectable and levels of the two larger forms were severely diminished in measurements of total RNA in a patient with metachromatic leukodystrophy who was homozygous for allele I.  We conclude that the deficiency of the splice donor site of exon 2 renders the three forms of arylsulfatase A RNA unstable and that the presence of allele I does not lead to the synthesis of detectable amounts of polypeptides that cross-react with arylsulfatase A.\n\n<mark>【36】Figure 3.</mark> Molecular Phenotype of Mutant Arylsulfatase A Alleles.\n\n【37】Homogenates from cultured fibroblasts of a patient with metachromatic leukodystrophy who was homozygous for allele A (the substitution of leucine for proline at position 426) underwent Western blot analysis. Lane 1 shows a Western blot of homogenates from untreated fibroblasts, and lane 2 from fibroblasts treated for 14 days with a cysteine proteinase inhibitor (0.8 μmol of carbobenzoxy-Phe-Ala diazomethylketone per liter).  The band specific for arylsulfatase A is indicated by an arrow.\n\n【38】The biochemical phenotype of two patients with the adult form of metachromatic leukodystrophy who proved to be homozygous for allele A in this study was reported earlier.  Incubation of fibroblasts from these patients with inhibitors of cysteine proteinases partially restored the arylsulfatase A activity. The deficiency was thought to result from an increased susceptibility of the mutant arylsulfatase A polypeptides to lysosomal cysteine proteinases.  <sup>, </sup>  The accumulation of arylsulfatase A polypeptides in fibroblasts from a patient homozygous for allele A in response to incubation with a cysteine proteinase inhibitor is<mark> shown in Figure 3 . </mark>We conclude from these results that the exchange of leucine for proline at position 426 increases the susceptibility of arylsulfatase A to lysosomal cysteine proteinases and results in a severe reduction in the half-life of the mutant polypeptides.\n\n【39】Identification of Compound Heterozygotes for the Arylsulfatase A Pseudodeficiency Allele and Allele I We previously identified the mutations in the arylsulfatase A pseudodeficiency allele.  The gene frequency of this allele is estimated to range from 7.3 to 15 percent, and persons who are homozygous for the pseudodeficiency allele are clinically healthy.  <sup>, </sup>  We have identified two persons with compound heterozygosity for the pseudodeficiency allele and the metachromatic leukodystrophy allele I. The combination of these alleles is expected to reduce arylsulfatase A activity to about 10 percent  of normal. Both persons are in their third decade of life and so far have no symptoms characteristic of metachromatic leukodystrophy.\n\n【40】Discussion\n----------\n\n【41】It is apparent from this study that a clear correlation exists between the arylsulfatase A genotype and the clinical phenotype. The most severe type of metachromatic leukodystrophy, the late-infantile form, is associated with homozygosity for allele I, which does not encode for functional arylsulfatase A polypeptides. One copy of allele A, which encodes for an unstable but active arylsulfatase A, is sufficient to mitigate the clinical course and produce the juvenile form, whereas two copies of this allele allow for the mildest course of the disease, the adult form of metachromatic leukodystrophy. One copy of the arylsulfatase A pseudodeficiency allele is sufficient to sustain a normal phenotype. Although one cannot be certain that symptoms will not develop in these persons very late in life, it seems that the critical threshold is approximately 10 percent residual arylsulfatase A activity. Small variations in residual arylsulfatase A activity may greatly influence the accumulation of its substrates and its clinical manifestation.\n\n【42】Bone marrow transplantation has been proposed as a treatment for metachromatic leukodystrophy. Improvement of the clinical symptoms was recently reported in a girl who had received a bone marrow transplant several years earlier.  Our data support the view that the low levels of enzyme delivered to the brain by the microglial cells derived from the donor's bone marrow may be sufficient to alter the course of the disease. Patients with the juvenile or adult form of metachromatic leukodystrophy should be better candidates for bone marrow transplantation than those with the late-infantile form, because their level of residual arylsulfatase A activity is higher and therefore less enzyme needs to be replaced.\n\n【43】Although the average age at onset is clearly different in the three forms of metachromatic leukodystrophy, there is a remarkable variability among the patients who are homozygous for allele A. This genotype can be found both among patients with the juvenile form and among those with the adult form of the disease. Such variability can occur within a single family10 and suggests the existence of additional loci that can influence the clinical phenotype of metachromatic leukodystrophy. For example, the pattern of expression and activity of lysosomal proteinases may differ from person to person, and this in turn may influence the half-life of the mutant arylsulfatase A protein and explain the variability of the clinical manifestations in adult patients with metachromatic leukodystrophy.", "index": 16462, "show": true, "start": 16397, "end": 16425, "province": ["格式规范性", "多余标点"], "isEdit": false}]}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-14 00:24:10", "grab_time": "2024-08-13 23:50:49"}
{"id": 2234406, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "dab02809-4e33-4ee0-8b7c-8414e7f26447", "title": "The Public, Political Parties, and Stem-Cell Research", "text": "【0】The Public, Political Parties, and Stem-Cell Research\nThe 2012 presidential election campaign has created uncertainty about federal funding for human embryonic stem-cell research, with most Republican candidates suggesting that they would substantially reduce such funding. Where do U.S. voters stand on this issue? This Perspective summarizes polling results.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:54:21", "endTime": "2024/08/14 14:54:33", "cost": 11.032}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 22:54:33", "grab_time": "2024-08-13 22:54:21"}
{"id": 2234405, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "860eb007-d54a-4258-91e4-3f58ae4a95d6", "title": "Clinical Characteristics of Patients with Ventricular Fibrillation during Antiarrhythmic Drug Therapy", "text": "【0】Clinical Characteristics of Patients with Ventricular Fibrillation during Antiarrhythmic Drug Therapy\nAbstract\n--------\n\n【1】We retrospectively studied 28 patients with 38 episodes of newly occurring ventricular fibrillation during antiarrhythmic drug therapy. Twenty-six of these patients, who had ventricular fibrillation during single-drug therapy with quinidine, procainamide, or disopyramide, were compared with a control group of 62 patients who had been treated similarly for ventricular arrhythmias but did not have ventricular fibrillation during treatment.\n\n【2】The median duration of therapy before ventricular fibrillation was three days. The left ventricular ejection fraction of the study group was lower than that of the control group (0.29 vs. 0.43; P<0.0001), and concomitant treatment with digitalis and diuretic agents was more common in the study group. The base-line QT interval (corrected for heart rate) was slightly longer in the study group than in the controls (0.47 vs. 0.44; P<0.005), although both groups had similar degrees of QT prolongation during drug therapy. Four of 13 patients (31 percent) who underwent multiple trials of antiarrhythmic drugs had recurrent episodes of ventricular fibrillation. Six patients died suddenly after a mean follow-up of 18 months — four who were receiving antiarrhythmic therapy and two who were not.\n\n【3】We conclude that drug-associated ventricular fibrillation is an early event, that there may be an increased risk of its recurrence with subsequent trials of antiarrhythmic drugs, and that left ventricular dysfunction and concomitant therapy with digitalis and diuretic agents may predispose patients to this complication.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:52:59", "endTime": "2024/08/14 15:53:10", "cost": 10.942}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 23:53:10", "grab_time": "2024-08-13 23:52:58"}
{"id": 2234404, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "42bce0c7-8041-4e8c-afcd-59cdf342133f", "title": "Heparin-Induced Immune Thrombocytopenia", "text": "【0】Heparin-Induced Immune Thrombocytopenia\nAbstract\n--------\n\n【1】We studied five patients in whom severe thrombocytopenia developed during intermittent intravenous heparin treatment of arterial and venous thrombosis. Platelet aggregation was demonstrated when heparin (0.5 U per milliliter) was incubated with the patients' citrated platelet-rich plasma or with normal platelet-rich plasma in the presence of the patients' serum. Antiplatelet antibody was not detected in the patient globulin fractions prepared from serum collected within one week after heparin withdrawal by use of the platelet factor 3 availability technic. When the studies were repeated with modifications to detect heparin-dependent antiplatelet antibodies, positive results were obtained in four of five patients. The data suggest that a causal relation, mediated by an immune mechanism, existed between heparin therapy and thrombocytopenia, and that this syndrome may occur more often than has previously been suspected.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:15:41", "endTime": "2024/08/14 15:16:09", "cost": 27.786}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 23:16:09", "grab_time": "2024-08-13 23:15:41"}
{"id": 2234403, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "53f29750-a296-4aa3-81e9-6ee933ead450", "title": "Single-Dose Cholera Vaccine in Response to an Outbreak in Zambia", "text": "【0】Single-Dose Cholera Vaccine in Response to an Outbreak in Zambia\nTo the Editor:\n--------------\n\n【1】Killed oral cholera vaccines (OCVs) are part of the standard response package to a cholera outbreak, although the two-dose regimen of vaccines that has been prequalified by the World Health Organization (WHO) poses challenges to timely and efficient reactive vaccination campaigns.  Recent data suggest that the first dose alone provides short-term protection, similar to that of two doses, which may largely dictate the effect of OCVs during epidemics. \n\n【2】A cholera outbreak was detected in Lusaka, Zambia, in February 2016, after a period of 4 years without a reported case of cholera. An emergency reactive vaccination campaign was implemented in April 2016, targeting more than 500,000 persons who were at high risk for cholera in Lusaka (population, >2 million persons). The Ministry of Health, with support from Médecins sans Frontières and the WHO, decided to implement a single-dose campaign to quell the epidemic rapidly, in view of the insufficient number of vaccine doses that were available in the global stockpile to complete a two-dose campaign. In December 2016, when more doses became available, a second round of vaccination was organized and the second vaccine dose was offered to persons at risk.\n\n【3】We conducted a matched case–control study to quantify the short-term effectiveness of a single-dose OCV regimen (Shanchol) between April 25, 2016, and June 15, 2016. The study was approved by two institutional review boards, and written informed consent was obtained from all the participants . Cases of cholera were confirmed by means of culture, polymerase-chain-reaction assay, or both. Age- and sex-matched controls were selected from among the neighbors of case patients with cholera.  We ascertained vaccination status by means of structured interviews using photographs of OCVs, and verified the information with the use of vaccination cards, when available. We calculated the vaccine effectiveness as (1−odds ratio)×100, using conditional logistic regression. We also conducted a bias-indicator study involving persons with noncholera diarrhea and matched controls.\n\n【4】Table 1. Crude and Adjusted Estimates of Vaccine Effectiveness against Cholera (Main Analysis) and Noncholera Diarrhea (Bias-Indicator Analysis).\n\n【5】We enrolled 66 persons with confirmed cholera and 330 matched controls. Vaccination with a single dose was associated with significant protection in both the crude and adjusted analyses (effectiveness in the adjusted analysis, 88.9%; 95% confidence interval, 42.7 to 97.8; P=0.009) . The bias-indicator analysis included 145 persons with noncholera diarrhea and 725 matched controls. In that analysis, we found that the odds of vaccination did not vary significantly between the two groups in the crude or adjusted analyses (P=0.29 in the adjusted analysis), which suggests the absence of selection bias.\n\n【6】Our results show the short-term effectiveness of a single dose of OCV delivered during an outbreak. Previous studies measuring the protection provided by a single dose of OCV were conducted in areas with recent exposure to cholera, which raises the possibility that single-dose regimens might act to boost natural immunity.  Our results indicate that single-dose regimens provide protection in populations with less exposure to cholera, such as those in Lusaka and much of sub-Saharan Africa, where multiyear lull periods are punctuated by explosive outbreaks. Although additional work is needed to determine the protection provided by a single-dose vaccine in young children and persons not previously exposed to cholera, the duration of protection provided by a single-dose regimen, and an appropriate interval for the administration of a second dose, our results support the use of single-dose regimens to improve responses during a cholera outbreak.\n\n【7】Eva Ferreras, M.Pharm., M.Sc.  \nEpicentre, Paris, France", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "【7】Eva Ferreras, M.Pharm., M.Sc.\n\nEpicentre, Paris, France", "content": "【0】Single-Dose Cholera Vaccine in Response to an Outbreak in Zambia\nTo the Editor:\n--------------\n\n【1】Killed oral cholera vaccines (OCVs) are part of the standard response package to a cholera outbreak, although the two-dose regimen of vaccines that has been prequalified by the World Health Organization (WHO) poses challenges to timely and efficient reactive vaccination campaigns.  Recent data suggest that the first dose alone provides short-term protection, similar to that of two doses, which may largely dictate the effect of OCVs during epidemics. \n\n【2】A cholera outbreak was detected in Lusaka, Zambia, in February 2016, after a period of 4 years without a reported case of cholera. An emergency reactive vaccination campaign was implemented in April 2016, targeting more than 500,000 persons who were at high risk for cholera in Lusaka (population, >2 million persons). The Ministry of Health, with support from Médecins sans Frontières and the WHO, decided to implement a single-dose campaign to quell the epidemic rapidly, in view of the insufficient number of vaccine doses that were available in the global stockpile to complete a two-dose campaign. In December 2016, when more doses became available, a second round of vaccination was organized and the second vaccine dose was offered to persons at risk.\n\n【3】We conducted a matched case–control study to quantify the short-term effectiveness of a single-dose OCV regimen (Shanchol) between April 25, 2016, and June 15, 2016. The study was approved by two institutional review boards, and written informed consent was obtained from all the participants . Cases of cholera were confirmed by means of culture, polymerase-chain-reaction assay, or both. Age- and sex-matched controls were selected from among the neighbors of case patients with cholera.  We ascertained vaccination status by means of structured interviews using photographs of OCVs, and verified the information with the use of vaccination cards, when available. We calculated the vaccine effectiveness as (1−odds ratio)×100, using conditional logistic regression. We also conducted a bias-indicator study involving persons with noncholera diarrhea and matched controls.\n\n【4】Table 1. Crude and Adjusted Estimates of Vaccine Effectiveness against Cholera (Main Analysis) and Noncholera Diarrhea (Bias-Indicator Analysis).\n\n【5】We enrolled 66 persons with confirmed cholera and 330 matched controls. Vaccination with a single dose was associated with significant protection in both the crude and adjusted analyses (effectiveness in the adjusted analysis, 88.9%; 95% confidence interval, 42.7 to 97.8; P=0.009) . The bias-indicator analysis included 145 persons with noncholera diarrhea and 725 matched controls. In that analysis, we found that the odds of vaccination did not vary significantly between the two groups in the crude or adjusted analyses (P=0.29 in the adjusted analysis), which suggests the absence of selection bias.\n\n【6】Our results show the short-term effectiveness of a single dose of OCV delivered during an outbreak. Previous studies measuring the protection provided by a single dose of OCV were conducted in areas with recent exposure to cholera, which raises the possibility that single-dose regimens might act to boost natural immunity.  Our results indicate that single-dose regimens provide protection in populations with less exposure to cholera, such as those in Lusaka and much of sub-Saharan Africa, where multiyear lull periods are punctuated by explosive outbreaks. Although additional work is needed to determine the protection provided by a single-dose vaccine in young children and persons not previously exposed to cholera, the duration of protection provided by a single-dose regimen, and an appropriate interval for the administration of a second dose, our results support the use of single-dose regimens to improve responses during a cholera outbreak.\n\n【7】Eva Ferreras, M.Pharm., M.Sc.  \nEpicentre, Paris, France", "index": 3916, "show": true, "start": 3916, "end": 3974, "province": ["文本干净度", "无关文本"], "isEdit": false}], "startTime": "2024/08/13 18:03:07", "endTime": "2024/08/13 18:03:33", "cost": 25.581}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 02:03:33", "grab_time": "2024-08-13 02:03:07"}
{"id": 2234402, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "82a49139-0b53-4f8a-b05c-a04233bafbc7", "title": "Case 3-2016 — A 9-Year-Old Girl with Intermittent Abdominal Pain", "text": "【0】Case 3-2016 — A 9-Year-Old Girl with Intermittent Abdominal Pain\nA 9-year-old girl with chronic constipation was seen in the gastroenterology clinic because of increasingly frequent episodes of abdominal pain with associated nonbilious vomiting. A diagnosis was made.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:41:03", "endTime": "2024/08/14 14:41:11", "cost": 8.321}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 22:41:11", "grab_time": "2024-08-13 22:41:03"}
{"id": 2234401, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "585a8fe5-c508-415b-9ce4-e5d20b80955f", "title": "Raxibacumab for the Treatment of Inhalational Anthrax", "text": "【0】Raxibacumab for the Treatment of Inhalational Anthrax\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Inhalational anthrax caused by _Bacillus anthracis_ is associated with high mortality primarily due to toxin-mediated injury. Raxibacumab is a human IgG1λ monoclonal antibody directed against protective antigen, a component of the anthrax toxin.\n\n【3】Methods\n-------\n\n【4】We evaluated the efficacy of raxibacumab as a prophylactic agent and after disease onset in a total of four randomized, placebo-controlled studies conducted in rabbits and monkeys. Animals were exposed to an aerosolized target exposure of _B. anthracis_ spores that was approximately 100 times (in the prophylactic studies) and 200 times (in the therapeutic-intervention studies) the median lethal dose. In the therapeutic-intervention studies, animals were monitored for the onset of symptoms. Animals with detectable protective antigen in serum, a significant increase in temperature, or both received a single intravenous bolus of placebo or raxibacumab at a dose of either 20 mg per kilogram of body weight or 40 mg per kilogram. The primary end point was survival at day 14 (in rabbits) or at day 28 (in monkeys). Safety studies were conducted with intravenous raxibacumab (40 mg per kilogram) in 333 healthy human volunteers.\n\n【5】Results\n-------\n\n【6】In both rabbits and monkeys, the time to detection of protective antigen correlated with the time to bacteremia (r=0.9, P<0.001). In the therapeutic-intervention studies, the survival rate was significantly higher among rabbits that received raxibacumab at a dose of 40 mg per kilogram (44% \\[8 of 18\\]) than among rabbits that received placebo (0% \\[0 of 18\\]; P=0.003). Raxibacumab treatment also significantly increased survival in monkeys (64% \\[9 of 14\\], vs. 0% \\[0 of 12\\] with placebo; P<0.001). In human subjects, intravenous raxibacumab at a dose of 40 mg per kilogram had a half-life of 20 to 22 days and provided a maximum concentration of the drug in excess of levels that are protective in animals. Concentrations of raxibacumab provide a surrogate end point that should be predictive of clinical benefit.\n\n【7】Conclusions\n-----------\n\n【8】A single dose of raxibacumab improved survival in rabbits and monkeys with symptomatic inhalational anthrax. \n\n【9】Introduction\n------------\n\n【10】_Bacillus anthracis_ causes anthrax, a zoonotic infection affecting a wide range of mammalian species, and it can be transmitted from animals to humans.  The innate hardiness of _B. anthracis_ endospores has allowed anthrax spores to be developed as “weapons-grade” material for biologic weapons.  The largest outbreak of inhalational anthrax occurred in 1979 in Sverdlovsk (in the former Soviet Union),  and the 2001 anthrax attacks were the first confirmed outbreak associated with intentional anthrax release in the United States.  Inhalational anthrax exposure rapidly progresses to bacteremia and toxemia, with mortality ranging from 45 to 80%.  Although several antibiotics have potent bactericidal activity,  there is a considerable unmet need for agents to counter toxin-mediated illness and death in the treatment of inhalational anthrax. The anthrax toxin is a tripartite toxin that comprises lethal factor and edema factor as the enzymatic moieties of the toxin and protective antigen as the binding moiety.  Blocking the binding of protective antigen to its host receptors can counter the deleterious effects of the anthrax toxin  and provides the basis for vaccine  and passive immunization with anti–protective antigen immunoglobulin. \n\n【11】Current guidelines include administration of antibiotics for up to 60 days and the AVA (anthrax vaccine adsorbed) vaccine after exposure to _B. anthracis_ spores.  The clinical presentation of inhalational anthrax in nonhuman primates and rabbits is similar to that in humans,  and studies conducted in animals that received postexposure prophylaxis provided the basis for approval of these agents for use in humans.  Raxibacumab is a fully human monoclonal antibody directed against _B. anthracis_ protective antigen.  We conducted randomized, placebo-controlled studies in two animal models of inhalational anthrax to assess the efficacy of raxibacumab administered as a prophylactic agent and after the onset of systemic disease. We then assessed the safety in human subjects of a dose of raxibacumab that provided a survival benefit in animals.\n\n【12】Methods\n-------\n\n【13】Study Agent\n-----------\n\n【14】Raxibacumab is a recombinant, fully human, IgG1λ monoclonal antibody directed against _B. anthracis_ protective antigen. This agent inhibits protective antigen binding to the anthrax toxin receptor with a 50% inhibitory concentration of 0.5 nM, or 50% of the maximal inhibition of receptor binding. Raxibacumab inhibits toxin-mediated cell death in a murine macrophage-based assay  and death in a rat model .  Raxibacumab and matching placebo were supplied as a liquid formulation and stored in sterile, single-use vials at 2 to 8°C.\n\n【15】Design of Studies in Animals\n----------------------------\n\n【16】Challenge studies involving _B. anthracis_ spores were conducted in biosafety level 3 facilities at the Battelle Biomedical Research Center in Columbus, Ohio. The aerosol concentrations of _B. anthracis_ spores (Ames strain) delivered were quantified by determination of colony-forming units in the effluent streams ( Supplementary Appendix ). The protocols were approved by the Institutional Animal Care and Use Committee at the Battelle Biomedical Research Center, and the efficacy studies were conducted according to Good Laboratory Practice guidelines.\n\n【17】Prophylactic Studies\n--------------------\n\n【18】These studies were open label, parallel-group, randomized, and placebo-controlled. New Zealand white rabbits ( _Oryctolagus cuniculus_ ) were randomly assigned to six groups of 12 animals each to receive either a single subcutaneous dose of placebo or raxibacumab at 1, 5, 10, or 20 mg per kilogram of body weight on day −2, or a single intravenous dose of raxibacumab at 40 mg per kilogram immediately after spore challenge on day 0. In a separate study, cynomolgus macaques ( _Macaca fascicularis_ ) were randomly assigned to four groups of 10 animals per group to receive either a single subcutaneous dose of placebo or raxibacumab at 10, 20, or 40 mg per kilogram on day −2. On day 0, all rabbits or monkeys were exposed to _B. anthracis_ spores at a target dose that was 100 times the median lethal dose. The study end points were survival time (defined as the time from spore challenge to death) and survival at day 14 (in rabbits) or day 28 (in monkeys).\n\n【19】To assess the susceptibility of survivors to rechallenge 1 year later, 21 monkeys (11 males and 10 females) that survived the anthrax-spore challenge and 6 monkeys (3 males and 3 females) that had not previously received treatment were exposed to _B. anthracis_ spores at a target dose of 100 times the median lethal dose, without any interventions, and survival at day 28 was assessed.\n\n【20】Disease Characterization\n------------------------\n\n【21】Studies to evaluate markers of the disease course of inhalation anthrax were conducted in rabbits and monkeys. The objectives of each study were to examine the time to the appearance of laboratory and clinical abnormalities and to identify an optimal time window for therapeutic intervention. Eight New Zealand white rabbits or cynomolgus macaques were exposed to a target dose of _B. anthracis_ spores that was 200 times the median lethal dose. Clinical findings, the temperature of the animals, the level of protective antigen in serum, and the presence or absence of bacteremia detected in culture and by means of polymerase-chain-reaction (PCR) assays were assessed. The primary analysis examined the relationship between survival time and the onset of clinical variables that were indicative of anthrax infection.\n\n【22】Therapeutic Efficacy in Rabbits\n-------------------------------\n\n【23】An open-label, parallel-group, randomized, placebo-controlled study conducted according to Good Laboratory Practice guidelines evaluated the therapeutic efficacy of raxibacumab in rabbits exposed to aerosolized anthrax spores. Fifty-four New Zealand white rabbits were randomly assigned according to sex and body weight to three groups of 18 rabbits each and were challenged on day 0 with a targeted dose of _B. anthracis_ spores that was 200 times the median lethal dose. On detection of protective antigen in serum or an increase in body temperature of 1.1°C (2°F) or more above the baseline value, individual rabbits were given a single-bolus intravenous injection of either raxibacumab (20 or 40 mg per kilogram) or placebo. The primary efficacy end point was survival at day 14, defined as the percentage of rabbits that were alive at day 14. The secondary efficacy end point was survival time, defined as the time from spore challenge to death during the 14-day period.\n\n【24】Therapeutic Efficacy in Monkeys\n-------------------------------\n\n【25】A blinded, parallel-group, randomized, placebo-controlled study conducted according to Good Laboratory Practice guidelines evaluated the therapeutic efficacy of raxibacumab in monkeys exposed to aerosolized anthrax spores. Forty cynomolgus monkeys that had not received treatment previously were randomly assigned according to sex to two groups of 14 monkeys each and one group of 12 monkeys and were challenged with a target dose of _B. anthracis_ spores (Ames strain) that was 200 times the median lethal dose. On detection of protective antigen in serum, individual monkeys were given a single-bolus intravenous injection of raxibacumab (either 20 mg per kilogram or 40 mg per kilogram) or placebo. The primary efficacy end point was survival at day 28, defined as the percentage of monkeys that were alive at day 28. The secondary efficacy end point was survival time, defined as the time from spore challenge to death during the 28-day period.\n\n【26】Design of Safety Studies in Humans\n----------------------------------\n\n【27】A total of four raxibacumab studies in healthy human volunteers were conducted in the United States ( Supplementary Appendix ). The institutional review boards of the participating centers approved the protocols. All volunteers provided written informed consent. Human Genome Sciences sponsored the studies and was responsible for data collection and statistical analyses. These studies were conducted according to the International Conference on Harmonisation Good Clinical Practice standards.\n\n【28】This randomized, single-blind, placebo-controlled study to evaluate the adverse-event profile of raxibacumab at a dose of 40 mg per kilogram was conducted at six U.S. sites from March through July 2008. A total of 438 subjects were randomly assigned to one of two raxibacumab groups (one received a single dose, and the other a double dose) or to one of two matching placebo groups. Subjects in the double-dose cohort received a dose on day 0 and day 14 of the study. Randomization with the use of a centralized, interactive voice-response system assigned subjects in blocks of eight in a ratio of  to receive either raxibacumab or placebo. Randomization was stratified according to age (<65 or ≥65 years of age). The primary objective of the study was to evaluate the safety and tolerability of raxibacumab in healthy subjects. The secondary objective was to determine serum concentrations of raxibacumab for use in a population pharmacokinetic analysis. Raxibacumab or placebo (250 ml) was administered as an intravenous infusion over a period of 2 hours.\n\n【29】The authors designed the studies in animals and humans and collected and analyzed the data. All the authors vouch for the completeness and accuracy of the data presented.\n\n【30】Assays\n------\n\n【31】The level of protective antigen in serum was measured by means of an electrochemiluminescence-based assay with a limit of quantitation of protective antigen of 0.6 ng per milliliter in undiluted rabbit serum and 1 ng per milliliter in cynomolgus serum. Bacteremia was assessed in whole blood streaked on blood-agar plates with macroscopical observation for bacterial colonies. Anti–protective antigen antibody titers were determined by means of an enzyme-linked immunosorbent assay, and toxin neutralization activity was assessed with the use of a cell-based assay measuring inhibition of cytotoxicity caused by lethal toxin.  Details are provided in the Supplementary Appendix .\n\n【32】Statistical Analysis\n--------------------\n\n【33】For the prophylactic studies, the primary analysis was performed in the intention-to-treat population and compared survival at day 14 (in rabbits) or day 28 (in monkeys) between the raxibacumab groups and the placebo group with the use of a two-sided Fisher's exact test. The Cochran–Armitage test was used to examine the dose–response trend for survival at day 14 or day 28 across all groups. The survival time was compared between the raxibacumab groups and the placebo group with the use of the log-rank test. For the disease-characterization studies, Spearman correlation coefficients were used to assess the correlation between survival time and the time to onset of bacteremia (detected in culture and by means of PCR analysis), time to detectable protective antigen in serum, and time to a clinically significant increase in body temperature. All reported P values are two-sided and have not been adjusted for multiplicity.\n\n【34】The therapeutic-intervention studies involving rabbits and monkeys had prespecified primary end points and analyses. The sample size in the rabbit study (18 animals per group) was chosen to provide 80% power at a 5% significance level to detect an absolute improvement in survival of 45 percentage points or more in one of the raxibacumab groups, as compared with the placebo group. Limitation on the number of monkeys reduced the power of the second study to 74% to detect an improvement of 45 percentage points or more.\n\n【35】For analysis of the primary efficacy end point, survival at day 14 (in rabbits) or day 28 (in monkeys) was compared between the placebo group and each of the raxibacumab groups in the intention-to-treat population (defined as all animals that underwent randomization and spore challenge) with the use of a two-sided Fisher's exact test. The primary analysis in the rabbit study was adjusted for multiple comparisons with the use of the Hochberg procedure ( Supplementary Appendix ). The primary analysis in the monkey study was adjusted for multiple comparisons with the use of the step-down sequential testing procedure. Prespecified subgroup analysis of the primary efficacy end points was performed in animals based on detection of protective antigen, bacteria, and elevated temperature (in rabbits only) before treatment. The Kaplan–Meier method was used to estimate the median survival time and other time-to-event variables.\n\n【36】Results\n-------\n\n【37】Prophylactic Efficacy of Raxibacumab\n------------------------------------\n\n【38】Figure 1. Improved Survival in Rabbits and Monkeys with Administration of Raxibacumab before Inhalation of _B. anthracis_ Spores.\n\n【39】Raxibacumab (at a dose of 1, 5, 10, or 20 mg per kilogram of body weight in New Zealand white rabbits and a dose of 10, 20, or 40 mg per kilogram in cynomolgus monkeys) or placebo was administered subcutaneously 2 days before exposure or at the time of exposure (at a dose of 40 mg per kilogram intravenously in rabbits), with a target dose that was 100 times the median lethal dose of inhaled _B. anthracis_ spores. Survival is shown for rabbits in all treatment groups versus controls  and for monkeys in all treatment groups versus controls . The P values were calculated with the use of a log-rank test for the comparison of the survival time between each active-treatment group and the placebo group. IV denotes intravenous, and SC subcutaneous.\n\n【40】In rabbits , doses of raxibacumab of 10 mg per kilogram or higher provided a significant benefit with respect to the primary end point, the 14-day survival rate (80 to 100%, as compared with 0% with placebo; P<0.001). Survival was significantly longer in all raxibacumab groups, and a significant dose–response trend for survival at day 14 (P<0.001) was observed. Given the dose–response observed in rabbits, only the higher subcutaneous raxibacumab doses — 10, 20, and 40 mg per kilogram — were assessed in cynomolgus monkeys. The 28-day survival rate was significantly higher in all raxibacumab groups than in the placebo group  (70 to 90% in the groups that received 20 and 40 mg per kilogram, respectively, vs. 0% in the placebo group; P<0.001). The median survival was significantly longer in all the active-treatment groups than in the placebo group. More than 6 months after challenge, all monkeys that survived had an increase by a factor of 5 to 74 (mean \\[±SD\\], 28±22) in the total anti–protective antigen titer over the baseline value ( Supplementary Appendix ). These 21 monkeys were protected when rechallenged with inhaled anthrax spores approximately 1 year later, whereas 100% of the animals that received placebo at rechallenge died.\n\n【41】Protective Antigen in Serum during Systemic Anthrax Infection\n-------------------------------------------------------------\n\n【42】Figure 2. Inhalational Anthrax in Rabbits and Monkeys.\n\n【43】Time to events (death, first detection of protective antigen, first detection of bacteremia by blood culture or polymerase-chain-reaction \\[PCR\\] assay, and increase in body temperature) is shown for rabbits  and monkeys , with Pearson correlation coefficients for time to death. In both animal species, protective antigen in serum and bacteremia by culture or PCR assay were the earliest indicators of anthrax disease. Survival time was strongly correlated with the presence or absence of protective antigen in both species.\n\n【44】Clinical and laboratory changes associated with the onset of systemic infection after inhalation of spores in the rabbit and monkey studies were characterized in order to define objective triggers for therapeutic intervention. The median time to the first detection of protective antigen in serum was 30 hours in rabbits and 39 hours in monkeys. In both the rabbits and monkeys, detectable protective antigen in serum and bacteremia detected by culture or PCR appeared to be the first indicators of disease, followed by changes in temperature . These findings justified the use of the detection of protective antigen in serum as the trigger for treatment in rabbits and cynomolgus monkeys, given its high correlation with the first detection of bacteremia (r≥0.90) and the time to death (r≥0.90) in both animal species.\n\n【45】Therapeutic Efficacy of Raxibacumab\n-----------------------------------\n\n【46】Figure 3. Improved Survival with Raxibacumab in Rabbits and Monkeys after the Onset of Systemic Illness.\n\n【47】Survival after treatment with a single dose of intravenous raxibacumab at 20 mg per kilogram of body weight or 40 mg per kilogram in rabbits  and in monkeys  that had signs of inhalational anthrax is indicated by detectable protective antigen in serum. Absolute improvement in survival in all animals is shown in Panel C (rabbits) and Panel D (monkeys). The P values were calculated with the use of a log-rank test for the comparison of the survival time in each active-treatment group with that in the placebo group. The absolute improvement in survival (point estimates and 95% confidence intervals) among animals in the treatment group that received 40 mg per kilogram and the treatment group that received 20 mg per kilogram, as compared with placebo, is shown in Panels C and D. The primary efficacy analysis in the intention-to-treat population and the results for the subgroups (according to status with respect to toxemia, bacteremia, and increased temperature at the time of administration of the study agent) are shown. The dashed vertical line indicates the point estimate of the survival benefit in the intention-to-treat population. The 95% confidence intervals were calculated with the use of an unconditional exact method. For 95% confidence intervals that excluded 0, the statistical significance should be interpreted according to results from the Fisher's exact test based on a conditional method.\n\n【48】An efficacy study of raxibacumab in rabbits and a confirmatory study of raxibacumab in cynomolgus monkeys were conducted. As shown in Figure 3A , the primary end point (survival at day 14) was met in the rabbit study, with improved survival in the group that received 20 mg of raxibacumab per kilogram (28%) and the group that received 40 mg per kilogram (44%), as compared with placebo (0%; P=0.02 and P=0.003, respectively). The difference in survival between the two raxibacumab groups was not significant (17%; 95% confidence interval \\[CI\\], −16 to 47; P=0.30). Survival was significantly prolonged in the groups that received 20 and 40 mg per kilogram of raxibacumab (median, 3.5 days, P=0.018, and median, 3.8 days, P=0.003, respectively) versus placebo (median, 2.7 days) . The primary end point (survival at day 28) was also met in monkeys, with improved survival in the group that received 20 mg of raxibacumab per kilogram (50%) and the group that received 40 mg per kilogram (64%), as compared with placebo (0%; P=0.003 and P<0.001, respectively) . Survival did not differ significantly between the two raxibacumab groups (absolute difference, 14 percentage points; 95% CI, −24 to 54; P=0.44). Survival was significantly longer in the groups that received 20 and 40 mg of raxibacumab per kilogram (median survival, >28 days) than in the group that received placebo (median, 3.3 days; P=0.003 and P<0.001, respectively) . Positive toxin neutralization activity titers developed in surviving monkeys by postchallenge day 28.\n\n【49】The survival benefit with raxibacumab was robust and was observed across all prespecified subgroups in rabbits and monkeys . In all subgroups of animals confirmed to have bacteremia, toxemia, or both at or before the time of treatment initiation, there was a significant survival benefit associated with 20 or 40 mg of raxibacumab per kilogram as compared with placebo. The majority of survivors had negative _B. anthracis_ blood cultures by 10 to 24 hours after treatment, and all surviving animals had negative blood cultures at the end of the study. The kinetic analysis of protective antigen in serum showed higher levels and a greater magnitude of increase in animals that died than in surviving animals ( Supplementary Appendix ). In both studies, gross findings at necropsy were consistent with death due to inhalational anthrax, and histopathological analysis revealed microscopical lesions that were characteristic of inhalational anthrax ( Supplementary Appendix ).\n\n【50】Safety of Raxibacumab in Human Subjects\n---------------------------------------\n\n【51】Table 1. Baseline Characteristics of the Human Subjects.\n\n【52】Human safety tests with raxibacumab included 333 subjects who received intravenous raxibacumab at a dose of 40 mg per kilogram, the dose recommended for licensure ( Supplementary Appendix ). The demographic characteristics of the subjects are summarized in Table 1 . The characteristics were well balanced between the raxibacumab and placebo groups.\n\n【53】Table 2. Adverse Events during Treatment.\n\n【54】After the administration of raxibacumab alone or in combination with ciprofloxacin, there was a single report of a serious adverse event that was considered to be at least possibly related to raxibacumab; this case of cholecystitis was judged by the investigator to be most likely related to an underlying condition. Most adverse events were mild to moderate in severity and transient; their incidence did not differ significantly between the raxibacumab and placebo groups .\n\n【55】Pharmacokinetics of Raxibacumab in Humans and Animals\n-----------------------------------------------------\n\n【56】Figure 4. Pharmacokinetics of Raxibacumab in Humans, Rabbits, and Monkeys and Predictors of Survival.\n\n【57】As shown in Panel A, the pharmacokinetics of a single intravenous dose of 40 mg of raxibacumab per kilogram of body weight in monkeys, rabbits, and humans indicated that the pharmacokinetic properties are translatable across the three species. AUC denotes area under the curve, CL clearance, C <sub>max </sub> maximum concentration of the drug, MRT mean residence time, and V <sub>ss </sub> volume of distribution at steady state. As shown in Panel B, in rabbits and monkeys, the ratio of raxibacumab to protective antigen in serum at the time of therapeutic intervention was associated with improved survival rates (odds ratio) or survival time (hazard ratio for death). In Panel C, the relationship of serum levels of raxibacumab (intravenous administration of 40 mg per kilogram in a single dose) in humans to maximum levels of protective antigen in serum in animals that died of inhalational anthrax is shown. A single dose is sufficient to ensure that 95% or more of the human population, at 28 days relative to monkeys and at 48 days relative to rabbits, can be expected to have levels of serum raxibacumab that are equal to or greater than the highest observed levels of protective antigen in animals at the time of death.\n\n【58】In rabbits, monkeys, and humans, raxibacumab had consistent and predictable pharmacokinetic properties, with similar peak exposures across the species . The longer half-life of raxibacumab in humans, as compared with that in the animal species, resulted in greater overall exposure in humans. Furthermore, 40 mg per kilogram of raxibacumab does not alter antibiotic safety or pharmacokinetic properties, allowing for concomitant administration ( Supplementary Appendix ).\n\n【59】To translate the effective doses in animals into appropriate doses in humans, the ratio of the raxibacumab concentration to the protective antigen concentration in serum at the time of therapeutic intervention was assessed. A higher ratio of raxibacumab to protective antigen at the time of treatment resulted in an improved survival rate and survival time in both rabbits and monkeys . This finding emphasizes the need for early intervention before levels of protective antigen reach lethal levels and suggests the potential benefit of the 40-mg-per-kilogram dose as compared with the 20-mg-per-kilogram dose. As shown in Figure 4C , a single dose of 40 mg of raxibacumab per kilogram is sufficient to ensure that 95% or more of the human population, for at least 28 days, will have serum raxibacumab levels in excess of the highest observed levels of protective antigen in animals at the time of death.\n\n【60】Discussion\n----------\n\n【61】New treatments directed at neutralizing anthrax toxins are needed.  The criteria for demonstrating efficacy in animals when it is not ethical or feasible to conduct studies in humans have been described by the Food and Drug Administration in the “animal rule.” The development program for raxibacumab meets all requirements under this rule, as enumerated below.\n\n【62】First, the pathophysiological mechanism for the effects of protective antigen and its amelioration or prevention by raxibacumab should be well understood. The mechanisms underlying the effects of anthrax toxin and its contributions to tissue injury have been elucidated.  We have shown that raxibacumab binds protective antigen with high affinity and specifically blocks the binding of protective antigen to its receptor, preventing anthrax toxin–mediated damage. Second, effectiveness must be demonstrated in more than one animal species expected to have a response that is predictive for humans, and the end point in studies in animals must be clearly related to the desired benefit in humans. Our studies in rabbits and monkeys confirm that the course of inhalational anthrax has pathophysiological features and outcomes that are similar to those in humans. We have shown that raxibacumab improved survival among rabbits and monkeys with evidence of systemic disease after a lethal exposure to inhaled _B. anthracis_ spores (approximately 200 times the median lethal dose). In both rabbits and monkeys, raxibacumab significantly increased the overall survival rate and the time to death. Finally, the pharmacokinetic properties of the product in animals and humans should be sufficiently well understood to allow selection of an effective dose in humans. We found that a dose of 40 mg of raxibacumab per kilogram in humans results in levels of serum raxibacumab that are similar to or greater than those that provide a survival benefit in animal models. The safety profile in humans provides support for the use of raxibacumab, particularly in the clinical setting of immediately life-threatening inhalational anthrax disease.\n\n【63】Although antibiotics are the mainstay of initial treatment after exposure to _B. anthracis,_ clinical experience has highlighted the need for additional measures to address the significant morbidity observed.  Our data indicate that early intervention (before the logarithmic increase in levels of protective antigen) is associated with significantly better survival in animals. Hence, in patients with a high clinical index of suspicion for inhalational anthrax infection, we anticipate the use of raxibacumab concomitantly with antibiotics or when the initial use of antibiotics is associated with a suboptimal clinical response.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": " ( Supplementary Appendix )", "content": "【0】Raxibacumab for the Treatment of Inhalational Anthrax\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Inhalational anthrax caused by _Bacillus anthracis_ is associated with high mortality primarily due to toxin-mediated injury. Raxibacumab is a human IgG1λ monoclonal antibody directed against protective antigen, a component of the anthrax toxin.\n\n【3】Methods\n-------\n\n【4】We evaluated the efficacy of raxibacumab as a prophylactic agent and after disease onset in a total of four randomized, placebo-controlled studies conducted in rabbits and monkeys. Animals were exposed to an aerosolized target exposure of _B. anthracis_ spores that was approximately 100 times (in the prophylactic studies) and 200 times (in the therapeutic-intervention studies) the median lethal dose. In the therapeutic-intervention studies, animals were monitored for the onset of symptoms. Animals with detectable protective antigen in serum, a significant increase in temperature, or both received a single intravenous bolus of placebo or raxibacumab at a dose of either 20 mg per kilogram of body weight or 40 mg per kilogram. The primary end point was survival at day 14 (in rabbits) or at day 28 (in monkeys). Safety studies were conducted with intravenous raxibacumab (40 mg per kilogram) in 333 healthy human volunteers.\n\n【5】Results\n-------\n\n【6】In both rabbits and monkeys, the time to detection of protective antigen correlated with the time to bacteremia (r=0.9, P<0.001). In the therapeutic-intervention studies, the survival rate was significantly higher among rabbits that received raxibacumab at a dose of 40 mg per kilogram (44% \\[8 of 18\\]) than among rabbits that received placebo (0% \\[0 of 18\\]; P=0.003). Raxibacumab treatment also significantly increased survival in monkeys (64% \\[9 of 14\\], vs. 0% \\[0 of 12\\] with placebo; P<0.001). In human subjects, intravenous raxibacumab at a dose of 40 mg per kilogram had a half-life of 20 to 22 days and provided a maximum concentration of the drug in excess of levels that are protective in animals. Concentrations of raxibacumab provide a surrogate end point that should be predictive of clinical benefit.\n\n【7】Conclusions\n-----------\n\n【8】A single dose of raxibacumab improved survival in rabbits and monkeys with symptomatic inhalational anthrax. \n\n【9】Introduction\n------------\n\n【10】_Bacillus anthracis_ causes anthrax, a zoonotic infection affecting a wide range of mammalian species, and it can be transmitted from animals to humans.  The innate hardiness of _B. anthracis_ endospores has allowed anthrax spores to be developed as “weapons-grade” material for biologic weapons.  The largest outbreak of inhalational anthrax occurred in 1979 in Sverdlovsk (in the former Soviet Union),  and the 2001 anthrax attacks were the first confirmed outbreak associated with intentional anthrax release in the United States.  Inhalational anthrax exposure rapidly progresses to bacteremia and toxemia, with mortality ranging from 45 to 80%.  Although several antibiotics have potent bactericidal activity,  there is a considerable unmet need for agents to counter toxin-mediated illness and death in the treatment of inhalational anthrax. The anthrax toxin is a tripartite toxin that comprises lethal factor and edema factor as the enzymatic moieties of the toxin and protective antigen as the binding moiety.  Blocking the binding of protective antigen to its host receptors can counter the deleterious effects of the anthrax toxin  and provides the basis for vaccine  and passive immunization with anti–protective antigen immunoglobulin. \n\n【11】Current guidelines include administration of antibiotics for up to 60 days and the AVA (anthrax vaccine adsorbed) vaccine after exposure to _B. anthracis_ spores.  The clinical presentation of inhalational anthrax in nonhuman primates and rabbits is similar to that in humans,  and studies conducted in animals that received postexposure prophylaxis provided the basis for approval of these agents for use in humans.  Raxibacumab is a fully human monoclonal antibody directed against _B. anthracis_ protective antigen.  We conducted randomized, placebo-controlled studies in two animal models of inhalational anthrax to assess the efficacy of raxibacumab administered as a prophylactic agent and after the onset of systemic disease. We then assessed the safety in human subjects of a dose of raxibacumab that provided a survival benefit in animals.\n\n【12】Methods\n-------\n\n【13】Study Agent\n-----------\n\n【14】Raxibacumab is a recombinant, fully human, IgG1λ monoclonal antibody directed against _B. anthracis_ protective antigen. This agent inhibits protective antigen binding to the anthrax toxin receptor with a 50% inhibitory concentration of 0.5 nM, or 50% of the maximal inhibition of receptor binding. Raxibacumab inhibits toxin-mediated cell death in a murine macrophage-based assay  and death in a rat model .  Raxibacumab and matching placebo were supplied as a liquid formulation and stored in sterile, single-use vials at 2 to 8°C.\n\n【15】Design of Studies in Animals\n----------------------------\n\n【16】Challenge studies involving _B. anthracis_ spores were conducted in biosafety level 3 facilities at the Battelle Biomedical Research Center in Columbus, Ohio. The aerosol concentrations of _B. anthracis_ spores (Ames strain) delivered were quantified by determination of colony-forming units in the effluent streams ( Supplementary Appendix ). The protocols were approved by the Institutional Animal Care and Use Committee at the Battelle Biomedical Research Center, and the efficacy studies were conducted according to Good Laboratory Practice guidelines.\n\n【17】Prophylactic Studies\n--------------------\n\n【18】These studies were open label, parallel-group, randomized, and placebo-controlled. New Zealand white rabbits ( _Oryctolagus cuniculus_ ) were randomly assigned to six groups of 12 animals each to receive either a single subcutaneous dose of placebo or raxibacumab at 1, 5, 10, or 20 mg per kilogram of body weight on day −2, or a single intravenous dose of raxibacumab at 40 mg per kilogram immediately after spore challenge on day 0. In a separate study, cynomolgus macaques ( _Macaca fascicularis_ ) were randomly assigned to four groups of 10 animals per group to receive either a single subcutaneous dose of placebo or raxibacumab at 10, 20, or 40 mg per kilogram on day −2. On day 0, all rabbits or monkeys were exposed to _B. anthracis_ spores at a target dose that was 100 times the median lethal dose. The study end points were survival time (defined as the time from spore challenge to death) and survival at day 14 (in rabbits) or day 28 (in monkeys).\n\n【19】To assess the susceptibility of survivors to rechallenge 1 year later, 21 monkeys (11 males and 10 females) that survived the anthrax-spore challenge and 6 monkeys (3 males and 3 females) that had not previously received treatment were exposed to _B. anthracis_ spores at a target dose of 100 times the median lethal dose, without any interventions, and survival at day 28 was assessed.\n\n【20】Disease Characterization\n------------------------\n\n【21】Studies to evaluate markers of the disease course of inhalation anthrax were conducted in rabbits and monkeys. The objectives of each study were to examine the time to the appearance of laboratory and clinical abnormalities and to identify an optimal time window for therapeutic intervention. Eight New Zealand white rabbits or cynomolgus macaques were exposed to a target dose of _B. anthracis_ spores that was 200 times the median lethal dose. Clinical findings, the temperature of the animals, the level of protective antigen in serum, and the presence or absence of bacteremia detected in culture and by means of polymerase-chain-reaction (PCR) assays were assessed. The primary analysis examined the relationship between survival time and the onset of clinical variables that were indicative of anthrax infection.\n\n【22】Therapeutic Efficacy in Rabbits\n-------------------------------\n\n【23】An open-label, parallel-group, randomized, placebo-controlled study conducted according to Good Laboratory Practice guidelines evaluated the therapeutic efficacy of raxibacumab in rabbits exposed to aerosolized anthrax spores. Fifty-four New Zealand white rabbits were randomly assigned according to sex and body weight to three groups of 18 rabbits each and were challenged on day 0 with a targeted dose of _B. anthracis_ spores that was 200 times the median lethal dose. On detection of protective antigen in serum or an increase in body temperature of 1.1°C (2°F) or more above the baseline value, individual rabbits were given a single-bolus intravenous injection of either raxibacumab (20 or 40 mg per kilogram) or placebo. The primary efficacy end point was survival at day 14, defined as the percentage of rabbits that were alive at day 14. The secondary efficacy end point was survival time, defined as the time from spore challenge to death during the 14-day period.\n\n【24】Therapeutic Efficacy in Monkeys\n-------------------------------\n\n【25】A blinded, parallel-group, randomized, placebo-controlled study conducted according to Good Laboratory Practice guidelines evaluated the therapeutic efficacy of raxibacumab in monkeys exposed to aerosolized anthrax spores. Forty cynomolgus monkeys that had not received treatment previously were randomly assigned according to sex to two groups of 14 monkeys each and one group of 12 monkeys and were challenged with a target dose of _B. anthracis_ spores (Ames strain) that was 200 times the median lethal dose. On detection of protective antigen in serum, individual monkeys were given a single-bolus intravenous injection of raxibacumab (either 20 mg per kilogram or 40 mg per kilogram) or placebo. The primary efficacy end point was survival at day 28, defined as the percentage of monkeys that were alive at day 28. The secondary efficacy end point was survival time, defined as the time from spore challenge to death during the 28-day period.\n\n【26】Design of Safety Studies in Humans\n----------------------------------\n\n【27】A total of four raxibacumab studies in healthy human volunteers were conducted in the United States ( Supplementary Appendix ). The institutional review boards of the participating centers approved the protocols. All volunteers provided written informed consent. Human Genome Sciences sponsored the studies and was responsible for data collection and statistical analyses. These studies were conducted according to the International Conference on Harmonisation Good Clinical Practice standards.\n\n【28】This randomized, single-blind, placebo-controlled study to evaluate the adverse-event profile of raxibacumab at a dose of 40 mg per kilogram was conducted at six U.S. sites from March through July 2008. A total of 438 subjects were randomly assigned to one of two raxibacumab groups (one received a single dose, and the other a double dose) or to one of two matching placebo groups. Subjects in the double-dose cohort received a dose on day 0 and day 14 of the study. Randomization with the use of a centralized, interactive voice-response system assigned subjects in blocks of eight in a ratio of  to receive either raxibacumab or placebo. Randomization was stratified according to age (<65 or ≥65 years of age). The primary objective of the study was to evaluate the safety and tolerability of raxibacumab in healthy subjects. The secondary objective was to determine serum concentrations of raxibacumab for use in a population pharmacokinetic analysis. Raxibacumab or placebo (250 ml) was administered as an intravenous infusion over a period of 2 hours.\n\n【29】The authors designed the studies in animals and humans and collected and analyzed the data. All the authors vouch for the completeness and accuracy of the data presented.\n\n【30】Assays\n------\n\n【31】The level of protective antigen in serum was measured by means of an electrochemiluminescence-based assay with a limit of quantitation of protective antigen of 0.6 ng per milliliter in undiluted rabbit serum and 1 ng per milliliter in cynomolgus serum. Bacteremia was assessed in whole blood streaked on blood-agar plates with macroscopical observation for bacterial colonies. Anti–protective antigen antibody titers were determined by means of an enzyme-linked immunosorbent assay, and toxin neutralization activity was assessed with the use of a cell-based assay measuring inhibition of cytotoxicity caused by lethal toxin.  Details are provided in the Supplementary Appendix .\n\n【32】Statistical Analysis\n--------------------\n\n【33】For the prophylactic studies, the primary analysis was performed in the intention-to-treat population and compared survival at day 14 (in rabbits) or day 28 (in monkeys) between the raxibacumab groups and the placebo group with the use of a two-sided Fisher's exact test. The Cochran–Armitage test was used to examine the dose–response trend for survival at day 14 or day 28 across all groups. The survival time was compared between the raxibacumab groups and the placebo group with the use of the log-rank test. For the disease-characterization studies, Spearman correlation coefficients were used to assess the correlation between survival time and the time to onset of bacteremia (detected in culture and by means of PCR analysis), time to detectable protective antigen in serum, and time to a clinically significant increase in body temperature. All reported P values are two-sided and have not been adjusted for multiplicity.\n\n【34】The therapeutic-intervention studies involving rabbits and monkeys had prespecified primary end points and analyses. The sample size in the rabbit study (18 animals per group) was chosen to provide 80% power at a 5% significance level to detect an absolute improvement in survival of 45 percentage points or more in one of the raxibacumab groups, as compared with the placebo group. Limitation on the number of monkeys reduced the power of the second study to 74% to detect an improvement of 45 percentage points or more.\n\n【35】For analysis of the primary efficacy end point, survival at day 14 (in rabbits) or day 28 (in monkeys) was compared between the placebo group and each of the raxibacumab groups in the intention-to-treat population (defined as all animals that underwent randomization and spore challenge) with the use of a two-sided Fisher's exact test. The primary analysis in the rabbit study was adjusted for multiple comparisons with the use of the Hochberg procedure ( Supplementary Appendix ). The primary analysis in the monkey study was adjusted for multiple comparisons with the use of the step-down sequential testing procedure. Prespecified subgroup analysis of the primary efficacy end points was performed in animals based on detection of protective antigen, bacteria, and elevated temperature (in rabbits only) before treatment. The Kaplan–Meier method was used to estimate the median survival time and other time-to-event variables.\n\n【36】Results\n-------\n\n【37】Prophylactic Efficacy of Raxibacumab\n------------------------------------\n\n<mark>【38】Figure 1.</mark> Improved Survival in Rabbits and Monkeys with Administration of Raxibacumab before Inhalation of _B. anthracis_ Spores.\n\n【39】Raxibacumab (at a dose of 1, 5, 10, or 20 mg per kilogram of body weight in New Zealand white rabbits and a dose of 10, 20, or 40 mg per kilogram in cynomolgus monkeys) or placebo was administered subcutaneously 2 days before exposure or at the time of exposure (at a dose of 40 mg per kilogram intravenously in rabbits), with a target dose that was 100 times the median lethal dose of inhaled _B. anthracis_ spores. Survival is shown for rabbits in all treatment groups versus controls  and for monkeys in all treatment groups versus controls . The P values were calculated with the use of a log-rank test for the comparison of the survival time between each active-treatment group and the placebo group. IV denotes intravenous, and SC subcutaneous.\n\n【40】In rabbits , doses of raxibacumab of 10 mg per kilogram or higher provided a significant benefit with respect to the primary end point, the 14-day survival rate (80 to 100%, as compared with 0% with placebo; P<0.001). Survival was significantly longer in all raxibacumab groups, and a significant dose–response trend for survival at day 14 (P<0.001) was observed. Given the dose–response observed in rabbits, only the higher subcutaneous raxibacumab doses — 10, 20, and 40 mg per kilogram — were assessed in cynomolgus monkeys. The 28-day survival rate was significantly higher in all raxibacumab groups than in the placebo group  (70 to 90% in the groups that received 20 and 40 mg per kilogram, respectively, vs. 0% in the placebo group; P<0.001). The median survival was significantly longer in all the active-treatment groups than in the placebo group. More than 6 months after challenge, all monkeys that survived had an increase by a factor of 5 to 74 (mean \\[±SD\\], 28±22) in the total anti–protective antigen titer over the baseline value ( Supplementary Appendix ). These 21 monkeys were protected when rechallenged with inhaled anthrax spores approximately 1 year later, whereas 100% of the animals that received placebo at rechallenge died.\n\n【41】Protective Antigen in Serum during Systemic Anthrax Infection\n-------------------------------------------------------------\n\n【42】Figure 2. Inhalational Anthrax in Rabbits and Monkeys.\n\n【43】Time to events (death, first detection of protective antigen, first detection of bacteremia by blood culture or polymerase-chain-reaction \\[PCR\\] assay, and increase in body temperature) is shown for rabbits  and monkeys , with Pearson correlation coefficients for time to death. In both animal species, protective antigen in serum and bacteremia by culture or PCR assay were the earliest indicators of anthrax disease. Survival time was strongly correlated with the presence or absence of protective antigen in both species.\n\n【44】Clinical and laboratory changes associated with the onset of systemic infection after inhalation of spores in the rabbit and monkey studies were characterized in order to define objective triggers for therapeutic intervention. The median time to the first detection of protective antigen in serum was 30 hours in rabbits and 39 hours in monkeys. In both the rabbits and monkeys, detectable protective antigen in serum and bacteremia detected by culture or PCR appeared to be the first indicators of disease, followed by changes in temperature . These findings justified the use of the detection of protective antigen in serum as the trigger for treatment in rabbits and cynomolgus monkeys, given its high correlation with the first detection of bacteremia (r≥0.90) and the time to death (r≥0.90) in both animal species.\n\n【45】Therapeutic Efficacy of Raxibacumab\n-----------------------------------\n\n【46】Figure 3. Improved Survival with Raxibacumab in Rabbits and Monkeys after the Onset of Systemic Illness.\n\n【47】Survival after treatment with a single dose of intravenous raxibacumab at 20 mg per kilogram of body weight or 40 mg per kilogram in rabbits  and in monkeys  that had signs of inhalational anthrax is indicated by detectable protective antigen in serum. Absolute improvement in survival in all animals is shown in Panel C (rabbits) and Panel D (monkeys). The P values were calculated with the use of a log-rank test for the comparison of the survival time in each active-treatment group with that in the placebo group. The absolute improvement in survival (point estimates and 95% confidence intervals) among animals in the treatment group that received 40 mg per kilogram and the treatment group that received 20 mg per kilogram, as compared with placebo, is shown in Panels C and D. The primary efficacy analysis in the intention-to-treat population and the results for the subgroups (according to status with respect to toxemia, bacteremia, and increased temperature at the time of administration of the study agent) are shown. The dashed vertical line indicates the point estimate of the survival benefit in the intention-to-treat population. The 95% confidence intervals were calculated with the use of an unconditional exact method. For 95% confidence intervals that excluded 0, the statistical significance should be interpreted according to results from the Fisher's exact test based on a conditional method.\n\n【48】An efficacy study of raxibacumab in rabbits and a confirmatory study of raxibacumab in cynomolgus monkeys were conducted. As shown in Figure 3A , the primary end point (survival at day 14) was met in the rabbit study, with improved survival in the group that received 20 mg of raxibacumab per kilogram (28%) and the group that received 40 mg per kilogram (44%), as compared with placebo (0%; P=0.02 and P=0.003, respectively). The difference in survival between the two raxibacumab groups was not significant (17%; 95% confidence interval \\[CI\\], −16 to 47; P=0.30). Survival was significantly prolonged in the groups that received 20 and 40 mg per kilogram of raxibacumab (median, 3.5 days, P=0.018, and median, 3.8 days, P=0.003, respectively) versus placebo (median, 2.7 days) . The primary end point (survival at day 28) was also met in monkeys, with improved survival in the group that received 20 mg of raxibacumab per kilogram (50%) and the group that received 40 mg per kilogram (64%), as compared with placebo (0%; P=0.003 and P<0.001, respectively) . Survival did not differ significantly between the two raxibacumab groups (absolute difference, 14 percentage points; 95% CI, −24 to 54; P=0.44). Survival was significantly longer in the groups that received 20 and 40 mg of raxibacumab per kilogram (median survival, >28 days) than in the group that received placebo (median, 3.3 days; P=0.003 and P<0.001, respectively) . Positive toxin neutralization activity titers developed in surviving monkeys by postchallenge day 28.\n\n【49】The survival benefit with raxibacumab was robust and was observed across all prespecified subgroups in rabbits and monkeys . In all subgroups of animals confirmed to have bacteremia, toxemia, or both at or before the time of treatment initiation, there was a significant survival benefit associated with 20 or 40 mg of raxibacumab per kilogram as compared with placebo. The majority of survivors had negative _B. anthracis_ blood cultures by 10 to 24 hours after treatment, and all surviving animals had negative blood cultures at the end of the study. The kinetic analysis of protective antigen in serum showed higher levels and a greater magnitude of increase in animals that died than in surviving animals ( Supplementary Appendix ). In both studies, gross findings at necropsy were consistent with death due to inhalational anthrax, and histopathological analysis revealed microscopical lesions that were characteristic of inhalational anthrax ( Supplementary Appendix ).\n\n【50】Safety of Raxibacumab in Human Subjects\n---------------------------------------\n\n【51】Table 1. Baseline Characteristics of the Human Subjects.\n\n【52】Human safety tests with raxibacumab included 333 subjects who received intravenous raxibacumab at a dose of 40 mg per kilogram, the dose recommended for licensure ( Supplementary Appendix ). The demographic characteristics of the subjects are summarized in Table 1 . The characteristics were well balanced between the raxibacumab and placebo groups.\n\n【53】Table 2. Adverse Events during Treatment.\n\n【54】After the administration of raxibacumab alone or in combination with ciprofloxacin, there was a single report of a serious adverse event that was considered to be at least possibly related to raxibacumab; this case of cholecystitis was judged by the investigator to be most likely related to an underlying condition. Most adverse events were mild to moderate in severity and transient; their incidence did not differ significantly between the raxibacumab and placebo groups .\n\n【55】Pharmacokinetics of Raxibacumab in Humans and Animals\n-----------------------------------------------------\n\n【56】Figure 4. Pharmacokinetics of Raxibacumab in Humans, Rabbits, and Monkeys and Predictors of Survival.\n\n【57】As shown in Panel A, the pharmacokinetics of a single intravenous dose of 40 mg of raxibacumab per kilogram of body weight in monkeys, rabbits, and humans indicated that the pharmacokinetic properties are translatable across the three species. AUC denotes area under the curve, CL clearance, C <sub>max </sub> maximum concentration of the drug, MRT mean residence time, and V <sub>ss </sub> volume of distribution at steady state. As shown in Panel B, in rabbits and monkeys, the ratio of raxibacumab to protective antigen in serum at the time of therapeutic intervention was associated with improved survival rates (odds ratio) or survival time (hazard ratio for death). In Panel C, the relationship of serum levels of raxibacumab (intravenous administration of 40 mg per kilogram in a single dose) in humans to maximum levels of protective antigen in serum in animals that died of inhalational anthrax is shown. A single dose is sufficient to ensure that 95% or more of the human population, at 28 days relative to monkeys and at 48 days relative to rabbits, can be expected to have levels of serum raxibacumab that are equal to or greater than the highest observed levels of protective antigen in animals at the time of death.\n\n【58】In rabbits, monkeys, and humans, raxibacumab had consistent and predictable pharmacokinetic properties, with similar peak exposures across the species . The longer half-life of raxibacumab in humans, as compared with that in the animal species, resulted in greater overall exposure in humans. Furthermore, 40 mg per kilogram of raxibacumab does not alter antibiotic safety or pharmacokinetic properties, allowing for concomitant administration ( Supplementary Appendix ).\n\n【59】To translate the effective doses in animals into appropriate doses in humans, the ratio of the raxibacumab concentration to the protective antigen concentration in serum at the time of therapeutic intervention was assessed. A higher ratio of raxibacumab to protective antigen at the time of treatment resulted in an improved survival rate and survival time in both rabbits and monkeys . This finding emphasizes the need for early intervention before levels of protective antigen reach lethal levels and suggests the potential benefit of the 40-mg-per-kilogram dose as compared with the 20-mg-per-kilogram dose. As shown in Figure 4C , a single dose of 40 mg of raxibacumab per kilogram is sufficient to ensure that 95% or more of the human population, for at least 28 days, will have serum raxibacumab levels in excess of the highest observed levels of protective antigen in animals at the time of death.\n\n【60】Discussion\n----------\n\n【61】New treatments directed at neutralizing anthrax toxins are needed.  The criteria for demonstrating efficacy in animals when it is not ethical or feasible to conduct studies in humans have been described by the Food and Drug Administration in the “animal rule.” The development program for raxibacumab meets all requirements under this rule, as enumerated below.\n\n【62】First, the pathophysiological mechanism for the effects of protective antigen and its amelioration or prevention by raxibacumab should be well understood. The mechanisms underlying the effects of anthrax toxin and its contributions to tissue injury have been elucidated.  We have shown that raxibacumab binds protective antigen with high affinity and specifically blocks the binding of protective antigen to its receptor, preventing anthrax toxin–mediated damage. Second, effectiveness must be demonstrated in more than one animal species expected to have a response that is predictive for humans, and the end point in studies in animals must be clearly related to the desired benefit in humans. Our studies in rabbits and monkeys confirm that the course of inhalational anthrax has pathophysiological features and outcomes that are similar to those in humans. We have shown that raxibacumab improved survival among rabbits and monkeys with evidence of systemic disease after a lethal exposure to inhaled _B. anthracis_ spores (approximately 200 times the median lethal dose). In both rabbits and monkeys, raxibacumab significantly increased the overall survival rate and the time to death. Finally, the pharmacokinetic properties of the product in animals and humans should be sufficiently well understood to allow selection of an effective dose in humans. We found that a dose of 40 mg of raxibacumab per kilogram in humans results in levels of serum raxibacumab that are similar to or greater than those that provide a survival benefit in animal models. The safety profile in humans provides support for the use of raxibacumab, particularly in the clinical setting of immediately life-threatening inhalational anthrax disease.\n\n【63】Although antibiotics are the mainstay of initial treatment after exposure to _B. anthracis,_ clinical experience has highlighted the need for additional measures to address the significant morbidity observed.  Our data indicate that early intervention (before the logarithmic increase in levels of protective antigen) is associated with significantly better survival in animals. Hence, in patients with a high clinical index of suspicion for inhalational anthrax infection, we anticipate the use of raxibacumab concomitantly with antibiotics or when the initial use of antibiotics is associated with a suboptimal clinical response.", "index": 22635, "show": true, "start": 22622, "end": 22649, "province": ["文本干净度", "无关文本"], "isEdit": false, "comment": "49"}, {"text": "( Supplementary Appendix )", "content": "【0】Raxibacumab for the Treatment of Inhalational Anthrax\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Inhalational anthrax caused by _Bacillus anthracis_ is associated with high mortality primarily due to toxin-mediated injury. Raxibacumab is a human IgG1λ monoclonal antibody directed against protective antigen, a component of the anthrax toxin.\n\n【3】Methods\n-------\n\n【4】We evaluated the efficacy of raxibacumab as a prophylactic agent and after disease onset in a total of four randomized, placebo-controlled studies conducted in rabbits and monkeys. Animals were exposed to an aerosolized target exposure of _B. anthracis_ spores that was approximately 100 times (in the prophylactic studies) and 200 times (in the therapeutic-intervention studies) the median lethal dose. In the therapeutic-intervention studies, animals were monitored for the onset of symptoms. Animals with detectable protective antigen in serum, a significant increase in temperature, or both received a single intravenous bolus of placebo or raxibacumab at a dose of either 20 mg per kilogram of body weight or 40 mg per kilogram. The primary end point was survival at day 14 (in rabbits) or at day 28 (in monkeys). Safety studies were conducted with intravenous raxibacumab (40 mg per kilogram) in 333 healthy human volunteers.\n\n【5】Results\n-------\n\n【6】In both rabbits and monkeys, the time to detection of protective antigen correlated with the time to bacteremia (r=0.9, P<0.001). In the therapeutic-intervention studies, the survival rate was significantly higher among rabbits that received raxibacumab at a dose of 40 mg per kilogram (44% \\[8 of 18\\]) than among rabbits that received placebo (0% \\[0 of 18\\]; P=0.003). Raxibacumab treatment also significantly increased survival in monkeys (64% \\[9 of 14\\], vs. 0% \\[0 of 12\\] with placebo; P<0.001). In human subjects, intravenous raxibacumab at a dose of 40 mg per kilogram had a half-life of 20 to 22 days and provided a maximum concentration of the drug in excess of levels that are protective in animals. Concentrations of raxibacumab provide a surrogate end point that should be predictive of clinical benefit.\n\n【7】Conclusions\n-----------\n\n【8】A single dose of raxibacumab improved survival in rabbits and monkeys with symptomatic inhalational anthrax. \n\n【9】Introduction\n------------\n\n【10】_Bacillus anthracis_ causes anthrax, a zoonotic infection affecting a wide range of mammalian species, and it can be transmitted from animals to humans.  The innate hardiness of _B. anthracis_ endospores has allowed anthrax spores to be developed as “weapons-grade” material for biologic weapons.  The largest outbreak of inhalational anthrax occurred in 1979 in Sverdlovsk (in the former Soviet Union),  and the 2001 anthrax attacks were the first confirmed outbreak associated with intentional anthrax release in the United States.  Inhalational anthrax exposure rapidly progresses to bacteremia and toxemia, with mortality ranging from 45 to 80%.  Although several antibiotics have potent bactericidal activity,  there is a considerable unmet need for agents to counter toxin-mediated illness and death in the treatment of inhalational anthrax. The anthrax toxin is a tripartite toxin that comprises lethal factor and edema factor as the enzymatic moieties of the toxin and protective antigen as the binding moiety.  Blocking the binding of protective antigen to its host receptors can counter the deleterious effects of the anthrax toxin  and provides the basis for vaccine  and passive immunization with anti–protective antigen immunoglobulin. \n\n【11】Current guidelines include administration of antibiotics for up to 60 days and the AVA (anthrax vaccine adsorbed) vaccine after exposure to _B. anthracis_ spores.  The clinical presentation of inhalational anthrax in nonhuman primates and rabbits is similar to that in humans,  and studies conducted in animals that received postexposure prophylaxis provided the basis for approval of these agents for use in humans.  Raxibacumab is a fully human monoclonal antibody directed against _B. anthracis_ protective antigen.  We conducted randomized, placebo-controlled studies in two animal models of inhalational anthrax to assess the efficacy of raxibacumab administered as a prophylactic agent and after the onset of systemic disease. We then assessed the safety in human subjects of a dose of raxibacumab that provided a survival benefit in animals.\n\n【12】Methods\n-------\n\n【13】Study Agent\n-----------\n\n【14】Raxibacumab is a recombinant, fully human, IgG1λ monoclonal antibody directed against _B. anthracis_ protective antigen. This agent inhibits protective antigen binding to the anthrax toxin receptor with a 50% inhibitory concentration of 0.5 nM, or 50% of the maximal inhibition of receptor binding. Raxibacumab inhibits toxin-mediated cell death in a murine macrophage-based assay  and death in a rat model .  Raxibacumab and matching placebo were supplied as a liquid formulation and stored in sterile, single-use vials at 2 to 8°C.\n\n【15】Design of Studies in Animals\n----------------------------\n\n【16】Challenge studies involving _B. anthracis_ spores were conducted in biosafety level 3 facilities at the Battelle Biomedical Research Center in Columbus, Ohio. The aerosol concentrations of _B. anthracis_ spores (Ames strain) delivered were quantified by determination of colony-forming units in the effluent streams ( Supplementary Appendix ). The protocols were approved by the Institutional Animal Care and Use Committee at the Battelle Biomedical Research Center, and the efficacy studies were conducted according to Good Laboratory Practice guidelines.\n\n【17】Prophylactic Studies\n--------------------\n\n【18】These studies were open label, parallel-group, randomized, and placebo-controlled. New Zealand white rabbits ( _Oryctolagus cuniculus_ ) were randomly assigned to six groups of 12 animals each to receive either a single subcutaneous dose of placebo or raxibacumab at 1, 5, 10, or 20 mg per kilogram of body weight on day −2, or a single intravenous dose of raxibacumab at 40 mg per kilogram immediately after spore challenge on day 0. In a separate study, cynomolgus macaques ( _Macaca fascicularis_ ) were randomly assigned to four groups of 10 animals per group to receive either a single subcutaneous dose of placebo or raxibacumab at 10, 20, or 40 mg per kilogram on day −2. On day 0, all rabbits or monkeys were exposed to _B. anthracis_ spores at a target dose that was 100 times the median lethal dose. The study end points were survival time (defined as the time from spore challenge to death) and survival at day 14 (in rabbits) or day 28 (in monkeys).\n\n【19】To assess the susceptibility of survivors to rechallenge 1 year later, 21 monkeys (11 males and 10 females) that survived the anthrax-spore challenge and 6 monkeys (3 males and 3 females) that had not previously received treatment were exposed to _B. anthracis_ spores at a target dose of 100 times the median lethal dose, without any interventions, and survival at day 28 was assessed.\n\n【20】Disease Characterization\n------------------------\n\n【21】Studies to evaluate markers of the disease course of inhalation anthrax were conducted in rabbits and monkeys. The objectives of each study were to examine the time to the appearance of laboratory and clinical abnormalities and to identify an optimal time window for therapeutic intervention. Eight New Zealand white rabbits or cynomolgus macaques were exposed to a target dose of _B. anthracis_ spores that was 200 times the median lethal dose. Clinical findings, the temperature of the animals, the level of protective antigen in serum, and the presence or absence of bacteremia detected in culture and by means of polymerase-chain-reaction (PCR) assays were assessed. The primary analysis examined the relationship between survival time and the onset of clinical variables that were indicative of anthrax infection.\n\n【22】Therapeutic Efficacy in Rabbits\n-------------------------------\n\n【23】An open-label, parallel-group, randomized, placebo-controlled study conducted according to Good Laboratory Practice guidelines evaluated the therapeutic efficacy of raxibacumab in rabbits exposed to aerosolized anthrax spores. Fifty-four New Zealand white rabbits were randomly assigned according to sex and body weight to three groups of 18 rabbits each and were challenged on day 0 with a targeted dose of _B. anthracis_ spores that was 200 times the median lethal dose. On detection of protective antigen in serum or an increase in body temperature of 1.1°C (2°F) or more above the baseline value, individual rabbits were given a single-bolus intravenous injection of either raxibacumab (20 or 40 mg per kilogram) or placebo. The primary efficacy end point was survival at day 14, defined as the percentage of rabbits that were alive at day 14. The secondary efficacy end point was survival time, defined as the time from spore challenge to death during the 14-day period.\n\n【24】Therapeutic Efficacy in Monkeys\n-------------------------------\n\n【25】A blinded, parallel-group, randomized, placebo-controlled study conducted according to Good Laboratory Practice guidelines evaluated the therapeutic efficacy of raxibacumab in monkeys exposed to aerosolized anthrax spores. Forty cynomolgus monkeys that had not received treatment previously were randomly assigned according to sex to two groups of 14 monkeys each and one group of 12 monkeys and were challenged with a target dose of _B. anthracis_ spores (Ames strain) that was 200 times the median lethal dose. On detection of protective antigen in serum, individual monkeys were given a single-bolus intravenous injection of raxibacumab (either 20 mg per kilogram or 40 mg per kilogram) or placebo. The primary efficacy end point was survival at day 28, defined as the percentage of monkeys that were alive at day 28. The secondary efficacy end point was survival time, defined as the time from spore challenge to death during the 28-day period.\n\n【26】Design of Safety Studies in Humans\n----------------------------------\n\n【27】A total of four raxibacumab studies in healthy human volunteers were conducted in the United States ( Supplementary Appendix ). The institutional review boards of the participating centers approved the protocols. All volunteers provided written informed consent. Human Genome Sciences sponsored the studies and was responsible for data collection and statistical analyses. These studies were conducted according to the International Conference on Harmonisation Good Clinical Practice standards.\n\n【28】This randomized, single-blind, placebo-controlled study to evaluate the adverse-event profile of raxibacumab at a dose of 40 mg per kilogram was conducted at six U.S. sites from March through July 2008. A total of 438 subjects were randomly assigned to one of two raxibacumab groups (one received a single dose, and the other a double dose) or to one of two matching placebo groups. Subjects in the double-dose cohort received a dose on day 0 and day 14 of the study. Randomization with the use of a centralized, interactive voice-response system assigned subjects in blocks of eight in a ratio of  to receive either raxibacumab or placebo. Randomization was stratified according to age (<65 or ≥65 years of age). The primary objective of the study was to evaluate the safety and tolerability of raxibacumab in healthy subjects. The secondary objective was to determine serum concentrations of raxibacumab for use in a population pharmacokinetic analysis. Raxibacumab or placebo (250 ml) was administered as an intravenous infusion over a period of 2 hours.\n\n【29】The authors designed the studies in animals and humans and collected and analyzed the data. All the authors vouch for the completeness and accuracy of the data presented.\n\n【30】Assays\n------\n\n【31】The level of protective antigen in serum was measured by means of an electrochemiluminescence-based assay with a limit of quantitation of protective antigen of 0.6 ng per milliliter in undiluted rabbit serum and 1 ng per milliliter in cynomolgus serum. Bacteremia was assessed in whole blood streaked on blood-agar plates with macroscopical observation for bacterial colonies. Anti–protective antigen antibody titers were determined by means of an enzyme-linked immunosorbent assay, and toxin neutralization activity was assessed with the use of a cell-based assay measuring inhibition of cytotoxicity caused by lethal toxin.  Details are provided in the Supplementary Appendix .\n\n【32】Statistical Analysis\n--------------------\n\n【33】For the prophylactic studies, the primary analysis was performed in the intention-to-treat population and compared survival at day 14 (in rabbits) or day 28 (in monkeys) between the raxibacumab groups and the placebo group with the use of a two-sided Fisher's exact test. The Cochran–Armitage test was used to examine the dose–response trend for survival at day 14 or day 28 across all groups. The survival time was compared between the raxibacumab groups and the placebo group with the use of the log-rank test. For the disease-characterization studies, Spearman correlation coefficients were used to assess the correlation between survival time and the time to onset of bacteremia (detected in culture and by means of PCR analysis), time to detectable protective antigen in serum, and time to a clinically significant increase in body temperature. All reported P values are two-sided and have not been adjusted for multiplicity.\n\n【34】The therapeutic-intervention studies involving rabbits and monkeys had prespecified primary end points and analyses. The sample size in the rabbit study (18 animals per group) was chosen to provide 80% power at a 5% significance level to detect an absolute improvement in survival of 45 percentage points or more in one of the raxibacumab groups, as compared with the placebo group. Limitation on the number of monkeys reduced the power of the second study to 74% to detect an improvement of 45 percentage points or more.\n\n【35】For analysis of the primary efficacy end point, survival at day 14 (in rabbits) or day 28 (in monkeys) was compared between the placebo group and each of the raxibacumab groups in the intention-to-treat population (defined as all animals that underwent randomization and spore challenge) with the use of a two-sided Fisher's exact test. The primary analysis in the rabbit study was adjusted for multiple comparisons with the use of the Hochberg procedure ( Supplementary Appendix ). The primary analysis in the monkey study was adjusted for multiple comparisons with the use of the step-down sequential testing procedure. Prespecified subgroup analysis of the primary efficacy end points was performed in animals based on detection of protective antigen, bacteria, and elevated temperature (in rabbits only) before treatment. The Kaplan–Meier method was used to estimate the median survival time and other time-to-event variables.\n\n【36】Results\n-------\n\n【37】Prophylactic Efficacy of Raxibacumab\n------------------------------------\n\n<mark>【38】Figure 1.</mark> Improved Survival in Rabbits and Monkeys with Administration of Raxibacumab before Inhalation of _B. anthracis_ Spores.\n\n【39】Raxibacumab (at a dose of 1, 5, 10, or 20 mg per kilogram of body weight in New Zealand white rabbits and a dose of 10, 20, or 40 mg per kilogram in cynomolgus monkeys) or placebo was administered subcutaneously 2 days before exposure or at the time of exposure (at a dose of 40 mg per kilogram intravenously in rabbits), with a target dose that was 100 times the median lethal dose of inhaled _B. anthracis_ spores. Survival is shown for rabbits in all treatment groups versus controls  and for monkeys in all treatment groups versus controls . The P values were calculated with the use of a log-rank test for the comparison of the survival time between each active-treatment group and the placebo group. IV denotes intravenous, and SC subcutaneous.\n\n【40】In rabbits , doses of raxibacumab of 10 mg per kilogram or higher provided a significant benefit with respect to the primary end point, the 14-day survival rate (80 to 100%, as compared with 0% with placebo; P<0.001). Survival was significantly longer in all raxibacumab groups, and a significant dose–response trend for survival at day 14 (P<0.001) was observed. Given the dose–response observed in rabbits, only the higher subcutaneous raxibacumab doses — 10, 20, and 40 mg per kilogram — were assessed in cynomolgus monkeys. The 28-day survival rate was significantly higher in all raxibacumab groups than in the placebo group  (70 to 90% in the groups that received 20 and 40 mg per kilogram, respectively, vs. 0% in the placebo group; P<0.001). The median survival was significantly longer in all the active-treatment groups than in the placebo group. More than 6 months after challenge, all monkeys that survived had an increase by a factor of 5 to 74 (mean \\[±SD\\], 28±22) in the total anti–protective antigen titer over the baseline value ( Supplementary Appendix ). These 21 monkeys were protected when rechallenged with inhaled anthrax spores approximately 1 year later, whereas 100% of the animals that received placebo at rechallenge died.\n\n【41】Protective Antigen in Serum during Systemic Anthrax Infection\n-------------------------------------------------------------\n\n【42】Figure 2. Inhalational Anthrax in Rabbits and Monkeys.\n\n【43】Time to events (death, first detection of protective antigen, first detection of bacteremia by blood culture or polymerase-chain-reaction \\[PCR\\] assay, and increase in body temperature) is shown for rabbits  and monkeys , with Pearson correlation coefficients for time to death. In both animal species, protective antigen in serum and bacteremia by culture or PCR assay were the earliest indicators of anthrax disease. Survival time was strongly correlated with the presence or absence of protective antigen in both species.\n\n【44】Clinical and laboratory changes associated with the onset of systemic infection after inhalation of spores in the rabbit and monkey studies were characterized in order to define objective triggers for therapeutic intervention. The median time to the first detection of protective antigen in serum was 30 hours in rabbits and 39 hours in monkeys. In both the rabbits and monkeys, detectable protective antigen in serum and bacteremia detected by culture or PCR appeared to be the first indicators of disease, followed by changes in temperature . These findings justified the use of the detection of protective antigen in serum as the trigger for treatment in rabbits and cynomolgus monkeys, given its high correlation with the first detection of bacteremia (r≥0.90) and the time to death (r≥0.90) in both animal species.\n\n【45】Therapeutic Efficacy of Raxibacumab\n-----------------------------------\n\n【46】Figure 3. Improved Survival with Raxibacumab in Rabbits and Monkeys after the Onset of Systemic Illness.\n\n【47】Survival after treatment with a single dose of intravenous raxibacumab at 20 mg per kilogram of body weight or 40 mg per kilogram in rabbits  and in monkeys  that had signs of inhalational anthrax is indicated by detectable protective antigen in serum. Absolute improvement in survival in all animals is shown in Panel C (rabbits) and Panel D (monkeys). The P values were calculated with the use of a log-rank test for the comparison of the survival time in each active-treatment group with that in the placebo group. The absolute improvement in survival (point estimates and 95% confidence intervals) among animals in the treatment group that received 40 mg per kilogram and the treatment group that received 20 mg per kilogram, as compared with placebo, is shown in Panels C and D. The primary efficacy analysis in the intention-to-treat population and the results for the subgroups (according to status with respect to toxemia, bacteremia, and increased temperature at the time of administration of the study agent) are shown. The dashed vertical line indicates the point estimate of the survival benefit in the intention-to-treat population. The 95% confidence intervals were calculated with the use of an unconditional exact method. For 95% confidence intervals that excluded 0, the statistical significance should be interpreted according to results from the Fisher's exact test based on a conditional method.\n\n【48】An efficacy study of raxibacumab in rabbits and a confirmatory study of raxibacumab in cynomolgus monkeys were conducted. As shown in Figure 3A , the primary end point (survival at day 14) was met in the rabbit study, with improved survival in the group that received 20 mg of raxibacumab per kilogram (28%) and the group that received 40 mg per kilogram (44%), as compared with placebo (0%; P=0.02 and P=0.003, respectively). The difference in survival between the two raxibacumab groups was not significant (17%; 95% confidence interval \\[CI\\], −16 to 47; P=0.30). Survival was significantly prolonged in the groups that received 20 and 40 mg per kilogram of raxibacumab (median, 3.5 days, P=0.018, and median, 3.8 days, P=0.003, respectively) versus placebo (median, 2.7 days) . The primary end point (survival at day 28) was also met in monkeys, with improved survival in the group that received 20 mg of raxibacumab per kilogram (50%) and the group that received 40 mg per kilogram (64%), as compared with placebo (0%; P=0.003 and P<0.001, respectively) . Survival did not differ significantly between the two raxibacumab groups (absolute difference, 14 percentage points; 95% CI, −24 to 54; P=0.44). Survival was significantly longer in the groups that received 20 and 40 mg of raxibacumab per kilogram (median survival, >28 days) than in the group that received placebo (median, 3.3 days; P=0.003 and P<0.001, respectively) . Positive toxin neutralization activity titers developed in surviving monkeys by postchallenge day 28.\n\n【49】The survival benefit with raxibacumab was robust and was observed across all prespecified subgroups in rabbits and monkeys . In all subgroups of animals confirmed to have bacteremia, toxemia, or both at or before the time of treatment initiation, there was a significant survival benefit associated with 20 or 40 mg of raxibacumab per kilogram as compared with placebo. The majority of survivors had negative _B. anthracis_ blood cultures by 10 to 24 hours after treatment, and all surviving animals had negative blood cultures at the end of the study. The kinetic analysis of protective antigen in serum showed higher levels and a greater magnitude of increase in animals that died than in surviving animals<mark> ( Supplementary Appendix )</mark>. In both studies, gross findings at necropsy were consistent with death due to inhalational anthrax, and histopathological analysis revealed microscopical lesions that were characteristic of inhalational anthrax ( Supplementary Appendix ).\n\n【50】Safety of Raxibacumab in Human Subjects\n---------------------------------------\n\n【51】Table 1. Baseline Characteristics of the Human Subjects.\n\n【52】Human safety tests with raxibacumab included 333 subjects who received intravenous raxibacumab at a dose of 40 mg per kilogram, the dose recommended for licensure ( Supplementary Appendix ). The demographic characteristics of the subjects are summarized in Table 1 . The characteristics were well balanced between the raxibacumab and placebo groups.\n\n【53】Table 2. Adverse Events during Treatment.\n\n【54】After the administration of raxibacumab alone or in combination with ciprofloxacin, there was a single report of a serious adverse event that was considered to be at least possibly related to raxibacumab; this case of cholecystitis was judged by the investigator to be most likely related to an underlying condition. Most adverse events were mild to moderate in severity and transient; their incidence did not differ significantly between the raxibacumab and placebo groups .\n\n【55】Pharmacokinetics of Raxibacumab in Humans and Animals\n-----------------------------------------------------\n\n【56】Figure 4. Pharmacokinetics of Raxibacumab in Humans, Rabbits, and Monkeys and Predictors of Survival.\n\n【57】As shown in Panel A, the pharmacokinetics of a single intravenous dose of 40 mg of raxibacumab per kilogram of body weight in monkeys, rabbits, and humans indicated that the pharmacokinetic properties are translatable across the three species. AUC denotes area under the curve, CL clearance, C <sub>max </sub> maximum concentration of the drug, MRT mean residence time, and V <sub>ss </sub> volume of distribution at steady state. As shown in Panel B, in rabbits and monkeys, the ratio of raxibacumab to protective antigen in serum at the time of therapeutic intervention was associated with improved survival rates (odds ratio) or survival time (hazard ratio for death). In Panel C, the relationship of serum levels of raxibacumab (intravenous administration of 40 mg per kilogram in a single dose) in humans to maximum levels of protective antigen in serum in animals that died of inhalational anthrax is shown. A single dose is sufficient to ensure that 95% or more of the human population, at 28 days relative to monkeys and at 48 days relative to rabbits, can be expected to have levels of serum raxibacumab that are equal to or greater than the highest observed levels of protective antigen in animals at the time of death.\n\n【58】In rabbits, monkeys, and humans, raxibacumab had consistent and predictable pharmacokinetic properties, with similar peak exposures across the species . The longer half-life of raxibacumab in humans, as compared with that in the animal species, resulted in greater overall exposure in humans. Furthermore, 40 mg per kilogram of raxibacumab does not alter antibiotic safety or pharmacokinetic properties, allowing for concomitant administration ( Supplementary Appendix ).\n\n【59】To translate the effective doses in animals into appropriate doses in humans, the ratio of the raxibacumab concentration to the protective antigen concentration in serum at the time of therapeutic intervention was assessed. A higher ratio of raxibacumab to protective antigen at the time of treatment resulted in an improved survival rate and survival time in both rabbits and monkeys . This finding emphasizes the need for early intervention before levels of protective antigen reach lethal levels and suggests the potential benefit of the 40-mg-per-kilogram dose as compared with the 20-mg-per-kilogram dose. As shown in Figure 4C , a single dose of 40 mg of raxibacumab per kilogram is sufficient to ensure that 95% or more of the human population, for at least 28 days, will have serum raxibacumab levels in excess of the highest observed levels of protective antigen in animals at the time of death.\n\n【60】Discussion\n----------\n\n【61】New treatments directed at neutralizing anthrax toxins are needed.  The criteria for demonstrating efficacy in animals when it is not ethical or feasible to conduct studies in humans have been described by the Food and Drug Administration in the “animal rule.” The development program for raxibacumab meets all requirements under this rule, as enumerated below.\n\n【62】First, the pathophysiological mechanism for the effects of protective antigen and its amelioration or prevention by raxibacumab should be well understood. The mechanisms underlying the effects of anthrax toxin and its contributions to tissue injury have been elucidated.  We have shown that raxibacumab binds protective antigen with high affinity and specifically blocks the binding of protective antigen to its receptor, preventing anthrax toxin–mediated damage. Second, effectiveness must be demonstrated in more than one animal species expected to have a response that is predictive for humans, and the end point in studies in animals must be clearly related to the desired benefit in humans. Our studies in rabbits and monkeys confirm that the course of inhalational anthrax has pathophysiological features and outcomes that are similar to those in humans. We have shown that raxibacumab improved survival among rabbits and monkeys with evidence of systemic disease after a lethal exposure to inhaled _B. anthracis_ spores (approximately 200 times the median lethal dose). In both rabbits and monkeys, raxibacumab significantly increased the overall survival rate and the time to death. Finally, the pharmacokinetic properties of the product in animals and humans should be sufficiently well understood to allow selection of an effective dose in humans. We found that a dose of 40 mg of raxibacumab per kilogram in humans results in levels of serum raxibacumab that are similar to or greater than those that provide a survival benefit in animal models. The safety profile in humans provides support for the use of raxibacumab, particularly in the clinical setting of immediately life-threatening inhalational anthrax disease.\n\n【63】Although antibiotics are the mainstay of initial treatment after exposure to _B. anthracis,_ clinical experience has highlighted the need for additional measures to address the significant morbidity observed.  Our data indicate that early intervention (before the logarithmic increase in levels of protective antigen) is associated with significantly better survival in animals. Hence, in patients with a high clinical index of suspicion for inhalational anthrax infection, we anticipate the use of raxibacumab concomitantly with antibiotics or when the initial use of antibiotics is associated with a suboptimal clinical response.", "index": 22888, "show": true, "start": 22862, "end": 22888, "province": ["文本干净度", "无关文本"], "isEdit": false, "comment": "49"}]}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-14 00:21:36", "grab_time": "2024-08-13 23:46:38"}
{"id": 2234400, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "e95b8c0a-5381-464f-86e9-5fa3cac330c8", "title": "Splenic Reticuloendothelial Function after Splenectomy, Spleen Repair, and Spleen Autotransplantation", "text": "【0】Splenic Reticuloendothelial Function after Splenectomy, Spleen Repair, and Spleen Autotransplantation\nAbstract\n--------\n\n【1】Overwhelming infection after splenectomy remains a problem despite the introduction of vaccine and antimicrobial prophylaxis. To evaluate prospectively various procedures proposed for salvage of the spleen, we measured reticuloendothelial function for two to five years in 51 patients who had initially presented with abdominal trauma and suspected splenic rupture.\n\n【2】The mean percentage of pocked erythrocytes and the clearance of antibody-coated autologous erythrocytes in 8 patients who had splenic repair and in 6 who had partial splenectomy were the same as in 11 controls with intraabdominal injury that did not involve the spleen. The mean percentage of pocked erythrocytes remained significantly elevated in 19 patients who had undergone total splenectomy without autotransplantation of splenic tissue. One of seven patients who underwent splenic autotransplantation had a normal level of pocked erythrocytes 18 months after surgery, and a second patient had only a slight elevation at 24 months. The mean (±SEM) half-time clearance of labeled erythrocytes was significantly longer in the group that had total splenectomy without autotransplantation (421.1±74.5 hours) than in the autotransplantation group (91.6±20.0) or in the controls (5.4±2.0).\n\n【3】We conclude that reticuloendothelial function was better preserved after partial splenectomy and splenic repair than after splenic autotransplantation, but that autotransplantation was superior to total splenectomy and appeared to be safe. Splenic autotransplantation deserves further study in patients who have had splenic trauma when other surgical maneuvers to save the spleen are not possible.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:13:47", "endTime": "2024/08/14 15:14:05", "cost": 18.302}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 23:14:05", "grab_time": "2024-08-13 23:13:47"}
{"id": 2234399, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "7743f5db-d680-4fad-9253-3764e40335b0", "title": "Anagrelide: A New Drug for Treating Thrombocytosis", "text": "【0】Anagrelide: A New Drug for Treating Thrombocytosis\nAbstract\n--------\n\n【1】Anagrelide is a member of the imidazo (2, 1 -b) quinazolin-2-one series of compounds, with a powerful antiaggregating effect on platelets. During studies in humans, anagrelide in small doses has produced thrombo-cytopenia. We therefore evaluated it in the treatment of thrombocytosis, and to date, platelet levels in 15 of 17 patients with primary thrombocythemia, 2 patients with polycythemia vera and thrombocytosis, and 1 patient with chronic granulocytic leukemia and thrombocytosis have been well controlled with the use of this agent.\n\n【2】Induction doses of 1.0 to 1.5 mg given orally every six hours have produced a decrease in the platelet count, starting on day 5 and reaching a normal level by day 12. Side effects of anagrelide have been minimal. Maintenance therapy with 1.5 to 4.0 mg a day has continued to control the platelet count in patients for up to 28 months.\n\n【3】This new agent appears promising in the treatment of thrombocytosis in patients with chronic myeloproliferative disease.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:16:30", "endTime": "2024/08/14 15:16:40", "cost": 9.789}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 23:16:40", "grab_time": "2024-08-13 23:16:11"}
{"id": 2234398, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "33c7b19d-f570-470d-928d-3a674f7dcab4", "title": "The Changing Base Line of Complex Ventricular Arrhythmias — A New Consideration in Assessing Long-Term Antiarrhythmic Drug Therapy", "text": "【0】The Changing Base Line of Complex Ventricular Arrhythmias — A New Consideration in Assessing Long-Term Antiarrhythmic Drug Therapy\nAbstract\n--------\n\n【1】Initial base-line electrocardiograms are used to assess the efficacy of treatment for ventricular arrhythmias. This approach assumes that in the absence of treatment the frequency of arrhythmia would remain constant. To test the validity of this assumption, we studied 26 clinically stable patients with symptomatic but not life-threatening ventricular arrhythmias, during two periods of placebo treatment separated by a mean of 17 months.\n\n【2】As compared with the initial placebo period, there were significant reductions in ventricular premature depolarizations (50 per cent), pairs (65 per cent), and ventricular tachycardia (83 per cent) during the second period of placebo administration (P≤0.05 for all comparisons). Over one third of the patients gave the appearance of receiving successful therapy during the second placebo period, even when the reported spontaneous variability of ventricular arrhythmia was taken into consideration. If unrecognized, these long-term spontaneous changes in the frequency of arrhythmia could result in continuation of unnecessary and potentially toxic therapy and lead to incorrect conclusions regarding the efficacy of antiarrhythmic drugs in clinical trials. We therefore recommend that the frequency of arrhythmia be reassessed annually in the absence of treatment in patients similar to those in our study. These recommendations should not be applied to patients with life-threatening ventricular arrhythmias.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:38:48", "endTime": "2024/08/14 15:38:51", "cost": 3.461}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 23:38:52", "grab_time": "2024-08-13 23:38:48"}
{"id": 2234397, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "6409371a-0297-4e40-905c-9fdfdfa5b165", "title": "The View from Puerto Rico — Hurricane Maria and Its Aftermath", "text": "【0】The View from Puerto Rico — Hurricane Maria and Its Aftermath\nArticle\n-------\n\n【1】### Audio Interview\n\n【2】 Interview with Dr. Carmen Zorrilla on how one hospital in Puerto Rico responded to Hurricane Maria and what will come next for the island. \n\n【3】Figure 1. Streets in Puerto Rico Blocked by Debris from Hurricane Maria.\n\n【4】Lourdes De Jesus.\n\n【5】Hurricane Maria hit Puerto Rico on September 20 and caused unprecedented damage affecting the island’s 3.4 million inhabitants . Though no one in Puerto Rico was spared at least some impact, the poor and vulnerable were disproportionately affected. Loss of communication and electricity, scarcity of water, isolation of some residents, slow coordination of the aid that has been sent, and the magnitude and scope of the necessary repairs all merit a call for help from and the engagement of the global community. Indeed, Puerto Ricans and U.S. Virgin Islanders are U.S. citizens and expect the same federal aid and support during natural disasters as the rest of the United States.\n\n【6】In contrast to sudden disasters, hurricanes often allow officials and populations a window of opportunity to prepare, evacuate people, and update emergency plans. Yet our infrastructure, including the health care infrastructure, was already in crisis, and the much milder hit from Hurricane Irma 2 weeks earlier had caused a partial collapse of the power system. In addition, the island’s economic situation, causing concerns about lack of income or reductions in wages, fueled a sense of uncertainty and despair among many Puerto Ricans, as we were faced with the most powerful hurricane to hit Puerto Rico in nearly a century. We prepared for the worst while hoping for the best — and we got the worst.\n\n【7】Destruction of health care facilities, paired with the “survival mode” in which patients and the community had already been living, disrupted the health care system. During the storm, the majority of the island’s 69 hospitals were left without electricity or fuel for generators.  Much construction is cement-based and withstood the hurricane, but wooden structures built in mountain regions or elsewhere were lost or severely damaged.\n\n【8】During and after the hurricane, people described their experiences and searched for family members and friends through social networks. Our sources of information were the only operational radio station on the island and limited social networks. The governor declared a curfew of 6 p.m. and made it later as safe access to roads was established. Among our cultural values is responsibility for family, which I believe is what kept the number of people in shelters as low as about 12,000.\n\n【9】As an obstetrician–gynecologist on the faculty of the University of Puerto Rico School of Medicine who is involved in patient care, clinical and behavioral research, and education of residents, medical students, and undergraduates, I experienced Hurricane Maria through the lens not only of my own fears, but also the concerns of our patients and staff. I had lived through two previous hurricanes: Hugo (category 3) in 1989 and Georges (category 4) in 1998. This time, I dared to stay on an 18th floor, covering doors and windows as best as I could. The experience was worse than I remembered from prior hurricanes, since the building moved with the winds. My personal experience was less frightening than those of my patients, but our shared story created a new bond between us. It became clear to all of us that nature is stronger than medical interventions.\n\n【10】Yet obstetrical services had to be available 24/7 for pregnant women. Women in labor cannot wait for services to be reinstated or for staff to show up, and we try to avoid home deliveries. The hospitals that didn’t have major structural damage attempted to continue operations with backup power generators. But only three major hospitals were functioning 3 or 4 days after the hurricane, and information was scarce, since most communications systems had been disrupted. Neither hospitals, patients, nor staff had the means to connect with one another.\n\n【11】Figure 2. Tents Provided by the U.S. Department of Health and Human Services for Overflow from the Puerto Rico Medical Center Emergency Room.\n\n【12】Jorge Matta.\n\n【13】Located at the Puerto Rico Medical Center in San Juan, the University Hospital provides care to any patient from the island who has a complicated medical condition. We house most of Puerto Rico’s residency programs and subspecialty training programs. All these programs established emergency coverage rosters with 24-hour shifts. All elective surgeries and clinics were canceled. We continued working with the help of the power generator, but the water supply was limited .\n\n【14】On one of my night shifts, we had double the maximum occupancy in labor rooms, and the wards were full of patients who had been discharged but had no contact with relatives, no means of transportation, or no place to go. By the sixth day, we had no clean sheets, only a weak drip of water from the faucets, and no way to autoclave our surgical instruments. My residents were overwhelmed, not just from physical exhaustion but from our patients’ stories and the difficult decisions we had to make. We are not trained in disaster management, so we had to draw on our own personal and emotional strengths in managing the situation, aiming to provide high-quality and efficient care while maintaining our professionalism, humanism, and empathy. We were fully functional on day 8, by which time many patients had been transferred to their own or relatives’ homes. By 9 days after the hurricane, we had seen a 33% increase in September 2017 deliveries over those for September 2016.\n\n【15】Our research areas include HIV, Zika, high-risk pregnancies, and prevention studies. But our pharmacy and laboratory facilities were affected by the storm. We transferred medications to the hospital pharmacy 2 days after the hurricane. Our research and clinic staff returned to work 5 days after Maria, even though some of them had lost their homes or had major difficulties with road access and gasoline supply. Our clinics opened 10 days, and our labs 14 days, after the hurricane passed. None of our stored samples were lost.\n\n【16】The impact of this disaster on morbidity, survival, adherence to treatments, and medical complications has yet to be documented. The potential development of infectious disease outbreaks and reactivation of dengue, Zika, and chikungunya epidemics is one major concern. As of December 22, 2016, there were 2591 pregnant women diagnosed with Zika and 36,364 total Zika cases that had been confirmed by laboratory testing.  Of an estimated 28,200 live births in 2016, Zika affected at least 9.2%. By September 15 of this year, 1546 pregnant women had confirmed cases of Zika. Though the numbers are decreasing, cases are still being reported. This hurricane might well increase the mosquito population, and people may not pay attention to prevention messages or be willing to modify behaviors that affect their seeking of food, water, and gasoline or repairing of their homes.\n\n【17】In an attempt to save babies born with congenital heart disease, pediatric cardiovascular surgeons whose hospital lacked power attempted to establish an operating room in the nursery. Surgeries could not be performed, and the babies had to be transferred to the mainland United States by the medical emergency teams that were established on the third day after the hurricane. Two pregnant women whose fetuses had heart defects were also expediently transferred to the mainland. Fortunately, general pediatric surgery (excluding cardiac) continues to be performed at our medical center, but some pregnant women are leaving the island to avoid additional medical crises. Many physicians have volunteered to take care of people in shelters through an initiative of the Puerto Rico College of Physicians and Surgeons. Physicians who want to help can join the diverse national organizations that represent our specialties.\n\n【18】As of 16 days after the hurricane, 25 hospitals were working, only 9.2% of people had power, 54% had water, 45% had cell phone service, and the Federal Emergency Management Agency had distributed 433,000 food packages and 42,000 gallons of water.  Puerto Rico clearly faces a long road to recovery.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-14 00:23:16", "grab_time": "2024-08-13 23:43:04"}
{"id": 2234396, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "3aca6b78-9f01-41e6-a9f6-7c8e567b2dba", "title": "Fundamentals of Public Health: U.S. Public Health Law — Foundations and Emerging Shifts", "text": "【0】Fundamentals of Public Health: U.S. Public Health Law — Foundations and Emerging Shifts\n### Audio Interview\n\n【1】 Interview with Prof. Michelle Mello on individual rights and state and federal powers to regulate health matters in the United States. \n\n【2】The Covid pandemic has focused attention on the complex relationship between individual rights and public health protection. This tension has long occupied U.S. courts, but today some long-settled understandings in public health law are being contested and disrupted.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": null, "finished": false, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-12 23:58:30", "grab_time": "2024-08-13 19:11:32"}
{"id": 2234395, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "10301e37-c615-4f62-9168-dd7d0aaab273", "title": "The Natural History of Transfusion-Associated Infection with Human Immunodeficiency Virus", "text": "【0】The Natural History of Transfusion-Associated Infection with Human Immunodeficiency Virus\nAbstract\n\n【1】Patients infected by the human immunodeficiency virus (HIV) as a result of blood transfusions are unique in that their dates of infection are well defined and their medical conditions before infection are known. To characterize the natural history of transfusion-associated HIV infection, we studied 694 recipients of blood from 112 donors in whom AIDS later developed and from 31 donors later found to be positive for HIV antibody.\n\n【2】Of the recipients tested, 85 were seronegative, 116 were seropositive, and 19 had AIDS. Of 101 HIV-seropositive recipients followed for a median of 55 months after infection, 54 had Centers for Disease Control Class IV disease, including 43 with AIDS. Life-table analysis suggested that AIDS will develop in 49 percent of infected recipients (95 percent confidence limits, 36 to 62 percent) within seven years after infection. As compared with recipients without AIDS, the 43 recipients with AIDS had received more transfusions at the time of infection (median, 21 vs. 7; P = 0.01).\n\n【3】HIV-infected blood donors in whom AIDS developed were grouped according to whether AIDS developed within 29 months (the median) after donation (Group 1) or 29 or more months after donation (Group 2). As compared with the 31 recipients of blood from Group 2 blood donors, the 31 recipients of blood from Group 1 donors were more likely to have AIDS four years after infection (49 percent vs. 4 percent; P = 0.005) and illnesses resembling acute retroviral syndrome (14 of 24 vs. 5 of 22; P = 0.03).\n\n【4】We conclude that most recipients of HIV-infected blood become seropositive, that AIDS develops in about half these recipients within seven years, and that the risk may be higher when AIDS develops in the blood donor soon after donation.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 10:08:51", "endTime": "2024/08/14 10:08:56", "cost": 4.417}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 18:08:55", "grab_time": "2024-08-13 18:03:27"}
{"id": 2234394, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "6d39b89a-8bb7-4078-8876-e224001a5dbe", "title": "Enzyme Replacement Therapy by Renal Allotransplantation in Fabry's Disease", "text": "【0】Enzyme Replacement Therapy by Renal Allotransplantation in Fabry's Disease\nAbstract\n--------\n\n【1】Serial measurements of the neutral glycosphingolipids in the plasma and urine of a man who underwent renal allotransplantation because of renal failure due to Fabry's disease were done to evaluate the contribution of the donor organ to the correction of the basic metabolic defect. The concentration of galactosylgalactosylglucosylceramide in the plasma transiently decreased after the renal transplantation (from 0.76 to 0.48 μmoles per 100 ml). The variations in concentration of this lipid closely paralleled similar changes in the concentration of its precursor, N-acetylgalactosaminylgalactosylgalactosylglucosylceramide (from 0.23 to 0.07 μmoles per 100 ml), suggesting that the alterations in galactosylgalactosylglucosylceramide were the result of changes in the rate of formation of the lipid rather than increased catabolism by the graft. The data do not support the hypothesis that enzyme replacement by renal transplantation is effective in correcting the basic metabolic defect in patients with Fabry's disease.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 17:40:33", "endTime": "2024/08/13 17:43:35", "cost": 181.885}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 01:43:35", "grab_time": "2024-08-13 01:06:16"}
{"id": 2234393, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "8523f02d-8fc1-4d72-95b0-6ceee8f5506a", "title": "A Follow-up Study of Vascular Disease in Growth-Hormone-Deficient Dwarfs with Diabetes", "text": "【0】A Follow-up Study of Vascular Disease in Growth-Hormone-Deficient Dwarfs with Diabetes\nAbstract\n--------\n\n【1】Thirty - one growth - hormone - deficient dwarfs were re-examined after a period of 10 to 12 years. These subjects had initially shown glucose intolerance, insulinopenia and hyperlipidemia comparable to those of diabetic patients matched for age and sex, but vascular complications were not present in dwarfs.\n\n【2】After 10 years glucose tolerance became progressively more abnormal in dwarfs than could be accounted for by expected deterioration with age, and hyperglycemia after mixed meals remained greater than in control subjects. Serum lipid and serum lipoprotein concentrations were abnormal in over one third of the dwarfs.\n\n【3】Despite the metabolic similarity to the diabetic patients, clinical complications of diabetes were absent in dwarfs: retinopathy did not occur, and the prevalence of hypertension and arteriosclerosis was considerably lower in dwarfs than in the diabetic subjects in both study periods.\n\n【4】The follow-up data support the hypothesis that growth hormone has at least a supportive role in the pathogenesis of vascular disease in the diabetic state.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 16:39:12", "endTime": "2024/08/13 16:41:31", "cost": 138.941}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 00:41:31", "grab_time": "2024-08-13 00:39:12"}
{"id": 2234392, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "bfaf8c97-4e98-4228-8269-6b5442b21e43", "title": "Propranolol-Withdrawal Rebound Phenomenon — Exacerbation of Coronary Events after Abrupt Cessation of Antianginal Therapy", "text": "【0】Propranolol-Withdrawal Rebound Phenomenon — Exacerbation of Coronary Events after Abrupt Cessation of Antianginal Therapy\nAbstract\n--------\n\n【1】Effects on anginal symptoms of sudden withdrawal of large doses of propranolol or placebo were evaluated in 20 patients in a double-blind crossover efficacy trial requiring sudden cessation of the agent. With propranolol, 160 to 320 mg per day for six and 12 weeks, no patients had increased angina or nitroglycerin use, and there were no hospitalizations or deaths. However, within two weeks of discontinuance of propranolol, untoward ischemic events developed in 10 patients. Six had serious withdrawal complications: intermediate coronary syndrome in three, and ventricular tachycardia, fatal myocardial infarction, and sudden death in one each. In four patients discontinuance of placebo increased anginal symptoms; in the remaining 10, ischemic symptoms were not provoked. The rebound phenomenon was related to degree of pre-propranolol angina and relief of pain by the agent. Thus, chronically administered propranolol should be gradually reduced, and activity restricted during its withdrawal.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:09:14", "endTime": "2024/08/14 15:09:23", "cost": 9.803}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 23:09:23", "grab_time": "2024-08-13 23:09:13"}
{"id": 2234391, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "cdc9ecab-227e-47d6-892b-fb22dd75dc37", "title": "Inclisiran for the Treatment of Heterozygous Familial Hypercholesterolemia", "text": "【0】Inclisiran for the Treatment of Heterozygous Familial Hypercholesterolemia\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Familial hypercholesterolemia is characterized by an elevated level of low-density lipoprotein (LDL) cholesterol and an increased risk of premature atherosclerotic cardiovascular disease. Monoclonal antibodies directed against proprotein convertase subtilisin–kexin type 9 (PCSK9) have been shown to reduce LDL cholesterol levels by more than 50% but require administration every 2 to 4 weeks. In a phase 2 trial, a twice-yearly injection of inclisiran, a small interfering RNA, was shown to inhibit hepatic synthesis of PCSK9 in adults with heterozygous familial hypercholesterolemia.\n\n【3】Methods\n-------\n\n【4】In this phase 3, double-blind trial, we randomly assigned, in a  ratio, 482 adults who had heterozygous familial hypercholesterolemia to receive subcutaneous injections of inclisiran sodium (at a dose of 300 mg) or matching placebo on days 1, 90, 270, and 450. The two primary end points were the percent change from baseline in the LDL cholesterol level on day 510 and the time-adjusted percent change from baseline in the LDL cholesterol level between day 90 and day 540.\n\n【5】Results\n-------\n\n【6】The median age of the patients was 56 years, and 47% were men; the mean baseline level of LDL cholesterol was 153 mg per deciliter. At day 510, the percent change in the LDL cholesterol level was a reduction of 39.7% (95% confidence interval \\[CI\\], −43.7 to −35.7) in the inclisiran group and an increase of 8.2% (95% CI, 4.3 to 12.2) in the placebo group, for a between-group difference of −47.9 percentage points (95% CI, −53.5 to −42.3; P<0.001). The time-averaged percent change in the LDL cholesterol level between day 90 and day 540 was a reduction of 38.1% (95% CI, −41.1 to −35.1) in the inclisiran group and an increase of 6.2% (95% CI, 3.3 to 9.2) in the placebo group, for a between-group difference of −44.3 percentage points (95% CI, −48.5 to −40.1; P<0.001). There were robust reductions in LDL cholesterol levels in all genotypes of familial hypercholesterolemia. Adverse events and serious adverse events were similar in the two groups.\n\n【7】Conclusions\n-----------\n\n【8】Among adults with heterozygous familial hypercholesterolemia, those who received inclisiran had significantly lower levels of LDL cholesterol than those who received placebo, with an infrequent dosing regimen and an acceptable safety profile. \n\n【9】Introduction\n------------\n\n【10】Heterozygous familial hypercholesterolemia, a genetic disorder that affects 1 in 250 persons or 30 million people worldwide, is characterized by elevated levels of low-density lipoprotein (LDL) cholesterol from birth. Without treatment, the condition is associated with premature complications and death from accelerated development of atherosclerotic cardiovascular disease. \n\n【11】Variants in the gene encoding the LDL receptor ( _LDLR_ ) account for more than 90% of cases of familial hypercholesterolemia, whereas variants in other genes, such as those encoding apolipoprotein B ( _APOB_ ) and proprotein convertase subtilisin–kexin type 9 ( _PCSK9_ ), account for 5% and less than 2% of cases, respectively.  However, despite the use of next-generation sequencing, a monogenic variant cannot be identified in up to 30% of patients who have received a clinical diagnosis of definite heterozygous familial hypercholesterolemia.  Since the risk of atherosclerotic cardiovascular disease is driven by the degree and duration of an elevated LDL cholesterol level, the goal of management should be the initiation of therapy to lower the LDL cholesterol level as soon as possible after diagnosis, with even more intensive lipid-lowering therapy in patients with established atherosclerosis. \n\n【12】Pharmacologic management of familial hypercholesterolemia includes the use of high-intensity statins, ezetimibe, and monoclonal antibodies directed against circulating PCSK9. Monoclonal antibodies against PCSK9 have been shown to reduce LDL cholesterol levels by more than 50% but require administration every 2 to 4 weeks.  The phase 2 ORION-1 trial showed that inclisiran, a small interfering RNA targeting hepatic PCSK9 synthesis, has the potential to substantially reduce LDL cholesterol levels with an acceptable side-effect profile and an infrequent dosing regimen.  Here, we report the results of the phase 3 ORION-9 trial, in which we evaluated the use of inclisiran in a large cohort of adult patients with heterozygous familial hypercholesterolemia who had been treated with a maximally accepted dose of statin therapy.\n\n【13】Methods\n-------\n\n【14】Trial Oversight and Design\n--------------------------\n\n【15】ORION-9 was a double-blind, randomized, placebo-controlled trial that was conducted in 8 countries at 46 sites. The trial protocol  was approved by an institutional review board or independent ethics committee at each participating institution. All the trial patients provided written informed consent. The trial was designed by the academic steering committee and the sponsor, the Medicines Company. The first author wrote the initial draft of the manuscript, and all the authors had access to the data and contributed to the review of and revisions to the initial draft of the manuscript. All the authors vouch for the accuracy and completeness of the data and for the fidelity of the trial to the protocol.\n\n【16】Patients\n--------\n\n【17】The diagnosis of familial hypercholesterolemia was based on genetic confirmation or established phenotypic Simon Broome criteria.  The patients were required to have an LDL cholesterol level of at least 100 mg per deciliter (2.6 mmol per liter) despite receiving a maximally accepted dose of statin therapy with or without ezetimibe. Patients who were receiving a PCSK9 monoclonal antibody were excluded.\n\n【18】Trial Procedures\n----------------\n\n【19】The patients were randomly assigned in a  ratio to receive inclisiran sodium (at a dose of 300 mg, which corresponds to a dose of 284 mg of inclisiran free acid) or matching placebo, which were both administered as a 1.5-ml subcutaneous injection on days 1, 90, 270, and 450. During visits for drug administration, the patients remained under observation for 30 minutes after injection. The patients also attended clinic visits on days 30, 150, 330, and 510 to undergo fasting biochemical measurements and to assess the safety and side-effect profile of inclisiran. The last trial visit was conducted on day 540 .\n\n【20】End Points\n----------\n\n【21】The two primary end points were the percent change from baseline in the LDL cholesterol level at day 510 and the time-adjusted percent change from baseline in the LDL cholesterol level between day 90 and day 540. Key secondary end points were the mean absolute change from baseline in the LDL cholesterol level at day 510, the time-adjusted absolute reduction from baseline between day 90 and day 540, and changes in levels of PCSK9, total cholesterol, apolipoprotein B, and non–high-density lipoprotein (HDL) cholesterol. Prespecified exploratory end points included the proportion of patients who met the lipid targets for their level of cardiovascular risk and the treatment response according to the underlying genotype of familial hypercholesterolemia.\n\n【22】Genotyping\n----------\n\n【23】Next-generation sequencing was performed for the coding regions of the four genes ( _LDLR_ , _APOB_ , _PCSK9_ , and _LDLRAP1_ \\[encoding LDLR adaptor protein 1\\]) that are known to account for the majority of cases of familial hypercholesterolemia.  _LDLR_ exons 1 through 18, _APOB_ exons 1 through 29, _PCSK9_ exons 1 through 12, and _LDLRAP1_ exons 1 through 9 were captured, amplified on polymerase-chain-reaction assay, and subjected to pair-end DNA sequencing with the use of the Illumina MiSeq sequencing platform. Secondary and tertiary analysis of DNA sequences were performed with the use of the commercial bioinformatics software CLC Genomics Workbench (Qiagen) for variant calling and VarSeq (Golden Helix) for variant analysis. VS-CNV software (Golden Helix) was used to identify DNA copy-number variations in _LDLR_ , which are the cause of familial hypercholesterolemia in up to 10% of patients.  Variants that were identified were aligned to the GRCh37 (hg19) reference genome, and the pathogenicity of reported variants was determined according to current guidelines.  _LDLR_ variants were grouped as pathogenic, probably pathogenic, or of uncertain significance. \n\n【24】Safety Reports\n--------------\n\n【25】Adverse events and laboratory values were recorded at all visits through the end-of-trial visit on day 540. Vital signs were recorded at all injection visits and at day 540. Electrocardiography was performed at the time of screening and on days 1 and 540. Investigators classified adverse events as mild, moderate, or severe according to organ class using the criteria of the _Medical Dictionary for Regulatory Activities_ . Injection-site reactions were evaluated with the use of prespecified terms. Antidrug antibodies were measured with the use of a highly sensitive screening method and, if needed, confirmatory assays in accordance with the most recent regulatory guidance.\n\n【26】Statistical Analysis\n--------------------\n\n【27】The sample size was based on the assumption that the mean (±SD) decrease from baseline in the LDL cholesterol level would be at least 30±20 mg per deciliter (0.8±0.5 mmol per liter) more in the inclisiran group than in the placebo group. We calculated that approximately 380 patients would be needed to evaluate efficacy between the inclisiran and placebo groups, assuming a dropout rate of 5%, a two-sided alpha level of 0.05, and a power of more than 90% to detect a 30% reduction from baseline in the LDL cholesterol level. Because of faster-than-expected enrollment, the actual enrollment was 482 patients to allow for all screened and eligible patients to enter the trial.\n\n【28】We used a sequential testing procedure with a two-sided alpha level of 0.05 to assess the percent change in the LDL cholesterol level from baseline to day 510. Once the null hypothesis was rejected, we used a two-sided alpha level of 0.05 to test the time-adjusted percent change from baseline in the LDL cholesterol level between day 90 and day 540. We used a reflexive approach to measuring the LDL cholesterol level in calculating the primary end points. First, we used the Friedewald formula to estimate the LDL cholesterol level. If the LDL cholesterol level was less than 40 mg per deciliter (1.0 mmol per liter) or if the triglyceride levels were more than 400 mg per deciliter (4.5 mmol per liter), we performed preparative ultracentrifugation to directly measure the LDL cholesterol level.\n\n【29】For the first of the two primary end points (the percent change in the LDL cholesterol level from baseline to day 510), we used a multiple-imputation washout model to impute missing values. The primary analysis was conducted in the intention-to-treat population and was based on an analysis of covariance (ANCOVA) model on each multiply imputed data set (100 total). The model included the fixed effects of treatment and the baseline LDL cholesterol level. We then used Rubin’s model to combine treatment effects from these ANCOVA analyses. For the second primary end point (the time-adjusted percent change in the LDL cholesterol level between day 90 and day 540), we used a control-based pattern-mixture model to impute missing values. We used a mixed-effects model for repeated measurements of data obtained during all visits on each multiply imputed data set. The model included fixed effects for treatment, visit, baseline LDL cholesterol level, and the interaction between treatment and visit.\n\n【30】Analyses of the secondary end points were performed only after the analyses of the two primary end points were completed and the null hypotheses were rejected. The Hochberg procedure was applied to control for family-wise type I error at a two-sided significance level of 0.05 for the comparison of key secondary end points. We used the two-sided 95% confidence intervals for least-squares means for testing of continuous variables. Odds ratios and 95% confidence intervals were used for assessment for binary variables.\n\n【31】We also performed a prespecified subgroup analysis of the percent change from baseline in the LDL cholesterol level according to genotype (the presence or absence of a monogenic familial hypercholesterolemia variant) and according to the presence or absence of variants in _LDLR_ , _APOB_ , and _PCSK9_ . We also determined the mean differences in treatment effect between these subgroups. All analyses were performed with the use of SAS software, version 9.4 (SAS Institute). Details regarding the statistical analysis plans are provided in the protocol .\n\n【32】Results\n-------\n\n【33】Trial Population\n----------------\n\n【34】Table 1. Demographic and Clinical Characteristics of the Patients at Baseline.\n\n【35】The trial was conducted between December 2017 and September 2019. A total of 617 patients were screened; of these patients, 482 underwent randomization (242 patients to receive inclisiran and 240 to receive placebo). In the overall trial population, the mean age was 56 years; 227 patients (47%) were men, and 453 (94%) were white . Preexisting coronary heart disease was present in 25% of the patients and diabetes in 10%. The mean baseline LDL cholesterol level was 153.1±54.0 mg per deciliter (4.0±1.4 mmol per liter). A total of 90% of the patients were receiving statins, including 75% who were receiving high-intensity statins (at least 20 mg of rosuvastatin, 40 mg of atorvastatin, 40 mg of simvastatin, or the equivalent per day); more than 50% were also receiving ezetimibe. Of the patients in the intention-to-treat population, 235 patients (91.7%) in the inclisiran group and 231 (96.3%) in the placebo group completed the trial activities through day 540 .\n\n【36】Primary End Points\n------------------\n\n【37】Figure 1. Percent and Absolute Changes in Low-Density Lipoprotein (LDL) Cholesterol and PCSK9 Levels during the 540-Day Trial Period (Intention-to-Treat Population).\n\n【38】Panel A shows the percent change in the level of LDL cholesterol from baseline to day 510 (the first primary end point) in the inclisiran group and the placebo group. Panel B shows mean absolute LDL cholesterol levels from baseline to day 510 (a key secondary end point). Also shown are corresponding values for proprotein convertase subtilisin–kexin type 9 (PCSK9), including the percent change from baseline  and mean absolute levels from baseline to day 510 , which are other key secondary end points.\n\n【39】For the first primary end point, the percent change in the LDL cholesterol level from baseline to day 510 was a decrease of 39.7% (95% confidence interval \\[CI\\], −43.7 to −35.7) in the inclisiran group and an increase of 8.2% (95% CI, 4.3 to 12.2) in the placebo group, for a between-group difference of −47.9 percentage points (95% CI, −53.5 to −42.3; P<0.001) . For the second primary end point, the time-averaged percent change in the LDL cholesterol level between day 90 and day 540 was a decrease of 38.1% (95% CI, −41.1 to −35.1) in the inclisiran group and an increase of 6.2% (95% CI, 3.3 to 9.2) in the placebo group, for a between group difference of −44.3 percentage points (95% CI, −48.5 to −40.1; P<0.001). Sensitivity analyses using imputation for missing values produced similar results .\n\n【40】Key Secondary End Points\n------------------------\n\n【41】The mean absolute change from baseline in the LDL cholesterol level at day 510 was a decrease of 59.0 mg per deciliter (95% CI, −64.8 to −53.2 \\[1.5 mmol per liter; 95% CI, −1.7 to −1.4\\]) in the inclisiran group and an increase of 9.9 mg per deciliter (95% CI, 4.1 to 15.8 \\[0.3 mmol per liter; 95% CI, 0.1 to 0.4\\]) in the placebo group, for a between-group difference of −68.9 mg per deciliter (95% CI, −77.1 to −60.7 \\[1.8 mmol per liter; 95% CI, −2.0 to −1.6\\]; P<0.001) . The time-averaged observed difference in LDL cholesterol levels between day 90 and day 540 was −56.9 mg per deciliter (−1.5 mmol per liter) in the inclisiran group and 5.8 mg per deciliter (0.1 mmol per liter) in the placebo group, for a between-group difference of −62.6 mg per deciliter (−1.6 mmol per liter) (P<0.001), a difference of 44.6%.\n\n【42】At day 510, the percent change in the PCSK9 level was a decrease of 60.7% (95% CI, −64.4 to −57.0) in the inclisiran group and an increase of 17.7% (95% CI, 13.9 to 21.4) in the placebo group, for a between-group difference of −78.4 percentage points (95% CI, −83.7 to −73.0; P<0.001) . At day 510, the mean absolute change in the PCSK9 level was a decrease of 282.6 μg per liter (95% CI, −297.9 to −267.2) in the inclisiran group and an increase of 54.5 μg per liter (95% CI, 39.1 to 70.0) in the placebo group, for a between-group difference of −337.1 μg per liter (95% CI, −358.9 to −315.3; P<0.001) . The time-averaged observed difference in PCSK9 levels between day 90 and day 540 was −284.6 μg per liter (95% CI, −303.8 to −265.4) in the inclisiran group and 44.0 μg per liter (95% CI, 32.3 to 55.6) in the placebo group, for a between group difference of −328.6 μg per liter (95% CI, −351.0 to −306.1; P<0.001), a difference of 77%. Waterfall plots for individual changes in levels of LDL cholesterol and PCSK9 among the patients are shown in Figure S3.\n\n【43】Inclisiran was associated with lower levels of total cholesterol, non–HDL cholesterol, apolipoprotein B, and triglycerides than placebo, along with higher HDL cholesterol levels. In the inclisiran group, the median level of lipoprotein(a) was reduced by 17.2% from baseline, but there was little change in the median level of high-sensitivity C-reactive protein .\n\n【44】Exploratory Outcomes\n--------------------\n\n【45】At day 510, a reduction from baseline in the mean LDL cholesterol level of 50% or more was reported in 92 patients (38.0%) in the inclisiran group and in 2 (0.8%) in the placebo group (P<0.001). An LDL cholesterol level of less than 100 mg per deciliter was reported in 158 patients (65.3%) in the inclisiran group and in 21 (8.8%) in the placebo group; of these patients, 40.8% in the inclisiran group and 1.3% in the placebo group had a level of less than 70 mg per deciliter (1.8 mmol per liter); 19.0% and 0.8%, respectively, had a level of less than 50 mg per deciliter (1.3 mmol per liter) . Among the patients with atherosclerotic cardiovascular disease in the inclisiran group, 38 of 59 (64%) had an LDL cholesterol level of less than 70 mg per deciliter.\n\n【46】Monogenic familial hypercholesterolemia variants were found in 317 of 432 patients (73.4%) who consented to genetic testing. Of these patients, 256 (80.8%) had single _LDLR_ causative variants, of whom 231 (90.2%) had _LDLR_ pathogenic variants, 17 (6.6%) had probably pathogenic variants, and 8 (3.1%) had variants that were of uncertain significance.\n\n【47】Of the 432 patients who were tested, 23 (5.3%) had variants in _APOB_ , and 1 had a PCSK9 gain-of-function variant in _PCSK9_ . In 37 patients (8.6%), two variants were consistent with either double heterozygous familial hypercholesterolemia (a variant in _LDLR_ and in either _APOB_ or _PCSK9_ ), compound heterozygous disease (two different variants in _LDLR_ ), or truly homozygous disease (two identical _LDLR_ variants).  The mean baseline LDL cholesterol level in these patients was 152.4 mg per deciliter (3.9 mmol per liter). The patients who had _LDLR_ pathogenic variants had the highest mean baseline LDL cholesterol level (160.8 mg per deciliter \\[4.2 mmol per liter\\]).\n\n【48】Table 2. Changes from Baseline in LDL Cholesterol Levels at Day 510, According to Genotype.\n\n【49】In the inclisiran group, the mean reductions in the LDL cholesterol levels were similar in patients with _LDLR_ pathogenic variants, probably pathogenic variants, and variants of uncertain significance. The mean between-group difference in the percent change in LDL cholesterol levels in patients with two identified variants was −41.2 percentage points. The corresponding between-group difference among the patients in whom a causative variant could not be identified was −59.2 percentage points; among the 50 patients who did not undergo genetic testing, the corresponding between-group difference was −46.8 percentage points . In patients with _APOB_ variants in the inclisiran group, the between-group difference was −52.1 percentage points; in the single patient with a _PCSK9_ gain-of-function variant, the between-group difference was −89.7 percentage points.\n\n【50】Safety and Adverse Events\n-------------------------\n\n【51】Table 3. Adverse Events and Key Safety Laboratory Results.\n\n【52】The adverse events that were reported in the safety population during treatment are shown in Table 3 . Adverse events that occurred during the trial period, regardless of causality, were reported in 185 of 241 patients (76.8%) in the inclisiran group and in 172 of 240 patients (71.7%) in the placebo group. The majority of events (94.6% in the inclisiran group and 91.9% in the placebo group) were reported as mild to moderate . More patients in the inclisiran group than in the placebo group had a protocol-defined injection-site reaction (17.0% vs. 1.7%), with the majority of events (90.2%) graded as mild and none described as severe or persistent. There was a lower number of serious adverse events with inclisiran than with placebo (7.5% vs. 13.8%). These events included 1 death in each of the groups, neither of which was thought to be related to the trial intervention by the investigators.\n\n【53】The frequency of adverse events was similar in the two groups as assessed according to system-organ class . Laboratory defined adverse events were also similar between the groups .\n\n【54】In the inclisiran group, low-titer antidrug antibodies were detected in 2.6% of the samples (25 samples from 18 patients), a finding that was consistent with assay-testing characteristics and not considered to be due to treatment with inclisiran. The presence of antidrug antibodies in post-treatment samples was often transient and not associated with changes in any pharmacologic or clinical measurements.\n\n【55】Discussion\n----------\n\n【56】Heterozygous familial hypercholesterolemia is a common condition and may account for as many as 1 in 10 cases of premature acute coronary syndromes.  The major driver of the risk of atherosclerotic cardiovascular disease among patients with this condition is the lifelong cumulative exposure to elevated levels of LDL cholesterol, especially when there is a delay in the initiation of effective cholesterol-lowering therapy.  In our trial, among patients who received a regimen of subcutaneous injections of inclisiran on days 1, 90, 270, and 450, the between-group difference in the percent change in the LDL cholesterol level from baseline to day 510 (the first primary end point) was a reduction of 47.9 percentage points in the inclisiran group. The corresponding between-group difference in the time-averaged percent change in the LDL cholesterol level between day 90 and day 540 (the second primary end point) was a reduction of 44.3 percentage points. It is notable that at baseline the majority of patients who had such reductions were receiving high-intensity statin therapy along with ezetimibe. In addition, 65% of the patients in the inclisiran group had an LDL cholesterol level of less than 100 mg per deciliter. These reductions were achieved without additional safety signals after four injections during a 16-month period.\n\n【57】The robust reduction in LDL cholesterol levels in patients with different monogenic _LDLR_ variants is consistent with the findings in trials of monoclonal antibodies and suggests that the response to PCSK9 inhibition is mainly dependent on the up-regulation of normally functioning LDL receptors on the hepatocyte surface, which override the minor role of clearance of LDL cholesterol by the up-regulation of dysfunctional LDL receptors.  This hypothesis is also supported by the observation that patients with _LDLR_ null homozygous familial hypercholesterolemia have either a poor response or no response to PCSK9 inhibition. \n\n【58】The significant reductions in lipoprotein(a) levels with inclisiran, as has been seen with PCSK9 monoclonal antibody therapy, contrasts with the actions of other drugs, especially statins, which also act by up-regulating the LDL receptor. Since an elevated lipoprotein(a) level is an independent risk factor for atherosclerotic cardiovascular disease, this activity may be an additional benefit of inclisiran therapy. \n\n【59】Since inclisiran acts predominantly in the liver, which is the main site of PCSK9 production, the reduction in LDL cholesterol levels with inclisiran in patients with heterozygous familial hypercholesterolemia is similar to that achieved with PCSK9 monoclonal antibody therapy.  The reduction in LDL cholesterol levels of almost 50% with twice-yearly administration of inclisiran in patients with heterozygous familial hypercholesterolemia who had been receiving maximally accepted background statin therapy has the potential to improve their adherence to the treatment regimen.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 11:02:24", "endTime": "2024/08/14 11:04:18", "cost": 114.527}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 19:04:18", "grab_time": "2024-08-13 19:02:23"}
{"id": 2234390, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "fd7b46e0-33c2-4f9b-80f6-08e7ebafeb70", "title": "Neglected — Cancer Care and Mental Health in Rural America", "text": "【0】Neglected — Cancer Care and Mental Health in Rural America\nThe woman had neglected breast cancer, but the root of her problem was bipolar disorder, for which her family, feeling guilty about committing her in the past, would no longer compel treatment. Moreover, much of rural America has less than 1 psychiatrist per 30,000 people.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:00:08", "endTime": "2024/08/14 15:00:28", "cost": 19.78}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 23:00:28", "grab_time": "2024-08-13 23:00:04"}
{"id": 2234389, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "0c849f94-10e8-48e6-b6fe-812ee298d1de", "title": "Circulating Iron-Containing Macrophages in Hemochromatosis", "text": "【0】Circulating Iron-Containing Macrophages in Hemochromatosis\nAbstract\n--------\n\n【1】Iron-containing macrophages, present in various tissues in patients with iron-storage diseases, have been demonstrated to pass from the intestinal villus into the intestinal lumen, acting to transport iron as well as to store it. It was proposed that these cells may transport iron from one organ to another and thus might be present in the circulating blood. Therefore, they were sought in buffy-coat preparations of venous blood in normal subjects and in patients with hemochromatosis and other iron-storage conditions such as transfusion siderosis. Circulating hemosiderin-containing cells were demonstrated in eight of the nine untreated patients with hemochromatosis and in four of 20 with other iron-storage disorders. None were found in normal subjects. The discovery of such cells in the circulating blood suggests an iron-storage disease although their absence does not exclude such a possibility. The macrophages in hemochromatosis appear different from those in transfusion siderosis, containing smaller granules of iron.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:40:01", "endTime": "2024/08/14 15:40:13", "cost": 12.654}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 23:40:13", "grab_time": "2024-08-13 23:40:00"}
{"id": 2234388, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "88dc5721-5819-40f7-a83c-77d9b7b2ae13", "title": "A Trial of Topical Acyclovir in Genital Herpes Simplex Virus Infections", "text": "【0】A Trial of Topical Acyclovir in Genital Herpes Simplex Virus Infections\nAbstract\n--------\n\n【1】Seventy-seven patients with first episodes of genital herpes and 111 with recurrent episodes were enrolled in a double-blind trial comparing topical acyclovir with a placebo (polyethylene glycol ointment). Among acyclovir-treated patients with first-episode primary genital herpes, the mean duration of viral shedding (4.1 days) and the time to complete crusting of lesions present at the initiation of therapy (7.1 days) were shorter than among placebo recipients (7.0 and 10.5 days, respectively) (P<0.05). Acyclovir-treated patients with recurrent herpes had a shorter duration of viral shedding than placebo recipients (0.95 vs. 1.90 days) (P = 0.03). Among the patients with recurrent herpes, acyclovir reduced the time to crusting of lesions in men but had no effect on the symptoms or healing times in women. Topical acyclovir shortens the duration of viral shedding and accelerates healing of some genital herpes simplex virus infections\\.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:27:31", "endTime": "2024/08/14 15:27:40", "cost": 8.412}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 23:27:40", "grab_time": "2024-08-13 23:27:31"}
{"id": 2234387, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "f1e4e947-e85c-4fbb-9f3f-5d49cc2e82b6", "title": "Prediction of Awakening after Out-of-Hospital Cardiac Arrest", "text": "【0】Prediction of Awakening after Out-of-Hospital Cardiac Arrest\nAbstract\n--------\n\n【1】To develop a model that would forecast neurologic recovery after out-of-hospital cardiac arrest, we reviewed charts on 389 consecutive patients who were not awake on admission to the hospital after resuscitation from asystole or ventricular fibrillation. The outcome variable was \"awakening,\" which was defined as having comprehensible speech or the ability to follow commands. Predictor variables that we considered included both preadmission and admission data. Using discriminant analysis, we derived models from a 60 per cent random sample of cases and tested the models on the remaining 40 per cent. We judged that the best model contained four variables from the admission examination: motor response, pupillary light response, spontaneous eye movements, and blood glucose (levels below 300 mg per deciliter predicted awakening). Overall correct classification was 80 per cent in the derivation sample and 77 per cent in the test sample. In a simplified form, the model's predictions of awakening had a sensitivity of 0.92, a specificity of 0.65, a positive predictive value of 0.80, and a negative predictive value of 0.84. This rule should be clinically useful in estimating the neurologic prognosis of patients resuscitated after out-of-hospital cardiac arrest.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 16:01:48", "endTime": "2024/08/13 16:22:49", "cost": 1261.305}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 00:22:49", "grab_time": "2024-08-13 00:01:48"}
{"id": 2234386, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "22477616-821b-4765-a673-1bafcbb16c52", "title": "Rice-Based Oral Electrolyte Solutions for the Management of Infantile Diarrhea", "text": "【0】Rice-Based Oral Electrolyte Solutions for the Management of Infantile Diarrhea\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】In infants the treatment of acute diarrhea with glucose-based solutions results in rehydration but does not reduce the severity of diarrhea. Oral rehydration with solutions based on rice powder may reduce stool output as well as restore fluid volume.\n\n【3】Methods.\n--------\n\n【4】We designed a prospective, randomized, double-blind study to evaluate the efficacy of two rice-based rehydration solutions and a conventional glucose-based solution. Solution A contained only rice-syrup solids, solution B contained rice-syrup solids and casein hydrolysate, and solution C, the glucose-based solution, served as control. The study subjects were 86 mildly to moderately dehydrated infant boys, 3 to 18 months old, who were admitted to a children's hospital with acute diarrhea. We measured fluid intake, fecal and urine output, and absorption and retention of fluid, sodium, and potassium at intervals for 48 hours in all 86 infants.\n\n【5】Results.\n--------\n\n【6】The mean (±SE) fecal output was significantly lower in the infants given solution A (group A infants) than in the infants given solution C (group C) (29±4 vs. 46±7 ml per kilogram of body weight, P<0.05) during the first six hours of therapy. The infants in group A also had greater fluid absorption (221±16 vs. 167±9 ml per kilogram, P<0.05) over the entire 48 hours of therapy and greater potassium absorption (1.6±0.2 vs. 0.6±0.1 mmol per kilogram, P<0.05) during the first six hours than the infants in group C. Solution B offered no advantages over solution A.\n\n【7】Conclusions.\n------------\n\n【8】Solutions containing rice-syrup solids were effective in the rehydration of infants with acute diarrhea. They decreased stool output and promoted greater absorption and retention of fluid and electrolytes than did a glucose-based solution. \n\n【9】Introduction\n------------\n\n【10】GLUCOSE-BASED oral rehydration solutions have provided a simple and successful means of treating or preventing dehydration due to acute diarrhea in infants and children. Although glucose-based solutions stimulate the intestinal absorption of fluid and electrolytes from isotonic luminal contents, they do not aid in the reabsorption of fluid secreted by the intestine.  Thus, these solutions do not lessen the severity of diarrhea. The lack of efficacy of oral rehydration therapy in reducing diarrhea is the primary barrier to its global acceptance; it is estimated that the oral-rehydration-therapy packets provided by the World Health Organization are used in only 19 percent of episodes of diarrhea worldwide. \n\n【11】Some but not all investigators have found that adding small carrier molecules, such as amino acids, to oral rehydration solutions improves their performance.  <sup><a>4 </a></sup>  Recent studies have indicated that oral rehydration solutions prepared from rice not only ameliorate dehydration but also decrease diarrheal fluid loss.  <sup><a>7 </a></sup>  <sup><a>9 </a></sup> The effects of these polymeric solutions are either comparable or superior to those of glucose-containing solutions.  The cited disadvantages of rice solutions, however, include the need for cooking, the possibility of incorrect preparation, and rapid fermentation.  <sup>, </sup>  In addition, some infants may not tolerate whole starch. \n\n【12】Two oral rehydration solutions have been developed that retain the advantages of a rice-based solution while eliminating the disadvantages mentioned above. One of these solutions contains rice-syrup solids prepared under industrial conditions from solubilized rice starch as a carbohydrate source; the other has the same rice-syrup solids plus casein hydrolysate. The solutions are ready to use and stable.\n\n【13】We designed this randomized, double-blind study to evaluate the safety and efficacy of these rice-based solutions in the management of mild to moderate dehydration in infants with acute diarrhea. A commercial glucose-based oral rehydration solution was also evaluated for comparison purposes.\n\n【14】Methods\n-------\n\n【15】Patients\n--------\n\n【16】Ninety-four infant boys, 3 to 18 months of age, were selected from patients entering the Emergency Service of the Hospital Nacional de Niños in San José, Costa Rica. All were candidates for oral rehydration therapy because they had mild (<5 percent) or moderate (5 to 10 percent) dehydration caused by acute diarrhea of less than seven days' duration. The study was conducted during a six-month period, from September 1988 through February 1989. Patients were excluded if any of the following conditions were present: severe malnutrition, obesity, absence of bowel sounds, pneumonia, meningitis, severe congenital or metabolic disease, convulsions, unconsciousness, or shock. No girls were included in the study, since the separate collection of urine and stool from infant girls is difficult unless catheters are used. We had no reason to think that the results of oral rehydration therapy would differ between boys and girls.\n\n【17】The population served by the hospital consists mostly of lower- and middle-class families from urban or rural-urban areas. The study was approved by the institutional review board for human research of the Costa Rican Social Security System and by the Hospital Nacional de Niños Clinical Investigations Committee. Written informed consent was obtained from each infant's parent or guardian at the time of admission.\n\n【18】Treatment Protocol\n------------------\n\n【19】Table 1. Composition of the Oral Solutions Used to Treat Infants with Acute Diarrhea.\n\n【20】After an initial clinical history taking and physical examination, the patients were admitted to the rehydration unit. By means of a computer-generated block randomization schedule (PLAN Procedure),  the infants were randomly assigned in double-blind fashion to one of three treatment groups. Those in group A received a rice-based electrolyte solution containing 30 g of rice-syrup solids and 50 mmol of sodium per liter (solution A; Ricelyte, Mead Johnson nutritional Group, Evansville, Ind.). Those in group B received a solution with the same ingredients, with the addition of 5 g of casein hydrolysate per liter (solution B; Mead Johnson nutritional Group). Infants in group C received a commercial oral rehydration solution containing 75 mmol of sodium and 25 g of glucose per liter (solution C; Rehydralyte, Ross Laboratories, Columbus, Ohio). The composition of the solutions is shown in Table 1 . The solutions were coded to keep investigators and parents unaware of which solution was being administered.\n\n【21】The rice-syrup solids were analyzed by high-performance liquid chromatography to determine the carbohydrate profile. The results were as follows: glucose, 3.5 percent; glucose polymers of two to six units, 64.9 percent; and glucose polymers of more than seven units, 31.6 percent. The casein hydrolysate was composed of small peptides (50 percent) and amino acids (50 percent).\n\n【22】At the time of admission, each infant's fluid deficit was determined by multiplying his weight at admission by the percent dehydration, which was estimated on the basis of clinical signs.  The randomly assigned solution was administered in a volume twice as great as the estimated fluid deficit within the next four to six hours. After he had ingested the solution, the infant's degree of hydration was reassessed. If rehydration had not been achieved, the same solution was administered again in a volume calculated on the basis of the most recent estimate of the infants's fluid deficit. \n\n【23】If the infant refused to drink the solution or vomited frequently, the solution was administered by nasogastric tube at a rate of 15 ml per kilogram of body weight per hour. If the solution was tolerated for 15 to 30 minutes, the rate of administration was increased to 30 ml per kilogram per hour. If an infant required intravenous therapy because of persistent serum electrolyte abnormalities, high fecal output, or continued vomiting, treatment was considered to have failed.\n\n【24】After rehydration, the patients received a soy-based formula containing 2.76 kJ (0.66 kcal) per milliliter (ProSobee, Mead Johnson nutritional Group) in a volume of 120 ml per kilogram every 24 hours. In addition, the infants were offered oral rehydration solution after each diarrheal stool in a volume equal to the stool volume. The infants who were breast-fed before admission were allowed to resume breast-feeding after rehydration. Breast-milk intake was estimated by subtracting the mean of three values for the infant's weight before nursing from the mean of three values for his weight afterward. Plain water was allowed ad libitum after rehydration.\n\n【25】The patients were discharged after 48 hours or 16 hours after the last diarrheal stool, whichever was later.\n\n【26】Intake, Output, and Balance Studies\n-----------------------------------\n\n【27】Fluid intake was measured for the following periods during the study: period 1, 0 to 6 hours; period 2, >6 to 12 hours; period 3, >12 to 24 hours; and period 4, >24 to 48 hours; it was also measured cumulatively, for the entire 48-hour study period. Net fluid intake was determined by subtracting the weight of any vomitus from the amount of fluid ingested. The weight of vomitus was calculated as the difference between the dry and wet weights of diapers used to collect the vomitus.\n\n【28】All infants remained on metabolic beds during the study; urine and feces were collected separately for the following periods: period 1, 0 to 6 hours; period 2, >6 to 12 hours; period 3, >12 to 24 hours; and period 4, >24 to 48 hours. Urine was measured and feces were weighed on a precision scale with a tolerance of 100 mg (Triple-Beam Balance Dial-O-Gram model 1630, Ohaus Scale, Union, N.J.).\n\n【29】Each infant's sodium and potassium intake was calculated on the basis of the composition of the ingested rehydration solutions and the soy formula. If infants were breast-fed, breast-milk samples were analyzed for sodium and potassium with a spectrophotometer (Astra-8, Beckman Instruments, Fullerton, Calif.), and these values were used in the calculations of intake. Fecal sodium content, potassium content, and osmolality and urinary sodium content, potassium content, specific gravity, and pH were also determined (Astra-8, OA TS Meter, American Optical, Buffalo, N.Y.; and Combur 8 Test, Boehringer–Mannheim, Waldhof, Germany).\n\n【30】The apparent absorption of fluid, sodium, and potassium was calculated by subtracting the fecal output from the net intake for the same period. The apparent retention of fluid, sodium, and potassium was calculated by subtracting both fecal and urinary output from net intake.\n\n【31】Other Measurements\n------------------\n\n【32】Nude body weights were recorded at admission, on completion of rehydration, and after 6, 12, 24, and 48 hours on a mechanical baby scale with a tolerance of 10 g (Doctor's Infant Scale, Detecto Scales, Brooklyn, N.Y.).\n\n【33】Blood was drawn at admission and after 6, 12, 24, and 48 hours for the measurement of pH and partial pressure of carbon dioxide, serum sodium, potassium, chloride, bicarbonate, glucose, and urea nitrogen levels, and osmolality (Astra-8; and pH/Blood Gas Analyzer model 1301, Instrumentation Laboratory, Milan, Italy). The initial samples of stool were examined for salmonella, shigella, _Campylobacter jejuni_ , cryptosporidium,  <sup><a>18 </a></sup>  and ova and parasites. Rotavirus antigen was identified in the stool with an enzyme-linked immunoassay.  <sup><a>19 </a></sup> \n\n【34】Statistical Analysis\n--------------------\n\n【35】The results are expressed as means ±SE unless otherwise indicated. Differences between treatments were tested for significance by analysis of variance. Treatment differences over time were tested by repeated-measures analysis of variance. Nonparametric data were tested by the chi-square test. Differences were considered significant when the P value was less than 0.05. The Statistical Analysis System (SAS) software was used for the analyses. \n\n【36】Results\n-------\n\n【37】Characteristics of Patients\n---------------------------\n\n【38】Of the 94 infants enrolled in the study, 8 were not included in the final analysis for reasons unrelated to treatment. In group A, bronchiolitis developed in one patient, and fecal collections were incomplete for two patients. In group B, fecal collections were incomplete for two patients, one had an epileptic seizure (a condition not identified in the history), and bronchiolitis developed in one. Output measurements were incomplete for one patient in group C. Thus, 30 infants remained in group A, 27 in group B, and 29 in group C, for a total of 86.\n\n【39】Table 2. Characteristics of the 86 Infants with Acute Diarrhea at Admission.\\*\n\n【40】The clinical characteristics of these 86 infant boys at the time of admission are shown in Table 2 . There were no significant differences between the groups except that the infants in group B were heavier than those in group A.\n\n【41】The distribution of stool samples positive for pathogens was similar in the three groups . The stools of 35 percent of the patients were positive for rotavirus antigen.\n\n【42】Intake, Output, and Balance Studies\n-----------------------------------\n\n【43】### _Fluids_\n\n【44】Reluctance to drink the solution led to its nasogastric administration to six infants in group A, one in group B, and five in group C. Four infants in group A, 14 in group B, and 4 in group C received the solutions by that route because of persistent vomiting.\n\n【45】Table 3. Fluid Intake, Fecal Output, and Apparent Fluid Absorption and Retention during Treatment in 86 Infants with Acute Diarrhea.\\*\n\n【46】During the first 12 hours, the volume of vomitus for the infants who received the rice-based solution with casein hydrolysate (group B, 38±8 ml per kilogram) was significantly greater than that for group A (15±8 ml per kilogram) or group C (21±8 ml per kilogram). The net fluid intake was comparable in the three groups of infants during the first six hours of treatment (period 1). From >6 to 12 hours (period 2) and from >24 to 48 hours (period 4), the infants fed the rice solution with casein hydrolysate (group B) had a lower net intake than those in the other two groups .\n\n【47】The mean fecal output was higher for the infants in group C during several periods . The fecal weights during the 48-hour study (periods 1 through 4) were 199±18 g per kilogram for group A, 145±15 g per kilogram for group B, and 264±35 g per kilogram for group C. Overall, the infants who received the rice-based solutions (groups A and B) had 25 and 45 percent less fecal output, respectively, than the infants in group C.\n\n【48】The apparent absorption of fluid in the infants in group A was significantly greater than that in the infants in groups B and C from 0 to 6 hours and from >12 to 24 hours after the beginning of therapy (periods 1 and 3). During the entire 48 hours of the study, the mean amount of fluid apparently absorbed by infants in group A was also significantly greater than that in the other two groups .\n\n【49】During the first six hours of therapy (period 1), the mean amount of fluid apparently retained was significantly greater in group A than in the other two groups. The apparent retention of fluid was also greater in the infants in group A than in those in group B during the entire 48-hour study period .\n\n【50】### _Sodium_\n\n【51】During the first six hours, sodium intake was significantly higher in the infants in group C, who received the oral rehydration solution with the highest sodium concentration (group A, 5.2±0.4 mmol per kilogram; group B, 4.3±0.3 mmol per kilogram; and group C, 7.6±0.7 mmol per kilogram). Although the infants in group C had higher intake values thereafter, the differences were significant only in comparison with group B. The sodium output in the feces of the infants in group C was significantly higher in the first six hours of therapy (group A, 1.4±0.3 mmol per kilogram; group B, 1.1±0.2 mmol per kilogram; and group C, 2.9±0.7 mmol per kilogram) and during the entire 48-hour study period (group A, 9.4±1.1 mmol per kilogram; group B, 5.7±0.7 mmol per kilogram; and group C, 15.7±2.6 mmol per kilogram).\n\n【52】Table 4. Apparent Retention of Sodium and Potassium during Treatment in 86 Infants with Acute Diarrhea.\\*\n\n【53】The apparent absorption and retention of sodium were generally comparable in the three groups throughout the study. Only during two collection periods (periods 1 and 4) did the infants receiving the rice-based solution with casein hydrolysate (group B) have significantly lower retention of sodium than those in group C .\n\n【54】### _Potassium_\n\n【55】The potassium intake of the infants in the three groups differed only during period 1 (0 to 6 hours), when that of the infants in group A was significantly higher than that in group C (group A, 2.7±0.2 mmol per kilogram; group B, 2.2±0.2 mmol per kilogram; and group C, 2.1±0.2 mmol per kilogram). During this six-hour period, the infants in group C had a significantly higher fecal output of potassium (group A, 1.0±0.1 mmol per kilogram; group B, 1.1±0.1 mmol per kilogram; and group C, 1.4±0.2 mmol per kilogram) than those in the other groups. The apparent absorption of potassium was significantly higher in the infants in group A than that in those in group C from 0 to 6 hours (P<0.05) (group A, 1.6±0.2 mmol per kilogram; group B, 1.2±0.1 mmol per kilogram; and group C, 0.6±0.1 mmol per kilogram) and for the entire 48-hour study period (P<0.05) (group A, 3.4±0.5 mmol per kilogram; group B, 2.7±0.5 mmol per kilogram; and group C, 1.8±0.5 mmol per kilogram). The amounts of potassium apparently retained are shown in Table 4 .\n\n【56】Measurements in Blood\n---------------------\n\n【57】The mean serum sodium concentrations in the three groups were within the normal range throughout the study. The 13 infants in groups A and B who had hypernatremia on admission (serum sodium level, ≥150 mmol per liter) all had normal levels after 24 hours, if not earlier. Of the two infants in group C who had hypernatremia on admission, one had normal serum sodium levels after 48 hours, and the other had persistent hypernatremia throughout his hospital stay. Both were asymptomatic.\n\n【58】Five infants had hyponatremia (serum sodium level, ≤130 mmol per liter) at the time of their entry into the study. Four of them had normal concentrations after 48 hours of treatment. The fifth (in group A) had persistent hyponatremia, with a high fecal output (16 ml per kilogram per hour) and fecal sodium concentrations of 60 to 83 mmol per liter. After 24 hours, this child received intravenous fluids. He had a seizure after beginning intravenous treatment but recovered uneventfully. This patient was the only one in whom treatment failed.\n\n【59】No significant differences were found in the mean serum chloride, potassium, bicarbonate, glucose, and urea nitrogen concentrations or in values for blood pH and partial pressure of carbon dioxide among the three groups at any time. The mean serum osmolality for the infants in group A was significantly lower than that for the infants in group C throughout the study (290±2 vs. 298±2 mmol per kilogram; P<0.05).\n\n【60】Clinical Outcomes\n-----------------\n\n【61】The percent gains in body weight after rehydration were comparable among the three groups: group A, 4.0±0.4 percent; group B, 5.2±0.6 percent; and group C, 4.6±0.5 percent. The average lengths of time necessary to achieve rehydration were not significantly different: group A, 7.3±0.6 hours; group B, 6.4±0.7 hours; and group C, 6.7±0.7 hours. The duration of diarrhea, measured as the time between the initiation of oral rehydration therapy and the last liquid stool, did not differ significantly: group A, 62.9±7.5 hours; group B, 51.1±4.5 hours; and group C, 55.8±5.3 hours.\n\n【62】Discussion\n----------\n\n【63】Most oral rehydration solutions contain glucose and electrolytes. No optimal composition has been determined, however.  <sup>, </sup>  The results of this clinical trial, in which we used stable, ready-to-use, commercially prepared oral rehydration solutions containing rice-syrup solids, indicate that such solutions may be more efficient than glucose-based solutions in promoting fluid and electrolyte absorption during the rehydration phase in infants with acute diarrhea. In the 48-hour study, the infants in the two groups (groups A and B) that received rice solutions had lower fecal outputs than those in group C, who received the glucose solution. The mean fecal output of the infants in group A was 25 percent lower and that of the infants in group B was 45 percent lower than that of the infants in group C. In addition, the infants in group A had higher values for the absorption of fluid and potassium. Furthermore, even though the rice-based solutions contained one third less sodium, the groups' sodium balances were similar. These results suggest that the rice-syrup solids were very efficient in promoting sodium absorption.\n\n【64】One possible explanation for these results is the lower osmolality of the rice-based solutions. Hypotonie solutions promote water absorption in the proximal jejunum more effectively than isotonic solutions.  Thus, polymeric solutions permit glucose to be administered at little osmotic cost. Moreover, rice-syrup solids contain primarily short-chain glucose polymers. This makes them a readily available substrate for digestion by glucoamylase,  an intestinal enzyme that is present in infants and is relatively resistant to intestinal mucosal injury. \n\n【65】It has been theorized that the amino acids in oral rehydration solutions might potentiate the effects of carbohydrate on the absorption of sodium and water.  We added casein hydrolysate to one of our rice solutions to test this theory. We found that the infants receiving that solution (group B) had a lower net intake of rehydration solution because they vomited more during the rehydration period. The reduced intake could have been a factor in the infants' low stool output (the lowest among the groups). For most of the other measurements, there were no important differences between the two groups receiving solutions made with rice-syrup solids (with and without casein hydrolysate). Consequently, there appears to be no advantage to adding casein hydrolysate to a solution of this kind. However, the addition of other specific amino acids, different peptides, or both, may further enhance the absorption of fluid and electrolytes.\n\n【66】All three oral rehydration solutions were effective treatments for mild to moderate dehydration due to acute diarrhea. In only one infant, who had a high stool output and persistent hyponatremia, was treatment considered to have failed; this infant required intravenous therapy. The rehydration solution containing 50 mmol of sodium per liter was inadequate to correct his condition. Several investigators have reported that solutions with sodium concentrations of 50 or 75 mmol per liter are adequate for rehydration of well-nourished children with cholera.  <sup>, </sup>  <sup>, </sup>  However, the oral rehydration solutions failed to reverse hyponatremia in more than half of patients when the fecal output exceeded 10 ml per kilogram per hour, even when the rehydration solution contained 90 mmol of sodium per liter. \n\n【67】In summary, oral rehydration solutions containing rice-syrup solids were found to be superior to a glucose-based solution in decreasing stool output. Since the solution containing rice-syrup solids without added casein hydrolysate promoted higher water and potassium balances and was better tolerated, it may be the most suitable solution for the management of acute diarrhea in infants without cholera.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": " (Triple-Beam Balance Dial-O-Gram model 1630, Ohaus Scale, Union, N.J.).", "content": "【0】Rice-Based Oral Electrolyte Solutions for the Management of Infantile Diarrhea\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】In infants the treatment of acute diarrhea with glucose-based solutions results in rehydration but does not reduce the severity of diarrhea. Oral rehydration with solutions based on rice powder may reduce stool output as well as restore fluid volume.\n\n【3】Methods.\n--------\n\n【4】We designed a prospective, randomized, double-blind study to evaluate the efficacy of two rice-based rehydration solutions and a conventional glucose-based solution. Solution A contained only rice-syrup solids, solution B contained rice-syrup solids and casein hydrolysate, and solution C, the glucose-based solution, served as control. The study subjects were 86 mildly to moderately dehydrated infant boys, 3 to 18 months old, who were admitted to a children's hospital with acute diarrhea. We measured fluid intake, fecal and urine output, and absorption and retention of fluid, sodium, and potassium at intervals for 48 hours in all 86 infants.\n\n【5】Results.\n--------\n\n【6】The mean (±SE) fecal output was significantly lower in the infants given solution A (group A infants) than in the infants given solution C (group C) (29±4 vs. 46±7 ml per kilogram of body weight, P<0.05) during the first six hours of therapy. The infants in group A also had greater fluid absorption (221±16 vs. 167±9 ml per kilogram, P<0.05) over the entire 48 hours of therapy and greater potassium absorption (1.6±0.2 vs. 0.6±0.1 mmol per kilogram, P<0.05) during the first six hours than the infants in group C. Solution B offered no advantages over solution A.\n\n【7】Conclusions.\n------------\n\n【8】Solutions containing rice-syrup solids were effective in the rehydration of infants with acute diarrhea. They decreased stool output and promoted greater absorption and retention of fluid and electrolytes than did a glucose-based solution. \n\n【9】Introduction\n------------\n\n【10】GLUCOSE-BASED oral rehydration solutions have provided a simple and successful means of treating or preventing dehydration due to acute diarrhea in infants and children. Although glucose-based solutions stimulate the intestinal absorption of fluid and electrolytes from isotonic luminal contents, they do not aid in the reabsorption of fluid secreted by the intestine.  Thus, these solutions do not lessen the severity of diarrhea. The lack of efficacy of oral rehydration therapy in reducing diarrhea is the primary barrier to its global acceptance; it is estimated that the oral-rehydration-therapy packets provided by the World Health Organization are used in only 19 percent of episodes of diarrhea worldwide. \n\n【11】Some but not all investigators have found that adding small carrier molecules, such as amino acids, to oral rehydration solutions improves their performance.  <sup><a>4 </a></sup>  Recent studies have indicated that oral rehydration solutions prepared from rice not only ameliorate dehydration but also decrease diarrheal fluid loss.  <sup><a>7 </a></sup>  <sup><a>9 </a></sup> The effects of these polymeric solutions are either comparable or superior to those of glucose-containing solutions.  The cited disadvantages of rice solutions, however, include the need for cooking, the possibility of incorrect preparation, and rapid fermentation.  <sup>, </sup>  In addition, some infants may not tolerate whole starch. \n\n【12】Two oral rehydration solutions have been developed that retain the advantages of a rice-based solution while eliminating the disadvantages mentioned above. One of these solutions contains rice-syrup solids prepared under industrial conditions from solubilized rice starch as a carbohydrate source; the other has the same rice-syrup solids plus casein hydrolysate. The solutions are ready to use and stable.\n\n【13】We designed this randomized, double-blind study to evaluate the safety and efficacy of these rice-based solutions in the management of mild to moderate dehydration in infants with acute diarrhea. A commercial glucose-based oral rehydration solution was also evaluated for comparison purposes.\n\n【14】Methods\n-------\n\n【15】Patients\n--------\n\n【16】Ninety-four infant boys, 3 to 18 months of age, were selected from patients entering the Emergency Service of the Hospital Nacional de Niños in San José, Costa Rica. All were candidates for oral rehydration therapy because they had mild (<5 percent) or moderate (5 to 10 percent) dehydration caused by acute diarrhea of less than seven days' duration. The study was conducted during a six-month period, from September 1988 through February 1989. Patients were excluded if any of the following conditions were present: severe malnutrition, obesity, absence of bowel sounds, pneumonia, meningitis, severe congenital or metabolic disease, convulsions, unconsciousness, or shock. No girls were included in the study, since the separate collection of urine and stool from infant girls is difficult unless catheters are used. We had no reason to think that the results of oral rehydration therapy would differ between boys and girls.\n\n【17】The population served by the hospital consists mostly of lower- and middle-class families from urban or rural-urban areas. The study was approved by the institutional review board for human research of the Costa Rican Social Security System and by the Hospital Nacional de Niños Clinical Investigations Committee. Written informed consent was obtained from each infant's parent or guardian at the time of admission.\n\n【18】Treatment Protocol\n------------------\n\n<mark>【19】Table 1. </mark>Composition of the Oral Solutions Used to Treat Infants with Acute Diarrhea.\n\n【20】After an initial clinical history taking and physical examination, the patients were admitted to the rehydration unit. By means of a computer-generated block randomization schedule (PLAN Procedure),  the infants were randomly assigned in double-blind fashion to one of three treatment groups. Those in group A received a rice-based electrolyte solution containing 30 g of rice-syrup solids and 50 mmol of sodium per liter (solution A; Ricelyte, Mead Johnson nutritional Group, Evansville, Ind.). Those in group B received a solution with the same ingredients, with the addition of 5 g of casein hydrolysate per liter (solution B; Mead Johnson nutritional Group). Infants in group C received a commercial oral rehydration solution containing 75 mmol of sodium and 25 g of glucose per liter (solution C; Rehydralyte, Ross Laboratories, Columbus, Ohio).<mark> The composition of the solutions is shown in Table 1 .</mark> The solutions were coded to keep investigators and parents unaware of which solution was being administered.\n\n【21】The rice-syrup solids were analyzed by high-performance liquid chromatography to determine the carbohydrate profile. The results were as follows: glucose, 3.5 percent; glucose polymers of two to six units, 64.9 percent; and glucose polymers of more than seven units, 31.6 percent. The casein hydrolysate was composed of small peptides (50 percent) and amino acids (50 percent).\n\n【22】At the time of admission, each infant's fluid deficit was determined by multiplying his weight at admission by the percent dehydration, which was estimated on the basis of clinical signs.  The randomly assigned solution was administered in a volume twice as great as the estimated fluid deficit within the next four to six hours. After he had ingested the solution, the infant's degree of hydration was reassessed. If rehydration had not been achieved, the same solution was administered again in a volume calculated on the basis of the most recent estimate of the infants's fluid deficit. \n\n【23】If the infant refused to drink the solution or vomited frequently, the solution was administered by nasogastric tube at a rate of 15 ml per kilogram of body weight per hour. If the solution was tolerated for 15 to 30 minutes, the rate of administration was increased to 30 ml per kilogram per hour. If an infant required intravenous therapy because of persistent serum electrolyte abnormalities, high fecal output, or continued vomiting, treatment was considered to have failed.\n\n【24】After rehydration, the patients received a soy-based formula containing 2.76 kJ (0.66 kcal) per milliliter (ProSobee, Mead Johnson nutritional Group) in a volume of 120 ml per kilogram every 24 hours. In addition, the infants were offered oral rehydration solution after each diarrheal stool in a volume equal to the stool volume. The infants who were breast-fed before admission were allowed to resume breast-feeding after rehydration. Breast-milk intake was estimated by subtracting the mean of three values for the infant's weight before nursing from the mean of three values for his weight afterward. Plain water was allowed ad libitum after rehydration.\n\n【25】The patients were discharged after 48 hours or 16 hours after the last diarrheal stool, whichever was later.\n\n【26】Intake, Output, and Balance Studies\n-----------------------------------\n\n【27】Fluid intake was measured for the following periods during the study: period 1, 0 to 6 hours; period 2, >6 to 12 hours; period 3, >12 to 24 hours; and period 4, >24 to 48 hours; it was also measured cumulatively, for the entire 48-hour study period. Net fluid intake was determined by subtracting the weight of any vomitus from the amount of fluid ingested. The weight of vomitus was calculated as the difference between the dry and wet weights of diapers used to collect the vomitus.\n\n【28】All infants remained on metabolic beds during the study; urine and feces were collected separately for the following periods: period 1, 0 to 6 hours; period 2, >6 to 12 hours; period 3, >12 to 24 hours; and period 4, >24 to 48 hours. Urine was measured and feces were weighed on a precision scale with a tolerance of 100 mg (Triple-Beam Balance Dial-O-Gram model 1630, Ohaus Scale, Union, N.J.).\n\n【29】Each infant's sodium and potassium intake was calculated on the basis of the composition of the ingested rehydration solutions and the soy formula. If infants were breast-fed, breast-milk samples were analyzed for sodium and potassium with a spectrophotometer (Astra-8, Beckman Instruments, Fullerton, Calif.), and these values were used in the calculations of intake. Fecal sodium content, potassium content, and osmolality and urinary sodium content, potassium content, specific gravity, and pH were also determined (Astra-8, OA TS Meter, American Optical, Buffalo, N.Y.; and Combur 8 Test, Boehringer–Mannheim, Waldhof, Germany).\n\n【30】The apparent absorption of fluid, sodium, and potassium was calculated by subtracting the fecal output from the net intake for the same period. The apparent retention of fluid, sodium, and potassium was calculated by subtracting both fecal and urinary output from net intake.\n\n【31】Other Measurements\n------------------\n\n【32】Nude body weights were recorded at admission, on completion of rehydration, and after 6, 12, 24, and 48 hours on a mechanical baby scale with a tolerance of 10 g (Doctor's Infant Scale, Detecto Scales, Brooklyn, N.Y.).\n\n【33】Blood was drawn at admission and after 6, 12, 24, and 48 hours for the measurement of pH and partial pressure of carbon dioxide, serum sodium, potassium, chloride, bicarbonate, glucose, and urea nitrogen levels, and osmolality (Astra-8; and pH/Blood Gas Analyzer model 1301, Instrumentation Laboratory, Milan, Italy). The initial samples of stool were examined for salmonella, shigella, _Campylobacter jejuni_ , cryptosporidium,  <sup><a>18 </a></sup>  and ova and parasites. Rotavirus antigen was identified in the stool with an enzyme-linked immunoassay.  <sup><a>19 </a></sup> \n\n【34】Statistical Analysis\n--------------------\n\n【35】The results are expressed as means ±SE unless otherwise indicated. Differences between treatments were tested for significance by analysis of variance. Treatment differences over time were tested by repeated-measures analysis of variance. Nonparametric data were tested by the chi-square test. Differences were considered significant when the P value was less than 0.05. The Statistical Analysis System (SAS) software was used for the analyses. \n\n【36】Results\n-------\n\n【37】Characteristics of Patients\n---------------------------\n\n【38】Of the 94 infants enrolled in the study, 8 were not included in the final analysis for reasons unrelated to treatment. In group A, bronchiolitis developed in one patient, and fecal collections were incomplete for two patients. In group B, fecal collections were incomplete for two patients, one had an epileptic seizure (a condition not identified in the history), and bronchiolitis developed in one. Output measurements were incomplete for one patient in group C. Thus, 30 infants remained in group A, 27 in group B, and 29 in group C, for a total of 86.\n\n【39】Table 2. Characteristics of the 86 Infants with Acute Diarrhea at Admission.\\*\n\n【40】The clinical characteristics of these 86 infant boys at the time of admission are shown in Table 2 . There were no significant differences between the groups except that the infants in group B were heavier than those in group A.\n\n【41】The distribution of stool samples positive for pathogens was similar in the three groups . The stools of 35 percent of the patients were positive for rotavirus antigen.\n\n【42】Intake, Output, and Balance Studies\n-----------------------------------\n\n【43】### _Fluids_\n\n【44】Reluctance to drink the solution led to its nasogastric administration to six infants in group A, one in group B, and five in group C. Four infants in group A, 14 in group B, and 4 in group C received the solutions by that route because of persistent vomiting.\n\n【45】Table 3. Fluid Intake, Fecal Output, and Apparent Fluid Absorption and Retention during Treatment in 86 Infants with Acute Diarrhea.\\*\n\n【46】During the first 12 hours, the volume of vomitus for the infants who received the rice-based solution with casein hydrolysate (group B, 38±8 ml per kilogram) was significantly greater than that for group A (15±8 ml per kilogram) or group C (21±8 ml per kilogram). The net fluid intake was comparable in the three groups of infants during the first six hours of treatment (period 1). From >6 to 12 hours (period 2) and from >24 to 48 hours (period 4), the infants fed the rice solution with casein hydrolysate (group B) had a lower net intake than those in the other two groups .\n\n【47】The mean fecal output was higher for the infants in group C during several periods . The fecal weights during the 48-hour study (periods 1 through 4) were 199±18 g per kilogram for group A, 145±15 g per kilogram for group B, and 264±35 g per kilogram for group C. Overall, the infants who received the rice-based solutions (groups A and B) had 25 and 45 percent less fecal output, respectively, than the infants in group C.\n\n【48】The apparent absorption of fluid in the infants in group A was significantly greater than that in the infants in groups B and C from 0 to 6 hours and from >12 to 24 hours after the beginning of therapy (periods 1 and 3). During the entire 48 hours of the study, the mean amount of fluid apparently absorbed by infants in group A was also significantly greater than that in the other two groups .\n\n【49】During the first six hours of therapy (period 1), the mean amount of fluid apparently retained was significantly greater in group A than in the other two groups. The apparent retention of fluid was also greater in the infants in group A than in those in group B during the entire 48-hour study period .\n\n【50】### _Sodium_\n\n【51】During the first six hours, sodium intake was significantly higher in the infants in group C, who received the oral rehydration solution with the highest sodium concentration (group A, 5.2±0.4 mmol per kilogram; group B, 4.3±0.3 mmol per kilogram; and group C, 7.6±0.7 mmol per kilogram). Although the infants in group C had higher intake values thereafter, the differences were significant only in comparison with group B. The sodium output in the feces of the infants in group C was significantly higher in the first six hours of therapy (group A, 1.4±0.3 mmol per kilogram; group B, 1.1±0.2 mmol per kilogram; and group C, 2.9±0.7 mmol per kilogram) and during the entire 48-hour study period (group A, 9.4±1.1 mmol per kilogram; group B, 5.7±0.7 mmol per kilogram; and group C, 15.7±2.6 mmol per kilogram).\n\n【52】Table 4. Apparent Retention of Sodium and Potassium during Treatment in 86 Infants with Acute Diarrhea.\\*\n\n【53】The apparent absorption and retention of sodium were generally comparable in the three groups throughout the study. Only during two collection periods (periods 1 and 4) did the infants receiving the rice-based solution with casein hydrolysate (group B) have significantly lower retention of sodium than those in group C .\n\n【54】### _Potassium_\n\n【55】The potassium intake of the infants in the three groups differed only during period 1 (0 to 6 hours), when that of the infants in group A was significantly higher than that in group C (group A, 2.7±0.2 mmol per kilogram; group B, 2.2±0.2 mmol per kilogram; and group C, 2.1±0.2 mmol per kilogram). During this six-hour period, the infants in group C had a significantly higher fecal output of potassium (group A, 1.0±0.1 mmol per kilogram; group B, 1.1±0.1 mmol per kilogram; and group C, 1.4±0.2 mmol per kilogram) than those in the other groups. The apparent absorption of potassium was significantly higher in the infants in group A than that in those in group C from 0 to 6 hours (P<0.05) (group A, 1.6±0.2 mmol per kilogram; group B, 1.2±0.1 mmol per kilogram; and group C, 0.6±0.1 mmol per kilogram) and for the entire 48-hour study period (P<0.05) (group A, 3.4±0.5 mmol per kilogram; group B, 2.7±0.5 mmol per kilogram; and group C, 1.8±0.5 mmol per kilogram). The amounts of potassium apparently retained are shown in Table 4 .\n\n【56】Measurements in Blood\n---------------------\n\n【57】The mean serum sodium concentrations in the three groups were within the normal range throughout the study. The 13 infants in groups A and B who had hypernatremia on admission (serum sodium level, ≥150 mmol per liter) all had normal levels after 24 hours, if not earlier. Of the two infants in group C who had hypernatremia on admission, one had normal serum sodium levels after 48 hours, and the other had persistent hypernatremia throughout his hospital stay. Both were asymptomatic.\n\n【58】Five infants had hyponatremia (serum sodium level, ≤130 mmol per liter) at the time of their entry into the study. Four of them had normal concentrations after 48 hours of treatment. The fifth (in group A) had persistent hyponatremia, with a high fecal output (16 ml per kilogram per hour) and fecal sodium concentrations of 60 to 83 mmol per liter. After 24 hours, this child received intravenous fluids. He had a seizure after beginning intravenous treatment but recovered uneventfully. This patient was the only one in whom treatment failed.\n\n【59】No significant differences were found in the mean serum chloride, potassium, bicarbonate, glucose, and urea nitrogen concentrations or in values for blood pH and partial pressure of carbon dioxide among the three groups at any time. The mean serum osmolality for the infants in group A was significantly lower than that for the infants in group C throughout the study (290±2 vs. 298±2 mmol per kilogram; P<0.05).\n\n【60】Clinical Outcomes\n-----------------\n\n【61】The percent gains in body weight after rehydration were comparable among the three groups: group A, 4.0±0.4 percent; group B, 5.2±0.6 percent; and group C, 4.6±0.5 percent. The average lengths of time necessary to achieve rehydration were not significantly different: group A, 7.3±0.6 hours; group B, 6.4±0.7 hours; and group C, 6.7±0.7 hours. The duration of diarrhea, measured as the time between the initiation of oral rehydration therapy and the last liquid stool, did not differ significantly: group A, 62.9±7.5 hours; group B, 51.1±4.5 hours; and group C, 55.8±5.3 hours.\n\n【62】Discussion\n----------\n\n【63】Most oral rehydration solutions contain glucose and electrolytes. No optimal composition has been determined, however.  <sup>, </sup>  The results of this clinical trial, in which we used stable, ready-to-use, commercially prepared oral rehydration solutions containing rice-syrup solids, indicate that such solutions may be more efficient than glucose-based solutions in promoting fluid and electrolyte absorption during the rehydration phase in infants with acute diarrhea. In the 48-hour study, the infants in the two groups (groups A and B) that received rice solutions had lower fecal outputs than those in group C, who received the glucose solution. The mean fecal output of the infants in group A was 25 percent lower and that of the infants in group B was 45 percent lower than that of the infants in group C. In addition, the infants in group A had higher values for the absorption of fluid and potassium. Furthermore, even though the rice-based solutions contained one third less sodium, the groups' sodium balances were similar. These results suggest that the rice-syrup solids were very efficient in promoting sodium absorption.\n\n【64】One possible explanation for these results is the lower osmolality of the rice-based solutions. Hypotonie solutions promote water absorption in the proximal jejunum more effectively than isotonic solutions.  Thus, polymeric solutions permit glucose to be administered at little osmotic cost. Moreover, rice-syrup solids contain primarily short-chain glucose polymers. This makes them a readily available substrate for digestion by glucoamylase,  an intestinal enzyme that is present in infants and is relatively resistant to intestinal mucosal injury. \n\n【65】It has been theorized that the amino acids in oral rehydration solutions might potentiate the effects of carbohydrate on the absorption of sodium and water.  We added casein hydrolysate to one of our rice solutions to test this theory. We found that the infants receiving that solution (group B) had a lower net intake of rehydration solution because they vomited more during the rehydration period. The reduced intake could have been a factor in the infants' low stool output (the lowest among the groups). For most of the other measurements, there were no important differences between the two groups receiving solutions made with rice-syrup solids (with and without casein hydrolysate). Consequently, there appears to be no advantage to adding casein hydrolysate to a solution of this kind. However, the addition of other specific amino acids, different peptides, or both, may further enhance the absorption of fluid and electrolytes.\n\n【66】All three oral rehydration solutions were effective treatments for mild to moderate dehydration due to acute diarrhea. In only one infant, who had a high stool output and persistent hyponatremia, was treatment considered to have failed; this infant required intravenous therapy. The rehydration solution containing 50 mmol of sodium per liter was inadequate to correct his condition. Several investigators have reported that solutions with sodium concentrations of 50 or 75 mmol per liter are adequate for rehydration of well-nourished children with cholera.  <sup>, </sup>  <sup>, </sup>  However, the oral rehydration solutions failed to reverse hyponatremia in more than half of patients when the fecal output exceeded 10 ml per kilogram per hour, even when the rehydration solution contained 90 mmol of sodium per liter. \n\n【67】In summary, oral rehydration solutions containing rice-syrup solids were found to be superior to a glucose-based solution in decreasing stool output. Since the solution containing rice-syrup solids without added casein hydrolysate promoted higher water and potassium balances and was better tolerated, it may be the most suitable solution for the management of acute diarrhea in infants without cholera.", "index": 9822, "show": true, "start": 9796, "end": 9868, "province": ["文本干净度", "无关文本"], "isEdit": false}, {"text": " (Astra-8, OA TS Meter, American Optical, Buffalo, N.Y.; and Combur 8 Test, Boehringer–Mannheim, Waldhof, Germany).", "content": "【0】Rice-Based Oral Electrolyte Solutions for the Management of Infantile Diarrhea\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】In infants the treatment of acute diarrhea with glucose-based solutions results in rehydration but does not reduce the severity of diarrhea. Oral rehydration with solutions based on rice powder may reduce stool output as well as restore fluid volume.\n\n【3】Methods.\n--------\n\n【4】We designed a prospective, randomized, double-blind study to evaluate the efficacy of two rice-based rehydration solutions and a conventional glucose-based solution. Solution A contained only rice-syrup solids, solution B contained rice-syrup solids and casein hydrolysate, and solution C, the glucose-based solution, served as control. The study subjects were 86 mildly to moderately dehydrated infant boys, 3 to 18 months old, who were admitted to a children's hospital with acute diarrhea. We measured fluid intake, fecal and urine output, and absorption and retention of fluid, sodium, and potassium at intervals for 48 hours in all 86 infants.\n\n【5】Results.\n--------\n\n【6】The mean (±SE) fecal output was significantly lower in the infants given solution A (group A infants) than in the infants given solution C (group C) (29±4 vs. 46±7 ml per kilogram of body weight, P<0.05) during the first six hours of therapy. The infants in group A also had greater fluid absorption (221±16 vs. 167±9 ml per kilogram, P<0.05) over the entire 48 hours of therapy and greater potassium absorption (1.6±0.2 vs. 0.6±0.1 mmol per kilogram, P<0.05) during the first six hours than the infants in group C. Solution B offered no advantages over solution A.\n\n【7】Conclusions.\n------------\n\n【8】Solutions containing rice-syrup solids were effective in the rehydration of infants with acute diarrhea. They decreased stool output and promoted greater absorption and retention of fluid and electrolytes than did a glucose-based solution. \n\n【9】Introduction\n------------\n\n【10】GLUCOSE-BASED oral rehydration solutions have provided a simple and successful means of treating or preventing dehydration due to acute diarrhea in infants and children. Although glucose-based solutions stimulate the intestinal absorption of fluid and electrolytes from isotonic luminal contents, they do not aid in the reabsorption of fluid secreted by the intestine.  Thus, these solutions do not lessen the severity of diarrhea. The lack of efficacy of oral rehydration therapy in reducing diarrhea is the primary barrier to its global acceptance; it is estimated that the oral-rehydration-therapy packets provided by the World Health Organization are used in only 19 percent of episodes of diarrhea worldwide. \n\n【11】Some but not all investigators have found that adding small carrier molecules, such as amino acids, to oral rehydration solutions improves their performance.  <sup><a>4 </a></sup>  Recent studies have indicated that oral rehydration solutions prepared from rice not only ameliorate dehydration but also decrease diarrheal fluid loss.  <sup><a>7 </a></sup>  <sup><a>9 </a></sup> The effects of these polymeric solutions are either comparable or superior to those of glucose-containing solutions.  The cited disadvantages of rice solutions, however, include the need for cooking, the possibility of incorrect preparation, and rapid fermentation.  <sup>, </sup>  In addition, some infants may not tolerate whole starch. \n\n【12】Two oral rehydration solutions have been developed that retain the advantages of a rice-based solution while eliminating the disadvantages mentioned above. One of these solutions contains rice-syrup solids prepared under industrial conditions from solubilized rice starch as a carbohydrate source; the other has the same rice-syrup solids plus casein hydrolysate. The solutions are ready to use and stable.\n\n【13】We designed this randomized, double-blind study to evaluate the safety and efficacy of these rice-based solutions in the management of mild to moderate dehydration in infants with acute diarrhea. A commercial glucose-based oral rehydration solution was also evaluated for comparison purposes.\n\n【14】Methods\n-------\n\n【15】Patients\n--------\n\n【16】Ninety-four infant boys, 3 to 18 months of age, were selected from patients entering the Emergency Service of the Hospital Nacional de Niños in San José, Costa Rica. All were candidates for oral rehydration therapy because they had mild (<5 percent) or moderate (5 to 10 percent) dehydration caused by acute diarrhea of less than seven days' duration. The study was conducted during a six-month period, from September 1988 through February 1989. Patients were excluded if any of the following conditions were present: severe malnutrition, obesity, absence of bowel sounds, pneumonia, meningitis, severe congenital or metabolic disease, convulsions, unconsciousness, or shock. No girls were included in the study, since the separate collection of urine and stool from infant girls is difficult unless catheters are used. We had no reason to think that the results of oral rehydration therapy would differ between boys and girls.\n\n【17】The population served by the hospital consists mostly of lower- and middle-class families from urban or rural-urban areas. The study was approved by the institutional review board for human research of the Costa Rican Social Security System and by the Hospital Nacional de Niños Clinical Investigations Committee. Written informed consent was obtained from each infant's parent or guardian at the time of admission.\n\n【18】Treatment Protocol\n------------------\n\n<mark>【19】Table 1. </mark>Composition of the Oral Solutions Used to Treat Infants with Acute Diarrhea.\n\n【20】After an initial clinical history taking and physical examination, the patients were admitted to the rehydration unit. By means of a computer-generated block randomization schedule (PLAN Procedure),  the infants were randomly assigned in double-blind fashion to one of three treatment groups. Those in group A received a rice-based electrolyte solution containing 30 g of rice-syrup solids and 50 mmol of sodium per liter (solution A; Ricelyte, Mead Johnson nutritional Group, Evansville, Ind.). Those in group B received a solution with the same ingredients, with the addition of 5 g of casein hydrolysate per liter (solution B; Mead Johnson nutritional Group). Infants in group C received a commercial oral rehydration solution containing 75 mmol of sodium and 25 g of glucose per liter (solution C; Rehydralyte, Ross Laboratories, Columbus, Ohio).<mark> The composition of the solutions is shown in Table 1 .</mark> The solutions were coded to keep investigators and parents unaware of which solution was being administered.\n\n【21】The rice-syrup solids were analyzed by high-performance liquid chromatography to determine the carbohydrate profile. The results were as follows: glucose, 3.5 percent; glucose polymers of two to six units, 64.9 percent; and glucose polymers of more than seven units, 31.6 percent. The casein hydrolysate was composed of small peptides (50 percent) and amino acids (50 percent).\n\n【22】At the time of admission, each infant's fluid deficit was determined by multiplying his weight at admission by the percent dehydration, which was estimated on the basis of clinical signs.  The randomly assigned solution was administered in a volume twice as great as the estimated fluid deficit within the next four to six hours. After he had ingested the solution, the infant's degree of hydration was reassessed. If rehydration had not been achieved, the same solution was administered again in a volume calculated on the basis of the most recent estimate of the infants's fluid deficit. \n\n【23】If the infant refused to drink the solution or vomited frequently, the solution was administered by nasogastric tube at a rate of 15 ml per kilogram of body weight per hour. If the solution was tolerated for 15 to 30 minutes, the rate of administration was increased to 30 ml per kilogram per hour. If an infant required intravenous therapy because of persistent serum electrolyte abnormalities, high fecal output, or continued vomiting, treatment was considered to have failed.\n\n【24】After rehydration, the patients received a soy-based formula containing 2.76 kJ (0.66 kcal) per milliliter (ProSobee, Mead Johnson nutritional Group) in a volume of 120 ml per kilogram every 24 hours. In addition, the infants were offered oral rehydration solution after each diarrheal stool in a volume equal to the stool volume. The infants who were breast-fed before admission were allowed to resume breast-feeding after rehydration. Breast-milk intake was estimated by subtracting the mean of three values for the infant's weight before nursing from the mean of three values for his weight afterward. Plain water was allowed ad libitum after rehydration.\n\n【25】The patients were discharged after 48 hours or 16 hours after the last diarrheal stool, whichever was later.\n\n【26】Intake, Output, and Balance Studies\n-----------------------------------\n\n【27】Fluid intake was measured for the following periods during the study: period 1, 0 to 6 hours; period 2, >6 to 12 hours; period 3, >12 to 24 hours; and period 4, >24 to 48 hours; it was also measured cumulatively, for the entire 48-hour study period. Net fluid intake was determined by subtracting the weight of any vomitus from the amount of fluid ingested. The weight of vomitus was calculated as the difference between the dry and wet weights of diapers used to collect the vomitus.\n\n【28】All infants remained on metabolic beds during the study; urine and feces were collected separately for the following periods: period 1, 0 to 6 hours; period 2, >6 to 12 hours; period 3, >12 to 24 hours; and period 4, >24 to 48 hours. Urine was measured and feces were weighed on a precision scale with a tolerance of 100 mg<mark> (Triple-Beam Balance Dial-O-Gram model 1630, Ohaus Scale, Union, N.J.).</mark>\n\n【29】Each infant's sodium and potassium intake was calculated on the basis of the composition of the ingested rehydration solutions and the soy formula. If infants were breast-fed, breast-milk samples were analyzed for sodium and potassium with a spectrophotometer (Astra-8, Beckman Instruments, Fullerton, Calif.), and these values were used in the calculations of intake. Fecal sodium content, potassium content, and osmolality and urinary sodium content, potassium content, specific gravity, and pH were also determined (Astra-8, OA TS Meter, American Optical, Buffalo, N.Y.; and Combur 8 Test, Boehringer–Mannheim, Waldhof, Germany).\n\n【30】The apparent absorption of fluid, sodium, and potassium was calculated by subtracting the fecal output from the net intake for the same period. The apparent retention of fluid, sodium, and potassium was calculated by subtracting both fecal and urinary output from net intake.\n\n【31】Other Measurements\n------------------\n\n【32】Nude body weights were recorded at admission, on completion of rehydration, and after 6, 12, 24, and 48 hours on a mechanical baby scale with a tolerance of 10 g (Doctor's Infant Scale, Detecto Scales, Brooklyn, N.Y.).\n\n【33】Blood was drawn at admission and after 6, 12, 24, and 48 hours for the measurement of pH and partial pressure of carbon dioxide, serum sodium, potassium, chloride, bicarbonate, glucose, and urea nitrogen levels, and osmolality (Astra-8; and pH/Blood Gas Analyzer model 1301, Instrumentation Laboratory, Milan, Italy). The initial samples of stool were examined for salmonella, shigella, _Campylobacter jejuni_ , cryptosporidium,  <sup><a>18 </a></sup>  and ova and parasites. Rotavirus antigen was identified in the stool with an enzyme-linked immunoassay.  <sup><a>19 </a></sup> \n\n【34】Statistical Analysis\n--------------------\n\n【35】The results are expressed as means ±SE unless otherwise indicated. Differences between treatments were tested for significance by analysis of variance. Treatment differences over time were tested by repeated-measures analysis of variance. Nonparametric data were tested by the chi-square test. Differences were considered significant when the P value was less than 0.05. The Statistical Analysis System (SAS) software was used for the analyses. \n\n【36】Results\n-------\n\n【37】Characteristics of Patients\n---------------------------\n\n【38】Of the 94 infants enrolled in the study, 8 were not included in the final analysis for reasons unrelated to treatment. In group A, bronchiolitis developed in one patient, and fecal collections were incomplete for two patients. In group B, fecal collections were incomplete for two patients, one had an epileptic seizure (a condition not identified in the history), and bronchiolitis developed in one. Output measurements were incomplete for one patient in group C. Thus, 30 infants remained in group A, 27 in group B, and 29 in group C, for a total of 86.\n\n【39】Table 2. Characteristics of the 86 Infants with Acute Diarrhea at Admission.\\*\n\n【40】The clinical characteristics of these 86 infant boys at the time of admission are shown in Table 2 . There were no significant differences between the groups except that the infants in group B were heavier than those in group A.\n\n【41】The distribution of stool samples positive for pathogens was similar in the three groups . The stools of 35 percent of the patients were positive for rotavirus antigen.\n\n【42】Intake, Output, and Balance Studies\n-----------------------------------\n\n【43】### _Fluids_\n\n【44】Reluctance to drink the solution led to its nasogastric administration to six infants in group A, one in group B, and five in group C. Four infants in group A, 14 in group B, and 4 in group C received the solutions by that route because of persistent vomiting.\n\n【45】Table 3. Fluid Intake, Fecal Output, and Apparent Fluid Absorption and Retention during Treatment in 86 Infants with Acute Diarrhea.\\*\n\n【46】During the first 12 hours, the volume of vomitus for the infants who received the rice-based solution with casein hydrolysate (group B, 38±8 ml per kilogram) was significantly greater than that for group A (15±8 ml per kilogram) or group C (21±8 ml per kilogram). The net fluid intake was comparable in the three groups of infants during the first six hours of treatment (period 1). From >6 to 12 hours (period 2) and from >24 to 48 hours (period 4), the infants fed the rice solution with casein hydrolysate (group B) had a lower net intake than those in the other two groups .\n\n【47】The mean fecal output was higher for the infants in group C during several periods . The fecal weights during the 48-hour study (periods 1 through 4) were 199±18 g per kilogram for group A, 145±15 g per kilogram for group B, and 264±35 g per kilogram for group C. Overall, the infants who received the rice-based solutions (groups A and B) had 25 and 45 percent less fecal output, respectively, than the infants in group C.\n\n【48】The apparent absorption of fluid in the infants in group A was significantly greater than that in the infants in groups B and C from 0 to 6 hours and from >12 to 24 hours after the beginning of therapy (periods 1 and 3). During the entire 48 hours of the study, the mean amount of fluid apparently absorbed by infants in group A was also significantly greater than that in the other two groups .\n\n【49】During the first six hours of therapy (period 1), the mean amount of fluid apparently retained was significantly greater in group A than in the other two groups. The apparent retention of fluid was also greater in the infants in group A than in those in group B during the entire 48-hour study period .\n\n【50】### _Sodium_\n\n【51】During the first six hours, sodium intake was significantly higher in the infants in group C, who received the oral rehydration solution with the highest sodium concentration (group A, 5.2±0.4 mmol per kilogram; group B, 4.3±0.3 mmol per kilogram; and group C, 7.6±0.7 mmol per kilogram). Although the infants in group C had higher intake values thereafter, the differences were significant only in comparison with group B. The sodium output in the feces of the infants in group C was significantly higher in the first six hours of therapy (group A, 1.4±0.3 mmol per kilogram; group B, 1.1±0.2 mmol per kilogram; and group C, 2.9±0.7 mmol per kilogram) and during the entire 48-hour study period (group A, 9.4±1.1 mmol per kilogram; group B, 5.7±0.7 mmol per kilogram; and group C, 15.7±2.6 mmol per kilogram).\n\n【52】Table 4. Apparent Retention of Sodium and Potassium during Treatment in 86 Infants with Acute Diarrhea.\\*\n\n【53】The apparent absorption and retention of sodium were generally comparable in the three groups throughout the study. Only during two collection periods (periods 1 and 4) did the infants receiving the rice-based solution with casein hydrolysate (group B) have significantly lower retention of sodium than those in group C .\n\n【54】### _Potassium_\n\n【55】The potassium intake of the infants in the three groups differed only during period 1 (0 to 6 hours), when that of the infants in group A was significantly higher than that in group C (group A, 2.7±0.2 mmol per kilogram; group B, 2.2±0.2 mmol per kilogram; and group C, 2.1±0.2 mmol per kilogram). During this six-hour period, the infants in group C had a significantly higher fecal output of potassium (group A, 1.0±0.1 mmol per kilogram; group B, 1.1±0.1 mmol per kilogram; and group C, 1.4±0.2 mmol per kilogram) than those in the other groups. The apparent absorption of potassium was significantly higher in the infants in group A than that in those in group C from 0 to 6 hours (P<0.05) (group A, 1.6±0.2 mmol per kilogram; group B, 1.2±0.1 mmol per kilogram; and group C, 0.6±0.1 mmol per kilogram) and for the entire 48-hour study period (P<0.05) (group A, 3.4±0.5 mmol per kilogram; group B, 2.7±0.5 mmol per kilogram; and group C, 1.8±0.5 mmol per kilogram). The amounts of potassium apparently retained are shown in Table 4 .\n\n【56】Measurements in Blood\n---------------------\n\n【57】The mean serum sodium concentrations in the three groups were within the normal range throughout the study. The 13 infants in groups A and B who had hypernatremia on admission (serum sodium level, ≥150 mmol per liter) all had normal levels after 24 hours, if not earlier. Of the two infants in group C who had hypernatremia on admission, one had normal serum sodium levels after 48 hours, and the other had persistent hypernatremia throughout his hospital stay. Both were asymptomatic.\n\n【58】Five infants had hyponatremia (serum sodium level, ≤130 mmol per liter) at the time of their entry into the study. Four of them had normal concentrations after 48 hours of treatment. The fifth (in group A) had persistent hyponatremia, with a high fecal output (16 ml per kilogram per hour) and fecal sodium concentrations of 60 to 83 mmol per liter. After 24 hours, this child received intravenous fluids. He had a seizure after beginning intravenous treatment but recovered uneventfully. This patient was the only one in whom treatment failed.\n\n【59】No significant differences were found in the mean serum chloride, potassium, bicarbonate, glucose, and urea nitrogen concentrations or in values for blood pH and partial pressure of carbon dioxide among the three groups at any time. The mean serum osmolality for the infants in group A was significantly lower than that for the infants in group C throughout the study (290±2 vs. 298±2 mmol per kilogram; P<0.05).\n\n【60】Clinical Outcomes\n-----------------\n\n【61】The percent gains in body weight after rehydration were comparable among the three groups: group A, 4.0±0.4 percent; group B, 5.2±0.6 percent; and group C, 4.6±0.5 percent. The average lengths of time necessary to achieve rehydration were not significantly different: group A, 7.3±0.6 hours; group B, 6.4±0.7 hours; and group C, 6.7±0.7 hours. The duration of diarrhea, measured as the time between the initiation of oral rehydration therapy and the last liquid stool, did not differ significantly: group A, 62.9±7.5 hours; group B, 51.1±4.5 hours; and group C, 55.8±5.3 hours.\n\n【62】Discussion\n----------\n\n【63】Most oral rehydration solutions contain glucose and electrolytes. No optimal composition has been determined, however.  <sup>, </sup>  The results of this clinical trial, in which we used stable, ready-to-use, commercially prepared oral rehydration solutions containing rice-syrup solids, indicate that such solutions may be more efficient than glucose-based solutions in promoting fluid and electrolyte absorption during the rehydration phase in infants with acute diarrhea. In the 48-hour study, the infants in the two groups (groups A and B) that received rice solutions had lower fecal outputs than those in group C, who received the glucose solution. The mean fecal output of the infants in group A was 25 percent lower and that of the infants in group B was 45 percent lower than that of the infants in group C. In addition, the infants in group A had higher values for the absorption of fluid and potassium. Furthermore, even though the rice-based solutions contained one third less sodium, the groups' sodium balances were similar. These results suggest that the rice-syrup solids were very efficient in promoting sodium absorption.\n\n【64】One possible explanation for these results is the lower osmolality of the rice-based solutions. Hypotonie solutions promote water absorption in the proximal jejunum more effectively than isotonic solutions.  Thus, polymeric solutions permit glucose to be administered at little osmotic cost. Moreover, rice-syrup solids contain primarily short-chain glucose polymers. This makes them a readily available substrate for digestion by glucoamylase,  an intestinal enzyme that is present in infants and is relatively resistant to intestinal mucosal injury. \n\n【65】It has been theorized that the amino acids in oral rehydration solutions might potentiate the effects of carbohydrate on the absorption of sodium and water.  We added casein hydrolysate to one of our rice solutions to test this theory. We found that the infants receiving that solution (group B) had a lower net intake of rehydration solution because they vomited more during the rehydration period. The reduced intake could have been a factor in the infants' low stool output (the lowest among the groups). For most of the other measurements, there were no important differences between the two groups receiving solutions made with rice-syrup solids (with and without casein hydrolysate). Consequently, there appears to be no advantage to adding casein hydrolysate to a solution of this kind. However, the addition of other specific amino acids, different peptides, or both, may further enhance the absorption of fluid and electrolytes.\n\n【66】All three oral rehydration solutions were effective treatments for mild to moderate dehydration due to acute diarrhea. In only one infant, who had a high stool output and persistent hyponatremia, was treatment considered to have failed; this infant required intravenous therapy. The rehydration solution containing 50 mmol of sodium per liter was inadequate to correct his condition. Several investigators have reported that solutions with sodium concentrations of 50 or 75 mmol per liter are adequate for rehydration of well-nourished children with cholera.  <sup>, </sup>  <sup>, </sup>  However, the oral rehydration solutions failed to reverse hyponatremia in more than half of patients when the fecal output exceeded 10 ml per kilogram per hour, even when the rehydration solution contained 90 mmol of sodium per liter. \n\n【67】In summary, oral rehydration solutions containing rice-syrup solids were found to be superior to a glucose-based solution in decreasing stool output. Since the solution containing rice-syrup solids without added casein hydrolysate promoted higher water and potassium balances and was better tolerated, it may be the most suitable solution for the management of acute diarrhea in infants without cholera.", "index": 520, "show": true, "start": 520, "end": 635, "province": ["文本干净度", "无关文本"], "isEdit": false}, {"text": " (Doctor’s Infant Scale, Detecto Scales, Brooklyn, N.Y.).", "content": "【0】Rice-Based Oral Electrolyte Solutions for the Management of Infantile Diarrhea\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】In infants the treatment of acute diarrhea with glucose-based solutions results in rehydration but does not reduce the severity of diarrhea. Oral rehydration with solutions based on rice powder may reduce stool output as well as restore fluid volume.\n\n【3】Methods.\n--------\n\n【4】We designed a prospective, randomized, double-blind study to evaluate the efficacy of two rice-based rehydratio<mark> (Astra-8, OA TS Meter, American Optical, Buffalo, N.Y.; and Combur 8 Test, Boehringer–Mannheim, Waldhof, Germany).</mark>ained rice-syrup solids and casein hydrolysate, and solution C, the glucose-based solution, served as control. The study subjects were 86 mildly to moderately dehydrated infant boys, 3 to 18 months old, who were admitted to a children's hospital with acute diarrhea. We measured fluid intake, fecal and urine output, and absorption and retention of fluid, sodium, and potassium at intervals for 48 hours in all 86 infants.\n\n【5】Results.\n--------\n\n【6】The mean (±SE) fecal output was significantly lower in the infants given solution A (group A infants) than in the infants given solution C (group C) (29±4 vs. 46±7 ml per kilogram of body weight, P<0.05) during the first six hours of therapy. The infants in group A also had greater fluid absorption (221±16 vs. 167±9 ml per kilogram, P<0.05) over the entire 48 hours of therapy and greater potassium absorption (1.6±0.2 vs. 0.6±0.1 mmol per kilogram, P<0.05) during the first six hours than the infants in group C. Solution B offered no advantages over solution A.\n\n【7】Conclusions.\n------------\n\n【8】Solutions containing rice-syrup solids were effective in the rehydration of infants with acute diarrhea. They decreased stool output and promoted greater absorption and retention of fluid and electrolytes than did a glucose-based solution. \n\n【9】Introduction\n------------\n\n【10】GLUCOSE-BASED oral rehydration solutions have provided a simple and successful means of treating or preventing dehydration due to acute diarrhea in infants and children. Although glucose-based solutions stimulate the intestinal absorption of fluid and electrolytes from isotonic luminal contents, they do not aid in the reabsorption of fluid secreted by the intestine.  Thus, these solutions do not lessen the severity of diarrhea. The lack of efficacy of oral rehydration therapy in reducing diarrhea is the primary barrier to its global acceptance; it is estimated that the oral-rehydration-therapy packets provided by the World Health Organization are used in only 19 percent of episodes of diarrhea worldwide. \n\n【11】Some but not all investigators have found that adding small carrier molecules, such as amino acids, to oral rehydration solutions improves their performance.  <sup><a>4 </a></sup>  Recent studies have indicated that oral rehydration solutions prepared from rice not only ameliorate dehydration but also decrease diarrheal fluid loss.  <sup><a>7 </a></sup>  <sup><a>9 </a></sup> The effects of these polymeric solutions are either comparable or superior to those of glucose-containing solutions.  The cited disadvantages of rice solutions, however, include the need for cooking, the possibility of incorrect preparation, and rapid fermentation.  <sup>, </sup>  In addition, some infants may not tolerate whole starch. \n\n【12】Two oral rehydration solutions have been developed that retain the advantages of a rice-based solution while eliminating the disadvantages mentioned above. One of these solutions contains rice-syrup solids prepared under industrial conditions from solubilized rice starch as a carbohydrate source; the other has the same rice-syrup solids plus casein hydrolysate. The solutions are ready to use and stable.\n\n【13】We designed this randomized, double-blind study to evaluate the safety and efficacy of these rice-based solutions in the management of mild to moderate dehydration in infants with acute diarrhea. A commercial glucose-based oral rehydration solution was also evaluated for comparison purposes.\n\n【14】Methods\n-------\n\n【15】Patients\n--------\n\n【16】Ninety-four infant boys, 3 to 18 months of age, were selected from patients entering the Emergency Service of the Hospital Nacional de Niños in San José, Costa Rica. All were candidates for oral rehydration therapy because they had mild (<5 percent) or moderate (5 to 10 percent) dehydration caused by acute diarrhea of less than seven days' duration. The study was conducted during a six-month period, from September 1988 through February 1989. Patients were excluded if any of the following conditions were present: severe malnutrition, obesity, absence of bowel sounds, pneumonia, meningitis, severe congenital or metabolic disease, convulsions, unconsciousness, or shock. No girls were included in the study, since the separate collection of urine and stool from infant girls is difficult unless catheters are used. We had no reason to think that the results of oral rehydration therapy would differ between boys and girls.\n\n【17】The population served by the hospital consists mostly of lower- and middle-class families from urban or rural-urban areas. The study was approved by the institutional review board for human research of the Costa Rican Social Security System and by the Hospital Nacional de Niños Clinical Investigations Committee. Written informed consent was obtained from each infant's parent or guardian at the time of admission.\n\n【18】Treatment Protocol\n------------------\n\n<mark>【19】Table 1. </mark>Composition of the Oral Solutions Used to Treat Infants with Acute Diarrhea.\n\n【20】After an initial clinical history taking and physical examination, the patients were admitted to the rehydration unit. By means of a computer-generated block randomization schedule (PLAN Procedure),  the infants were randomly assigned in double-blind fashion to one of three treatment groups. Those in group A received a rice-based electrolyte solution containing 30 g of rice-syrup solids and 50 mmol of sodium per liter (solution A; Ricelyte, Mead Johnson nutritional Group, Evansville, Ind.). Those in group B received a solution with the same ingredients, with the addition of 5 g of casein hydrolysate per liter (solution B; Mead Johnson nutritional Group). Infants in group C received a commercial oral rehydration solution containing 75 mmol of sodium and 25 g of glucose per liter (solution C; Rehydralyte, Ross Laboratories, Columbus, Ohio).<mark> The composition of the solutions is shown in Table 1 .</mark> The solutions were coded to keep investigators and parents unaware of which solution was being administered.\n\n【21】The rice-syrup solids were analyzed by high-performance liquid chromatography to determine the carbohydrate profile. The results were as follows: glucose, 3.5 percent; glucose polymers of two to six units, 64.9 percent; and glucose polymers of more than seven units, 31.6 percent. The casein hydrolysate was composed of small peptides (50 percent) and amino acids (50 percent).\n\n【22】At the time of admission, each infant's fluid deficit was determined by multiplying his weight at admission by the percent dehydration, which was estimated on the basis of clinical signs.  The randomly assigned solution was administered in a volume twice as great as the estimated fluid deficit within the next four to six hours. After he had ingested the solution, the infant's degree of hydration was reassessed. If rehydration had not been achieved, the same solution was administered again in a volume calculated on the basis of the most recent estimate of the infants's fluid deficit. \n\n【23】If the infant refused to drink the solution or vomited frequently, the solution was administered by nasogastric tube at a rate of 15 ml per kilogram of body weight per hour. If the solution was tolerated for 15 to 30 minutes, the rate of administration was increased to 30 ml per kilogram per hour. If an infant required intravenous therapy because of persistent serum electrolyte abnormalities, high fecal output, or continued vomiting, treatment was considered to have failed.\n\n【24】After rehydration, the patients received a soy-based formula containing 2.76 kJ (0.66 kcal) per milliliter (ProSobee, Mead Johnson nutritional Group) in a volume of 120 ml per kilogram every 24 hours. In addition, the infants were offered oral rehydration solution after each diarrheal stool in a volume equal to the stool volume. The infants who were breast-fed before admission were allowed to resume breast-feeding after rehydration. Breast-milk intake was estimated by subtracting the mean of three values for the infant's weight before nursing from the mean of three values for his weight afterward. Plain water was allowed ad libitum after rehydration.\n\n【25】The patients were discharged after 48 hours or 16 hours after the last diarrheal stool, whichever was later.\n\n【26】Intake, Output, and Balance Studies\n-----------------------------------\n\n【27】Fluid intake was measured for the following periods during the study: period 1, 0 to 6 hours; period 2, >6 to 12 hours; period 3, >12 to 24 hours; and period 4, >24 to 48 hours; it was also measured cumulatively, for the entire 48-hour study period. Net fluid intake was determined by subtracting the weight of any vomitus from the amount of fluid ingested. The weight of vomitus was calculated as the difference between the dry and wet weights of diapers used to collect the vomitus.\n\n【28】All infants remained on metabolic beds during the study; urine and feces were collected separately for the following periods: period 1, 0 to 6 hours; period 2, >6 to 12 hours; period 3, >12 to 24 hours; and period 4, >24 to 48 hours. Urine was measured and feces were weighed on a precision scale with a tolerance of 100 mg<mark> (Triple-Beam Balance Dial-O-Gram model 1630, Ohaus Scale, Union, N.J.).</mark>\n\n【29】Each infant's sodium and potassium intake was calculated on the basis of the composition of the ingested rehydration solutions and the soy formula. If infants were breast-fed, breast-milk samples were analyzed for sodium and potassium with a spectrophotometer (Astra-8, Beckman Instruments, Fullerton, Calif.), and these values were used in the calculations of intake. Fecal sodium content, potassium content, and osmolality and urinary sodium content, potassium content, specific gravity, and pH were also determined (Astra-8, OA TS Meter, American Optical, Buffalo, N.Y.; and Combur 8 Test, Boehringer–Mannheim, Waldhof, Germany).\n\n【30】The apparent absorption of fluid, sodium, and potassium was calculated by subtracting the fecal output from the net intake for the same period. The apparent retention of fluid, sodium, and potassium was calculated by subtracting both fecal and urinary output from net intake.\n\n【31】Other Measurements\n------------------\n\n【32】Nude body weights were recorded at admission, on completion of rehydration, and after 6, 12, 24, and 48 hours on a mechanical baby scale with a tolerance of 10 g (Doctor's Infant Scale, Detecto Scales, Brooklyn, N.Y.).\n\n【33】Blood was drawn at admission and after 6, 12, 24, and 48 hours for the measurement of pH and partial pressure of carbon dioxide, serum sodium, potassium, chloride, bicarbonate, glucose, and urea nitrogen levels, and osmolality (Astra-8; and pH/Blood Gas Analyzer model 1301, Instrumentation Laboratory, Milan, Italy). The initial samples of stool were examined for salmonella, shigella, _Campylobacter jejuni_ , cryptosporidium,  <sup><a>18 </a></sup>  and ova and parasites. Rotavirus antigen was identified in the stool with an enzyme-linked immunoassay.  <sup><a>19 </a></sup> \n\n【34】Statistical Analysis\n--------------------\n\n【35】The results are expressed as means ±SE unless otherwise indicated. Differences between treatments were tested for significance by analysis of variance. Treatment differences over time were tested by repeated-measures analysis of variance. Nonparametric data were tested by the chi-square test. Differences were considered significant when the P value was less than 0.05. The Statistical Analysis System (SAS) software was used for the analyses. \n\n【36】Results\n-------\n\n【37】Characteristics of Patients\n---------------------------\n\n【38】Of the 94 infants enrolled in the study, 8 were not included in the final analysis for reasons unrelated to treatment. In group A, bronchiolitis developed in one patient, and fecal collections were incomplete for two patients. In group B, fecal collections were incomplete for two patients, one had an epileptic seizure (a condition not identified in the history), and bronchiolitis developed in one. Output measurements were incomplete for one patient in group C. Thus, 30 infants remained in group A, 27 in group B, and 29 in group C, for a total of 86.\n\n【39】Table 2. Characteristics of the 86 Infants with Acute Diarrhea at Admission.\\*\n\n【40】The clinical characteristics of these 86 infant boys at the time of admission are shown in Table 2 . There were no significant differences between the groups except that the infants in group B were heavier than those in group A.\n\n【41】The distribution of stool samples positive for pathogens was similar in the three groups . The stools of 35 percent of the patients were positive for rotavirus antigen.\n\n【42】Intake, Output, and Balance Studies\n-----------------------------------\n\n【43】### _Fluids_\n\n【44】Reluctance to drink the solution led to its nasogastric administration to six infants in group A, one in group B, and five in group C. Four infants in group A, 14 in group B, and 4 in group C received the solutions by that route because of persistent vomiting.\n\n【45】Table 3. Fluid Intake, Fecal Output, and Apparent Fluid Absorption and Retention during Treatment in 86 Infants with Acute Diarrhea.\\*\n\n【46】During the first 12 hours, the volume of vomitus for the infants who received the rice-based solution with casein hydrolysate (group B, 38±8 ml per kilogram) was significantly greater than that for group A (15±8 ml per kilogram) or group C (21±8 ml per kilogram). The net fluid intake was comparable in the three groups of infants during the first six hours of treatment (period 1). From >6 to 12 hours (period 2) and from >24 to 48 hours (period 4), the infants fed the rice solution with casein hydrolysate (group B) had a lower net intake than those in the other two groups .\n\n【47】The mean fecal output was higher for the infants in group C during several periods . The fecal weights during the 48-hour study (periods 1 through 4) were 199±18 g per kilogram for group A, 145±15 g per kilogram for group B, and 264±35 g per kilogram for group C. Overall, the infants who received the rice-based solutions (groups A and B) had 25 and 45 percent less fecal output, respectively, than the infants in group C.\n\n【48】The apparent absorption of fluid in the infants in group A was significantly greater than that in the infants in groups B and C from 0 to 6 hours and from >12 to 24 hours after the beginning of therapy (periods 1 and 3). During the entire 48 hours of the study, the mean amount of fluid apparently absorbed by infants in group A was also significantly greater than that in the other two groups .\n\n【49】During the first six hours of therapy (period 1), the mean amount of fluid apparently retained was significantly greater in group A than in the other two groups. The apparent retention of fluid was also greater in the infants in group A than in those in group B during the entire 48-hour study period .\n\n【50】### _Sodium_\n\n【51】During the first six hours, sodium intake was significantly higher in the infants in group C, who received the oral rehydration solution with the highest sodium concentration (group A, 5.2±0.4 mmol per kilogram; group B, 4.3±0.3 mmol per kilogram; and group C, 7.6±0.7 mmol per kilogram). Although the infants in group C had higher intake values thereafter, the differences were significant only in comparison with group B. The sodium output in the feces of the infants in group C was significantly higher in the first six hours of therapy (group A, 1.4±0.3 mmol per kilogram; group B, 1.1±0.2 mmol per kilogram; and group C, 2.9±0.7 mmol per kilogram) and during the entire 48-hour study period (group A, 9.4±1.1 mmol per kilogram; group B, 5.7±0.7 mmol per kilogram; and group C, 15.7±2.6 mmol per kilogram).\n\n【52】Table 4. Apparent Retention of Sodium and Potassium during Treatment in 86 Infants with Acute Diarrhea.\\*\n\n【53】The apparent absorption and retention of sodium were generally comparable in the three groups throughout the study. Only during two collection periods (periods 1 and 4) did the infants receiving the rice-based solution with casein hydrolysate (group B) have significantly lower retention of sodium than those in group C .\n\n【54】### _Potassium_\n\n【55】The potassium intake of the infants in the three groups differed only during period 1 (0 to 6 hours), when that of the infants in group A was significantly higher than that in group C (group A, 2.7±0.2 mmol per kilogram; group B, 2.2±0.2 mmol per kilogram; and group C, 2.1±0.2 mmol per kilogram). During this six-hour period, the infants in group C had a significantly higher fecal output of potassium (group A, 1.0±0.1 mmol per kilogram; group B, 1.1±0.1 mmol per kilogram; and group C, 1.4±0.2 mmol per kilogram) than those in the other groups. The apparent absorption of potassium was significantly higher in the infants in group A than that in those in group C from 0 to 6 hours (P<0.05) (group A, 1.6±0.2 mmol per kilogram; group B, 1.2±0.1 mmol per kilogram; and group C, 0.6±0.1 mmol per kilogram) and for the entire 48-hour study period (P<0.05) (group A, 3.4±0.5 mmol per kilogram; group B, 2.7±0.5 mmol per kilogram; and group C, 1.8±0.5 mmol per kilogram). The amounts of potassium apparently retained are shown in Table 4 .\n\n【56】Measurements in Blood\n---------------------\n\n【57】The mean serum sodium concentrations in the three groups were within the normal range throughout the study. The 13 infants in groups A and B who had hypernatremia on admission (serum sodium level, ≥150 mmol per liter) all had normal levels after 24 hours, if not earlier. Of the two infants in group C who had hypernatremia on admission, one had normal serum sodium levels after 48 hours, and the other had persistent hypernatremia throughout his hospital stay. Both were asymptomatic.\n\n【58】Five infants had hyponatremia (serum sodium level, ≤130 mmol per liter) at the time of their entry into the study. Four of them had normal concentrations after 48 hours of treatment. The fifth (in group A) had persistent hyponatremia, with a high fecal output (16 ml per kilogram per hour) and fecal sodium concentrations of 60 to 83 mmol per liter. After 24 hours, this child received intravenous fluids. He had a seizure after beginning intravenous treatment but recovered uneventfully. This patient was the only one in whom treatment failed.\n\n【59】No significant differences were found in the mean serum chloride, potassium, bicarbonate, glucose, and urea nitrogen concentrations or in values for blood pH and partial pressure of carbon dioxide among the three groups at any time. The mean serum osmolality for the infants in group A was significantly lower than that for the infants in group C throughout the study (290±2 vs. 298±2 mmol per kilogram; P<0.05).\n\n【60】Clinical Outcomes\n-----------------\n\n【61】The percent gains in body weight after rehydration were comparable among the three groups: group A, 4.0±0.4 percent; group B, 5.2±0.6 percent; and group C, 4.6±0.5 percent. The average lengths of time necessary to achieve rehydration were not significantly different: group A, 7.3±0.6 hours; group B, 6.4±0.7 hours; and group C, 6.7±0.7 hours. The duration of diarrhea, measured as the time between the initiation of oral rehydration therapy and the last liquid stool, did not differ significantly: group A, 62.9±7.5 hours; group B, 51.1±4.5 hours; and group C, 55.8±5.3 hours.\n\n【62】Discussion\n----------\n\n【63】Most oral rehydration solutions contain glucose and electrolytes. No optimal composition has been determined, however.  <sup>, </sup>  The results of this clinical trial, in which we used stable, ready-to-use, commercially prepared oral rehydration solutions containing rice-syrup solids, indicate that such solutions may be more efficient than glucose-based solutions in promoting fluid and electrolyte absorption during the rehydration phase in infants with acute diarrhea. In the 48-hour study, the infants in the two groups (groups A and B) that received rice solutions had lower fecal outputs than those in group C, who received the glucose solution. The mean fecal output of the infants in group A was 25 percent lower and that of the infants in group B was 45 percent lower than that of the infants in group C. In addition, the infants in group A had higher values for the absorption of fluid and potassium. Furthermore, even though the rice-based solutions contained one third less sodium, the groups' sodium balances were similar. These results suggest that the rice-syrup solids were very efficient in promoting sodium absorption.\n\n【64】One possible explanation for these results is the lower osmolality of the rice-based solutions. Hypotonie solutions promote water absorption in the proximal jejunum more effectively than isotonic solutions.  Thus, polymeric solutions permit glucose to be administered at little osmotic cost. Moreover, rice-syrup solids contain primarily short-chain glucose polymers. This makes them a readily available substrate for digestion by glucoamylase,  an intestinal enzyme that is present in infants and is relatively resistant to intestinal mucosal injury. \n\n【65】It has been theorized that the amino acids in oral rehydration solutions might potentiate the effects of carbohydrate on the absorption of sodium and water.  We added casein hydrolysate to one of our rice solutions to test this theory. We found that the infants receiving that solution (group B) had a lower net intake of rehydration solution because they vomited more during the rehydration period. The reduced intake could have been a factor in the infants' low stool output (the lowest among the groups). For most of the other measurements, there were no important differences between the two groups receiving solutions made with rice-syrup solids (with and without casein hydrolysate). Consequently, there appears to be no advantage to adding casein hydrolysate to a solution of this kind. However, the addition of other specific amino acids, different peptides, or both, may further enhance the absorption of fluid and electrolytes.\n\n【66】All three oral rehydration solutions were effective treatments for mild to moderate dehydration due to acute diarrhea. In only one infant, who had a high stool output and persistent hyponatremia, was treatment considered to have failed; this infant required intravenous therapy. The rehydration solution containing 50 mmol of sodium per liter was inadequate to correct his condition. Several investigators have reported that solutions with sodium concentrations of 50 or 75 mmol per liter are adequate for rehydration of well-nourished children with cholera.  <sup>, </sup>  <sup>, </sup>  However, the oral rehydration solutions failed to reverse hyponatremia in more than half of patients when the fecal output exceeded 10 ml per kilogram per hour, even when the rehydration solution contained 90 mmol of sodium per liter. \n\n【67】In summary, oral rehydration solutions containing rice-syrup solids were found to be superior to a glucose-based solution in decreasing stool output. Since the solution containing rice-syrup solids without added casein hydrolysate promoted higher water and potassium balances and was better tolerated, it may be the most suitable solution for the management of acute diarrhea in infants without cholera.", "index": 164, "show": true, "start": 164, "end": 221, "province": ["文本干净度", "无关文本"], "isEdit": false}, {"text": " 18  ", "content": "【0】Rice-Based Oral Electrolyte Solutions for the Management of Infantile Diarrhea\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】In infants the treatment of acut<mark> (Doctor’s Infant Scale, Detecto Scales, Brooklyn, N.Y.).</mark>ation but does not reduce the severity of diarrhea. Oral rehydration with solutions based on rice powder may reduce stool output as well as restore fluid volume.\n\n【3】Methods.\n--------\n\n【4】We designed a prospective, randomized, double-blind study to evaluate the efficacy of two rice-based rehydratio<mark> (Astra-8, OA TS Meter, American Optical, Buffalo, N.Y.; and Combur 8 Test, Boehringer–Mannheim, Waldhof, Germany).</mark>ained rice-syrup solids and casein hydrolysate, and solution C, the glucose-based solution, served as control. The study subjects were 86 mildly to moderately dehydrated infant boys, 3 to 18 months old, who were admitted to a children's hospital with acute diarrhea. We measured fluid intake, fecal and urine output, and absorption and retention of fluid, sodium, and potassium at intervals for 48 hours in all 86 infants.\n\n【5】Results.\n--------\n\n【6】The mean (±SE) fecal output was significantly lower in the infants given solution A (group A infants) than in the infants given solution C (group C) (29±4 vs. 46±7 ml per kilogram of body weight, P<0.05) during the first six hours of therapy. The infants in group A also had greater fluid absorption (221±16 vs. 167±9 ml per kilogram, P<0.05) over the entire 48 hours of therapy and greater potassium absorption (1.6±0.2 vs. 0.6±0.1 mmol per kilogram, P<0.05) during the first six hours than the infants in group C. Solution B offered no advantages over solution A.\n\n【7】Conclusions.\n------------\n\n【8】Solutions containing rice-syrup solids were effective in the rehydration of infants with acute diarrhea. They decreased stool output and promoted greater absorption and retention of fluid and electrolytes than did a glucose-based solution. \n\n【9】Introduction\n------------\n\n【10】GLUCOSE-BASED oral rehydration solutions have provided a simple and successful means of treating or preventing dehydration due to acute diarrhea in infants and children. Although glucose-based solutions stimulate the intestinal absorption of fluid and electrolytes from isotonic luminal contents, they do not aid in the reabsorption of fluid secreted by the intestine.  Thus, these solutions do not lessen the severity of diarrhea. The lack of efficacy of oral rehydration therapy in reducing diarrhea is the primary barrier to its global acceptance; it is estimated that the oral-rehydration-therapy packets provided by the World Health Organization are used in only 19 percent of episodes of diarrhea worldwide. \n\n【11】Some but not all investigators have found that adding small carrier molecules, such as amino acids, to oral rehydration solutions improves their performance.  <sup><a>4 </a></sup>  Recent studies have indicated that oral rehydration solutions prepared from rice not only ameliorate dehydration but also decrease diarrheal fluid loss.  <sup><a>7 </a></sup>  <sup><a>9 </a></sup> The effects of these polymeric solutions are either comparable or superior to those of glucose-containing solutions.  The cited disadvantages of rice solutions, however, include the need for cooking, the possibility of incorrect preparation, and rapid fermentation.  <sup>, </sup>  In addition, some infants may not tolerate whole starch. \n\n【12】Two oral rehydration solutions have been developed that retain the advantages of a rice-based solution while eliminating the disadvantages mentioned above. One of these solutions contains rice-syrup solids prepared under industrial conditions from solubilized rice starch as a carbohydrate source; the other has the same rice-syrup solids plus casein hydrolysate. The solutions are ready to use and stable.\n\n【13】We designed this randomized, double-blind study to evaluate the safety and efficacy of these rice-based solutions in the management of mild to moderate dehydration in infants with acute diarrhea. A commercial glucose-based oral rehydration solution was also evaluated for comparison purposes.\n\n【14】Methods\n-------\n\n【15】Patients\n--------\n\n【16】Ninety-four infant boys, 3 to 18 months of age, were selected from patients entering the Emergency Service of the Hospital Nacional de Niños in San José, Costa Rica. All were candidates for oral rehydration therapy because they had mild (<5 percent) or moderate (5 to 10 percent) dehydration caused by acute diarrhea of less than seven days' duration. The study was conducted during a six-month period, from September 1988 through February 1989. Patients were excluded if any of the following conditions were present: severe malnutrition, obesity, absence of bowel sounds, pneumonia, meningitis, severe congenital or metabolic disease, convulsions, unconsciousness, or shock. No girls were included in the study, since the separate collection of urine and stool from infant girls is difficult unless catheters are used. We had no reason to think that the results of oral rehydration therapy would differ between boys and girls.\n\n【17】The population served by the hospital consists mostly of lower- and middle-class families from urban or rural-urban areas. The study was approved by the institutional review board for human research of the Costa Rican Social Security System and by the Hospital Nacional de Niños Clinical Investigations Committee. Written informed consent was obtained from each infant's parent or guardian at the time of admission.\n\n【18】Treatment Protocol\n------------------\n\n<mark>【19】Table 1. </mark>Composition of the Oral Solutions Used to Treat Infants with Acute Diarrhea.\n\n【20】After an initial clinical history taking and physical examination, the patients were admitted to the rehydration unit. By means of a computer-generated block randomization schedule (PLAN Procedure),  the infants were randomly assigned in double-blind fashion to one of three treatment groups. Those in group A received a rice-based electrolyte solution containing 30 g of rice-syrup solids and 50 mmol of sodium per liter (solution A; Ricelyte, Mead Johnson nutritional Group, Evansville, Ind.). Those in group B received a solution with the same ingredients, with the addition of 5 g of casein hydrolysate per liter (solution B; Mead Johnson nutritional Group). Infants in group C received a commercial oral rehydration solution containing 75 mmol of sodium and 25 g of glucose per liter (solution C; Rehydralyte, Ross Laboratories, Columbus, Ohio).<mark> The composition of the solutions is shown in Table 1 .</mark> The solutions were coded to keep investigators and parents unaware of which solution was being administered.\n\n【21】The rice-syrup solids were analyzed by high-performance liquid chromatography to determine the carbohydrate profile. The results were as follows: glucose, 3.5 percent; glucose polymers of two to six units, 64.9 percent; and glucose polymers of more than seven units, 31.6 percent. The casein hydrolysate was composed of small peptides (50 percent) and amino acids (50 percent).\n\n【22】At the time of admission, each infant's fluid deficit was determined by multiplying his weight at admission by the percent dehydration, which was estimated on the basis of clinical signs.  The randomly assigned solution was administered in a volume twice as great as the estimated fluid deficit within the next four to six hours. After he had ingested the solution, the infant's degree of hydration was reassessed. If rehydration had not been achieved, the same solution was administered again in a volume calculated on the basis of the most recent estimate of the infants's fluid deficit. \n\n【23】If the infant refused to drink the solution or vomited frequently, the solution was administered by nasogastric tube at a rate of 15 ml per kilogram of body weight per hour. If the solution was tolerated for 15 to 30 minutes, the rate of administration was increased to 30 ml per kilogram per hour. If an infant required intravenous therapy because of persistent serum electrolyte abnormalities, high fecal output, or continued vomiting, treatment was considered to have failed.\n\n【24】After rehydration, the patients received a soy-based formula containing 2.76 kJ (0.66 kcal) per milliliter (ProSobee, Mead Johnson nutritional Group) in a volume of 120 ml per kilogram every 24 hours. In addition, the infants were offered oral rehydration solution after each diarrheal stool in a volume equal to the stool volume. The infants who were breast-fed before admission were allowed to resume breast-feeding after rehydration. Breast-milk intake was estimated by subtracting the mean of three values for the infant's weight before nursing from the mean of three values for his weight afterward. Plain water was allowed ad libitum after rehydration.\n\n【25】The patients were discharged after 48 hours or 16 hours after the last diarrheal stool, whichever was later.\n\n【26】Intake, Output, and Balance Studies\n-----------------------------------\n\n【27】Fluid intake was measured for the following periods during the study: period 1, 0 to 6 hours; period 2, >6 to 12 hours; period 3, >12 to 24 hours; and period 4, >24 to 48 hours; it was also measured cumulatively, for the entire 48-hour study period. Net fluid intake was determined by subtracting the weight of any vomitus from the amount of fluid ingested. The weight of vomitus was calculated as the difference between the dry and wet weights of diapers used to collect the vomitus.\n\n【28】All infants remained on metabolic beds during the study; urine and feces were collected separately for the following periods: period 1, 0 to 6 hours; period 2, >6 to 12 hours; period 3, >12 to 24 hours; and period 4, >24 to 48 hours. Urine was measured and feces were weighed on a precision scale with a tolerance of 100 mg<mark> (Triple-Beam Balance Dial-O-Gram model 1630, Ohaus Scale, Union, N.J.).</mark>\n\n【29】Each infant's sodium and potassium intake was calculated on the basis of the composition of the ingested rehydration solutions and the soy formula. If infants were breast-fed, breast-milk samples were analyzed for sodium and potassium with a spectrophotometer (Astra-8, Beckman Instruments, Fullerton, Calif.), and these values were used in the calculations of intake. Fecal sodium content, potassium content, and osmolality and urinary sodium content, potassium content, specific gravity, and pH were also determined (Astra-8, OA TS Meter, American Optical, Buffalo, N.Y.; and Combur 8 Test, Boehringer–Mannheim, Waldhof, Germany).\n\n【30】The apparent absorption of fluid, sodium, and potassium was calculated by subtracting the fecal output from the net intake for the same period. The apparent retention of fluid, sodium, and potassium was calculated by subtracting both fecal and urinary output from net intake.\n\n【31】Other Measurements\n------------------\n\n【32】Nude body weights were recorded at admission, on completion of rehydration, and after 6, 12, 24, and 48 hours on a mechanical baby scale with a tolerance of 10 g (Doctor's Infant Scale, Detecto Scales, Brooklyn, N.Y.).\n\n【33】Blood was drawn at admission and after 6, 12, 24, and 48 hours for the measurement of pH and partial pressure of carbon dioxide, serum sodium, potassium, chloride, bicarbonate, glucose, and urea nitrogen levels, and osmolality (Astra-8; and pH/Blood Gas Analyzer model 1301, Instrumentation Laboratory, Milan, Italy). The initial samples of stool were examined for salmonella, shigella, _Campylobacter jejuni_ , cryptosporidium,  <sup><a>18 </a></sup>  and ova and parasites. Rotavirus antigen was identified in the stool with an enzyme-linked immunoassay.  <sup><a>19 </a></sup> \n\n【34】Statistical Analysis\n--------------------\n\n【35】The results are expressed as means ±SE unless otherwise indicated. Differences between treatments were tested for significance by analysis of variance. Treatment differences over time were tested by repeated-measures analysis of variance. Nonparametric data were tested by the chi-square test. Differences were considered significant when the P value was less than 0.05. The Statistical Analysis System (SAS) software was used for the analyses. \n\n【36】Results\n-------\n\n【37】Characteristics of Patients\n---------------------------\n\n【38】Of the 94 infants enrolled in the study, 8 were not included in the final analysis for reasons unrelated to treatment. In group A, bronchiolitis developed in one patient, and fecal collections were incomplete for two patients. In group B, fecal collections were incomplete for two patients, one had an epileptic seizure (a condition not identified in the history), and bronchiolitis developed in one. Output measurements were incomplete for one patient in group C. Thus, 30 infants remained in group A, 27 in group B, and 29 in group C, for a total of 86.\n\n【39】Table 2. Characteristics of the 86 Infants with Acute Diarrhea at Admission.\\*\n\n【40】The clinical characteristics of these 86 infant boys at the time of admission are shown in Table 2 . There were no significant differences between the groups except that the infants in group B were heavier than those in group A.\n\n【41】The distribution of stool samples positive for pathogens was similar in the three groups . The stools of 35 percent of the patients were positive for rotavirus antigen.\n\n【42】Intake, Output, and Balance Studies\n-----------------------------------\n\n【43】### _Fluids_\n\n【44】Reluctance to drink the solution led to its nasogastric administration to six infants in group A, one in group B, and five in group C. Four infants in group A, 14 in group B, and 4 in group C received the solutions by that route because of persistent vomiting.\n\n【45】Table 3. Fluid Intake, Fecal Output, and Apparent Fluid Absorption and Retention during Treatment in 86 Infants with Acute Diarrhea.\\*\n\n【46】During the first 12 hours, the volume of vomitus for the infants who received the rice-based solution with casein hydrolysate (group B, 38±8 ml per kilogram) was significantly greater than that for group A (15±8 ml per kilogram) or group C (21±8 ml per kilogram). The net fluid intake was comparable in the three groups of infants during the first six hours of treatment (period 1). From >6 to 12 hours (period 2) and from >24 to 48 hours (period 4), the infants fed the rice solution with casein hydrolysate (group B) had a lower net intake than those in the other two groups .\n\n【47】The mean fecal output was higher for the infants in group C during several periods . The fecal weights during the 48-hour study (periods 1 through 4) were 199±18 g per kilogram for group A, 145±15 g per kilogram for group B, and 264±35 g per kilogram for group C. Overall, the infants who received the rice-based solutions (groups A and B) had 25 and 45 percent less fecal output, respectively, than the infants in group C.\n\n【48】The apparent absorption of fluid in the infants in group A was significantly greater than that in the infants in groups B and C from 0 to 6 hours and from >12 to 24 hours after the beginning of therapy (periods 1 and 3). During the entire 48 hours of the study, the mean amount of fluid apparently absorbed by infants in group A was also significantly greater than that in the other two groups .\n\n【49】During the first six hours of therapy (period 1), the mean amount of fluid apparently retained was significantly greater in group A than in the other two groups. The apparent retention of fluid was also greater in the infants in group A than in those in group B during the entire 48-hour study period .\n\n【50】### _Sodium_\n\n【51】During the first six hours, sodium intake was significantly higher in the infants in group C, who received the oral rehydration solution with the highest sodium concentration (group A, 5.2±0.4 mmol per kilogram; group B, 4.3±0.3 mmol per kilogram; and group C, 7.6±0.7 mmol per kilogram). Although the infants in group C had higher intake values thereafter, the differences were significant only in comparison with group B. The sodium output in the feces of the infants in group C was significantly higher in the first six hours of therapy (group A, 1.4±0.3 mmol per kilogram; group B, 1.1±0.2 mmol per kilogram; and group C, 2.9±0.7 mmol per kilogram) and during the entire 48-hour study period (group A, 9.4±1.1 mmol per kilogram; group B, 5.7±0.7 mmol per kilogram; and group C, 15.7±2.6 mmol per kilogram).\n\n【52】Table 4. Apparent Retention of Sodium and Potassium during Treatment in 86 Infants with Acute Diarrhea.\\*\n\n【53】The apparent absorption and retention of sodium were generally comparable in the three groups throughout the study. Only during two collection periods (periods 1 and 4) did the infants receiving the rice-based solution with casein hydrolysate (group B) have significantly lower retention of sodium than those in group C .\n\n【54】### _Potassium_\n\n【55】The potassium intake of the infants in the three groups differed only during period 1 (0 to 6 hours), when that of the infants in group A was significantly higher than that in group C (group A, 2.7±0.2 mmol per kilogram; group B, 2.2±0.2 mmol per kilogram; and group C, 2.1±0.2 mmol per kilogram). During this six-hour period, the infants in group C had a significantly higher fecal output of potassium (group A, 1.0±0.1 mmol per kilogram; group B, 1.1±0.1 mmol per kilogram; and group C, 1.4±0.2 mmol per kilogram) than those in the other groups. The apparent absorption of potassium was significantly higher in the infants in group A than that in those in group C from 0 to 6 hours (P<0.05) (group A, 1.6±0.2 mmol per kilogram; group B, 1.2±0.1 mmol per kilogram; and group C, 0.6±0.1 mmol per kilogram) and for the entire 48-hour study period (P<0.05) (group A, 3.4±0.5 mmol per kilogram; group B, 2.7±0.5 mmol per kilogram; and group C, 1.8±0.5 mmol per kilogram). The amounts of potassium apparently retained are shown in Table 4 .\n\n【56】Measurements in Blood\n---------------------\n\n【57】The mean serum sodium concentrations in the three groups were within the normal range throughout the study. The 13 infants in groups A and B who had hypernatremia on admission (serum sodium level, ≥150 mmol per liter) all had normal levels after 24 hours, if not earlier. Of the two infants in group C who had hypernatremia on admission, one had normal serum sodium levels after 48 hours, and the other had persistent hypernatremia throughout his hospital stay. Both were asymptomatic.\n\n【58】Five infants had hyponatremia (serum sodium level, ≤130 mmol per liter) at the time of their entry into the study. Four of them had normal concentrations after 48 hours of treatment. The fifth (in group A) had persistent hyponatremia, with a high fecal output (16 ml per kilogram per hour) and fecal sodium concentrations of 60 to 83 mmol per liter. After 24 hours, this child received intravenous fluids. He had a seizure after beginning intravenous treatment but recovered uneventfully. This patient was the only one in whom treatment failed.\n\n【59】No significant differences were found in the mean serum chloride, potassium, bicarbonate, glucose, and urea nitrogen concentrations or in values for blood pH and partial pressure of carbon dioxide among the three groups at any time. The mean serum osmolality for the infants in group A was significantly lower than that for the infants in group C throughout the study (290±2 vs. 298±2 mmol per kilogram; P<0.05).\n\n【60】Clinical Outcomes\n-----------------\n\n【61】The percent gains in body weight after rehydration were comparable among the three groups: group A, 4.0±0.4 percent; group B, 5.2±0.6 percent; and group C, 4.6±0.5 percent. The average lengths of time necessary to achieve rehydration were not significantly different: group A, 7.3±0.6 hours; group B, 6.4±0.7 hours; and group C, 6.7±0.7 hours. The duration of diarrhea, measured as the time between the initiation of oral rehydration therapy and the last liquid stool, did not differ significantly: group A, 62.9±7.5 hours; group B, 51.1±4.5 hours; and group C, 55.8±5.3 hours.\n\n【62】Discussion\n----------\n\n【63】Most oral rehydration solutions contain glucose and electrolytes. No optimal composition has been determined, however.  <sup>, </sup>  The results of this clinical trial, in which we used stable, ready-to-use, commercially prepared oral rehydration solutions containing rice-syrup solids, indicate that such solutions may be more efficient than glucose-based solutions in promoting fluid and electrolyte absorption during the rehydration phase in infants with acute diarrhea. In the 48-hour study, the infants in the two groups (groups A and B) that received rice solutions had lower fecal outputs than those in group C, who received the glucose solution. The mean fecal output of the infants in group A was 25 percent lower and that of the infants in group B was 45 percent lower than that of the infants in group C. In addition, the infants in group A had higher values for the absorption of fluid and potassium. Furthermore, even though the rice-based solutions contained one third less sodium, the groups' sodium balances were similar. These results suggest that the rice-syrup solids were very efficient in promoting sodium absorption.\n\n【64】One possible explanation for these results is the lower osmolality of the rice-based solutions. Hypotonie solutions promote water absorption in the proximal jejunum more effectively than isotonic solutions.  Thus, polymeric solutions permit glucose to be administered at little osmotic cost. Moreover, rice-syrup solids contain primarily short-chain glucose polymers. This makes them a readily available substrate for digestion by glucoamylase,  an intestinal enzyme that is present in infants and is relatively resistant to intestinal mucosal injury. \n\n【65】It has been theorized that the amino acids in oral rehydration solutions might potentiate the effects of carbohydrate on the absorption of sodium and water.  We added casein hydrolysate to one of our rice solutions to test this theory. We found that the infants receiving that solution (group B) had a lower net intake of rehydration solution because they vomited more during the rehydration period. The reduced intake could have been a factor in the infants' low stool output (the lowest among the groups). For most of the other measurements, there were no important differences between the two groups receiving solutions made with rice-syrup solids (with and without casein hydrolysate). Consequently, there appears to be no advantage to adding casein hydrolysate to a solution of this kind. However, the addition of other specific amino acids, different peptides, or both, may further enhance the absorption of fluid and electrolytes.\n\n【66】All three oral rehydration solutions were effective treatments for mild to moderate dehydration due to acute diarrhea. In only one infant, who had a high stool output and persistent hyponatremia, was treatment considered to have failed; this infant required intravenous therapy. The rehydration solution containing 50 mmol of sodium per liter was inadequate to correct his condition. Several investigators have reported that solutions with sodium concentrations of 50 or 75 mmol per liter are adequate for rehydration of well-nourished children with cholera.  <sup>, </sup>  <sup>, </sup>  However, the oral rehydration solutions failed to reverse hyponatremia in more than half of patients when the fecal output exceeded 10 ml per kilogram per hour, even when the rehydration solution contained 90 mmol of sodium per liter. \n\n【67】In summary, oral rehydration solutions containing rice-syrup solids were found to be superior to a glucose-based solution in decreasing stool output. Since the solution containing rice-syrup solids without added casein hydrolysate promoted higher water and potassium balances and was better tolerated, it may be the most suitable solution for the management of acute diarrhea in infants without cholera.", "index": 11554, "show": true, "start": 11489, "end": 11494, "province": ["文本干净度", "页码/数字"], "isEdit": false}, {"text": " 19 ", "content": "【0】Rice-Based Oral Electrolyte Solutions for the Management of Infantile Diarrhea\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】In infants the treatment of acut<mark> (Doctor’s Infant Scale, Detecto Scales, Brooklyn, N.Y.).</mark>ation but does not reduce the severity of diarrhea. Oral rehydration with solutions based on rice powder may reduce stool output as well as restore fluid volume.\n\n【3】Methods.\n--------\n\n【4】We designed a prospective, randomized, double-blind study to evaluate the efficacy of two rice-based rehydratio<mark> (Astra-8, OA TS Meter, American Optical, Buffalo, N.Y.; and Combur 8 Test, Boehringer–Mannheim, Waldhof, Germany).</mark>ained rice-syrup solids and casein hydrolysate, and solution C, the glucose-based solution, served as control. The study subjects were 86 mildly to moderately dehydrated infant boys, 3 to 18 months old, who were admitted to a children's hospital with acute diarrhea. We measured fluid intake, fecal and urine output, and absorption and retention of fluid, sodium, and potassium at intervals for 48 hours in all 86 infants.\n\n【5】Results.\n--------\n\n【6】The mean (±SE) fecal output was significantly lower in the infants given solution A (group A infants) than in the infants given solution C (group C) (29±4 vs. 46±7 ml per kilogram of body weight, P<0.05) during the first six hours of therapy. The infants in group A also had greater fluid absorption (221±16 vs. 167±9 ml per kilogram, P<0.05) over the entire 48 hours of therapy and greater potassium absorption (1.6±0.2 vs. 0.6±0.1 mmol per kilogram, P<0.05) during the first six hours than the infants in group C. Solution B offered no advantages over solution A.\n\n【7】Conclusions.\n------------\n\n【8】Solutions containing rice-syrup solids were effective in the rehydration of infants with acute diarrhea. They decreased stool output and promoted greater absorption and retention of fluid and electrolytes than did a glucose-based solution. \n\n【9】Introduction\n------------\n\n【10】GLUCOSE-BASED oral rehydration solutions have provided a simple and successful means of treating or preventing dehydration due to acute diarrhea in infants and children. Although glucose-based solutions stimulate the intestinal absorption of fluid and electrolytes from isotonic luminal contents, they do not aid in the reabsorption of fluid secreted by the intestine.  Thus, these solutions do not lessen the severity of diarrhea. The lack of efficacy of oral rehydration therapy in reducing diarrhea is the primary barrier to its global acceptance; it is estimated that the oral-rehydration-therapy packets provided by the World Health Organization are used in only 19 percent of episodes of diarrhea worldwide. \n\n【11】Some but not all investigators have found that adding small carrier molecules, such as amino acids, to oral rehydration solutions improves their performance.  <sup><a>4 </a></sup>  Recent studies have indicated that oral rehydration solutions prepared from rice not only ameliorate dehydration but also decrease diarrheal fluid loss.  <sup><a>7 </a></sup>  <sup><a>9 </a></sup> The effects of these polymeric solutions are either comparable or superior to those of glucose-containing solutions.  The cited disadvantages of rice solutions, however, include the need for cooking, the possibility of incorrect preparation, and rapid fermentation.  <sup>, </sup>  In addition, some infants may not tolerate whole starch. \n\n【12】Two oral rehydration solutions have been developed that retain the advantages of a rice-based solution while eliminating the disadvantages mentioned above. One of these solutions contains rice-syrup solids prepared under industrial conditions from solubilized rice starch as a carbohydrate source; the other has the same rice-syrup solids plus casein hydrolysate. The solutions are ready to use and stable.\n\n【13】We designed this randomized, double-blind study to evaluate the safety and efficacy of these rice-based solutions in the management of mild to moderate dehydration in infants with acute diarrhea. A commercial glucose-based oral rehydration solution was also evaluated for comparison purposes.\n\n【14】Methods\n-------\n\n【15】Patients\n--------\n\n【16】Ninety-four infant boys, 3 to 18 months of age, were selected from patients entering the Emergency Service of the Hospital Nacional de Niños in San José, Costa Rica. All were candidates for oral rehydration therapy because they had mild (<5 percent) or moderate (5 to 10 percent) dehydration caused by acute diarrhea of less than seven days' duration. The study was conducted during a six-month period, from September 1988 through February 1989. Patients were excluded if any of the following conditions were present: severe malnutrition, obesity, absence of bowel sounds, pneumonia, meningitis, severe congenital or metabolic disease, convulsions, unconsciousness, or shock. No girls were included in the study, since the separate collection of urine and stool from infant girls is difficult unless catheters are used. We had no reason to think that the results of oral rehydration therapy would differ between boys and girls.\n\n【17】The population served by the hospital consists mostly of lower- and middle-class families from urban or rural-urban areas. The study was approved by the institutional review board for human research of the Costa Rican Social Security System and by the Hospital Nacional de Niños Clinical Investigations Committee. Written informed consent was obtained from each infant's parent or guardian at the time of admission.\n\n【18】Treatment Protocol\n------------------\n\n<mark>【19】Table 1. </mark>Composition of the Oral Solutions Used to Treat Infants with Acute Diarrhea.\n\n【20】After an initial clinical history taking and physical examination, the patients were admitted to the rehydration unit. By means of a computer-generated block randomization schedule (PLAN Procedure),  the infants were randomly assigned in double-blind fashion to one of three treatment groups. Those in group A received a rice-based electrolyte solution containing 30 g of rice-syrup solids and 50 mmol of sodium per liter (solution A; Ricelyte, Mead Johnson nutritional Group, Evansville, Ind.). Those in group B received a solution with the same ingredients, with the addition of 5 g of casein hydrolysate per liter (solution B; Mead Johnson nutritional Group). Infants in group C received a commercial oral rehydration solution containing 75 mmol of sodium and 25 g of glucose per liter (solution C; Rehydralyte, Ross Laboratories, Columbus, Ohio).<mark> The composition of the solutions is shown in Table 1 .</mark> The solutions were coded to keep investigators and parents unaware of which solution was being administered.\n\n【21】The rice-syrup solids were analyzed by high-performance liquid chromatography to determine the carbohydrate profile. The results were as follows: glucose, 3.5 percent; glucose polymers of two to six units, 64.9 percent; and glucose polymers of more than seven units, 31.6 percent. The casein hydrolysate was composed of small peptides (50 percent) and amino acids (50 percent).\n\n【22】At the time of admission, each infant's fluid deficit was determined by multiplying his weight at admission by the percent dehydration, which was estimated on the basis of clinical signs.  The randomly assigned solution was administered in a volume twice as great as the estimated fluid deficit within the next four to six hours. After he had ingested the solution, the infant's degree of hydration was reassessed. If rehydration had not been achieved, the same solution was administered again in a volume calculated on the basis of the most recent estimate of the infants's fluid deficit. \n\n【23】If the infant refused to drink the solution or vomited frequently, the solution was administered by nasogastric tube at a rate of 15 ml per kilogram of body weight per hour. If the solution was tolerated for 15 to 30 minutes, the rate of administration was increased to 30 ml per kilogram per hour. If an infant required intravenous therapy because of persistent serum electrolyte abnormalities, high fecal output, or continued vomiting, treatment was considered to have failed.\n\n【24】After rehydration, the patients received a soy-based formula containing 2.76 kJ (0.66 kcal) per milliliter (ProSobee, Mead Johnson nutritional Group) in a volume of 120 ml per kilogram every 24 hours. In addition, the infants were offered oral rehydration solution after each diarrheal stool in a volume equal to the stool volume. The infants who were breast-fed before admission were allowed to resume breast-feeding after rehydration. Breast-milk intake was estimated by subtracting the mean of three values for the infant's weight before nursing from the mean of three values for his weight afterward. Plain water was allowed ad libitum after rehydration.\n\n【25】The patients were discharged after 48 hours or 16 hours after the last diarrheal stool, whichever was later.\n\n【26】Intake, Output, and Balance Studies\n-----------------------------------\n\n【27】Fluid intake was measured for the following periods during the study: period 1, 0 to 6 hours; period 2, >6 to 12 hours; period 3, >12 to 24 hours; and period 4, >24 to 48 hours; it was also measured cumulatively, for the entire 48-hour study period. Net fluid intake was determined by subtracting the weight of any vomitus from the amount of fluid ingested. The weight of vomitus was calculated as the difference between the dry and wet weights of diapers used to collect the vomitus.\n\n【28】All infants remained on metabolic beds during the study; urine and feces were collected separately for the following periods: period 1, 0 to 6 hours; period 2, >6 to 12 hours; period 3, >12 to 24 hours; and period 4, >24 to 48 hours. Urine was measured and feces were weighed on a precision scale with a tolerance of 100 mg<mark> (Triple-Beam Balance Dial-O-Gram model 1630, Ohaus Scale, Union, N.J.).</mark>\n\n【29】Each infant's sodium and potassium intake was calculated on the basis of the composition of the ingested rehydration solutions and the soy formula. If infants were breast-fed, breast-milk samples were analyzed for sodium and potassium with a spectrophotometer (Astra-8, Beckman Instruments, Fullerton, Calif.), and these values were used in the calculations of intake. Fecal sodium content, potassium content, and osmolality and urinary sodium content, potassium content, specific gravity, and pH were also determined (Astra-8, OA TS Meter, American Optical, Buffalo, N.Y.; and Combur 8 Test, Boehringer–Mannheim, Waldhof, Germany).\n\n【30】The apparent absorption of fluid, sodium, and potassium was calculated by subtracting the fecal output from the net intake for the same period. The apparent retention of fluid, sodium, and potassium was calculated by subtracting both fecal and urinary output from net intake.\n\n【31】Other Measurements\n------------------\n\n【32】Nude body weights were recorded at admission, on completion of rehydration, and after 6, 12, 24, and 48 hours on a mechanical baby scale with a tolerance of 10 g (Doctor's Infant Scale, Detecto Scales, Brooklyn, N.Y.).\n\n【33】Blood was drawn at admission and after 6, 12, 24, and 48 hours for the measurement of pH and partial pressure of carbon dioxide, serum sodium, potassium, chloride, bicarbonate, glucose, and urea nitrogen levels, and osmolality (Astra-8; and pH/Blood Gas Analyzer model 1301, Instrumentation Laboratory, Milan, Italy). The initial samples of stool were examined for salmonella, shigella, _Campylobacter jejuni_ , cryptosporidium, <mark> 18  </mark>><a>18 </a></sup>  and ova and parasites. Rotavirus antigen was identified in the stool with an enzyme-linked immunoassay.  <sup><a>19 </a></sup> \n\n【34】Statistical Analysis\n--------------------\n\n【35】The results are expressed as means ±SE unless otherwise indicated. Differences between treatments were tested for significance by analysis of variance. Treatment differences over time were tested by repeated-measures analysis of variance. Nonparametric data were tested by the chi-square test. Differences were considered significant when the P value was less than 0.05. The Statistical Analysis System (SAS) software was used for the analyses. \n\n【36】Results\n-------\n\n【37】Characteristics of Patients\n---------------------------\n\n【38】Of the 94 infants enrolled in the study, 8 were not included in the final analysis for reasons unrelated to treatment. In group A, bronchiolitis developed in one patient, and fecal collections were incomplete for two patients. In group B, fecal collections were incomplete for two patients, one had an epileptic seizure (a condition not identified in the history), and bronchiolitis developed in one. Output measurements were incomplete for one patient in group C. Thus, 30 infants remained in group A, 27 in group B, and 29 in group C, for a total of 86.\n\n【39】Table 2. Characteristics of the 86 Infants with Acute Diarrhea at Admission.\\*\n\n【40】The clinical characteristics of these 86 infant boys at the time of admission are shown in Table 2 . There were no significant differences between the groups except that the infants in group B were heavier than those in group A.\n\n【41】The distribution of stool samples positive for pathogens was similar in the three groups . The stools of 35 percent of the patients were positive for rotavirus antigen.\n\n【42】Intake, Output, and Balance Studies\n-----------------------------------\n\n【43】### _Fluids_\n\n【44】Reluctance to drink the solution led to its nasogastric administration to six infants in group A, one in group B, and five in group C. Four infants in group A, 14 in group B, and 4 in group C received the solutions by that route because of persistent vomiting.\n\n【45】Table 3. Fluid Intake, Fecal Output, and Apparent Fluid Absorption and Retention during Treatment in 86 Infants with Acute Diarrhea.\\*\n\n【46】During the first 12 hours, the volume of vomitus for the infants who received the rice-based solution with casein hydrolysate (group B, 38±8 ml per kilogram) was significantly greater than that for group A (15±8 ml per kilogram) or group C (21±8 ml per kilogram). The net fluid intake was comparable in the three groups of infants during the first six hours of treatment (period 1). From >6 to 12 hours (period 2) and from >24 to 48 hours (period 4), the infants fed the rice solution with casein hydrolysate (group B) had a lower net intake than those in the other two groups .\n\n【47】The mean fecal output was higher for the infants in group C during several periods . The fecal weights during the 48-hour study (periods 1 through 4) were 199±18 g per kilogram for group A, 145±15 g per kilogram for group B, and 264±35 g per kilogram for group C. Overall, the infants who received the rice-based solutions (groups A and B) had 25 and 45 percent less fecal output, respectively, than the infants in group C.\n\n【48】The apparent absorption of fluid in the infants in group A was significantly greater than that in the infants in groups B and C from 0 to 6 hours and from >12 to 24 hours after the beginning of therapy (periods 1 and 3). During the entire 48 hours of the study, the mean amount of fluid apparently absorbed by infants in group A was also significantly greater than that in the other two groups .\n\n【49】During the first six hours of therapy (period 1), the mean amount of fluid apparently retained was significantly greater in group A than in the other two groups. The apparent retention of fluid was also greater in the infants in group A than in those in group B during the entire 48-hour study period .\n\n【50】### _Sodium_\n\n【51】During the first six hours, sodium intake was significantly higher in the infants in group C, who received the oral rehydration solution with the highest sodium concentration (group A, 5.2±0.4 mmol per kilogram; group B, 4.3±0.3 mmol per kilogram; and group C, 7.6±0.7 mmol per kilogram). Although the infants in group C had higher intake values thereafter, the differences were significant only in comparison with group B. The sodium output in the feces of the infants in group C was significantly higher in the first six hours of therapy (group A, 1.4±0.3 mmol per kilogram; group B, 1.1±0.2 mmol per kilogram; and group C, 2.9±0.7 mmol per kilogram) and during the entire 48-hour study period (group A, 9.4±1.1 mmol per kilogram; group B, 5.7±0.7 mmol per kilogram; and group C, 15.7±2.6 mmol per kilogram).\n\n【52】Table 4. Apparent Retention of Sodium and Potassium during Treatment in 86 Infants with Acute Diarrhea.\\*\n\n【53】The apparent absorption and retention of sodium were generally comparable in the three groups throughout the study. Only during two collection periods (periods 1 and 4) did the infants receiving the rice-based solution with casein hydrolysate (group B) have significantly lower retention of sodium than those in group C .\n\n【54】### _Potassium_\n\n【55】The potassium intake of the infants in the three groups differed only during period 1 (0 to 6 hours), when that of the infants in group A was significantly higher than that in group C (group A, 2.7±0.2 mmol per kilogram; group B, 2.2±0.2 mmol per kilogram; and group C, 2.1±0.2 mmol per kilogram). During this six-hour period, the infants in group C had a significantly higher fecal output of potassium (group A, 1.0±0.1 mmol per kilogram; group B, 1.1±0.1 mmol per kilogram; and group C, 1.4±0.2 mmol per kilogram) than those in the other groups. The apparent absorption of potassium was significantly higher in the infants in group A than that in those in group C from 0 to 6 hours (P<0.05) (group A, 1.6±0.2 mmol per kilogram; group B, 1.2±0.1 mmol per kilogram; and group C, 0.6±0.1 mmol per kilogram) and for the entire 48-hour study period (P<0.05) (group A, 3.4±0.5 mmol per kilogram; group B, 2.7±0.5 mmol per kilogram; and group C, 1.8±0.5 mmol per kilogram). The amounts of potassium apparently retained are shown in Table 4 .\n\n【56】Measurements in Blood\n---------------------\n\n【57】The mean serum sodium concentrations in the three groups were within the normal range throughout the study. The 13 infants in groups A and B who had hypernatremia on admission (serum sodium level, ≥150 mmol per liter) all had normal levels after 24 hours, if not earlier. Of the two infants in group C who had hypernatremia on admission, one had normal serum sodium levels after 48 hours, and the other had persistent hypernatremia throughout his hospital stay. Both were asymptomatic.\n\n【58】Five infants had hyponatremia (serum sodium level, ≤130 mmol per liter) at the time of their entry into the study. Four of them had normal concentrations after 48 hours of treatment. The fifth (in group A) had persistent hyponatremia, with a high fecal output (16 ml per kilogram per hour) and fecal sodium concentrations of 60 to 83 mmol per liter. After 24 hours, this child received intravenous fluids. He had a seizure after beginning intravenous treatment but recovered uneventfully. This patient was the only one in whom treatment failed.\n\n【59】No significant differences were found in the mean serum chloride, potassium, bicarbonate, glucose, and urea nitrogen concentrations or in values for blood pH and partial pressure of carbon dioxide among the three groups at any time. The mean serum osmolality for the infants in group A was significantly lower than that for the infants in group C throughout the study (290±2 vs. 298±2 mmol per kilogram; P<0.05).\n\n【60】Clinical Outcomes\n-----------------\n\n【61】The percent gains in body weight after rehydration were comparable among the three groups: group A, 4.0±0.4 percent; group B, 5.2±0.6 percent; and group C, 4.6±0.5 percent. The average lengths of time necessary to achieve rehydration were not significantly different: group A, 7.3±0.6 hours; group B, 6.4±0.7 hours; and group C, 6.7±0.7 hours. The duration of diarrhea, measured as the time between the initiation of oral rehydration therapy and the last liquid stool, did not differ significantly: group A, 62.9±7.5 hours; group B, 51.1±4.5 hours; and group C, 55.8±5.3 hours.\n\n【62】Discussion\n----------\n\n【63】Most oral rehydration solutions contain glucose and electrolytes. No optimal composition has been determined, however.  <sup>, </sup>  The results of this clinical trial, in which we used stable, ready-to-use, commercially prepared oral rehydration solutions containing rice-syrup solids, indicate that such solutions may be more efficient than glucose-based solutions in promoting fluid and electrolyte absorption during the rehydration phase in infants with acute diarrhea. In the 48-hour study, the infants in the two groups (groups A and B) that received rice solutions had lower fecal outputs than those in group C, who received the glucose solution. The mean fecal output of the infants in group A was 25 percent lower and that of the infants in group B was 45 percent lower than that of the infants in group C. In addition, the infants in group A had higher values for the absorption of fluid and potassium. Furthermore, even though the rice-based solutions contained one third less sodium, the groups' sodium balances were similar. These results suggest that the rice-syrup solids were very efficient in promoting sodium absorption.\n\n【64】One possible explanation for these results is the lower osmolality of the rice-based solutions. Hypotonie solutions promote water absorption in the proximal jejunum more effectively than isotonic solutions.  Thus, polymeric solutions permit glucose to be administered at little osmotic cost. Moreover, rice-syrup solids contain primarily short-chain glucose polymers. This makes them a readily available substrate for digestion by glucoamylase,  an intestinal enzyme that is present in infants and is relatively resistant to intestinal mucosal injury. \n\n【65】It has been theorized that the amino acids in oral rehydration solutions might potentiate the effects of carbohydrate on the absorption of sodium and water.  We added casein hydrolysate to one of our rice solutions to test this theory. We found that the infants receiving that solution (group B) had a lower net intake of rehydration solution because they vomited more during the rehydration period. The reduced intake could have been a factor in the infants' low stool output (the lowest among the groups). For most of the other measurements, there were no important differences between the two groups receiving solutions made with rice-syrup solids (with and without casein hydrolysate). Consequently, there appears to be no advantage to adding casein hydrolysate to a solution of this kind. However, the addition of other specific amino acids, different peptides, or both, may further enhance the absorption of fluid and electrolytes.\n\n【66】All three oral rehydration solutions were effective treatments for mild to moderate dehydration due to acute diarrhea. In only one infant, who had a high stool output and persistent hyponatremia, was treatment considered to have failed; this infant required intravenous therapy. The rehydration solution containing 50 mmol of sodium per liter was inadequate to correct his condition. Several investigators have reported that solutions with sodium concentrations of 50 or 75 mmol per liter are adequate for rehydration of well-nourished children with cholera.  <sup>, </sup>  <sup>, </sup>  However, the oral rehydration solutions failed to reverse hyponatremia in more than half of patients when the fecal output exceeded 10 ml per kilogram per hour, even when the rehydration solution contained 90 mmol of sodium per liter. \n\n【67】In summary, oral rehydration solutions containing rice-syrup solids were found to be superior to a glucose-based solution in decreasing stool output. Since the solution containing rice-syrup solids without added casein hydrolysate promoted higher water and potassium balances and was better tolerated, it may be the most suitable solution for the management of acute diarrhea in infants without cholera.", "index": 11695, "show": true, "start": 11617, "end": 11621, "province": ["文本干净度", "页码/数字"], "isEdit": false}]}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-14 00:21:33", "grab_time": "2024-08-13 23:19:52"}
{"id": 2234385, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "cd8c62ff-3b53-4ccd-aae3-1facaca97d67", "title": "Covid-19 — The Law and Limits of Quarantine", "text": "【0】Covid-19 — The Law and Limits of Quarantine\nArticle\n-------\n\n【1】As Covid-19 spreads around the globe, governments have imposed quarantines and travel bans on an unprecedented scale. China locked down whole cities, and Italy has imposed draconian restrictions throughout the country. In the United States, thousands of people have been subjected to legally enforceable quarantines or are in “self-quarantine.” The federal government has also banned entry by non–U.S. nationals traveling from China, Iran, and most of Europe and is screening passengers returning from heavily affected countries. Still, the numbers of cases and deaths continue to rise.\n\n【2】Quarantines and travel bans are often the first response against new infectious diseases. However, these old tools are usually of limited utility for highly transmissible diseases, and if imposed with too heavy a hand, or in too haphazard a manner, they can be counterproductive.  With a virus such as SARS-CoV-2, they cannot provide a sufficient response.\n\n【3】In public health practice, “quarantine” refers to the separation of persons (or communities) who have been exposed to an infectious disease. “Isolation,” in contrast, applies to the separation of persons who are known to be infected. In U.S. law, however, “quarantine” often refers to both types of interventions, as well as to limits on travel. Isolation and quarantine can be voluntary or imposed by law.\n\n【4】Inside the country, isolation and quarantine orders have traditionally come from the states. Courts have typically upheld these orders in deference to the states’ broad powers to protect public health. Nevertheless, courts have occasionally intervened when a quarantine was unreasonable or when officials failed to follow necessary procedures. For example, in _Jew Ho v. Williamson_ (1900), a federal court struck down a quarantine imposed by San Francisco in response to an outbreak of bubonic plague because it was racially motivated and ill-suited to stop the outbreak.\n\n【5】Although isolation and quarantine orders have been less common in recent decades, many states have isolated patients with tuberculosis who did not adhere to medication regimens.  At least 18 states quarantined people returning from West Africa during the 2014 Ebola outbreak.  In March 2019, Rockland County, New York, prohibited all minors who were unvaccinated against measles from entering any place of public assembly. In _W.D. v. County of Rockland_ (2019), a New York State judge struck down that order, ruling that there was no emergency. Most states, however, do not require an emergency declaration in order to issue a quarantine.\n\n【6】The federal quarantine power is limited to preventing the spread of communicable diseases into the country or across state lines. Section 361 of the Public Health Service Act grants the Surgeon General the power (since delegated to the Centers for Disease Control and Prevention \\[CDC\\]) to apprehend, detain, or issue a conditional release for the purpose of preventing the introduction into the country, or the spread across state lines, of a quarantinable disease, as designated by executive order . The current list includes “severe acute respiratory syndromes,” which encompasses Covid-19.\n\n【7】Quarantinable Diseases. <sup><a>*</a></sup>\n-------------------------------------------\n\n【8】*   Cholera\n\n【9】*   Diphtheria\n\n【10】*   Infectious tuberculosis\n\n【11】*   Plague\n\n【12】*   Smallpox\n\n【13】*   Yellow fever\n\n【14】*   Viral hemorrhagic fevers\n\n【15】*   Severe acute respiratory syndromes\n\n【16】*   Influenza that can cause a pandemic\n\n【17】\\* From the Centers for Disease Control and Prevention. Legal authorities for isolation and quarantine. www.cdc.gov/quarantine/aboutlawsregulationsquarantineisolation.html . opens in new tab .\n\n【18】Despite the breadth of its powers, the CDC has generally focused on providing expert guidance to states during outbreaks. In 2017, however, the agency issued new quarantine regulations (codified in 42 Code of Federal Regulations \\[CFR\\], parts 70 and 71) suggesting that it would no longer defer to the states. These regulations make clear that, independent of state action, the CDC may isolate, quarantine, examine, or bar travel of anyone within the country who CDC officials reasonably believe may bring a communicable disease into the country or spread it across state lines. When the secretary of health and human services declares a public health emergency, as Secretary Alex Azar did on January 31, these orders can be issued against persons in the precommunicable stage, which begins at a person’s earliest opportunity for exposure to an infection and ends on the latest date at which the person could reasonably be expected to become contagious.\n\n【19】The regulations also commit the CDC to providing medical care for people who are detained, but they may charge insurers for that care. In addition, they establish a multilevel internal administrative review process. But they do not ensure expeditious or independent review of detention orders or travel bans. Moreover, although the CDC stated that it would “seek to use the least restrictive means necessary to prevent the spread of communicable diseases,” the regulations do not require the agency to adhere to that standard. Though the CDC’s quarantine powers permit it to deny entry into the United States for a quarantinable disease, President Trump relied on Sections 212(f) and 215(a) of the Immigration and Naturalization Act to ban Chinese and Iranian nationals from entering the country.\n\n【20】Despite their breadth, the federal and state quarantine powers are subject to important constitutional limitations.  First, as _Jew Ho_ affirmed, quarantines cannot be imposed in a racially invidious manner. Second, governments must have a strong basis for the restrictions. Looking to case law regarding civil commitment, many scholars and some lower courts have concluded that isolation and quarantine are constitutional only when the government can show by clear and compelling evidence that they are the least restrictive means of protecting the public’s health. However, at least two federal courts reviewing postdetention challenges to Ebola quarantines held that the standard was not sufficiently well established to allow the claims to go forward.  Third, persons who are detained, or whose liberty is otherwise restricted, are entitled to judicial review — traditionally under the writ of habeas corpus.  Finally, when governments detain people, they must meet those people’s basic needs, ensuring access to health care, medication, food, and sanitation. Such standards are not only constitutionally compelled: they are critical to ensuring that detained persons comply with orders.\n\n【21】Although we are likely to see greater use of robust social distancing measures, such as school closures or the cancellation of public meetings, broad sanitary cordons — in which geographic areas are quarantined — would raise serious constitutional questions. They also can present numerous logistical challenges and can increase the risk to those living in the restricted zone. Such measures may also have limited efficacy with a highly contagious disease such as Covid-19. \n\n【22】With community transmission occurring in several parts of the United States, it is time to recognize that travel bans and mandatory quarantines alone cannot end the outbreak. In a public letter to the Trump administration, we (along with more than 800 other public health and legal scholars and organizations) argue that more constructive tools are needed. \n\n【23】Flattening the curve — slowing the spread of Covid-19 across space and time — is critical. The health care system cannot sustain a massive influx of infectious cases to emergency departments and hospitals. Patients with mild symptoms should stay home when possible. To facilitate this step, workers should be allowed to telecommute wherever it’s feasible to do so. But many low-wage and gig workers cannot afford to stay home. Nor can they handle the economic impact of other social distancing measures that may help to slow transmission. On March 13, the House of Representatives, with President Trump’s support, took the first step by passing the Families First Coronavirus Response Act, which includes provisions for paid sick leave and unemployment insurance for many, but unfortunately not all, workers. As of mid March, the Senate has yet to take up the bill.\n\n【24】We must also reduce hurdles to testing and care. The House bill would provide free testing, but more needs to be done to ensure that testing kits are available. Furthermore, noncitizens must be protected from adverse immigration consequences for seeking testing or care or for complying with contact tracing. Finally, emergency guidance or regulations can be issued to limit the financial impact of high-deductible health plans and “surprise bills” from out-of-network providers for Covid-19 diagnosis or treatment.\n\n【25】Despite the breadth and allure of travel bans and mandatory quarantine, an effective response to Covid-19 requires newer, more creative legal tools. With Covid-19 in our communities, the time has come to imagine and implement public health laws that emphasize support rather than restriction.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:20:26", "endTime": "2024/08/14 15:20:56", "cost": 29.245}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:30", "update_time": "2024-08-13 23:20:55", "grab_time": "2024-08-13 23:20:26"}
{"id": 2234384, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "db947a0d-e87d-44e5-96cd-ac8b77643fe5", "title": "Hypotension Associated with Prekallikrein Activator (Hageman-Factor Fragments) in Plasma Protein Fraction", "text": "【0】Hypotension Associated with Prekallikrein Activator (Hageman-Factor Fragments) in Plasma Protein Fraction\nAbstract\n--------\n\n【1】Thirteen lots of plasma protein fraction made by one manufacturer were implicated in 23 recent reports of hypotension in surgical patients. Four of these patients required resuscitation after rapid administration of the product in the postoperative period. All implicated lots had prekallikrein-activator activity but low levels of bradykinin and kallikrein. The prekallikrein activator was identified as Hageman-factor fragments by molecular weight (35,000 as estimated by gel chromatography), isoelectric point (4.2 to 4.4), and inhibition by antibody to Hageman factor. These data suggest that Hageman-factor fragments are potent hypotensive agents, presumably because they trigger the generation of bradykinin in recipients. Prekallikrein-activator activity, usually at levels lower than those in the initial 13 implicated lots, was frequently detected in plasma protein fraction made by other manufacturers. Several of these lots were associated with additional reports of hypotension. Prekallikrein-activator activity rarely occurred in albumin.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:38:06", "endTime": "2024/08/14 15:39:00", "cost": 53.871}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 23:39:00", "grab_time": "2024-08-13 23:38:06"}
{"id": 2234383, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "0a676fce-0f84-458f-ae55-7c1c223c7d5b", "title": "Kathryn", "text": "【0】Kathryn\n### Audio Interview\n\n【1】 Interview with Dr. Stuart Slavin on depression and suicide among physicians and trainees and how to address stigma associated with mental illness. \n\n【2】Last August, a fourth-year medical student ended her life by jumping out of a window. In the aftermath, other students expressed rage over not feeling adequately supported, indicating that they were also struggling with depression, anxiety, and suicidal ideation.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:02:32", "endTime": "2024/08/14 15:02:54", "cost": 22.152}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 23:02:55", "grab_time": "2024-08-13 23:02:32"}
{"id": 2234382, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "4854778f-f3c7-4d12-b8a0-a4d5121c6f1b", "title": "Management of Chronic Obstructive Pulmonary Disease", "text": "【0】Management of Chronic Obstructive Pulmonary Disease\n*   Related Articles\n\n【1】To the Editor\n-------------\n\n【2】In their review of the management of chronic obstructive pulmonary disease (April 8 issue),  Ferguson and Cherniack state, “All persons who are at risk \\[for the disease\\] should be evaluated for airflow limitation with the use of spirometry\\.\\[S\\]pirometry should be a part of routine examinations, since it provides valuable information on changes in lung function over time.” Why was such a definitive comment made?\n\n【3】Before routine diagnostic testing is recommended, there should be some indication of how the results will alter management. Since the risk factors for chronic obstructive pulmonary disease (i.e., smoking or occupational exposure) should in any event be avoided, why perform this test routinely, adding to the cost without providing a comparable increase in benefit?\n\n【4】Robert Matz, M.D.  \nMount Sinai Medical Center, New York, NY 10029\n\n【5】1 Reference\n\n【6】1.  1\\. Ferguson GT, Cherniack RM. Management of chronic obstructive pulmonary disease. N Engl J Med 1993 ;328: 1017 \\- 1022\n\n【7】    *   Full Text\n    *   Web of Science . opens in new tab\n    *   Medline . opens in new tab\n    Google Scholar . opens in new tab\n\n【8】To the Editor\n-------------\n\n【9】In their recent review of the management of chronic obstructive pulmonary disease, Ferguson and Cherniack state in Table 2 that pirbuterol, a beta <sub>2 </sub> \\-agonist, is less beta <sub>2 </sub> \\-selective and has a shorter duration of action than albuterol. This conclusion is not supported by published data  .\n\n【10】In 12 patients with asthma, the improvement in the forced expiratory volume in one second after the administration of two puffs of pirbuterol (400 μg) or albuterol (200 μg) was similar  . Double-blind comparisons of inhaled pirbuterol with placebo established that pirbuterol has a median duration of action of more than five hours  . In five crossover studies comparing the functional effects of inhaled albuterol and pirbuterol for four hours after the administration of each drug, 80.8 percent of patients were still responding to pirbuterol after four hours, whereas only 67.3 percent were responding to albuterol. The magnitude of the response at four hours was higher in the patients still responding to pirbuterol than in the patients still responding to albuterol  . These data indicate that pirbuterol has a duration of action that equals or exceeds that of albuterol.\n\n【11】Thierry C. Chinet, M.D.  \nUniversity of Paris, 92104 Boulogne, France\n\n【12】4 References\n\n【13】1.  1\\. Moore PF, Constantine JW, Barth WE. Pirbuterol, a selective beta2 adrenergic bronchodilator. J Pharmacol Exp Ther 1978 ;207: 410 \\- 418\n\n【14】    *   Web of Science . opens in new tab\n    *   Medline . opens in new tab\n    Google Scholar . opens in new tab\n2.  2\\. Windom H, Grainger J, Burgess C, Crane J, Pearce N, Beasley R. A comparison of the haemodynamic and hypokalaemic effects of inhaled pirbuterol and salbutamol. N Z Med J 1990 ;103: 259 \\- 261\n\n【15】    *   Web of Science . opens in new tab\n    *   Medline . opens in new tab\n    Google Scholar . opens in new tab\n3.  3\\. Beumer HM. Pirbuterol aerosol versus salbutamol and placebo aerosols in bronchial asthma. Drugs Exp Clin Res 1980 ;2: 77 \\- 83\n\n【16】    Google Scholar . opens in new tab\n4.  4\\. Pitts NE, Borger AP, Ghaly MS, Salsburg DS, Gans DJ. Pirbuterol -- a new selective beta-agonist. Proc R Soc Med 1983 ;56: 1 \\- 31\n\n【17】    Google Scholar . opens in new tab\n\n【18】To the Editor\n-------------\n\n【19】We would like to add something from the ophthalmologist's point of view to the review by Ferguson and Cherniack. We have seen several patients in whom acute angle-closure glaucoma developed soon after treatment with an ipratropium inhaler was begun. Patients prescribed this drug or an equivalent agent should be warned to seek treatment if a red eye or misty vision develops. Such patients usually also have a headache and a fixed (or sluggish), semidilated pupil. The condition may occur in both eyes simultaneously.  In addition, airways disease may develop in a patient undergoing long-term treatment with topical beta-blockers for glaucoma. The patient's physician may not be aware that the patient is using eyedrops, and the ophthalmologist may be unaware of the airways disease.\n\n【20】David Kinshuck, M.B., B.S., F.C.Ophth.  \nTahira Malik, M.B., Ch.B.  \nWolverhampton Eye Infirmary, Wolverhampton WV3 9QR, United Kingdom\n\n【21】1 Reference\n\n【22】1.  1\\. Shah P, Dhurjon L, Metcalfe T, Gibson JM. Acute angle closure glaucoma associated with nebulised ipratropium bromide and salbutamol. BMJ 1992 ;304: 40 \\- 41\n\n【23】    *   Crossref . opens in new tab\n    *   Web of Science . opens in new tab\n    *   Medline . opens in new tab\n    Google Scholar . opens in new tab\n\n【24】To the Editor\n-------------\n\n【25】I believe that there is a mistake in the dose of ipratropium in Table 2 of the review by Ferguson and Cherniack. The dose should be 0.02 mg per puff, or perhaps 0.018 mg per puff if one is using the American preparation. The dose of 0.18 mg per puff is an error.\n\n【26】Norbert K. Mulleneisen, M.D.  \nKlinikum Leverkusen, 51304 Leverkusen, Germany\n\n【27】Response\n--------\n\n【28】The authors reply:\n\n【29】_To the Editor:_ We disagree with Dr. Matz. Clearly, avoidance of risk factors is important, yet many patients do not heed this warning. Early identification of chronic obstructive pulmonary disease with the use of spirometry may provide the added incentive for patients to avoid these risks, especially cigarette smoking. Because of the large reserve capacity of the lung, waiting for pulmonary symptoms delays diagnosis to a point at which serious lung damage is likely to be present. In a manner akin to the management of hypertension, regular spirometry can be used to diagnose acute airflow limitation and, with observation of trends (the rate of decline in the forced expiratory volume in one second), can be used to identify people with increased susceptibility to the disease. This approach should allow earlier diagnosis, lead to early intervention, and alter the long-term course. This is especially true of patients with hereditary predispositions, including alpha <sub>1 </sub> \\-antitrypsin deficiency, in whom overt risk factors may not be evident and the diagnosis may be missed or delayed without screening spirometry. Furthermore, spirometry adds little to the cost of an evaluation, and plays an essential part in management once the disease is identified and treatment is initiated.\n\n【30】In response to Dr. Chinet, the information provided in Table 2 of our review was gleaned from a literature search and compiled from several reviews of the pharmacotherapy of chronic obstructive pulmonary disease, which typically do not include pirbuterol  ; a recent pharmacologic review of pirbuterol  ; and an original investigation of the pharmacology of inhaled pirbuterol  . We have tried not to emphasize the use of one beta-agonist over another, but we believe these references support the data in the table.\n\n【31】In response to Drs. Kinshuck and Malik, we agree that pulmonary medications can affect the eye. Although they may be uncommon, it is important to be aware of the potential side effects of any medication.\n\n【32】Finally, Dr. Mulleneisen is correct. In converting micrograms to milligrams, we dropped a zero; the correct dose of ipratropium is 18 μg, or 0.018 mg, per puff.\n\n【33】Gary T. Ferguson, M.D.  \nReuben M. Cherniack, M.D.  \nNational Jewish Center for Immunology and Respiratory Medicine, Denver, CO 80206\n\n【34】3 References\n\n【35】1.  1\\. American Thoracic Society. Standards for the diagnosis and care of patients with chronic obstructive pulmonary disease (COPD) and asthma. Am Rev Respir Dis 1987 ;136: 225 \\- 244\n\n【36】    *   Crossref . opens in new tab\n    *   Web of Science . opens in new tab\n    *   Medline . opens in new tab\n    Google Scholar . opens in new tab\n2.  2\\. Richards DM, Brogden RN. Pirbuterol: a preliminary review of its pharmacological properties and therapeutic efficacy in reversible bronchospastic disease. Drugs 1985 ;30: 6 \\- 21\n\n【37】    *   Crossref . opens in new tab\n    *   Web of Science . opens in new tab\n    *   Medline . opens in new tab\n    Google Scholar . opens in new tab\n3.  3\\. Littner MR, Tashkin DP, Calvarese B, Bautista M. Acute bronchial and cardiovascular effects of increasing doses of pirbuterol acetate aerosol in asthma. Ann Allergy 1982 ;48: 14 \\- 20\n\n【38】    *   Medline . opens in new tab\n    Google Scholar . opens in new tab", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "【4】Robert Matz, M.D.\n\nMount Sinai Medical Center, New York, NY 10029\n\n【5】1 Reference\n\n【6】1.  1. Ferguson GT, Cherniack RM. Management of chronic obstructive pulmonary disease. N Engl J Med 1993 ;328: 1017 - 1022\n\n【7】    *   Full Text\n\nWeb of Science . opens in new tab\nMedline . opens in new tab\nGoogle Scholar . opens in new tab", "content": "【0】Management of Chronic Obstructive Pulmonary Disease\n*   Related Articles\n\n【1】To the Editor\n-------------\n\n【2】In their review of the management of chronic obstructive pulmonary disease (April 8 issue),  Ferguson and Cherniack state, “All persons who are at risk \\[for the disease\\] should be evaluated for airflow limitation with the use of spirometry\\.\\[S\\]pirometry should be a part of routine examinations, since it provides valuable information on changes in lung function over time.” Why was such a definitive comment made?\n\n【3】Before routine diagnostic testing is recommended, there should be some indication of how the results will alter management. Since the risk factors for chronic obstructive pulmonary disease (i.e., smoking or occupational exposure) should in any event be avoided, why perform this test routinely, adding to the cost without providing a comparable increase in benefit?\n\n【4】Robert Matz, M.D.  \nMount Sinai Medical Center, New York, NY 10029\n\n【5】1 Reference\n\n【6】1.  1\\. Ferguson GT, Cherniack RM. Management of chronic obstructive pulmonary disease. N Engl J Med 1993 ;328: 1017 \\- 1022\n\n【7】    *   Full Text\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n\n【8】To the Editor\n-------------\n\n【9】In their recent review of the management of chronic obstructive pulmonary disease, Ferguson and Cherniack state in Table 2 that pirbuterol, a beta <sub>2 </sub> \\-agonist, is less beta <sub>2 </sub> \\-selective and has a shorter duration of action than albuterol. This conclusion is not supported by published data  .\n\n【10】In 12 patients with asthma, the improvement in the forced expiratory volume in one second after the administration of two puffs of pirbuterol (400 μg) or albuterol (200 μg) was similar  . Double-blind comparisons of inhaled pirbuterol with placebo established that pirbuterol has a median duration of action of more than five hours  . In five crossover studies comparing the functional effects of inhaled albuterol and pirbuterol for four hours after the administration of each drug, 80.8 percent of patients were still responding to pirbuterol after four hours, whereas only 67.3 percent were responding to albuterol. The magnitude of the response at four hours was higher in the patients still responding to pirbuterol than in the patients still responding to albuterol  . These data indicate that pirbuterol has a duration of action that equals or exceeds that of albuterol.\n\n【11】Thierry C. Chinet, M.D.  \nUniversity of Paris, 92104 Boulogne, France\n\n【12】4 References\n\n【13】1.  1\\. Moore PF, Constantine JW, Barth WE. Pirbuterol, a selective beta2 adrenergic bronchodilator. J Pharmacol Exp Ther 1978 ;207: 410 \\- 418\n\n【14】    *   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n2.  2\\. Windom H, Grainger J, Burgess C, Crane J, Pearce N, Beasley R. A comparison of the haemodynamic and hypokalaemic effects of inhaled pirbuterol and salbutamol. N Z Med J 1990 ;103: 259 \\- 261\n\n【15】    *   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n3.  3\\. Beumer HM. Pirbuterol aerosol versus salbutamol and placebo aerosols in bronchial asthma. Drugs Exp Clin Res 1980 ;2: 77 \\- 83\n\n【16】    Google Scholar . opens in new tab\n4.  4\\. Pitts NE, Borger AP, Ghaly MS, Salsburg DS, Gans DJ. Pirbuterol -- a new selective beta-agonist. Proc R Soc Med 1983 ;56: 1 \\- 31\n\n【17】    Google Scholar . opens in new tab\n\n【18】To the Editor\n-------------\n\n【19】We would like to add something from the ophthalmologist's point of view to the review by Ferguson and Cherniack. We have seen several patients in whom acute angle-closure glaucoma developed soon after treatment with an ipratropium inhaler was begun. Patients prescribed this drug or an equivalent agent should be warned to seek treatment if a red eye or misty vision develops. Such patients usually also have a headache and a fixed (or sluggish), semidilated pupil. The condition may occur in both eyes simultaneously.  In addition, airways disease may develop in a patient undergoing long-term treatment with topical beta-blockers for glaucoma. The patient's physician may not be aware that the patient is using eyedrops, and the ophthalmologist may be unaware of the airways disease.\n\n【20】David Kinshuck, M.B., B.S., F.C.Ophth.  \nTahira Malik, M.B., Ch.B.  \nWolverhampton Eye Infirmary, Wolverhampton WV3 9QR, United Kingdom\n\n【21】1 Reference\n\n【22】1.  1\\. Shah P, Dhurjon L, Metcalfe T, Gibson JM. Acute angle closure glaucoma associated with nebulised ipratropium bromide and salbutamol. BMJ 1992 ;304: 40 \\- 41\n\n【23】    *   Crossref . opens in new tab\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n\n【24】To the Editor\n-------------\n\n【25】I believe that there is a mistake in the dose of ipratropium in Table 2 of the review by Ferguson and Cherniack. The dose should be 0.02 mg per puff, or perhaps 0.018 mg per puff if one is using the American preparation. The dose of 0.18 mg per puff is an error.\n\n【26】Norbert K. Mulleneisen, M.D.  \nKlinikum Leverkusen, 51304 Leverkusen, Germany\n\n【27】Response\n--------\n\n【28】The authors reply:\n\n【29】_To the Editor:_ We disagree with Dr. Matz. Clearly, avoidance of risk factors is important, yet many patients do not heed this warning. Early identification of chronic obstructive pulmonary disease with the use of spirometry may provide the added incentive for patients to avoid these risks, especially cigarette smoking. Because of the large reserve capacity of the lung, waiting for pulmonary symptoms delays diagnosis to a point at which serious lung damage is likely to be present. In a manner akin to the management of hypertension, regular spirometry can be used to diagnose acute airflow limitation and, with observation of trends (the rate of decline in the forced expiratory volume in one second), can be used to identify people with increased susceptibility to the disease. This approach should allow earlier diagnosis, lead to early intervention, and alter the long-term course. This is especially true of patients with hereditary predispositions, including alpha <sub>1 </sub> \\-antitrypsin deficiency, in whom overt risk factors may not be evident and the diagnosis may be missed or delayed without screening spirometry. Furthermore, spirometry adds little to the cost of an evaluation, and plays an essential part in management once the disease is identified and treatment is initiated.\n\n【30】In response to Dr. Chinet, the information provided in Table 2 of our review was gleaned from a literature search and compiled from several reviews of the pharmacotherapy of chronic obstructive pulmonary disease, which typically do not include pirbuterol  ; a recent pharmacologic review of pirbuterol  ; and an original investigation of the pharmacology of inhaled pirbuterol  . We have tried not to emphasize the use of one beta-agonist over another, but we believe these references support the data in the table.\n\n【31】In response to Drs. Kinshuck and Malik, we agree that pulmonary medications can affect the eye. Although they may be uncommon, it is important to be aware of the potential side effects of any medication.\n\n【32】Finally, Dr. Mulleneisen is correct. In converting micrograms to milligrams, we dropped a zero; the correct dose of ipratropium is 18 μg, or 0.018 mg, per puff.\n\n【33】Gary T. Ferguson, M.D.  \nReuben M. Cherniack, M.D.  \nNational Jewish Center for Immunology and Respiratory Medicine, Denver, CO 80206\n\n【34】3 References\n\n【35】1.  1\\. American Thoracic Society. Standards for the diagnosis and care of patients with chronic obstructive pulmonary disease (COPD) and asthma. Am Rev Respir Dis 1987 ;136: 225 \\- 244\n\n【36】    *   Crossref . opens in new tab\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n2.  2\\. Richards DM, Brogden RN. Pirbuterol: a preliminary review of its pharmacological properties and therapeutic efficacy in reversible bronchospastic disease. Drugs 1985 ;30: 6 \\- 21\n\n【37】    *   Crossref . opens in new tab\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n3.  3\\. Littner MR, Tashkin DP, Calvarese B, Bautista M. Acute bronchial and cardiovascular effects of increasing doses of pirbuterol acetate aerosol in asthma. Ann Allergy 1982 ;48: 14 \\- 20\n\n【38】    *   Medline . opens in new tab\nGoogle Scholar . opens in new tab", "index": 902, "show": true, "start": 902, "end": 1231, "province": ["文本干净度", "无关文本"], "isEdit": false}, {"text": "Related Articles", "content": "【0】Management of Chronic Obstructive Pulmonary Disease\n*   Related Articles\n\n【1】To the Editor\n-------------\n\n【2】In their review of the management of chronic obstructive pulmonary disease (April 8 issue),  Ferguson and Cherniack state, “All persons who are at risk \\[for the disease\\] should be evaluated for airflow limitation with the use of spirometry\\.\\[S\\]pirometry should be a part of routine examinations, since it provides valuable information on changes in lung function over time.” Why was such a definitive comment made?\n\n【3】Before routine diagnostic testing is recommended, there should be some indication of how the results will alter management. Since the risk factors for chronic obstructive pulmonary disease (i.e., smoking or occupational exposure) should in any event be avoided, why perform this test routinely, adding to the cost without providing a comparable increase in benefit?\n\n<mark>【4】Robert Matz, M.D.\n\nMount Sinai Medical Center, New York, NY 10029\n\n【5】1 Reference\n\n【6】1.  1. Ferguson GT, Cherniack RM. Management of chronic obstructive pulmonary disease. N Engl J Med 1993 ;328: 1017 - 1022\n\n【7】    *   Full Text\n\nWeb of Science . opens in new tab\nMedline . opens in new tab\nGoogle Scholar . opens in new tab</mark>in new tab\n\n【8】To the Editor\n-------------\n\n【9】In their recent review of the management of chronic obstructive pulmonary disease, Ferguson and Cherniack state in Table 2 that pirbuterol, a beta <sub>2 </sub> \\-agonist, is less beta <sub>2 </sub> \\-selective and has a shorter duration of action than albuterol. This conclusion is not supported by published data  .\n\n【10】In 12 patients with asthma, the improvement in the forced expiratory volume in one second after the administration of two puffs of pirbuterol (400 μg) or albuterol (200 μg) was similar  . Double-blind comparisons of inhaled pirbuterol with placebo established that pirbuterol has a median duration of action of more than five hours  . In five crossover studies comparing the functional effects of inhaled albuterol and pirbuterol for four hours after the administration of each drug, 80.8 percent of patients were still responding to pirbuterol after four hours, whereas only 67.3 percent were responding to albuterol. The magnitude of the response at four hours was higher in the patients still responding to pirbuterol than in the patients still responding to albuterol  . These data indicate that pirbuterol has a duration of action that equals or exceeds that of albuterol.\n\n【11】Thierry C. Chinet, M.D.  \nUniversity of Paris, 92104 Boulogne, France\n\n【12】4 References\n\n【13】1.  1\\. Moore PF, Constantine JW, Barth WE. Pirbuterol, a selective beta2 adrenergic bronchodilator. J Pharmacol Exp Ther 1978 ;207: 410 \\- 418\n\n【14】    *   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n2.  2\\. Windom H, Grainger J, Burgess C, Crane J, Pearce N, Beasley R. A comparison of the haemodynamic and hypokalaemic effects of inhaled pirbuterol and salbutamol. N Z Med J 1990 ;103: 259 \\- 261\n\n【15】    *   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n3.  3\\. Beumer HM. Pirbuterol aerosol versus salbutamol and placebo aerosols in bronchial asthma. Drugs Exp Clin Res 1980 ;2: 77 \\- 83\n\n【16】    Google Scholar . opens in new tab\n4.  4\\. Pitts NE, Borger AP, Ghaly MS, Salsburg DS, Gans DJ. Pirbuterol -- a new selective beta-agonist. Proc R Soc Med 1983 ;56: 1 \\- 31\n\n【17】    Google Scholar . opens in new tab\n\n【18】To the Editor\n-------------\n\n【19】We would like to add something from the ophthalmologist's point of view to the review by Ferguson and Cherniack. We have seen several patients in whom acute angle-closure glaucoma developed soon after treatment with an ipratropium inhaler was begun. Patients prescribed this drug or an equivalent agent should be warned to seek treatment if a red eye or misty vision develops. Such patients usually also have a headache and a fixed (or sluggish), semidilated pupil. The condition may occur in both eyes simultaneously.  In addition, airways disease may develop in a patient undergoing long-term treatment with topical beta-blockers for glaucoma. The patient's physician may not be aware that the patient is using eyedrops, and the ophthalmologist may be unaware of the airways disease.\n\n【20】David Kinshuck, M.B., B.S., F.C.Ophth.  \nTahira Malik, M.B., Ch.B.  \nWolverhampton Eye Infirmary, Wolverhampton WV3 9QR, United Kingdom\n\n【21】1 Reference\n\n【22】1.  1\\. Shah P, Dhurjon L, Metcalfe T, Gibson JM. Acute angle closure glaucoma associated with nebulised ipratropium bromide and salbutamol. BMJ 1992 ;304: 40 \\- 41\n\n【23】    *   Crossref . opens in new tab\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n\n【24】To the Editor\n-------------\n\n【25】I believe that there is a mistake in the dose of ipratropium in Table 2 of the review by Ferguson and Cherniack. The dose should be 0.02 mg per puff, or perhaps 0.018 mg per puff if one is using the American preparation. The dose of 0.18 mg per puff is an error.\n\n【26】Norbert K. Mulleneisen, M.D.  \nKlinikum Leverkusen, 51304 Leverkusen, Germany\n\n【27】Response\n--------\n\n【28】The authors reply:\n\n【29】_To the Editor:_ We disagree with Dr. Matz. Clearly, avoidance of risk factors is important, yet many patients do not heed this warning. Early identification of chronic obstructive pulmonary disease with the use of spirometry may provide the added incentive for patients to avoid these risks, especially cigarette smoking. Because of the large reserve capacity of the lung, waiting for pulmonary symptoms delays diagnosis to a point at which serious lung damage is likely to be present. In a manner akin to the management of hypertension, regular spirometry can be used to diagnose acute airflow limitation and, with observation of trends (the rate of decline in the forced expiratory volume in one second), can be used to identify people with increased susceptibility to the disease. This approach should allow earlier diagnosis, lead to early intervention, and alter the long-term course. This is especially true of patients with hereditary predispositions, including alpha <sub>1 </sub> \\-antitrypsin deficiency, in whom overt risk factors may not be evident and the diagnosis may be missed or delayed without screening spirometry. Furthermore, spirometry adds little to the cost of an evaluation, and plays an essential part in management once the disease is identified and treatment is initiated.\n\n【30】In response to Dr. Chinet, the information provided in Table 2 of our review was gleaned from a literature search and compiled from several reviews of the pharmacotherapy of chronic obstructive pulmonary disease, which typically do not include pirbuterol  ; a recent pharmacologic review of pirbuterol  ; and an original investigation of the pharmacology of inhaled pirbuterol  . We have tried not to emphasize the use of one beta-agonist over another, but we believe these references support the data in the table.\n\n【31】In response to Drs. Kinshuck and Malik, we agree that pulmonary medications can affect the eye. Although they may be uncommon, it is important to be aware of the potential side effects of any medication.\n\n【32】Finally, Dr. Mulleneisen is correct. In converting micrograms to milligrams, we dropped a zero; the correct dose of ipratropium is 18 μg, or 0.018 mg, per puff.\n\n【33】Gary T. Ferguson, M.D.  \nReuben M. Cherniack, M.D.  \nNational Jewish Center for Immunology and Respiratory Medicine, Denver, CO 80206\n\n【34】3 References\n\n【35】1.  1\\. American Thoracic Society. Standards for the diagnosis and care of patients with chronic obstructive pulmonary disease (COPD) and asthma. Am Rev Respir Dis 1987 ;136: 225 \\- 244\n\n【36】    *   Crossref . opens in new tab\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n2.  2\\. Richards DM, Brogden RN. Pirbuterol: a preliminary review of its pharmacological properties and therapeutic efficacy in reversible bronchospastic disease. Drugs 1985 ;30: 6 \\- 21\n\n【37】    *   Crossref . opens in new tab\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n3.  3\\. Littner MR, Tashkin DP, Calvarese B, Bautista M. Acute bronchial and cardiovascular effects of increasing doses of pirbuterol acetate aerosol in asthma. Ann Allergy 1982 ;48: 14 \\- 20\n\n【38】    *   Medline . opens in new tab\nGoogle Scholar . opens in new tab", "index": 59, "show": true, "start": 59, "end": 75, "province": ["文本干净度", "无关文本"], "isEdit": false}, {"text": "【11】Thierry C. Chinet, M.D.\n\nUniversity of Paris, 92104 Boulogne, France\n\n【12】4 References\n\n【13】1.  1. Moore PF, Constantine JW, Barth WE. Pirbuterol, a selective beta2 adrenergic bronchodilator. J Pharmacol Exp Ther 1978 ;207: 410 - 418\n\n【14】    *   Web of Science . opens in new tab\n\nMedline . opens in new tab\nGoogle Scholar . opens in new tab\n2. Windom H, Grainger J, Burgess C, Crane J, Pearce N, Beasley R. A comparison of the haemodynamic and hypokalaemic effects of inhaled pirbuterol and salbutamol. N Z Med J 1990 ;103: 259 - 261\n【15】    *   Web of Science . opens in new tab\n\nMedline . opens in new tab\nGoogle Scholar . opens in new tab\n3. Beumer HM. Pirbuterol aerosol versus salbutamol and placebo aerosols in bronchial asthma. Drugs Exp Clin Res 1980 ;2: 77 - 83\n【16】    Google Scholar . opens in new tab\n\n4.  4. Pitts NE, Borger AP, Ghaly MS, Salsburg DS, Gans DJ. Pirbuterol – a new selective beta-agonist. Proc R Soc Med 1983 ;56: 1 - 31\n\n【17】    Google Scholar . opens in new tab", "content": "【0】Management of Chronic Obstructive Pulmonary Disease\n*   <mark>Related Articles</mark>\n\n【1】To the Editor\n-------------\n\n【2】In their review of the management of chronic obstructive pulmonary disease (April 8 issue),  Ferguson and Cherniack state, “All persons who are at risk \\[for the disease\\] should be evaluated for airflow limitation with the use of spirometry\\.\\[S\\]pirometry should be a part of routine examinations, since it provides valuable information on changes in lung function over time.” Why was such a definitive comment made?\n\n【3】Before routine diagnostic testing is recommended, there should be some indication of how the results will alter management. Since the risk factors for chronic obstructive pulmonary disease (i.e., smoking or occupational exposure) should in any event be avoided, why perform this test routinely, adding to the cost without providing a comparable increase in benefit?\n\n<mark>【4】Robert Matz, M.D.\n\nMount Sinai Medical Center, New York, NY 10029\n\n【5】1 Reference\n\n【6】1.  1. Ferguson GT, Cherniack RM. Management of chronic obstructive pulmonary disease. N Engl J Med 1993 ;328: 1017 - 1022\n\n【7】    *   Full Text\n\nWeb of Science . opens in new tab\nMedline . opens in new tab\nGoogle Scholar . opens in new tab</mark>in new tab\n\n【8】To the Editor\n-------------\n\n【9】In their recent review of the management of chronic obstructive pulmonary disease, Ferguson and Cherniack state in Table 2 that pirbuterol, a beta <sub>2 </sub> \\-agonist, is less beta <sub>2 </sub> \\-selective and has a shorter duration of action than albuterol. This conclusion is not supported by published data  .\n\n【10】In 12 patients with asthma, the improvement in the forced expiratory volume in one second after the administration of two puffs of pirbuterol (400 μg) or albuterol (200 μg) was similar  . Double-blind comparisons of inhaled pirbuterol with placebo established that pirbuterol has a median duration of action of more than five hours  . In five crossover studies comparing the functional effects of inhaled albuterol and pirbuterol for four hours after the administration of each drug, 80.8 percent of patients were still responding to pirbuterol after four hours, whereas only 67.3 percent were responding to albuterol. The magnitude of the response at four hours was higher in the patients still responding to pirbuterol than in the patients still responding to albuterol  . These data indicate that pirbuterol has a duration of action that equals or exceeds that of albuterol.\n\n【11】Thierry C. Chinet, M.D.  \nUniversity of Paris, 92104 Boulogne, France\n\n【12】4 References\n\n【13】1.  1\\. Moore PF, Constantine JW, Barth WE. Pirbuterol, a selective beta2 adrenergic bronchodilator. J Pharmacol Exp Ther 1978 ;207: 410 \\- 418\n\n【14】    *   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n2.  2\\. Windom H, Grainger J, Burgess C, Crane J, Pearce N, Beasley R. A comparison of the haemodynamic and hypokalaemic effects of inhaled pirbuterol and salbutamol. N Z Med J 1990 ;103: 259 \\- 261\n\n【15】    *   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n3.  3\\. Beumer HM. Pirbuterol aerosol versus salbutamol and placebo aerosols in bronchial asthma. Drugs Exp Clin Res 1980 ;2: 77 \\- 83\n\n【16】    Google Scholar . opens in new tab\n4.  4\\. Pitts NE, Borger AP, Ghaly MS, Salsburg DS, Gans DJ. Pirbuterol -- a new selective beta-agonist. Proc R Soc Med 1983 ;56: 1 \\- 31\n\n【17】    Google Scholar . opens in new tab\n\n【18】To the Editor\n-------------\n\n【19】We would like to add something from the ophthalmologist's point of view to the review by Ferguson and Cherniack. We have seen several patients in whom acute angle-closure glaucoma developed soon after treatment with an ipratropium inhaler was begun. Patients prescribed this drug or an equivalent agent should be warned to seek treatment if a red eye or misty vision develops. Such patients usually also have a headache and a fixed (or sluggish), semidilated pupil. The condition may occur in both eyes simultaneously.  In addition, airways disease may develop in a patient undergoing long-term treatment with topical beta-blockers for glaucoma. The patient's physician may not be aware that the patient is using eyedrops, and the ophthalmologist may be unaware of the airways disease.\n\n【20】David Kinshuck, M.B., B.S., F.C.Ophth.  \nTahira Malik, M.B., Ch.B.  \nWolverhampton Eye Infirmary, Wolverhampton WV3 9QR, United Kingdom\n\n【21】1 Reference\n\n【22】1.  1\\. Shah P, Dhurjon L, Metcalfe T, Gibson JM. Acute angle closure glaucoma associated with nebulised ipratropium bromide and salbutamol. BMJ 1992 ;304: 40 \\- 41\n\n【23】    *   Crossref . opens in new tab\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n\n【24】To the Editor\n-------------\n\n【25】I believe that there is a mistake in the dose of ipratropium in Table 2 of the review by Ferguson and Cherniack. The dose should be 0.02 mg per puff, or perhaps 0.018 mg per puff if one is using the American preparation. The dose of 0.18 mg per puff is an error.\n\n【26】Norbert K. Mulleneisen, M.D.  \nKlinikum Leverkusen, 51304 Leverkusen, Germany\n\n【27】Response\n--------\n\n【28】The authors reply:\n\n【29】_To the Editor:_ We disagree with Dr. Matz. Clearly, avoidance of risk factors is important, yet many patients do not heed this warning. Early identification of chronic obstructive pulmonary disease with the use of spirometry may provide the added incentive for patients to avoid these risks, especially cigarette smoking. Because of the large reserve capacity of the lung, waiting for pulmonary symptoms delays diagnosis to a point at which serious lung damage is likely to be present. In a manner akin to the management of hypertension, regular spirometry can be used to diagnose acute airflow limitation and, with observation of trends (the rate of decline in the forced expiratory volume in one second), can be used to identify people with increased susceptibility to the disease. This approach should allow earlier diagnosis, lead to early intervention, and alter the long-term course. This is especially true of patients with hereditary predispositions, including alpha <sub>1 </sub> \\-antitrypsin deficiency, in whom overt risk factors may not be evident and the diagnosis may be missed or delayed without screening spirometry. Furthermore, spirometry adds little to the cost of an evaluation, and plays an essential part in management once the disease is identified and treatment is initiated.\n\n【30】In response to Dr. Chinet, the information provided in Table 2 of our review was gleaned from a literature search and compiled from several reviews of the pharmacotherapy of chronic obstructive pulmonary disease, which typically do not include pirbuterol  ; a recent pharmacologic review of pirbuterol  ; and an original investigation of the pharmacology of inhaled pirbuterol  . We have tried not to emphasize the use of one beta-agonist over another, but we believe these references support the data in the table.\n\n【31】In response to Drs. Kinshuck and Malik, we agree that pulmonary medications can affect the eye. Although they may be uncommon, it is important to be aware of the potential side effects of any medication.\n\n【32】Finally, Dr. Mulleneisen is correct. In converting micrograms to milligrams, we dropped a zero; the correct dose of ipratropium is 18 μg, or 0.018 mg, per puff.\n\n【33】Gary T. Ferguson, M.D.  \nReuben M. Cherniack, M.D.  \nNational Jewish Center for Immunology and Respiratory Medicine, Denver, CO 80206\n\n【34】3 References\n\n【35】1.  1\\. American Thoracic Society. Standards for the diagnosis and care of patients with chronic obstructive pulmonary disease (COPD) and asthma. Am Rev Respir Dis 1987 ;136: 225 \\- 244\n\n【36】    *   Crossref . opens in new tab\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n2.  2\\. Richards DM, Brogden RN. Pirbuterol: a preliminary review of its pharmacological properties and therapeutic efficacy in reversible bronchospastic disease. Drugs 1985 ;30: 6 \\- 21\n\n【37】    *   Crossref . opens in new tab\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n3.  3\\. Littner MR, Tashkin DP, Calvarese B, Bautista M. Acute bronchial and cardiovascular effects of increasing doses of pirbuterol acetate aerosol in asthma. Ann Allergy 1982 ;48: 14 \\- 20\n\n【38】    *   Medline . opens in new tab\nGoogle Scholar . opens in new tab", "index": 2506, "show": true, "start": 2480, "end": 3477, "province": ["文本干净度", "无关文本"], "isEdit": false}, {"text": "【20】David Kinshuck, M.B., B.S., F.C.Ophth.\n\nTahira Malik, M.B., Ch.B.\n\nWolverhampton Eye Infirmary, Wolverhampton WV3 9QR, United Kingdom\n\n【21】1 Reference\n\n【22】1.  1. Shah P, Dhurjon L, Metcalfe T, Gibson JM. Acute angle closure glaucoma associated with nebulised ipratropium bromide and salbutamol. BMJ 1992 ;304: 40 - 41\n\n【23】    *   Crossref . opens in new tab\n\nWeb of Science . opens in new tab\nMedline . opens in new tab\nGoogle Scholar . opens in new tab", "content": "【0】Management of Chronic Obstructive Pulmonary Disease\n*   <mark>Related Articles</mark>\n\n【1】To the Editor\n-------------\n\n【2】In their review of the management of chronic obstructive pulmonary disease (April 8 issue),  Ferguson and Cherniack state, “All persons who are at risk \\[for the disease\\] should be evaluated for airflow limitation with the use of spirometry\\.\\[S\\]pirometry should be a part of routine examinations, since it provides valuable information on changes in lung function over time.” Why was such a definitive comment made?\n\n【3】Before routine diagnostic testing is recommended, there should be some indication of how the results will alter management. Since the risk factors for chronic obstructive pulmonary disease (i.e., smoking or occupational exposure) should in any event be avoided, why perform this test routinely, adding to the cost without providing a comparable increase in benefit?\n\n<mark>【4】Robert Matz, M.D.\n\nMount Sinai Medical Center, New York, NY 10029\n\n【5】1 Reference\n\n【6】1.  1. Ferguson GT, Cherniack RM. Management of chronic obstructive pulmonary disease. N Engl J Med 1993 ;328: 1017 - 1022\n\n【7】    *   Full Text\n\nWeb of Science . opens in new tab\nMedline . opens in new tab\nGoogle Scholar . opens in new tab</mark>in new tab\n\n【8】To the Editor\n-------------\n\n【9】In their recent review of the management of chronic obstructive pulmonary disease, Ferguson and Cherniack state in Table 2 that pirbuterol, a beta <sub>2 </sub> \\-agonist, is less beta <sub>2 </sub> \\-selective and has a shorter duration of action than albuterol. This conclusion is not supported by published data  .\n\n【10】In 12 patients with asthma, the improvement in the forced expiratory volume in one second after the administration of two puffs of pirbuterol (400 μg) or albuterol (200 μg) was similar  . Double-blind comparisons of inhaled pirbuterol with placebo established that pirbuterol has a median duration of action of more than five hours  . In five crossover studies comparing the functional effects of inhaled albuterol and pirbuterol for four hours after the administration of each drug, 80.8 percent of patients were still responding to pirbuterol after four hours, whereas only 67.3 percent were responding to albuterol. The magnitude of the response at four hours was higher in the patients still responding to pirbuterol than in the patients still responding to albuterol  . These data indicate that pirbuterol has a duration of action that equals or exceeds that of albuterol.\n\n<mark>【11】Thierry C. Chinet, M.D.\n\nUniversity of Paris, 92104 Boulogne, France\n\n【12】4 References\n\n【13】1.  1. Moore PF, Constantine JW, Barth WE. Pirbuterol, a selective beta2 adrenergic bronchodilator. J Pharmacol Exp Ther 1978 ;207: 410 - 418\n\n【14】    *   Web of Science . opens in new tab\n\nMedline . opens in new tab\nGoogle Scholar . opens in new tab\n2. Windom H, Grainger J, Burgess C, Crane J, Pearce N, Beasley R. A comparison of the haemodynamic and hypokalaemic effects of inhaled pirbuterol and salbutamol. N Z Med J 1990 ;103: 259 - 261\n【15】    *   Web of Science . opens in new tab\n\nMedline . opens in new tab\nGoogle Scholar . opens in new tab\n3. Beumer HM. Pirbuterol aerosol versus salbutamol and placebo aerosols in bronchial asthma. Drugs Exp Clin Res 1980 ;2: 77 - 83\n【16】    Google Scholar . opens in new tab\n\n4.  4. Pitts NE, Borger AP, Ghaly MS, Salsburg DS, Gans DJ. Pirbuterol – a new selective beta-agonist. Proc R Soc Med 1983 ;56: 1 - 31\n\n【17】    Google Scholar . opens in new tab</mark>cholar . opens in new tab\n\n【18】To the Editor\n-------------\n\n【19】We would like to add something from the ophthalmologist's point of view to the review by Ferguson and Cherniack. We have seen several patients in whom acute angle-closure glaucoma developed soon after treatment with an ipratropium inhaler was begun. Patients prescribed this drug or an equivalent agent should be warned to seek treatment if a red eye or misty vision develops. Such patients usually also have a headache and a fixed (or sluggish), semidilated pupil. The condition may occur in both eyes simultaneously.  In addition, airways disease may develop in a patient undergoing long-term treatment with topical beta-blockers for glaucoma. The patient's physician may not be aware that the patient is using eyedrops, and the ophthalmologist may be unaware of the airways disease.\n\n【20】David Kinshuck, M.B., B.S., F.C.Ophth.  \nTahira Malik, M.B., Ch.B.  \nWolverhampton Eye Infirmary, Wolverhampton WV3 9QR, United Kingdom\n\n【21】1 Reference\n\n【22】1.  1\\. Shah P, Dhurjon L, Metcalfe T, Gibson JM. Acute angle closure glaucoma associated with nebulised ipratropium bromide and salbutamol. BMJ 1992 ;304: 40 \\- 41\n\n【23】    *   Crossref . opens in new tab\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n\n【24】To the Editor\n-------------\n\n【25】I believe that there is a mistake in the dose of ipratropium in Table 2 of the review by Ferguson and Cherniack. The dose should be 0.02 mg per puff, or perhaps 0.018 mg per puff if one is using the American preparation. The dose of 0.18 mg per puff is an error.\n\n【26】Norbert K. Mulleneisen, M.D.  \nKlinikum Leverkusen, 51304 Leverkusen, Germany\n\n【27】Response\n--------\n\n【28】The authors reply:\n\n【29】_To the Editor:_ We disagree with Dr. Matz. Clearly, avoidance of risk factors is important, yet many patients do not heed this warning. Early identification of chronic obstructive pulmonary disease with the use of spirometry may provide the added incentive for patients to avoid these risks, especially cigarette smoking. Because of the large reserve capacity of the lung, waiting for pulmonary symptoms delays diagnosis to a point at which serious lung damage is likely to be present. In a manner akin to the management of hypertension, regular spirometry can be used to diagnose acute airflow limitation and, with observation of trends (the rate of decline in the forced expiratory volume in one second), can be used to identify people with increased susceptibility to the disease. This approach should allow earlier diagnosis, lead to early intervention, and alter the long-term course. This is especially true of patients with hereditary predispositions, including alpha <sub>1 </sub> \\-antitrypsin deficiency, in whom overt risk factors may not be evident and the diagnosis may be missed or delayed without screening spirometry. Furthermore, spirometry adds little to the cost of an evaluation, and plays an essential part in management once the disease is identified and treatment is initiated.\n\n【30】In response to Dr. Chinet, the information provided in Table 2 of our review was gleaned from a literature search and compiled from several reviews of the pharmacotherapy of chronic obstructive pulmonary disease, which typically do not include pirbuterol  ; a recent pharmacologic review of pirbuterol  ; and an original investigation of the pharmacology of inhaled pirbuterol  . We have tried not to emphasize the use of one beta-agonist over another, but we believe these references support the data in the table.\n\n【31】In response to Drs. Kinshuck and Malik, we agree that pulmonary medications can affect the eye. Although they may be uncommon, it is important to be aware of the potential side effects of any medication.\n\n【32】Finally, Dr. Mulleneisen is correct. In converting micrograms to milligrams, we dropped a zero; the correct dose of ipratropium is 18 μg, or 0.018 mg, per puff.\n\n【33】Gary T. Ferguson, M.D.  \nReuben M. Cherniack, M.D.  \nNational Jewish Center for Immunology and Respiratory Medicine, Denver, CO 80206\n\n【34】3 References\n\n【35】1.  1\\. American Thoracic Society. Standards for the diagnosis and care of patients with chronic obstructive pulmonary disease (COPD) and asthma. Am Rev Respir Dis 1987 ;136: 225 \\- 244\n\n【36】    *   Crossref . opens in new tab\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n2.  2\\. Richards DM, Brogden RN. Pirbuterol: a preliminary review of its pharmacological properties and therapeutic efficacy in reversible bronchospastic disease. Drugs 1985 ;30: 6 \\- 21\n\n【37】    *   Crossref . opens in new tab\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n3.  3\\. Littner MR, Tashkin DP, Calvarese B, Bautista M. Acute bronchial and cardiovascular effects of increasing doses of pirbuterol acetate aerosol in asthma. Ann Allergy 1982 ;48: 14 \\- 20\n\n【38】    *   Medline . opens in new tab\nGoogle Scholar . opens in new tab", "index": 4367, "show": true, "start": 4328, "end": 4787, "province": ["文本干净度", "无关文本"], "isEdit": false}, {"text": "【26】Norbert K. Mulleneisen, M.D.\n\nKlinikum Leverkusen, 51304 Leverkusen, Germany\n\n【27】Response\n【28】The authors reply:", "content": "【0】Management of Chronic Obstructive Pulmonary Disease\n*   <mark>Related Articles</mark>\n\n【1】To the Editor\n-------------\n\n【2】In their review of the management of chronic obstructive pulmonary disease (April 8 issue),  Ferguson and Cherniack state, “All persons who are at risk \\[for the disease\\] should be evaluated for airflow limitation with the use of spirometry\\.\\[S\\]pirometry should be a part of routine examinations, since it provides valuable information on changes in lung function over time.” Why was such a definitive comment made?\n\n【3】Before routine diagnostic testing is recommended, there should be some indication of how the results will alter management. Since the risk factors for chronic obstructive pulmonary disease (i.e., smoking or occupational exposure) should in any event be avoided, why perform this test routinely, adding to the cost without providing a comparable increase in benefit?\n\n<mark>【4】Robert Matz, M.D.\n\nMount Sinai Medical Center, New York, NY 10029\n\n【5】1 Reference\n\n【6】1.  1. Ferguson GT, Cherniack RM. Management of chronic obstructive pulmonary disease. N Engl J Med 1993 ;328: 1017 - 1022\n\n【7】    *   Full Text\n\nWeb of Science . opens in new tab\nMedline . opens in new tab\nGoogle Scholar . opens in new tab</mark>in new tab\n\n【8】To the Editor\n-------------\n\n【9】In their recent review of the management of chronic obstructive pulmonary disease, Ferguson and Cherniack state in Table 2 that pirbuterol, a beta <sub>2 </sub> \\-agonist, is less beta <sub>2 </sub> \\-selective and has a shorter duration of action than albuterol. This conclusion is not supported by published data  .\n\n【10】In 12 patients with asthma, the improvement in the forced expiratory volume in one second after the administration of two puffs of pirbuterol (400 μg) or albuterol (200 μg) was similar  . Double-blind comparisons of inhaled pirbuterol with placebo established that pirbuterol has a median duration of action of more than five hours  . In five crossover studies comparing the functional effects of inhaled albuterol and pirbuterol for four hours after the administration of each drug, 80.8 percent of patients were still responding to pirbuterol after four hours, whereas only 67.3 percent were responding to albuterol. The magnitude of the response at four hours was higher in the patients still responding to pirbuterol than in the patients still responding to albuterol  . These data indicate that pirbuterol has a duration of action that equals or exceeds that of albuterol.\n\n<mark>【11】Thierry C. Chinet, M.D.\n\nUniversity of Paris, 92104 Boulogne, France\n\n【12】4 References\n\n【13】1.  1. Moore PF, Constantine JW, Barth WE. Pirbuterol, a selective beta2 adrenergic bronchodilator. J Pharmacol Exp Ther 1978 ;207: 410 - 418\n\n【14】    *   Web of Science . opens in new tab\n\nMedline . opens in new tab\nGoogle Scholar . opens in new tab\n2. Windom H, Grainger J, Burgess C, Crane J, Pearce N, Beasley R. A comparison of the haemodynamic and hypokalaemic effects of inhaled pirbuterol and salbutamol. N Z Med J 1990 ;103: 259 - 261\n【15】    *   Web of Science . opens in new tab\n\nMedline . opens in new tab\nGoogle Scholar . opens in new tab\n3. Beumer HM. Pirbuterol aerosol versus salbutamol and placebo aerosols in bronchial asthma. Drugs Exp Clin Res 1980 ;2: 77 - 83\n【16】    Google Scholar . opens in new tab\n\n4.  4. Pitts NE, Borger AP, Ghaly MS, Salsburg DS, Gans DJ. Pirbuterol – a new selective beta-agonist. Proc R Soc Med 1983 ;56: 1 - 31\n\n【17】    Google Scholar . opens in new tab</mark>cholar . opens in new tab\n\n【18】To the Editor\n-------------\n\n【19】We would like to add something from the ophthalmologist's point of view to the review by Ferguson and Cherniack. We have seen several patients in whom acute angle-closure glaucoma developed soon after treatment with an ipratropium inhaler was begun. Patients prescribed this drug or an equivalent agent should be warned to seek treatment if a red eye or misty vision develops. Such patients usually also have a headache and a fixed (or sluggish), semidilated pupil. The condition may occur in both eyes simultaneously.  In addition, airways disease may develop in a patient undergoing long-term treatment with topical beta-blockers for glaucoma. The patient's physician may not be aware that the patient is using eyedrops, and the ophthalmologist may be unaware of the airways disease.\n\n<mark>【20】David Kinshuck, M.B., B.S., F.C.Ophth.\n\nTahira Malik, M.B., Ch.B.\n\nWolverhampton Eye Infirmary, Wolverhampton WV3 9QR, United Kingdom\n\n【21】1 Reference\n\n【22】1.  1. Shah P, Dhurjon L, Metcalfe T, Gibson JM. Acute angle closure glaucoma associated with nebulised ipratropium bromide and salbutamol. BMJ 1992 ;304: 40 - 41\n\n【23】    *   Crossref . opens in new tab\n\nWeb of Science . opens in new tab\nMedline . opens in new tab\nGoogle Scholar . opens in new tab</mark> in new tab\n\n【24】To the Editor\n-------------\n\n【25】I believe that there is a mistake in the dose of ipratropium in Table 2 of the review by Ferguson and Cherniack. The dose should be 0.02 mg per puff, or perhaps 0.018 mg per puff if one is using the American preparation. The dose of 0.18 mg per puff is an error.\n\n【26】Norbert K. Mulleneisen, M.D.  \nKlinikum Leverkusen, 51304 Leverkusen, Germany\n\n【27】Response\n--------\n\n【28】The authors reply:\n\n【29】_To the Editor:_ We disagree with Dr. Matz. Clearly, avoidance of risk factors is important, yet many patients do not heed this warning. Early identification of chronic obstructive pulmonary disease with the use of spirometry may provide the added incentive for patients to avoid these risks, especially cigarette smoking. Because of the large reserve capacity of the lung, waiting for pulmonary symptoms delays diagnosis to a point at which serious lung damage is likely to be present. In a manner akin to the management of hypertension, regular spirometry can be used to diagnose acute airflow limitation and, with observation of trends (the rate of decline in the forced expiratory volume in one second), can be used to identify people with increased susceptibility to the disease. This approach should allow earlier diagnosis, lead to early intervention, and alter the long-term course. This is especially true of patients with hereditary predispositions, including alpha <sub>1 </sub> \\-antitrypsin deficiency, in whom overt risk factors may not be evident and the diagnosis may be missed or delayed without screening spirometry. Furthermore, spirometry adds little to the cost of an evaluation, and plays an essential part in management once the disease is identified and treatment is initiated.\n\n【30】In response to Dr. Chinet, the information provided in Table 2 of our review was gleaned from a literature search and compiled from several reviews of the pharmacotherapy of chronic obstructive pulmonary disease, which typically do not include pirbuterol  ; a recent pharmacologic review of pirbuterol  ; and an original investigation of the pharmacology of inhaled pirbuterol  . We have tried not to emphasize the use of one beta-agonist over another, but we believe these references support the data in the table.\n\n【31】In response to Drs. Kinshuck and Malik, we agree that pulmonary medications can affect the eye. Although they may be uncommon, it is important to be aware of the potential side effects of any medication.\n\n【32】Finally, Dr. Mulleneisen is correct. In converting micrograms to milligrams, we dropped a zero; the correct dose of ipratropium is 18 μg, or 0.018 mg, per puff.\n\n【33】Gary T. Ferguson, M.D.  \nReuben M. Cherniack, M.D.  \nNational Jewish Center for Immunology and Respiratory Medicine, Denver, CO 80206\n\n【34】3 References\n\n【35】1.  1\\. American Thoracic Society. Standards for the diagnosis and care of patients with chronic obstructive pulmonary disease (COPD) and asthma. Am Rev Respir Dis 1987 ;136: 225 \\- 244\n\n【36】    *   Crossref . opens in new tab\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n2.  2\\. Richards DM, Brogden RN. Pirbuterol: a preliminary review of its pharmacological properties and therapeutic efficacy in reversible bronchospastic disease. Drugs 1985 ;30: 6 \\- 21\n\n【37】    *   Crossref . opens in new tab\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n3.  3\\. Littner MR, Tashkin DP, Calvarese B, Bautista M. Acute bronchial and cardiovascular effects of increasing doses of pirbuterol acetate aerosol in asthma. Ann Allergy 1982 ;48: 14 \\- 20\n\n【38】    *   Medline . opens in new tab\nGoogle Scholar . opens in new tab", "index": 5153, "show": true, "start": 5101, "end": 5218, "province": ["文本干净度", "无关文本"], "isEdit": false}, {"text": "【33】Gary T. Ferguson, M.D.\n\nReuben M. Cherniack, M.D.\n\nNational Jewish Center for Immunology and Respiratory Medicine, Denver, CO 80206\n\n【34】3 References\n\n【35】1.  1. American Thoracic Society. Standards for the diagnosis and care of patients with chronic obstructive pulmonary disease (COPD) and asthma. Am Rev Respir Dis 1987 ;136: 225 - 244\n\n【36】    *   Crossref . opens in new tab\n\nWeb of Science . opens in new tab\nMedline . opens in new tab\nGoogle Scholar . opens in new tab\n2. Richards DM, Brogden RN. Pirbuterol: a preliminary review of its pharmacological properties and therapeutic efficacy in reversible bronchospastic disease. Drugs 1985 ;30: 6 - 21\n【37】    *   Crossref . opens in new tab\n\nWeb of Science . opens in new tab\nMedline . opens in new tab\nGoogle Scholar . opens in new tab\n3. Littner MR, Tashkin DP, Calvarese B, Bautista M. Acute bronchial and cardiovascular effects of increasing doses of pirbuterol acetate aerosol in asthma. Ann Allergy 1982 ;48: 14 - 20\n【38】    *   Medline . opens in new tab\n\nGoogle Scholar . opens in new tab", "content": "【0】Management of Chronic Obstructive Pulmonary Disease\n*   <mark>Related Articles</mark>\n\n【1】To the Editor\n-------------\n\n【2】In their review of the management of chronic obstructive pulmonary disease (April 8 issue),  Ferguson and Cherniack state, “All persons who are at risk \\[for the disease\\] should be evaluated for airflow limitation with the use of spirometry\\.\\[S\\]pirometry should be a part of routine examinations, since it provides valuable information on changes in lung function over time.” Why was such a definitive comment made?\n\n【3】Before routine diagnostic testing is recommended, there should be some indication of how the results will alter management. Since the risk factors for chronic obstructive pulmonary disease (i.e., smoking or occupational exposure) should in any event be avoided, why perform this test routinely, adding to the cost without providing a comparable increase in benefit?\n\n<mark>【4】Robert Matz, M.D.\n\nMount Sinai Medical Center, New York, NY 10029\n\n【5】1 Reference\n\n【6】1.  1. Ferguson GT, Cherniack RM. Management of chronic obstructive pulmonary disease. N Engl J Med 1993 ;328: 1017 - 1022\n\n【7】    *   Full Text\n\nWeb of Science . opens in new tab\nMedline . opens in new tab\nGoogle Scholar . opens in new tab</mark>in new tab\n\n【8】To the Editor\n-------------\n\n【9】In their recent review of the management of chronic obstructive pulmonary disease, Ferguson and Cherniack state in Table 2 that pirbuterol, a beta <sub>2 </sub> \\-agonist, is less beta <sub>2 </sub> \\-selective and has a shorter duration of action than albuterol. This conclusion is not supported by published data  .\n\n【10】In 12 patients with asthma, the improvement in the forced expiratory volume in one second after the administration of two puffs of pirbuterol (400 μg) or albuterol (200 μg) was similar  . Double-blind comparisons of inhaled pirbuterol with placebo established that pirbuterol has a median duration of action of more than five hours  . In five crossover studies comparing the functional effects of inhaled albuterol and pirbuterol for four hours after the administration of each drug, 80.8 percent of patients were still responding to pirbuterol after four hours, whereas only 67.3 percent were responding to albuterol. The magnitude of the response at four hours was higher in the patients still responding to pirbuterol than in the patients still responding to albuterol  . These data indicate that pirbuterol has a duration of action that equals or exceeds that of albuterol.\n\n<mark>【11】Thierry C. Chinet, M.D.\n\nUniversity of Paris, 92104 Boulogne, France\n\n【12】4 References\n\n【13】1.  1. Moore PF, Constantine JW, Barth WE. Pirbuterol, a selective beta2 adrenergic bronchodilator. J Pharmacol Exp Ther 1978 ;207: 410 - 418\n\n【14】    *   Web of Science . opens in new tab\n\nMedline . opens in new tab\nGoogle Scholar . opens in new tab\n2. Windom H, Grainger J, Burgess C, Crane J, Pearce N, Beasley R. A comparison of the haemodynamic and hypokalaemic effects of inhaled pirbuterol and salbutamol. N Z Med J 1990 ;103: 259 - 261\n【15】    *   Web of Science . opens in new tab\n\nMedline . opens in new tab\nGoogle Scholar . opens in new tab\n3. Beumer HM. Pirbuterol aerosol versus salbutamol and placebo aerosols in bronchial asthma. Drugs Exp Clin Res 1980 ;2: 77 - 83\n【16】    Google Scholar . opens in new tab\n\n4.  4. Pitts NE, Borger AP, Ghaly MS, Salsburg DS, Gans DJ. Pirbuterol – a new selective beta-agonist. Proc R Soc Med 1983 ;56: 1 - 31\n\n【17】    Google Scholar . opens in new tab</mark>cholar . opens in new tab\n\n【18】To the Editor\n-------------\n\n【19】We would like to add something from the ophthalmologist's point of view to the review by Ferguson and Cherniack. We have seen several patients in whom acute angle-closure glaucoma developed soon after treatment with an ipratropium inhaler was begun. Patients prescribed this drug or an equivalent agent should be warned to seek treatment if a red eye or misty vision develops. Such patients usually also have a headache and a fixed (or sluggish), semidilated pupil. The condition may occur in both eyes simultaneously.  In addition, airways disease may develop in a patient undergoing long-term treatment with topical beta-blockers for glaucoma. The patient's physician may not be aware that the patient is using eyedrops, and the ophthalmologist may be unaware of the airways disease.\n\n<mark>【20】David Kinshuck, M.B., B.S., F.C.Ophth.\n\nTahira Malik, M.B., Ch.B.\n\nWolverhampton Eye Infirmary, Wolverhampton WV3 9QR, United Kingdom\n\n【21】1 Reference\n\n【22】1.  1. Shah P, Dhurjon L, Metcalfe T, Gibson JM. Acute angle closure glaucoma associated with nebulised ipratropium bromide and salbutamol. BMJ 1992 ;304: 40 - 41\n\n【23】    *   Crossref . opens in new tab\n\nWeb of Science . opens in new tab\nMedline . opens in new tab\nGoogle Scholar . opens in new tab</mark> in new tab\n\n【24】To the Editor\n-------------\n\n【25】I believe that there is a mistake in the dose of ipratropium in Table 2 of the review by Ferguson and Cherniack. The dose should be 0.02 mg per puff, or perhaps 0.018 mg per puff if one is using the American preparation. The dose of 0.18 mg per puff is an error.\n\n<mark>【26】Norbert K. Mulleneisen, M.D.\n\nKlinikum Leverkusen, 51304 Leverkusen, Germany\n\n【27】Response\n【28】The authors reply:</mark>hors reply:\n\n【29】_To the Editor:_ We disagree with Dr. Matz. Clearly, avoidance of risk factors is important, yet many patients do not heed this warning. Early identification of chronic obstructive pulmonary disease with the use of spirometry may provide the added incentive for patients to avoid these risks, especially cigarette smoking. Because of the large reserve capacity of the lung, waiting for pulmonary symptoms delays diagnosis to a point at which serious lung damage is likely to be present. In a manner akin to the management of hypertension, regular spirometry can be used to diagnose acute airflow limitation and, with observation of trends (the rate of decline in the forced expiratory volume in one second), can be used to identify people with increased susceptibility to the disease. This approach should allow earlier diagnosis, lead to early intervention, and alter the long-term course. This is especially true of patients with hereditary predispositions, including alpha <sub>1 </sub> \\-antitrypsin deficiency, in whom overt risk factors may not be evident and the diagnosis may be missed or delayed without screening spirometry. Furthermore, spirometry adds little to the cost of an evaluation, and plays an essential part in management once the disease is identified and treatment is initiated.\n\n【30】In response to Dr. Chinet, the information provided in Table 2 of our review was gleaned from a literature search and compiled from several reviews of the pharmacotherapy of chronic obstructive pulmonary disease, which typically do not include pirbuterol  ; a recent pharmacologic review of pirbuterol  ; and an original investigation of the pharmacology of inhaled pirbuterol  . We have tried not to emphasize the use of one beta-agonist over another, but we believe these references support the data in the table.\n\n【31】In response to Drs. Kinshuck and Malik, we agree that pulmonary medications can affect the eye. Although they may be uncommon, it is important to be aware of the potential side effects of any medication.\n\n【32】Finally, Dr. Mulleneisen is correct. In converting micrograms to milligrams, we dropped a zero; the correct dose of ipratropium is 18 μg, or 0.018 mg, per puff.\n\n【33】Gary T. Ferguson, M.D.  \nReuben M. Cherniack, M.D.  \nNational Jewish Center for Immunology and Respiratory Medicine, Denver, CO 80206\n\n【34】3 References\n\n【35】1.  1\\. American Thoracic Society. Standards for the diagnosis and care of patients with chronic obstructive pulmonary disease (COPD) and asthma. Am Rev Respir Dis 1987 ;136: 225 \\- 244\n\n【36】    *   Crossref . opens in new tab\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n2.  2\\. Richards DM, Brogden RN. Pirbuterol: a preliminary review of its pharmacological properties and therapeutic efficacy in reversible bronchospastic disease. Drugs 1985 ;30: 6 \\- 21\n\n【37】    *   Crossref . opens in new tab\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n3.  3\\. Littner MR, Tashkin DP, Calvarese B, Bautista M. Acute bronchial and cardiovascular effects of increasing doses of pirbuterol acetate aerosol in asthma. Ann Allergy 1982 ;48: 14 \\- 20\n\n【38】    *   Medline . opens in new tab\nGoogle Scholar . opens in new tab", "index": 7499, "show": true, "start": 7434, "end": 8490, "province": ["文本干净度", "无关文本"], "isEdit": false}], "startTime": "2024/08/14 15:36:41", "endTime": "2024/08/14 15:38:46", "cost": 124.399}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 23:38:46", "grab_time": "2024-08-13 23:36:41"}
{"id": 2234381, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "66a75776-f5e3-4054-9bd5-f8873c106cba", "title": "Recurrences after Oral and Genital Herpes Simplex Virus Infection", "text": "【0】Recurrences after Oral and Genital Herpes Simplex Virus Infection\nAbstract\n--------\n\n【1】We prospectively followed 39 adults with concurrent primary herpes simplex virus (HSV) infection (12 with HSV type 1 and 27 with HSV type 2) of the oropharynx and genitalia, caused by the same virus in each person, to evaluate the influence of viral type (HSV-1 vs. HSV-2) and site of infection (oropharyngeal vs. genital) on the frequency of recurrence.\n\n【2】The subsequent recurrence patterns of HSV infection differed markedly according to viral type and anatomical site. Oral–labial recurrences developed in 5 of 12 patients with HSV-1 and 1 of 27 patients with HSV-2 (P<0.001). Conversely, genital recurrences developed in 24 of 27 patients with HSV-2 and 3 of 12 patients with HSV-1 (P<0.01). The mean rate of subsequent genital recurrences (due to HSV-1 and HSV-2) was 0.23 per month, whereas the mean rate of oral–labial recurrences was only 0.04 per month (P<0.001). The mean monthly frequencies of recurrence were, in order, genital HSV-2 infections, 0.33 per month; oral–labial HSV-1 infections, 0.12 per month; genital HSV-1 infections, 0.020 per month; and oral HSV-2 infections, 0.001 per month (P<0.01 for each comparison).\n\n【3】We conclude that the likelihood of reactivation of HSV infection differs between HSV-1 and HSV-2 infections and between the sacral and trigeminal anatomical sites. The six-fold more frequent clinical recurrence rate of genital HSV infections as compared with oral–labial HSV infections may account for the relatively rapid increase in the prevalence of clinically recognized genital herpes in recent years.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:26:43", "endTime": "2024/08/14 15:27:02", "cost": 19.51}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 23:27:02", "grab_time": "2024-08-13 23:26:43"}
{"id": 2234380, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "ed699fb0-6f7c-4cf4-a9a6-fc8d2b6cd1af", "title": "Abacterial and Bacterial Pyelonephritis — Immunofluorescent Localization of Bacterial Antigen", "text": "【0】Abacterial and Bacterial Pyelonephritis — Immunofluorescent Localization of Bacterial Antigen\nAbstract\n--------\n\n【1】Immunofluorescent detection of bacterial antigen in bacterial and \"abacterial\" pyelonephritis was evaluated with the use of antiserum against an antigen shared by most strains of enterobacteriaceae. Bacterial antigen could not be detected in renal specimens from 20 subjects without renal disease or in eight of nine specimens from patients with various forms of chronic renal disease other than pyelonephritis. Bacterial antigen was found in all six kidneys from patients with pyelonephritis caused by bacteria containing this common antigen. Bacteria and amorphous bacterial antigen were observed in the interstitial tissue, renal tubules, tubular epithelium, macrophages and blood-vessel walls in specimens from the latter patients.\n\n【2】Bacterial antigen was also detected in renal specimens from six of the seven patients with \"abacterial\" pyelonephritis, suggesting that remote asymptomatic renal infection had initiated their renal disease.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:04:54", "endTime": "2024/08/14 15:05:08", "cost": 14.18}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 23:05:08", "grab_time": "2024-08-13 23:04:53"}
{"id": 2234379, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "64ecce81-3e46-4acf-ab36-266a2b663e9c", "title": "Epidemic of Bilateral Optic Neuropathy in Dar es Salaam, Tanzania", "text": "【0】Epidemic of Bilateral Optic Neuropathy in Dar es Salaam, Tanzania\nTo the Editor:\n--------------\n\n【1】An epidemic of bilateral optic neuropathy, often with sensorineural hearing loss and symptoms of peripheral neuropathy, is affecting young adults in Dar es Salaam, Tanzania.  The disease is clinically identical to that seen in the recent epidemic of bilateral optic neuropathy in Cuba. \n\n【2】We conducted a community survey to determine the magnitude of the epidemic. We used stratified simple random sampling to select a sample of 1078 persons, 10 to 39 years old, in the 21 residential areas of Dar es Salaam (population, 3.8 million), of whom 927 (86.0 percent) were examined for signs of the disease. The disease predominantly affects persons between the ages of 10 and 39.\n\n【3】The fundi were examined by direct ophthalmoscopy with the use of standard tungsten and red-free illumination. Clinicians who had wide experience with the disease performed the examinations. The Tanzanian case definition requires each of the following to be present: visual acuity with pinhole correction of 20/30 or worse for both eyes, failure of at least 1 of 15 Ishihara color-vision test plates for both eyes, bilateral temporal pallor of the optic disks, and bilateral loss of cecocentral projections of the nerve fiber layer. \n\n【4】Table 1. Characteristics of 22 Patients with Bilateral Optic Neuropathy.\n\n【5】Twenty-two cases were identified (prevalence, 2.4 percent; 95 percent confidence interval, 1.7 to 3.0 percent) . Eight cases were found among the 392 males examined, and 14 among the 535 females examined. Breast-feeding was a strong risk factor. Seven cases were found among the 35 women who were breast-feeding (20.0 percent), as compared with six cases among the 375 women of reproductive age who were not breast-feeding (1.6 percent; prevalence ratio, 12.5; 95 percent confidence interval, 4.4 to 35.2).\n\n【6】On the basis of a prevalence of disease of 2.4 percent and the patterns of presentation at health clinics, we estimate that 40,000 persons are currently affected with optic neuropathy in Dar es Salaam. Not included in this estimate are people with isolated peripheral neuropathy, who seek care at primary health clinics with the same frequency as those with optic neuropathy (data not shown).\n\n【7】The cause of the epidemic is unknown. Cyanide intoxication from improperly processed cassava and tobacco smoking have been ruled out.  Mitochondrial-DNA analyses have not shown any common mutations associated with Leber's hereditary optic neuropathy.  Biochemical analyses show that acute cases are associated with deficiencies of several B-complex vitamins, although controls (persons without optic neuropathy) have identical deficiencies. Thus, the outbreak is occurring in a nutritionally deficient population. Further investigations are needed to determine the cause and to identify appropriate intervention and treatment strategies.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 18:15:45", "endTime": "2024/08/13 18:16:06", "cost": 21.597}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 02:16:07", "grab_time": "2024-08-13 02:15:45"}
{"id": 2234378, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "7b2607fd-0ccf-4bbe-9b98-2ef2db876f11", "title": "Mesenteric Lymphoid Hamartoma Associated with Chronic Hypoferremia, Anemia, Growth Failure and Hyperglobulinemia", "text": "【0】Mesenteric Lymphoid Hamartoma Associated with Chronic Hypoferremia, Anemia, Growth Failure and Hyperglobulinemia\nAbstract\n--------\n\n【1】A mesenteric lymphoid hamartoma was found in a 16-year-old boy associated with growth arrest, chronic hypochromic anemia and hypergammaglobulinemia. Radioisotope tracer scanning technics revealed the lesion. After removal of the tumor all three findings improved in a short time. No definitive immunologic or infectious cause was elucidated. The finding of a foreign-body granuloma in the tumor was noted, but the etiologic role could not be determined.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:09:01", "endTime": "2024/08/14 15:09:10", "cost": 8.432}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 23:09:10", "grab_time": "2024-08-13 23:09:01"}
{"id": 2234377, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "cb3f17f9-925b-4e08-8995-5bb128a2a3aa", "title": "Autologous Pancreatic Islet Transplantation for Severe Trauma", "text": "【0】Autologous Pancreatic Islet Transplantation for Severe Trauma\nTo the Editor:\n--------------\n\n【1】Autologous pancreatic islet transplantation has been successfully carried out after total pancreatectomy for chronic pancreatitis, and allogeneic islet-cell transplantation has had limited success.  We report a case of successful islet transplantation from the pancreas after total pancreatectomy because of trauma.\n\n【2】A 21-year-old airman serving in a remote part of Afghanistan was hit by three high-velocity bullets on November 21, 2009, and was rapidly transferred to Walter Reed Army Medical Center. As part of needed rescue surgery, a portion of the stomach, the gallbladder, the entire duodenum, and the head of the pancreas were removed. In addition, the patient required left hemicolectomy and resection of a portion of the small bowel.\n\n【3】During the attempt to reconstruct the intraabdominal structures, the remnant pancreas (weighing 63.5 g, approximately half the entire pancreas) was found to be damaged from the effects of the gunshot wounds and was leaking pancreatic enzymes and dissolving critical abdominal structures and blood vessels. We decided to remove the entire remaining pancreas to prevent further leakage, breakdown, and bleeding, which could be fatal. The pancreas was flushed with University of Wisconsin solution, packed in ice, and transported to the University of Miami. The islets (221,250 islet equivalents of 40% purity and 90% viability) were shipped back to Walter Reed, where by laparotomy they were injected back into the patient's main portal vein so as to seed in the liver. Portal pressures remained normal throughout the infusion.\n\n【4】Levels of C-peptide in basal and stimulated (after an oral glucose-tolerance test) conditions were 0.5 ng per milliliter with a glucose level of 80 mg per deciliter (fasting) and 3.9 ng per milliliter with a glucose level of 184 mg per deciliter (stimulated). As of postoperative day 114, the patient had normal islet function. Liver enzymes peaked on day 3 (800 IU for aspartate aminotransferase and 900 IU for alanine aminotransferase) and normalized on day 8. The patient was able to discontinue insulin on day 24. Initially, he required a small amount of insulin (1 to 2 units per hour) for total parenteral nutrition and 11 serial surgical procedures to close his abdomen. As of day 20, the patient was eating a normal diet.\n\n【5】In this patient, we were able to isolate and transplant insulin-producing cells after a severe trauma requiring complete removal of the pancreas. This procedure may prevent diabetes and secondary complications if even a small portion of pancreas can be salvaged. We also showed the feasibility of sending a pancreas to a remote location for islet isolation and purification and then transporting the islets back for successful infusion within 24 hours.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:46:08", "endTime": "2024/08/14 15:46:21", "cost": 12.651}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 23:46:21", "grab_time": "2024-08-13 23:46:08"}
{"id": 2234376, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "cbdf90b1-0252-42af-af9e-5cc98456d70b", "title": "Coitus and Associated Amniotic-Fluid Infections", "text": "【0】Coitus and Associated Amniotic-Fluid Infections\nAbstract\n--------\n\n【1】Data were analyzed from 26,886 pregnancies to determine whether coitus is involved in the genesis of amniotic-fluid infections. The frequency of infection was 156 per thousand births when mothers reported coitus once or more per week during the month before delivery, versus 117 per thousand when no coitus was reported (P<0.001). The percentage of infected infants who died was 11.0 when there was coitus versus 2.4 when there was no coitus (P<0.001). The frequencies of low Apgar scores, neonatal respiratory distress, and hyperbilirubinemia were about doubled when mothers reported coitus. The coitus-associated effects were greater in preterm than in full-term infants. The pregnancies in the study took place between 1959 and 1966, when national perinatal mortality rates were higher than they are now. Deaths from coitus-associated infections may be less frequent today.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:53:22", "endTime": "2024/08/14 14:53:42", "cost": 20.368}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 22:53:42", "grab_time": "2024-08-13 22:53:22"}
{"id": 2234375, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "d7309a8d-2160-4adb-ad49-474283c6ba48", "title": "Nonmetastatic, Castration-Resistant Prostate Cancer and Survival with Darolutamide", "text": "【0】Nonmetastatic, Castration-Resistant Prostate Cancer and Survival with Darolutamide\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Darolutamide is a structurally distinct androgen-receptor inhibitor that is approved for the treatment of nonmetastatic, castration-resistant prostate cancer. In the planned primary analysis of a phase 3 trial, the median metastasis-free survival was significantly longer with darolutamide (40.4 months) than with placebo (18.4 months). The data for the analysis of overall survival were immature at the time of the primary analysis.\n\n【3】Methods\n-------\n\n【4】In this double-blind, placebo-controlled trial, we randomly assigned 1509 men, in a  ratio, to receive darolutamide (955 patients) or placebo (554 patients) while they continued to receive androgen-deprivation therapy. After the results of the primary end-point analysis were found to be positive, unblinding of the treatment assignments occurred, and patients in the placebo group were permitted to cross over to receive open-label darolutamide treatment. At the time of this prespecified final analysis, which had been planned to be performed after approximately 240 deaths had occurred, overall survival and all other secondary end points were evaluated.\n\n【5】Results\n-------\n\n【6】The median follow-up time was 29.0 months. At the time of unblinding of the data, all 170 patients who were still receiving placebo crossed over to receive darolutamide; 137 patients who had discontinued placebo before unblinding had occurred received at least one other life-prolonging therapy. Overall survival at 3 years was 83% (95% confidence interval \\[CI\\], 80 to 86) in the darolutamide group and 77% (95% CI, 72 to 81) in the placebo group. The risk of death was significantly lower, by 31%, in the darolutamide group than in the placebo group (hazard ratio for death, 0.69; 95% CI, 0.53 to 0.88; P=0.003). Darolutamide was also associated with a significant benefit with respect to all other secondary end points, including the time to first symptomatic skeletal event and the time to first use of cytotoxic chemotherapy. The incidence of adverse events after the start of treatment was similar in the two groups; no new safety signals were observed.\n\n【7】Conclusions\n-----------\n\n【8】Among men with nonmetastatic, castration-resistant prostate cancer, the percentage of patients who were alive at 3 years was significantly higher among those who received darolutamide than among those who received placebo. The incidence of adverse events was similar in the two groups. \n\n【9】Introduction\n------------\n\n【10】 QUICK TAKE  \nDarolutamide for Nonmetastatic, Castration-Resistant Prostate Cancer  \n\n【11】Nonmetastatic, castration-resistant prostate cancer is defined by rising levels of serum prostate-specific antigen (PSA) and an absence of detectable metastases on conventional imaging in patients receiving androgen-deprivation therapy.  Patients with nonmetastatic, castration-resistant prostate cancer are at risk for progression to metastatic disease,  which is often accompanied by the onset of cancer-related symptoms in this previously asymptomatic population.  Prolonging survival and delaying the onset of cancer-related symptoms while minimizing treatment-related adverse events are key therapeutic goals in patients with nonmetastatic, castration-resistant prostate cancer. \n\n【12】Darolutamide, a structurally distinct androgen-receptor inhibitor, is approved for the treatment of nonmetastatic, castration-resistant prostate cancer  on the basis of the current trial — the phase 3 Androgen Receptor Antagonizing Agent for Metastasis-free Survival (ARAMIS) trial — in which the addition of darolutamide to ongoing androgen-deprivation therapy significantly prolonged median metastasis-free survival by 22 months.  As expected, the overall survival data were immature at the time of the primary analysis for metastasis-free survival, with the occurrence of only 136 deaths; the final analysis was planned to be performed after the occurrence of approximately 240 deaths. Nonetheless, the interim analysis for overall survival favored darolutamide over placebo (hazard ratio for death, 0.71; 95% confidence interval \\[CI\\], 0.50 to 0.99; P=0.045), although the prespecified significance level of 0.0002 was not reached.  Darolutamide was not associated with a higher incidence of adverse events that are known to be associated with other androgen-receptor inhibitors — including falls, seizures, cognitive disorders, mental impairment disorders, and hypertension — than placebo.  Quality of life was maintained for the duration of treatment.  We report here the results from the prespecified final analysis of overall survival, all other secondary end points, and long-term safety in the ARAMIS trial.\n\n【13】Methods\n-------\n\n【14】Trial Design and Conduct\n------------------------\n\n【15】The trial was sponsored by Bayer HealthCare and Orion Pharma. Both sponsors, together with the first and last authors, developed the trial design. The institutional review board at each participating institution approved the trial, which was conducted in compliance with the principles of the Declaration of Helsinki and in accordance with the International Conference on Harmonisation guidelines for Good Clinical Practice. All the patients provided written informed consent. Unblinded safety data were reviewed by an independent data and safety monitoring board throughout the trial.\n\n【16】The data were collected by the investigators, analyzed by statisticians who were employed by the sponsors, and interpreted by the authors, including employees of the sponsors. Bayer HealthCare provided funding for medical writing and editing assistance. The authors reviewed and approved the manuscript that was submitted for publication.\n\n【17】Patients\n--------\n\n【18】Full details of the trial inclusion and exclusion criteria have been reported previously.  In brief, men who had nonmetastatic, castration-resistant prostate cancer and a baseline PSA level of at least 2 ng per milliliter, a PSA doubling time of 10 months or less, and an Eastern Cooperative Oncology Group (ECOG) performance status score of 0 or 1 (scores range from 0 to 5, with higher scores indicating greater disability) were eligible for participation. Enrollment of patients who had a previous seizure disorder or a condition that conferred a predisposition to seizure was permitted.\n\n【19】Trial Design and Treatment Assignments\n--------------------------------------\n\n【20】Patients were randomly assigned, in a  ratio in a double-blind manner, to receive darolutamide at an oral dose of 600 mg twice daily with food or matched placebo while they continued to receive androgen-deprivation therapy. Randomization was stratified according to PSA doubling time (≤6 months vs. >6 months) and the use of osteoclast-targeted therapy at randomization (yes vs. no). Patients continued to take darolutamide or placebo until protocol-defined progression, discontinuation of the assigned treatment because of adverse events, start of another anticancer therapy, or withdrawal of consent. Unblinding of the treatment assignments occurred after the results from the primary analysis for metastasis-free survival were found to be positive, at which time patients in the placebo group were allowed to cross over to receive open-label darolutamide treatment or to receive other subsequent treatment at the discretion of the investigator .\n\n【21】Assessments\n-----------\n\n【22】Information on demographic characteristics, relevant medical history, and pertinent clinical conditions was obtained at the screening visit, as described previously.  Data were collected at 16-week intervals during the double-blind treatment period, at the start of the open-label treatment period, and every 16 weeks thereafter until the end of the trial. If metastatic progression was observed by the investigator, the trial treatment was discontinued, and the patient was followed every 16 weeks until death or the end of the trial. At the time of progression, treatment outside the trial protocol could be initiated at the discretion of the physician. Review of imaging results was performed both locally and by blinded independent central review during the double-blind period but was performed only locally during the open-label period. Assessment of laboratory values, including the PSA level, was performed centrally during both treatment periods. Data on adverse events that occurred after the start of treatment, including the type and severity  of the events, as well as whether they were assessed by the investigator as being related to the trial treatment, were recorded at each visit.\n\n【23】End Points\n----------\n\n【24】The results of the analysis of the primary end point, metastasis-free survival, have been reported previously.  Secondary end points evaluated at this final analysis included overall survival, the time to pain progression, the time to first use of cytotoxic chemotherapy, and the time to first symptomatic skeletal event. Pain progression was defined as either an increase of 2 or more points from baseline in the score assessed with the Brief Pain Inventory Short-Form questionnaire (a 10-point scale on which higher numbers reflect greater pain; minimum clinically important difference, 2 points) or initiation of opioid treatment for cancer pain, whichever occurred first. A symptomatic skeletal event was defined as external-beam radiation therapy to relieve skeletal symptoms, a new symptomatic pathologic bone fracture, the occurrence of spinal cord compression, or tumor-related orthopedic surgical intervention. Exploratory end points evaluated at this final analysis include the time to first prostate cancer–related invasive procedure and the time to initiation of subsequent antineoplastic therapy.\n\n【25】Statistical Analysis\n--------------------\n\n【26】The test for statistical significance of the final analysis was planned to be performed after approximately 240 deaths had occurred. Secondary end points were evaluated in a hierarchical order, with a two-sided significance level of 0.05 split between the primary analysis (0.0002) and the final analysis (0.0498) by a rho-family spending function with a parameter rho of 10; overall survival, the time to pain progression, the time to first use of cytotoxic chemotherapy, and the time to first symptomatic skeletal event were tested sequentially.\n\n【27】A stratified log-rank test with the same stratification factors as those used for randomization was used to compare the darolutamide and placebo groups. Kaplan–Meier curves, including median survival times and corresponding 95% confidence intervals, were constructed for all secondary and exploratory end points; hazard ratios were calculated in time-to-event analyses with the use of Cox proportional-hazards models. Prespecified subgroup analyses of overall survival were performed to determine the effect of demographic or baseline characteristics.\n\n【28】The statistical analysis and the generation of patient data listings were performed with the use of SAS software, version 9.2 (SAS Institute). Incomplete data on event occurrence dates were imputed as the earliest possible date.\n\n【29】Efficacy was evaluated in the intention-to-treat population, which comprised all patients who underwent randomization. Safety was evaluated in the safety population, which comprised all patients who underwent randomization and received at least one dose of darolutamide or placebo. Adverse events were assessed separately for the double-blind period and the open-label period. If the start date of an adverse event was missing, the adverse event was considered to have occurred during the double-blind period.\n\n【30】Results\n-------\n\n【31】Patients\n--------\n\n【32】Patients were enrolled from September 2014 through March 2018. The intention-to-treat population included 1509 patients (955 in the darolutamide group and 554 in the placebo group) . Demographic and clinical characteristics of the two groups were well balanced at baseline, as reported previously.  In addition, the primary analysis of metastasis-free survival showed that, among the patients who had metastatic progression, the distribution of sites of metastases was similar in the darolutamide and placebo groups .\n\n【33】Table 1. Life-Prolonging Therapy in the Intention-to-Treat Population.\n\n【34】The data cutoff for the primary analysis was September 3, 2018, and the unblinding of the treatment assignments occurred on November 30, 2018 . At the time of unblinding, all 170 patients who were still receiving placebo crossed over to receive open-label darolutamide (crossover group) . The data cutoff for the final analysis of overall survival was November 15, 2019; the median follow-up time was 29.0 months for the overall trial population, 11.2 additional months after the primary analysis of metastasis-free survival. At the time of data cutoff, 49% of the patients who had been originally assigned to receive darolutamide were still receiving darolutamide, and 86% of the patients in the crossover group were still receiving darolutamide . The median duration of exposure in the darolutamide group was 25.8 months during the combined double-blind and open-label periods. In the placebo group, the median duration of exposure during the double-blind period was 11.6 months. Patients who crossed over to receive open-label darolutamide had a median duration of exposure to darolutamide of 11.0 months.\n\n【35】Subsequent Therapy\n------------------\n\n【36】In the placebo group, 307 of the 554 patients (55%) received subsequent treatment with darolutamide or other life-prolonging therapy . Among the 384 patients randomly assigned to the placebo group who had discontinued placebo before unblinding of the data had occurred, 137 received a subsequent life-prolonging therapy other than darolutamide. The most commonly used subsequent life-prolonging therapies were docetaxel, abiraterone acetate, and enzalutamide. In the darolutamide group, 141 of the 955 patients (15%) received subsequent life-prolonging therapy other than darolutamide.\n\n【37】Overall Survival\n----------------\n\n【38】Table 2. Secondary and Exploratory End Points at 3 Years in the Intention-to-Treat Population. Figure 1.  Figure 1. Kaplan–Meier Estimates of Overall Survival.\n\n【39】The final analysis of overall survival was performed after 254 deaths (148 \\[15%\\] in the darolutamide group and 106 \\[19%\\] in the placebo group) had occurred. The percentage of patients who were alive at 3 years was 83% (95% CI, 80 to 86) in the darolutamide group and 77% (95% CI, 72 to 81) in the placebo group. The risk of death was significantly lower, by 31%, in the darolutamide group than in the placebo group (hazard ratio for death, 0.69; 95% CI, 0.53 to 0.88; P=0.003) . In both treatment groups, the number of prostate cancer–related deaths was higher than the number of deaths from any other cause (80 of 149 deaths in the darolutamide group and 56 of 106 deaths in the placebo group) , and the majority of those deaths occurred after discontinuation of treatment. However, the trial was not powered to assess the treatment effect of darolutamide on deaths due to prostate cancer. The treatment effect on overall survival consistently favored darolutamide over placebo in prespecified subgroups, including those defined according to baseline PSA doubling time of 6 months or less or more than 6 months, geographic region, presence or absence of lymph-node involvement at baseline, and baseline ECOG performance status score of 0 or 1 (although the confidence intervals in some subgroups with a smaller sample size crossed 1.00) .\n\n【40】Other Secondary and Exploratory End Points\n------------------------------------------\n\n【41】Figure 2. Kaplan–Meier Estimates of Time to First Use of Cytotoxic Chemotherapy and Time to First Symptomatic Skeletal Event.\n\n【42】Because statistical significance for overall survival was achieved, the time to pain progression, the time to first use of cytotoxic chemotherapy, and the time to first symptomatic skeletal event were evaluated hierarchically in this sequence. The time to pain progression was evaluated with the use of data from the primary analysis cutoff date of September 3, 2018, since no additional data were collected for this end point beyond that time; the analysis showed a significantly longer time to pain progression in the darolutamide group than in the placebo group (median, 40.3 months vs. 25.4 months; hazard ratio, 0.65; 95% CI, 0.53 to 0.79; P<0.001). At 3 years, the percentage of patients who had not yet received their first cytotoxic chemotherapy was 83% in the darolutamide group and 75% in the placebo group. Darolutamide was associated with a significantly longer time to first use of cytotoxic chemotherapy than placebo (hazard ratio, 0.58; 95% CI, 0.44 to 0.76; P<0.001) . At 3 years, the percentage of patients who had not had a first symptomatic skeletal event was 96% in the darolutamide group and 92% in the placebo group. Darolutamide was associated with a significantly longer time to first symptomatic skeletal event (hazard ratio, 0.48; 95% CI, 0.29 to 0.82; P=0.005) than placebo .\n\n【43】The results of the exploratory end points evaluated at this analysis also favored darolutamide over placebo . Treatment with darolutamide resulted in a longer time to disease progression and a longer time to additional treatment (i.e., prostate cancer–related invasive procedures and subsequent antineoplastic therapy).\n\n【44】Safety\n------\n\n【45】Overall, adverse events were reported in 85.7% of the patients who received darolutamide and in 79.2% of the patients who received placebo during the double-blind period, as well as in 70.0% of the patients in the crossover group during the open-label period . The percentages of patients who discontinued the assigned treatment because of adverse events were unchanged from the primary analysis (8.9% in the darolutamide group and 8.7% in the placebo group). The incidences of serious adverse events and grade 5 adverse events in the darolutamide group and the placebo group during the double-blind period were consistent with those from the primary analysis. With longer exposure to darolutamide, the incidence of all types of adverse events increased slightly, as expected. The types of adverse events reported in the crossover group were in line with those observed with darolutamide treatment.\n\n【46】Table 3. Adverse Events of Interest in the Safety Population during the Double-Blind Period.\n\n【47】The results of the final analysis of the safety profile of darolutamide are consistent with those of the primary analysis reported previously. Fatigue was reported in 13.2% of the patients in the darolutamide group and was the only adverse event reported in more than 10% of the patients in that group during the double-blind period . The incidence of all other adverse events that occurred in more than 5% of the patients in either group was generally similar in the two groups. The results of the analysis of key adverse events that are known to be associated with androgen-deprivation therapy continued to show small or no differences in incidence between the darolutamide group and the placebo group . The incidence of cardiac events is represented by the grouped terms of cardiac arrhythmia, coronary-artery disorder, and heart failure. Although the incidence of cardiac arrhythmia was higher with darolutamide than with placebo, both a history of cardiac arrhythmia and electrocardiographic abnormalities were present to a greater extent in the darolutamide group at baseline, as observed at the time of the primary analysis (unpublished data). After adjustment for treatment exposure, the incidences of most of the adverse events of interest, including falls, seizures, hypertension, mental-impairment disorders, and depressed-mood disorders, showed little or no difference between the darolutamide group and the placebo group .\n\n【48】Discussion\n----------\n\n【49】At this prespecified final analysis, the percentage of patients who were alive at 3 years was 83% with darolutamide and 77% with placebo. Among men with nonmetastatic, castration-resistant prostate cancer and a PSA doubling time of 10 months or less, darolutamide was associated with a significant overall survival benefit, with a 31% lower risk of death than placebo. The survival benefit with darolutamide was evident from the Kaplan–Meier survival curves, which showed a separation of the two treatment groups at 18 months, favoring darolutamide, and this separation was maintained over time. This overall survival benefit was observed despite the fact that more than half the patients in the placebo group (307 of the 554 patients) received subsequent treatment with darolutamide or other life-prolonging therapy. This treatment effect was also consistent across patient subgroups. In addition, darolutamide was associated with a significant benefit with respect to all other secondary end points. As compared with placebo, treatment with darolutamide resulted in a significantly longer time to first use of cytotoxic chemotherapy, a significantly longer time to first symptomatic skeletal event, and a significantly longer time to pain progression.\n\n【50】After a median follow-up of 29.0 months in the overall trial population, darolutamide continued to have a favorable safety profile, similar to that described previously.  The percentage of patients who discontinued the assigned treatment because of adverse events during the complete double-blind period was unchanged from that reported at the primary analysis, indicating that patients with nonmetastatic, castration-resistant prostate cancer are able to receive this androgen-receptor inhibitor for prolonged periods. The incidence of adverse events commonly associated with androgen-receptor inhibitors, including falls, seizures, mental-impairment disorders, and hypertension, was similar in the two groups. The incidence of fractures was slightly higher in the darolutamide group than in the placebo group; however, after adjustment for the duration of exposure, the between-group difference decreased. This updated analysis of the ARAMIS trial confirms the low potential for central nervous system–related effects expected with darolutamide, which has been postulated to be due to the very low penetration of the blood–brain barrier that has been reported in preclinical and clinical studies of darolutamide.  Consideration of the safety profiles of treatments for nonmetastatic, castration-resistant prostate cancer is important for assessing the risk–benefit balance for patients. In clinical trials, other androgen-receptor inhibitors have shown higher incidences of central nervous system–related adverse events and hypertension than placebo.  The patient population in the current trial generally had a lower incidence of adverse events than did the patients in the PROSPER and SPARTAN (Selective Prostate Androgen Receptor Targeting with ARN-509) trials.  In all three trials, there were differences in the duration of treatment and follow-up that could have directly affected the incidence of adverse events reported in the placebo group of each trial. The fact that the incidence of death in the placebo group in the current trial was higher than the incidence of any individual adverse event is not surprising, given the median age of the trial population (74 years) and the percentage of patients who had coexisting conditions (98% of patients).\n\n【51】A major strength of this trial is the large size, which enabled a robust statistical analysis, particularly for the reported overall survival analysis with extended follow-up. A limitation of the trial is the small size of some subgroups, and hence, the low numbers of events in these subgroups and the low numbers of patients of particular races or ethnic groups (e.g., only 52 patients of African descent); therefore, no conclusions can be drawn about efficacy in these specific groups of patients.\n\n【52】Metastasis-free survival and overall survival were significantly longer with darolutamide than with placebo among men with nonmetastatic, castration-resistant prostate cancer and a PSA doubling time of 10 months or less. An overall survival benefit was observed even though more than half the patients in the placebo group received subsequent treatment with darolutamide or another life-prolonging therapy. The time to first use of cytotoxic chemotherapy, the time to first symptomatic skeletal event, and the time to pain progression were significantly longer with darolutamide than with placebo. The incidence of adverse events was similar in the darolutamide group and the placebo group.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 10:45:50", "endTime": "2024/08/14 10:46:06", "cost": 15.788}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 18:46:05", "grab_time": "2024-08-13 18:39:57"}
{"id": 2234374, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "a97e276f-0d9f-48c4-817b-c890fdffd3ff", "title": "Idiopathic Hirsutism — An Ovarian Abnormality", "text": "【0】Idiopathic Hirsutism — An Ovarian Abnormality\nAbstract\n--------\n\n【1】We investigated increased production of testosterone and androstenedione in 44 women with unexplained adult-onset hirsutism, 41 of whom had Normal-Sized ovaries. Twenty women in this group had at least 50 per cent suppression of plasma testosterone and androstenedione after four to five days of dexamethasone. Testosterone and androstenedione values in ovarian-vein effluents were higher than those of their adrenal veins. We calculated adrenal secretion rates of both androgens in each patient by relating the adrenal gradients to those of cortisol.\n\n【2】In 42 of the hirsute women, including those whose androgens were suppressed after dexamethasone, the ovaries were the predominant source of androgen production. The women with dexamethasone suppression had milder degrees of virilism and lower production rates of testosterone and androstenedione. We conclude that the ovaries are the source of excessive androgens in most women with unexplained hirsutism, and that corticoid-suppressible patients have milder forms of ovarian hyperandrogenism.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:18:22", "endTime": "2024/08/14 15:18:33", "cost": 10.299}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 23:18:32", "grab_time": "2024-08-13 23:18:21"}
{"id": 2234373, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "aace9ce6-954d-4dac-900c-83a357536011", "title": "Veterans Affairs Diabetes Trial — Corrections", "text": "【0】Veterans Affairs Diabetes Trial — Corrections\nTo the Editor:\n--------------\n\n【1】The Supplementary Appendix in which we provided additional information related to our article (Jan. 8 issue)  contains some errors. In both Appendix 1 and Appendix 2, the heading “6 Year Event Rate” should have read “6-Year Event-free Rate.” We thank the reader who detected this error.\n\n【2】In addition, on further examination of the data on albuminuria from the Veterans Affairs Diabetes Trial, we found that the data set that we used to evaluate the progression of disease was constructed improperly. As a result, the rates of progression to microalbuminuria and macroalbuminuria were reported in Table 3 of our article as being lower than they actually were. An error in the computer code resulted in the replacement of post-randomization albumin-to-creatinine ratios with the baseline albumin-to-creatinine ratio in certain patients. Because of this error, an increase in the albumin-to-creatinine ratio was not reported for some patients. Table 3, which has been corrected at NEJM.org, now has slightly smaller sample sizes than those shown in the original version of the table. Patients who had only one follow-up visit were included in the original table. By definition, these patients could not have had progression, since an elevated albumin-to-creatinine ratio for 2 successive years was required to show progression.\n\n【3】Both progression from normal to either microalbuminuria or macroalbuminuria (P=0.03) and progression from either normal or microalbuminuria to macroalbuminuria (P=0.04) favor intensive treatment. Any progression of albuminuria is now highly statistically significant (P<0.01); 13.8% of the patients in the standard-therapy group, as compared with 9.1% of patients in the intensive-therapy group, had worsening albuminuria.\n\n【4】We appreciate the opportunity to update our results regarding nephropathy, but we regret any confusion this may cause. The rest of Table 3 remains unaffected. As a consequence of these changes in Table 3, parts of the Abstract, Results, and Discussion are affected , but the overall conclusions of the trial are similar. We regret these errors.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 10:51:37", "endTime": "2024/08/14 10:52:02", "cost": 24.712}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 18:52:02", "grab_time": "2024-08-13 18:51:37"}
{"id": 2234372, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "bb74b885-89fa-4564-ac17-754c3a0c74de", "title": "Cholesterol Crystals and the Formation of Cholesterol Gallstones", "text": "【0】Cholesterol Crystals and the Formation of Cholesterol Gallstones\nAbstract\n--------\n\n【1】To examine the relation of cholesterol crystallization to the formation of gallstones, gallbladder bile was obtained by means of duodenal intubation in 54 patients (eight with asymptomatic gallstones) and from 17 patients undergoing cholecystectomy for cholelithiasis. Hepatic bile was obtained from nine patients with common-duct stones. Bile samples were examined for cholesterol monohydrate crystals and analyzed to determine the percentage of cholesterol saturation.\n\n【2】Intubation in the eight patients with asymptomatic gallstones revealed a cholesterol saturation of 142±42 per cent (mean ±S.D.) and crystals in five patients. Crystals were absent in the other 36 patients with supersaturated bile (cholesterol saturation, 166±44 per cent) and in the 10 patients with undersaturated bile (cholesterol saturation, 81±24 per cent). In the 26 patients with symptomatic cholelithiasis or common-duct stones, crystals were not seen in the bile of the seven patients with pigment stones but were present in the bile of all 19 patients with cholesterol stones. (In some cases crystals appeared only after 24 to 48 hours of incubation.)\n\n【3】Cholesterol crystallization is probably a prerequisite for the formation of cholesterol gallstones; however, many subjects have no crystallization despite marked supersaturation.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:04:18", "endTime": "2024/08/14 15:04:27", "cost": 9.354}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 23:04:27", "grab_time": "2024-08-13 23:04:17"}
{"id": 2234371, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "9e4e3d51-5c90-4ff2-97e2-b657e660efa5", "title": "When the CHIPs Are Down — Health Coverage and Care at Risk for U.S. Children", "text": "【0】When the CHIPs Are Down — Health Coverage and Care at Risk for U.S. Children\nCongress failed to reauthorize the Children’s Health Insurance Program (CHIP) last fall, causing uncertainty and worry for families and state CHIP directors alike. After a period of stopgap funding, CHIP was reauthorized for 6 years in late January.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:46:23", "endTime": "2024/08/14 15:46:32", "cost": 8.553}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 23:46:32", "grab_time": "2024-08-13 23:46:23"}
{"id": 2234370, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "5ef8ea1c-9f1a-4950-bd7d-bf6dbd5d5362", "title": "Age-Related Increase in Mortality among Patients with First Myocardial Infarctions Treated with Thrombolysis", "text": "【0】Age-Related Increase in Mortality among Patients with First Myocardial Infarctions Treated with Thrombolysis\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】The overall rate of mortality due to ischemic heart disease is known to increase progressively with age. We evaluated the relation between the mortality rate and age in patients with first myocardial infarctions treated with thrombolytic therapy.\n\n【3】Methods\n-------\n\n【4】We studied 9720 patients with first infarctions who had been enrolled in the GISSI-2 trial. (This trial compared the efficacy of tissue plasminogen activator with that of streptokinase in patients with myocardial infarction.) Of these, only 35 percent had a history of angina. The relation between age and mortality during hospitalization and during the six months after discharge was determined by unadjusted and adjusted analyses.\n\n【5】Results\n-------\n\n【6】The in-hospital mortality rate was 1.9 percent among patients 40 years old or younger, but it increased to 31.9 percent among those more than 80 years old; however, values for indicators of infarct size did not increase with age. Autopsies were performed in 20 percent of the 772 patients who died in the hospital; the findings showed that the frequency of cardiac rupture increased from 19 percent among patients 60 years old or younger to 86 percent among those more than 70 years old. The mortality rate for the first six months after hospital discharge also increased significantly with age. After adjustment for confounding variables, older age continued to be significantly associated with a higher risk of in-hospital and post-discharge death. When age was introduced into a multivariate model as a continuous variable, the risk of death was estimated to increase by about 6 percent per year for both in-hospital and six-month mortality rates.\n\n【7】Conclusions\n-----------\n\n【8】In patients with first myocardial infarctions who received thrombolytic therapy, age was a powerful independent predictor of both in-hospital and post-discharge mortality rates. The exponential, age-related increase in the mortality rate did not appear to be explained by larger infarcts.\n\n【9】Introduction\n------------\n\n【10】The rate of mortality due to ischemic heart disease increases progressively with age. In the United States, about 80 percent of deaths from ischemic heart disease occur among patients over the age of 65 <sup><a>1 </a></sup> .\n\n【11】The findings of recent large multicenter trials of thrombolytic therapy for acute myocardial infarction have shown that among patients over the age of 70 years, mortality during hospitalization is considerably higher than among younger patients  . However, it is unclear whether the increased incidence of fatal outcomes in the elderly is the result of more severe coronary atherosclerosis (which could lead to larger infarcts), greater susceptibility of the aging heart to myocardial necrosis, or other variables, such as coexisting illnesses.\n\n【12】The aim of this study was to assess the effect of clinical and epidemiologic variables on in-hospital and six-month mortality as a function of age in patients with first confirmed myocardial infarctions who were enrolled in the trial conducted by the Gruppo Italiano per lo Studio della Sopravvivenza nell'Infarto Miocardico (GISSI-2).\n\n【13】Methods\n-------\n\n【14】Trial Design, Selection of Patients, and Treatment\n--------------------------------------------------\n\n【15】The details of the design and main results of the GISSI-2 trial have been presented elsewhere  . In brief, patients of any age were eligible for randomization if they presented to the participating centers within six hours after the onset of symptoms, had no contraindications to thrombolytic therapy, and had electrocardiographic evidence of ST-segment elevation of at least 1 mm in two limb leads or of at least 2 mm in one precordial lead. A total of 12,381 patients with acute myocardial infarction who met these criteria were randomly assigned to treatment with streptokinase (1.5 million units given over a period of 30 to 60 minutes) or alteplase (tissue plasminogen activator, 100 mg given over a period of 3 hours), with or without heparin (12,500 units given subcutaneously twice daily). Of the total studied, 9720 patients (78.5 percent) had first confirmed myocardial infarctions.\n\n【16】Clinical Data\n-------------\n\n【17】Information about smoking, hypercholesterolemia, hypertension, and diabetes was abstracted from a standardized questionnaire by cardiologists specifically trained for this purpose. When the patients visited the clinic, the cardiologists who completed the study forms collected information about any earlier event suggesting angina pectoris, as indicated by recurring chest pain caused by effort and relieved by rest and also pain occurring during emotional stress or spontaneously and lasting less than 15 minutes, with a typical location or radiation or with the same features as the pain experienced during the infarction. Whenever possible, the investigators also reviewed the patients' previous clinical records documenting the clinical history. The Killip scale  was used to stratify the severity of impairment of left ventricular function on admission. Whenever possible, left ventricular function was also assessed in survivors by two-dimensional echocardiography before discharge. Standard 12-lead electrocardiography was also performed on discharge to calculate the QRS score as a measure of the size of the infarct  .\n\n【18】An ad hoc committee blinded to the patients' thrombolytic treatment reviewed the clinical records of those who had died, to assess the causes of death. Cardiac rupture and cardiogenic shock resulting from rupture of the interventricular septum or papillary muscle were diagnosed only if they were found at autopsy.\n\n【19】Postmortem findings were available for 158 (20 percent) of the 772 patients who died in the hospital. The degree of coronary arteriosclerosis and the percentage of the left ventricle that was infarcted were estimated qualitatively during the postmortem examinations.\n\n【20】For the 1073 patients (11 percent of the total population) who could not be reached by the local monitor of the study, vital status six months after discharge was determined through the census offices of their cities of residence. The deaths of 30 patients were confirmed in this manner.\n\n【21】Estimation of Infarct Size and Left Ventricular Dysfunction\n-----------------------------------------------------------\n\n【22】Three indicators of infarct size were used: the number of leads with ST-segment elevation on the admission electrocardiogram, the ratio of the peak creatine kinase level to the upper limit of normal at each study-center laboratory, and the QRS score calculated at discharge  .\n\n【23】Left ventricular dysfunction was defined as the presence of late (after the fourth hospital day) clinical congestive heart failure (indicated by the presence of an S <sub>3 </sub> gallop, rales, dyspnea, or radiologic evidence of pulmonary congestion), or as extensive left ventricular injury in the absence of clinical heart failure (indicated by a left ventricular ejection fraction of 35 percent or less on echocardiography, or by injury to 45 percent or more of myocardial segments \\[akinetic-dyskinetic scores\\] when a measurement of the left ventricular ejection fraction was not available  ). The ejection fraction was calculated from left ventricular two-dimensional tomograms by either the area-length method or the modified Simpson rule  . Ejection fractions and akinetic-dyskinetic scores at discharge were available for 3228 and 8044 patients, respectively (33.2 percent and 82.8 percent of the study population).\n\n【24】Quality Control\n---------------\n\n【25】Local monitors received a two-day training course on methods of data collection. The importance of validating the patients' answers was given special emphasis, and investigators were asked to review the patients' clinical records whenever possible. A random sample of about 10 percent of all echocardiographic assessments was also reviewed centrally. Data on the overall frequency of agreement were adjusted for the agreement expected by chance alone (kappa values). The kappa statistic showed highly satisfactory agreement for echocardiographic markers of left ventricular dysfunction (0.75 for the ejection fraction and 0.77 for the akinetic-dyskinetic score).\n\n【26】Statistical Analysis\n--------------------\n\n【27】The patients were divided into three age groups: patients 60 years old or younger, those 61 to 70 years old, and those more than 70 years old. All relations between variables were first determined by an unadjusted analysis  . Statistical significance was analyzed by chi-square tests. An adjusted analysis was performed with models constructed by multiple logistic regression  . Factors considered in the multivariable model for in-hospital mortality were age (≤ 60, 61 to 70, and >70 years); sex; number of hours between the onset of symptoms and admission; Killip class on admission; location of the infarct (anterior or elsewhere); history of smoking, hypertension, diabetes, or angina; body-mass index; peak creatine kinase ratio; and the number of leads with ST-segment elevation. A second adjusted analysis (Cox model) of six-month mortality included the same variables and the indicators of the degree of left ventricular dysfunction at discharge. A third model incorporated the same variables and age as a continuous variable in an analysis of both in-hospital and six-month mortality. The results are presented in terms of Mantel-Haenszel odds ratios for in-hospital mortality and in terms of relative risks for six-month mortality, both with 95 percent confidence intervals.\n\n【28】Results\n-------\n\n【29】Table 1. Distribution of Clinical Variables of Patients with First Myocardial Infarctions, According to Age Group.\n\n【30】The base-line clinical characteristics of the patients are presented according to age group in Table 1 .\n\n【31】A history of angina was obtained from about 35 percent of the study population, and the incidence was similar in the age groups. In this trial, in which only patients with ST-segment elevation could be enrolled, the number of leads showing ST-segment elevation at admission was similar among the age groups. The number of patients in Killip classes 3 and 4 (classes indicating more severe hemodynamic impairment) and the number with anterior infarctions increased with age. A history of smoking was significantly more common among younger patients, whereas a history of diabetes, hypercholesterolemia, and treated hypertension was obtained significantly more frequently among older patients.\n\n【32】In-Hospital Mortality\n---------------------\n\n【33】Of the 9720 patients enrolled in the study, 1035 (10.6 percent) had died within six months after discharge -- 772 (7.9 percent) during hospitalization and 263 (2.9 percent of the survivors) during the six months after discharge.\n\n【34】Table 2. In-Hospital Mortality, According to Analysis of Study Variables.\n\n【35】In the univariate analysis , age was a powerful predictor of in-hospital mortality, with an odds ratio of 2.9 (95 percent confidence interval, 2.3 to 3.6) for patients 61 to 70 years old as compared with younger patients, and an odds ratio of 8.9 (7.4 to 10.8) for patients more than 70 years old. A history of smoking was found to be a “protective” factor in relation to the outcome of a first infarction. This paradoxical finding may be due to the base-line characteristics of the patients who smoked and, in particular, to the fact that smokers were younger than nonsmokers. The apparent protective effect of a history of smoking must be interpreted as a confounded result, because the statistical significance of this variable disappeared when the data were adjusted for age. All the other variables tested in the univariate analysis were associated with higher mortality, but the magnitude of these associations differed greatly among the variables. Weak associations (odds ratio, <2) were found between mortality and a longer interval between the onset of symptoms and arrival at the hospital, a history of hypertension, the presence of non-insulin-dependent diabetes, and chronic angina (angina present for more than one month). Stronger associations (odds ratio, >2) were found for advanced age, female sex, high Killip class at admission, insulin-dependent diabetes, anterior-wall infarction, and a high number of leads ( ≥ 6) with ST-segment elevation on the admission electrocardiogram.\n\n【36】To assess the independent contribution of age, the same variables were introduced into a multivariate model . Older age was confirmed to be an independent predictor of mortality, with an odds ratio of 2.2 (95 percent confidence interval, 1.6 to 2.9) for patients 61 to 70 years old and 3.9 (95 percent confidence interval, 2.9 to 5.3) for patients more than 70 years old. The other variables that were confirmed as significantly associated with in-hospital mortality after adjustment were high Killip class on admission, anterior location of the infarct, and a high number of leads with ST-segment elevation on the admission electrocardiogram.\n\n【37】Figure 1. Mortality among Patients with First Myocardial Infarctions, According to Age and Indicators of Infarct Size.\n\n【38】Age was considered a continuous variable, with the age of 40 years as the reference value. Values for the indicators of the size of the myocardial infarction did not show any increase with age.\n\n【39】Mortality during hospitalization increased exponentially with age; it is shown as an odds ratio (OR, calculated with the formula × = 0.1002588 × e <sup>0.0575x </sup> ) and 95 percent confidence interval (CI). The curves for the indicators of infarct size show the percentage of patients with peak creatine kinase ratios more than six times the upper normal value of the study-center laboratory (CK >6 × normal) and the percentage with involvement of more than six electrocardiographic leads at entry.\n\n【40】Mortality during the interval from discharge to six months after discharge also increased exponentially with age; it is shown as a relative risk (RR, calculated with the formula × = 0.1094814 × e <sup>0.0553x </sup> ). The curves for the indicators of infarct size show the percentage of patients with peak creatine kinase ratios more than six times normal and the percentage with QRS scores above 10.\n\n【41】When age was introduced into the multivariate model as a continuous variable, its predictive value for in-hospital mortality was confirmed; the risk was estimated to increase exponentially by about 6 percent per year (odds ratio, 1.06; 95 percent confidence interval, 1.05 to 1.07). The overall in-hospital mortality was 1.9 percent among patients 40 years old or younger, which increased to 31.9 percent among patients more than 80 years old; values for the indicators of infarct size did not increase significantly with age .\n\n【42】Causes of In-Hospital Deaths\n----------------------------\n\n【43】About half the deaths in each age group occurred on the day of the infarction or the day after -- i.e., in 70 (56 percent) of the 125 patients 60 years old or younger who died, 112 (46 percent) of the 244 patients 61 to 70 years old who died, and 210 (52 percent) of the 403 patients more than 70 years old who died.\n\n【44】Electromechanical dissociation occurred in 13 percent of the patients 60 years old or younger, 20 percent of those 61 to 70 years old, and 25 percent of those more than 70 years old. Conversely, the rate of death due to ventricular fibrillation decreased, from 15 percent among patients 60 years old or younger to 10 percent among those 61 to 70 years old and to 6 percent among those more than 70 years old. Autopsies were performed in 158 (20 percent) of the 772 patients who died during hospitalization (25 percent, 18 percent, and 21 percent of the three age groups, respectively). Cardiac rupture was found post mortem in 103 of these patients, or 65 percent, and its incidence increased progressively, from 19 percent among those 60 years old or younger (6 of 31 patients) to 58 percent among those 61 to 70 years old (25 of 43 patients) and to 86 percent among those more than 70 years old (72 of 84 patients). The variable incidence of cardiac rupture in previous reports may well be due to the inclusion of patients from different age groups,  but a possible role of thrombolytic therapy cannot be excluded. At least two coronary arteries with severe stenoses were found in 40 percent of patients 60 years old or younger, 35 percent of those 61 to 70 years old, and 32 percent of those more than 70 years old. Infarcts involving less than 10 percent of the left ventricle were found in 20 percent of patients 60 years old or younger, 23 percent of those 61 to 70 years old, and 32 percent of those more than 70 years old.\n\n【45】Evaluation of Survivors before Discharge\n----------------------------------------\n\n【46】The QRS score decreased progressively with age, but the differences among the three age groups were not significant. The percentage of patients with injury to more than 45 percent of myocardial segments (expressed by the akinetic-dyskinetic score) was 3 percent in the group 60 years old or younger, 4 percent in the group 61 to 70 years old, and 6 percent in the group more than 70 years old; the mean left ventricular ejection fraction was 50.8 ±11.5, 49.1 ±11.6, and 47.4 ±12.9, respectively.\n\n【47】Mortality from Discharge to Six Months\n--------------------------------------\n\n【48】Table 3. Post-discharge Mortality, According to Analysis of Study Variables.\n\n【49】The mortality rate during the six months after discharge increased significantly, from 1.3 percent among patients 60 years old or younger to 3.0 percent among those 61 to 70 years old and to 7.4 percent among those more than 70 years old . After adjustment, age continued to be associated with a higher risk of death after discharge, with a relative risk of 2.0 (95 percent confidence interval, 1.4 to 2.8) for patients 61 to 70 years old and 3.9 (95 percent confidence interval, 2.7 to 5.6) for those more than 70 years old. When age was introduced into the adjusted model as a continuous variable, the risk of death during the first six months after discharge was estimated to increase exponentially by 5.7 percent per year (relative risk, 1.06; 95 percent confidence interval, 1.04 to 1.07). Overall mortality after hospital discharge was 0.8 percent among patients 40 years old or younger and 11.6 percent among those more than 80 years old ; the QRS scores at discharge were similar in these two age groups.\n\n【50】Discussion\n----------\n\n【51】In this study of a large group of patients presenting with first myocardial infarctions who were eligible to receive thrombolytic therapy, we observed that in-hospital mortality increased from 2.8 percent among patients 60 years old or younger to 19.0 percent among those more than 70 years old, confirming the findings of previous studies  . The mortality rate during the first six months after discharge was 1.3 percent among patients 60 years old or younger, but 7.4 percent among those more than 70 years old. The age-related increase in mortality did not appear to be explained by larger infarcts, as assessed by peak creatine kinase ratios and QRS scores on the electrocardiogram. However, both those measurements have limited precision in determining infarct size. As the age of the patients increased, we observed an increase in the frequency of Killip classes 3 and 4 (reflecting more severe hemodynamic dysfunction), echocardiographic evidence of left ventricular dysfunction, clinical signs of left ventricular failure, electromechanical dissociation, and cardiac rupture. Thus, older patients had more severe hemodynamic compromise than younger patients, despite the fact that the measurements of infarct size were similar across all age groups. Although the patients from all age groups who survived until discharge had a similar degree of estimated myocardial injury, the mortality rate during the first six months after discharge increased exponentially with age and was about six times higher among patients more than 70 years old than among those 60 years old or younger.\n\n【52】The explanation for our findings is unclear. Although the extent of coronary atherosclerosis increases with age, the number of coronary obstructive lesions was shown to plateau after the age of 60 in a series of 600 men who underwent autopsy  and in a similar series of women  . Also, myocardial infarction was the very first manifestation of ischemic heart disease in about 60 percent of our patients, irrespective of age. Such patients often do not have severe stenoses in the infarct-related artery  and have less severe and less extensive coronary atherosclerosis detectable by coronary angiography than patients presenting with a long history of uncomplicated stable angina  . Furthermore, in our selected group of patients with myocardial infarction who presented with ST-segment elevation, and who died and subsequently underwent autopsy (20 percent of patients who died during hospitalization), the number and degree of critical coronary stenoses did not differ according to age group. Consequently, the higher mortality rate among older patients may not be related to more extensive coronary artery disease.\n\n【53】Echocardiographic measurements of left ventricular dimensions remain unchanged up to the ninth decade of life, whereas left-ventricular-wall thickness increases by approximately 30 percent between the ages of 25 and 80 years  . The rate of myocardial contraction and relaxation decreases slightly with age, and the response to beta-adrenergic stimulation is considerably reduced  . Furthermore, postmortem studies indicate a sustained loss of myocardial cells in old age, with considerable expansion of the interstitial space and hypertrophy of myocardial cells  \\-- findings similar to those in the hearts of old rats  \\-- which could result in a greater impairment of left ventricular function and a greater risk of cardiac rupture in older patients even if the estimated size of their infarct is similar to or smaller than that of younger patients. Reductions in lung compliance, renal function, and catecholamine response may be additional factors responsible for the worse outcome of myocardial infarction in older patients. The tendency of coexisting illnesses (such as pneumonia or pulmonary emboli) to develop in elderly patients may also have a role.\n\n【54】Our findings may be applicable only to patients presenting with ST-segment elevation who are eligible to receive thrombolytic therapy, but our data on this large group of patients suggest that besides infarct size, older age is a major, independent risk factor for death among patients with acute myocardial infarction. Furthermore, research should be directed toward the prevention of cardiac failure, rupture, and electromechanical dissociation in the elderly. For example, beta-blockers may reduce myocardial rupture due to infarction  . Ongoing multicenter trials  may eventually show whether nitrates or angiotensin-converting-enzyme inhibitors lower mortality after acute myocardial infarction in older patients with cardiac failure by reducing their vulnerability to myocardial necrosis.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-14 00:18:02", "grab_time": "2024-08-13 22:49:49"}
{"id": 2234369, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "d860b6cd-940b-40dd-a689-d1f2388d9dc4", "title": "Hirsutism", "text": "【0】Hirsutism\nA 19-year-old woman seeks care for slowly progressive hair growth. Since high school, she has shaved her upper lip weekly and waxed her abdomen and thighs monthly. Her menstrual periods are regular. Physical examination is unremarkable except for a body-mass index of 31 and trace hair over the abdomen and thighs, with a moderate amount over her back. There is no clitorimegaly. How should this patient be evaluated and treated?", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:51:44", "endTime": "2024/08/14 14:51:56", "cost": 11.828}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 22:51:56", "grab_time": "2024-08-13 22:51:43"}
{"id": 2234368, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "bc4e8f71-a94c-406a-901a-90c908c475e9", "title": "A Wii Fracture", "text": "【0】A Wii Fracture\nTo the Editor:\n--------------\n\n【1】In 1990, Brasington described “Nintendinitis”  in a patient with pain over the extensor tendon of her thumb after 5 hours of playing a Nintendo video game. Nintendo next released the highly popular Wii games console that includes a wireless remote capable of detecting movement in three dimensions. Clinicians began to see patients with “Wiiitis.”  There do not seem to be reports of associated bony injuries, although interactive gaming has been reported to aid in the rehabilitation of patients after fracture. \n\n【2】In the United Kingdom, a healthy 14-year-old girl presented to the emergency department at Horton General Hospital in Banbury (near Oxford), having sustained an injury to her right foot with associated difficulty in mobilization. She had been playing on her Wii Fit balance board and had fallen off, sustaining an inversion injury. (The Wii Fit replaces handheld controls with a pressure-sensitive board about 2 in. off the ground that lets the user participate in tricky games that can improve balance.)\n\n【3】Figure 1. Fracture of the Base of the Fifth Metatarsal in the Patient.\n\n【4】On examination, there was soft-tissue swelling around the base of the fifth metatarsal, which was maximally tender to palpation. A radiograph showed a small fracture of the base of the fifth metatarsal . The patient was treated conservatively with the use of crutches and was referred to the fracture clinic for outpatient follow-up. The fracture probably resulted from the pull of the peroneus brevis muscle during inversion of the ankle.\n\n【5】Other reported Wii-associated injuries have included traumatic hemothorax (from a fall while playing),  dislocations, and head injuries (from being struck accidentally by a gaming partner). \n\n【6】Karen A. Eley, M.R.C.S.(Ed)  \nOxford Radcliffe Hospitals NHS Trust, Oxford, United Kingdom  \nkaren.  a.  eley@gmail.  com\n\n【7】5 References\n\n【8】1.  1\\. Brasington R. Nintendinitis. N Engl J Med 1990 ;322: 1473 \\- 1474\n\n【9】    *   Full Text\n    *   Web of Science . opens in new tab\n    *   Medline . opens in new tab\n    Google Scholar . opens in new tab\n2.  2\\. Bonis J. Acute Wiiitis. N Engl J Med 2007 ;356: 2431 \\- 2432\n\n【10】    *   Free Full Text\n    *   Web of Science . opens in new tab\n    *   Medline . opens in new tab\n    Google Scholar . opens in new tab\n3.  3\\. Wii games help fracture patients regain movement. Nursing Times. May 16, 2009.\n\n【11】    Google Scholar . opens in new tab\n4.  4\\. Peek AC, Ibrahim T, Abunasra H, Waller D, Natarajan R. White-out from a Wii: traumatic haemothorax sustained playing Nintendo Wii. Ann R Coll Surg Engl 2008 ;90: 9 \\- 10\n\n【12】    *   Crossref . opens in new tab\n    Google Scholar . opens in new tab\n5.  5\\. Wells JJ. An 8-year-old girl presented to the ER after accidentally being hit by a Wii remote control swung by her brother. J Trauma 2008 ;65: 1203 \\- 1203\n\n【13】    *   Crossref . opens in new tab\n    *   Web of Science . opens in new tab\n    *   Medline . opens in new tab\n    Google Scholar . opens in new tab\n\n【14】Supplementary Material\n----------------------\n\n| Disclosure Forms | PDF | 79KB |\n| --- | --- | --- |\n\n【16】Citing Articles _(13)_\n----------------------\n\n【17】Close Citing Articles", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "【6】Karen A. Eley, M.R.C.S.(Ed)\n\nOxford Radcliffe Hospitals NHS Trust, Oxford, United Kingdom\n\nkaren.  a.  eley@gmail.  com\n\n【7】5 References\n\n【8】1.  1. Brasington R. Nintendinitis. N Engl J Med 1990 ;322: 1473 - 1474\n\n【9】    *   Full Text\n\nWeb of Science . opens in new tab\nMedline . opens in new tab\nGoogle Scholar . opens in new tab\n2. Bonis J. Acute Wiiitis. N Engl J Med 2007 ;356: 2431 - 2432\n【10】    *   Free Full Text\n\nWeb of Science . opens in new tab\nMedline . opens in new tab\nGoogle Scholar . opens in new tab\n3. Wii games help fracture patients regain movement. Nursing Times. May 16, 2009.\n【11】    Google Scholar . opens in new tab\n\n4.  4. Peek AC, Ibrahim T, Abunasra H, Waller D, Natarajan R. White-out from a Wii: traumatic haemothorax sustained playing Nintendo Wii. Ann R Coll Surg Engl 2008 ;90: 9 - 10\n\n【12】    *   Crossref . opens in new tab\n\nGoogle Scholar . opens in new tab\n\n5.  5. Wells JJ. An 8-year-old girl presented to the ER after accidentally being hit by a Wii remote control swung by her brother. J Trauma 2008 ;65: 1203 - 1203\n\n【13】    *   Crossref . opens in new tab\n\nWeb of Science . opens in new tab\nMedline . opens in new tab\nGoogle Scholar . opens in new tab\n【14】Supplementary Material\nDisclosure Forms\tPDF\t79KB\n【16】Citing Articles (13)\n【17】Close Citing Articles", "content": "【0】A Wii Fracture\nTo the Editor:\n--------------\n\n【1】In 1990, Brasington described “Nintendinitis”  in a patient with pain over the extensor tendon of her thumb after 5 hours of playing a Nintendo video game. Nintendo next released the highly popular Wii games console that includes a wireless remote capable of detecting movement in three dimensions. Clinicians began to see patients with “Wiiitis.”  There do not seem to be reports of associated bony injuries, although interactive gaming has been reported to aid in the rehabilitation of patients after fracture. \n\n【2】In the United Kingdom, a healthy 14-year-old girl presented to the emergency department at Horton General Hospital in Banbury (near Oxford), having sustained an injury to her right foot with associated difficulty in mobilization. She had been playing on her Wii Fit balance board and had fallen off, sustaining an inversion injury. (The Wii Fit replaces handheld controls with a pressure-sensitive board about 2 in. off the ground that lets the user participate in tricky games that can improve balance.)\n\n<mark>【3】Figure 1. </mark>Fracture of the Base of the Fifth Metatarsal in the Patient.\n\n【4】On examination, there was soft-tissue swelling around the base of the fifth metatarsal, which was maximally tender to palpation. A radiograph showed a small fracture of the base of the fifth metatarsal . The patient was treated conservatively with the use of crutches and was referred to the fracture clinic for outpatient follow-up. The fracture probably resulted from the pull of the peroneus brevis muscle during inversion of the ankle.\n\n【5】Other reported Wii-associated injuries have included traumatic hemothorax (from a fall while playing),  dislocations, and head injuries (from being struck accidentally by a gaming partner). \n\n【6】Karen A. Eley, M.R.C.S.(Ed)  \nOxford Radcliffe Hospitals NHS Trust, Oxford, United Kingdom  \nkaren.  a.  eley@gmail.  com\n\n【7】5 References\n\n【8】1.  1\\. Brasington R. Nintendinitis. N Engl J Med 1990 ;322: 1473 \\- 1474\n\n【9】    *   Full Text\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n2.  2\\. Bonis J. Acute Wiiitis. N Engl J Med 2007 ;356: 2431 \\- 2432\n\n【10】    *   Free Full Text\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n3.  3\\. Wii games help fracture patients regain movement. Nursing Times. May 16, 2009.\n\n【11】    Google Scholar . opens in new tab\n4.  4\\. Peek AC, Ibrahim T, Abunasra H, Waller D, Natarajan R. White-out from a Wii: traumatic haemothorax sustained playing Nintendo Wii. Ann R Coll Surg Engl 2008 ;90: 9 \\- 10\n\n【12】    *   Crossref . opens in new tab\nGoogle Scholar . opens in new tab\n5.  5\\. Wells JJ. An 8-year-old girl presented to the ER after accidentally being hit by a Wii remote control swung by her brother. J Trauma 2008 ;65: 1203 \\- 1203\n\n【13】    *   Crossref . opens in new tab\n*   Web of Science . opens in new tab\n*   Medline . opens in new tab\nGoogle Scholar . opens in new tab\n\n【14】Supplementary Material\n----------------------\n\n| Disclosure Forms | PDF | 79KB |\n| --- | --- | --- |\n\n【16】Citing Articles _(13)_\n----------------------\n\n【17】Close Citing Articles", "index": 1803, "show": true, "start": 1790, "end": 3090, "province": ["文本干净度", "无关文本"], "isEdit": false}]}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-14 00:20:49", "grab_time": "2024-08-13 23:13:41"}
{"id": 2234367, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "1d2bfe53-8456-4490-8801-90f45c0350af", "title": "Evaluation of a Program for Preventing Adolescent Pregnancy", "text": "【0】Evaluation of a Program for Preventing Adolescent Pregnancy\nAbstract\n\n【1】Birth-control services with intensive individual and group counseling were provided for preventing unplanned pregnancy in sexually active nulliparous adolescents. During the first two years of the program 100 girls were placed on contraception. Despite intensive follow-up efforts, only 50 per cent remained active with the program one year after admission. However, almost half the younger adolescents were still active in the program at the end of two years. Side effects were minimal, except for weight gain, which was most frequent among girls who were overweight at the time of admission to the program. These observations indicate the complexities involved and demonstrate the need for an interdisciplinary team approach in the prevention of adolescent pregnancy.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:52:49", "endTime": "2024/08/14 14:52:58", "cost": 8.284}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 22:52:58", "grab_time": "2024-08-13 22:52:49"}
{"id": 2234366, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "dbae8d2e-ca58-401d-8535-41dc4392cca9", "title": "Reduction of Nosocomial Infection during Pediatric Intensive Care by Protective Isolation", "text": "【0】Reduction of Nosocomial Infection during Pediatric Intensive Care by Protective Isolation\nAbstract\n--------\n\n【1】To determine whether simple protective isolation reduces the incidence of nosocomial bacterial and fungal infection during pediatric intensive care, we randomly assigned 70 children who were not immunosuppressed and who required mechanical ventilator support and three or more days of intensive care to receive standard care (n = 38) or protective isolation (n = 32) with the use of disposable, nonwoven, polypropylene gowns and nonsterile latex gloves. Risk factors predisposing patients to infection were comparable in the two groups.\n\n【2】Nosocomial colonization occurred later among isolated patients (median, 12 vs. 7 days; P<0.01) and was associated with subsequent infection in 2 patients, as compared with 12 patients given standard care (P = 0.01). Among patients who were isolated, the interval before the first infection was significantly longer (median, 20 vs. 8 days; P = 0.04), the daily infection rate was 2.2 times lower (95 percent confidence interval, 1.2 to 4.0; P = 0.007), and there were fewer days with fever (13 percent vs. 21 percent; P = 0.001). The benefit of isolation was most notable after seven days of intensive care. Isolation was well tolerated by patients and their families. Regular monitoring showed that the children in each group were touched and handled comparably often by hospital personnel and family members.\n\n【3】We conclude that the use of disposable, high-barrier gowns and gloves for the care of selected, high-risk children who require prolonged intensive care significantly reduces the incidence of nosocomial infection, is well tolerated, and does not compromise the delivery of care.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:34:50", "endTime": "2024/08/14 14:35:02", "cost": 12.343}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 22:35:02", "grab_time": "2024-08-13 22:34:49"}
{"id": 2234365, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "832fe237-ffd7-45b3-9679-009399f7f4cc", "title": "Aligning Quality Measures across CMS — The Universal Foundation", "text": "【0】Aligning Quality Measures across CMS — The Universal Foundation\nArticle\n-------\n\n【1】The quality-measurement movement began more than 20 years ago and has resulted in transparent quality-performance information, accountability, and improvements. At the same time, proliferation of quality measures has caused confusion, increased reporting burden, and misalignment of approaches for common clinical scenarios. The Centers for Medicare and Medicaid Services (CMS) and public–private partnerships have therefore moved toward creating more parsimonious sets of measures. Although some progress has been made, lack of alignment across CMS’s quality programs has contributed to challenges for clinicians, facilities, and health insurers when it comes to prioritizing outcomes that are meaningful for patients.\n\n【2】We — the leaders of many CMS centers — aim to promote high-quality, safe, and equitable care. We believe aligning measures to focus provider attention and drive quality improvement and care transformation will catalyze efforts in this area. Since there is tension between measuring all important aspects of quality and reducing measure proliferation, we are proposing a move toward a building-block approach: a “universal foundation” of quality measures that will apply to as many CMS quality-rating and value-based care programs as possible, with additional measures added on, depending on the population or setting.\n\n【3】CMS operates more than 20 quality programs focused on individual clinicians, certain health care settings such as hospitals or skilled nursing facilities, health insurers, and value-based entities such as accountable care organizations. Each of these programs has its own set of quality measures; entities report on and are held accountable for their performance on various measures. Although some of these measures are consistent across our programs, many are not. Insurers often use the same quality measures as CMS (such as the Medicare Part C and D star ratings or plan-level measures for Medicaid managed-care organizations) to adjust clinician reimbursement as part of value-based arrangements — although some insurers use different or modified measures, which has also contributed to measure proliferation.\n\n【4】The Universal Foundation is part of CMS’s efforts to implement the vision outlined in our National Quality Strategy  and is fundamental to achieving several of the agency’s quality and value-based care goals.  It is intended to focus providers’ attention on measures that are meaningful for the health of broad segments of the population; reduce provider burden by streamlining and aligning measures; advance equity with the use of measures that will help CMS recognize and track disparities in care among and within populations; aid the transition from manual reporting of quality measures to seamless, automatic digital reporting; and permit comparisons among various quality and value-based care programs, to help the agency better understand what drives quality improvement and what does not. To select measures for the Universal Foundation, CMS prioritized measures that were most likely to achieve these goals and have minimal unintended consequences (e.g., promoting overtreatment of certain conditions).\n\n【5】Across CMS, the existence of multiple processes for measure selection and approval has historically made implementation of aligned measures challenging. As such, we have created a cross-center working group focused on coordination of these processes and on development and implementation of aligned measures to support a consistent approach under the Universal Foundation.\n\n【6】 Preliminary Adult and Pediatric Universal Foundation Measures.\n\n【7】Our intention is that the Universal Foundation will eventually include selected measures for assessing quality along a person’s care journey — from infancy to adulthood — and for important care events, such as pregnancy and end-of-life care. We started by identifying preliminary measures for the Universal Foundation’s adult and pediatric components . The streamlined measures included here would be used across CMS programs and populations, to the extent that they are applicable and in keeping with legislative statutes. Additional measures will be necessary for assessing care provided to specific populations or in certain settings, such as hospital-based care, maternity care, dialysis care, and long-term and community services. CMS will identify add-on measures that could be implemented consistently across programs. In some instances, we may seek to include a particular measure in only one program, but only if it captures an aspect of quality that is specific to that setting. For example, it’s impossible to capture all aspects of specialist quality in a foundational set, so CMS will continue to evaluate specialty-specific measures for potential inclusion in the Merit-Based Incentive Payment System Value Pathways and certain innovation models.\n\n【8】The quality measures we selected underlie many of the diseases and conditions associated with the highest morbidity and mortality in the United States, including diabetes, high blood pressure, and cancer. The cancer-related measures are in line with the goals of the Cancer Moonshot program.  The measures also reflect the importance of high-quality preventive care, including vaccination. Identification and treatment of depression and substance use disorders are included in the Universal Foundation because addressing these behavioral health conditions in an integrated way can improve both physical and behavioral health outcomes.  The focus on quality in behavioral health care for pediatric populations reflects the need to improve care for children and adolescents with depression, other mental health disorders, and substance use disorders. Finally, the measures focus on care coordination after hospitalization, patient experience, and screening for social drivers of health (we also intend for them to eventually cover follow-up to address identified social needs). Although equity is a measurement-category domain, CMS also plans to use the full set of measures to stratify outcome data and identify disparities among and within populations to inform future equity efforts internally and for health insurers and providers.\n\n【9】For organizations that develop and endorse quality measures, the Universal Foundation will identify CMS’s priority areas for measurement and reveal gaps. For example, although patient safety is a top priority for CMS and there are several well-developed safety measures used in hospitals, there is no patient-safety measure that is widely used in ambulatory settings. Another current gap is the lack of a measure of holistic well-being. The Universal Foundation will continue to evolve over time; as quality measurement improves or when quality goals within a category are met, CMS will consider replacing or removing measures. We also intend to move toward using more outcome and patient-reported measures and measures for which data can be collected and reported digitally. The CMS Innovation Center will continue to test new quality measures in models when such measures are appropriate given a particular model’s quality aims, while leveraging the Universal Foundation where possible. To promote the goal of alignment across programs, Universal Foundation measures will be prioritized before other measures addressing similar aspects of quality.\n\n【10】Looking ahead, CMS intends to move toward aligning measures while collecting feedback by means of listening sessions, requests for information and proposed rulemaking, and other interactions with the medical community and general public. We will incorporate this feedback into future iterations of the Universal Foundation. For Medicaid and the Children’s Health Insurance Program specifically, any changes to measure sets will be made in partnership with states and other stakeholders. CMS will also continue to engage in discussions about broader alignment of quality measures outside CMS, for instance as part of the Core Quality Measures Collaborative, state efforts, and the Health Care Payment Learning and Action Network, to identify future opportunities for alignment.\n\n【11】We believe that, by focusing providers’ attention, the Universal Foundation will result in higher-quality care for the more than 150 million Americans covered by our programs. But quality-measure alignment is just the first step; we cannot accomplish the enormous task of quality improvement and care transformation without a concerted effort among clinicians, provider organizations, insurers, community-based organizations, state and local governments, and patients. We hope that alignment focused on the Universal Foundation within CMS can also set the stage for alignment throughout the health care system, with improved outcomes being our collective North Star.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:57:15", "endTime": "2024/08/14 14:57:59", "cost": 44.724}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 22:57:59", "grab_time": "2024-08-13 22:57:15"}
{"id": 2234364, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "2ca1a359-00c3-45a9-812e-2bc9232abc78", "title": "Acute Neurologic Disorder from an Inhibitor of Fatty Acid Amide Hydrolase", "text": "【0】Acute Neurologic Disorder from an Inhibitor of Fatty Acid Amide Hydrolase\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】A decrease in fatty acid amide hydrolase (FAAH) activity increases the levels of endogenous analogues of cannabinoids, or endocannabinoids. FAAH inhibitors have shown analgesic and antiinflammatory activity in animal models, and some have been tested in phase 1 and 2 studies. In a phase 1 study, BIA 10-2474, an orally administered reversible FAAH inhibitor, was given to healthy volunteers to assess safety.\n\n【3】Methods\n-------\n\n【4】Single doses (0.25 to 100 mg) and repeated oral doses (2.5 to 20 mg for 10 days) of BIA 10-2474 had been administered to 84 healthy volunteers in sequential cohorts; no severe adverse events had been reported. Another cohort of participants was then assigned to placebo (2 participants) or 50 mg of BIA 10-2474 per day (6 participants). This report focuses on neurologic adverse events in participants in this final cohort. A total of 4 of the 6 participants who received active treatment consented to have their clinical and radiologic data included in this report.\n\n【5】Results\n-------\n\n【6】An acute and rapidly progressive neurologic syndrome developed in three of the four participants starting on the fifth day of drug administration. The main clinical features were headache, a cerebellar syndrome, memory impairment, and altered consciousness. Magnetic resonance imaging showed bilateral and symmetric cerebral lesions, including microhemorrhages and hyperintensities on fluid-attenuated inversion recovery and diffusion-weighted imaging sequences predominantly involving the pons and hippocampi. One patient became brain dead; the condition of two patients subsequently improved, but one patient had residual memory impairment, and the other patient had a residual cerebellar syndrome. One patient remained asymptomatic.\n\n【7】Conclusions\n-----------\n\n【8】An unanticipated severe neurologic disorder occurred after ingestion of BIA 10-2474 at the highest dose level used in a phase 1 trial. The underlying mechanism of this toxic cerebral syndrome remains unknown.\n\n【9】Introduction\n------------\n\n【10】A decrease in fatty acid amide hydrolase (FAAH) activity increases the levels of endogenous analogues of cannabinoids, or endocannabinoids.  FAAH inhibitors have shown analgesic and antiinflammatory activity in animal models,  and some have been tested for these purposes in phase 1 and phase 2 studies.  Phase 3 studies were not pursued owing to a lack of efficacy. BIA 10-2474, with the chemical name 3-(1-(cyclohexyl(methyl)carbamoyl)-1H-imidazol-4-yl)pyridine 1-oxide, is a new reversible FAAH inhibitor. A phase 1 study was conducted in healthy volunteers to explore the safety profile of BIA 10-2474. Five of the six participants who had received the highest cumulative dose had an acute and rapidly progressive neurologic syndrome. \n\n【11】Methods\n-------\n\n【12】Trial Conduct\n-------------\n\n【13】BIA 10-2474 was developed by Bial, a Portuguese pharmaceutical company. The research trial was conducted by Biotrial, a contract research organization that has been approved by the French Health Ministry. This was the first randomized, double-blind, placebo-controlled study of BIA 10-2474 involving humans. Sequential cohorts of 8 participants (6 assigned to the active agent and 2 assigned to placebo) were enrolled. A single ascending dose of BIA 10-2474 (0.25 mg, 1.25 mg, 2.5 mg, 5 mg, 10 mg, 20 mg, 40 mg, and 100 mg) had been administered to 48 healthy volunteers. A multiple ascending dose of BIA 10-2474 (2.5 mg for 10 days, 5 mg for 10 days, 10 mg for 10 days, and 20 mg for 10 days) had been administrated to 24 healthy volunteers. A total of 12 other participants, who were enrolled in an additional cohort to study food interaction, received 40 mg of BIA 10-2474. Therefore, BIA 10-2474 had been administered to 84 healthy volunteers between July 2015 and December 2015, and no serious adverse events had been reported. In January 2016, the fifth multiple-dose cohort of 8 participants was studied; 2 received placebo and 6 received 50 mg per day of BIA 10-2474. This report focuses on the adverse events in the patients in this final cohort.\n\n【14】Participants and Study Oversight\n--------------------------------\n\n【15】The trial was approved by the institutional review board of Brest on June 23, 2015. Written informed consent for participation in the trial was obtained from all the volunteers by Biotrial. Of the six participants who received active treatment in the final study cohort, three participants and the family of the deceased participant provided written informed consent for their inclusion in this report. Two participants who received active treatment in the final cohort of eight volunteers declined to be included in this report. This article thus reports on the clinical and radiologic findings of four of the six participants. They were transferred from the Biotrial clinical research facility to Centre Hospitalier Universitaire Hôpital Pontchaillou (Rennes University Hospital) after the occurrence of neurologic disorders (three participants) or for systematic monitoring (one participant).\n\n【16】During the past 5 years, in its capacity as a contract research organization, Biotrial had conducted research at Rennes University Hospital that involved the Departments of Neurology and Radiology (studies of mitoxantrone–interferon beta-1a and of biotin). Biotrial also provides financial support to Institut des Neurosciences Cliniques de Rennes, which funds academic research projects on brain diseases in Rennes. The authors of this report are employed by Rennes University Hospital but were not involved in the conduct of the phase 1 study of BIA 10-2474.\n\n【17】Results\n-------\n\n【18】Patients\n--------\n\n【19】The four patients who were transferred to Rennes University Hospital were previously healthy men, 27 to 49 years of age. No major clinical or surgical history and no history of drug abuse were reported at screening. They were taking no medication other than the study drug. At the time of the patients’ admission to the hospital, analyses for amphetamines, barbiturates, benzodiazepines, cannabinoids, cocaine, and opiates were negative. Two of the four patients had previously participated in phase 1 studies testing molecules that were not related to the endocannabinoid system.\n\n【20】Table 1. Clinical Data for the Four Patients. Table 2.  Table 2. Description of Magnetic Resonance Imaging Abnormalities in the Four Patients.\n\n【21】The first day of drug administration (day 1) was January 6, 2016; clinical follow-up extended to 55 days. A 50-mg dose of BIA 10-2474 was administered orally to each patient between 8 a.m. and  a.m. each day; Patient 1 received the drug for 5 consecutive days, and Patients 2, 3, and 4 for 6 consecutive days. The first serious adverse event was reported on day 5. Clinical and radiologic data are summarized in Table 1 and Table 2 .\n\n【22】Patient 1\n---------\n\n【23】At 11 a.m. on day 5, Patient 1 reported moderate blurred vision and floating specks. At  p.m., he reported moderate headache. When gait disturbance and slurred speech developed, he was transferred from the Biotrial clinical research facility to the emergency department of Rennes University Hospital at  p.m. The physician in the emergency department described moderate limb ataxia, which was worse on the left side, involving the arm and leg equally; moderate cerebellar dysarthria; and gaze-evoked and direction-changing nystagmus. The patient was awake and had no sensory loss, weakness, oculomotor paralysis, Babinski sign, reflex alteration, or memory defect. The temperature was 36.4°C, heart rate 62 beats per minute, blood pressure 149/89 mm Hg, and oxygen saturation 95% while the patient was breathing ambient air. A cranial computed tomographic (CT) scan and a CT angiogram were initially interpreted as normal. A subtle hypodensity in the pons could be seen, retrospectively. The complete blood count and blood levels of electrolytes, urea, creatinine, and C-reactive protein (CRP) were normal, as were the results of coagulation and liver-function tests. The patient received 160 mg of aspirin. At  a.m. on day 6, he suddenly became confused and agitated, and he had worse limb and postural ataxia with severe dysmetria, limb and truncal kinetic tremor, and an inability to sit up in bed.\n\n【24】Figure 1. Magnetic Resonance Imaging (MRI) Studies in Patient 1.\n\n【25】Panels A through F depict MRI studies from day 6, and Panels G through K depict studies from day 8. On day 6, MRI showed hyperintense lesions (thin arrows) on diffusion-weighted images in the pons (diffuse lesion; Panel A) and right hippocampus (punctate lesion; Panel D), microhemorrhages (thick arrows) on susceptibility-weighted images in the pons  and hippocampi , and pathologic hypersignal (arrowhead) on fluid-attenuated inversion recovery (FLAIR) images in the pons  and midbrain . On day 8, MRI showed worsening of lesions: hyperintense lesions on diffusion-weighted images involving mainly the cortex, external capsula, thalami  and the pons, hippocampi, amygdala, and mammillary bodies (not shown); microhemorrhages on susceptibility-weighted images in the hippocampi, amygdala, external capsula, all the basal ganglia, and the cortex ; and pathologic hypersignal on FLAIR images in the cortex, thalami , and the brain stem, hippocampi, and amygdala (not shown).\n\n【26】Magnetic resonance imaging (MRI)  showed hyperintensities in the pons and hippocampi on fluid-attenuated inversion recovery (FLAIR) and diffusion-weighted sequences, with multiple microhemorrhages in the pons. As the patient’s condition deteriorated further, he became unconscious (Glasgow Coma Scale score of 9, on a scale from 3 to 15, with lower scores indicating a reduced level of consciousness; the pupils were symmetric and reactive to light), and he required tracheal intubation and mechanical ventilation with sedation. The temperature became elevated to 38.2°C. The cerebrospinal fluid had 173 white cells per cubic millimeter (87% of which were neutrophils), a protein level of 353 mg per deciliter, and a glucose level of 4.58 mmol per liter; the serum glucose level was 8 mmol per liter (144 mg per deciliter). He received acyclovir, cefotaxime, and amoxicillin until cerebrospinal fluid studies for herpes simplex virus, varicella virus, and _Listeria monocytogenes_ were determined to be negative. Levels of antinuclear antibodies, complement, and ADAMTS13 (a disintegrin and metalloproteinase with a thrombospondin type 1 motif, member 13) were normal, and there were no signs of thrombotic microangiopathy.\n\n【27】On day 7, the patient’s heart rate was slower than 40 beats per minute, and he was hypotensive. A CT scan showed edema of the brain stem, hippocampi, and temporal lobes. On day 8, he had bilateral dilated and light-unreactive pupils. MRI showed diffuse hyperintense lesions on FLAIR and diffusion-weighted sequences and multiple microhemorrhages, mainly involving the brain stem, hippocampi, cortex, and thalamus. He was declared brain dead the following day. An autopsy was performed, but the results have not been made available to the authors.\n\n【28】Patient 2\n---------\n\n【29】Figure 2. MRI Studies in Patient 2.\n\n【30】A time series of diffusion-weighted images on day 7 , day 8 , and day 9  shows progressive worsening of hyperintense lesions in the hippocampi and amygdala. MRI on day 9  showed several moderate microhemorrhages (thick arrows) on susceptibility-weighted images in the median part of the pons  and in the hippocampi and amygdala  as well as pathologic hypersignal (arrowhead) on FLAIR images in the pons and anterior temporal lobe  and in the hippocampi and amygdala .\n\n【31】On day 7, Patient 2 began asking the same questions repeatedly about recent activities. He was transferred from the Biotrial clinical research facility to the emergency department of Rennes University Hospital. A neurologic examination was performed by the on-duty neurologist. The patient was incapable of encoding new facts, events, or names. Although the retrieval of information from years ago was relatively preserved, his memory for the previous 2 to 3 months was incomplete. He reported moderate headache. Brain MRI showed hippocampal and anterior pontine signal hyperintensities on diffusion-weighted sequences . The complete blood count and blood levels of electrolytes, urea, creatinine, and CRP were normal, as were the results of coagulation and liver-function tests.\n\n【32】On day 8, he had moderate dysarthria and moderate limb and gait ataxia (he was incapable of walking in a straight line). A second MRI scan showed hyperintense lesions on FLAIR and diffusion-weighted sequences and several microhemorrhages involving the pons and hippocampi. The patient received intravenous glucocorticoids from day 8 to day 12. On day 9, his condition was unchanged. A third MRI showed an increased number of microhemorrhages. His condition gradually improved, and at the last clinical follow-up, on day 55, his amnesic symptoms had lessened, but he had partial retrograde amnesia regarding the period from 2 months before to 1 month after administration of the drug and minimal anterograde amnesia. Dysarthria and ataxia were no longer evident. MRI showed that the diffusion-weighted hyperintensities had disappeared and that the FLAIR hyperintensities had partially regressed . The hippocampi had heterogeneous signal hyperintensities, and some focal hyperintensities were still visible in the pons on FLAIR images. No new lesion had appeared.\n\n【33】Patient 3\n---------\n\n【34】Figure 3. MRI Studies in Patient 3.\n\n【35】MRI on day 8 showed hyperintense lesions (thin arrows) on diffusion-weighted images in the pons , several microhemorrhages (thick arrows) on susceptibility-weighted images in the median pons , and pathologic hypersignal (arrowhead) on FLAIR images in the pons  and hippocampi . MRI on day 9 showed punctate hyperintense lesions (thin arrows) on diffusion-weighted images in the hippocampi and amygdala , worsening of existing microhemorrhages (thick arrows) on susceptibility-weighted images in the median pons  as well as new microhemorrhages in the hippocampi and amygdala , and pathologic hypersignal (arrowhead) on FLAIR images  in the pons, anterior part of the medulla oblongata, and the hippocampi (not shown).\n\n【36】On day 5, Patient 3 reported mild asthenia, headache, and dizziness, but repeated neurologic examinations performed by the physician at the Biotrial clinical research facility were normal. At  a.m. on day 8, he presented with a subacute gait disturbance, slurred speech, and a syncope. He was transferred from the Biotrial facility to the emergency department of Rennes University Hospital. A neurologic examination was performed by the on-duty neurologist. The patient was somnolent and had severe limb, gait, and postural ataxia (he was unable to walk or sit up in bed without assistance) and moderate dysarthria. No sensory or motor disturbances (including oculomotor paralysis) and no memory defects were found. Nystagmus (gaze-evoked and direction-changing) subsequently appeared. The headache ceased. The results of blood tests were normal. MRI showed hyperintensities on diffusion-weighted and FLAIR sequences in the brain stem (pons and medulla oblongata) and hippocampi and a focal microhemorrhage in the pons . The cerebrospinal fluid had a protein level of 1.13 g per liter but no white or red cells. He received intravenous glucocorticoids from day 8 to day 10. On day 9, the cerebellar syndrome was unchanged. On day 10, he had severe dysarthria and somnolence. He was given 1 g of intravenous cyclophosphamide.\n\n【37】His condition gradually improved beginning on day 11, and he could walk without assistance on day 13. At the last clinical follow-up on day 55, he was able to walk without assistance but had difficulty with tandem gait and had nystagmus on left lateral gaze. MRI showed that the diffusion-weighted and FLAIR hyperintensities in the medulla oblongata and hippocampi had disappeared . Focal hyperintensities were still visible in the pons on FLAIR images, as were microhemorrhages.\n\n【38】Patient 4\n---------\n\n【39】Patient 4 had moderate diarrhea on days 6 and 7. MRI scans on days 8 and 10 were normal, except for an asymptomatic cavernous malformation located in the brain stem. On day 55, he remained asymptomatic.\n\n【40】Discussion\n----------\n\n【41】The healthy volunteers described in this article participated in a phase 1 study of BIA 10-2474, a new FAAH inhibitor. They had received the highest cumulative dose (250 to 300 mg) administered to humans. A total of 84 healthy volunteers had previously received cumulative doses of up to 200 mg of BIA 10-2474. No clinical severe adverse event had been reported. The product contained in the capsules administered to all the volunteers was the same as that used for the toxicology studies, and assays confirmed that it was of high purity.  These data suggest that the toxic effects we observed were related to drug accumulation. This hypothesis is supported by the nonlinear pharmacokinetics of BIA 10-2474 for doses higher than 40 to 100 mg. \n\n【42】The clinical syndrome in these patients was an acute and rapidly progressive central nervous system disorder with limb, gait, and postural ataxia as well as dysarthria and nystagmus, all of which are compatible with a cerebellar syndrome; amnesia compatible with medial temporal amnesia; headache; and altered consciousness.\n\n【43】Consistent with these clinical signs and symptoms, the lesions on MRI involved mainly the pons and hippocampi, bilaterally and symmetrically. The cerebellar syndrome can be explained by lesions in the cerebellar peduncles of the crossing cerebellar fibers at the pontine and mesencephalic levels, because the cerebellum was not directly affected on MRI. Thalamic and cortical lesions were seen in Patient 1 and had radiologic characteristics that were similar to those of the pontine and hippocampal lesions; these findings suggest that a similar pathophysiological process took place that was restricted mostly to gray matter in many regions of the brain. The MRI findings included microhemorrhages on susceptibility-weighted images and hyperintensities on FLAIR and diffusion-weighted images. The diffusion hyperintensities may have been related to vasogenic or cytotoxic edema. The apparent diffusion coefficient usually helps to differentiate between vasogenic and cytotoxic edema. However, because the microhemorrhages disrupted the signal, apparent-diffusion-coefficient maps could not be reliably used to characterize the underlying mechanism.\n\n【44】The meningitis reported in Patient 1 may have been from severe brain-tissue injury, but it is possible that there was an inflammatory component to the toxic syndrome. No meningitis was found in the other patient who underwent a lumbar puncture and who had a milder form of the syndrome (Patient 3). The syndrome was partially reversible in Patients 2 and 3, and the potential benefit of early high-dose glucocorticoid infusion remains an open question. Long-term clinical and MRI follow-up of the surviving patients is planned. Because three of the four volunteers who had received the molecule presented with adverse events, a genetic susceptibility to these effects is improbable.\n\n【45】The atypical distribution of the brain lesions; the widespread, bilateral, and symmetric pattern of the injury; and the drug-accumulation–dependent toxic effects suggest direct toxicity of BIA 10-2474.  Nevertheless, the precise mechanism of this toxic cerebral syndrome is unknown. The distribution of the brain lesions does not exactly match the location of the endocannabinoid system.  Endocannabinoid receptors and FAAHs are highly expressed in the hippocampi but not in the pons. Moreover, severe toxic effects in the central nervous system as a result of an increased level of endocannabinoids have not been reported previously; this suggests the possibility of an off-target effect of the drug, owing to the low specificity of BIA 10-2474 for FAAH, or an effect of a metabolite.  These unanticipated severe adverse events were caused by the drug and reflect the complexities of clinical drug research.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 17:01:57", "endTime": "2024/08/13 17:03:20", "cost": 83.216}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 01:03:20", "grab_time": "2024-08-13 01:01:57"}
{"id": 2234363, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "e94980fa-4eaa-49aa-9d86-702ec84bea12", "title": "Prevalence of Hemochromatosis among 11,065 Presumably Healthy Blood Donors", "text": "【0】Prevalence of Hemochromatosis among 11,065 Presumably Healthy Blood Donors\nAbstract\n--------\n\n【1】There is evidence that iron loading and organ damage can be prevented in patients with hemochromatosis if prophylactic phlebotomy is employed early in the disease — findings emphasizing the importance of early detection before clinical signs occur. This study was designed to determine the efficacy of transferrin saturation as a screening tool for hemochromatosis and to assess the frequency of homozygosity for the HLA-linked hemochromatosis gene in a healthy population. We screened 11,065 presumably healthy blood donors (5840 men and 5225 women). Donors with transferrin saturations of 62 percent or more after an overnight fast were considered potential homozygotes and were asked to undergo liver biopsy and pedigree analysis.\n\n【2】The frequency of values for transferrin saturation of 62 or higher in men was 0.008 and in women 0.003. Thirty-eight persons with values higher than 62 were studied in detail; 35 underwent liver biopsy. Liver iron stores ranged from normal to markedly increased. Twelve siblings with an identical HLA match to a proband underwent liver biopsy, and 11 had increased liver iron stores. According to likelihood analysis of the pedigrees, 26 of the 38 probands were homozygotes, and 12 were heterozygotes.\n\n【3】The estimated frequency of homozygosity was based on the data in men, because the threshold value of 62 for the transferrin saturation identified only half as many female homozygotes as expected. The frequency of homozygosity was 0.0045, corresponding to a gene frequency of 0.067.\n\n【4】The value of population screening is demonstrated in these studies by the detection of homozygotes before clinical manifestations of hemochromatosis occur.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:41:29", "endTime": "2024/08/14 14:41:40", "cost": 10.887}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 22:41:39", "grab_time": "2024-08-13 22:41:28"}
{"id": 2234362, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "522a0d5c-97aa-4113-ad30-42507edbe60e", "title": "A Randomized Clinical Trial of Cyclosporine in Cadaveric Renal Transplantation", "text": "【0】A Randomized Clinical Trial of Cyclosporine in Cadaveric Renal Transplantation\nAbstract\n--------\n\n【1】In a randomized multicenter trial, 209 recipients of cadaveric renal transplants were treated either with cyclosporine and prednisone or with standard therapy that included azathioprine and prednisone. Predicted graft survival at one year was 80.4 per cent in patients receiving cyclosporine and 64.0 per cent in those receiving standard therapy (P = 0.003). Predicted patient survival at one year was 96.6 per cent in patients given cyclosporine and 86.4 per cent in those given standard therapy. A detrimental effect on predicted graft survival at one year was seen in patients treated with cyclosporine if they received kidneys that were perfused by machine for longer than 24 hours (70 vs. 88 per cent, P = 0.005) or if the time used to perform the surgical anastomosis was longer than 45 minutes (60 vs. 89 per cent, P = 0.002). In the group receiving standard therapy, predicted graft survival was better in patients who had had five or more blood transfusions than in those who had had two to four transfusions (77 vs. 55 per cent, P = 0.05). Serum creatinine was 2.6 mg per deciliter in patients receiving cyclosporine 90 days after transplantation and 2.0 mg per deciliter in those receiving standard therapy (P = 0.03). Lymphoma developed in one patient receiving cyclosporine.\n\n【2】We conclude that cyclosporine is preferable to azathioprine in preventing renal transplant rejection. Further studies will be required to determine the optimal regimen with this agent.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:43:27", "endTime": "2024/08/14 15:43:35", "cost": 8.107}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 23:43:35", "grab_time": "2024-08-13 23:43:27"}
{"id": 2234361, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "2c5b5939-3986-4706-bcc2-06b60f7f809d", "title": "Microvascular Injury in the Brains of Patients with Covid-19", "text": "【0】Microvascular Injury in the Brains of Patients with Covid-19\nTo the Editor:\n--------------\n\n【1】We conducted postmortem high-resolution magnetic resonance imaging (magnetic resonance microscopy) of the brains of patients with coronavirus disease 2019 (Covid-19) (median age, 50 years) and histopathological examination that focused on microvascular changes in the olfactory bulb and brain stem.  Images were obtained from the brains of 13 patients with the use of an 11.7-Tesla scanner at a resolution of 25 μm for the olfactory bulb and at a resolution of 100 μm for the brain. Abnormalities were seen in the brains of 10 patients. We examined the brains of patients that showed abnormalities by means of multiplex fluorescence imaging (in 5 patients) and by means of chromogenic immunostaining (in 10 patients). We performed conventional histopathological examination of the brains of 18 patients. Fourteen patients had chronic illnesses, including diabetes and hypertension, and 11 had been found dead or had died suddenly and unexpectedly. Of the 16 patients with available medical histories, 1 had delirium, 5 had mild respiratory symptoms, 4 had acute respiratory distress syndrome, 2 had pulmonary embolism, and the symptoms were not known in 3 .\n\n【2】Figure 1. Pathological Studies of Microvascular Injury in the Brains of Patients Who Died from Covid-19.\n\n【3】Panel A (magnetic resonance microscopy of the olfactory bulb) shows an area of hyperintense signal (arrow). Panel B shows the corresponding area on multiplex immunofluorescence imaging, which revealed a focal area of fibrinogen leakage (in the box, fibrinogen is shown in green, collagen IV is shown in yellow, and nuclei are shown in blue). Panel B1 shows diffuse leakage of fibrinogen in the parenchyma (an enlarged view showing marked blood vessel staining for collagen IV is shown in Panel B2). Panel B2 (collagen IV immunostaining) shows intact (arrowhead) and thinned (arrow) basal lamina with fibrinogen leakage into the parenchyma. Panel C shows magnetic resonance microscopy of the pons, and Panel D (fibrinogen staining) shows areas of increased signal intensity corresponding to the vascular leakage visible on magnetic resonance microscopy. The arrows and the area within the dashed lines in Panels C and D indicate the vascular leakage. Panels A through E represent imaging performed in Patient IA1. Panel E (collagen IV immunostaining) shows areas of fibrinogen leakage in blood vessels in Patient IA1. Panel F shows magnetic resonance microscopy of the medulla in Patient IA3. The yellow arrows indicate linear hypointense signals, and the red arrows indicate linear hyperintense signals. Panel G shows CD68+ perivascular macrophages in the pons in Patient NY6. Panel H shows perivascular astrocytosis in the basal ganglia in Patient NY5. Panel I shows perivascular CD3+ cells in the cerebellum in Patient IA1. Panel J shows intraluminal and perivascular CD8+ cells in the pons in Patient NY6. Panel K shows perineuronal IBA1 cells in the pons in Patient NY6. Panel L shows CD68+ cells in the dorsal motor nucleus of the vagus nerve in Patient IA1. Panel M shows a solitary nucleus in the medulla and Panel N shows a pre-Bötzinger complex in Patient IA1. (Diaminobenzidine staining was used in Panels G through N.)\n\n【4】Magnetic resonance microscopy showed punctate hyperintensities in 9 patients, which represented areas of microvascular injury and fibrinogen leakage. These features were observed on corresponding histopathological examination performed with the use of fluorescence imaging . These areas showed thinning of the basal lamina of the endothelial cells, as determined by collagen IV immunostaining in 5 patients . Punctate hypointensities on imaging in 10 patients corresponded to congested blood vessels  with surrounding areas of fibrinogen leakage  and relatively intact vasculature . Areas of linear hypointensities were interpreted as microhemorrhages . There was minimal perivascular inflammation in the specimens examined, but there was no vascular occlusion, as previously described in the _Journal_ .  Perivascular-activated microglia, macrophage infiltrates, and hypertrophic astrocytes were seen in 13 patients .  There were CD3+ and CD8+ T cells in the perivascular spaces and in lumens adjacent to endothelial cells in 8 patients, which may have contributed to vascular injury , as suggested in a previous report.  Activated microglia were found adjacent to neurons in 5 patients, which is suggestive of neuronophagia in the olfactory bulb, substantia nigra, dorsal motor nucleus of the vagal nerve, and the pre-Bötzinger complex in the medulla, which is involved in the generation of spontaneous rhythmic breathing .\n\n【5】Severe acute respiratory syndrome coronavirus 2 was not detected by means of polymerase chain reaction with multiple primer sets, RNA sequencing of several areas of the brain, or RNA in situ hybridization and immunostaining . It is possible that the virus was cleared by the time of death or that viral copy numbers were below the level of detection by our assays.\n\n【6】In a convenience sample of patients who had died from Covid-19, multifocal microvascular injury was observed in the brain and olfactory bulbs by means of magnetic resonance microscopy, histopathological evaluation, and immunohistochemical analysis of corresponding sections, without evidence of viral infection. These findings may inform the interpretation of changes observed on magnetic resonance imaging of punctate hyperintensities and linear hypointensities in patients with Covid-19. Because of the limited clinical information that was available, no conclusions can be drawn in relation to neurologic features of Covid-19.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 16:00:04", "endTime": "2024/08/13 16:01:32", "cost": 87.291}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 00:01:32", "grab_time": "2024-08-13 00:00:04"}
{"id": 2234360, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "551ce07b-4a16-405d-81ea-b2b8996c90ed", "title": "Immunogenicity and Safety of Beta-Adjuvanted Recombinant Booster Vaccine", "text": "【0】Immunogenicity and Safety of Beta-Adjuvanted Recombinant Booster Vaccine\nTo the Editor:\n--------------\n\n【1】The value of variant-adapted vaccines that are capable of inducing a higher and broader immune response against severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) at booster vaccination is currently being evaluated.  We conducted a multicenter, randomized, single-blind trial to assess the immunogenicity and safety of two adjuvanted recombinant vaccines and the messenger RNA (mRNA) vaccine BNT162b2 (Pfizer–BioNTech) administered as a booster .\n\n【2】We randomly assigned adults with no previous diagnosis of coronavirus disease 2019 (Covid-19) who had received primary vaccination with two doses of BNT162b2 (with the second dose received between 3 and 7 months earlier) to receive booster vaccination with one of the following: a third dose of BNT162b2, a dose of the Sanofi–GSK SARS-CoV-2 adjuvanted recombinant protein MVD614 vaccine (monovalent formulation based on the original strain), or a dose of the SARS-CoV-2 adjuvanted recombinant protein MVB.1.351 vaccine (monovalent beta formulation; beta-adjuvanted vaccine). The primary end point was the percentage of participants who had an increase in the neutralizing-antibody titer by a factor of at least 10 between day 0 and day 15 after receipt of the booster as measured by microneutralization against the original D614 (wild-type) strain of SARS-CoV-2 or the B.1.351 (beta) variant. The primary end point was assessed in the per-protocol population, which included all the participants who underwent randomization and did not meet any of the exclusion criteria . The main other prespecified immunologic end points were the rate of increase between day 0 and day 15 in neutralizing-antibody titers against the original D614 strain and the beta, B.1.617.2 (delta), and B.1.1.529 (omicron) BA.1 variants; the geometric mean of anti-spike (anti-S1) IgG levels; and interferon-γ– and interleukin-2–secreting CD4+ T-cell response against the original strain and the omicron variant in each randomized group.\n\n【3】Among the 247 participants who underwent randomization between December 8, 2021, and January 14, 2022, a total of 24 participants were excluded, mainly owing to preexisting immunity against SARS-CoV-2. The per-protocol population included 223 participants: 76 in the MVD614 group, 71 in the MVB.1.351 group, and 76 in the BNT162b2 group . The mean age of the participants was 40.6 years, and 40% were women. The baseline characteristics of the participants did not differ among the trial groups .\n\n【4】The percentage of participants who had an increase in the neutralizing-antibody titer by a factor of at least 10 between day 0 and day 15 for the original strain was 55% (95% confidence interval \\[CI\\], 43 to 67) in the MVD614 group, 76% (95% CI, 64 to 85) in the MVB.1.351 group, and 63% (95% CI, 51 to 74) in the BNT162b2 group. For the beta variant, the corresponding percentages were 45% (95% CI, 33 to 57), 85% (95% CI, 74 to 92), and 51% (95% CI, 40 to 63).\n\n【5】Figure 1. Neutralizing Antibodies against Wild-type SARS-CoV-2 and the Beta, Delta, and Omicron BA.1 Variants at Days 0 and 15 after Receipt of a Third Vaccine Dose (Per-Protocol Population).\n\n【6】Shown are geometric mean titers (GMTs) of neutralizing antibodies against the original D614 (wild-type) strain of the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) and the beta (B.1.351), delta (B.1.617.2), and omicron (B.1.1.529) BA.1 variants, as assessed at days 0 and 15 after the receipt of a third vaccine dose (booster). Participants who had received two doses of the BNT162b2 vaccine were randomly assigned to receive one of the following as a booster dose: the MVD614 vaccine (monovalent parental formulation), the MVB.1.351 vaccine (beta-adjuvanted formulation), or a third dose of the BNT162b2 vaccine. The per-protocol population included all the participants who underwent randomization and did not meet any of the exclusion criteria. The factor increases in each trial group are shown for the change from day 0 to day 15. 𝙸 bars indicate 95% confidence intervals, and circles the titers in individual participants. The dashed line represents the positivity threshold on the neutralization assay.\n\n【7】The MVB.1.351 vaccine elicited higher neutralizing-antibody titers than the other vaccines against the original strain and against the beta, delta, and omicron BA.1 variants . The geometric mean titer of anti-S1 increased from 277.1 binding antibody units (BAU) per milliliter at day 0 to 1875.1 BAU per milliliter at day 15 in the MVD614 group, from 206.8 to 2240.8 BAU per milliliter in the MVB.1.351 group, and from 253.6 to 2405.4 BAU per milliliter in the BNT162b2 group . The MVB.1.351 vaccine also induced high levels of specific polyfunctional CD4+ type 1 helper T-cell response . The reactogenicity profiles of the three booster vaccines did not differ among the trial groups .\n\n【8】Over the short term, heterologous boosting with the beta-adjuvanted MVB.1.351 vaccine resulted in a higher neutralizing-antibody response against the beta variant as well as against the original strain and the delta and omicron BA.1 variants than did the mRNA vaccine BNT162b2 or the MVD614 formulation. The use of new vaccines that contain beta spike protein may be an interesting strategy for broader protection against SARS-CoV-2 variants.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 16:31:46", "endTime": "2024/08/13 16:33:45", "cost": 118.762}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 00:33:45", "grab_time": "2024-08-13 00:31:46"}
{"id": 2234359, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "6d2c1cd3-3391-4ebb-aa7e-c723c6b42f99", "title": "Case 21-2021: A 33-Year-Old Pregnant Woman with Fever, Abdominal Pain, and Headache", "text": "【0】Case 21-2021: A 33-Year-Old Pregnant Woman with Fever, Abdominal Pain, and Headache\nA 33-year-old pregnant woman with ulcerative colitis presented at 10 weeks of gestation with fever, nausea, vomiting, abdominal pain, and headache. On hospital day 3, the systolic blood pressure declined to 70 mm Hg. Three weeks earlier, the patient had had an ulcerative colitis flare; methylprednisolone and mesalamine were administered. A diagnosis was made.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:07:14", "endTime": "2024/08/14 15:07:21", "cost": 7.505}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 23:07:21", "grab_time": "2024-08-13 23:07:13"}
{"id": 2234358, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "858f3960-8356-4cb3-917e-f3ab9cde28af", "title": " Mutation and Atypical Femoral Fractures with Bisphosphonates", "text": "【0】 Mutation and Atypical Femoral Fractures with Bisphosphonates\nTo the Editor:\n--------------\n\n【1】Atypical femoral fractures have been associated with long-term bisphosphonate treatment.  However, the underlying mechanisms remain obscure. We studied three sisters who had atypical femoral fractures after receiving various oral bisphosphonates for 6 years. Two of the sisters had a single fracture (at the ages of 64 and 73 years), and one had bilateral fractures (one at the age of 60 years and the other at the age of 61 years). Given the low incidence of atypical femoral fractures in the general population (5.9 per 10,000 person-years),  we hypothesized that these sisters might have an underlying genetic background that contributed to these fractures.\n\n【2】Figure 1. High Degree of Conservation of the Relevant Amino Acid Sequence of GGPPS in Multiple Species.\n\n【3】Shown is the alignment of the region containing the D188 residue (arrow) in geranylgeranyl pyrophosphate synthase protein encoded by _GGPS1_ in different species. This mutation would be expected to severely impair enzyme activity by disrupting a Mg <sup>2+ </sup> binding site that is critical for binding of the farnesyl pyrophosphate substrate and for catalysis.  This mutation would be expected to disrupt the α-helix secondary structure (shown above the corresponding sequences). The numbers after each species indicate the first identified residue of the corresponding protein.\n\n【4】We performed whole-exome sequencing to detect possible shared genetic variants involved in their apparent increased risk. In addition, we performed whole-exome sequencing in three unrelated patients with atypical femoral fractures who each had received bisphosphonates for more than 5 years. We prioritized rare nonsynonymous mutations in the variant filtering, and only mutations that were shared among the three sisters were considered. No mutation was found to be homozygous or in any gene containing mutations in both chromosomes (compound heterozygous). Assuming that a dominant model was involved, we detected 37 rare mutations (in 34 genes), among them a novel p.Asp188Tyr substitution in the enzyme geranylgeranyl pyrophosphate synthase (GGPPS), which is a site of inhibition by bisphosphonates in the mevalonate pathway.  The variant that is located in the genomic position g.235505746G→T on chromosome 1 (GRCh37/hg19) in _GGPS1_ had the best conservation score and was not described in any of the available databases. This variant would be expected to severely impair the enzyme activity . Furthermore, the gene encoding cytochrome P-450 family 1 subfamily A member 1 ( _CYP1A1_ ), which is involved in steroid metabolism, was also mutated in all three sisters and in one of the unrelated patients, which suggests that it could be another potential susceptibility gene for bisphosphonate-related atypical femoral fractures. An additional mutation in the gene encoding mevalonate diphosphate decarboxylase ( _MVD_ ) was detected in one unrelated patient.\n\n【5】Pathway analysis of the mutated genes showed enrichment of the isoprenoid biosynthetic pathway (GO:0008299), which includes _GGPS1, CYP1A1,_ and _MVD_ (P<0.001). We speculate that other variants that have been identified might also be involved in susceptibility to bisphosphonate-related atypical femoral fractures. Such variants include missense changes in the gene encoding fibronectin 1 ( _FN1_ ) and in the genes encoding synapse defective Rho GTPase homolog 2 ( _SYDE2_ ) and neuronal guanine nucleotide exchange factor ( _NGEF_ ); the latter two proteins are regulators of small GTPases. We speculate that our results may support a model in which accumulation of susceptibility variants (including some in relevant genes, notably _GGPS1_ ) may lead to a possible genetic component of predisposition to atypical femoral fractures.\n\n【6】Neus Roca-Ayats, M.Sc.  \nCentro de Investigación Biomédica en Red de Enfermedades Raras (CIBERER), Barcelona, Spain", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "【6】Neus Roca-Ayats, M.Sc.\n\nCentro de Investigación Biomédica en Red de Enfermedades Raras (CIBERER), Barcelona, Spain", "content": "【0】 Mutation and Atypical Femoral Fractures with Bisphosphonates\nTo the Editor:\n--------------\n\n【1】Atypical femoral fractures have been associated with long-term bisphosphonate treatment.  However, the underlying mechanisms remain obscure. We studied three sisters who had atypical femoral fractures after receiving various oral bisphosphonates for 6 years. Two of the sisters had a single fracture (at the ages of 64 and 73 years), and one had bilateral fractures (one at the age of 60 years and the other at the age of 61 years). Given the low incidence of atypical femoral fractures in the general population (5.9 per 10,000 person-years),  we hypothesized that these sisters might have an underlying genetic background that contributed to these fractures.\n\n<mark>【2】Figure 1. </mark>High Degree of Conservation of the Relevant Amino Acid Sequence of GGPPS in Multiple Species.\n\n【3】Shown is the alignment of the region containing the D188 residue (arrow) in geranylgeranyl pyrophosphate synthase protein encoded by _GGPS1_ in different species. This mutation would be expected to severely impair enzyme activity by disrupting a Mg <sup>2+ </sup> binding site that is critical for binding of the farnesyl pyrophosphate substrate and for catalysis.  This mutation would be expected to disrupt the α-helix secondary structure (shown above the corresponding sequences). The numbers after each species indicate the first identified residue of the corresponding protein.\n\n【4】We performed whole-exome sequencing to detect possible shared genetic variants involved in their apparent increased risk. In addition, we performed whole-exome sequencing in three unrelated patients with atypical femoral fractures who each had received bisphosphonates for more than 5 years. We prioritized rare nonsynonymous mutations in the variant filtering, and only mutations that were shared among the three sisters were considered. No mutation was found to be homozygous or in any gene containing mutations in both chromosomes (compound heterozygous). Assuming that a dominant model was involved, we detected 37 rare mutations (in 34 genes), among them a novel p.Asp188Tyr substitution in the enzyme geranylgeranyl pyrophosphate synthase (GGPPS), which is a site of inhibition by bisphosphonates in the mevalonate pathway.  The variant that is located in the genomic position g.235505746G→T on chromosome 1 (GRCh37/hg19) in _GGPS1_ had the best conservation score and was not described in any of the available databases. This variant would be expected to severely impair the enzyme activity . Furthermore, the gene encoding cytochrome P-450 family 1 subfamily A member 1 ( _CYP1A1_ ), which is involved in steroid metabolism, was also mutated in all three sisters and in one of the unrelated patients, which suggests that it could be another potential susceptibility gene for bisphosphonate-related atypical femoral fractures. An additional mutation in the gene encoding mevalonate diphosphate decarboxylase ( _MVD_ ) was detected in one unrelated patient.\n\n【5】Pathway analysis of the mutated genes showed enrichment of the isoprenoid biosynthetic pathway (GO:0008299), which includes _GGPS1, CYP1A1,_ and _MVD_ (P<0.001). We speculate that other variants that have been identified might also be involved in susceptibility to bisphosphonate-related atypical femoral fractures. Such variants include missense changes in the gene encoding fibronectin 1 ( _FN1_ ) and in the genes encoding synapse defective Rho GTPase homolog 2 ( _SYDE2_ ) and neuronal guanine nucleotide exchange factor ( _NGEF_ ); the latter two proteins are regulators of small GTPases. We speculate that our results may support a model in which accumulation of susceptibility variants (including some in relevant genes, notably _GGPS1_ ) may lead to a possible genetic component of predisposition to atypical femoral fractures.\n\n【6】Neus Roca-Ayats, M.Sc.  \nCentro de Investigación Biomédica en Red de Enfermedades Raras (CIBERER), Barcelona, Spain", "index": 3877, "show": true, "start": 3864, "end": 3981, "province": ["文本干净度", "无关文本"], "isEdit": false}]}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-14 00:22:12", "grab_time": "2024-08-13 23:29:11"}
{"id": 2234357, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "1af8b65c-ef23-407b-a35c-9942944e3aa9", "title": "ABT-450/r–Ombitasvir and Dasabuvir with or without Ribavirin for HCV", "text": "【0】ABT-450/r–Ombitasvir and Dasabuvir with or without Ribavirin for HCV\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】The interferon-free regimen of ABT-450 with ritonavir (ABT-450/r), ombitasvir, and dasabuvir with or without ribavirin has shown efficacy in inducing a sustained virologic response in a phase 2 study involving patients with hepatitis C virus (HCV) genotype 1 infection. We conducted two phase 3 trials to examine the efficacy and safety of this regimen in previously untreated patients with HCV genotype 1 infection and no cirrhosis.\n\n【3】Methods\n-------\n\n【4】We randomly assigned 419 patients with HCV genotype 1b infection (PEARL-III study) and 305 patients with genotype 1a infection (PEARL-IV study) to 12 weeks of ABT-450/r–ombitasvir (at a once-daily dose of 150 mg of ABT-450, 100 mg of ritonavir, and 25 mg of ombitasvir), dasabuvir (250 mg twice daily), and ribavirin administered according to body weight or to matching placebo for ribavirin. The primary efficacy end point was a sustained virologic response (an HCV RNA level of <25 IU per milliliter) 12 weeks after the end of treatment.\n\n【5】Results\n-------\n\n【6】The study regimen resulted in high rates of sustained virologic response among patients with HCV genotype 1b infection (99.5% with ribavirin and 99.0% without ribavirin) and among those with genotype 1a infection (97.0% and 90.2%, respectively). Of patients with genotype 1b infection, 1 had virologic failure, and 2 did not have data available at post-treatment week 12. Among patients with genotype 1a infection, the rate of virologic failure was higher in the ribavirin-free group than in the ribavirin group (7.8% vs. 2.0%). In both studies, decreases in the hemoglobin level were significantly more common in patients receiving ribavirin. Two patients (0.3%) discontinued the study drugs owing to adverse events. The most common adverse events were fatigue, headache, and nausea.\n\n【7】Conclusions\n-----------\n\n【8】Twelve weeks of treatment with ABT-450/r–ombitasvir and dasabuvir without ribavirin was associated with high rates of sustained virologic response among previously untreated patients with HCV genotype 1 infection. Rates of virologic failure were higher without ribavirin than with ribavirin among patients with genotype 1a infection but not among those with genotype 1b infection. \n\n【9】Introduction\n------------\n\n【10】Hepatitis C virus (HCV) infection is a worldwide health issue, with 3 million to 4 million new infections yearly and infection rates as high as 5% in some countries.  Chronic infection leads to liver disease, cirrhosis, or liver cancer in a large proportion of infected persons, and hepatitis C accounts for 25% of all liver cancers, representing the leading indication for liver transplantation.  Genotype 1 is the most common HCV genotype worldwide and includes 11 subgenotypes, of which 1a and 1b are responsible for the vast majority of infections.  Genotype 1b infection is the most prevalent form worldwide, particularly in Europe and East Asia, whereas genotype 1a infection is more prevalent in North America. \n\n【11】Approved treatments for HCV genotype 1 infection include peginterferon and ribavirin combined with a direct-acting antiviral agent.  Peginterferon is associated with substantial adverse events, including influenza-like symptoms, depression, fatigue, and cytopenias that make it difficult for patients to adhere to treatment.  Cure rates for genotype 1a and 1b infection may differ depending on the treatment regimen; rates are generally lower among patients with genotype 1a infection when the treatment regimen includes an NS3 protease inhibitor or an NS5A replication complex inhibitor  and among patients with genotype 1b infection when the regimen includes the nucleotide analogue sofosbuvir.  Data suggest that genotype 1a infection is more difficult to cure than genotype 1b infection owing to the development of resistance.  Thus, careful assessment of the efficacy of individual regimens in patients with different subgenotypes of HCV infection is warranted.\n\n【12】Ribavirin is an important component of peginterferon-based therapy with first-generation protease inhibitors, but phase 2 clinical trials of interferon-free regimens based on direct-acting antiviral agents suggest that ribavirin may not always be required.  Although ribavirin appears to have less toxicity in the absence of peginterferon,  ribavirin is teratogenic and is associated with hemolytic anemia. Therefore, identifying patients who could be successfully treated without ribavirin is of great importance.\n\n【13】ABT-450, an inhibitor of the HCV nonstructural 3/4A (NS3/4A) protease, is administered with ritonavir (ABT-450/r) to increase ABT-450 plasma levels and half-life, permitting once-daily dosing.  Ombitasvir (ABT-267) is an inhibitor of the HCV NS5A replication complex, and dasabuvir (ABT-333) is a nonnucleoside NS5B polymerase inhibitor. All three agents have potent activity against HCV genotype 1 in vitro.  In a randomized, controlled, phase 2b study, a regimen of ABT-450/r, ombitasvir, and dasabuvir with ribavirin, administered for 12 weeks, was efficacious in previously untreated patients with HCV genotype 1 infection.  In addition, all 25 patients with genotype 1b infection who were treated without ribavirin had undetectable HCV RNA levels 24 weeks after the end of therapy.\n\n【14】On the basis of these data, two separate phase 3 trials were designed to evaluate the role of ribavirin in the treatment of patients with genotype 1a or 1b infection. We assessed the efficacy and safety of a 12-week treatment regimen of coformulated ABT-450/r–ombitasvir and dasabuvir with or without ribavirin in previously untreated patients without cirrhosis who had HCV genotype 1a infection (PEARL-IV study) or genotype 1b infection (PEARL-III study). The double-blind, placebo-controlled design of these studies permitted a thorough assessment of the contribution of ribavirin to the adverse-event profile of the combination regimen.\n\n【15】Methods\n-------\n\n【16】Patients\n--------\n\n【17】Patients 18 to 70 years of age were eligible for enrollment if they had chronic HCV genotype 1 infection with an HCV RNA level of more than 10,000 IU per milliliter and had never received any antiviral treatment for HCV. Patients with genotype 1a infection were screened at 53 sites in Canada, the United States, and the United Kingdom (PEARL-IV study). Patients with genotype 1b infection were screened at 50 sites in Austria, Belgium, Hungary, Israel, Italy, Poland, Portugal, Romania, the Russian Federation, Spain, and the United States (PEARL-III study). For both studies, eligible patients had no evidence of cirrhosis as documented by means of a liver biopsy within the previous 24 months, transient elastography (FibroScan), or noninvasive assessment of serum markers (FibroTest). Patients were excluded if they had coinfection with human immunodeficiency virus or hepatitis B virus or if they had infection with any HCV genotype other than 1a (PEARL-IV study) or 1b (PEARL-III study).\n\n【18】Study Designs\n-------------\n\n【19】Figure 1. Study Designs.\n\n【20】Patients with hepatitis C virus (HCV) genotype 1a infection (PEARL-IV study) or genotype 1b infection (PEARL-III study) and no cirrhosis were randomly assigned to receive ribavirin (1000 or 1200 mg daily according to body weight) or matching placebo for 12 weeks. All patients received ABT-450 with ritonavir (ABT-450/r)–ombitasvir (at a once-daily dose of 150 mg of ABT-450, 100 mg of ritonavir, and 25 mg of ombitasvir) and dasabuvir (250 mg twice daily) for 12 weeks.\n\n【21】Patients in both studies were stratified according to _IL28B_ genotype (CC vs. non-CC) and randomly assigned in a  ratio (genotype 1a study) or a  ratio (genotype 1b study) to receive either ribavirin twice daily according to body weight (1000 mg daily if the body weight was <75 kg and 1200 mg daily if the body weight was ≥75 kg) or matching placebo for 12 weeks. All the patients received open-label ABT-450/r–ombitasvir (at a once-daily dose of 150 mg of ABT-450, 100 mg of ritonavir, and 25 mg of ombitasvir) and dasabuvir (250 mg twice daily) for 12 weeks . Visits were scheduled at weeks 0, 1, 2, 4, 6, 8, 10, and 12 of the treatment period, and patients were followed for 48 weeks after the treatment period. The investigators, patients, and study sponsor (AbbVie) were unaware of the treatment assignments and hemoglobin or hematocrit values. If a predefined toxicity criterion for hemoglobin values was met, all hematologic laboratory data were disclosed to the site investigator to allow for appropriate patient care. Additional details on study designs are provided in the Supplementary Appendix .\n\n【22】The studies were conducted in accordance with the International Conference on Harmonisation guidelines, applicable regulations, and guidelines governing clinical-study conduct and ethical principles that have their origin in the Declaration of Helsinki. All the patients provided written informed consent. The studies were designed by the study sponsor. The investigators and sponsor jointly conducted the study and gathered the data. The sponsor conducted the data analyses. All the authors signed a confidentiality agreement with the sponsor. The first draft of the manuscript was written by a sponsor-employed medical writer, with input from all the authors.\n\n【23】Efficacy and Safety Assessments\n-------------------------------\n\n【24】Details of the collection of plasma samples, HCV RNA measurement, virologic-failure criteria, resistance testing, and logistic-regression analyses of response predictors are available in the Supplementary Appendix . Adverse-event assessment and clinical laboratory testing were performed at each study visit during treatment and in the follow-up period. Adverse events were reported from the time of study-treatment initiation until 30 days after the last dose. Data on serious adverse events were collected throughout the study.\n\n【25】Efficacy End Points\n-------------------\n\n【26】The primary efficacy end point for both studies was a sustained virologic response (a plasma HCV RNA level of <25 IU per milliliter) 12 weeks after the end of treatment. The primary objective of both studies was to assess the noninferiority of the rate of sustained virologic response at post-treatment week 12 in each study group, as compared with the historical rate with telaprevir plus peginterferon–ribavirin among previously untreated patients with the corresponding HCV subgenotype. The historical rate was 72% among patients with genotype 1a infection (95% confidence interval \\[CI\\], 68 to 75) and 80% among those with genotype 1b infection (95% CI, 75 to 84) . Secondary efficacy objectives in each study were to assess the noninferiority of the sustained-virologic-response rate in the group that did not receive ribavirin as compared with the group that received ribavirin, the superiority of the rate at post-treatment week 12 in each group as compared with the historical rate with telaprevir plus peginterferon–ribavirin in the corresponding patient population, the percentage of patients in each group with a hemoglobin level below the lower limit of the normal range at the end of treatment, and the percentage of patients in each group with virologic failure during treatment or relapse after treatment.\n\n【27】Statistical Analysis\n--------------------\n\n【28】Efficacy analyses were performed in the modified intention-to-treat population, defined as all randomly assigned patients who received at least one dose of a study drug. For the analysis of whether the rate of sustained virologic response with the interferon-free regimen was noninferior to the historical rate with telaprevir plus peginterferon–ribavirin, a noninferiority margin of 10.5 percentage points was used. To establish that the rate with the interferon-free regimen was noninferior to the historical rate, the lower boundary of the 95% confidence interval (based on the normal approximation to the binomial distribution) had to exceed 73% for the genotype 1b study and 65% for the genotype 1a study. Superiority could be established if the lower boundary of the confidence interval for the interferon-free regimen was greater than the upper boundary of the confidence interval for the historical rate: 84% for the genotype 1b study and 75% for the genotype 1a study. The assessment of the noninferiority of the regimen without ribavirin as compared with the regimen with ribavirin was based on a noninferiority margin of 10.5 percentage points.  Details of the efficacy analyses, including the fixed-sequence testing plan for the primary and secondary end points, are provided in the Supplementary Appendix .\n\n【29】Safety analyses compared the rate of adverse events and laboratory abnormalities between treatment groups in each study with the use of Fisher's exact test. Sample-size determination is described in the Supplementary Appendix . SAS software for the UNIX operating system (SAS Institute) was used for all analyses. All statistical tests and all confidence intervals were two-sided, with a significance level of 0.05.\n\n【30】Results\n-------\n\n【31】Baseline Demographic and Clinical Characteristics\n-------------------------------------------------\n\n【32】Table 1. Baseline Demographic and Clinical Characteristics.\n\n【33】In the genotype 1a study, 305 of 436 screened patients underwent randomization and received at least one dose of a study drug . A total of 629 patients were screened for the genotype 1b study, of whom 419 underwent randomization and received at least one dose of a study drug. Baseline demographic and clinical characteristics were well balanced between the two groups in each study . The majority of patients in the genotype 1a study were enrolled in North America, whereas the majority of patients in the genotype 1b study were enrolled in Europe. Among patients enrolled in the United States, blacks accounted for 14.2% of patients in the genotype 1a study (35 of 247 patients) and 21.1% of patients in the genotype 1b study (20 of 95 patients).\n\n【34】Efficacy Outcomes\n-----------------\n\n【35】### _Genotype 1a Study_\n\n【36】Figure 2. Sustained Virologic Response at 12 Weeks after the End of Treatment.\n\n【37】The dashed horizontal lines indicate noninferiority thresholds, based on the historical rate of sustained virologic response with telaprevir plus peginterferon–ribavirin, for the genotype 1a study (65%) and genotype 1b study (73%). The solid horizontal lines indicate superiority thresholds, based on the historical rate with telaprevir plus peginterferon–ribavirin, for the genotype 1a study (75%) and genotype 1b study (84%). The I bars indicate 95% confidence intervals.\n\n【38】After 12 weeks of treatment with ABT-450/r–ombitasvir and dasabuvir in the genotype 1a study, 97 of 100 patients who received the antiviral regimen with ribavirin had a sustained virologic response at post-treatment week 12, for a rate of 97.0% (95% CI, 93.7 to 100); 185 of 205 patients who received the regimen without ribavirin had a sustained virologic response, for a rate of 90.2% (95% CI, 86.2 to 94.3) . Hence, the sustained-virologic-response rates for the regimens with and without ribavirin were both noninferior and superior to the historical rate with telaprevir plus peginterferon–ribavirin in previously untreated adults with HCV genotype 1a infection and no cirrhosis. The regimen without ribavirin did not meet the noninferiority criterion as compared with the regimen with ribavirin, because the lower boundary of the confidence interval for the difference (−6.8 percentage points \\[95% CI, −12.0 to −1.5\\]) crossed the noninferiority margin of 10.5 percentage points. In addition, the upper boundary of the confidence interval did not cross zero, indicating a significant difference between groups.\n\n【39】A total of 18 patients with genotype 1a infection had virologic failure, 16 of whom received the regimen without ribavirin. Of the 3 patients with genotype 1a infection who received the regimen with ribavirin and did not have a sustained virologic response, 2 had virologic failure (1 had a rebound in HCV RNA levels during treatment and 1 had a relapse after treatment), and 1 did not complete follow-up testing at post-treatment week 12. Of the 16 patients with genotype 1a infection who received the regimen without ribavirin and had virologic failure, 6 had a virologic rebound during treatment and 10 had a relapse after treatment. All the patients with a relapse received at least 11 weeks of treatment. Adherence to the dosing regimen for each study drug was greater than 95% for 16 of the 17 patients with virologic failure for whom data were available; 1 patient who received the antiviral regimen without ribavirin and had a virologic rebound took 88.5% of the planned ABT-450/r–ombitasvir doses and 90.8% of the planned dasabuvir doses. On the basis of logistic-regression analyses of baseline demographic and clinical characteristics, only _IL28B_ CC genotype, which has historically been associated with increased rates of response to treatment for HCV infection, was associated with an increased rate of sustained virologic response among patients with genotype 1a infection (P=0.03).\n\n【40】At the time of virologic failure, each of the 18 patients with genotype 1a infection and a virologic failure had at least one resistance-associated variant known to be selected by one of the three direct-acting antiviral agents included in the regimen. The most frequently detected variants in patients with virologic failure were D168V in NS3, M28T and Q30R in NS5A, and S556G in NS5B.\n\n【41】### _Genotype 1b Study_\n\n【42】In this study, 209 of the 210 patients who received the antiviral regimen with ribavirin had a sustained virologic response at post-treatment week 12, for a rate of 99.5% (95% CI, 98.6 to 100.0); 207 of the 209 patients who received the regimen without ribavirin had a sustained virologic response, for a rate of 99.0% (95% CI, 97.7 to 100.0). Thus, the sustained-virologic-response rates among patients who received ribavirin and those who did not were both noninferior and superior to the historical rate with telaprevir plus peginterferon–ribavirin among previously untreated adults with HCV genotype 1b infection and no cirrhosis. In addition, the sustained-virologic-response rate among patients who did not receive ribavirin was noninferior to the rate among those who received ribavirin (difference, −0.5 percentage points \\[95% CI, −2.1 to 1.1\\]).\n\n【43】Table 2. Sustained Virologic Response and Reasons for Nonresponse.\n\n【44】Only one patient with genotype 1b infection had virologic failure during treatment; this patient, who received the antiviral regimen with ribavirin, had a virologic rebound during treatment. The two patients who received the regimen without ribavirin and did not have a sustained virologic response completed treatment but did not complete follow-up testing at post-treatment week 12 . Owing to the high rates of sustained virologic response, there were no significant predictors of virologic failure.\n\n【45】Adverse Events\n--------------\n\n【46】Table 3. Adverse Events and Laboratory Abnormalities.\n\n【47】In both studies, adverse events were more frequently reported in the groups receiving antiviral regimens that contained ribavirin than in the groups that received the ribavirin-free regimen (P=0.03 in the genotype 1a study and P=0.003 in the genotype 1b study) . The most common adverse events reported in the two studies, headache and fatigue, did not differ significantly in either study between the group that received ribavirin and the group that did not receive it. Among other common adverse events, pruritus, nausea, and insomnia occurred at a higher frequency among patients who received ribavirin than among those who did not in one or both studies. The majority of adverse events in all treatment groups were mild; overall, two patients (both in the genotype 1a study) discontinued the study drugs owing to adverse events.\n\n【48】Serious adverse events occurred in eight patients in the genotype 1b study (four who received ribavirin and four who did not) and in four patients in the genotype 1a study (three who received ribavirin and one who did not). All patients with a serious adverse event had a sustained virologic response. Details of all serious adverse events are provided in Table S5 in the Supplementary Appendix .\n\n【49】Decreased Hemoglobin Levels\n---------------------------\n\n【50】Among the patients in the genotype 1a study who had a hemoglobin level within the normal range at baseline, 42.0% of patients who received the antiviral regimen with ribavirin and 3.9% of patients who received the ribavirin-free regimen had a hemoglobin level below the lower limit of the normal range at the end of treatment (P<0.001). Similarly, in the genotype 1b study, 51.2% of patients who received ribavirin had a low hemoglobin level at the end of treatment, as compared with 3.4% of patients who did not receive ribavirin (P<0.001). A hemoglobin level of less than 10 g per deciliter at any time during treatment occurred in 4.0% of patients with genotype 1a infection who received ribavirin and in 9.0% of patients with genotype 1b infection who received ribavirin but did not occur in any patients who received the ribavirin-free regimen . The ribavirin dose was reduced in accordance with the protocol because of a decreased hemoglobin level in 6 patients with genotype 1a infection who received ribavirin (6.0%) and in 16 patients with genotype 1b infection who received ribavirin (7.6%); all these patients had a sustained virologic response. Additional data on hemoglobin levels are provided in the Supplementary Appendix .\n\n【51】Other Laboratory Abnormalities\n------------------------------\n\n【52】In both studies, the proportions of patients with elevations in the serum level of bilirubin were higher in the groups that received the ribavirin-containing regimen than in the groups that received the ribavirin-free regimen . Elevated levels of indirect (unconjugated) bilirubin primarily accounted for the abnormalities in both studies. Mean bilirubin levels peaked 1 week after the start of study-drug treatment and stabilized or normalized thereafter; maximal observed bilirubin levels were 6.5 mg per deciliter (110 μmol per liter) in the genotype 1a study and 9.4 mg per deciliter (160 μmol per liter) in the genotype 1b study. Elevations in the bilirubin level were not associated with elevations in aminotransferase levels. Additional details on laboratory abnormalities are provided in the Supplementary Appendix .\n\n【53】Discussion\n----------\n\n【54】In two phase 3 studies (PEARL-III and PEARL-IV), 90.2 to 99.5% of previously untreated patients with HCV genotype 1 infection and no cirrhosis had a sustained virologic response after 12 weeks of treatment with ABT-450/r–ombitasvir and dasabuvir with or without ribavirin. Response rates in all treatment groups were superior to the historical response rate with a peginterferon-containing telaprevir-based regimen.  These findings suggest that in previously untreated patients with HCV infection and no cirrhosis, this 12-week regimen of three direct-acting antiviral agents is efficacious both with and without ribavirin.\n\n【55】We also assessed the contribution of ribavirin to the treatment response and safety profile of the regimen. The effect of ribavirin on the treatment response in patients with HCV genotype 1a infection differed from that in patients with genotype 1b infection. The inclusion of ribavirin did not significantly affect the sustained-virologic-response rate among patients with genotype 1b infection, because the rate was 99.0% in the group that did not receive ribavirin and 99.5% in the group that received it. Thus, in this patient population, the 12-week regimen of ABT-450/r–ombitasvir and dasabuvir resulted in similarly high rates of sustained virologic response with and without ribavirin, results that are consistent with those of a phase 2b study  and phase 3 studies  of this regimen. In contrast, although more than 90% of patients in each treatment group in the genotype 1a study had a sustained virologic response, the response rate in the group that that received the ribavirin-free regimen did not meet the criterion for noninferiority to the rate in the group that received the ribavirin-containing regimen owing to a higher rate of virologic failure with the ribavirin-free regimen. A total of 18 patients with genotype 1a infection had virologic failure, and only 2 of these patients received ribavirin. Hence, the use of ribavirin in this population appears to confer an additional benefit.\n\n【56】Regardless of whether the antiviral regimen included ribavirin, the rate of discontinuation of the study drugs owing to adverse events was low (<1%). As compared with the groups that did not receive ribavirin, the groups that did receive it had more adverse events, particularly pruritus, nausea, and insomnia — events that are known to be associated with ribavirin. In addition, laboratory abnormalities that have historically been associated with ribavirin — decreases in the hemoglobin level and increases in the total bilirubin level — were more common in the groups that received ribavirin. The pattern of bilirubin elevations across treatment regimens confirmed that the hyperbilirubinemic effect of ABT-450, an inhibitor of the bilirubin transporter OATP1B1, is enhanced by ribavirin-associated hemolysis. However, these abnormalities did not appear to affect the likelihood of treatment success and did not result in treatment discontinuation. Overall, the adverse events observed in these two phase 3 trials were consistent with those observed in past trials with these regimens.\n\n【57】Studies of direct-acting antiviral therapy have shown that these regimens can result in high rates of sustained virologic response. The role of and need for ribavirin in maximizing sustained-virologic-response rates in different patient populations remain incompletely characterized by clinical studies. Exploratory studies have shown sustained-virologic-response rates of 95% or higher when sofosbuvir is combined with other direct-acting antiviral agents (ledipasvir, daclatasvir, or simeprevir) with or without ribavirin, although these findings remain to be confirmed by larger trials.  Although these results suggest that sufficiently efficacious ribavirin-free treatments may obviate the need for ribavirin in some patients, larger studies will be needed to determine which patient populations may require ribavirin for the greatest chance of virologic cure.\n\n【58】The PEARL-III and PEARL-IV studies were double-blind, randomized trials with large samples and a broad geographic scope of enrollment. The patient populations were representative of typical North American or European populations with genotype 1a or 1b infection, the two most prevalent subgenotypes in North America, Asia, and Europe. Rates of premature discontinuation and loss to follow-up were low in both trials. A limitation of the studies was the inability to completely conceal the ribavirin and placebo assignments from patients and investigators because of the characteristic adverse events and laboratory abnormalities associated with ribavirin. In addition, the studies did not include previously treated patients or patients with cirrhosis, although this regimen with ribavirin was associated with a high rate of sustained virologic response in these patient populations in recent studies. \n\n【59】Although the two studies showed that premature discontinuation and serious adverse events were uncommon with the 12-week course of all-oral therapy that included ribavirin, as well as with the ribavirin-free regimen, some patients may benefit from a ribavirin-free treatment option, including patients with contraindications to ribavirin therapy, such as hemoglobinopathies and severe cardiac or pulmonary disease, and those with severe renal impairment. Given the known teratogenicity of ribavirin, a ribavirin-free regimen would also be preferable for some women of childbearing potential.\n\n【60】In conclusion, previously untreated patients with HCV genotype 1a or 1b infection and no cirrhosis who received ABT-450/r–ombitasvir and dasabuvir with or without ribavirin had high sustained-virologic-response rates that were superior to the historical response rate with peginterferon–ribavirin plus telaprevir. Although ribavirin did not improve the response in patients with genotype 1b infection, our findings suggest that ribavirin confers an additional benefit for patients with genotype 1a infection.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-14 00:19:43", "grab_time": "2024-08-13 23:18:34"}
{"id": 2234356, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "9737035a-0a6d-4470-a1ef-f808a2f6194e", "title": "On the \"Principles of the Heart\" and the Psychiatric Insights of Zen", "text": "【0】On the \"Principles of the Heart\" and the Psychiatric Insights of Zen\nAbstract\n\n【1】Two basic tenets of Zen Buddhism emphasize the importance of life in and with nature, and immersion of the individual in the family, the group and the community. A Japanese physician, Shomei Morita, has used these elements of Zen conduct to construct a form of psychotherapy. The Morita regimen discourages egocentric analysis, and every effort is made to have the patient immerse himself in nature and society. This approach to psychotherapy has no parallel in any Western psychiatric system.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:53:09", "endTime": "2024/08/14 14:53:20", "cost": 10.396}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 22:53:20", "grab_time": "2024-08-13 22:53:09"}
{"id": 2234355, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "a67116bf-7fbe-4741-8898-08906b5448a0", "title": "Defective Regulation of Inflammatory Mediators in Hodgkin's Disease — Supernormal Levels of Chemotactic-Factor Inactivator", "text": "【0】Defective Regulation of Inflammatory Mediators in Hodgkin's Disease — Supernormal Levels of Chemotactic-Factor Inactivator\nAbstract\n--------\n\n【1】Elevated levels of the chemotactic-factor inactivator, a naturally occurring regulator of inflammatory mediators, were found in the serums of nine patients with Hodgkin's disease. When these same serums were activated with the yeast particle zymosan, so as to generate chemotactic activity, considerably less chemotactic activity was found in the specimens from patients with Hodgkin's disease than in four similarly treated normal serums. Inactivator isolated from either serum of the patients or normal serum inactivated monocyte as well as neutrophil chemotactic factors. Inactivator in patients' serum was qualitatively similar to that isolated from normal human serum, but may not be functionally homogeneous. The elevated levels in serum of patients, together with inactivation of leukotactic factors that are complement-derived, complement-independent and lymphocyte-derived, suggest that patients with Hodgkin's disease have a generalized defect in the ability to mobilize inflammatory cells.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:03:08", "endTime": "2024/08/14 15:03:18", "cost": 10.663}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 23:03:18", "grab_time": "2024-08-13 23:03:07"}
{"id": 2234354, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "6d0e5205-06c7-4877-b4be-a52b497bc46d", "title": "Treatment of Congenital Osteopetrosis with High-Dose Calcitriol", "text": "【0】Treatment of Congenital Osteopetrosis with High-Dose Calcitriol\nAbstract\n--------\n\n【1】We administered high doses of calcitriol (up to 32 μg per day) to an infant with malignant osteopetrosis, in an attempt to stimulate bone resorption. The patient was placed on a low-calcium diet to prevent hypercalcemia. Measures of bone turnover increased during calcitriol therapy; hydroxyproline excretion rose from 140 to 1358 μg per milligram of creatinine per 24 hours, with parallel increases in the ratio of calcium to creatinine in the urine, urinary gamma-carboxyglutamic acid, serum osteocalcin, and serum alkaline phosphatase. A pretreatment bone-biopsy specimen contained no osteoclasts with ruffled borders, a feature of active osteoclasts. After 11 days of calcitriol, ruffled borders were noted. After three months, numerous osteoclasts with ruffled borders and associated bony disruption were evident. Before therapy, the patient's monocytes were incapable of in vitro bone resorption, but after calcitriol, their resorptive capacity was increased to 3.3 times control levels. These data demonstrate that calcitriol increased bone mineral and matrix turnover in our patient. However, during the three months of calcitriol therapy there was only slight clinical improvement in her severe disease. Early and sustained treatment with calcitriol may be useful in osteopetrosis.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 10:52:06", "endTime": "2024/08/14 10:54:26", "cost": 140.124}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 18:54:26", "grab_time": "2024-08-13 18:52:05"}
{"id": 2234353, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "f5157947-ad42-4332-b7c3-2e01ae34ff71", "title": "Demonstration of Collateral Arterial Flow after Interruption of Hepatic Arteries in Man", "text": "【0】Demonstration of Collateral Arterial Flow after Interruption of Hepatic Arteries in Man\nAbstract\n--------\n\n【1】After delineating hepatic arterial flow in 20 patients, we dispute the concept that hepatic arteries are end arteries. Selective arteriography shows retrohepatic arterial flow 10 hours after interruption of hepatic arteries. When either the right or the left hepatic artery is interrupted adjacent to the liver, intrahepatic translobar vessels establish flow in the ligated system. Such intrahepatic vessels between the right and left rami cannot be portrayed by cadaver liver perfusions, nor are they apparent on arteriograms of normal subjects.\n\n【2】If the common hepatic artery is interrupted, revascularization occurs through inferior phrenic, pancreaticoduodenal and intercalary de novo arteries. Hepatic necrosis after hepatic-artery ligation in man is rare if portal-vein flow and oxygenation are optimum until arterial flow is reconstituted. Complete dearterialization of the human liver cannot be accomplished by simple ligature or excision.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:53:12", "endTime": "2024/08/14 15:53:21", "cost": 9.085}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 23:53:21", "grab_time": "2024-08-13 23:53:11"}
{"id": 2234352, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "48e799e1-19cd-4a07-bec5-92c5ab275d57", "title": "Engineering for Grief", "text": "【0】Engineering for Grief\nAfter his mother’s death, a physician wondered how his father, a human process engineer who’d always relied on his wife to keep him grounded, would be able to process her death without her. But he engineered a way: “Listen. Don’t talk. Ask about them.”", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 11:01:09", "endTime": "2024/08/14 11:01:29", "cost": 20.351}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 19:01:29", "grab_time": "2024-08-13 19:01:08"}
{"id": 2234351, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "ea042a16-da4d-4ce7-ad04-c92c9fcda466", "title": "Inhibition of Megakaryopoiesis by Kell-Related Antibodies", "text": "【0】Inhibition of Megakaryopoiesis by Kell-Related Antibodies\nTo the Editor:\n--------------\n\n【1】Kell, one of the major red-cell groups in humans, comprises 22 antigens. These antigens are encoded by alleles on chromosome 7, including sets of antithetical antigens such as Kell (K) and Cellano (k), which differ by a single amino acid.  Anti-Kell antibodies have been shown to suppress the growth of erythroid progenitor cells in a semisolid culture system.  This finding has been linked to the reticulocytopenia that is usual in hemolytic disease of the newborn (erythroblastosis neonatorum) induced by anti-Kell antibodies.  We recently observed substantial thrombocytopenia in three fetuses with erythroblastosis fetalis due to anti-Kell antibodies (platelet counts, 70 × 10 <sup>9 </sup> per liter, 53 × 10 <sup>9 </sup> per liter, and 67 × 10 <sup>9 </sup> per liter). The mean (±SE) platelet count in these three fetuses was 63±5 × 10 <sup>9 </sup> per liter, as compared with a mean platelet count of 252±15 × 10 <sup>9 </sup> per liter in five fetuses with erythroblastosis fetalis induced by anti-D antibodies (P<0.005 by the t-test). In these fetuses, intrauterine cord blood was obtained between the 21st and 28th weeks of gestation.  We therefore studied the expression of Kell blood-group antigens on megakaryocytic progenitor cells from both cord blood and adult blood using a commercial semisolid in vitro culture system (MegaCult-C, Stem Cell Technologies, Vancouver, Canada) that supports the growth of megakaryocyte colony-forming units (CFU-MK). Because of the low frequency of persons with the K+k– phenotype (0.2 percent), we used only K–k+ blood samples.\n\n【2】Table 1. Growth of Megakaryocyte Colony-Forming Units Derived from Cord-Blood Mononuclear Cells from K–k+ Newborns in the Presence and Absence of Anti-k and Anti-K Antibodies.\n\n【3】In five experiments using cord-blood mononuclear cells from healthy K–k+ newborns, we observed a clear and dose-dependent inhibition of the growth of CFU-MK with the addition of 10 μl of human anti-k antibody per dish (titer, ; IgG, Diamed, Basel, Switzerland) . Not unexpectedly, the addition of 10 μl of human anti-K antibody per dish (titer, ; IgG, Diamed) had no effect on the growth of CFU-MK from these K– infants, suggesting specific inhibition by the anti-k antibody . Using peripheral-blood mononuclear cells from nine hematologically normal adults, we also found a significant inhibition of the growth of CFU-MK with the addition of 10 μl of anti-k antibody per dish (control value, 8.3±1.5 colonies per dish; value with the addition of anti-k antibody, 3.8±0.7 colonies per dish; P<0.005).\n\n【4】Our findings indicate that Kell blood-group antigens are expressed not only on erythroid progenitors but also on megakaryocyte progenitors. Therefore, antibody-mediated inhibition of progenitor cells may affect not only erythropoiesis in newborns with erythroblastosis neonatorum induced by anti-Kell antibodies, but also the formation of platelets, as we observed in three fetuses.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-14 00:21:56", "grab_time": "2024-08-13 23:27:24"}
{"id": 2234350, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "6a259afd-8441-4316-8083-f6f50c4f8cd6", "title": "Epidemiologic Features of Chronic Atrial Fibrillation — The Framingham Study", "text": "【0】Epidemiologic Features of Chronic Atrial Fibrillation — The Framingham Study\nAbstract\n--------\n\n【1】In the Framingham Study 2325 men and 2866 women 30 to 62 years old at entry were followed biennially over 22 years for the development of chronic atrial fibrillation in relation to antecedent cardiovascular disease and risk factors. During surveillance, atrial fibrillation developed in 49 men and 49 women.\n\n【2】The incidence rose sharply with age but did not differ significantly between the sexes. Overall, there was a 2.0 per cent chance that the disorder would develop in two decades. Atrial fibrillation usually followed the development of overt cardiovascular disease. Only 18 men and 12 women (31 per cent) had chronic atrial fibrillation in the absence of cardiovascular disease. Cardiac failure and rheumatic heart disease were the most powerful predictive precursors, with relative risks in excess of six-fold. Hypertensive cardiovascular disease was the most common antecedent disease, largely because of its frequency in the general population. Among the risk factors for cardiovascular disease, diabetes and electrocardiographic evidence of left ventricular hypertrophy were related to the occurrence of atrial fibrillation. The development of chronic atrial fibrillation was associated with a doubling of overall mortality and of mortality from cardiovascular disease.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:54:44", "endTime": "2024/08/14 14:55:18", "cost": 33.904}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 22:55:18", "grab_time": "2024-08-13 22:54:44"}
{"id": 2234349, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "92bd4128-f38b-4601-b9ca-6b286d7f37e2", "title": "Addressing Vaccine Inequity — Covid-19 Vaccines as a Global Public Good", "text": "【0】Addressing Vaccine Inequity — Covid-19 Vaccines as a Global Public Good\nArticle\n-------\n\n【1】The first peer-reviewed clinical trial evidence that a Covid-19 vaccine provided robust protection against SARS-CoV-2 infection was published in the _Journal_ in December 2020,  less than a year after the sequence of the viral genome was reported. This unprecedentedly rapid development of vaccines was a scientific triumph. In the year since, about 62% of the world’s population has received at least one dose of a Covid-19 vaccine, and 54% have completed the primary vaccine series.  This would appear to be a landmark success in global health mobilization.\n\n【2】Figure 1. Covid-19 Vaccine Doses Administered in Countries Categorized by Income Level, December 2, 2020, through February 20, 2022.\n\n【3】Income categories are those defined by the World Bank. All doses, including boosters, are counted individually; since the same person may receive more than one dose, the number of doses may exceed the number of people in the population. Data are from Our World in Data .\n\n【4】The truth, of course, is very different. The availability of Covid-19 vaccines differs vastly across the globe . While several wealthy countries have exceeded 90% vaccine coverage, only about 11% of all people in low-income countries have received at least one dose, and only 25% of our health care colleagues in Africa were fully vaccinated by November, before the omicron wave.  Approximately three billion people worldwide have not received a single dose. The gulf in vaccination rates according to national income is overwhelming, despite the fact that a number of the pivotal phase 3 trials that led to vaccine licensing were conducted in part in some less developed countries. Poorer countries with no capacity to manufacture vaccines joined the end of the queue, as countries with manufacturing capacity prioritized local supply and wealthier countries purchased the vaccines. We should not be surprised by vaccine nationalism; company CEOs and boards have a fiduciary responsibility to maximize their stock price, and politicians are elected to prefer the interests of their voters over populations in other nations, despite cogent arguments to prioritize vaccinations globally for the vulnerable and for health care workers. \n\n【5】And a new challenge to the global vaccine supply has emerged: data from multiple in vitro and real-world studies published in the _Journal_ have shown that antibodies to SARS-CoV-2 wane over a matter of months after vaccination, findings that underscore the need for a booster to restore high antibody levels both to reduce infection with new variants and to minimize hospitalization and death.  In developed countries, the rapid emergence of the omicron variant has increased the urgency of these booster doses. Israel, a front-runner in providing booster doses, is now testing the efficacy of yet a fourth vaccine dose, and further boosters and redesigned vaccines are likely to be needed over time. These developments guarantee that existing vaccine supplies will be directed to rich countries, further delaying their availability in poor countries. Appeals from the World Health Organization (WHO) to delay booster doses in order to prioritize first doses to the world’s three billion unvaccinated people have gone unheeded in countries that see boosters as the way to open their economies and end unpopular social interventions. There is also the risk that “old vaccines” will be dumped on poorer countries as the rich shift to second-generation redesigned vaccines.\n\n【6】The COVAX (Covid-19 Vaccines Global Access) program, set up as part of the ACT (Access to Covid-19 Tools) Accelerator and led by GAVI (the Vaccine Alliance), CEPI (the Coalition for Epidemic Preparedness Innovations), and the WHO to support equitable access, was established in anticipation of this problem. But COVAX’s impact has been muted by supply-chain issues, vaccine nationalism, the decision by some countries to halt the export of vaccines, and queue-jumping by wealthy countries, which caused its initial projections of vaccine availability to be cut substantially.  The two largest countries in the world, China and India, improved the situation by vaccinating their populations through their national production. But the majority of countries have no local production capacity and are entirely dependent on external purchases, vaccine diplomacy, or donations. Developed countries that send about-to-expire batches of vaccine to poorer countries do little to address inequities.\n\n【7】Furthermore, different vaccines have different efficacy against illness, and the half-life of that efficacy, along with supply, would ideally be factored into any global vaccination strategy, but this cannot happen when the different vaccines vary in price and availability. Fortunately, even one dose of most vaccines appears to adequately boost those who have had a primary infection, which suggests that even a single vaccination may be a beneficial bridge to completing a primary series in countries where the prevalence of antibodies due to primary infection is high.\n\n【8】It has become an article of faith that “no one is safe until everyone is safe,”  but in countries that can vaccinate a very high proportion of their populations and supply boosters, and perhaps boosters-on-boosters, Covid-19 may become a controllable infection (although the emergence of immune-escape variants remains an ever-present threat and immunosuppressed people remain at risk). In countries with low vaccine coverage, however, SARS-CoV-2 will still cause major morbidity and mortality, strain health systems, sicken health workers, and cause economic disruption and will potentially provoke intermittent travel bans when new variants emerge. As developed countries stockpile boosters in response to virus variants, when will less-developed countries find a timely and secure supply of Covid-19 vaccines?\n\n【9】It is argued that the self-interest of rich countries should lead them to help vaccinate poorer countries because the uncontrolled spread of SARS-CoV-2 could foster the emergence of escape mutants that will unsettle their vaccine-induced protection against infection, hospitalization, and death. But although such unchecked viral replication and transmission increase the risk of new variants, SARS-CoV-2 evolution in immunosuppressed patients can create new variants anywhere, including the developed world.  Since current vaccines do not provide sterilizing immunity against infection with new variants such as omicron, SARS-CoV-2 will continue to circulate, and perhaps mutate, even in highly vaccinated populations. The case for global vaccine equity cannot rest solely on a defense against escape mutants. Morality and social justice argue that Covid-19 morbidity and mortality and their impact on economic and health systems should be prevented in all countries, rich and poor, around the world.\n\n【10】In the short term, poorer countries will have to compete for the purchase of vaccines in the global marketplace and hope that the COVAX mechanism can radically speed up and augment deliveries, despite the COVAX CEO’s assessment that “what we do not have today are the resources to help countries adapt to the new challenges that we know Covid-19 will create in 2022.”  Meanwhile, one potential solution, a World Trade Organization TRIPS waiver of intellectual property rights due to a public health emergency, has been stymied for over 18 months, despite endorsements from the WHO, the U.S. president, and over 100 governments,  including those of India, South Africa, Russia, and China. The Oxford–AstraZeneca ChAdOx1-nCoV-19 vaccine and some others have been voluntarily licensed to multiple countries for scaled-up production. Baylor College of Medicine has made publicly available the formula for a protein subunit vaccine that has received Emergency Use Authorization in India.  But the mRNA vaccine strategy that can most flexibly accommodate antigenic changes remains fiercely protected by the companies involved, despite being based on research funded for decades from the public purse. In the early months of vaccine production, the argument that supply chains for the 280 ingredients necessary for mRNA vaccine manufacture would be disrupted by any change might have made sense. But continuing exclusivity has meant that little public funding has gone into scaling up the production of those ingredients, a situation that perpetuates these limitations in the supply chains. It is long past time to break this impasse.\n\n【11】The medium-to-long-term solution is clear. Less developed and smaller countries need access to local or regional capacity to manufacture vaccines, because they cannot rely on the excess production capacity of richer countries for vaccine supplies in this or future pandemics. A report in 2017 estimated that over 99% of the vaccines used in Africa were imported, and astonishingly, although in 1997 about 55 countries had vaccine manufacturing capacity, by 2015 commercial and regulatory pressures had reduced that number to fewer than 20.  This situation contrasts with aims of the Global Action Plan for influenza vaccines developed by the WHO, which has emphasized and supported regional manufacture of flu vaccines.  CEPI plans to develop an international network that will reduce the time needed to produce a vaccine against a new epidemic pathogen to 100 days,  but the immediate test case is how to ramp up the production of the most effective Covid-19 vaccines today.\n\n【12】A sustained effort to develop and increase regional vaccine-production capacity is needed to reduce reliance on the business plans of a handful of commercial entities. This should include licensing and technology transfer arrangements such as those developed by the WHO and the Medicines Patent Pool, which have successfully made antiretroviral treatments widely and cheaply available to treat AIDS, even in the poorest countries. The WHO has gone further, creating vaccine hubs, such as the mRNA vaccine hubs in South Africa and five other African countries,  that hold the promise of locally developed and manufactured vaccines for Covid-19 and future pandemics. The chair of the International Monetary Fund maintains that financing vaccine production in Africa is “good for the world,” since the investment needed is tiny as compared with the global economic impact of Covid-19.  An alternative, giving poor countries loans to purchase Covid-19 vaccines, only perpetuates indebtedness. Finally, as new vaccines are developed, regulatory mechanisms must adapt to changing circumstances; where a high proportion of people have partial immunity from natural infection, vaccination, or both, phase 3 trials that aim to show the superiority of a new Covid-19 vaccine become impossibly large, making noninferiority studies the preferred option in order to increase the diversity of licensed vaccines.\n\n【13】Vaccine inequity is symptomatic of the failure of global governance of the pandemic. The haphazard way in which vaccines are currently distributed must be addressed as part of a global vaccine strategy that includes a system of intellectual-property management, manufacturing, and distribution that ensures that vaccines are made available equitably around the world. Vaccines against pandemic diseases, and the ability to manufacture them, must not be a sequestered asset that maximizes the return to pharmaceutical company executives and shareholders or increases the electability of politicians. They must be a global public good.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-14 00:11:46", "grab_time": "2024-08-13 22:47:01"}
{"id": 2234348, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "fa3da591-d14a-41e4-bf54-909710d2336b", "title": "Monkeypox — Past as Prologue", "text": "【0】Monkeypox — Past as Prologue\nArticle\n-------\n\n【1】In this issue of the _Journal_ , Thornhill et al. report on 528 persons with monkeypox in a cohort spanning 16 countries on five continents.  The authors provide important demographic, epidemiologic, and clinical details on the largest reported cohort of patients in the latest emerging infectious disease outbreak of global importance. Diagnosis relied on polymerase-chain-reaction (PCR) assays of swab specimens taken from lesions, predominantly in the skin, anogenital region, nose, or throat. The authors note a diverse set of dermatologic and oropharyngeal clinical manifestations that in many instances could be confused with a variety of other illnesses, including several sexually transmitted infections. Most of the patients had 10 or fewer lesions, with 10% having a single genital lesion, findings consistent with other early reports. Lesions ranged in appearance from maculopapular to vesiculopustular to crusted, with the anogenital region the most common site. The Supplementary Appendix of the article  contains an excellent array of images of lesions to aid in case recognition. Although there were no fatalities within the cohort, 13% of the persons with infection were hospitalized for management of pain or secondary infections.\n\n【2】Monkeypox has been recognized as an endemic disease in central and western Africa since 1970, when it was diagnosed in a 9-month-old child in the Democratic Republic of Congo who had not been vaccinated against smallpox.  Since then, cases have been reported from central and western Africa and can be classified on the basis of molecular characteristics into two major groups, often referred to as the Congo Basin (clade I) and West African (clades IIa and IIb \\[formerly clades 2 and 3\\]) groups.  The West African clades cause disease most closely resembling the currently emerging outbreak in countries in which the disease is not endemic, whereas the Congo Basin clade causes a more severe disease, with an associated 10% mortality. Early genomic analyses suggest that the current global outbreak is caused by clade IIb viruses similar to those that caused a Nigerian outbreak in 2017 and 2018, which included cases that were exported to the United Kingdom, Israel, and Singapore in 2018 and 2019; the viruses in the current outbreak are characterized by a pattern of evolutionary changes potentially driven by apolipoprotein B messenger RNA–editing catalytic polypeptide-like 3 (APOBEC3) enzymes.  It is noteworthy that there appears to have been a recent change in the epidemiologic characteristics of monkeypox in Africa, where cases are now occurring in new geographic areas, perhaps facilitated by climate change and deforestation leading to changes in the environmental interface between humans and the animal reservoir (or reservoirs). \n\n【3】The emerging epidemiologic pattern of these cases bears a striking resemblance to the early cases of HIV/AIDS. In the present study, men who identified as homosexual or bisexual accounted for 98% of cases. The classic mode of transmission of monkeypox virus infection is thought to be direct lesion-to-skin contact. Thus far, there has been very little evidence of household spread of any form of monkeypox other than among caregivers, which suggests that this infection is not spread through casual contact and probably requires prolonged or repeated exposure to virus-shedding lesions. In the present study, the finding of PCR positivity in 29 of 32 semen samples, the presence of lesions isolated to the oropharynx in 23% of the persons with infection, and the observation that 73% of persons in the cohort had lesions in the anogenital area suggest that sexual transmission may also play a role. Given how little we know about the epidemiologic characteristics of the current outbreak, it is prudent to heed an observation made during the first year of the HIV/AIDS pandemic: “… any assumption that it will remain restricted to a particular segment of our society is truly an assumption without a scientific basis.”  Thus, additional detailed epidemiologic and observational cohort studies, serosurveys, and ongoing surveillance for new cases are of critical importance.\n\n【4】If one compares the situations at the start of the AIDS, Covid-19, and current global monkeypox outbreaks, certain interesting similarities and differences are apparent. In the case of AIDS, the etiologic agent was unknown, and no effective specific countermeasures were available. Today, we know the cause and have effective therapies; however, it took years to get to that point, and we still lack a vaccine. In the case of Covid-19, we quickly identified the etiologic agent; however, we lacked effective countermeasures. Today, we have effective diagnostics, vaccines, and therapies, after approximately a year of intense research and development. In contrast, in the case of monkeypox, the etiologic agent has been known for decades. One licensed monkeypox vaccine — the nonreplicating modified vaccinia Ankara (Jynneos \\[called Imvamune in Canada and Imvanex in Europe\\], Bavarian Nordic) — and one vaccine that is available for monkeypox under the FDA Expanded Access Investigational New Drug mechanism (live virus vaccinia \\[ACAM2000, Emergent BioSolutions\\]) are in the Strategic National Stockpile. In addition, two drugs (tecovirimat and brincidofovir) had already been licensed through the “Animal Rule” for the closely related virus variola (which causes smallpox). Studies of the disease and its animal reservoirs had been ongoing in Africa,  and a randomized, placebo-controlled trail of tecovirimat was close to starting in the Democratic Republic of Congo.  Thus, the challenge to the public health and research communities during this time of emergency response is to ensure the efficient and equitable availability and distribution of existing countermeasures to those in need of them while at the same time conducting the rigorous studies needed to define what the clinical efficacy may be, understand any potential safety concerns, and guide proper utilization.\n\n【5】The current monkeypox outbreak provides a new set of challenges to patients as well as to the medical and biomedical research communities. At the time that the article by Thornhill et al. was published online, approximately 14,000 cases had been reported in the world; at the time this editorial was being written (approximately 2 weeks later), that number had doubled.  Lessons learned during the responses to AIDS and Covid-19 should help us to marshal a more efficient and effective response to monkeypox, and the response to monkeypox should, in turn, help to inform our response to the inevitable next emerging or reemerging infectious disease of pandemic potential.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:52:46", "endTime": "2024/08/14 14:54:19", "cost": 92.969}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 22:54:19", "grab_time": "2024-08-13 22:52:46"}
{"id": 2234347, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "c924f0f5-75d9-4213-85d1-8ffc6953ff12", "title": "Case 40-2014 — A 57-Year-Old Man with Inguinal Pain, Lymphadenopathy, and HIV Infection", "text": "【0】Case 40-2014 — A 57-Year-Old Man with Inguinal Pain, Lymphadenopathy, and HIV Infection\nA 57-year-old man with HIV infection was seen in the emergency department because of pain in the left inguinal region. CT of the abdomen and pelvis revealed enlarged lymph nodes with areas of necrosis. A diagnostic test was performed.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:43:14", "endTime": "2024/08/14 14:43:59", "cost": 45.819}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 22:43:59", "grab_time": "2024-08-13 22:43:13"}
{"id": 2234346, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "21854540-80ff-4eac-ae89-16a4b868bce1", "title": "Mechanisms of Disease: Mechanisms of Hypoglycemia-Associated Autonomic Failure in Diabetes", "text": "【0】Mechanisms of Disease: Mechanisms of Hypoglycemia-Associated Autonomic Failure in Diabetes\nAsymptomatic hypoglycemia is a major problem in diabetes. Mechanisms involved in a patient's inability to sense low glucose levels are reviewed. Autonomic dysfunction is a key contributor. Mechanistic studies suggest interventions that may restore the normal autonomic response.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:41:01", "endTime": "2024/08/14 14:41:17", "cost": 15.609}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 22:41:17", "grab_time": "2024-08-13 22:41:01"}
{"id": 2234345, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "0763bd2d-fa47-4a13-9ea9-c52eca58ac0b", "title": "Hepatitis A in Day-Care Centers — A Community-Wide Assessment", "text": "【0】Hepatitis A in Day-Care Centers — A Community-Wide Assessment\nAbstract\n--------\n\n【1】We investigated the spread of viral hepatitis in day-care centers in Maricopa County, Ariz. Over a 10-month period, 398 (40 per cent) of 1008 reported cases of hepatitis Type A or viral hepatitis of unspecified type occurred in persons closely associated with day-care centers. Outbreaks of hepatitis comprising 310 cases were identified in 30 of the 308 centers in the county. In 28 outbreaks investigated, the majority of symptomatic cases occurred in household contacts or close relatives of children who attended day-care centers, with 16 per cent of the cases occurring in children who attended the centers and 15 per cent occurring in employees. Hepatitis in both employees and household contacts was strongly related to contact with children one to two years of age who attended the centers (P<0.001). Day-care centers appear to be important in the spread of hepatitis A in the United States.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:31:33", "endTime": "2024/08/14 14:32:43", "cost": 70.558}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 22:32:43", "grab_time": "2024-08-13 22:31:32"}
{"id": 2234344, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "b538cedc-6910-43da-82dc-a2aca5b905bf", "title": " Reactivation Osteomyelitis after 75 Years", "text": "【0】 Reactivation Osteomyelitis after 75 Years\nTo the Editor:\n--------------\n\n【1】In 1934, a 10-year-old girl was hospitalized at the Children's Hospital of Boston for 1 1/2 years for _Staphylococcus aureus_ osteomyelitis of the left femur. This was the preantibiotic era, so she did not receive any antibiotic therapy at that time but, instead, underwent multiple orthopedic procedures including “scalloping” (i.e., removal of infected bone). She recovered fully, never underwent any drainage procedures, and did well until she reached 85 years of age, when she felt pain in her left midfemur while rising from a chair. The following day she noted a purulent drainage from her left thigh and presented to our institution.\n\n【2】Radiographic findings identified a pathologic fracture of the left midfemur, scalloping changes, and medullary changes consistent with osteomyelitis. After successful open reduction and internal fixation of the fracture, she recovered without sequelae. During surgery, an old sinus tract that had never drained was found. All cultures of samples from the bone and tract grew only _S. aureus_ ; there was no evidence of a malignant condition. As expected, the _S. aureus_ strain was sensitive to all antibiotics tested, including penicillin and oxacillin.\n\n【3】Sequence type 30 (ST30) _S. aureus_ femoral osteomyelitis became reactivated in our patient after 75 years. _S. aureus_ reactivation osteomyelitis occurring many decades after the initial infection has been reported previously.  We performed Multi Locus Sequence Typing of the recovered _S. aureus_ strain in standard fashion,  and seven _S. aureus_ housekeeping genes ( _arcC, aroE, glpF, gmk\\_, pta\\_, tpi\\_,_ and _yqiL_ ) were fully sequenced with the use of the Applied Biosystems 3730xl DNA Analyzer. The allelic profile of this _S. aureus_ strain placed it among ST30 _S. aureus_ isolates. \n\n【4】In the 1950s and 1960s, a penicillin-resistant but methicillin-susceptible ST30 _S. aureus_ clone spread throughout the world.  More recently, community-acquired and hospital-acquired methicillin-susceptible and methicillin-resistant strains of ST30 _S. aureus_ have been reported to be the prevalent clones in Australia and Oceania.  Our report suggests that an ST30 _S. aureus_ clone sensitive to all antibiotics was circulating in the eastern United States in 1934.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:29:01", "endTime": "2024/08/14 15:31:08", "cost": 127.835}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:29", "update_time": "2024-08-13 23:31:08", "grab_time": "2024-08-13 23:29:00"}
{"id": 2234343, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "95ba5241-26cc-45ee-8a09-a306e28a9dda", "title": "Case 9-2020: A 64-Year-Old Man with Shortness of Breath, Cough, and Hypoxemia", "text": "【0】Case 9-2020: A 64-Year-Old Man with Shortness of Breath, Cough, and Hypoxemia\nA 64-year-old man with a history of melanoma presented to the hospital after evaluation for clumsiness of the right arm had revealed a brain mass. Metastatic melanoma was diagnosed, and treatment included combination immune checkpoint inhibitor therapy. Fevers, dyspnea, and cough developed. Treatment decisions were made.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:53:41", "endTime": "2024/08/14 14:53:50", "cost": 8.655}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 22:53:50", "grab_time": "2024-08-13 22:53:41"}
{"id": 2234342, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "c0e1d5fb-d4b8-4dd5-b754-8745efd1c842", "title": "Development of a Scleroderma-like Illness during Therapy with L-5-Hydroxytryptophan and Carbidopa", "text": "【0】Development of a Scleroderma-like Illness during Therapy with L-5-Hydroxytryptophan and Carbidopa\nAbstract\n--------\n\n【1】A scleroderma-like illness developed in a patient treated with L-5 hydroxytryptophan (L-5HTP) and carbidopa for intention myoclonus. The patient had high plasma kynurenine levels that remained high when the L-5HTP-carbidopa combination was discontinued. However, levels rose further on drug rechallenge, suggesting that the drug unmasked an abnormality in one of the enzymes that catabolize kynurenine. Plasma kynurenine was also determined to be high in seven of 15 patients with idiopathic scleroderma, but not in eight patients with intention myoclonus treated with L-5HTP and a decarboxylase inhibitor and in whom scleroderma did not develop or in 10 patients with Parkinson's disease treated with L-dopa and carbidopa.\n\n【2】Our data and studies in the literature suggest that two factors may be important in the pathogenesis of some scleroderma-like illness: high plasma serotonin and the abnormality associated with elevated kynurenine.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:05:10", "endTime": "2024/08/14 15:05:23", "cost": 13.445}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 23:05:23", "grab_time": "2024-08-13 23:05:10"}
{"id": 2234341, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "dd7f3672-db91-4b4e-8f34-19e889eec4f8", "title": "A Randomized Trial of Intensive versus Standard Blood-Pressure Control", "text": "【0】A Randomized Trial of Intensive versus Standard Blood-Pressure Control\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】The most appropriate targets for systolic blood pressure to reduce cardiovascular morbidity and mortality among persons without diabetes remain uncertain.\n\n【3】Methods\n-------\n\n【4】We randomly assigned 9361 persons with a systolic blood pressure of 130 mm Hg or higher and an increased cardiovascular risk, but without diabetes, to a systolic blood-pressure target of less than 120 mm Hg (intensive treatment) or a target of less than 140 mm Hg (standard treatment). The primary composite outcome was myocardial infarction, other acute coronary syndromes, stroke, heart failure, or death from cardiovascular causes.\n\n【5】Results\n-------\n\n【6】At 1 year, the mean systolic blood pressure was 121.4 mm Hg in the intensive-treatment group and 136.2 mm Hg in the standard-treatment group. The intervention was stopped early after a median follow-up of 3.26 years owing to a significantly lower rate of the primary composite outcome in the intensive-treatment group than in the standard-treatment group (1.65% per year vs. 2.19% per year; hazard ratio with intensive treatment, 0.75; 95% confidence interval \\[CI\\], 0.64 to 0.89; P<0.001). All-cause mortality was also significantly lower in the intensive-treatment group (hazard ratio, 0.73; 95% CI, 0.60 to 0.90; P=0.003). Rates of serious adverse events of hypotension, syncope, electrolyte abnormalities, and acute kidney injury or failure, but not of injurious falls, were higher in the intensive-treatment group than in the standard-treatment group.\n\n【7】Conclusions\n-----------\n\n【8】Among patients at high risk for cardiovascular events but without diabetes, targeting a systolic blood pressure of less than 120 mm Hg, as compared with less than 140 mm Hg, resulted in lower rates of fatal and nonfatal major cardiovascular events and death from any cause, although significantly higher rates of some adverse events were observed in the intensive-treatment group. \n\n【9】Introduction\n------------\n\n【10】 QUICK TAKE  \nThe SPRINT Trial  \n\n【11】Hypertension is highly prevalent in the adult population in the United States, especially among persons older than 60 years of age, and affects approximately 1 billion adults worldwide.  Among persons 50 years of age or older, isolated systolic hypertension is the most common form of hypertension,  and systolic blood pressure becomes more important than diastolic blood pressure as an independent risk predictor for coronary events, stroke, heart failure, and end-stage renal disease (ESRD).  The Global Burden of Disease Study identified elevated blood pressure as the leading risk factor, among 67 studied, for death and disability-adjusted life-years lost during 2010. \n\n【12】Clinical trials have shown that treatment of hypertension reduces the risk of cardiovascular disease outcomes, including incident stroke (by 35 to 40%), myocardial infarction (by 15 to 25%), and heart failure (by up to 64%).  However, the target for systolic blood-pressure lowering is uncertain. Observational studies have shown a progressive increase in cardiovascular risk as systolic blood pressure rises above 115 mm Hg,  but the available evidence from randomized, controlled trials in the general population of patients with hypertension only documents the benefit of treatment to achieve a systolic blood-pressure target of less than 150 mm Hg, with limited data concerning lower blood-pressure targets.  In a trial involving patients with type 2 diabetes mellitus, the rate of major cardiovascular events was similar with a systolic blood-pressure target of less than 120 mm Hg and the commonly recommended target of less than 140 mm Hg, though the rate of stroke was lower with the target of less than 120 mm Hg.  A recent trial involving patients who had had a stroke compared treatment to lower systolic blood pressure to less than 130 mm Hg with treatment to lower it to less than 150 mm Hg and showed no significant benefit of the lower target with respect to the overall risk of another stroke but a significant benefit with respect to the risk of hemorrhagic stroke. \n\n【13】The hypothesis that a lower systolic blood-pressure goal (e.g., <120 mm Hg) would reduce clinical events more than a standard goal was designated by a National Heart, Lung, and Blood Institute (NHLBI) expert panel in 2007 as the most important hypothesis to test regarding the prevention of hypertension-related complications among patients without diabetes.  The current article describes the primary results of the Systolic Blood Pressure Intervention Trial (SPRINT), which compared the benefit of treatment of systolic blood pressure to a target of less than 120 mm Hg with treatment to a target of less than 140 mm Hg.\n\n【14】Methods\n-------\n\n【15】Study Design and Oversight\n--------------------------\n\n【16】SPRINT was a randomized, controlled, open-label trial that was conducted at 102 clinical sites (organized into 5 clinical center networks) in the United States, including Puerto Rico . A trial coordinating center served as a data and biostatistical core center and supervised the central laboratory, the electrocardiography reading center, the magnetic resonance imaging reading center, and the drug-distribution center.\n\n【17】SPRINT was sponsored by the NHLBI, with cosponsorship by the National Institute of Diabetes and Digestive and Kidney Diseases, the National Institute of Neurological Disorders and Stroke, and the National Institute on Aging. An independent data and safety monitoring board monitored unblinded trial results and safety events. The study was approved by the institutional review board at each participating study site. The steering committee designed the study, gathered the data (in collaboration with investigators at the clinics and other study units), made the decision to submit the manuscript for publication, and vouches for the fidelity of the study to the protocol . The writing committee wrote the manuscript and vouches for the completeness and accuracy of the data and analysis. The coordinating center was responsible for analyzing the data. Scientists at the National Institutes of Health participated in the design of the study and as a group had one vote on the steering committee of the trial.\n\n【18】Study Population\n----------------\n\n【19】Participants were required to meet all the following criteria: an age of at least 50 years, a systolic blood pressure of 130 to 180 mm Hg , and an increased risk of cardiovascular events. Increased cardiovascular risk was defined by one or more of the following: clinical or subclinical cardiovascular disease other than stroke; chronic kidney disease, excluding polycystic kidney disease, with an estimated glomerular filtration rate (eGFR) of 20 to less than 60 ml per minute per 1.73 m <sup>2 </sup> of body-surface area, calculated with the use of the four-variable Modification of Diet in Renal Disease equation; a 10-year risk of cardiovascular disease of 15% or greater on the basis of the Framingham risk score; or an age of 75 years or older. Patients with diabetes mellitus or prior stroke were excluded. Detailed inclusion and exclusion criteria are listed in the Supplementary Appendix . All participants provided written informed consent.\n\n【20】Randomization and Interventions\n-------------------------------\n\n【21】Eligible participants were assigned to a systolic blood-pressure target of either less than 140 mm Hg (the standard-treatment group) or less than 120 mm Hg (the intensive-treatment group). Randomization was stratified according to clinical site. Participants and study personnel were aware of the study-group assignments, but outcome adjudicators were not.\n\n【22】After the participants underwent randomization, their baseline antihypertensive regimens were adjusted on the basis of the study-group assignment. The treatment algorithms were similar to those used in the Action to Control Cardiovascular Risk in Diabetes (ACCORD) trial.  These algorithms and our formulary are listed in Figures S1 and S2 and Table S1 in the Supplementary Appendix . All major classes of antihypertensive agents were included in the formulary and were provided at no cost to the participants. SPRINT investigators could also prescribe other antihypertensive medications (not provided by the study). The protocol encouraged, but did not mandate, the use of drug classes with the strongest evidence for reduction in cardiovascular outcomes, including thiazide-type diuretics (encouraged as the first-line agent), loop diuretics (for participants with advanced chronic kidney disease), and beta-adrenergic blockers (for those with coronary artery disease).  Chlorthalidone was encouraged as the primary thiazide-type diuretic, and amlodipine as the preferred calcium-channel blocker.  Azilsartan and azilsartan combined with chlorthalidone were donated by Takeda Pharmaceuticals International and Arbor Pharmaceuticals; neither company had any other role in the study.\n\n【23】Participants were seen monthly for the first 3 months and every 3 months thereafter. Medications for participants in the intensive-treatment group were adjusted on a monthly basis to target a systolic blood pressure of less than 120 mm Hg. For participants in the standard-treatment group, medications were adjusted to target a systolic blood pressure of 135 to 139 mm Hg, and the dose was reduced if systolic blood pressure was less than 130 mm Hg on a single visit or less than 135 mm Hg on two consecutive visits. Dose adjustment was based on a mean of three blood-pressure measurements at an office visit while the patient was seated and after 5 minutes of quiet rest; the measurements were made with the use of an automated measurement system (Model 907, Omron Healthcare). Lifestyle modification was encouraged as part of the management strategy. Retention in the study and adherence to treatment were monitored prospectively and routinely throughout the trial. \n\n【24】Study Measurements\n------------------\n\n【25】Demographic data were collected at baseline. Clinical and laboratory data were obtained at baseline and every 3 months thereafter. A structured interview was used in both groups every 3 months to obtain self-reported cardiovascular disease outcomes. Although the interviewers were aware of the study-group assignments, they used the same format for interviews in the two groups to minimize ascertainment bias. Medical records and electrocardiograms were obtained for documentation of events. Whenever clinical-site staff became aware of a death, a standard protocol was used to obtain information on the event.\n\n【26】Serious adverse events were defined as events that were fatal or life-threatening, that resulted in clinically significant or persistent disability, that required or prolonged a hospitalization, or that were judged by the investigator to represent a clinically significant hazard or harm to the participant that might require medical or surgical intervention to prevent one of the other events listed above.  A short list of monitored conditions were reported as adverse events if they were evaluated in an emergency department: hypotension, syncope, injurious falls, electrolyte abnormalities, and bradycardia. We also monitored occurrences of acute kidney injury or acute renal failure if they were noted on admission or occurred during a hospitalization and were reported in the hospital discharge summary as a primary or main secondary diagnosis. The _Medical Dictionary for Regulatory Activities_ was used to classify the safety events. Coding was performed at the coordinating center, and up to three codes were assigned to each safety event. The relationship of serious adverse events to the intervention was assessed by the trial safety officer and reviewed monthly by the safety committee.\n\n【27】Study Outcomes\n--------------\n\n【28】Definitions of study outcomes are outlined in the Supplementary Appendix . A committee whose members were unaware of the study-group assignments adjudicated the clinical outcomes specified in the protocol. The primary hypothesis was that treatment to reach a systolic blood-pressure target of less than 120 mm Hg, as compared with a target of less than 140 mm Hg, would result in a lower rate of the composite outcome of myocardial infarction, acute coronary syndrome not resulting in myocardial infarction, stroke, acute decompensated heart failure, or death from cardiovascular causes. Secondary outcomes included the individual components of the primary composite outcome, death from any cause, and the composite of the primary outcome or death from any cause.\n\n【29】We also assessed renal outcomes, using a different definition for patients with chronic kidney disease (eGFR <60 ml per minute per 1.73 m <sup>2 </sup> ) at baseline and those without it. The renal outcome in participants with chronic kidney disease at baseline was a composite of a decrease in the eGFR of 50% or more (confirmed by a subsequent laboratory test) or the development of ESRD requiring long-term dialysis or kidney transplantation. In participants without chronic kidney disease at baseline, the renal outcome was defined by a decrease in the eGFR of 30% or more to a value of less than 60 ml per minute per 1.73 m <sup>2 </sup> . Incident albuminuria, defined for all study participants by a doubling of the ratio of urinary albumin (in milligrams) to creatinine (in grams) from less than 10 at baseline to greater than 10 during follow-up, was also a prespecified renal outcome.\n\n【30】Prespecified subgroups of interest for all outcomes were defined according to status with respect to cardiovascular disease at baseline (yes vs. no), status with respect to chronic kidney disease at baseline (yes vs. no), sex, race (black vs. nonblack), age (<75 vs. ≥75 years), and baseline systolic blood pressure in three levels (≤132 mm Hg, >132 to <145 mm Hg, and ≥145 mm Hg). We also planned a comparison of the effects of systolic blood-pressure targets on incident dementia, changes in cognitive function, and cerebral small-vessel ischemic disease; these results are not presented here.\n\n【31】Statistical Analysis\n--------------------\n\n【32】We planned a 2-year recruitment period, with a maximum follow-up of 6 years, and anticipated a loss to follow-up of 2% per year. With an enrollment target of 9250 participants, we estimated that the trial would have 88.7% power to detect a 20% effect with respect to the primary outcome, assuming an event rate of 2.2% per year in the standard-treatment group.\n\n【33】Our primary analysis compared the time to the first occurrence of a primary outcome event between the two study groups with the use of the intention-to-treat approach for all randomly assigned participants; for this analysis, we used Cox proportional-hazards regression with two-sided tests at the 5% level of significance, with stratification according to clinic. Follow-up time was censored on the date of last event ascertainment. Interactions between treatment effect and prespecified subgroups were assessed with a likelihood-ratio test for the interaction with the use of Hommel-adjusted P values.  Interim analyses were performed for each meeting of the data and safety monitoring board, with group-sequential stopping boundaries defined with the use of the Lan–DeMets method with an O’Brien–Fleming–type spending function.  The Fine–Gray model for the competing risk of death was used as a sensitivity analysis. \n\n【34】Results\n-------\n\n【35】Study Participants\n------------------\n\n【36】Figure 1. Eligibility, Randomization, and Follow-up.\n\n【37】Discontinued intervention refers to participants who discontinued the study treatment but did not withdraw consent or become lost to follow-up.Table 1.  Table 1. Baseline Characteristics of the Study Participants.\n\n【38】A total of 9361 participants were enrolled between November 2010 and March 2013 . Descriptive baseline statistics are presented in Table 1 . On August 20, 2015, the NHLBI director accepted a recommendation from the data and safety monitoring board of the trial to inform the investigators and participants of the cardiovascular-outcome results after analyses of the primary outcome exceeded the monitoring boundary at two consecutive time points , thus initiating the process to end the blood-pressure intervention early. The median follow-up on August 20, 2015, was 3.26 years of the planned average of 5 years.\n\n【39】Blood Pressure\n--------------\n\n【40】Figure 2. Systolic Blood Pressure in the Two Treatment Groups over the Course of the Trial.\n\n【41】The systolic blood-pressure target in the intensive-treatment group was less than 120 mm Hg, and the target in the standard-treatment group was less than 140 mm Hg. The mean number of medications is the number of blood-pressure medications administered at the exit of each visit. I bars represent 95% confidence intervals.\n\n【42】The two treatment strategies resulted in a rapid and sustained between-group difference in systolic blood pressure . At 1 year, the mean systolic blood pressure was 121.4 mm Hg in the intensive-treatment group and 136.2 mm Hg in the standard-treatment group, for an average difference of 14.8 mm Hg. The mean diastolic blood pressure at 1 year was 68.7 mm Hg in the intensive-treatment group and 76.3 mm Hg in the standard-treatment group . Throughout the 3.26 years of follow-up, the mean systolic blood pressure was 121.5 mm Hg in the intensive-treatment group and 134.6 mm Hg in the standard-treatment group, and the mean number of blood-pressure medications was 2.8 and 1.8, respectively. The relative distribution of antihypertensive medication classes used was similar in the two groups, though the use of each class was greater in the intensive-treatment group .\n\n【43】Clinical Outcomes\n-----------------\n\n【44】Table 2. Primary and Secondary Outcomes and Renal Outcomes. Figure 3.  Figure 3. Primary Outcome and Death from Any Cause.\n\n【45】Shown are the cumulative hazards for the primary outcome (a composite of myocardial infarction, acute coronary syndrome, stroke, heart failure, or death from cardiovascular causes)  and for death from any cause . The inset in each panel shows the same data on an enlarged y axis. CI denotes confidence interval.\n\n【46】A primary outcome event was confirmed in 562 participants — 243 (1.65% per year) in the intensive-treatment group and 319 (2.19% per year) in the standard-treatment group (hazard ratio with intensive treatment, 0.75; 95% confidence interval \\[CI\\], 0.64 to 0.89; P<0.001) . Separation in the primary outcome between the groups was apparent at 1 year . The between-group differences were consistent across the components of the primary outcome and other prespecified secondary outcomes .\n\n【47】A total of 365 deaths occurred — 155 in the intensive-treatment group and 210 in the standard-treatment group (hazard ratio, 0.73; 95% CI, 0.60 to 0.90; P=0.003). Separation in mortality between the groups became apparent at approximately 2 years . Causes of death are provided in Table S3 in the Supplementary Appendix . The relative risk of death from cardiovascular causes was 43% lower with the intensive intervention than with the standard treatment (P=0.005) .\n\n【48】Figure 4. Forest Plot of Primary Outcome According to Subgroups.\n\n【49】The dashed vertical line represents the hazard ratio for the overall study population. The box sizes are proportional to the precision of the estimates (with larger boxes indicating a greater degree of precision). The subgroup of no previous chronic kidney disease (CKD) includes some participants with unknown CKD status at baseline. Black race includes Hispanic black and black as part of a multiracial identification.\n\n【50】The numbers needed to treat to prevent a primary outcome event, death from any cause, and death from cardiovascular causes during the median 3.26 years of the trial were 61, 90, and 172, respectively. The effects of the intervention on the rate of the primary outcome and on the rate of death from any cause were consistent across the prespecified subgroups . There were no significant interactions between treatment and subgroup with respect to the primary outcome or death from any cause. When death was treated as a competing risk in a Fine–Gray model, the results with respect to the primary outcome were virtually unchanged (hazard ratio, 0.76; 95% CI, 0.64 to 0.89).\n\n【51】Among participants who had chronic kidney disease at baseline, no significant between-group difference in the composite outcome of a decrease in the eGFR of 50% or more or the development of ESRD was noted, though the number of events was small . Among participants who did not have chronic kidney disease at baseline, the incidence of the outcome defined by a decrease in the eGFR of 30% or more to a value of less than 60 ml per minute per 1.73 m <sup>2 </sup> was higher in the intensive-treatment group than in the standard-treatment group (1.21% per year vs. 0.35% per year; hazard ratio, 3.49; 95% CI, 2.44 to 5.10; P<0.001).\n\n【52】Serious Adverse Events\n----------------------\n\n【53】Table 3. Serious Adverse Events, Conditions of Interest, and Monitored Clinical Events.\n\n【54】Serious adverse events occurred in 1793 participants in the intensive-treatment group (38.3%) and in 1736 participants in the standard-treatment group (37.1%) (hazard ratio with intensive treatment, 1.04; P=0.25) . Serious adverse events of hypotension, syncope, electrolyte abnormalities, and acute kidney injury or acute renal failure, but not injurious falls or bradycardia, occurred more frequently in the intensive-treatment group than in the standard-treatment group. Orthostatic hypotension as assessed during a clinic visit was significantly less common in the intensive-treatment group. A total of 220 participants in the intensive-treatment group (4.7%) and 118 participants in the standard-treatment group (2.5%) had serious adverse events that were classified as possibly or definitely related to the intervention (hazard ratio, 1.88; P<0.001) . The magnitude and pattern of differences in adverse events according to treatment assignment among participants 75 years of age or older were similar to those in the overall cohort .\n\n【55】Discussion\n----------\n\n【56】SPRINT showed that among adults with hypertension but without diabetes, lowering systolic blood pressure to a target goal of less than 120 mm Hg, as compared with the standard goal of less than 140 mm Hg, resulted in significantly lower rates of fatal and nonfatal cardiovascular events and death from any cause. Trial participants assigned to the lower systolic blood-pressure target (intensive-treatment group), as compared with those assigned to the higher target (standard-treatment group), had a 25% lower relative risk of the primary outcome; in addition, the intensive-treatment group had lower rates of several other important outcomes, including heart failure (38% lower relative risk), death from cardiovascular causes (43% lower relative risk), and death from any cause (27% lower relative risk). During the follow-up period of the trial (median, 3.26 years), the number needed to treat with a strategy of intensive blood-pressure control to prevent one primary outcome event was 61, and the number needed to treat to prevent one death from any cause was 90. These benefits with respect to both the primary outcome and death were consistent across all prespecified subgroups, including participants 75 years of age or older.\n\n【57】Owing in part to a lower-than-expected decline in the eGFR and to the early termination of the trial, the number of renal events was small. Among participants who had chronic kidney disease at baseline, the number of participants with a decrease in the eGFR of 50% or more or reaching ESRD over the course of the trial did not differ significantly between the two intervention groups. Among participants who did not have chronic kidney disease at baseline, a decrease in the eGFR of 30% or more to a value of less than 60 ml per minute per 1.73 m <sup>2 </sup> occurred more frequently in the intensive-treatment group than in the standard-treatment group (1.21% per year vs. 0.35% per year). Among all participants, acute kidney injury or acute renal failure occurred more frequently in the intensive-treatment group than in the standard-treatment group . The differences in adverse renal outcomes may be related to a reversible intrarenal hemodynamic effect of the greater reduction in blood pressure and greater use of diuretics, angiotensin-converting–enzyme inhibitors, and angiotensin-receptor blockers in the intensive-treatment group.  With the currently available data, there is no evidence of substantial permanent kidney injury associated with the lower systolic blood-pressure goal; however, the possibility of a long-term adverse renal outcome cannot be excluded. These observations and hypotheses need to be explored further in analyses that incorporate more clinical outcomes and longer follow-up.\n\n【58】The results of SPRINT add substantially to the evidence of benefits of lowering systolic blood pressure, especially in older patients with hypertension. Trials such as the Systolic Hypertension in the Elderly Program trial,  the Systolic Hypertension in Europe trial,  and the Hypertension in the Very Elderly Trial  showed the benefits of lowering systolic blood pressure below 150 mm Hg. However, trials evaluating systolic blood-pressure levels lower than those studied in these trials have been either underpowered  or performed without specific systolic blood-pressure targets.  A major component of the controversy regarding the selection of the systolic blood-pressure goal in this population has resulted from inadequate data on the risks versus benefits of systolic blood-pressure targets below 150 mm Hg.  SPRINT now provides evidence of benefits for an even lower systolic blood-pressure target than that currently recommended in most patients with hypertension.\n\n【59】Comparisons between SPRINT and the ACCORD trial  are inevitable, because the trials examined identical systolic blood-pressure targets (<120 mm Hg vs. <140 mm Hg). In contrast to the findings of SPRINT, the cardiovascular and mortality benefits observed in the ACCORD trial were not statistically significant and were of a lesser magnitude. Several important differences between these trials should be noted. The ACCORD trial enrolled participants with diabetes exclusively, whereas SPRINT excluded participants with diabetes; in addition, the sample size of the ACCORD trial was only half that of SPRINT (4733 vs. 9361). SPRINT enrolled an older cohort (mean age, 68 years, vs. 62 years in the ACCORD trial), with 28% of participants 75 years of age or older, and also included participants with chronic kidney disease. The ACCORD trial showed a (nonsignificant) 12% lower risk of its primary composite cardiovascular outcome, with a 95% confidence interval that included the possibility of a 27% lower risk, which is consistent with the cardiovascular benefit observed in SPRINT. The ACCORD trial also used a factorial design that included comparisons of standard and intensive glycemic and lipid treatment targets in the same trial. A secondary analysis of the ACCORD results showed that, as compared with the combined standard glycemia and blood-pressure treatments, intensive blood-pressure treatment alone reduced major cardiovascular outcomes by 26% without additional benefit from combining the two intensive treatments.  Thus, the difference in results between the trials could be due to differences in study design, treatment interactions, or the play of chance. An inherent difference in the cardiovascular benefits of systolic blood-pressure lowering between the population with diabetes and the population without diabetes seems unlikely but cannot be ruled out.\n\n【60】In the Secondary Prevention of Small Subcortical Strokes trial (intensive systolic blood-pressure goal <130 mm Hg)  and in the ACCORD trial (intensive systolic blood-pressure goal <120 mm Hg), the lower blood-pressure target was associated with a nonsignificant 19% lower incidence of stroke (P=0.08) and a significant 41% lower incidence of stroke, respectively, than the incidence with higher targets. The intensive-treatment group in SPRINT had a nonsignificant 11% lower incidence of stroke, though SPRINT also excluded persons with prevalent stroke or transient ischemic attack at baseline.\n\n【61】In SPRINT, significant between-group differences were noted in some adverse effects that were attributed to the intervention . Orthostatic hypotension as assessed during a clinic visit  was observed less frequently in the intensive-treatment group than in the standard-treatment group (P=0.01), but syncope was more common among participants in the intensive-treatment group than among those in the standard-treatment group (3.5% vs. 2.4%, P=0.003), as was hypotension (3.4% vs. 2.0%, P<0.001). There was no between-group difference in injurious falls (hazard ratio, 1.00; P=0.97). There was a higher rate of acute kidney injury or acute renal failure in the intensive-treatment group, as noted above. These adverse events need to be weighed against the benefits with respect to cardiovascular events and death that are associated with intensive control of systolic blood pressure.\n\n【62】The strengths of SPRINT include a large sample size, the diversity of the population (including a large proportion of patients 75 years of age or older), and its success in achieving the intended separation in systolic blood pressure between the two intervention groups throughout the trial. The lack of generalizability to populations not included in the study — such as persons with diabetes, those with prior stroke, and those younger than 50 years of age — is a limitation. It is also worth noting that we did not enroll older adults residing in nursing homes or assisted-living facilities. In addition, the effects of the lower blood pressure on the central nervous system and kidney cannot be reasonably interpreted until analysis of these end points has been completed.\n\n【63】The SPRINT results raise important practical issues. Hypertension control to a blood pressure of less than 140/90 mm Hg is achieved in only about 50% of the general population in the United States, which suggests that control to even that level is challenging.  We excluded patients with more severe hypertension, and control of systolic blood pressure to less than 120 mm Hg required, on average, one additional antihypertensive drug. In addition, the median systolic blood pressure in the intensive-treatment group was just above 120 mm Hg, which indicates that more than half the participants had a systolic blood pressure above the 120 mm Hg target. These observations suggest that achieving a systolic blood-pressure goal of less than 120 mm Hg in the overall population of patients with hypertension would be more demanding and time-consuming for both providers and patients than achieving a goal of 140 mm Hg, and would necessitate increased medication costs and clinic visits.\n\n【64】In conclusion, targeting a systolic blood pressure of less than 120 mm Hg, as compared with less than 140 mm Hg, in patients at high risk for cardiovascular events but without diabetes resulted in lower rates of fatal and nonfatal major cardiovascular events and death from any cause. However, some adverse events occurred significantly more frequently with the lower target.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-14 00:20:25", "grab_time": "2024-08-13 23:05:25"}
{"id": 2234340, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "bbd0d1b4-1358-4401-97cc-c8ea1774d019", "title": "Asymptomatic Hyperinsulinemic Hypoglycemia after Gastric Banding", "text": "【0】Asymptomatic Hyperinsulinemic Hypoglycemia after Gastric Banding\nTo the Editor:\n--------------\n\n【1】Service et al. (July 21 issue)  recently reported on six patients with hyperinsulinemic hypoglycemia and nesidioblastosis after Roux-en-Y gastric bypass surgery. The authors postulated that the rapid presentation of nutrients in the duodenum stimulated excessive secretion of glucagon-like peptide 1, leading to islet-cell hypertrophy, proliferation, and neogenesis. This report prompted us to review the incidence of hyperinsulinemic hypoglycemia after laparoscopic adjustable gastric banding (LAGB), the most common bariatric procedure performed in Europe. This procedure effectively achieves gastric restriction and a durable weight loss in obese patients without permanently altering the intestinal anatomy, improves insulin resistance, and prevents the development of type 2 diabetes mellitus and hypertension. \n\n【2】Table 1. Body-Mass Index and Metabolic Data Obtained before Laparoscopic Adjustable Gastric Banding and during Episodes of Hyperinsulinemic Hypoglycemia.\n\n【3】We followed 221 patients who underwent LAGB for morbid (grade III) obesity (according to the classification system of the World Health Organization) and measured serum levels of glucose and insulin at 0 minutes and 120 minutes after administration of 75 g of glucose before surgery and at 6, 12, 18, 24, and 36 months after surgery. No patient had hyperinsulinemic hypoglycemia (serum glucose level, <55 mg per deciliter; serum insulin level, ≥3 μU per milliliter) 120 minutes after the ingestion of glucose before LAGB. During follow-up (433 patient-years), we recorded nine episodes of asymptomatic hyperinsulinemic hypoglycemia in eight patients (five women and three men, 23 to 47 years of age, none of whom were receiving insulin or sulfonylureas at the time of the episode) . All episodes were recorded 120 minutes after glucose ingestion, and six episodes occurred within one year after the patient had undergone LAGB. Assessment according to the homeostatic model (fasting insulin \\[μU per milliliter\\]×fasting glucose \\[mM per liter\\]÷22.5) indicated a profound reduction in insulin resistance in all eight patients. In seven of them, no further episodes of asymptomatic hyperinsulinemic hypoglycemia occurred during the additional median follow-up period of 12 months (range, 12 to 30).\n\n【4】Our data show that transient asymptomatic hyperinsulinemic hypoglycemia occurs in 3 to 4 percent of patients after LAGB. We hypothesize that the substantial weight loss after this procedure markedly reduces insulin resistance in the context of beta-cell hypertrophy and hyperfunction that are commonly found in obesity.  Further studies are needed to clarify the pathogenesis of transient hyperinsulinemic hypoglycemia after LAGB.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 11:04:20", "endTime": "2024/08/14 11:04:38", "cost": 17.453}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 19:04:38", "grab_time": "2024-08-13 19:04:20"}
{"id": 2234339, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "ef21d502-e513-474f-acb0-4dbbbd2b7925", "title": "Adjö — My Patient’s Prolonged Good-Bye", "text": "【0】Adjö — My Patient’s Prolonged Good-Bye\n“Do you know how to say _au revoir_ in Swedish?” the patient asks. Smiling, the physician pretends she’s answering for the first time. She can’t help but compare the life of this lonely 95-year-old to those of the respected Igbo elders she knew growing up in Nigeria.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:31:14", "endTime": "2024/08/14 14:34:35", "cost": 201.067}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 22:34:35", "grab_time": "2024-08-13 22:31:13"}
{"id": 2234338, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "369fe620-f31f-44d4-93f8-d4090b4ba0f7", "title": "Prevention of Hereditary Angioedema Attacks with a Subcutaneous C1 Inhibitor", "text": "【0】Prevention of Hereditary Angioedema Attacks with a Subcutaneous C1 Inhibitor\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Hereditary angioedema is a disabling, potentially fatal condition caused by deficiency (type I) or dysfunction (type II) of the C1 inhibitor protein. In a phase 2 trial, the use of CSL830, a nanofiltered C1 inhibitor preparation that is suitable for subcutaneous injection, resulted in functional levels of C1 inhibitor activity that would be expected to provide effective prophylaxis of attacks.\n\n【3】Methods\n-------\n\n【4】We conducted an international, prospective, multicenter, randomized, double-blind, placebo-controlled, dose-ranging, phase 3 trial to evaluate the efficacy and safety of self-administered subcutaneous CSL830 in patients with type I or type II hereditary angioedema who had had four or more attacks in a consecutive 2-month period within 3 months before screening. We randomly assigned the patients to one of four treatment sequences in a crossover design, each involving two 16-week treatment periods: either 40 IU or 60 IU of CSL830 per kilogram of body weight twice weekly followed by placebo, or vice versa. The primary efficacy end point was the number of attacks of angioedema. Secondary efficacy end points were the proportion of patients who had a response (≥50% reduction in the number of attacks with CSL830 as compared with placebo) and the number of times that rescue medication was used.\n\n【5】Results\n-------\n\n【6】Of the 90 patients who underwent randomization, 79 completed the trial. Both doses of CSL830, as compared with placebo, reduced the rate of attacks of hereditary angioedema (mean difference with 40 IU, –2.42 attacks per month; 95% confidence interval \\[CI\\], –3.38 to –1.46; and mean difference with 60 IU, –3.51 attacks per month; 95% CI, –4.21 to –2.81; P<0.001 for both comparisons). Response rates were 76% (95% CI, 62 to 87) in the 40-IU group and 90% (95% CI, 77 to 96) in the 60-IU group. The need for rescue medication was reduced from 5.55 uses per month in the placebo group to 1.13 uses per month in the 40-IU group and from 3.89 uses in the placebo group to 0.32 uses per month in the 60-IU group. Adverse events (most commonly mild and transient local site reactions) occurred in similar proportions of patients who received CSL830 and those who received placebo.\n\n【7】Conclusions\n-----------\n\n【8】In patients with hereditary angioedema, the prophylactic use of a subcutaneous C1 inhibitor twice weekly significantly reduced the frequency of acute attacks. \n\n【9】Introduction\n------------\n\n【10】Hereditary angioedema is a disabling and potentially fatal condition characterized by recurrent episodes of swelling without urticaria or pruritus. The condition is caused by deficiency (type I) or dysfunction (type II) of the C1 inhibitor protein.  Patients have insufficient C1 inhibitor function to prevent bradykinin production by the contact system, leading to episodes of increased capillary hyperpermeability and swelling. These episodes manifest clinically as angioedema attacks. \n\n【11】Low levels of C1 inhibitor protein antigen or low functional levels of C1 inhibitor activity, as well as low levels of complement C4, are diagnostic for hereditary angioedema, and baseline C1 inhibitor function has been reported to correlate with disease severity.  According to clinical observations, a sustained threshold level of approximately 40% functional C1 inhibitor activity has been reported to confer certain protection against recurrent attacks. \n\n【12】Regular intravenous C1 inhibitor replacement is effective at reducing the frequency and severity of attacks and has an acceptable safety and side-effect profile. A double-blind, placebo-controlled, crossover trial involving 22 patients with frequent attacks showed a 50% reduction in the frequency and severity of attacks with the use of an intravenous C1 inhibitor at a dose of 1000 IU twice weekly.  However, because of the technical difficulties of regular venous access, risks with the use of indwelling venous catheters, and patient considerations,  the development of a C1 inhibitor concentrate suitable for regular subcutaneous administration is of interest.\n\n【13】A phase 2 trial showed that administration of CSL830 (CSL Behring), a low-volume, human plasma–derived, pasteurized, nanofiltered C1 inhibitor preparation that is suitable for subcutaneous injection, resulted in a dose-dependent and constant increase in trough plasma levels of functional C1 inhibitor activity above 40%,  a biochemical finding expected to provide effective prophylaxis of attacks.\n\n【14】We describe the results of the Clinical Study for Optimal Management of Preventing Angioedema with Low-Volume Subcutaneous C1-Inhibitor Replacement Therapy (COMPACT), a phase 3 trial testing the hypothesis that a twice-weekly subcutaneous injection of CSL830, as compared with placebo, could reduce the frequency of attacks of hereditary angioedema in patients with frequent attacks.\n\n【15】Methods\n-------\n\n【16】Trial Oversight\n---------------\n\n【17】The trial was jointly designed by the sponsor (CSL Behring) and the steering committee. The protocol , available with the full text of this article at NEJM.org, was approved by the appropriate regulatory authorities and ethics committees or institutional review boards. All the patients provided written informed consent. An independent data and safety monitoring board regularly monitored trial safety and provided recommendations to the sponsor on safety-related trial conduct.\n\n【18】The investigators at each participating center collected the data, which were analyzed by the sponsor with input from the steering committee. The members of the steering committee had access to the data and vouch for the accuracy and completeness of the data and analyses and for the fidelity of the trial to the protocol . The manuscript was drafted by the first author and revised by all the authors. Medical writing assistance, which was paid for by CSL Behring, was provided by ApotheCom.\n\n【19】Patients\n--------\n\n【20】Eligible patients were 12 years of age or older and had a clinical and central laboratory diagnosis of type I or II hereditary angioedema (functional C1 inhibitor activity of <50% and C4 antigen level below the normal level). All the patients had had four or more attacks requiring immediate treatment or medical attention or causing clinically significant functional impairment over a 2-month period within 3 months before screening, as documented in the patient’s medical records.\n\n【21】During the trial, the protocol was amended to include patients who were receiving oral medications for prophylaxis of angioedema attacks, if they had received a stable dose for 3 months before screening and planned to continue throughout the trial. Patients who had received an intravenous C1 inhibitor for routine prophylaxis within 3 months before screening were excluded.\n\n【22】Trial Design\n------------\n\n【23】COMPACT was an international, prospective, multicenter, randomized, double-blind, placebo-controlled, dose-ranging trial. After screening, eligible patients entered a run-in period of up to 8 weeks. All the patients had a clinical diagnosis of hereditary angioedema that had been confirmed by means of central laboratory testing and had had at least two attacks during any consecutive 4-week period or at least one attack during the first 2 weeks of the run-in period. The patients were randomly assigned in a : ratio by means of an interactive-response system to receive CSL830 at a dose of 40 IU per kilogram of body weight during the first 16-week treatment period followed by placebo for the second 16-week treatment period or vice versa (i.e., placebo first and CSL830 second); or CSL830 at a dose of 60 IU per kilogram followed by placebo or vice versa .\n\n【24】Patients who had 12 or more attacks in a consecutive 4-week period (excluding the first 4 weeks of each treatment period) could progress to the next treatment period or to trial completion at the investigator’s discretion. An end-of-trial visit was scheduled 1 week after completion of the second treatment period or if a patient was withdrawn from the trial.\n\n【25】Treatment\n---------\n\n【26】CSL830 or placebo was administered by the patient twice weekly in a double-blind crossover manner during each treatment period. Blinded trial medication was provided as a lyophilized powder to be reconstituted with sterile water for injection; the dose was rounded up to the nearest milliliter per 500 IU. To maintain the blinding by varying the volume of the agent that each patient received during the two 16-week treatment periods, we provided a high-volume placebo (matching the volume of the 60-IU dose of CSL830) to patients who received the 40-IU dose of CSL830 and a low-volume placebo (matching the volume of the 40-IU dose of CSL830) to patients who received the 60-IU dose of CSL830.\n\n【27】Patients were trained to administer the injections at home. Injections were to be given by means of a manual slow-push method in a single site in the abdominal area, unless the investigator thought an alternative subcutaneous injection site was clinically more appropriate. Patients were permitted to use intravenous C1 inhibitor concentrate, icatibant, ecallantide, or fresh-frozen plasma as a rescue medication for on-demand treatment of attacks at any time during the trial or for preprocedural prophylaxis.\n\n【28】Clinical Assessments\n--------------------\n\n【29】Patients used an electronic diary on a daily basis to record symptoms, use of the trial drug, and any rescue therapy. The investigator reviewed the electronic diary at each trial visit and reported the details of the attack on the electronic case-report form. Functional C1 inhibitor activity and C1 inhibitor and C4 protein levels were measured, and clinical laboratory assessments were conducted throughout the trial at specified trial visits .\n\n【30】Outcome Measures\n----------------\n\n【31】The primary efficacy end point was the number of attacks of angioedema, as reported by the investigator. Secondary efficacy end points were the percentage of patients who had a response (≥50% reduction vs. placebo in the number of attacks) and the number of times that rescue medication was used. Exploratory end points included the number of days of angioedema symptoms, severity of attacks, and proportion of patients in whom the number of attacks was reduced to less than one attack per 4-week period from one attack or more per 4-week period with placebo. The numbers of attacks and uses of rescue medication were normalized for the number of days that the patient received the corresponding treatment.\n\n【32】Safety and the side-effect profile were monitored throughout the trial. Adverse events, serious adverse events, solicited local site reactions (including discomfort, swelling, bruising, or itching at the injection site), the presence of inhibitory anti–C1 inhibitor antibodies, results of viral serologic tests, and clinically significant abnormalities in laboratory assessments were assessed. In addition, a prespecified pharmacokinetic and pharmacodynamic analysis that was based on an interval-censored repeated time-to-event model was constructed to directly relate functional C1 inhibitor activity to the attack of angioedema.\n\n【33】Statistical Analysis\n--------------------\n\n【34】All efficacy analyses were performed in the intention-to-treat population, which included all the patients who had undergone randomization. Efficacy data were included from the beginning of week 3 for each treatment period to account for a run-in or washout period. The primary efficacy analysis was conducted without imputation for missing data. Safety analyses were based on the safety population, which included all the patients in the intention-to-treat population who had received at least one dose of a study drug.\n\n【35】We estimated that a sample size of 72 patients would provide a power of 80% to detect a relative difference in the primary end point of 30% between the two doses of CSL830 and a power of 99% to detect a difference between active treatment and placebo at an alpha level of 0.05, assuming that patients in the placebo group would have a mean number of 0.152 attacks per day. We estimated that 100 patients would need to undergo screening on the assumption that 20% of the patients would be ineligible to enter the treatment periods after the run-in period and that 10% of the patients who entered the treatment periods would withdraw before trial completion.\n\n【36】Descriptive statistics were used. For the comparison of the number of attacks and the number of times that rescue medication was used, normalized for the number of days that the patient received the corresponding treatment, a least-squares mean difference was estimated with 95% confidence intervals and P values with the use of a mixed-model accounting for the within-patient correlation. Hypothesis testing was performed hierarchically to preserve the preset level of significance of 0.05. Thus, we first tested the 60-IU dose of CSL830 versus low-volume placebo, and only if the null hypothesis was rejected at an alpha level of 0.05 did we test the 40-IU dose versus high-volume placebo. Testing of the 60-IU dose versus the 40-IU dose was considered to be exploratory and was always tested at an alpha level of 0.05 for informational purposes. All statistical tests were two-sided. Statistical analyses were conducted with the use of SAS software, version 9.1.3 (SAS Institute).\n\n【37】Results\n-------\n\n【38】Patients\n--------\n\n【39】The trial was conducted from December 2013 through October 2015. Overall, 115 patients were screened at 38 centers: 18 in the United States and 20 across Australia, Canada, the Czech Republic, Hungary, Israel, Italy, Romania, Spain, and the United Kingdom . Of the 90 patients who underwent randomization, 11 discontinued for various reasons .\n\n【40】Table 1. Baseline Characteristics of Patients in the Intention-to-Treat Population.\n\n【41】Demographic and baseline clinical characteristics of the patients are shown in Table 1 . In the 3 months before screening, 36% of the patients who received 40 IU of CSL830 per kilogram and 49% of those who received 60 IU per kilogram had received a prophylactic treatment to prevent attacks of angioedema. One of these patients continued to receive oral prophylaxis (danazol) during the trial. The mean (±SD) number of attacks per month during the run-in period, normalized for the number of days that the patient received the corresponding drug or placebo, was 4.6±2.2 for the 40-IU treatment sequences and 4.0±2.0 for the 60-IU treatment sequences. The mean duration of exposure was similar for all treatments: 16.3±1.6 weeks for 40 IU, 16.0±2.1 weeks for 60 IU, and 15.3±3.3 weeks for combined placebo.\n\n【42】Efficacy Results\n----------------\n\n【43】Table 2. Primary, Secondary, and Exploratory Efficacy End Points in the Intention-to-Treat Population.\n\n【44】Among patients who received CSL830, the rate of attacks of angioedema was lower than the rate among patients who received placebo. The mean difference, as compared with placebo, was –2.42 attacks per month (95% confidence interval \\[CI\\], –3.38 to –1.46) with 40 IU and –3.51 attacks per month (95% CI, –4.21 to –2.81) with 60 IU (P<0.001 for both comparisons) . No significant difference was seen between the 40-IU and 60-IU treatment sequences. The occurrence of symptoms and the use of rescue medication in each patient during each treatment period are shown in Figure S3 in the Supplementary Appendix .\n\n【45】Secondary and exploratory end points are also listed in Table 2 . In patients with data that could be evaluated at both doses, the median reduction in the normalized number of attacks versus placebo was 88.6% (interquartile range, 69.6 to 100.0) with 40 IU of CSL830 and 95.1% (interquartile range, 79.0 to 100.0) with 60 IU. The percentage of patients who had a response was 76% in the 40-IU group and 90% in the 60-IU group. Overall, 43% of the patients in the 40-IU group and 58% of those in the 60-IU group had at least a 90% reduction in attacks, and 53% of the patients in the 40-IU group and 71% of those in the 60-IU group had less than one attack per month. Overall, 38% of the patients in the 40-IU group and 40% of those in the 60-IU group did not have an attack, as compared with 9% and no patients, respectively, who received placebo. Patients in the 60-IU group had half as many attacks as those in the 40-IU group.\n\n【46】Figure 1. Attacks of Hereditary Angioedema, According to the Maximum Severity of the Attack.\n\n【47】The investigator graded the severity of each attack according to the intensity of the most severe symptom among the patients in the intention-to-treat population. Percentages may not total 100 because of rounding.\n\n【48】The average severity of attacks was lower in the patients who received CSL830 than in those who received placebo . Thirteen patients who received CSL830 had a total of 52 severe attacks, and 64 patients who received placebo had a total of 252 severe attacks. In line with the observed reduction in the number of attacks regardless of their location in the body, the number of patients who had laryngeal attacks was reduced with CSL830, with 5 patients in the 40-IU group, no patients in the 60-IU group, and 25 patients in the placebo group.\n\n【49】The mean normalized number of times that rescue medication was used was reduced with both doses of CSL830 versus placebo . The rate of use of rescue medication was 71.7% lower among the patients in the 60-IU group than among those in the 40-IU group. In the 60-IU treatment sequences, the rate of use of rescue medication was lower than the rate of attacks.\n\n【50】Figure 2. Relationship between Functional Levels of C1 Inhibitor Activity and the Relative Risk of an Attack of Hereditary Angioedema.\n\n【51】The relative risk was expressed as the risk in relation to the baseline risk before treatment among patients with an observed geometric mean baseline functional level of C1 inhibitor activity of approximately 25%. The red dashed line indicates the median of the model-based risk relationship; the surrounding shaded area indicates the prediction intervals (standard errors). The box plots indicate the range of observed baseline and predicted functional levels of C1 inhibitor activity at steady-state troughs after the administration of CSL830 at doses of 40 IU per kilogram and of 60 IU per kilogram. In each box plot, the red dot indicates the geometric mean, the vertical line inside the box the median, the left and right sides of the box the lower and upper quartiles, and the I bars the minimum and maximum values.\n\n【52】At screening, the levels of functional C1 inhibitor activity, C1 inhibitor protein, and C4 protein were similar across the three groups; after randomization, all three biomarkers showed a dose-dependent increase that reached steady state at week 3 . In the population-based exposure-response analysis, an inverse relationship between the predicted functional C1 inhibitor activity at the time of an attack and the relative risk of an attack was established .\n\n【53】Safety and Side Effects\n-----------------------\n\n【54】Table 3. Adverse Events Reported during the Trial.\n\n【55】Adverse events were reported by similar proportions of patients in the CSL830 groups and the placebo groups . The majority of reported adverse events were mild (in 95% of the patients in the 40-IU group, 76% of those in the 60-IU group, and 83% of those in the combined placebo group) and were reported by the investigators to be resolved by the end of the trial (98% of the patients in the 40-IU group, 94% of those in the 60-IU group, and 96% of those in the combined placebo group). Three adverse events led to trial discontinuation: pulmonary embolism in a patient who received placebo, urticaria in a patient who received 60 IU of CSL830, and an increase in liver aminotransferase levels in a patient who received 60 IU of CSL830) . Four serious adverse events were reported in three patients: one event (urosepsis) in a patient who received the 40-IU dose and three events (pulmonary embolism, attack of angioedema, and syncope) in patients who received placebo.\n\n【56】Most reported adverse events were injection-site reactions, which occurred in 31% of the patients who received CSL830 and in 24% of those who received placebo. Of the injection-site reactions, 95% in the CSL830 groups and 95% in the placebo groups were mild; 83% in the CSL830 groups and 90% in the placebo groups resolved within 1 day after onset.\n\n【57】No seroconversions for the human immunodeficiency virus or hepatitis B or C virus were observed during the trial; such testing was performed as a safeguard since CSL830 is a plasma-derived product. No anaphylactic reactions or inhibitory anti–C1 inhibitor antibodies were detected.\n\n【58】Discussion\n----------\n\n【59】In COMPACT, among patients with hereditary angioedema, we found that twice-weekly administration of CSL830 at doses of 40 IU per kilogram or 60 IU per kilogram provided an excellent and dose-dependent preventive effect, as evidenced across multiple trial end points. The median reduction in the attack rate relative to placebo was 89% with 40 IU and 95% with 60 IU in patients who had data that could be evaluated during the two 16-week treatment periods. This treatment effect was associated with an overall reduced need for rescue medication.\n\n【60】C1 inhibitor replacement for prophylaxis is currently approved only as intravenous therapy. Its use was first described in two case reports in 1989.  On the basis of a placebo-controlled study  and some open-label studies,  international guidelines recommend twice-weekly intravenous infusions of a C1 inhibitor preparation (1000 IU) for routine prophylaxis. \n\n【61】A previous randomized, controlled trial involving 22 patients showed the efficacy of an intravenous C1 inhibitor infusion regimen in preventing attacks of angioedema.  This trial showed a response rate (defined as ≥50% reduction in the frequency of attacks) of 50%.  With the use of similar criteria, a response rate of 76 to 90% was observed in our trial.\n\n【62】A recent study showed that patients who received twice-weekly intravenous C1 inhibitor prophylaxis had breakthrough attacks that tended to occur shortly before the next scheduled infusion.  These findings suggest that low trough levels of functional C1 inhibitor predispose a patient to an increased risk of an attack. When modeled pharmacokinetic profiles of intravenous and subcutaneous C1 inhibitor were compared,  the simulated profiles of functional C1 inhibitor activity showed a lower peak-to-trough ratio and more consistent, sustained, and higher trough values after subcutaneous administration than after intravenous administration. Therefore, the better treatment response rate with a subcutaneous C1 inhibitor may be related to a sustained increase in C1 inhibitor activity to a level that is closer to physiologic values. On the basis of the pharmacokinetic and pharmacodynamic modeling, an inverse relationship between the relative risk of an attack and functional C1 inhibitor activity was established . This finding suggests that if the C1 inhibitor activity level could be maintained closer to the lower limit of normal, the risk of an attack would approach zero. Data are lacking on the usefulness of individualized administration of C1 inhibitor replacement therapy to reach and maintain this target level.\n\n【63】The requirement for long-term, intravenous access with C1 inhibitor prophylaxis is a major clinical challenge, and despite expert advice to the contrary, subcutaneous ports are used, which can be associated with various medical complications.  A subcutaneous C1 inhibitor may help to overcome many of these disadvantages.\n\n【64】Our trial had a limited observation period of 14 weeks per treatment period (after the exclusion of the 2-week run-in or washout period). Therefore, it was not possible to assess the safety and preventive effects of long-term continuous prophylaxis with CSL830. A qualitative analysis is under way to explore reasons for the variability in patient responses. An open-label extension trial  is also ongoing to address this question and to investigate whether individual dose adjustments can further improve treatment response. This question was not addressed in the current trial.\n\n【65】In conclusion, we found that CSL830 significantly lowered the rate of hereditary angioedema attacks, as compared with placebo. More than 50% of the patients had no moderate-to-severe attacks while they were receiving CSL830.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-14 00:14:09", "grab_time": "2024-08-13 23:20:38"}
{"id": 2234337, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "c08527ba-3620-4f7c-9e3e-8855702949fc", "title": "Pregnancy Potential of Human Oocytes – The Effect of Cryopreservation", "text": "【0】Pregnancy Potential of Human Oocytes – The Effect of Cryopreservation\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】In vitro fertilization, sometimes involving the cryopreservation of human embryos, has become a routine procedure for the treatment of infertility. Even though there are embryos available for transfer in about 85 percent of the treatment cycles, the rate of pregnancy rarely exceeds 25 percent per cycle. We designed this study to investigate two questions: Does this high rate of failure result from inadequate technique, or does it simply reflect the maximal potential of a cohort of aspirated eggs to produce a pregnancy? And to what extent does cryopreservation affect the capacity for implantation of embryos?\n\n【3】Methods.\n--------\n\n【4】The study was conducted among patients enrolled in an egg-donation program. Aspirated eggs from a given cohort were distributed to the donor herself and a few recipients. The recipients were prepared by a standard protocol of hormone replacement and were assigned at random to the transfer of either fresh or frozen and thawed embryos. The donors received only fresh embryos.\n\n【5】Results.\n--------\n\n【6】Forty cycles of donation were studied. In 25 cycles (63 percent) pregnancy was established in the donor, in the recipient (or recipients), or in both. Of the fresh embryos that were transferred to the recipients, 24 percent were successfully implanted, as compared with only 7.7 percent of the frozen and thawed embryos (P<0.01). A pregnancy success rate of 37 percent per recipient cycle was observed in the recipients of fresh embryos, as compared with a rate of only 16 percent in those receiving frozen and thawed embryos (P<0.05).\n\n【7】Conclusions.\n------------\n\n【8】The majority of egg cohorts evidently possess the potential to produce a pregnancy, but cryopreservation of human embryos significantly reduces their capacity for implantation. \n\n【9】Introduction\n------------\n\n【10】IN VITRO fertilization has become a routine procedure for the treatment of infertility, with a pregnancy success rate in many centers of 20 to 25 percent per egg collection. Considerable effort has been invested in improving laboratory procedures, methods of oocyte retrieval, and techniques of ovarian stimulation, without marked improvement in treatment results. It is not clear that a pregnancy success rate of 25 percent is the highest that can be expected. The rate depends on the potential of the retrieved eggs to produce pregnancy. In the framework of routine in vitro fertilization, it has been impossible to design and carry out an effective study of the pregnancy-producing potential of retrieved eggs, because it has been impossible to identify, isolate, and control for the numerous variables, including the different protocols used for ovarian stimulation, the quality of the sperm used, the receptivity of the uterus, and the use of cryopreservation.\n\n【11】An opportunity to control for some of these variables emerged from our program of egg donation, begun in 1985, in which a cohort of eggs retrieved from a donor is distributed among a group of recipients including the donor herself. Consequently, eggs from a single retrieval procedure are inseminated by different samples of semen, and the resulting embryos are transferred into different uteri. As a result, the eggs are subjected to various conditions, so that the possible effects of semen, endometrial environment, or both are controlled for. In this study, we investigated the effects of the various conditions on the rate of pregnancy, calculated per cohort of eggs. The rates we obtained may reflect the potential of a cohort to result in pregnancy.\n\n【12】Using the same model, we also studied the effect of cryopreservation on the implantation of embryos. The cryopreservation of human embryos is now a routine procedure in many programs of in vitro fertilization.  <sup><a>2 </a></sup>  <sup><a>4 </a></sup> Its reported benefits include an increased chance of pregnancy from a single oocyte-recovery procedure  and a reduced risk of multiple pregnancy. Although this reduced risk would appear to be an obvious outcome of cryopreservation, it is debatable whether the chances of pregnancy per oocyte recovery are increased, especially since some embryos are likely to be damaged during cryopreservation itself. A correlation was recently reported between some morphologic features as seen on video recordings after cryopreserved embryos had been thawed and their capacity for implantation.  Very little is known about the capacity for implantation and the extent to which it may depend on the quality of the embryos or the suitability of the uterine environment. Nor is it known whether freezing and thawing affect the capacity of embryos for implantation.\n\n【13】In a program of egg donation, cryopreservation offers a way to match the age of the embryo with the state of the recipient's endometrium.  The same result can be achieved with fresh embryos, however, by applying various means of synchronization.  <sup>, </sup>  Our model of egg donation, in which embryos are transferred under similar conditions — either fresh or after freezing and thawing — into similarly prepared uterine environments, provided an opportunity to examine the effect of cryopreservation on the rate of implantation.\n\n【14】Methods\n-------\n\n【15】Egg Donors\n----------\n\n【16】In Israel the donation of oocytes is permitted only by healthy patients who have no detectable genetic diseases and who are themselves undergoing in vitro fertilization because of infertility. For our study, potential donors who fulfilled these criteria were asked to donate one third of their aspirated eggs. It was explained before they signed a consent form that such a donation might diminish their own chances of conceiving to some extent. The donors were given no information about the identity of the recipients or the fate of the donated eggs, and the identity of the donors was not known to the recipients.\n\n【17】Recipients\n----------\n\n【18】The recipients were mainly women with primary ovarian failure, with a normal uterus and an adequate endometrial response to hormone replacement therapy (as judged by endometrial biopsies). Results of the husband's sperm analysis were normal in each case. All the recipients and their husbands gave written informed consent, including a statement that the newborn would be acknowledged as their own, regardless of any complications.\n\n【19】Hormone Replacement Therapy\n---------------------------\n\n【20】Estradiol valerate was administered, initially at a dose of 1 mg per day. The dose was increased by 1 mg every day for the next five days. The dose was then reduced to 2 mg per day, and it was maintained at that level for the remainder of the cycle. On the second day of the maintenance dose of estradiol, 100 mg of progesterone per day was added, given in vaginal suppositories. This day was considered to correspond to the day of egg retrieval in the donors.\n\n【21】Ovarian Stimulation, Oocyte Retrieval, and Laboratory and Freezing Techniques\n-----------------------------------------------------------------------------\n\n【22】Two protocols of ovarian stimulation were used in the donors. In the first, 3.2 mg of a gonadotropin-releasing hormone analogue (D-Trp-6, decapeptyl depot controlled release, Ferring, Malmö, Sweden) was given on day 21 of the natural cycle, followed two weeks later by 225 IU of human menopausal gonadotropin (Teva, Kefar Sava, Israel) per day. In the second, 225 IU of human menopausal gonadotropin a day was given starting on the third day of the natural cycle. In both protocols, human chorionic gonadotropin (Chorigon, Teva) was injected after six days of increased serum estradiol levels,  provided that the largest follicle reached 18 mm in diameter and estradiol levels were higher than 1835.5 pmol per liter (about 500 pg per milliliter). Oocytes were retrieved by ultrasonographically guided vaginal puncture and were cultured in modified Earle's medium. The method of freezing and thawing was that of Lassalle et al.  At the stage of two to four cells, the embryos were dehydrated with propylene glycol and 0.1 M sucrose and then frozen in a programmed freezer (Planer, Sunbury on Thames, U.K.). Rapid thawing was performed in the presence of 0.2 M sucrose.\n\n【23】Synchronization of Cycles for the Transfer of Fresh Embryos\n-----------------------------------------------------------\n\n【24】In cycles selected for the transfer of fresh embryos, we synchronized the cycles of the recipients with that of the donor, using the so-called six-day rule,  which suggests that the median duration of the increase in estradiol during the follicular phase is six days. Hence, the recipients started to receive estradiol valerate on the day an increase was first noted in the donor. Exogenous progesterone was begun in the recipients on the day of egg retrieval.\n\n【25】Synchronization of Cycles for the Transfer of Cryopreserved Embryos\n-------------------------------------------------------------------\n\n【26】All embryos allocated for cryopreservation were frozen, regardless of their morphologic features. The recipients were treated with the same hormone-replacement protocol as those awaiting the transfer of fresh embryos. The cryopreserved embryos were thawed and transferred on the third day of progesterone therapy, which corresponded hormonally with 48 hours after egg retrieval in the donors.\n\n【27】Study Protocol\n--------------\n\n【28】Thirty-two donors were treated in 40 donation cycles. The donated oocytes were distributed among 57 recipients treated in 84 cycles. Donation cycles were randomly assigned to the transfer of fresh embryos or cryopreservation. Two thirds of a donor's retrieved eggs were set aside for the donor herself, and the remaining one third was allocated to one or more recipients. The eggs thus allocated were then inseminated by the semen of the recipient's husband. Eggs originating from the same cohort were thus inseminated by different semen, and the resulting embryos, either fresh or after cryopreservation, were transferred into different uteri whose environments had all been prepared in the same way. There was no selection of embryos for freezing, and after thawing, all embryos that were not degenerating were transferred. In the donors all the available embryos were transferred fresh during the hyperstimulated cycles. In this study we defined pregnancy as any instance of established pregnancy, regardless of the number of embryos implanted. Implantation refers to the total number of implanted embryos. Embryos transferred were those that were judged suitable for replacement.\n\n【29】Results\n-------\n\n【30】Table 1. Donor Age, Number of Aspirated Eggs per Cycle, and Fertilization Rate in Donor Cycles Resulting in Pregnancy as Compared with Those Failing to Produce Pregnancy.\\*\n\n【31】Of 40 consecutive cycles of egg donation, pregnancy was established in 25 (63 percent). In 9 cycles (23 percent) either the donor or the donor plus the recipient (or recipients) conceived, and in 16 cycles (40 percent) only the recipient (or recipients) conceived. As shown in Table 1 , there were no differences in the mean age of the donors, mean number of eggs aspirated per retrieval procedure, or rate of fertilization between the donor cycles that resulted in pregnancy and those that did not. The donors were treated for mechanical infertility (26 cycles), unexplained infertility (9 cycles), endometriosis (3 cycles), and male infertility (3 cycles). Eggs from 18 cycles in women with mechanical infertility produced pregnancies (69 percent) in the donors, recipients, or both. Eggs from three cycles in women with unexplained infertility led to pregnancy (33 percent), and from one cycle in a woman with endometriosis (33 percent). All three cycles involving treatment for male infertility led to pregnancies in the recipients (100 percent).\n\n【32】Table 2. Comparison of Donor Cycles According to Whether Embryos Were Transferred Fresh or Frozen and Thawed.\\*\n\n【33】With respect to cryopreservation, of the 40 cycles of egg donation, 17 were synchronized for the transfer of fresh embryos to recipients other than the donor, and 13 of these (76 percent) resulted in pregnancy in the donors or the recipients . Embryos from the other 23 cycles were cryopreserved, and they produced pregnancies in 12 cycles in the recipients (52 percent). (Donors received only fresh embryos.) The mean age of the donors was similar in the two groups.\n\n【34】Table 3. Treatment Results in Recipient Cycles Synchronized for the Transfer of Fresh Embryos, as Compared with Those Synchronized for the Transfer of Frozen and Thawed Embryos.\\*\n\n【35】The results of treatment in the recipients are shown in Table 3 . The mean number of oocytes and the rate of fertilization were similar in the recipient cycles synchronized for the transfer of fresh embryos and those synchronized for the transfer of cryopreserved embryos. The implantation rate of fresh embryos, however, was significantly higher than that of frozen and thawed embryos (24 vs. 7.7 percent, P<0.01). Moreover, the rate of pregnancy in the group receiving fresh embryos was also significantly higher (37 vs. 15 percent, P<0.05).\n\n【36】Discussion\n----------\n\n【37】The relatively low rate of implantation (9 to 11 percent) in most in vitro fertilization programs may be attributable to several factors associated with the procedure — the eggs, the sperm, the endometrium, and the laboratory techniques. Probably all these factors contribute in some measure to the unsatisfactory success rate of in vitro fertilization. In order to improve the rate of pregnancy, more information is needed about the contribution of each variable to the theoretical potential for pregnancy, but in the framework of a routine in vitro fertilization program it is not possible to separate the relative contributions. The use of cryopreservation permits some flexibility in the time between in vitro fertilization and the transfer of embryos, but it introduces new hazards to the embryo. Moreover, technical and ethical problems make it difficult to evaluate the results of cryopreservation of human embryos for the following reasons: embryos are in most cases preselected for cryopreservation, and normally only those with good morphologic features are considered; embryos damaged during cryopreservation are not transferred, so they are usually not included in the analysis of results; and there is no proper control group for studying the effect of cryopreservation on the implantation of embryos, because the embryos with the best morphologic features are chosen for fresh transfer during the stimulation cycle. In our study most of these difficulties were eliminated: eggs were randomly allocated for donation; there was no selection of embryos before freezing; endometria were prepared with identical protocols; and all frozen embryos were thawed and transferred regardless of morphologic features. The significantly lower rate of implantation in frozen and thawed embryos (7.7 percent) as compared with fresh embryos (24 percent) can thus be attributed to the use of cryopreservation.\n\n【38】Our experimental design made it possible to isolate the potential contributions of poor-quality sperm and nonreceptive endometria to the failure of implantation, because more than one sample of semen was used for each cohort of eggs, and the resulting embryos were transferred into more than one uterus. In this way we could come closer to determining the actual potential of a cohort of aspirated eggs to produce pregnancy. Our findings indicate that most (63 percent) of the cohorts aspirated in this study could result in pregnancy when provided with favorable conditions (sperm of good quality and a properly stimulated endometrium). It should be noted that the embryos from more than half the cohorts in this series were cryopreserved, resulting in a lower rate of pregnancy (52 percent). The true potential of these egg cohorts was thus probably higher than the rate of 63 percent we obtained. When only fresh embryos were transferred, 76 percent of the egg cohorts produced a pregnancy. This pregnancy rate of 76 percent is in accord with our findings in a previous series of egg-donation cycles, in which only fresh embryos were transferred and 84 percent of the cohorts produced a pregnancy.  The high rate of pregnancy per cohort may be partly explained by the nature of egg donation itself: embryos that are foreign to the mother may be more effective in evoking an immune response required for implantation. Our finding that fresh embryos were implanted better in the recipients than in the donors may be also due to an immune phenomenon. A possible contribution of unrecognized male factors cannot be excluded, however, since simple semen analysis does not fully correlate with male fertility. It is also possible that an excess of embryos in the donors may actually decrease the chances of pregnancy, since multiple oocytes are most often the product of a cycle with high levels of estradiol and progesterone. The resulting overstimulation of the endometrium could be detrimental to implantation.\n\n【39】The findings of our study indicate that, at least in cases of egg donation, a better rate of pregnancy can be achieved using protocols of synchronization based on the transfer of fresh embryos. In contrast to this program, in which no more than three embryos were available for transfer to a recipient, a routine program of in vitro fertilization and embryo transfer might make more embryos available for transfer. The possible benefits of transferring fresh embryos could thus be complicated by the risks of multiple implantations, currently the main cause of perinatal morbidity in pregnancies involving in vitro fertilization. Acosta et al.  studied the effect of the number of embryos transferred on the chances of multiple implantation. They reported that in 81 patients with multiple pregnancy resulting from in vitro fertilization, 2.2 embryos per cycle were able to establish a normal pregnancy, regardless of the number of \"preembryos\" transferred. These findings indicate that the transfer of five embryos rather than three or four does not necessarily increase the chance of multiple pregnancy. On the other hand, two thirds of the frozen and thawed embryos in our study lost their potential to establish a pregnancy. When the number of embryos to be used in fresh transfer is being determined, both points should be kept in mind. In the absence of more reliable ways to predict the potential of a given embryo for pregnancy, the morphologic features of the blastomeres could be taken as a possible guideline. Unless there are at least two or three morphologically sound embryos available for fresh transfer, we recommend that no embryos be allocated to cryopreservation.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 11:00:06", "endTime": "2024/08/14 11:01:06", "cost": 60.015}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 19:01:06", "grab_time": "2024-08-13 19:00:06"}
{"id": 2234336, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "63eee45e-8111-460e-973a-6212ee84caaf", "title": "Identifying and Tracking SARS-CoV-2 Variants — A Challenge and an Opportunity", "text": "【0】Identifying and Tracking SARS-CoV-2 Variants — A Challenge and an Opportunity\nArticle\n-------\n\n【1】The emergence of worrisome variants of the SARS-CoV-2 virus has exposed the limited scale of surveillance efforts in the United States. More than 30 other countries conduct more sequencing of viral isolates than the United States does, thereby permitting greater understanding of the potential threat associated with various variants.  To address this challenge, the Biden administration is planning to spend $1.75 billion included in the March 2021 American Rescue Plan on strengthening and expanding activities related to genomic sequencing, analytics, and disease surveillance and the workforce in these areas.  This funding provides an opportunity to work toward establishing a more coherent and organized public health response system.\n\n【2】Public health surveillance encompasses the interactive system of public health agencies at various levels (including federal, state, and local) working with health care providers and the public to detect, report, and prevent illness and death.  These activities depend on the availability of accurate and timely data that can be analyzed using modern epidemiologic methods.  In the United States, public health surveillance and data systems are poorly funded, however, and they exist in silos. To avoid simply supporting the development of new silos for sequencing SARS-CoV-2 isolates, we believe the administration could pursue several approaches to building stronger surveillance infrastructure for the future.\n\n【3】First, to solve the current problem related to Covid-19 surveillance and tracking of variants, the federal government could build on the country’s existing network of 130 state and local public health laboratories to expand capacity in the multiple areas required to support genomic surveillance. These laboratories already use next-generation sequencing to monitor seasonal influenza, identify pathogens associated with foodborne disease outbreaks, and track antimicrobial resistance, among other applications.\n\n【4】In recent years, state and local laboratories have been constrained by budget cuts and personnel attrition. Ensuring that a strong genomic-sequencing effort is maintained over the long term in every public health laboratory would promote a much-needed rebuilding process. Funds are needed not only to build instrument and information-technology infrastructure and enable electronic data acquisition and transfer but also to support academic and professional training programs in expanding the workforce by building a pipeline of students with appropriate laboratory, data analytic, and epidemiologic skills.\n\n【5】Having fully resourced and highly capable state and local laboratories operating in the high-complexity, wet-bench mode and performing low-complexity testing in nontraditional sites using point-of-care devices would result in a more resilient national surveillance system. It would enable the development of skills and resources that could be applied to a range of pathogens beyond SARS-CoV-2. If such a system had been in place in late 2019, some of the testing difficulties that the United States experienced early in the Covid-19 pandemic might have been avoided. \n\n【6】Second, the newly designated funding could be used to build and support a national, publicly accessible database of viral sequences. A substantial amount of Covid-19 laboratory data has remained locked within single institutions or has been submitted to restricted databases. When each institution pursues its own research mission in isolation, the ability to identify larger, important trends is compromised. To counter this phenomenon, the government could require all laboratories — both public and private — that receive federal funding to immediately share sequencing information and associated metadata with a national, publicly accessible database, modeled in part on the system at the National Institutes of Health’s National Center for Biotechnology Information. It will be important to ensure that the database-submission process is simple, efficient, and straightforward. Whenever possible, submissions should be linked to metadata with clinical information about patients, an approach similar to that used by the United Kingdom’s Covid-19 surveillance program.\n\n【7】Data that are stored in this warehouse and stripped of individually identifiable patient information should be accessible to government and academic researchers. The Centers for Disease Control and Prevention (CDC) could create a governance structure to oversee the use of these data — one that considers issues such as patient privacy and intellectual property. Whether the warehouse is established at the CDC or elsewhere in coordination with the CDC and other federal agencies, the database’s initial guiding principle should be to promote broad use to address Covid-19. The information collected in the database will be invaluable for the development of new metagenomic-analysis tools; for research on pathogen properties, including virulence, host range, and the potential for drug resistance; and most important, for the development of new therapeutics.\n\n【8】Third, the new funds could support the establishment of a national public health data network. The United States has too many stand-alone, disconnected surveillance networks that require their own data-collection systems and data-transfer pathways. It makes little sense to have separate workflows and information systems for each pathogen or public health problem.\n\n【9】Genomic-sequencing funds could be tapped to develop a new, flexible infrastructure that could ultimately support broad pathogen surveillance and data modernization for genomic sequencing for many infectious diseases. Eventually, such an effort might require a less-siloed organizational structure at the CDC. The agency could establish a training program to provide education on using these data, with training available at the state and local levels to boost investigational capacity.\n\n【10】Finally, funding for addressing SARS-CoV-2 variants could go toward fostering a new model of collaboration between public health and academic medicine. Public health agencies must monitor and respond to the urgent challenges facing populations; academic researchers excel at making discoveries that advance knowledge and capabilities. Too often, these worlds are isolated, thereby limiting opportunities for implementing research findings that could have practical applications for improving health.\n\n【11】To avoid a similar fate for genomic-sequencing efforts, the Department of Health and Human Services (HHS) could create a funding mechanism that requires state and local public health laboratories and their parent agencies to establish formal partnerships with academic medical centers. The model would align academia’s role in developing new technical methods and data-analysis tools with public health’s role in implementing these tools in the field. In addition to supporting the development of a pipeline for students interested in public health careers, this approach could become a model for further collaboration between academic medicine and public health.\n\n【12】Guiding near-term Covid-19 initiatives using these strategies won’t be easy. The current scattered approach to public health surveillance reflects our health care system’s disorganization, the chronic underfunding of public health, and the inconsistent engagement of academic medicine in these efforts. Fixing these problems will require strong federal leadership, starting with an empowered team at HHS that can set conditions for spending the funds included in the American Rescue Plan to bring about important changes. Success will pay dividends not only during the Covid-19 pandemic but also for other major health threats. It will lead to more effective ways of tracking and controlling seasonal influenza and other respiratory diseases, antibiotic resistance, and the emergence of new pathogens.\n\n【13】Covid-19 has caused hardship and loss for millions of Americans, and the emergence and spread of viral variants raise concerns that our global battle with the pandemic is far from over. Even as these variants expose the weaknesses in our laboratory infrastructure, new investments create the potential for designing a stronger public health system for the future. Funding designated for increasing our understanding of SARS-CoV-2 variants could be used in ways that would help guide the current pandemic response and yield benefits for years to come.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:46:17", "endTime": "2024/08/14 14:46:41", "cost": 24.508}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 22:46:41", "grab_time": "2024-08-13 22:46:16"}
{"id": 2234335, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "fad70974-43b9-42fb-a34e-419b4f072c01", "title": "Turnover of Epidermal Langerhans' Cells", "text": "【0】Turnover of Epidermal Langerhans' Cells\nTo the Editor:\n--------------\n\n【1】Langerhans' cells are epidermal dendritic, antigen-presenting cells. Data from experiments in animals and observations in humans after transplantation of sex-mismatched bone marrow allografts have shown that Langerhans' cells originate from bone marrow precursors.  However, epidermal Langerhans' cells are capable of self-regeneration, as shown by the incorporation of \\[  H\\]thymidine or bromodeoxyuridine  and by electron-microscopical observations of mitotic Langerhans' cells.  Recent data from studies in chimeric mice suggest that, under steady-state conditions, the efflux of Langerhans' cells to local lymph nodes would be balanced by the division of Langerhans' cells within the epidermis, whereas under conditions that severely deplete epidermal Langerhans' cells, keratinocyte-produced chemokines would recruit Langerhans'-cell precursors from the peripheral blood. \n\n【2】Figure 1. Immunostaining for Langerhans' Cells in the Skin of the Allograft (Immunoperoxidase with Aminoethylcarbazole).\n\n【3】Panel A shows Langerhans' cells detected in the epidermis of the allograft 4.5 years after transplantation. In Panel B, the anti–HLA-24 antibody reveals some lymphoid HLA-A24–positive cells of recipient origin in the dermis of the allograft. No reactivity is evident within the epidermis.\n\n【4】So far, little is known about the kinetics of human epidermal Langerhans' cells under steady-state conditions. We report our observations concerning the presence of epidermal Langerhans' cells in the first double human hand allograft (transplantation was performed in January 2000).  The recipient (but not the donor) was positive for HLA-A24. Twenty-four punch-biopsy specimens were taken from the skin of the allografts from day 0 to 4.5 years after transplantation. Tissue sections were immunolabeled with antibodies that recognize Langerhans' cells (CD207 \\[Langerin\\], CD1a, and S100 protein). Cells of recipient origin within the allograft were detected by immunolabeling with an antibody to the recipient's specific HLA-A24 antigen. Langerhans' cells were detected within the epidermis in all biopsy specimens of the allograft skin. Their number, distribution, and morphologic features appeared normal . The anti–HLA-24 antibody labeled cells of the recipient's own skin; by contrast, no reactivity was detected in the epidermis of the allografts at any time after transplantation, although occasional lymphoid HLA-A24–positive cells were present in the dermis .\n\n【5】These results, showing that the Langerhans' cells present in the skin of the allografts remained of donor origin over a 4.5-year period, strongly suggest that, under steady-state conditions, the replacement of human epidermal Langerhans' cells by cells of bone marrow origin occurs at a very slow rate, if at all. In this patient, epidermal Langerhans' cells of the allograft may have persisted unchanged during the study period or may have been partly renewed from Langerhans'-cell precursors in the allograft. We conclude that in humans, as in mice,  the replacement of epidermal Langerhans' cells by cells from bone marrow progenitors under steady-state conditions is very slow. A longer follow-up of this patient (or of other recipients of composite-tissue allografts containing skin) will show whether, under the influence of danger signals, some or all of the epidermal population of Langerhans' cells in the allograft will be replaced by cells that originate in the recipient's bone marrow.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-14 00:12:48", "grab_time": "2024-08-13 22:51:15"}
{"id": 2234334, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "5fe6a109-f61e-42d3-ae23-7faaf24fbce2", "title": "Case 33-2009 — A 35-Year-Old Woman with Fever, Abdominal Pain, and Hypotension after Cesarean Section", "text": "【0】Case 33-2009 — A 35-Year-Old Woman with Fever, Abdominal Pain, and Hypotension after Cesarean Section\nA 35-year-old woman was transferred to this hospital because of abdominal pain, fever, and hypotension 3 days after an elective cesarean section. On examination, she appeared acutely ill. The temperature was 39.2°C, the blood pressure 70/52 mm Hg, and the pulse 149 beats per minute. The abdomen was distended and very tender, with rebound. There was erythema and edema in the region of the surgical incision, extending to the left flank, with no drainage. A diagnostic procedure was performed.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:51:33", "endTime": "2024/08/14 15:51:42", "cost": 9.44}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 23:51:42", "grab_time": "2024-08-13 23:51:32"}
{"id": 2234333, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "6ac11dc8-f6fe-4162-85ac-7aee3d7f3c99", "title": "Romosozumab or Alendronate for Fracture Prevention in Women with Osteoporosis", "text": "【0】Romosozumab or Alendronate for Fracture Prevention in Women with Osteoporosis\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Romosozumab is a monoclonal antibody that binds to and inhibits sclerostin, increases bone formation, and decreases bone resorption.\n\n【3】Methods\n-------\n\n【4】We enrolled 4093 postmenopausal women with osteoporosis and a fragility fracture and randomly assigned them in a  ratio to receive monthly subcutaneous romosozumab (210 mg) or weekly oral alendronate (70 mg) in a blinded fashion for 12 months, followed by open-label alendronate in both groups. The primary end points were the cumulative incidence of new vertebral fracture at 24 months and the cumulative incidence of clinical fracture (nonvertebral and symptomatic vertebral fracture) at the time of the primary analysis (after clinical fractures had been confirmed in ≥330 patients). Secondary end points included the incidences of nonvertebral and hip fracture at the time of the primary analysis. Serious cardiovascular adverse events, osteonecrosis of the jaw, and atypical femoral fractures were adjudicated.\n\n【5】Results\n-------\n\n【6】Over a period of 24 months, a 48% lower risk of new vertebral fractures was observed in the romosozumab-to-alendronate group (6.2% \\[127 of 2046 patients\\]) than in the alendronate-to-alendronate group (11.9% \\[243 of 2047 patients\\]) (P<0.001). Clinical fractures occurred in 198 of 2046 patients (9.7%) in the romosozumab-to-alendronate group versus 266 of 2047 patients (13.0%) in the alendronate-to-alendronate group, representing a 27% lower risk with romosozumab (P<0.001). The risk of nonvertebral fractures was lower by 19% in the romosozumab-to-alendronate group than in the alendronate-to-alendronate group (178 of 2046 patients \\[8.7%\\] vs. 217 of 2047 patients \\[10.6%\\]; P=0.04), and the risk of hip fracture was lower by 38% (41 of 2046 patients \\[2.0%\\] vs. 66 of 2047 patients \\[3.2%\\]; P=0.02). Overall adverse events and serious adverse events were balanced between the two groups. During year 1, positively adjudicated serious cardiovascular adverse events were observed more often with romosozumab than with alendronate (50 of 2040 patients \\[2.5%\\] vs. 38 of 2014 patients \\[1.9%\\]). During the open-label alendronate period, adjudicated events of osteonecrosis of the jaw (1 event each in the romosozumab-to-alendronate and alendronate-to-alendronate groups) and atypical femoral fracture (2 events and 4 events, respectively) were observed.\n\n【7】Conclusions\n-----------\n\n【8】In postmenopausal women with osteoporosis who were at high risk for fracture, romosozumab treatment for 12 months followed by alendronate resulted in a significantly lower risk of fracture than alendronate alone. \n\n【9】Introduction\n------------\n\n【10】 QUICK TAKE  \nRomosozumab vs. Alendronate for Osteoporosis (ARCH Trial)  \n\n【11】Fragility fractures are common and increase morbidity and mortality.  Romosozumab (Amgen and UCB Pharma) is a new bone-forming monoclonal antibody that binds to and inhibits sclerostin, with a dual effect of increasing bone formation and decreasing bone resorption. \n\n【12】In a randomized, controlled trial,  1 year of romosozumab treatment was associated with significantly lower risks of new vertebral fracture and clinical fracture (a composite of nonvertebral fracture and symptomatic vertebral fracture) than placebo among postmenopausal women with osteoporosis. That trial excluded patients with severe osteoporosis and thus enrolled a relatively low-risk population.  In that context, the risk of nonvertebral fracture was not significantly lower with romosozumab than with placebo.\n\n【13】Alendronate is an antiresorptive agent commonly used as first-line therapy for osteoporosis. In a trial involving postmenopausal women with prevalent fractures, the risks of vertebral and clinical (in particular, hip) fractures were lower with alendronate than with placebo. \n\n【14】There are few head-to-head studies of osteoporosis therapy with fracture end points, and only one trial evaluating bone-building versus antiresorptive therapy was designed with fracture as the primary end point.  In the Active-Controlled Fracture Study in Postmenopausal Women with Osteoporosis at High Risk (ARCH), we compared the effectiveness of a treatment regimen starting with romosozumab and transitioning to alendronate with alendronate treatment alone in reducing the risk of fracture among postmenopausal women with osteoporosis and a previous fracture.\n\n【15】Methods\n-------\n\n【16】Trial Design\n------------\n\n【17】Figure 1. Trial Schema.\n\n【18】Women were randomly assigned, in a  ratio, to receive 210 mg of romosozumab by subcutaneous injection once monthly or 70 mg of alendronate orally every week for 12 months for the double-blind period of the trial, followed by open-label alendronate until the time of the primary analysis; the initial treatment assignment remained blinded. The primary analysis was performed when events of clinical fracture (nonvertebral and symptomatic vertebral fracture) had been confirmed in at least 330 patients and all the patients had completed the month 24 visit. The median follow-up at the time of the primary analysis was 2.7 years (interquartile range, 2.2 to 3.3). Bone mineral density was assessed at the lumbar spine and proximal femur in all the patients at baseline and every 12 months thereafter, and also at months 6 and 18 in a substudy of the total patient population that involved 167 patients. Levels of bone-turnover markers were assessed at baseline (day 1) and months 1, 3, 6, 9, 12, 15, 18, 24, and 36 or until the primary analysis, whichever came first, in a subgroup of 277 patients from the total patient population.\n\n【19】In this phase 3, multicenter, international, randomized, double-blind trial, women were randomly assigned, in a  ratio, with the use of an interactive voice-response system, to receive monthly subcutaneous romosozumab (210 mg) or weekly oral alendronate (Merck; 70 mg) for 12 months . Randomization was stratified according to age (<75 vs. ≥75 years). After completion of the double-blind trial period, all the patients received open-label weekly oral alendronate (70 mg) until the end of the trial, with blinding to the initial treatment assignment maintained. Patients received daily calcium and vitamin D, as described previously.  In this trial designed to show the superiority of romosozumab over alendronate, the primary analysis was performed when clinical-fracture events had been confirmed in at least 330 patients and all the patients had completed the month 24 visit.\n\n【20】Trial Oversight\n---------------\n\n【21】The trial protocol , available with the full text of this article at NEJM.org, was approved by the ethics committee or institutional review board at each trial center. Patients provided written informed consent before any trial procedures were performed. Amgen and UCB Pharma designed the trial, and Amgen was responsible for trial oversight and data analyses per a prespecified statistical analysis plan. An external independent data monitoring committee monitored unblinded safety data.\n\n【22】Three authors (one academic author and two employees of Amgen) vouch for the accuracy and completeness of the data and analyses reported and for the fidelity of the trial to the protocol. All the authors had access to the data. The first and last authors wrote the first draft of the manuscript, with medical-writing assistance funded by Amgen and UCB Pharma. All the authors contributed to subsequent drafts and made the decision to submit the manuscript for publication. Trial investigators signed agreements with the sponsors relating to data confidentiality.\n\n【23】Patients\n--------\n\n【24】Ambulatory postmenopausal women 55 to 90 years of age who met at least one of the following criteria were eligible: a bone mineral density T score of –2.5 or less at the total hip or femoral neck and either one or more moderate or severe vertebral fractures or two or more mild vertebral fractures; or a bone mineral density T score of –2.0 or less at the total hip or femoral neck and either two or more moderate or severe vertebral fractures or a fracture of the proximal femur sustained 3 to 24 months before randomization. Women were excluded as described previously  and for an inability to take alendronate oral tablets or contraindications to alendronate, including a glomerular filtration rate below 35 ml per minute per 1.73 m <sup>2 </sup> of body-surface area.\n\n【25】Procedures\n----------\n\n【26】Lateral radiographs of the thoracic and lumbar spine were obtained at screening, at months 12 and 24, and every 12 months thereafter until the time of the primary analysis. Radiographs were assessed at a central imaging center, as described previously, as were nonvertebral fractures . \n\n【27】The bone mineral density at the lumbar spine and proximal femur was evaluated by means of dual-energy x-ray absorptiometry (Lunar or Hologic) at baseline and every 12 months thereafter; in a subgroup of 167 patients, assessment was also performed at months 6 and 18. Serum concentrations of the bone-turnover markers β-isomer of C-terminal telopeptide of type I collagen (β-CTX; LabCorp) and procollagen type 1 N-terminal propeptide (P1NP; Covance) were measured in a subgroup of 277 patients.\n\n【28】Adverse events were reported by individual trial sites. Serious cardiovascular adverse events were adjudicated by the Duke Clinical Research Institute, and potential cases of osteonecrosis of the jaw and atypical femoral fracture were adjudicated by independent committees. Serum was tested for anti-romosozumab antibodies at day 1 and until month 24; samples that were positive for binding antibodies were assessed for neutralizing antibodies.\n\n【29】Primary and Secondary End Points\n--------------------------------\n\n【30】The primary end points of this trial were the cumulative incidence of new vertebral fracture at 24 months and the cumulative incidence of clinical fracture (nonvertebral and symptomatic vertebral fracture) at the time of the primary analysis. Bone mineral density at the lumbar spine, total hip, and femoral neck at 12 and 24 months and the incidence of nonvertebral fracture at the time of the primary analysis were key secondary end points. Other fracture categories, including hip fracture, were evaluated as additional secondary end points.\n\n【31】Statistical Analysis\n--------------------\n\n【32】The trial was powered to show superiority, with 94% power to detect a 30% lower risk of clinical fracture in the romosozumab-to-alendronate group than in the alendronate-to-alendronate group at the time of the primary analysis and 95% power to detect a 50% lower risk of new vertebral fracture over a period of 24 months. If the differences in both primary end points were significant with the use of the Hochberg procedure,  a fixed-sequence testing procedure was to be used for bone mineral density and the key secondary end point of nonvertebral fracture to adjust for multiple comparisons and to maintain an overall significance level of 0.05. The nonvertebral-fracture end point was tested by means of a group sequential approach at the time of the primary analysis with the use of a Lan–DeMets alpha spending function . All remaining secondary and exploratory efficacy end points were analyzed at a significance level of 0.05 (two-sided).\n\n【33】All analyses of treatment effect used an intention-to-treat approach. Analyses of vertebral-fracture end points included all randomly assigned patients with a baseline radiograph and at least one radiograph obtained after baseline. When a radiograph assessment after baseline was missing, the status was imputed with the status from the last nonmissing visit after baseline. A post hoc analysis of vertebral fractures was also performed for all randomly assigned patients with the use of a multiple-imputation method that included treatment group and the following baseline variables: age, years since menopause, body-mass index, number of prevalent vertebral fractures, worst vertebral fracture severity, and bone mineral density T score at the lumbar spine, total hip, and femoral neck.\n\n【34】For the incidence of clinical, nonvertebral, major nonvertebral, hip, osteoporotic, symptomatic vertebral, and major osteoporotic fractures, the treatment groups were compared on the basis of a Cox proportional-hazards model with adjustment for age (<75 vs. ≥75 years), the presence or absence of severe vertebral fracture at baseline, and baseline bone mineral density T score at the total hip. For the incidence of new vertebral and new or worsening vertebral fractures, risk ratios were determined by means of the Mantel–Haenszel method, with treatment comparison assessed with the use of a logistic-regression model with adjustment for age (<75 vs. ≥75 years), the presence or absence of severe vertebral fracture at baseline, and baseline bone mineral density T score at the total hip. A total of 11 subgroup categories were prespecified and analyzed for treatment-by-subgroup interactions, as described previously. \n\n【35】Percentage changes from baseline in bone mineral density were assessed in patients who had a baseline measurement and at least one measurement after baseline. Between-group comparisons of the percentage change from baseline in bone mineral density were analyzed by means of a repeated-measures model with adjustment for treatment, age category, the presence or absence of severe vertebral fracture at baseline, visit, treatment-by-visit interaction, and baseline bone mineral density as fixed effects, with machine type and interaction between baseline bone mineral density and machine type as covariates, with the use of an unstructured variance–covariance structure. Percentage changes from baseline in bone-turnover markers were assessed in patients enrolled in the biomarker substudy, as described previously. \n\n【36】The safety analysis included all randomly assigned patients who received at least one dose of romosozumab or alendronate in the double-blind period. Incidence rates at the time of the primary analysis were cumulative and included all events in the double-blind and open-label periods in patients who received at least one dose of open-label alendronate. Odds ratios and confidence intervals were estimated for serious cardiovascular adverse events with the use of a logistic-regression model.\n\n【37】Results\n-------\n\n【38】Patients\n--------\n\n【39】Table 1. Demographic and Clinical Characteristics of the Patients at Baseline.\n\n【40】A total of 4093 patients underwent randomization; 3654 patients (89.3%) completed 12 months of the trial , and 3150 (77.0%) completed the primary analysis period. The reasons for discontinuation were similar in the two treatment groups . The demographic and clinical characteristics of the patients at baseline were balanced between the two groups . The mean age of the patients was 74.3 years, 99.0% had a previous osteoporotic fracture at 45 years of age or older, 96.1% had a prevalent vertebral fracture, and the mean bone mineral density T scores were –2.96 at the lumbar spine, –2.80 at the total hip, and –2.90 at the femoral neck.\n\n【41】Efficacy\n--------\n\n【42】### _Fracture_\n\n【43】Figure 2. Incidence of New Vertebral, Clinical, and Nonvertebral Fracture.\n\n【44】The primary end points were the cumulative incidence of new vertebral fracture at 24 months  and the cumulative incidence of clinical fracture at the time of the primary analysis . For new vertebral fractures, the risk ratio was assessed among patients in the romosozumab group as compared with those in the alendronate group (at 12 months) and among patients in the romosozumab-to-alendronate group as compared with those in the alendronate-to-alendronate group (at 24 months). Risks presented are based on a multiple-imputation method for patients with missing fracture status. For Kaplan–Meier curves of the first clinical fracture and the first nonvertebral fracture  in the time-to-event analysis, data from patients who withdrew or reached the end of the reporting period without having a fracture were censored at the last observation time. P values for clinical and nonvertebral fractures were calculated with the use of a Cox proportional-hazards model; P values for new vertebral fracture were calculated with the use of a logistic-regression model.\n\n【45】Over a period of 24 months, treatment with romosozumab followed by alendronate resulted in a 48% lower risk of new vertebral fractures than alendronate alone (6.2% \\[127 of 2046 patients\\] vs. 11.9% \\[243 of 2047 patients\\]; risk ratio, 0.52; 95% confidence interval \\[CI\\], 0.40 to 0.66; P<0.001) with the use of multiple imputation for missing fracture status ; similarly, a 50% lower risk with romosozumab was observed with the use of the last observation carried forward . At the time of the primary analysis, romosozumab followed by alendronate resulted in a 27% lower risk of clinical fracture than alendronate alone (hazard ratio, 0.73; 95% CI, 0.61 to 0.88; P<0.001) . The cumulative incidence of clinical fracture in the romosozumab-to-alendronate group was 9.7% (198 of 2046 patients) versus 13.0% (266 of 2047 patients) in the alendronate-to-alendronate group.\n\n【46】At the time of the primary analysis, romosozumab followed by alendronate also resulted in a 19% lower risk of nonvertebral fracture than alendronate alone (hazard ratio, 0.81; 95% CI, 0.66 to 0.99; P=0.04) , with fractures occurring in 178 of 2046 patients (8.7%) in the romosozumab-to-alendronate group versus 217 of 2047 patients (10.6%) in the alendronate-to-alendronate group . Hip fractures occurred in 41 of 2046 patients (2.0%) in the romosozumab-to-alendronate group as compared with 66 of 2047 patients (3.2%) in the alendronate-to-alendronate group at the time of the primary analysis, representing a 38% lower risk with romosozumab (hazard ratio, 0.62; 95% CI, 0.42 to 0.92; P=0.02).\n\n【47】Between-group differences in favor of romosozumab were observed by month 12, including in new vertebral fractures (risk ratio, 0.63; 95% CI, 0.47 to 0.85) and clinical fractures (hazard ratio, 0.72; 95% CI, 0.54 to 0.96). The risk of nonvertebral fracture was 26% lower with romosozumab than with alendronate, but the difference was not significant (P=0.06). Table S1 in the Supplementary Appendix shows details of these and other fracture end points.\n\n【48】### _Bone Mineral Density_\n\n【49】Figure 3. Percentage Change from Baseline in Bone Mineral Density and Levels of Bone-Turnover Markers.\n\n【50】The least-squares mean percentage changes in bone mineral density at the lumbar spine  and total hip  are shown for patients who had a baseline measurement and at least one measurement obtained at a postbaseline visit at or before month 36. Between-group comparisons of the percentage change in bone mineral density were analyzed with the use of a repeated-measures model; P<0.001 for all comparisons. The median percentage change from baseline in the levels of serum procollagen type 1 N-terminal propeptide (P1NP)  and β-isomer of C-terminal telopeptide of type I collagen (β-CTX)  are shown for a subgroup of 266 patients who had serial assessments of bone-turnover markers as part of the biomarker substudy and had a baseline measurement and at least one measurement after the baseline visit. The substudy population was representative of the overall trial population. Between-group comparisons of the percentage change from baseline in levels of P1NP and β-CTX were calculated with the use of the Wilcoxon rank-sum test; P<0.001 for the comparisons at months 1, 3, 6, 9, and 12. I bars indicate pointwise 95% confidence intervals for the values of bone mineral density and interquartile ranges for the levels of P1NP and β-CTX.\n\n【51】Patients who received romosozumab had greater gains in bone mineral density from baseline at all measured sites and at all time points than patients who received alendronate alone. The differential greater gains achieved by month 12 with romosozumab were maintained at month 36, after the transition to alendronate (P<0.001 for all comparisons) . In a subgroup of patients assessed every 6 months, greater gains with romosozumab were observed beginning at month 6 (P<0.001 for all comparisons) .\n\n【52】### _Bone-Turnover Markers_\n\n【53】Romosozumab increased levels of the bone-formation marker P1NP and decreased levels of the bone-resorption marker β-CTX within 12 months . After the transition to alendronate, levels of P1NP and β-CTX decreased and remained below baseline levels at 36 months. In patients receiving alendronate alone, levels of P1NP and β-CTX decreased within 1 month and remained below baseline levels at 36 months.\n\n【54】Safety\n------\n\n【55】Table 2. Adverse Events.\n\n【56】The incidences of adverse events and serious adverse events were similar overall between the two treatment groups during the 12-month double-blind period, and cumulative incidences were similar between the two groups during the primary analysis period . In the first 12 months, injection-site reactions (mostly mild in severity) were reported in more patients receiving romosozumab (90 of 2040 patients \\[4.4%\\]) than in those receiving alendronate (53 of 2014 patients \\[2.6%\\]).\n\n【57】An imbalance in adjudicated serious cardiovascular adverse events was observed during the double-blind period, with 50 patients (2.5%) in the romosozumab group and 38 (1.9%) in the alendronate group reporting these events (odds ratio, 1.31; 95% CI, 0.85 to 2.00). A total of 16 patients (0.8%) in the romosozumab group and 6 (0.3%) in the alendronate group reported cardiac ischemic events (odds ratio, 2.65; 95% CI, 1.03 to 6.77), and 16 patients (0.8%) in the romosozumab group and 7 (0.3%) in the alendronate group reported cerebrovascular events (odds ratio, 2.27; 95% CI, 0.93 to 5.22), whereas heart failure, noncoronary revascularization, and peripheral vascular ischemic events not requiring revascularization were numerically lower in the romosozumab group . Cardiovascular risk factors in patients with positively adjudicated cardiovascular events are shown in Table S4 in the Supplementary Appendix .\n\n【58】No adjudicated events of osteonecrosis of the jaw or atypical femoral fracture were reported in the 12-month double-blind period. During the open-label period, 2 events of osteonecrosis of the jaw (1 \\[<0.1%\\] in each treatment group) and 6 events of atypical femoral fracture (2 \\[<0.1%\\] in the romosozumab-to-alendronate group and 4 \\[0.2%\\] in the alendronate-to-alendronate group) were positively adjudicated.\n\n【59】During the first 18 months of the trial, binding anti-romosozumab antibodies were observed in 310 of 2028 patients (15.3%) in the romosozumab group; neutralizing antibodies were observed in 12 patients (0.6%), with no detectable effect on relevant efficacy or safety .\n\n【60】Discussion\n----------\n\n【61】In this phase 3 trial involving postmenopausal women with osteoporosis and a previous fracture, treatment with romosozumab for 12 months before alendronate was superior to alendronate alone with respect to the risks of a new vertebral, clinical, nonvertebral, and hip fracture. It is worth noting that romosozumab outperformed an effective drug; in large meta-analyses, alendronate has been shown to consistently reduce vertebral, nonvertebral, and hip fractures by up to 50%  among patients with osteoporosis. In our trial, the effect of romosozumab on the risk of fracture was rapid: the risks of new vertebral fracture and clinical fracture were significantly lower with romosozumab than with alendronate at 12 months, findings that imply both a near-term and persistent reduction in fracture risk with the initiation of romosozumab before antiresorptive therapy in patients at high risk for fracture. Although the placebo-controlled Fracture Study in Postmenopausal Women with Osteoporosis (FRAME) showed that 12 months of romosozumab had preventive effects with respect to vertebral and clinical but not nonvertebral fractures (potentially influenced by the lower baseline fracture risk),  the present trial assessed efficacy in a higher-risk population and showed broad beneficial effects on fracture risk as compared with a commonly used active drug.\n\n【62】Romosozumab rapidly increased bone mineral density, a finding consistent with those of previous studies.  We found significantly greater gains with romosozumab than with alendronate at the lumbar spine, total hip, and femoral neck by month 6. After the transition to alendronate, the significant difference between treatment groups was maintained. A plateau in bone mineral density was observed with ongoing alendronate therapy, a finding similar to results from other studies. \n\n【63】Overall, adverse events and serious adverse events were balanced between the two groups. No cases of osteonecrosis of the jaw or atypical femoral fracture were identified during the period of romosozumab-alone treatment. Events were observed in the alendronate open-label period, with four events of atypical femoral fracture in the alendronate-to-alendronate group and two in the romosozumab-to-alendronate group. Adjudicated serious cardiovascular adverse events were more frequent in the romosozumab group than in the alendronate group during the double-blind period, with cardiac ischemic events and cerebrovascular events contributing to the imbalance.\n\n【64】There are theoretical considerations that sclerostin inhibition could be associated with cardiovascular risk. Sclerostin is constitutively expressed in the aorta  and up-regulated in foci of vascular and valvular calcification.  The function of sclerostin in the vasculature is unknown. Although sclerostin may function as a negative regulator of vascular calcification and sclerostin inhibition could promote vascular calcification, studies have shown conflicting results.  In long-term toxicology studies in rats  and monkeys,  there was no histologic or radiographic evidence of the development or exacerbation of vascular mineralization. Vascular calcification, although not specifically examined, has not been reported in _Sost_ knockout mice or patients with sclerosteosis or van Buchem’s disease. \n\n【65】Further evaluation is needed to determine the cause of the observed imbalance in cardiovascular events. Such an imbalance was not seen in FRAME, a larger (7180 patients), placebo-controlled trial that enrolled a somewhat younger population with less advanced osteoporosis.  Another important contrast is the comparison drug. Alendronate has been associated with a reduction in the risk of cardiovascular disease in some studies  but not in two meta-analyses,  perhaps related to differences in the patient populations studied or the dosing of alendronate. \n\n【66】Strengths of this trial include an active-comparator design involving patients with osteoporosis and a high risk of fracture. Limitations include the facts that the trial was not designed as a cardiovascular-outcomes trial and that it did not include a placebo control. Investigation is ongoing, including evaluation of cardiovascular risk factors; however, the small number of events makes interpretation difficult.\n\n【67】In conclusion, rapid gains in bone mineral density from bone-forming therapy with romosozumab were associated with a lower risk of fracture than with alendronate within 1 year and over the course of romosozumab followed by alendronate. Hip fractures were less frequent with romosozumab followed by alendronate than with alendronate alone, suggesting an important benefit and challenging the common treatment practice of first-line use of alendronate in women who have had a previous fracture. An imbalance in serious cardiovascular adverse events in comparison with alendronate was also found, which was not observed in a previous large, placebo-controlled trial.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:41:42", "endTime": "2024/08/14 14:43:02", "cost": 80.434}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 22:43:02", "grab_time": "2024-08-13 22:41:41"}
{"id": 2234332, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "b066649d-589b-406b-8541-da8cf2dbfb26", "title": "The Comfort of the Ordinary — On Dying as We’ve Lived", "text": "【0】The Comfort of the Ordinary — On Dying as We’ve Lived\nThough the dying process may offer an opportunity for truth telling and atonement, reconciliation and expressions of love, it may also allow a space for life to go on just as it was. If we’re lucky, we’ll continue to live as we always did until the very end.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "Though the dying process may offer an opportunity for truth telling and atonement, reconciliation and expressions of love, it may also allow a space for life to go on just as it was. If we’re lucky, we’ll continue to live as we always did until the very end.", "content": "【0】The Comfort of the Ordinary — On Dying as We’ve Lived\nThough the dying process may offer an opportunity for truth telling and atonement, reconciliation and expressions of love, it may also allow a space for life to go on just as it was. If we’re lucky, we’ll continue to live as we always did until the very end.", "index": 57, "show": true, "start": 57, "end": 315, "province": ["语义有效性", "语义不完整"], "isEdit": false}], "startTime": "2024/08/14 10:24:48", "endTime": "2024/08/14 10:25:44", "cost": 56}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 18:25:44", "grab_time": "2024-08-13 18:24:48"}
{"id": 2234331, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "da08a407-625f-4004-957d-18f80ca09650", "title": "Five-Year Outcomes of the Partial Oral Treatment of Endocarditis (POET) Trial", "text": "【0】Five-Year Outcomes of the Partial Oral Treatment of Endocarditis (POET) Trial\nTo the Editor:\n--------------\n\n【1】Step-down therapy with oral antibiotics has shown efficacy in some complex infectious diseases, including bone and joint infections  and endocarditis,  but data on longer-term outcomes are needed.  In the Partial Oral Treatment of Endocarditis (POET) trial,  step-down therapy with oral antibiotics after clinical stabilization of patients with endocarditis on the left side of the heart was shown to be noninferior to continued intravenous antibiotic therapy after 6 months (primary trial outcome),  and no indications of treatment failure after 3 years were observed.  Here we report the outcome of the POET trial more than 5 years after randomization .\n\n【2】Patients in stable condition who had endocarditis on the left side of the heart caused by streptococci, _Enterococcus faecalis_ , _Staphylococcus aureus_ , or coagulase-negative staphylococci were randomly assigned to continue treatment with intravenous antibiotics (199 patients) or to shift to step-down treatment with oral antibiotics (201 patients) after at least 10 days of initial treatment with intravenous antibiotics. After undergoing randomization, patients in the group that received intravenous treatment remained hospitalized until the antibiotic treatment was completed (i.e., a median of 19 days \\[interquartile range, 14 to 25\\]). Patients who received step-down treatment with oral antibiotics were discharged after a median of 3 days (interquartile range, 1 to 10) after completion of the initial treatment with intravenous antibiotics. The primary outcome was a composite of death from any cause, unplanned cardiac surgery, embolic events, and relapse of positive blood cultures after 6 months.\n\n【3】In this post hoc analysis, patients were followed from randomization until July 10, 2020, or until death. Longer-term follow-up was performed by review of patient records. A clinical event committee, whose members were unaware of the treatment assignments, adjudicated the original prespecified clinical outcomes. No patients were lost to follow-up.\n\n【4】Figure 1. Cumulative Incidence of Events.\n\n【5】Shown are plots of the cumulative incidence of events from randomization to a median follow-up of 5.4 years. The patients assigned to the intravenous treatment group received intravenous antibiotic therapy for the entire treatment period, and the patients assigned to receive step-down treatment shifted from intravenous antibiotics to oral antibiotics after clinical stabilization was reached. The composite primary outcome consisted of death from any cause, unplanned cardiac surgery, embolic events, and relapse of a blood culture result positive for the primary pathogen.\n\n【6】After a median follow-up of 5.4 years (interquartile range, 4.0 to 6.9), a primary composite outcome had occurred in 66 patients (32.8%) in the group that had received step-down treatment and in 90 patients (45.2%) in the group that had received continued intravenous treatment (hazard ratio, 0.65; 95% confidence interval \\[CI\\], 0.47 to 0.90) . The difference was driven mainly by a lower incidence of death from any cause in the group that had received step-down treatment (47 patients \\[23.4%\\]) than in the group that had received continued intravenous treatment (70 patients \\[35.2%\\]) (hazard ratio, 0.61; 95% CI, 0.42 to 0.88) . There were no significant differences noted between the groups for the three other components of the composite outcome. The most frequent cause of death was cardiovascular, followed by infection and cancer . There was no difference between the groups in the distribution of causes of death. The longer-term effects were consistent across prespecified subgroups .\n\n【7】There were no indications of longer-term treatment failure among patients in the group that had received step-down treatment with oral antibiotics. These reassuring findings further support current considerations  of implementing step-down oral antibiotic therapy in selected patients with endocarditis on the left side of the heart.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 11:01:31", "endTime": "2024/08/14 11:02:19", "cost": 48.342}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 19:02:19", "grab_time": "2024-08-13 19:01:31"}
{"id": 2234330, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "68142923-a9f7-4daf-8c69-9351f303ca07", "title": "Diagnosis of Poorly Differentiated Thyroid Cancer with Radioiodine Scanning after Thyrotropin Alfa Stimulation", "text": "【0】Diagnosis of Poorly Differentiated Thyroid Cancer with Radioiodine Scanning after Thyrotropin Alfa Stimulation\nTo the Editor:\n--------------\n\n【1】Poorly differentiated thyroid cancers are rare and can be difficult for surgeons, endocrinologists, and pathologists to identify.  These cancers fall into two main histologic categories: insular and other (large cell). Most, but not all, stain with thyroglobulin or thyroid transcription factor 1; those that do not represent particular diagnostic challenges.  We describe a 60-year-old man who presented with bilateral cervical lymphadenopathy and an enlarged thyroid. Biopsy specimens of cervical nodes and the thyroid gland showed features of poorly differentiated adenocarcinoma of unknown primary origin — possibly pulmonary, colorectal, pancreatic, or thyroidal. Immunostaining for thyroglobulin and thyroid transcription factor 1 was negative. The level of serum thyroglobulin at initial presentation was 800 ng per milliliter. No tumor was found outside the neck with diagnostic imaging, including integrated positron-emission tomography and computed tomography (PET–CT) performed after the administration of  F-fluorodeoxyglucose. Ultrasonography showed multiple intrathyroidal tumor masses. The patient was unsuccessfully treated with chemotherapy for poorly differentiated adenocarcinoma, which could not be resected because of the extent of the tumor and local invasion.\n\n【2】Figure 1. Imaging Studies of the Head and Neck.\n\n【3】A radioiodine scan  shows normal thyroid tissue in the upper right lobe (short arrow) and the presence of a tumor in the lower right and left lobes (long arrows). A positron-emission tomographic scan obtained after the administration of  F-fluorodeoxyglucose (FDG)  shows mild uptake in normal thyroid tissue (short arrow) and increased uptake of FDG in the tumor of the lower right and left lobes (long arrows). These findings are consistent with an FDG-avid thyroid cancer partially concentrating radioiodine. An ultrasonogram of the right thyroid lobe  shows areas of normal thyroid tissue in the upper right lobe (short arrow) and tumor masses in the lower right lobe (long arrow). An ultrasonogram of the left lobe  shows tumor masses in the entire left lobe (short arrow) and strap-muscle invasion (long arrow).\n\n【4】Since thyrotropin levels were normal, diagnosis of potentially radioiodine-concentrating poorly differentiated thyroid cancer was possible only after stimulation with thyrotropin alfa. After two daily intramuscular injections of 0.9 mg of thyrotropin alfa, thyrotropin levels increased to 91 U per liter and the patient was given 3 mCi of radioiodine orally. A whole-body radioiodine scan obtained 48 hours later showed intense radioiodine uptake in the upper right thyroid lobe, corresponding to a region of normal thyroid tissue identified on ultrasonography and PET–CT. The scan also showed less intense uptake in the lower right lobe and in most of the left lobe, which according to the ultrasonographic and PET–CT findings, were composed entirely of tumor, with a heterogeneous, centrally necrotic tumor on the left . No uptake was seen in the areas of cervical lymphadenopathy. With the diagnosis of poorly differentiated thyroid cancer established, the patient underwent external-beam radiation.\n\n【5】This case shows how stimulation with thyrotropin alfa can be used in a patient with unresectable thyroid cancer to determine the degree of radioiodine concentration in the primary tumor and its metastases. For our patient, this test was critical in establishing the diagnosis of poorly differentiated thyroid cancer, with possible anaplastic transformation of some tumor regions plus metastases that limited the potential usefulness of radioiodine therapy. However, many poorly differentiated thyroid cancers avidly concentrate radioiodine, which has been used successfully to treat such cancers after thyroid resection.  Our approach of using thyrotropin alfa to stimulate tumoral uptake of radioiodine introduces the possibility of using this treatment even in patients with a thyroid gland that cannot be resected, regardless of the reason.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 16:36:34", "endTime": "2024/08/13 16:38:42", "cost": 128.52}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 00:38:42", "grab_time": "2024-08-13 00:36:34"}
{"id": 2234329, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "7b6c949a-d8cd-4396-a98e-b8b1f9f7740c", "title": "Effects of Tocopherol and Deprenyl on the Progression of Disability in Early Parkinson's Disease", "text": "【0】Effects of Tocopherol and Deprenyl on the Progression of Disability in Early Parkinson's Disease\nAbstract\n--------\n\n【1】Background and Methods\n----------------------\n\n【2】In 1987 we began a multicenter controlled clinical trial of deprenyl (a monoamine oxidase inhibitor) and tocopherol (a component of vitamin E that traps free radicals) in the treatment of early Parkinson's disease. We randomly assigned 800 patients to one of four treatments: placebo, active tocopherol and deprenyl placebo, active deprenyl and tocopherol placebo, or both active drugs. The primary end point was the onset of disability prompting the clinical decision to begin administering levodopa. An interim analysis showed that deprenyl was beneficial . We report the results of tocopherol treatment after a mean (±SD) follow-up of 14 ±6 months, as well as the follow-up results for deprenyl.\n\n【3】Results\n-------\n\n【4】There was no beneficial effect of tocopherol or any interaction between tocopherol and deprenyl. The beneficial effects of deprenyl, which occurred largely during the first 12 months of treatment, remained strong and significantly delayed the onset of disability requiring levodopa therapy (hazard ratio, 0.50; 95 percent confidence interval, 0.41 to 0.62; P<0.001). The difference in the estimated median time to the end point was about nine months. The ratings for Parkinson's disease improved during the first three months of deprenyl treatment; the motor performance of deprenyl-treated patients worsened after the treatments were withdrawn.\n\n【5】Conclusions\n-----------\n\n【6】Deprenyl (10 mg per day) but not tocopherol (2000 IU per day) delays the onset of disability associated with early, otherwise untreated Parkin-son's disease. The action of deprenyl that accounts for its beneficial effects remains unclear.\n\n【7】Introduction\n------------\n\n【8】A variety of oxidative mechanisms, involving the activity of monoamine oxidase and the formation of free radicals, have been implicated in the degeneration of neurons in the substantia nigra  . The possible role of such mechanisms in the pathogenesis of Parkinson's disease has led to clinical trials aimed at slowing the progressively disabling course of this illness. Deprenyl (selegiline or phenylisopropylmethylpropynylamine) is a selective and irreversible inhibitor of type B monoamine oxidase when administered in a dosage of 10 mg per day  . α-Tocopherol, a biologically active component of vitamin E, attenuates the effects of lipid peroxidation by trapping free radicals  .\n\n【9】The multicenter controlled clinical trial Deprenyl and Tocopherol Antioxidative Therapy of Parkinsonism (DATATOP) was carried out to determine whether long-term therapy with deprenyl or tocopherol would extend the length of time before advancing disability requires the initiation of levodopa therapy in patients with early, untreated Parkinson's disease  . An interim analysis of this trial, prompted by independent monitoring and based on the observation of 800 patients for a mean (±SD) of 12 ±5 months, indicated that deprenyl reduced the risk of disability requiring levodopa therapy by approximately 50 percent  . However, it was unclear whether the effects of deprenyl would be sustained or whether deprenyl resulted in short-term amelioration of clinical features (symptomatic effect), a slowing of underlying nigral degeneration (protective effect), or both mechanisms. This report extends the analysis of the DATATOP clinical trial to include 14 ±6 months of observation and a modification of the protocol based on the interim analysis, and addresses the independent and interactive effects of tocopherol and deprenyl.\n\n【10】Methods\n-------\n\n【11】The methods used in the DATATOP trial, including a description of the design, organization, recruitment of subjects, data acquisition and management, statistical methods, and interim results, have been reported in detail elsewhere  and are summarized below.\n\n【12】Enrollment and Follow-up\n------------------------\n\n【13】Eight hundred untreated patients who had had Parkinson's disease (stage I or II) for less than five years and who met other eligibility criteria  were enrolled between September 3, 1987, and November 15, 1988. They were randomly assigned according to a two-by-two factorial design  to one of four treatment groups: tocopherol placebo and deprenyl placebo; tocopherol (2000 IU per day) and deprenyl placebo; deprenyl (10 mg per day) and tocopherol placebo; and deprenyl (10 mg per day) and tocopherol (2000 IU per day). The process of randomization was designed to ensure that each investigator had an approximate numerical balance of subjects in the four groups  . The subjects took 1000-IU capsules of racemic dl-α-tocopherol or identical-appearing placebo capsules (Hoffmann-LaRoche, Nutley, N.J.) and 5-mg tablets of l-deprenyl or identical-appearing tablets of placebo (Somerset Pharmaceuticals, Tampa, Fla.) twice daily with morning and evening meals.\n\n【14】The subjects were reevaluated 1 month and 3 months after randomization and approximately every 3 months thereafter, for a planned maximum of 24 months of follow-up. At each visit, the subjects were evaluated with the Unified Parkinson's Disease Rating Scale (UPDRS), including its motor, mental, and activities-of-daily-living components  . Evaluation with the Hamilton Depression Scale  was carried out at base line, at one and three months, and at six-month intervals thereafter. The procedures for monitoring surveillance laboratory tests and compliance are described elsewhere  .\n\n【15】End Points\n----------\n\n【16】The primary end point of the trial occurred when, in the judgment of the enrolling investigator, a subject reached a level of functional disability sufficient to warrant the initiation of levodopa therapy  . Thereupon, the experimental treatments were withdrawn and investigators and subjects were kept unaware of the treatment assignments; the subjects underwent final evaluations approximately 30 days later.\n\n【17】Modification of the Protocol\n----------------------------\n\n【18】An independent monitoring committee recommended (February 11, 1989) an interim analysis  of the effect of deprenyl, which included follow-up data obtained through May 20, 1989, when investigators were first informed of the interim results. The subjects were first advised of the interim findings after their scheduled follow-up visits conducted between July 31, 1989, and December 19, 1989.\n\n【19】All actively participating subjects who had not reached the primary end point provided informed consent for the modification of the trial that followed the interim analysis. Under the revised protocol, additional follow-up evaluations of these subjects were performed approximately one and two months after experimental treatments were withdrawn by tapering the dosages over a one-week period. Treatment with deprenyl (10 mg per day) could be started during the two months after treatment was withdrawn if the investigator determined that features of Parkinson's disease had worsened sufficiently as a consequence of the withdrawal of experimental treatments. All subjects, coordinators, and investigators were kept unaware of the treatment assignments throughout this modified phase of the trial.\n\n【20】Statistical Analysis\n--------------------\n\n【21】In accordance with the intention-to-treat principle,  statistical analyses included all 800 subjects who were randomly assigned to the four treatment groups. All P values were two-tailed. The primary analysis used methods for evaluating survival  to account for the varying lengths of follow-up among subjects who reached the end point, those who withdrew from the trial before reaching the end point, and those still being followed who had not reached the end point. The cumulative probabilities of reaching the end point were estimated with the method of Kaplan and Meier  ; data on subjects who withdrew from the study were censored as of their date of withdrawal. The end-point comparisons used Pearson's chi-square statistic,  the stratified log-rank test,  and Cox's proportional-hazards regression model,  with the identity of the participating investigator entered as a stratification factor. The risk among subjects receiving an active treatment (deprenyl or tocopherol), relative to that among subjects not receiving that treatment, was expressed as a hazard ratio -- that is, the ratio of the risk per unit of time until the end point was reached among subjects assigned to active treatment to the corresponding risk among subjects not assigned to that treatment.\n\n【22】The differences among the four treatment groups with respect to adverse effects reported after base line were evaluated by chi-square statistics  . The rates of disease progression and the changes in the scores of the UPDRS and the Hamilton Depression Scale were evaluated by analysis of variance,  with adjustment for investigator effects. Follow-up variables were analyzed to determine the main effects of deprenyl and tocopherol as well as interactions between these drugs.\n\n【23】Results\n-------\n\n【24】Comparability of Treatment Groups and Adverse Events\n----------------------------------------------------\n\n【25】The four treatment groups did not differ significantly in the variables measured at base line, including age, sex, ratings on the UPDRS and Hamilton Depression Scale, any previous levodopa treatment, time from the onset of illness to randomization, level of education, and employment status.\n\n【26】The occurrence of adverse symptoms, other medical conditions, and abnormal laboratory results was generally infrequent and uniform among all treatment groups. Of the 63 symptoms of moderate or serious severity reported to have occurred at least once, regardless of any perceived relation to experimental treatments or Parkinson's disease, only nausea occurred disproportionately (in one subject taking placebo only, none taking tocopherol and placebo, two taking deprenyl and placebo, and six taking both drugs; nominal P = 0.045, deprenyl).\n\n【27】Of the 17 other medical conditions reported to have occurred at least once, regardless of any perceived relation to the experimental treatments or Parkinson's disease, only musculoskeletal injuries and cardiac arrhythmias occurred disproportionately (injuries in 5 subjects taking placebo only, 6 taking tocopherol and placebo, 18 taking deprenyl and placebo, and 11 taking both drugs; nominal P = 0.007, deprenyl; arrhythmias: 1 subject taking placebo, none taking tocopherol and placebo, 4 taking deprenyl and placebo, and 4 taking both drugs; nominal P = 0.045, deprenyl). The cardiac arrhythmias were not considered life-threatening and included increased premature ventricular contractions (one subject taking placebo only and one taking both drugs), supraventricular tachycardia (one taking deprenyl and placebo and one taking both drugs), and bradycardia with varying degrees of atrioventricular block (three taking deprenyl and placebo and two taking both drugs). No significant treatment-related changes in blood pressure or pulse recordings were found during the study.\n\n【28】Of the clinically important laboratory abnormalities found on the battery of 41 surveillance tests, only abnormal elevation of serum aminotransferase levels was found to be a significant treatment effect. Aspartate aminotransferase levels exceeding 36 U per liter in men and 34 U per liter in women occurred in 10 subjects taking placebo only, 3 taking tocopherol and placebo, 20 taking deprenyl and placebo, and 8 taking both drugs (P = 0.028, deprenyl; and P = 0.005, tocopherol); alanine aminotransferase levels exceeding 43 U per liter in men and 34 U per liter in women occurred in 10 subjects taking placebo only, 4 taking tocopherol and placebo, 24 taking deprenyl and placebo, and 7 taking both drugs (P = 0.016, deprenyl; and P = 0.001, tocopherol). Elevations of alanine aminotransferase levels exceeding 150 percent of base-line values on more than one follow-up visit were found in only two subjects (one taking deprenyl and placebo and one taking both drugs). Adverse events prompted emergency disclosure of the treatment assignments of two subjects (one taking deprenyl and placebo and one taking both drugs) in whom cancer developed and one subject taking both drugs who had hallucinations. No subjects died while participating in this phase of the study.\n\n【29】Compliance in taking experimental medications was excellent among all treatment groups. The overall compliance rate, as a percentage of the doses dispensed that were actually taken, ranged from 97.9 to 99.5 percent for both tocopherol and deprenyl. The results of urine testing for amphetamine and methamphetamine during the follow-up visits agreed well with the treatment assignments, ranging from 95 to 100 percent agreement among subjects not assigned to deprenyl and from 86 to 95 percent among those assigned to deprenyl. The distribution of serum tocopherol concentrations exceeding 2.0 mg per deciliter (46 μmol per liter) during the follow-up visits also matched the treatment assignments, ranging from 81 to 100 percent agreement among subjects not assigned to tocopherol and from 78 to 90 percent among those assigned to tocopherol.\n\n【30】End Points\n----------\n\n【31】Table 1. Status of the Subjects during the Study Period, According to Treatment Group.\n\n【32】Table 1 compares the status according to treatment group, as of the last evaluation during experimental treatments, of the 376 subjects who reached the primary end point, the 57 subjects who withdrew from the study before reaching the end point, and the 367 subjects who were still being followed and had not reached the end point.\n\n【33】Tocopherol treatment (regardless of deprenyl administration) did not reduce the probability of reaching the end point (hazard ratio, 0.91; 95 percent confidence interval, 0.74 to 1.12; P = 0.35), and the hazard ratios for tocopherol remained homogeneous throughout the maximal period of follow-up (24 months). Tocopherol alone did not significantly reduce the risk of reaching the end point, as compared with double placebo (hazard ratio, 0.92; 95 percent confidence interval, 0.70 to 1.22; P = 0.57). There was no interaction between deprenyl and tocopherol (P = 0.97).\n\n【34】Figure 1. Kaplan-Meier Estimate of the Cumulative Probability of Reaching the End Point, According to Treatment Group.\n\n【35】The hazard ratio for the comparison of subjects taking deprenyl (with placebo or tocopherol) with subjects not taking deprenyl (placebo only or tocopherol with placebo) with respect to the risk of reaching the end point per unit of time is 0.50 (P<0.001; 95 percent confidence interval, 0.41 to 0.62). The period of analysis was the time from base line to the last evaluation during treatment. The number of subjects evaluated in each group is shown under each time point.\n\n【36】Kaplan-Meier plots  of the probability of reaching the end point of the study differed significantly between subjects assigned to deprenyl (with placebo or tocopherol) and those not assigned to deprenyl (those taking placebo alone or placebo and tocopherol) (hazard ratio, 0.50; 95 percent confidence interval, 0.41 to 0.62; P<0.001). The projected median lengths of time to reach the end point were 719 days for the subjects who were assigned to deprenyl and 454 days for the subjects who were not assigned to deprenyl, representing an approximate difference of almost 9 months.\n\n【37】Although the overall hazard ratio of 0.50 for deprenyl treatment was significant, the hazard ratio did not remain constant during the 24 months of follow-up; it increased from 0.35 (95 percent confidence interval, 0.21 to 0.58) during the first 6 months to 0.38 (95 percent confidence interval, 0.27 to 0.54) during the second 6 months, to 0.77 (95 percent confidence interval, 0.52 to 1.15) during the third 6 months, and to 0.86 (95 percent confidence interval, 0.45 to 1.66) after 18 months. According to Cox's test,  these hazard ratios were significantly heterogeneous (P = 0.008). The Kaplan-Meier plots for the first 18 months after randomization were virtually identical to the plots reported in the preliminary analysis  ; thereafter, the probabilities of reaching the end point did not continue to diverge. Subjects assigned to deprenyl benefited from treatment irrespective of their base-line characteristics. There were no significant differences in treatment effects in relation to the enrolling investigator, the age of the subject, or the date of entry of the subject.\n\n【38】The 367 subjects who did not reach the end point were withdrawn from experimental treatments and evaluated approximately one and two months later. During the two months after treatment was withdrawn, 4 subjects (2 taking double placebo, 1 taking tocopherol and placebo, and 1 taking deprenyl and placebo) reached the primary end point, 1 taking both drugs left the trial, and 52 were judged by the investigator to have an increase in the severity of Parkinson's disease and were given deprenyl. There was no evidence of differences among the treatment groups in the rate of early deprenyl administration (12 of 72 subjects taking double placebo, 17 percent; 13 of 77 taking tocopherol and placebo, 17 percent; 19 of 110 taking deprenyl and placebo, 17 percent; and 8 of 108 taking both drugs, 7 percent; P = 0.12).\n\n【39】Secondary Response Variables\n----------------------------\n\n【40】Table 2. Average Annual Rate of Decline in UPDRS Ratings.\n\n【41】Table 2 shows the average rate of decline from base-line values for the UPDRS variables in all subjects completing at least a six-month evaluation, regardless of whether they reached the end point. There were no significant differences in the rate of change in secondary response variables between subjects assigned to tocopherol and those not assigned to tocopherol. The average rate of decline in all UPDRS variables was significantly slower in subjects taking deprenyl (with placebo or tocopherol) than in subjects not taking deprenyl (those taking placebo alone or tocopherol and placebo).\n\n【42】For subjects who did not reach the end point (survivors), the rates of decline in UPDRS variables were calculated from base line (before the initiation of experimental treatments) to the evaluation that occurred approximately two months after the withdrawal of treatment . Survivors assigned to deprenyl had a significantly slower decline in total UPDRS scores than did their counterparts who were not assigned to deprenyl. For subjects who reached the end point, most of the decline in UPDRS scores typically occurred immediately before the determination that the end point had been reached,  and there were no significant differences between treatment groups in the motor ratings on the UPDRS at the time that the end point was reached (data not shown).\n\n【43】Table 3. Changes in the Ratings on the UPDRS and Hamilton Depression Scale during the Initial Three Months of Treatment (Wash-in) and the Two Months after Withdrawal of Treatments (Washout).\n\n【44】Table 3 shows the changes in the ratings on the UPDRS and Hamilton Depression Scale from base line in all subjects who completed follow-up evaluations after one and three months. Significant changes during the first three months of treatment (the “wash-in” period) favoring the subjects taking deprenyl occurred in all UPDRS variables at one and three months. No significant short-term changes in UPDRS ratings were found that favored the subjects taking tocopherol.\n\n【45】Figure 2. Kaplan-Meier Estimate of the Cumulative Probability of Reaching the End Point, According to Treatment with Deprenyl or without Deprenyl and to the Presence (+) or Absence (-) of Improvement in the One-Month Total UPDRS Score.\n\n【46】The period of analysis was the time from base line to the last evaluation during treatment. The number of subjects evaluated in each group is shown under each time point. See the Results section for hazard ratios and P values.\n\n【47】When the subjects in each treatment group were divided into those who had an initial improvement in the total UPDRS score between base line and one month (a total of 407 subjects; 215 assigned to deprenyl and 192 not assigned to deprenyl) and those who had a decline or no change in the score (a total of 379 subjects; 178 assigned to deprenyl and 201 not assigned to deprenyl), the differences in the rate at which the end point was reached favored those assigned to deprenyl in both subgroups (subgroup with improvement: hazard ratio, 0.55; 95 percent confidence interval, 0.40 to 0.75; P<0.001; subgroup without improvement: hazard ratio, 0.53; 95 percent confidence interval, 0.39 to 0.73; P<0.001) . The beneficial effect of deprenyl in reducing the risk of reaching the primary end point persisted even when this analysis was carried out with data collected after the one-month visit (data not shown) and when the subjects assigned to deprenyl who did not improve were compared with subjects not assigned to deprenyl who did improve (hazard ratio, 0.56; 95 percent confidence interval, 0.40 to 0.78; P<0.001).\n\n【48】Among subjects who reached the end point, the mean changes in UPDRS ratings between the evaluation at the end point and the final evaluation one month later were slight, and the differences between the treatment groups were not significant except for a relative improvement (P = 0.006) in the mental component of the UPDRS in subjects not assigned to deprenyl.\n\n【49】Among the subjects who did not reach the end point and who were withdrawn from experimental treatments in accordance with the modification of the trial protocol, slight worsening of the motor component of the UPDRS was found one month (P = 0.042) and two months (P<0.001) after the withdrawal of treatments in the subjects assigned to deprenyl as compared with the subjects not assigned to deprenyl . The disproportionate worsening of motor performance was largely attributable to changes in scores for tremor and rigidity. There were no significant treatment-related effects due to withdrawal on the mental or activities-of-daily-living components of the UPDRS or on the Hamilton Depression Scale.\n\n【50】Discussion\n----------\n\n【51】Effects of Tocopherol on Primary and Secondary Response Variables\n-----------------------------------------------------------------\n\n【52】Our clinical trial revealed no evidence of any beneficial effect of α-tocopherol (2000 IU per day) in either slowing functional decline or ameliorating the clinical features of Parkinson's disease. The failure of tocopherol to influence the progression of Parkinson's disease in this study does not preclude the potential effectiveness of other antioxidants. Treatment with tocopherol, which traps peroxyl radicals and interrupts the chain reaction of lipid peroxidation, may be less effective than interventions that prevent the formation of cytotoxic radicals and the initiation of lipid peroxidation  . It is also possible that inadequate amounts of tocopherol accumulated in the central nervous system in our subjects.\n\n【53】Effects of Deprenyl on Primary and Secondary Response Variables\n---------------------------------------------------------------\n\n【54】Our previous findings of a substantial benefit of deprenyl in delaying the onset of disability associated with Parkinson's disease have been confirmed by the findings in this extended period of observation. The results translate into a delay of almost nine months in the development of disability requiring levodopa therapy. These benefits were associated with a slight improvement in motor performance after deprenyl treatment was begun and a slight worsening after it was withdrawn. The benefits of deprenyl with respect to the primary end point of disability were found in all subjects regardless of their base-line characteristics and are supported by a slowing of the rate of decline of the UPDRS scores . The effect of deprenyl on all response variables was the same among patients who received tocopherol and those who did not.\n\n【55】Mechanisms of Deprenyl Effects\n------------------------------\n\n【56】Our data support our previous findings that deprenyl is well tolerated and slows the functional decline of otherwise untreated subjects with early Parkinson's disease. The pattern of the survival curves comparing subjects who received deprenyl with those who did not receive it showed initial sharp divergence followed by approximately constant separation. Our extended observations, which included a two-month period without treatment, indicate that deprenyl produces a slight but sustained improvement in the clinical ratings of Parkinson's disease.\n\n【57】The improvement in the UPDRS scores after the initiation of deprenyl and the worsening of the UPDRS motor scores during the two months after withdrawal  suggest that the observed benefit of deprenyl in delaying disability is partly related to a symptomatic amelioration of Parkinson's disease. On the other hand, the superior survival with respect to the primary end point even among deprenyl-treated subjects who initially had no improvement in total UPDRS scores  and the overall persisting benefit (as compared with base-line status) among deprenyl-treated subjects who did not reach the end point and who did not require deprenyl during the two months after withdrawal  suggest a protective influence. There was no evidence that deprenyl had appreciable antidepressant effects during this extended period of observation.\n\n【58】Uncontrolled studies suggest that deprenyl may increase the life span of patients with advanced Parkinson's disease  and retard the death of nigral neurons  . The design of our clinical trial was based on earlier studies indicating that deprenyl did not by itself lead to symptomatic improvement in patients with early Parkinson's disease  . The small but definite ameliorating influence of deprenyl that we observed on the motor ratings of Parkinson's disease hampers a clear-cut detection of potentially protective actions of this monoamine oxidase inhibitor.\n\n【59】Adverse Effects of Treatment\n----------------------------\n\n【60】In keeping with our interim report,  the adverse effects of tocopherol and deprenyl were infrequent and not serious. The rare occurrence of cardiac arrhythmias among deprenyl-treated subjects is unexplained, but this complication may be related to the monoaminergic effects of the parent compound and its active metabolites  . The infrequent occurrence of deprenyl-related elevations of serum aspartate aminotransferase and alanine aminotransferase levels has been reported previously  and seems to reflect clinically unimportant effects on hepatic or muscle enzymes. Although adverse effects on mental status were rare among our otherwise untreated subjects, deprenyl is known to cause untoward mental changes in patients with Parkinson's disease who are treated concurrently with levodopa or other drugs that enhance dopaminergic activity  .\n\n【61】Therapeutic Recommendations\n---------------------------\n\n【62】In contrast to the findings from an uncontrolled pilot study,  our larger controlled study does not support the use of tocopherol at a dosage of 2000 IU per day in patients who have early Parkinson's disease. The use of deprenyl in a dose of 10 mg per day as monotherapy for early Parkinson's disease delays the development of disability requiring levodopa therapy. Therefore, deprenyl should be considered among the available therapeutic options for the initial treatment of early Parkinson's disease.\n\n【63】Comparison of Present Results with Earlier Results\n--------------------------------------------------\n\n【64】The effects of deprenyl demonstrated by our present analysis remain strong, but they have been less dramatic over the extended period of observation than the effects we reported previously  . The evidence that deprenyl ameliorates some of the clinical features of Parkinson's disease is clearer in this analysis than in our previous report or in smaller controlled studies carried out by other investigators  . Our ability to detect small clinical effects is related to the large study sample, the extended period of observation, and the longer period of withdrawal from experimental treatments among subjects who had not reached the end point of disability. Previous studies have suggested that deprenyl has a protective effect,  but this assertion has not yet been established.\n\n【65】Unresolved Issues and Future Investigations\n-------------------------------------------\n\n【66】Despite the lack of benefit of tocopherol in this trial, studies of other antioxidant agents in Parkinson's disease are still warranted. Examination of the effects of l-amphetamine metabolites of deprenyl  and of shorter-acting inhibitors of monoamine oxidase type B, such as lazabemide,  which are not metabolized to active compounds, may help clarify the action of deprenyl. Inhibitors of monoamine oxidase type A, the predominant intraneuronal form of this enzyme,  may also be of interest. The lack of validated biologic markers for the progression of Parkinson's disease hampers attempts to define the action of interventions in the treatment of this disorder.\n\n【67】In the present trial, despite the subjective nature of the primary end point and the large number of investigators, we have consistently found a beneficial effect of deprenyl  . The changes observed in the UPDRS variables supported this finding. The lack of conclusive evidence of a neuroprotective effect of deprenyl justifies further placebo-controlled trials of other promising agents in patients with early Parkinson's disease.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 10:21:14", "endTime": "2024/08/14 10:24:15", "cost": 180.845}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 18:24:15", "grab_time": "2024-08-13 18:21:13"}
{"id": 2234328, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "1616f44f-d119-4632-ba1d-a7d1a7ec2450", "title": "Detection of Malignant Tumors", "text": "【0】Detection of Malignant Tumors\nAbstract\n--------\n\n【1】A sensitive and specific blood test for cancer has long been sought. The water-suppressed proton nuclear magnetic resonance (NMR) spectrum of plasma is dominated by the resonances of plasma lipoprotein lipids. We measured the mean line widths of the methyl and methylene resonances, which were found to be correlated with the presence or absence of malignant tumors. Values for the average line width were lower in patients with cancer. We analyzed plasma from 331 people (normal controls, patients with malignant and benign tumors, patients without tumors, and pregnant patients); NMR analysis and measurement of line widths were blinded to diagnosis or patient group. The mean line width for 44 normal controls (±SD) was 39.5±1.6 Hz. For 81 patients with untreated cancer, demonstrated by biopsy, the line width was 29.9±2.5 Hz. Patients with malignant tumors were reliably distinguished from normal controls by this method (P<0.0001), and differed from patients with diseases that did not involve tumors (line width, 36.1±2.6 Hz; P<0.0001). Patients with benign tumors (e.g., those of the breast, ovary, uterus, and colon) had line widths of 36.7±2.0 Hz and were different from those with malignant tumors (P<0.0001). However, pregnant patients and those with benign prostatic hyperplasia had line widths consistent with the presence of malignant tumors. The narrowing of lipoprotein-lipid resonances with cancer is consistent with the response of a host to tumor growth.\n\n【2】We conclude that these preliminary results demonstrate that water-suppressed proton NMR spectroscopy is a potentially valuable approach to the detection of cancer and the monitoring of therapy.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:53:44", "endTime": "2024/08/14 14:53:56", "cost": 12.144}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 22:53:56", "grab_time": "2024-08-13 22:53:44"}
{"id": 2234327, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "5004b40f-7a23-4b79-8981-1cecea2b13d1", "title": "Evidence for a Defect in Switch T Cells in Patients with Immunodeficiency and Hyperimmunoglobulinemia M", "text": "【0】Evidence for a Defect in Switch T Cells in Patients with Immunodeficiency and Hyperimmunoglobulinemia M\nAbstract\n--------\n\n【1】Immunodeficiency with hyperimmunoglobulinemia M is a syndrome characterized by normal to elevated serum levels of IgM and low levels or absence of IgG and IgA. The defect in this syndrome is thought to reside within the B lymphocyte, which may be unable to undergo a \"switch\" in immunoglobulin class from IgM to IgG or IgA. To address this question more directly, we cultured B cells from nine patients with this syndrome with pokeweed mitogen and either \"switch\" T cells or normal control T cells. In cultures with normal T cells, only IgM was secreted, whereas in cultures with switch T cells, IgG as well as IgM, or IgM, IgG, and IgA were secreted. Furthermore, analysis of the immunoglobulin heavy-chain genes in these B cells by means of genetic probes of constant and switch regions revealed normal gene patterns. These data suggest that B cells from patients with hyperimmunoglobulinemia M may not be abnormal, as previously proposed, and that, at least in some patients with this syndrome, a defect in switch T cells may be pathogenic.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:35:04", "endTime": "2024/08/14 14:36:23", "cost": 78.966}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 22:36:23", "grab_time": "2024-08-13 22:35:04"}
{"id": 2234326, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "bcf7b8ad-f6bb-41ae-8a9e-1b7e7f794f33", "title": "Prospective Payment for Psychiatry — Feasibility and Impact", "text": "【0】Prospective Payment for Psychiatry — Feasibility and Impact\nAbstract\n\n【1】Although 15 diagnosis-related groups (DRGs) have been proposed for psychiatric hospital patients, psychiatric hospitals are currently exempt from the DRG prospective payment system. We investigated the ability of the psychiatric DRGs to predict the hospital length of stay and costs by retrospectively analyzing the charts of 8816 randomly selected patients from 32 psychiatric hospitals throughout the United States. In addition, we developed other grouping systems to see whether they would have been better predictors of length of stay.\n\n【2】We found that grouping the patients in the 15 psychiatric DRGs reduced the total variance in length of stay by only 3.9 percent. Furthermore, our best alternative grouping — based on major diagnostic categories, whether the patient was transferred from another facility, age, and psychiatric complications and comorbidities — reduced the variance by only 7.8 percent.\n\n【3】We conclude that DRGs do not adequately predict length of stay or costs in psychiatric hospitals. We identified factors other than diagnosis that predicted the length of stay better, but all the models we tested would create large financial \"winners\" and \"losers\" and thus introduce inappropriate incentives into the care of patients in psychiatric hospitals.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:31:51", "endTime": "2024/08/14 15:31:56", "cost": 5.413}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 23:31:56", "grab_time": "2024-08-13 23:31:16"}
{"id": 2234325, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "9c9b66ec-d3ce-45d5-a186-567741eb41b2", "title": "Limitations of the Electrocardiographic Response to Exercise in Predicting Coronary-Artery Disease", "text": "【0】Limitations of the Electrocardiographic Response to Exercise in Predicting Coronary-Artery Disease\nAbstract\n--------\n\n【1】The electrocardiographic response to exercise was compared with the results of coronary angiography in 89 patients with Type II hyperlipoproteinemia who had previous myocardial infarction or typical angina or both (43 patients) (Group A), \"atypical angina\" (16 patients) (Group B) or positive electrocardiographic response to exercise without other evidence of cardiac disease (30 patients) (Group C). Thirty-nine of 43 in Group A had ≥50 per cent stenosis, and 26 (67 per cent) of these 39 had negative exercise tests. In Group B, five of 16 had ≥50 per cent Stenosis, and three had positive exercise tests (one patient had a false-positive test). In Group C, eleven of 30 (37 per cent) had ≥50 per cent stenosis; however, nine (30 per cent) had minor stenoses (≤50 per cent), and 10 (33 per cent) normal coronary arteries.\n\n【2】The diagnostic usefulness of exercise electrocardiography is limited. False-negative responses are frequent in patients with clinically suspected coronary disease, and false-positive responses frequent in asymptomatic patients.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:53:46", "endTime": "2024/08/14 15:53:57", "cost": 11.169}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 23:53:57", "grab_time": "2024-08-13 23:50:38"}
{"id": 2234324, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "f96ce430-dd44-46a8-83ee-914ab59be01c", "title": "Anaphylaxis and Hypotension after Administration of Peginesatide", "text": "【0】Anaphylaxis and Hypotension after Administration of Peginesatide\nTo the Editor:\n--------------\n\n【1】Anemia in patients who have chronic kidney disease and are undergoing dialysis is treated with erythropoiesis-stimulating agents (ESAs).  In 2012, the Food and Drug Administration approved peginesatide, an ESA that is administered monthly to such patients. \n\n【2】In July 2012, a large dialysis organization with 2100 centers in the United States initiated a pilot introduction of peginesatide that included concurrent evaluation of the efficacy and safety of peginesatide and the logistics of administering it. Work groups established systems for evaluating clinical conditions, dosages of the drug, logistics of administration, and review of the efficacy and safety of the product. Personnel at each site were educated about the mechanism of action, pharmacokinetics, storage, handling, and dosing of the drug. The manufacturer provided site specialists. Although registration trials revealed no new toxic effects, by September, eight cases of anaphylaxis and hypotension among patients in the pilot initiative were reported, including two deaths from cardiorespiratory causes and three grade 4 anaphylaxis and hypotension events. In December 2012, the manufacturer updated the product label with a warning that serious allergic reactions, including anaphylaxis reactions and hypotension, may occur in patients who receive peginesatide. \n\n【3】Interim analyses of the pilot initiative showed strong results with respect to achieved hemoglobin levels, decreased iron utilization, and low overall toxicity. In February 2013, the pilot initiative was expanded to include patients who had chronic kidney disease and were undergoing dialysis at 348 centers. On February 11 and 12, field staff reported three fatal cardiorespiratory arrests and two episodes of grade 4 anaphylaxis and hypotension at 4 of these centers. No new patients began to receive peginesatide after February 12, pending analysis of the pilot initiative.\n\n【4】Figure 1. Fatal, Life-Threatening, and Non–Life-Threatening Occurrences of Anaphylaxis and Hypotension in Patients Who Received a First Dose of Peginesatide.\n\n【5】Deaths and life-threatening and non–life-threatening events were reported to the Food and Drug Administration.\n\n【6】Between July 2012 and February 2013, a total of 61,482 doses of peginesatide were administered to 19,540 patients at 348 centers . At a total of 19 centers, severe anaphylaxis and hypotension developed in 5 patients, who died from cardiorespiratory arrest in an ambulance or at nearby hospitals; 6 patients had grade 4 anaphylaxis and hypotension; and 17 patients had grade 3 anaphylaxis and hypotension. Symptoms of anaphylaxis began a median of 3.5 minutes after administration of peginesatide (range, 0 to 28.0 minutes). There were 1.4 anaphylaxis and hypotension events per 1000 patients. On February 22, 2013, after the review of data from the pilot initiative, the dialysis organization discontinued administration of peginesatide. On February 23, the manufacturer voluntarily recalled the drug.\n\n【7】The cause or causes of these episodes of anaphylaxis and hypotension have not been defined. All patients received peginesatide from multiple-use vials that contained preservatives, whereas in preapproval trials, patients received the drug from single-use vials.  Prior exposure to ESAs, demographic characteristics, and coexisting device or drug sensitivities have not been associated with the mechanisms of toxicity.\n\n【8】The recognition of anaphylaxis and hypotension resulted in removal of peginesatide from the market. Peginesatide was effective in maintaining hemoglobin levels and was convenient to administer in 19,512 of the 19,540 patients in the pilot initiative. Physicians have been able to continue using other drugs associated with anaphylaxis by administering test doses followed by monitoring before administering full doses or developing formulations that are not associated with anaphylaxis.  Finally, new peptide and protein therapeutic agents have been associated with immediate hypersensitivity and might be candidates for pilot initiatives with concurrent observational analysis such as the pilot initiative involving peginesatide.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-14 00:18:32", "grab_time": "2024-08-13 22:44:02"}
{"id": 2234323, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "79cdb5b5-1dad-4e0b-81e5-1a448653d002", "title": "Low Risk of Herpes Simplex Virus Infections in Neonates Exposed to the Virus at the Time of Vaginal Delivery to Mothers with Recurrent Genital Herpes Simplex Virus Infections", "text": "【0】Low Risk of Herpes Simplex Virus Infections in Neonates Exposed to the Virus at the Time of Vaginal Delivery to Mothers with Recurrent Genital Herpes Simplex Virus Infections\nAbstract\n--------\n\n【1】We studied the risk of herpes simplex virus (HSV) infections in neonates exposed to HSV at the time of vaginal delivery to mothers with a history of recurrent genital HSV infections. None of 34 infants exposed to HSV type 2 acquired an HSV infection. On the basis of this sample, the 95 percent confidence limit for the theoretical maximum infection rate is 8 percent. Cord blood or blood obtained during the first two weeks of life was available from 33 of the 34 exposed, uninfected neonates. All 33 of the samples possessed demonstrable neutralizing antibody to HSV type 2, and 79 percent had titers above . These results were compared with those in a previously studied group of neonates with HSV infections; the latter infants were significantly less likely at the onset of symptoms to have demonstrable neutralizing antibody to HSV type 2 (P = 0.000148) or to have titers above  (P<0.00001).\n\n【2】We conclude that given the low attack rate, empirical antiviral therapy is not warranted in all infants of mothers with recurrent genital HSV infection who are exposed to the virus in the birth canal. Our findings suggest that the presence and titer of neutralizing antibody to HSV contribute to the low attack rate.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:46:06", "endTime": "2024/08/14 15:46:16", "cost": 9.639}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 23:46:16", "grab_time": "2024-08-13 23:46:06"}
{"id": 2234322, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "3e7348b4-47a0-47e2-a8f4-d109d29546a7", "title": "Case 15-2007 — A 20-Year-Old Woman with Asthma and Cardiorespiratory Arrest", "text": "【0】Case 15-2007 — A 20-Year-Old Woman with Asthma and Cardiorespiratory Arrest\nA 20-year-old woman with a history of severe asthma was found at home in an unresponsive state and was taken to the emergency room. Asthma had been diagnosed at 4 years of age, with multiple exacerbations thereafter that required hospitalization. The patient and her mother had not followed environmental and medication regimens. In the weeks before admission, the patient had visited many emergency rooms and clinics because of exacerbations. She was pronounced dead shortly after arrival. An autopsy was performed.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 18:05:31", "endTime": "2024/08/13 18:05:48", "cost": 16.943}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 02:05:48", "grab_time": "2024-08-13 02:05:31"}
{"id": 2234321, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "fac6ea07-d1e2-4e3a-9e92-464e69d93477", "title": "Elevated Plasma 1,25-Dihydroxyvitamin D Concentrations in Infants with Hypercalcemia and an Elfin Facies", "text": "【0】Elevated Plasma 1,25-Dihydroxyvitamin D Concentrations in Infants with Hypercalcemia and an Elfin Facies\nAbstract\n--------\n\n【1】We measured plasma concentrations of 1,25-dihydroxyvitamin D (1,25-(OH) <sub>2 </sub> D) in the course of a 6-to-37-month survey of four children with hypercalcemia and an elfin facies (Williams syndrome). Levels of 1,25-(OH) <sub>2 </sub> D were elevated (160 to 470 pg per milliliter) during the hypercalcemic phase of the disease, when the children were five to nine months old, and they decreased thereafter. Plasma 1,25 (OH) <sub>2 </sub> D levels were higher than those found in (1) three children (16 to 60 months old) with the elfin facies syndrome and no hypercalcemia (42 to 71 pg per milliliter) and (2) eight children (1 to 36 months old) with hypercalcemia and no dysmorphy (12 to 140 pg per milliliter), including two children with vitamin D intoxication. Hypercalcemia in the three children with elfin facies was controlled by a low-calcium diet. Serum calcium levels fell to the normal range, and plasma 1,25-(OH) <sub>2 </sub> D levels were normal for age (18 to 105 pg per milliliter) at 14 to 47 months of age, even after appropriate therapy had been discontinued. These observations suggest that hypercalcemia may be the consequence of abnormal synthesis or degradation of 1,25-(OH) <sub>2 </sub> D in children with the elfin facies syndrome.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 16:31:21", "endTime": "2024/08/13 16:31:43", "cost": 21.982}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 00:31:44", "grab_time": "2024-08-13 00:31:21"}
{"id": 2234320, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "08f94966-c55a-4788-bed0-3897de99d3d5", "title": "Virus in Semen and the Risk of Sexual Transmission", "text": "【0】Virus in Semen and the Risk of Sexual Transmission\nArticle\n-------\n\n【1】Sexual contact is the primary route of human transmission for sexually transmitted infections (STIs). Traditional STIs are caused by a variety of pathogens, and classic examples of STIs include chlamydia, gonorrhea, syphilis, the acquired immunodeficiency syndrome, and genital herpes. Recently, reports showing virus detection in the semen of men infected with viruses that had previously been unknown to be sexually transmitted have caught the attention of infectious disease specialists, public health officials, and the media. Two of the more prominent examples are Zika virus (ZIKV) and Ebola virus (EBOV), which have been found in symptomatically infected patients and disease survivors.  Contrary to prevalent belief, the detection of viral genomes in semen tends to be more common among viruses that are typically not sexually transmitted, such as certain adenoviruses, bunyaviruses, flaviviruses, hepadnaviruses, herpesviruses, paramyxoviruses, and retroviruses.  However, although such detection should not come as a surprise, the contribution of it to virus transmission and consequently to epidemiology, disease burden, and public health needs to be defined.\n\n【2】Infectivity is a prerequisite for pathogen transmission, which also depends on factors such as infectious dose and exposure route. These days, virus detection seems to be achieved largely by means of molecular methods and the use of state-of-the-art technologies, such as polymerase-chain-reaction and deep-sequencing approaches. These methods have replaced more traditional approaches, especially in field diagnostic testing, because they provide more rapid, highly sensitive, and specific means of pathogen discovery. In the past, virus isolation, whether in cell culture or laboratory animals, was considered to be a standard procedure, but it seems almost neglected in diagnostic testing today because it is slower, more laborious, and potentially more hazardous than the newer molecular methods. In addition, the isolation of highly pathogenic viruses, such as EBOV, requires complex biosafety and biosecurity measures that can be lowered for most molecular approaches. Yet, virus isolation remains the only direct and definitive approach for proving infectivity.\n\n【3】The article by Mead and colleagues  in this issue of the _Journal_ shows the potential shortcomings of current virus-detection standards when it comes to the relevance for infectious disease and public health. In this study, 4% of the ZIKV RNA–positive semen samples were found to be infectious, and infectivity was observed only in samples that were obtained within 30 days after illness onset and that had a viral load of more than 7.0 log <sub>10 </sub> RNA copies per milliliter. This finding suggests that there is a short period during which ZIKV-infected men might transmit this virus through sexual contact. Likewise, the fact that sexual transmission could rarely be confirmed for EBOV, despite the detection of RNA in the semen of survivors more than 1 year after acute infection, further shows the shortcomings of molecular detection alone in understanding transmissibility.  In some contexts, current practice calls for the sequential testing of semen samples until at least two consecutive negative results are found. However, this algorithm is controversial because it may not address the potential for virus latency and reactivation (if it exists for a given pathogen) driven by undefined factors, which means that a person could be shedding virus intermittently. This also raises the question of whether modern molecular approaches are properly positioned to detect virus latency rather than persistence. Nevertheless, the goal should be the determination of infectivity, which is probably best assessed by means of viral isolation, which is considered to be less sensitive than molecular detection. Thus, the diagnostic situation is far more complicated than it seems.\n\n【4】For public health purposes, all the scenarios above might be less applicable. For communicable diseases, such as those caused by EBOV or similar viruses, preventive reactive measures must be taken on the basis of the potential for transmission. The World Health Organization reacted to the new risk of EBOV being sexually transmitted by revising the guidelines regarding sexual practices of survivors.  Similarly, public health entities have quickly issued recommendations for safer sex to prevent the spread of ZIKV and the potentially devastating complication of fetal infection.  These recommendations leverage the best data available and have been implemented but ought to be updated as new data emerge.\n\n【5】On the research front, we need more rapid approaches for detection that measure virus infectivity rather than genome presence. Even though it will be difficult to conduct this work, it should be feasible.  We must further understand the source and mechanism leading to virus latency or persistence in semen, which organelles and cell types produce virus, and the viral load in seminal fluid. These are just a few important research questions to be addressed.\n\n【6】Finally, the provocative notion that many pathogenic viruses in humans can be detected in the semen of infected men should be contemplated. The presence of such viruses in semen may potentially contribute to additional risks of transmission and complicate our understanding of the epidemiology of these emerging pathogens. Lassa virus, a rising public health concern in West Africa, might be the next example on the growing list of emerging viruses that are typically not sexually transmitted.  Do these viral diseases then all become STIs? This is unlikely, because potential STIs with distinct primary routes of transmission will probably be separated from the traditional STIs.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 10:54:28", "endTime": "2024/08/14 10:56:09", "cost": 101.369}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 18:56:09", "grab_time": "2024-08-13 18:54:28"}
{"id": 2234319, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "ac81757b-11c2-48b7-a2b8-726a91ada178", "title": "Dealing with Racist Patients", "text": "【0】Dealing with Racist Patients\nA patient's refusal of care based on the physician's race or ethnic background can raise thorny ethical, legal, and clinical issues — and can be painful and confusing for physicians. Sound decision making in this context turns on five ethical and practical factors.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:47:10", "endTime": "2024/08/14 14:47:17", "cost": 7.772}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 22:47:17", "grab_time": "2024-08-13 22:47:09"}
{"id": 2234318, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "269e8352-bb1a-48d6-b810-00cacaad9ddd", "title": "Ketek — The FDA Perspective", "text": "【0】Ketek — The FDA Perspective\nTo the Editor:\n--------------\n\n【1】In response to the article by Ross in this issue of the _Journal_  <sup><a>1 </a></sup> we wish to clarify how the Food and Drug Administration (FDA) reviewed Ketek (telithromycin). Although there are other statements or suggestions in the article that also need clarification, we address a few key points in the limited space available here.\n\n【2】First, safety concerns were identified by the FDA early in the review process and taken very seriously throughout four years and three review cycles. The FDA's approval decision followed a careful review of the safety data submitted, including foreign postmarketing adverse-event reports that accumulated during the FDA's review of the application. Although the FDA did not rely on study 3014 to support approval, we reviewed the study for safety findings that would have counted “against the drug,” as is consistent with good review practice.\n\n【3】Second, there was no intention to deceive the advisory committee or the public regarding our review of study 3014. Before the second advisory committee meeting, the FDA had only preliminary information regarding inspections of a few of over 1800 clinical study sites. Although the findings at one site had raised serious data-integrity concerns and had led to a referral for criminal investigation, we did not know at that time that we would conclude months later, after additional inspections and further review, that the entire study should not be relied upon. The FDA did not discuss data-integrity issues at the second advisory committee meeting to avoid compromising the ongoing investigations, recognizing that the FDA retained the ultimate decision authority.\n\n【4】Finally, noninferiority studies were considered acceptable as the basis for approval for treatment of certain respiratory infections when the Ketek New Drug Application was submitted. Concurrent with the Ketek review, our thinking on noninferiority studies was evolving. Today, noninferiority studies are no longer considered acceptable for two of the three indications for which Ketek was originally approved. We are applying this new regulatory position to more recently submitted and planned applications.\n\n【5】The FDA monitored the safety of Ketek after approval and conducted a 1-year postapproval safety review in the spring of 2005. After three reports of serious hepatotoxicity were published in January 2006, we conducted an analysis of the available safety data that led to the addition of a bolded warning regarding hepatotoxicity in June 2006. After an advisory committee review of Ketek in December 2006, in February 2007 we added a boxed warning and Medication Guide to the label and removed two indications. Although we believe that the potential benefits of Ketek outweigh its risks when it is used according to the current approved label, we continue our safety surveillance and will take further actions if warranted.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": " 1 ", "content": "【0】Ketek — The FDA Perspective\nTo the Editor:\n--------------\n\n【1】In response to the article by Ross in this issue of the _Journal_  <sup><a>1 </a></sup> we wish to clarify how the Food and Drug Administration (FDA) reviewed Ketek (telithromycin). Although there are other statements or suggestions in the article that also need clarification, we address a few key points in the limited space available here.\n\n【2】First, safety concerns were identified by the FDA early in the review process and taken very seriously throughout four years and three review cycles. The FDA's approval decision followed a careful review of the safety data submitted, including foreign postmarketing adverse-event reports that accumulated during the FDA's review of the application. Although the FDA did not rely on study 3014 to support approval, we reviewed the study for safety findings that would have counted “against the drug,” as is consistent with good review practice.\n\n【3】Second, there was no intention to deceive the advisory committee or the public regarding our review of study 3014. Before the second advisory committee meeting, the FDA had only preliminary information regarding inspections of a few of over 1800 clinical study sites. Although the findings at one site had raised serious data-integrity concerns and had led to a referral for criminal investigation, we did not know at that time that we would conclude months later, after additional inspections and further review, that the entire study should not be relied upon. The FDA did not discuss data-integrity issues at the second advisory committee meeting to avoid compromising the ongoing investigations, recognizing that the FDA retained the ultimate decision authority.\n\n【4】Finally, noninferiority studies were considered acceptable as the basis for approval for treatment of certain respiratory infections when the Ketek New Drug Application was submitted. Concurrent with the Ketek review, our thinking on noninferiority studies was evolving. Today, noninferiority studies are no longer considered acceptable for two of the three indications for which Ketek was originally approved. We are applying this new regulatory position to more recently submitted and planned applications.\n\n【5】The FDA monitored the safety of Ketek after approval and conducted a 1-year postapproval safety review in the spring of 2005. After three reports of serious hepatotoxicity were published in January 2006, we conducted an analysis of the available safety data that led to the addition of a bolded warning regarding hepatotoxicity in June 2006. After an advisory committee review of Ketek in December 2006, in February 2007 we added a boxed warning and Medication Guide to the label and removed two indications. Although we believe that the potential benefits of Ketek outweigh its risks when it is used according to the current approved label, we continue our safety surveillance and will take further actions if warranted.", "index": 131, "show": true, "start": 131, "end": 134, "province": ["文本干净度", "页码/数字"], "isEdit": false, "comment": "1"}], "startTime": "2024/08/14 15:08:17", "endTime": "2024/08/14 15:08:37", "cost": 19.996}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 23:08:37", "grab_time": "2024-08-13 23:08:16"}
{"id": 2234317, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "d16bb11e-f017-4f0b-bc6a-27dcb05d7e09", "title": "On Suboptimization — Cadillac Care at the Mecca", "text": "【0】On Suboptimization — Cadillac Care at the Mecca\nDavid was happy with his care at the Mecca, though it meant a year of unnecessary tests and worry. But it revealed a problem of suboptimization: what happens when the whole is greater than the sum of its parts and the right hand doesn’t know what the left hand is doing.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:14:17", "endTime": "2024/08/14 15:15:39", "cost": 81.518}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 23:15:39", "grab_time": "2024-08-13 23:14:17"}
{"id": 2234316, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "d2bf3937-f5dd-4d69-8f26-230e9728261f", "title": "Audio Interview: Waning Immunity against SARS-CoV-2", "text": "【0】Audio Interview: Waning Immunity against SARS-CoV-2\nArticle\n-------\n\n【1】### Audio Interview\n\n【2】 Waning Immunity against SARS-CoV-2 \n\n【3】The continuing spread of SARS-CoV-2 remains a Public Health Emergency of International Concern. What physicians need to know about transmission, diagnosis, and treatment of Covid-19 is the subject of ongoing updates from infectious disease experts at the _Journal_ .\n\n【4】In this audio interview conducted on December 7, 2021, the editors discuss new studies of the duration of immunity conferred by Covid-19 vaccines.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 10:24:18", "endTime": "2024/08/14 10:24:46", "cost": 28.011}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 18:24:46", "grab_time": "2024-08-13 18:24:18"}
{"id": 2234315, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "b28ede4b-5091-4261-a8ef-9cbf13af6ce6", "title": "Brief Report: Umbilical-Cord Ligation of an Acardiac Twin by Fetoscopy at 19 Weeks of Gestation", "text": "【0】Brief Report: Umbilical-Cord Ligation of an Acardiac Twin by Fetoscopy at 19 Weeks of Gestation\nIntroduction\n------------\n\n【1】Twin reversed-arterial-perfusion sequence is a serious complication of monozygotic multiple gestations, affecting 1 percent of monozygotic twins, or 1 in 35,000 births  . It has been hypothesized that in the presence of artery-to-artery and vein-to-vein anastomoses in a monozygotic placenta, blood is perfused by the hemodynamically advantaged twin (“pump” twin) to the other twin (“recipient” twin) by means of retrograde flow  . Inadequate perfusion of the recipient twin is responsible for the development of a characteristic and invariably lethal set of anomalies, including acardia and acephalus. Typically, the pump twin is structurally normal, but it is at risk for in utero cardiac failure and without treatment dies in 50 to 75 percent of cases, particularly if the recipient twin weighs more than half as much as the pump twin  . The therapeutic goal of interrupting the vascular communication between the twins, although simple in concept,  has been difficult to accomplish. Methods have ranged from removal of the anomalous twin (sectio parva)  to ultrasound-directed thrombosis of the umbilical circulation of the perfused twin  . The maternal morbidity associated with the performance of a hysterotomy in the former method and the unreliable outcome of ultrasound-directed procedures prompted us to explore a different therapeutic approach.\n\n【2】Transabdominal fetoscopy was developed as a method of prenatal diagnosis  . We now report on the use of in utero operative endoscopic techniques to ligate the umbilical cord of an acardiac twin at 19 weeks' gestation. The procedure was followed by the uncomplicated birth of a normal twin at 36 weeks' gestation.\n\n【3】Case Report\n-----------\n\n【4】Figure 1. Color Doppler Demonstration of Reversed Arterial Perfusion in the Acardiac Twin.\n\n【5】Flow toward the fetus appears in red. The arterial nature of this vessel is confirmed by pulsed Doppler ultrasonography. Note the cystic areas (arrow) in the abdomen of the acardiac twin.\n\n【6】A twin pregnancy with twin reversed-arterial-perfusion sequence was diagnosed at 18 weeks' gestation in a 24-year-old woman (gravida 3, para 1) at our institution. The affected fetus was an acardius acephalus, had characteristic cystic structures in the thoracoabdominal areas, and had no upper limbs. Analysis of color Doppler wave forms (Acuson 128-VP/10 OB, Mountain View, Calif.) confirmed arterial flow from the placenta toward the acardiac twin . The abdominal circumference of the acardiac twin was much larger than that of the normal twin (195 mm vs. 125 mm, a recipient twin:pump twin ratio of 156 percent). The pump twin appeared structurally normal with no hydramnios. Chromosomal studies indicated a normal 46,XY karyotype in both fetuses.\n\n【7】Therapeutic alternatives discussed with the parents included medical treatment with digoxin if cardiac failure was diagnosed in the normal twin  ; removal of the acardiac fetus by laparotomy; percutaneous, ultrasound-guided thrombosis of the umbilical cord with thrombogenic coils; termination of pregnancy; and fetoscopic umbilical-cord ligation. After being informed of the risks and potential benefits of each therapeutic approach, the couple agreed to try fetoscopic umbilical-cord ligation. Approval was obtained from the Human Investigations Committee of Hutzel Hospital.\n\n【8】Figure 2. Umbilical-Cord Ligation of the Acardiac Twin.\n\n【9】The first knot (shown in the center of the fetoscope) has been tied with purple Vicryl on the umbilical cord. The degree of tightening is evidenced by the constriction of the cord. The magnification is approximately x10.\n\n【10】The procedure was performed with the use of general anesthesia to decrease fetal activity and minimize discomfort to the mother. Ultrasonography revealed that the placenta covered most of the anterior uterine wall. Areas free of placenta were identified for the insertion of the operating instruments. The placental and fetal sites of insertion of the umbilical cord were identified sonographically in both fetuses. The umbilical cord of the acardiac twin lay beneath the fetus, beside the posterior uterine wall. A 12-gauge trocar with a check-flow valve (Cook Ob/Gyn, Spencer, Ind.) was introduced percutaneously under ultrasound guidance into the amniotic cavity at the level of the uterine fundus through a 2-mm skin incision (the viewing port). A 5-degree multilens endoscope that was 1.9 mm in diameter and 11 cm long (Richard Wolf, Vernon Hills, Ill.) was inserted through this sleeve into the amniotic cavity of the normal twin. A video camera (Karl Storz, Culver City, Calif.) was attached to the eyepiece of the endoscope, and the fetoscopic images were recorded. Severe oligohydramnios of the acardiac twin precluded fetoscopic access to its umbilical cord. Therefore, an 18-gauge needle (Cook Ob/Gyn) was used to infuse the sac of the acardiac twin with Ringer's lactated solution. A second 12-gauge trocar (Cook Ob/Gyn) (the working port) was placed approximately 10 cm below the first port, to avoid the placenta. The amniotic membrane of the sac of the acardiac twin was cut with 5-French semirigid scissors (Richard Wolf) to expose the umbilical cord. A 3-0 Vicryl suture (Ethicon, Sommerville, N.J.) was passed beneath the umbilical cord with a 5-French semirigid automatic rat-tooth grasper (Cook Ob/ Gyn). The grasper was then passed over the cord so that the suture could be grasped on the other side. The suture was pulled through the trocar sleeve back outside the amniotic cavity to the level of the patient's skin. The other end of the suture had previously been fed through a 19.5-gauge knot pusher (Cook Ob/Gyn). A tight extracorporeal knot was tied with four throws with the knot pusher through the working port . Wave-form analysis of the umbilical artery of the normal fetus demonstrated an increase in the systolic:diastolic ratio from 3.9 before the procedure to 5.0 after ligation, but no signs of heart failure were apparent. The ends of the sutures were cut with the scissors within the amniotic cavity, approximately 1 cm away from the knot. A second knot was tied around the cord approximately 3 cm away from the first knot.\n\n【11】Mild uterine irritability was easily controlled postoperatively with intravenous magnesium sulfate (a loading dose of 6 g followed by a maintenance dose of 2 g per hour) for 24 hours. The patient was sent home 36 hours after the procedure. Sonographic examinations were performed every week. No substantial change in the size or shape of the acardiac twin was noted for the first three weeks.\n\n【12】At 22 weeks' gestation, the patient reported the leakage of fluid from the vagina. Examination with a sterile speculum confirmed premature rupture of membranes (positive Nitrazine \\[Bristol-Myers, Princeton, N.J.\\], fern, and pool tests). Amniotic fluid obtained by amniocentesis was negative on Gram's staining and culture for microorganisms, and the leukocyte count and glucose concentration were within normal limits. Ultrasonography revealed decreased amniotic-fluid volume, with an amniotic-fluid index of 5 cm; the index decreased further to 2 cm during the next three days. After seven days of hospitalization, the patient noted no further leakage of fluid. Ultrasound assessment confirmed a progressively increasing amniotic-fluid volume (amniotic-fluid index of 8 cm on the 14th day of hospitalization). The patient was sent home. The cystic areas in the anomalous twin disappeared, but this fetus was still visible on ultrasonography throughout the pregnancy. The patient was hospitalized at 36 weeks' gestation with spontaneous rupture of the membranes. She went into spontaneous labor and delivered a healthy 2640-g boy with Apgar scores of 8 and 9 at one and five minutes, respectively. The neonate had a benign course, went home with his mother on the third day, and had a normal pediatric evaluation at three months of age. The acardiac acephalic twin weighed 31 g. Pathological analysis showed two distinct constrictions on the umbilical cord and fibrosis of the umbilical vessels distal to the ligation sites.\n\n【13】Discussion\n----------\n\n【14】The successful in utero management of twin reversed-arterial-perfusion sequence described in this report represents a new approach, that of operative fetoscopy, to the management of fetal disease. Previously used methods included selective delivery of the abnormal fetus through a hysterotomy  and intraarterial injection of either thrombogenic coils  or fibrin in the umbilical cord of the recipient twin  . Although these methods have been used with some success, the first approach requires a hysterotomy and a subsequent cesarean section and has been associated with abruptio placentae, preterm labor, preterm birth, and prolonged maternal hospitalization  . The insertion of thrombogenic coils or fibrin has been associated with the death of both twins  and recanalization of the umbilical cord. Fetoscopic ligation of the umbilical cord is inherently less morbid than hysterotomy and does not have the recanalization problems associated with percutaneous, ultrasound-guided thrombosis of the umbilical cord.\n\n【15】The execution of this procedure required the development of a set of instruments and skills suitable for the performance of intrauterine surgery under endoscopic control. These instruments and techniques were tested first on animals (unpublished data). Special 2-mm trocars (to minimize trauma to the fetal membranes) with check-flow valves were adapted to allow the introduction of the operative and optical instruments without interrupting amniotic-fluid exchange and the monitoring of intraamniotic pressure. Skills were developed to allow the precise orientation of operative instruments inside the uterine cavity under simultaneous endoscopic and sonographic control. Purple Vicryl 3-0 suture was used because of its color, strength, ease of handling, degree of friction, and pliability. The extracorporeal knot-pushing technique used was similar to that described by Clarke  .\n\n【16】The patient's postoperative course was complicated by premature rupture of the membranes three weeks after the procedure. Given that the membranes resealed, we wonder whether rupture of the membranes after operative fetoscopy may not follow the same natural history as spontaneous premature rupture of the membranes.\n\n【17】We anticipate that in utero operative endoscopic techniques will have a role in the care of monochorionic twins discordant for anomalies, pedunculated sacrococcygeal teratomas, and other fetal and placental diseases amenable to surgical treatment. However, one must exercise appropriate prudence and caution when applying recent advances in endoscopic surgery from other fields and from experiments in animals to human fetal surgery. Operative fetoscopy is a new frontier in fetal medicine.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-14 00:13:10", "grab_time": "2024-08-13 23:07:55"}
{"id": 2234314, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "ea173a02-3aa1-46cf-96ae-73f4ca04a599", "title": "Coffee Drinking and Death Due to Coronary Heart Disease", "text": "【0】Coffee Drinking and Death Due to Coronary Heart Disease\nAbstract\n--------\n\n【1】For a series of 649 patients who died of coronary heart disease within 24 hours of onset of symptoms, and an equal number of neighborhood controls, information was obtained on a large number of variables, including coffee consumption. An analysis using multivariate risk scores to control for all available variables yields a maximum likelihood estimate of the risk ratio associated with coffee drinking of 1.1 (95 per cent two-sided confidence limits, 0.8 to 1.6). The estimate of the risk ratio depends somewhat on the number and nature of variables controlled for in the analysis. Overall, our findings, limited to low-risk and middle-risk patients, suggest that the risk, if any, of death from coronary heart disease associated with coffee drinking is small.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:40:39", "endTime": "2024/08/14 14:40:45", "cost": 6.02}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 22:40:45", "grab_time": "2024-08-13 22:40:18"}
{"id": 2234313, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "c80fb473-a782-48fc-a4b8-0cec1b052342", "title": "Course and Prognosis of Chronic Obstructive Lung Disease — A Prospective Study of 200 Patients", "text": "【0】Course and Prognosis of Chronic Obstructive Lung Disease — A Prospective Study of 200 Patients\nAbstract\n--------\n\n【1】To document the course and prognosis of chronic obstructive lung disease, 200 patients with the disorder were enrolled in a prospective standardized study four to eight years ago. Their disease progressed in a more regular and more predictable fashion than had been anticipated from casual clinical observations. Reasonably precise predictions of longevity could be made on the basis of initial findings. Measurements of ventilatory capacity, resting heart rate and carbon dioxide levels were the best indicators of prognosis. Prediction of survival was further improved by consideration of the course of physiologic abnormalities over a two-year follow-up period. Most features of the disease showed a systematic tendency to worsen, but yearly changes were relatively small, often becoming evident only with long-term observation. Data are compatible with the concept that chronic obstructive lung disease is a slowly progressive disorder that begins many years before the onset of clinical symptoms.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:47:29", "endTime": "2024/08/14 14:47:36", "cost": 7.836}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 22:47:36", "grab_time": "2024-08-13 22:47:28"}
{"id": 2234312, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "461c987b-9643-4d85-9566-3fe3fe47f45f", "title": "Germline ", "text": "【0】To the Editor:\n--------------\n\n【1】The remarkable association between somatic _JAK2_ mutations and Philadelphia chromosome–negative myeloproliferative neoplasms is well established.  However, _JAK2_ mutations occur in heterogeneous disorders, and current evidence suggests that they are secondary events in both sporadic and familial myeloproliferative neoplasms, making it challenging to understand the exact role of _JAK2_ mutation in disease pathogenesis. \n\n【2】Figure 1. Autosomal Dominant Hereditary Thrombocytosis Associated with _JAK2_ V617I Mutation.\n\n【3】Panel A depicts the _JAK2_ V617I pedigree. Squares indicate male family members, circles female family members, shading family members found to be _JAK2_ V617I–positive, and slashes deceased persons. CVE denotes a history of an ischemic cerebrovascular event, IHD a diagnosis of ischemic heart disease (myocardial infarction or angina), Plts platelet counts (range of available historical blood counts \\[×10 <sup>−9 </sup> per liter\\] for each person), and VE vascular events. Panel B depicts an electropherogram trace showing a GTC-to-ATC missense mutation at _JAK2_ codon 617, causing a V617I mutation. Panels C and D depict phosphorylated signal transducer and activator of transcription 3 (pSTAT3) mean fluorescence intensity (MFI) relative to unstimulated cells, after stimulation with varying concentrations of granulocyte colony-stimulating factor (G-CSF) for 15 minutes in _JAK2_ V617I–positive versus control CD33+ myeloid cells  and CD34+ stem and progenitor cells .\n\n【4】We herein report a kindred with germline _JAK2_ V617I mutation associated with hereditary thrombocytosis . The proband (C1) presented at 53 years of age with an ischemic cerebrovascular event associated with long-standing thrombocytosis (platelet count, 700×10 <sup>9 </sup> to 970×10 <sup>9 </sup> per liter over a period of 10 years). Screening for _JAK2_ mutation carried out by targeted pyrosequencing showed an abnormal pyrogram trace, not consistent with V617F, identified as a heterozygous V617I mutation present in germline DNA . Family screening identified five additional _JAK2_ V617I–positive persons with thrombocytosis and two _JAK2_ V617I–negative persons with normal platelet counts . Results of other blood tests were normal . Bone marrow examination showed megakaryocyte hyperplasia but no fibrosis . Notably, all three older patients (>40 years of age) had had vascular events ; however, splenomegaly and leukemic transformation were absent. Single-nucleotide-polymorphism array analysis of four affected persons (C1 through C4) did not identify any copy-number abnormalities or areas of uniparental disomy , and sequencing for mutations in the genes for thrombopoietin ligand ( _THPO_ ) and thrombopoietin receptor ( _MPL_ ) was negative in C1 and C2 . Further clinical details are provided in the Supplementary Appendix .\n\n【5】Previous studies have suggested that _JAK2_ V617I, similarly to the more common _JAK2_ V617F, is constitutively activating when expressed in cell lines and in molecular dynamic simulations.  Importantly, _JAK2_ V617I has been reported to occur rarely in myeloproliferative neoplasms; there was 1 _JAK2_ V617I–positive case as compared with 4280 _JAK2_ V617F–positive cases in the same series.  To confirm aberrant signaling in germline _JAK2_ V617I patients, we investigated levels of phosphorylated signal transducer and activator of transcription 3 (pSTAT3) in their peripheral-blood cells. Baseline pSTAT3 activity was not different from that of normal controls . These results were supported by a lack of cytokine-independent colonies (data not shown), a distinction from reported _JAK2_ V617F cytokine-independent colony formation.  However, after stimulation with granulocyte colony-stimulating factor, _JAK2_ V617I–positive peripheral blood CD33+ myeloid and CD34+ stem and progenitor cells  showed a marked increase in pSTAT3 levels, particularly in response to low concentrations of granulocyte colony-stimulating factor. These findings suggest that _JAK2_ V617I causes limited constitutive activation but results in a considerably reduced threshold for cytokine-induced activation.\n\n【6】Germline _JAK2_ mutation is a previously unreported cause of inherited hematopoietic disease. The high penetrance and homogeneous phenotype associated with _JAK2_ V617I, together with cytokine-hyperresponsive _JAK2_ \\-dependent signaling in affected persons, provides compelling evidence of the causative nature of the mutation, although further work is needed. Our findings highlight the need to routinely screen for non– _JAK2_ V617F mutations  and to exclude germline mutation in selected cases. Although these are likely to be rare families, we predict that other germline _JAK2_ mutations will be detected, and genotype–phenotype correlations will be highly informative for our understanding of the direct hematologic effects and mechanisms of action of _JAK2_ mutations.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-14 00:20:22", "grab_time": "2024-08-13 23:26:48"}
{"id": 2234311, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "529456ea-de8d-4885-907c-7714fddb13c0", "title": "Effect of a Comprehensive Surgical Safety System on Patient Outcomes", "text": "【0】Effect of a Comprehensive Surgical Safety System on Patient Outcomes\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Adverse events in patients who have undergone surgery constitute a large proportion of iatrogenic illnesses. Most surgical safety interventions have focused on the operating room. Since more than half of all surgical errors occur outside the operating room, it is likely that a more substantial improvement in outcomes can be achieved by targeting the entire surgical pathway.\n\n【3】Methods\n-------\n\n【4】We examined the effects on patient outcomes of a comprehensive, multidisciplinary surgical safety checklist, including items such as medication, marking of the operative side, and use of postoperative instructions. The checklist was implemented in six hospitals with high standards of care. All complications occurring during admission were documented prospectively. We compared the rate of complications during a baseline period of 3 months with the rate during a 3-month period after implementation of the checklist, while accounting for potential confounders. Similar data were collected from a control group of five hospitals.\n\n【5】Results\n-------\n\n【6】In a comparison of 3760 patients observed before implementation of the checklist with 3820 patients observed after implementation, the total number of complications per 100 patients decreased from 27.3 (95% confidence interval \\[CI\\], 25.9 to 28.7) to 16.7 (95% CI, 15.6 to 17.9), for an absolute risk reduction of 10.6 (95% CI, 8.7 to 12.4). The proportion of patients with one or more complications decreased from 15.4% to 10.6% (P<0.001). In-hospital mortality decreased from 1.5% (95% CI, 1.2 to 2.0) to 0.8% (95% CI, 0.6 to 1.1), for an absolute risk reduction of 0.7 percentage points (95% CI, 0.2 to 1.2). Outcomes did not change in the control hospitals.\n\n【7】Conclusions\n-----------\n\n【8】Implementation of this comprehensive checklist was associated with a reduction in surgical complications and mortality in hospitals with a high standard of care. \n\n【9】Introduction\n------------\n\n【10】Hospitals are not the safe places we would like them to be. A systematic review has shown that 1 in every 150 patients admitted to a hospital dies as a consequence of an adverse event and that almost two thirds of in-hospital events are associated with surgical care.  In recognition of the disproportionate number of such events that are associated with surgical care, several interventions have been proposed to increase patient safety, including relegating surgical procedures to high-volume centers, establishing training programs for laparoscopic surgery, and improving the quality of teamwork in the operating room.  In addition, a number of surgical checklists have been developed. \n\n【11】The Safe Surgery Saves Lives Study Group at the World Health Organization (WHO) recently published the results of instituting a perioperative surgical safety checklist.  The use of this checklist in eight hospitals around the world was associated with a reduction in major complications from 11.0% before introduction of the checklist to 7.0% afterward. However, the standardization of surgical processes should not be limited to the operating room: several studies have shown that the majority of surgical errors (53 to 70%) occur outside the operating room, before or after surgery, making it likely that a more substantial improvement in safety could be achieved by targeting the entire surgical pathway. \n\n【12】This awareness has led to the development of the Surgical Patient Safety System (SURPASS) checklist, a multidisciplinary checklist that follows the surgical pathway from admission to discharge. We evaluated the effect of the use of this checklist on patient outcomes in a controlled, multicenter setting in teaching and academic hospitals with high baseline standards of health care.\n\n【13】Methods\n-------\n\n【14】Checklist and Study Design\n--------------------------\n\n【15】The development and validation of the checklist have been described elsewhere.  The checklist is divided into parts that correspond to the stages of care in the surgical pathway (preoperative, operative, recovery or intensive care, and postoperative), and it is multidisciplinary — the ward doctor, nurse, surgeon, anesthesiologist, and operating assistant are all responsible for completion of parts of the checklist. Items on the checklist include, among others, a review of imaging studies, an accounting of all necessary equipment and materials, the marking of the patient's operative side, the hand-off of postoperative instructions, and the provision of medication prescriptions to the patient at discharge .\n\n【16】Table 1. Characteristics of the Hospitals.\n\n【17】The effects of the checklist on patient outcomes were studied in a controlled, multicenter, prospective study comparing outcomes before and after implementation of the intervention, from October 2007 through March 2009. The checklist was implemented in two academic centers and four teaching hospitals in the Netherlands, all representing a high standard of health care . Before implementation of the checklist, all hospitals used numerous separate checks and protocols for various parts of the surgical pathway, including protocols for marking the operative side and medication checks. In each participating hospital, a project team was assembled, consisting of a surgeon, an anesthesiologist, and a quality-control officer. The implementation was presented to all departments as a quality-improvement project, without emphasizing its research aspect.\n\n【18】The amount of time required to implement the checklist was estimated at 6 to 9 months. The baseline measurement period was 3 months. Complications were documented in all adults who underwent general surgery and were discharged during this period. Patients who were discharged without having undergone surgery and patients with a hospital stay of less than 24 hours were excluded. After implementation of the checklist during a 9-month period, a postimplementation assessment was conducted for 3 months. All adults with a minimum hospital stay of 24 hours who underwent general surgery were included in the postimplementation cohort, not just the patients whose checklist had been completed.\n\n【19】A random sample of checklists from each hospital was entered into an online central database to estimate compliance rates. Compliance was expressed as the percentage of items that had been completed per checklist, and complication rates were compared between the group of patients whose checklists were above the median percentage of completed items and the group whose checklists were at or below the median.\n\n【20】Five control hospitals were selected — one academic center and four teaching hospitals — all of which had high standards of care and were qualitatively similar to the six intervention hospitals . In the control hospitals, data on patients and outcomes were collected in the same manner over the same periods of time as in the intervention hospitals.\n\n【21】The study was reviewed by the institutional review board of the Academic Medical Center and conducted in accordance with the protocol. Because this was an observational study in which the effect of a quality-improvement intervention was assessed with the use of outcome measures that are already routinely collected, the board determined that formal review and informed consent were not required.\n\n【22】Data Collection\n---------------\n\n【23】Data on age, sex, American Society of Anesthesiologists (ASA) score (a measure of coexisting conditions), length of stay, and number and type of surgical procedures were collected from hospital administrative data. Outcome data were collected from the prospective Dutch National Surgical Adverse Event Registration System (LHCR), a nationwide registration system that has been in use for more than 10 years.  The outcome grades in this system correspond to grades in the recently described Accordion Severity Grading System of Surgical Complications.  All postoperative complications are prospectively registered by ward doctors during the patient's hospital stay, discussed by staff at the time of discharge, and entered into an electronic database. The LHCR system is comprehensive. All complications are registered, including, for example, a postponed procedure, and more than one complication per patient can be registered. Complications that arose after discharge were not documented.\n\n【24】Statistical Analysis\n--------------------\n\n【25】All recorded complications were classified into 12 categories (part 2 of the Supplementary Appendix ). The number of complications per 100 patients per category and the proportion of patients with one or more complications were reported. Differences between patients undergoing surgery during the baseline and postimplementation periods were assessed with the use of the Mann–Whitney U-test (for age and length of stay) or the Pearson chi-square test (for sex, ASA score, type of surgical procedure \\[or type of first procedure, in the case of patients who underwent more than one\\], and urgency of medical need) to identify potential confounders. Zero-inflated negative binomial (ZINB) regression analyses were performed to assess the effect of the checklist on the number of complications while accounting for potential confounders. ZINB regression analysis is a suitable approach to counting data when there is overdispersion (the variance is greater than the mean), an excess of zero counts, or concern that complications may be correlated.  Two ZINB models were tested to assess the robustness of the influence of the checklist. The first model addressed the checklist alone; the second accounted for all potential confounders (sex, age, ASA score, hospital, type of surgical procedure, and urgency of medical need). Two-tailed tests of significance were used, and a P value of less than 0.05 was considered to indicate statistical significance. Exact 95% confidence intervals were calculated for the rate of complications (expressed as the number of complications per 100 patients) and the rate ratio. Confidence intervals for the absolute reduction in the risk of complications were calculated with the use of Wilson scores.  Logistic-regression analysis was performed to assess the effect of the checklist on mortality, with correction for the same potential confounders. The analyses were performed with the use of SPSS software, version 16.0, and SAS software, version 9.1.\n\n【26】Results\n-------\n\n【27】Study Cohorts\n-------------\n\n【28】Table 2. Characteristics of Patients in Intervention and Control Hospitals before and after Implementation of the Surgical Safety Checklist.\n\n【29】The preimplementation cohort consisted of 3760 patients, of whom 10.2% underwent more than one procedure; the total number of surgical procedures was 4364 . In the postimplementation cohort, 3820 patients underwent 4387 procedures; 9.7% underwent more than one procedure.\n\n【30】Characteristics of the patients are listed in Table 2 . Some differences between the preimplementation and postimplementation cohorts were observed. Patients in the postimplementation cohort were more likely to undergo surgery for a gastrointestinal condition or for trauma and less likely to undergo surgery for a vascular condition (P<0.001).\n\n【31】A random sample of checklists used for procedures in the postimplementation period (1146 of 4387 procedures, or 26%) was entered into the central database . Among these checklists, a median of 80% (interquartile range, 69 to 91) of items per checklist had been completed .\n\n【32】Outcomes in Intervention Hospitals\n----------------------------------\n\n【33】Figure 1. Mean Number of Complications in Intervention Hospitals and Control Hospitals before and after Implementation of the Surgical Safety Checklist.\n\n【34】The solid horizontal lines show the overall mean number of complications before implementation of the checklist, and the dashed horizontal lines show the mean number after implementation. The change in the mean number of complications from the preimplementation period to the postimplementation period was significant in the intervention hospitals (P<0.001) but not in the control hospitals (P=0.81).Table 3. Table 3. Complication and Outcome Rates in Intervention and Control Hospitals before and after Implementation of the Surgical Safety Checklist. Figure 2.  Figure 2. Number of Complications per Patient in Intervention Hospitals and Control Hospitals before and after Implementation of the Surgical Safety Checklist.\n\n【35】The change in the number of complications per patient from the preimplementation period to the postimplementation period was significant in the intervention hospitals (P<0.001) but not in the control hospitals (P=0.95).\n\n【36】During the 3-month preimplementation period, complication rates were stable . After implementation of the checklist, the total number of complications decreased from 27.3 per 100 patients (95% confidence interval \\[CI\\], 25.9 to 28.7) to 16.7 per 100 patients (95% CI, 15.6 to 17.9), corresponding to an absolute reduction of 10.6 complications (95% CI, 8.7 to 12.4)  and to an uncorrected rate ratio of 0.613 (95% CI, 0.545 to 0.681). There were differences among hospitals in the effect of the checklist. The absolute reduction in the number of complications ranged from 0.3 to 19.5 per 100 patients (part 4 of the Supplementary Appendix ). The proportion of patients with one or more complications was 15.4% in the preimplementation period versus 10.6% in the postimplementation period (P<0.001) .\n\n【37】The complication rate was 7.1 per 100 patients among the 566 patients for whom the extent of checklist completion was above the median, as compared with a rate of 18.8 per 100 among the 580 patients for whom checklist completion was at or below the median (absolute risk reduction, 11.7 complications; 95% CI, 7.9 to 15.6).\n\n【38】In-hospital mortality decreased from 1.5% (95% CI, 1.2 to 2.0) to 0.8%, with an absolute risk reduction of 0.7 percentage points (95% CI, 0.2 to 1.2)  and an uncorrected rate ratio of 0.52 (95% CI, 0.34 to 0.81). The proportion of patients who had temporary disability and the proportion of patients requiring a second surgical procedure to resolve a complication also decreased significantly, by 2.7 percentage points (95% CI, 1.5 to 4.0) and 1.1 percentage points (95% CI, 0.4 to 1.9), respectively .\n\n【39】The ZINB model showed that the checklist, when controlled for potential confounding factors (i.e., sex, age, ASA score, hospital, type of surgical procedure, and urgency of medical need), was associated with an absolute reduction of 9.7 complications (95% CI, 7.8 to 11.5) and a rate ratio for total complications of 0.646 (95% CI, 0.579 to 0.714), which are similar to the crude results of 10.6 and 0.613, respectively. The corrected rate ratio for mortality was 0.54 (95% CI, 0.33 to 0.88).\n\n【40】Outcomes in Control Hospitals\n-----------------------------\n\n【41】In the five control hospitals, complication rates and mortality did not change significantly throughout the study period . The number of complications was 30.4 per 100 patients during the first study period as compared with 31.2 per 100 during the second period (absolute risk reduction, −0.8; 95% CI, −3.2 to 1.7), and the proportions of patients with one or more complications in the first study period were 17.6% and 17.9%, respectively (P=0.95). Mortality was 1.2%, as compared with 1.1% in the second period (absolute risk reduction, 0.1 percentage points; 95% CI, −0.5 to 0.7).\n\n【42】Discussion\n----------\n\n【43】In this multicenter study, implementation of the SURPASS checklist in six teaching and academic hospitals with a high baseline standard of care was associated with a reduction in the postoperative complication rate from 27.3 per 100 patients before implementation to 16.7 per 100 afterward and a reduction in in-hospital mortality from 1.5 to 0.8%. The reduction in complication rates was consistent over the 3 months of the postimplementation period and remained significant after adjustment for potential confounding factors. During the same study period, outcomes did not change in five control hospitals with similar characteristics, increasing the likelihood that the decrease in complication rates in the intervention centers was a result of the use of the checklist. This hypothesis is further supported by the significantly lower complication rate among patients for whom 80% or more of the checklist items were completed than among those for whom a smaller proportion of the checklist items were completed.\n\n【44】Improved outcomes after implementation may be explained by a number of mechanisms. The checklist is designed to incorporate all existing protocols and checks in order to provide a comprehensive framework for the surgical pathway, minimize information loss during transfers from one stage of the pathway to the next, and promote interdisciplinary communication. Specific items on the checklist may directly prevent adverse events. For example, checking for timely cessation of anticoagulant agents may directly prevent perioperative bleeding. In addition, the implementation of the checklist triggers improvements in the entire surgical pathway. In all participating hospitals, many processes were optimized, including digital registration of blood-type cross-matching (incorporation into electronic records), standardization of protocols, and standardization of the timing of antibiotic prophylaxis. Finally, the checklist may lead to improved outcomes by improving teamwork, communication, and attitudes toward quality and safety.\n\n【45】A number of factors might account for the differences in baseline complication rates among the hospitals. One important factor is the difference in case mix. Patients at academic hospitals generally have a larger number of coexisting conditions and undergo more extensive procedures, increasing the likelihood of complications. Another factor that may account for the difference in complication rates is differences in aspects of registration. Although the hospitals' process of documenting complications was uniform, there might have been differences between hospitals in the vigilance and precision with which adverse outcomes were registered. In addition, there were considerable differences across hospitals in the effect of the checklist: the absolute reduction in the number of complications ranged from 19.5 to 0.3 per 100 patients. A number of reasons might account for this difference. First, there were differences in compliance with the use of the checklist at the hospitals. In addition, there might have been hospitals at which checklist integration was not yet optimal after 9 months owing to the existing culture in the hospital or department or to specific implementation strategies.\n\n【46】The improvements in outcome that we observed confirm the results that were achieved with the use of the WHO's surgical safety checklist. However, in the present study, only hospitals with a high baseline standard of care were included, whereas the hospitals included in the WHO study were more diverse. Another difference between this study and the WHO study is the scope of the intervention: the WHO's checklist is intended for use in the operating room only, whereas the SURPASS checklist covers the entire surgical pathway. Many of the risks along the surgical pathway should be corrected at an earlier stage than just before surgery. To delay certain checks until the patient is lying under the operating lights may lead to postponement of surgery, compromised safety, or both. In addition, many adverse events originate in the postoperative stage. \n\n【47】This study has several limitations. First, because it had preimplementation and postimplementation phases, any change that was observed in relation to the intervention might have been influenced by other changes in each hospital that occurred over time or by differences in case mix. However, a randomized study design was not feasible because of the contamination effect in interventions of this kind: hospital personnel using the checklist for one patient will still work according to the checklist, consciously or subconsciously, when providing care for a patient not assigned to the checklist.  In an effort to minimize the influence of changes over time, the measurements performed before and after implementation took place within a year of each other. No other fundamental changes in policy or surgical care occurred in any of the participating hospitals during that year, making it unlikely that the decrease in complications was attributable to factors other than the introduction of the SURPASS checklist. This hypothesis is supported by the observation that in the control hospitals, outcomes did not change significantly from the first 3 months of the study (the baseline period) to the last 3 months (corresponding to the postimplementation period).\n\n【48】A second limitation is the manner in which outcome data were collected. Documentation of complications by physicians has proved to be subject to underreporting.  However, the LHCR has been used to monitor the quality of surgical care in the Netherlands for more than 10 years and is well integrated into daily clinical care. It includes prospective documentation of complications during the hospital stay, with a daily plenary meeting at which staff and residents discuss all complications for patients being discharged. We have no reason to suspect that any possible underregistration was inconsistent over time.\n\n【49】Third, the documentation of complications was limited to the period of admission. Data on complications and deaths occurring after discharge were not collected.\n\n【50】Finally, in interpreting our results, it is important to note that health care providers did not fully comply with the checklist. Compliance rates were monitored in only a sample of patients for whom the checklist had been used. In this sample of 26% of patients who underwent surgical procedures in the postimplementation period, a median of 80% of items per checklist were completed. Although we have no reason to suspect that the checklist was not used at all for a large number of patients, suboptimal compliance during the study period may have led to an underestimation of the effect of the checklist.\n\n【51】The implementation of this checklist requires a considerable amount of time and effort. The checklist is quite comprehensive, requiring the input of care providers from multiple disciplines involved in the care of patients undergoing surgery. By providing a blueprint of the ideal situation, the system reveals safety risks and triggers improvements in all stages of the surgical pathway. These improvements are part of its beneficial effect; when a substantial improvement in patient safety is desired, merely developing and enforcing a checklist do not suffice.  A “culture of safety” is required in the organization, with concerted efforts to reduce risks.\n\n【52】In conclusion, our study shows that the use of the comprehensive SURPASS checklist is associated with reductions in complications and mortality among adults undergoing general surgery in hospitals that have a high baseline standard of care.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-14 00:22:53", "grab_time": "2024-08-13 23:38:53"}
{"id": 2234310, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "3eb81cd1-5bf0-4d41-b7e1-7226cfc2e8ed", "title": "Occurrence of Ophthalmopathy after Treatment for Graves' Hyperthyroidism", "text": "【0】Occurrence of Ophthalmopathy after Treatment for Graves' Hyperthyroidism\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】Ophthalmopathy caused by Graves' disease may first appear or worsen during or after treatment for hyperthyroidism. It is not known, however, whether choosing to treat hyperthyroidism with antithyroid drugs, iodine-131, or surgery affects the development or aggravation of Graves' ophthalmopathy.\n\n【3】Methods.\n--------\n\n【4】We studied 168 patients with hyperthyroidism caused by Graves' disease, stratified into two age groups — 20 to 34 years (54 patients, group 1) and 35 to 55 years (114 patients, group 2). The patients in group 1 were randomly assigned to treatment with methimazole for 18 months or subtotal thyroidectomy, and those in group 2 to either of these two treatments or to iodine-131 therapy. All the patients received thyroxine to avert hypothyroidism, except those treated with iodine-131, who received thyroxine only if hypothyroidism developed. The duration of follow-up was at least 24 months.\n\n【5】Results.\n--------\n\n【6】Twenty-two patients (13 percent) had infiltrative Graves' ophthalmopathy at randomization. During follow-up, ophthalmopathy developed for the first time in 22 patients (13 percent) and worsened in 8 patients (5 percent). The frequency of the development or worsening of ophthalmopathy was similar among the patients in group 1 (medical therapy, 4 of 27 patients \\[15 percent\\]; and surgery, 3 of 27 patients \\[11 percent\\]). In group 2, ophthalmopathy developed or worsened in 4 of the 38 patients (10 percent) treated medically, 6 of the 37 patients (16 percent) treated surgically, and 13 of the 39 patients (33 percent) given iodine-131 (P = 0.02 for the comparison between the iodine-131 subgroup and the others combined). The risk of the development or worsening of ophthalmopathy increased as pretreatment serum triiodothyronine concentrations increased.\n\n【7】Conclusions.\n------------\n\n【8】As compared with other forms of antithyroid therapy, iodine-131 is more likely to be followed by the development or exacerbation of Graves' ophthalmopathy. \n\n【9】Introduction\n------------\n\n【10】THE two most common components of Graves' disease are hyperthyroidism and ophthalmopathy. There is usually a close temporal relation between the onset of the two conditions, but ophthalmopathy can develop long before or after the onset of hyperthyroidism.  <sup>, </sup>  A consistent pathogenic link between them has not been identified, and the cause of Graves' ophthalmopathy is not known.\n\n【11】The choice of an antithyroid drug, thyroidectomy, or iodine-131 for the treatment of hyperthyroidism caused by Graves' disease is usually dictated by the patient's preference, age, the size of the thyroid gland, the severity of hyperthyroidism, and local resources and practice. To our knowledge, there has been no controlled clinical trial evaluating the effects of the different forms of antithyroid therapy on the course of the ophthalmopathy. The results of other types of studies vary widely. In some studies no worsening of ophthalmopathy has been found in patients treated with an antithyroid drug,  <sup>, </sup>  but others have found that exophthalmometer readings increased more among patients given an antithyroid drug than among those given other treatments.  Ophthalmopathy occurred more often among patients given iodine-131 than among those treated medically or surgically in one study,  but not in another study comparing surgery with iodine-131 therapy.  In two retrospective studies of a total of 662 patients with hyperthyroidism caused by Graves' disease who were treated with an antithyroid drug, subtotal thyroidectomy, or low-dose iodine-131, the choice of therapy had no influence on the frequency of either the development or the exacerbation of Graves' ophthalmopathy.  <sup>, </sup> \n\n【12】In 1983 we undertook a clinical trial in which patients with hyperthyroidism caused by Graves' disease were randomly assigned to treatment with an antithyroid drug, subtotal thyroidectomy, or iodine-131 therapy. The trial was designed to answer two questions. First, is there a difference in the frequency of the development or aggravation of Graves' ophthalmopathy among young patients treated with an antithyroid drug as compared with subtotal thyroidectomy and among older patients treated with an antithyroid drug, subtotal thyroidectomy, or iodine-131? And second, can factors that predict the development of Graves' ophthalmopathy be identified?\n\n【13】Methods\n-------\n\n【14】Study Design and Evaluations\n----------------------------\n\n【15】The study was approved by the ethics committee of the Karolinska Institute, and all the patients gave informed consent.\n\n【16】Between November 1983 and June 1990, all patients with hyperthyroidism caused by Graves' disease who were referred to us were evaluated for inclusion in the study. All 179 patients who agreed to enter the study were included. The diagnosis of hyperthyroidism caused by Graves' disease was based on the presence of symptoms and signs of hyperthyroidism, a diffuse goiter, elevated total and free thyroxine and total triiodothyronine (T <sub>3 </sub> ) concentrations in serum, detectable serum concentrations of thyrotropin-receptor antibodies, increased uptake of iodine-131 by the thyroid, and thyroid radionuclide scans showing a diffuse pattern of isotope uptake. Patients with a history of thyroid disease were excluded.\n\n【17】All the patients were examined by the study ophthalmologist before any therapy was begun. The eye examination included testing of visual acuity, tonometry, Hertel exophthalmometry, slitlamp examination, and tests of extraocular-muscle function with Lees' screen. The results of the examination were summarized as an ophthalmopathy-index score, which was based on a modification of the American Thyroid Association's classification of ocular changes in Graves' disease.  Four categories of findings (soft-tissue involvement, exophthalmos, extraocular-muscle involvement, and sight loss) were scored from 1 to 3 according to their severity, giving a maximal overall score of 12. A score of 1 or more was considered to indicate the presence of ophthalmopathy. We omitted corneal changes from our index because they are not specific for Graves' ophthalmopathy.\n\n【18】Through May 1991, 173 of the 179 patients had been followed for at least 24 months after therapy began (range, 24 to 90; mean, 47), and 6 patients for less than 24 months. The latter six were therefore not included in this analysis. Five patients were withdrawn from the study shortly after randomization (three because of noncompliance, one who rejected the assigned iodine-131 treatment, and one in whom the diagnosis was not confirmed). A further six patients did not complete their treatment: two rejected the assigned treatment (iodine-131 in one case and surgery in the other), the diagnosis was not confirmed in two, and two had drug-induced skin rashes; the six were followed, however, and remained in the study. This report therefore includes 168 patients, analyzed according to intention to treat.\n\n【19】Table 1. Clinical and Demographic Characteristics of the Patients with Hyperthyroidism Caused by Graves' Disease.\\*\n\n【20】The patients were stratified into two groups according to age at entry into the study. Group 1 included the patients who were 20 to 34 years old, and group 2 those who were 35 to 55 years old. The patients in group 1 were randomly assigned to treatment with an antithyroid drug plus thyroxine (medical therapy) or subtotal thyroidectomy followed by thyroxine (surgery); in group 2, iodine-131 therapy was included as a third alternative. Randomization was performed with use of balanced lists, one for each age group. The mean age, number of tobacco smokers, and initial serum concentrations of T <sub>3 </sub> , thyroxine, and thyrotropin-receptor antibodies were similar in the two groups, except for a significant difference in the level of thyrotropin-receptor antibodies between the patients who underwent surgery and those who received iodine-131 in group 2 . Apart from the patients who underwent surgery, all were treated as outpatients. The follow-up examinations were performed in the department in which therapy was given. These examinations included clinical evaluations, assessment of ophthalmologic status, and measurements of body weight and serum concentrations of T <sub>3 </sub> , thyroxine, thyrotropin, and thyrotropin-receptor antibodies. The patients in the medical-therapy subgroups also had peripheral-blood leukocyte counts performed, and the patients in the surgery subgroups hemoglobin and serum calcium measurements.\n\n【21】Therapy and Follow-up\n---------------------\n\n【22】### __Medical Therapy__\n\n【23】Medical therapy consisted of the administration of 10 mg of methimazole four times daily for 18 months. To avert hypothyroidism, thyroxine (0.1 to 0.3 mg daily; mean, 0.17) was added after three to five weeks in a dose that resulted in a normal serum T <sub>3 </sub> and a low serum thyrotropin concentration. Propranolol (60 to 240 mg per day) or metoprolol (50 to 300 mg per day) was given initially for a few weeks. Methimazole and thyroxine were discontinued simultaneously. The patients were examined monthly for two months after the initiation of treatment and then every three months. After treatment was discontinued, the patients were examined twice during the first year and then once yearly.\n\n【24】### __Surgery__\n\n【25】The patients who underwent surgery were given propranolol before the operation in a dose of at least 40 mg three to four times daily, or an equivalent dose of metoprolol. The median duration of this therapy before surgery was 26 days. The operation was a bilateral subtotal thyroidectomy, leaving the posterior capsule and approximately 1 g or less of each thyroid lobe. After surgery all the patients were given thyroxine to avert hypothyroidism (0.1 to 0.3 mg daily; mean in both age groups, 0.17 mg). The patients were seen after five weeks, then every three months during the first year after surgery and once yearly thereafter.\n\n【26】### __Iodine-131__\n\n【27】A single oral dose of iodine-131 was administered to the patients in the iodine subgroup. The dose was based on the size of the thyroid, the 24-hour iodine-131 uptake, and the estimated effective half-life of the isotope in the thyroid. The dose was intended to deliver 120 Gy to the thyroid; the calculations have been described elsewhere.  Unless contraindicated, propranolol or metoprolol was given to all the patients. The patients were examined 6 and 10 weeks after iodine-131 therapy, and the 24-hour uptake of iodine-131 by the thyroid was measured at 10 weeks. Eighteen patients were given more than one dose of iodine-131 from 10 weeks to 23 months after the initial treatment. Seven of these 18 patients had persistent hyperthyroidism at 10 weeks, 3 had recurrent hyperthyroidism without ophthalmopathy, 5 had recurrent hyperthyroidism and developing ophthalmopathy, and 3 had ophthalmopathy and no evidence of hyperthyroidism but continued to have iodine-131 uptake in the thyroid despite thyroxine therapy. Among the 18 patients who received more than one dose of iodine-131, ophthalmopathy worsened in 2 and developed in 10. Of the 10 patients, 3 received the second dose of iodine-131 before the ophthalmopathy developed. The patients who were euthyroid 10 weeks after iodine-131 therapy were examined every 3 months until they had biochemical evidence of hypothyroidism. All the patients eventually had hypothyroidism and received thyroxine (0.1 to 0.3 mg daily; mean, 0.15); thereafter, they were examined twice yearly for two years and then once yearly.\n\n【28】Ophthalmologic Follow-up\n------------------------\n\n【29】The patients were examined and their ophthalmopathy-index scores determined by the ophthalmologist after one year if the first examination had not revealed any signs of ophthalmopathy (i.e., an index score of 0). Patients were referred to the ophthalmologist if eye symptoms or signs developed during follow-up. Patients with ophthalmopathy (index score, ≥1) had monthly ophthalmologic examinations until their condition improved or stabilized; they were then examined one year later. The ophthalmologist was unaware of the type of therapy given except in the cases of patients who underwent surgery and those referred because of ocular problems.\n\n【30】Laboratory Studies\n------------------\n\n【31】Serum T <sub>3 </sub> and thyroxine concentrations were measured by radioimmunoassay with kits obtained from Pharmos Group (Turku, Finland). Serum free thyroxine concentrations were measured by radioimmunoassay with kits from Diagnostic Products (Los Angeles). Serum thyrotropin concentrations were measured by immunometric assay with kits from Delfia (Kabi-Pharmacia, Uppsala, Sweden), and thyrotropin-receptor antibodies by radioreceptor assay with kits provided by Dr. B. Rees Smith (Cardiff, United Kingdom). The normal reference ranges were as follows; T <sub>3 </sub> , 1.1 to 2.5 nmol per liter; thyroxine, 75 to 150 nmol per liter; free thyroxine, 9 to 21 pmol per liter; thyrotropin, 0.4 to 4.5 mU per liter; and thyrotropin-receptor antibodies, <10 percent. Measurements of 24-hour iodine-131 uptake by the thyroid, thyroid radionuclide scanning with iodine-131 or \\[ <sup>99m </sup> Tc\\]pertechnetate, and fine-needle aspiration biopsies of the thyroid were performed before therapy in all the patients. Biopsy was successful in 155 patients. The results were recorded as \"lymphocytes present\" (a higher number in the thyroid specimen than in the blood in the aspirate) or \"lymphocytes not present.\"\n\n【32】Statistical Analysis\n--------------------\n\n【33】Figure 1. Kaplan–Meier Plots of the Development or Worsening of Ophthalmopathy in Patients with Hyperthyroidism Caused by Graves' Disease. Figure 2.  Figure 2. Probability of the Development or Worsening of Ophthalmopathy in Patients with Hyperthyroidism Caused by Graves' Disease.\n\n【34】The curves were constructed from the regression coefficients in the logistic-regression analysis, with serum T <sub>3 </sub> concentrations before treatment and the type of therapy as explanatory variables.\n\n【35】All the data were stored with use of Medlog software (Information Analysis, Mountain View, Calif.). The hypothesis that there were no differences among treatments with regard to the occurrence of ophthalmopathy within two years after the initiation of therapy was tested by chi-square analysis. Kaplan–Meier survival curves  were used to illustrate the pattern of occurrence of ophthalmopathy according to treatment group. When searching for prognostic factors, we applied logistic-regression analysis, with the outcome variable defined as the development or worsening of ophthalmopathy within two years after treatment. Using the regression coefficients from this analysis, we could draw the risk functions  by means of Minitab software. In a final regression analysis, all the available follow-up information for each patient was used.\n\n【36】Results\n-------\n\n【37】The mean serum T <sub>3 </sub> , thyroxine, and free thyroxine concentrations were within the normal reference intervals in all subgroups within six weeks after the initiation of therapy (data not shown). The serum concentrations of thyrotropin-receptor antibodies decreased gradually during the first year in the surgically and medically treated subgroups. In the iodine-131 subgroup, however, serum thyrotropin-receptor antibodies increased during the first year, after which they decreased (mean peak value, 66 percent).\n\n【38】During follow-up after the discontinuation of medical therapy, 10 of the 27 patients (37 percent) in group 1 and 12 of the 38 patients (32 percent) in group 2 who received this therapy had recurrent hyperthyroidism. Eight patients who received medical therapy had skin rashes, and one had symptoms similar to those of systemic lupus erythematosus; no patient had agranulocytosis. None of the patients treated surgically had permanent hypoparathyroidism or recurrent laryngeal-nerve damage.\n\n【39】Ophthalmopathy\n--------------\n\n【40】Table 2. Pretreatment Ophthalmopathy-Index Scores of Patients with Hyperthyroidism Caused by Graves' Disease, According to Treatment.\n\n【41】Twenty-two patients (13 percent) had ophthalmopathy (i.e., an index score ≥1) at the time of the initial ophthalmologic examination, before any antithyroid treatment. The distribution of the index scores at that time is shown in Table 2 . Of the 22 patients, 4 were among the 54 patients in group 1 (7 percent) and 18 were among the 114 patients in group 2(16 percent). Eighty-seven of the 168 patients (52 percent) had ophthalmologic abnormalities (including those with only lid retraction and lid lag).\n\n【42】Table 3. Changes in the Ophthalmopathy-Index Score after Treatment and the Risk of Development or Worsening of Ophthalmopathy.\n\n【43】New ophthalmopathy developed in 22 patients (13 percent), and 8 patients (5 percent) had worsening of preexisting ophthalmopathy after therapy. The distribution of the patients with regard to the changes in ocular status is shown in Table 3 . There was no significant difference in the frequency of the development or worsening of ophthalmopathy among the medically and surgically treated patients in group 1 (chi-square, 0.16; P>0.05). In group 2, however, ophthalmopathy developed or worsened in 33 percent of the patients treated with iodine-131, as compared with 10 percent of those treated medically and 16 percent of those treated surgically (chi-square, 6.75 with 2 df; P = 0.03 \\[P = 0.02 for the comparison of the iodine-131 subgroup with the others combined\\]). The probability of the development or worsening of ophthalmopathy within the first five years is shown in Figure 1 .\n\n【44】Table 4. Characteristics of the 30 Patients with Hyperthyroidism Caused by Graves' Disease in Whom Ophthalmopathy Developed or Worsened.\n\n【45】The ophthalmopathy was mild in the majority of the 30 patients in whom it developed or worsened . The mean maximal index score ranged from 1.8 (group 1, medical-therapy subgroup) to 3.3 (group 2, medical-therapy subgroup), and the highest score in any patient was 7. Only 6 of the 168 patients (4 percent), all in group 2, required treatment for ophthalmopathy. One of these patients belonged to the medical-therapy subgroup, one to the surgical subgroup, and four to the iodine-131 subgroup. All six patients were treated with prednisolone, and the patient in the medical-therapy subgroup and three of those in the iodine-131 subgroup also received orbital radiotherapy. No patient lost vision because of optic-nerve compression, and none needed orbital decompression or eye-muscle surgery. Five patients had eyelid surgery. The ophthalmopathy developed or worsened in 24 patients within the first year after therapy began and in 6 patients during the second year.\n\n【46】Cytologic Studies\n-----------------\n\n【47】The frequency with which lymphocytes were detected in the fine-needle aspirates of the thyroid ranged from 26 to 48 percent in the five subgroups (P>0.05). Among the 51 patients with lymphocytes in the fine-needle aspirates, ophthalmopathy developed in only 3 (6 percent), whereas it developed in 25 of the 104 patients (24 percent) whose aspirates did not contain lymphocytes. Among the patients who underwent biopsies, ophthalmopathy developed in 21 and worsened in 7; the proportions of biopsy specimens containing lymphocytes were 14 percent (3 patients) and 0 percent, respectively (P>0.05).\n\n【48】Predictive Factors\n------------------\n\n【49】By means of a series of logistic-regression analyses, we sought possible predictive factors for the development or worsening of ophthalmopathy. Apart from the treatment, the variables that proved important were the pretreatment serum T <sub>3 </sub> concentration and the degree of lymphocytic infiltration of the thyroid. The influence of the T <sub>3 </sub> concentration and the type of treatment on the risk of the development or worsening of ophthalmopathy is shown in Figure 2 .\n\n【50】A proportional-hazards regression analysis based on all available follow-up information and including the background variables of sex and age for all patients revealed that the following explanatory variables were statistically significant: treatment with iodine-131 (relative risk, 3.6; 95 percent confidence interval, 1.6 to 8.2; P = 0.002), serum T <sub>3 </sub> concentration before treatment (P = 0.002), and the presence of lymphocytes in the thyroid (relative risk, 0.2; 95 percent confidence interval, 0.1 to 0.8; P = 0.02). When this analysis was performed for the patients in group 2 alone, the pattern was the same, and the relative risk of ophthalmopathy associated with iodine-131 treatment was 4.1 (95 percent confidence interval, 1.7 to 10.0; P = 0.02).\n\n【51】Table 5. Patients with Hyperthyroidism Caused by Graves' Disease According to Pretreatment Serum T <sub>3 </sub> Concentrations and the Development or Worsening of Ophthalmopathy.\n\n【52】The importance of the pretreatment serum T <sub>3 </sub> concentration is further demonstrated in Table 5 , which shows that a concentration of ≥5 nmol per liter was associated with an increased risk of the development or worsening of ophthalmopathy. Among the patients treated with iodine-131, the risk increased from 10 percent (2 of 20 patients) to 58 percent (11 of 19 patients). Among all the other patients the corresponding increase was from 2 percent (1 of 57 patients) to 22 percent (16 of 72 patients).\n\n【53】There was a positive correlation between the pretreatment serum concentrations of T <sub>3 </sub> and thyrotropin-receptor antibodies, but in the regression analyses the level of thyrotropin-receptor antibodies was not a significant determinant of ophthalmopathy.\n\n【54】Discussion\n----------\n\n【55】There is no entirely satisfactory classification of the ocular changes in Graves' disease. The original classification of the American Thyroid Association  has been modified several times,  <sup>, </sup>  and several ophthalmopathy indexes have been constructed to allow a quantitative evaluation of ophthalmopathy.  <sup><a>15 </a></sup>  <sup><a>17 </a></sup> In this study we quantified the ocular changes using an index derived by summing the scores for each of four of the components of ophthalmopathy,  and all evaluations were performed by one ophthalmologist. This type of index gives the same weight to the different components of ophthalmopathy, but the magnitude of the score does not necessarily correlate with the extent of subjective symptoms in an individual patient.\n\n【56】We included patients in our study regardless of the presence or absence of Graves' ophthalmopathy. During follow-up, relatively more patients (22) had new ophthalmopathy than had worsening of preexisting ophthalmopathy (8). Thus, most patients had no ophthalmopathy initially and it did not develop in most during follow-up, whatever their antithyroid treatment.\n\n【57】The risk of the development or worsening of ophthalmopathy was greater with increasing pretreatment serum T <sub>3 </sub> concentrations. The serum total thyroxine concentration did not have the same predictive value, although it was significant in some analyses that did not include serum T <sub>3 </sub> ; the serum free thyroxine concentration had no predictive value. It is unlikely that T <sub>3 </sub> itself induces or aggravates ophthalmopathy; it has no effect on the synthesis of hyaluronate by orbital fibroblasts in vitro.  It is more likely that high serum T <sub>3 </sub> concentrations indicate the presence of severe metabolic or immunologic disturbances that predispose a patient to Graves' ophthalmopathy.\n\n【58】The method of treatment also influenced the course of the eye changes. The risk of the development or worsening of ophthalmopathy was significantly greater for a patient with a high serum T <sub>3 </sub> concentration who was treated with iodine-131 than for a patient treated with methimazole or surgery. The reason for this relation is unknown. It has been suggested that post-treatment hypothyroidism is important in the development of ophthalmopathy.  None of the patients treated with methimazole or surgery had post-treatment hypothyroidism, however, because all were treated with thyroxine soon after surgery or the initiation of methimazole therapy. On the other hand, in the iodine-131 group biochemical hypothyroidism was allowed to develop before thyroxine therapy was initiated. A possible relation between the development of hypothyroidism after treatment and ophthalmopathy thus cannot be ruled out, but such a correlation was not found (data not shown).\n\n【59】The patients given methimazole received a relatively high daily dose of the drug throughout the 18-month treatment period, with thyroxine added soon after the start of therapy to prevent iatrogenic hypothyroidism. We and others  have used this combination routinely for several decades; it is safe and convenient and requires a minimum of follow-up visits during treatment. In addition, a high dose of methimazole may produce a higher rate of remission of hyperthyroidism than a low dose. \n\n【60】The presence or absence of lymphocytes in the thyroid was also predictive of the development or worsening of ophthalmopathy, the risk being lower if lymphocytes were present. None of the study patients had a history or any signs of thyroiditis, and all had an elevated 24-hour uptake of iodine-131 by the thyroid before treatment.\n\n【61】Many questions remain as to how patients with hyperthyroidism caused by Graves' disease should be treated. One concerns the influence of the severity of hyperthyroidism on the choice of therapy. We found that the risk of the development or worsening of ophthalmopathy increased from 10 to 58 percent among the older patients if their serum T <sub>3 </sub> concentrations before treatment were ≥5 nmol per liter and they were treated with iodine-131. For the other patients the corresponding increase was from 2 to 22 percent. In the patients with high serum T <sub>3 </sub> concentrations who were given methimazole, the risk of ophthalmopathy was lower, but there is a risk of relapse of hyperthyroidism in such patients after the drug is withdrawn.  <sup>, </sup>  Similarly, if patients are treated surgically, ophthalmopathy is not likely to develop or worsen, but this treatment has more risks than methimazole or iodine-131. Furthermore, the three treatments for hyperthyroidism can be carried out in a multitude of ways, and opinions about the treatment of choice vary, as surveys of physicians have shown.  <sup>, </sup>  In the final analysis, one must also consider the rates of relapse as well as the morbidity caused by the treatment.\n\n【62】It is possible that the risk of the development or worsening of ophthalmopathy can be reduced by modifying the iodine-131 therapy. For example, administering glucocorticoids before iodine-131 therapy may limit the progression of ophthalmopathy.  Pretreatment with an antithyroid drug or the administration of thyroxine soon after iodine-131 therapy might have the same effect.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 16:59:17", "endTime": "2024/08/13 17:00:22", "cost": 65.525}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 01:00:22", "grab_time": "2024-08-13 00:47:14"}
{"id": 2234309, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "ea164ebb-c50c-4269-affa-a1f49f1d369c", "title": "Vaccine-Associated Paralytic Poliomyelitis", "text": "【0】Vaccine-Associated Paralytic Poliomyelitis\nTo the Editor:\n--------------\n\n【1】Poliomyelitis was a major health problem in the United States until the introduction of inactivated poliovirus vaccine and attenuated oral poliovirus vaccine (OPV) in 1955 and 1961, respectively. Since 1963, trivalent OPV has been used routinely. Cases of vaccine-associated paralytic poliomyelitis have been described in recipients of this vaccine and contacts who were either immunodeficient or inadequately vaccinated  . We report a case of vaccine-associated paralytic poliomyelitis (the only 1 of 284 such cases reported to the Centers for Disease Control and Prevention \\[CDC\\] from 1961 through 1991) in an immunocompetent man who had received a three-dose primary series of OPV as a child.\n\n【2】Quadriplegia and apnea developed in a healthy 27-year-old man five weeks after his 3-month-old son received the first dose of trivalent OPV. Spinal magnetic resonance imaging revealed focal and symmetric high-signal abnormalities in the cervical anterior horns  . Poliovirus antibody-neutralization assays performed at the CDC showed elevated titers to both type 2 virus (> and type 3 virus  in serum; titers to type 1 virus were not detectable. Poliovirus type 3 was isolated from cerebrospinal fluid and characterized as vaccine-related by hybridization. Serologic tests for the human immunodeficiency virus were negative. Quantitative measurements of IgG, IgA, IgM, and IgE were normal. Medical records obtained from the man's pediatrician documented that the man had received doses of trivalent OPV at 5, 6, and 13 months of age.\n\n【3】Approximately eight people acquire poliomyelitis in the United States each year; virtually all these cases are vaccine-related  . The risk of vaccine-related poliomyelitis is 1 in 2.5 million doses of OPV distributed and is 10 times greater after the first dose than after all subsequent doses. The mean interval between vaccination and the onset of symptoms in contacts of the vaccine recipient is 31 days  . We are not aware of previous reports of vaccine-associated paralytic poliomyelitis in immunocompetent contacts who have received a three-dose primary series of trivalent OPV  . The risk is greatest in immunodeficient recipients of the vaccine and their contacts, especially those with hypogammaglobulinemia. Therefore, they should receive inactivated poliovirus vaccine  .\n\n【4】This exceptional case may have been due to primary vaccine failure (i.e., failure to seroconvert) resulting from the shorter-than-recommended interval between the first two doses of OPV or secondary failure (i.e., waning immunity). Thirty years of routine use, however, has shown OPV to be highly efficacious and safe. The threat of imported poliomyelitis from unvaccinated people in neighboring countries emphasizes the importance of vaccination as the only means of individual and community protection  .", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:23:29", "endTime": "2024/08/14 15:23:38", "cost": 9.326}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 23:23:38", "grab_time": "2024-08-13 23:23:28"}
{"id": 2234308, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "7f9cd8a4-eca2-4745-82fc-617326956650", "title": "Brief Report: Transfusions of Polymerized Bovine Hemoglobin in a Patient with Severe Autoimmune Hemolytic Anemia", "text": "【0】Brief Report: Transfusions of Polymerized Bovine Hemoglobin in a Patient with Severe Autoimmune Hemolytic Anemia\nIntroduction\n------------\n\n【1】Hemoglobin solutions have several potential advantages as substitutes for erythrocytes for transfusion. Hemoglobin solutions have a prolonged shelf life, are associated with a lower risk of transfusion reactions, and provide faster uptake of oxygen.  Hemoglobin-based oxygen carriers (HBOC) have been studied primarily in patients with hemorrhage, but the absence of cell-surface antigens in these solutions suggests that they may have a role in the treatment of autoimmune hemolytic anemias. We report the use of a polymerized bovine hemoglobin, HBOC-201 (Hemopure, Biopure, Cambridge, Mass.), in a woman with severe autoimmune hemolytic anemia.\n\n【2】Case Report\n-----------\n\n【3】Table 1. Hematologic Laboratory Findings.\n\n【4】A 21-year-old woman with a petechial rash and gingival bleeding (weight, 67 kg) was referred to our institution. Her medical, family, and social history was unremarkable, and her only medication was an oral contraceptive. Physical examination revealed multiple petechiae; no hepatosplenomegaly was noted. Table 1 shows the results of laboratory testing on admission. Bone marrow biopsy showed adequate cellularity, a predominance of erythroid cells, and a leftward shift in all cell counts. A presumptive diagnosis of idiopathic thrombocytopenic purpura was made. Treatment with prednisone was initiated at a dose of 1 mg per kilogram of body weight per day, with initial improvement in the platelet count to 83,000 per cubic millimeter.\n\n【5】Twelve days after her initial presentation, the patient was readmitted, reporting weakness, dyspnea, and fever (temperature, up to 39°C). Table 1 shows the results of laboratory testing at the time of readmission. Within 12 hours after readmission, the hematocrit had declined to 7.5 percent, and tachycardia, chest pressure, dyspnea, and electrocardiographic changes indicative of ischemia had developed. The symptoms and electrocardiographic changes resolved as the hematocrit rose to 12.4 percent (hemoglobin level, 4.2 g per deciliter \\[2.6 mmol per liter\\]) after the transfusion of 2 units of packed red cells. Methylprednisolone (pulses of 1 g per day) and intravenous immune globulin (total dose, 5 g per kilogram over a 10-day period) were administered, with transient improvement of the anemia.\n\n【6】Figure 1. Treatment before the Initiation of HBOC-201 Therapy.\n\n【7】Day 0 is the day of initial presentation. HBOC-201 therapy was initiated on day 75. Relative glucocorticoid potency indicates the daily antiinflammatory effect of glucocorticoid treatment relative to that of hydrocortisone (on a scale where 1 is equivalent to 1 mg of hydrocortisone); in this case it remained 5000 after 80 days.\n\n【8】Over the next 45 days, hemolysis increased, and the anemia was found to be refractory to treatment with high doses of glucocorticoids, plasmapheresis, splenectomy, and a second course of intravenous immune globulin . The peripheral blood smear showed marked spherocytosis and as many as 128 nucleated red cells per 100 white cells. The reticulocyte count peaked at 37 percent. Antibodies in the patient's serum reacted with erythrocytes from all available donors. To maintain a hematocrit greater than 12 percent and a hemoglobin level greater than 4.0 g per deciliter (2.5 mmol per liter), approximately the level previously associated with correction of the ischemic changes in the electrocardiogram, as many as 8 units of packed red cells per day were needed. The patient began to have fever, nausea, and back pain during the erythrocyte transfusions; these symptoms were attributed to acute hemolysis. At this time, therapy with cyclophosphamide (1000 mg per square meter of body-surface area) was begun.\n\n【9】Since conventional transfusions were ineffective, we obtained the patient's written informed consent to administer HBOC-201 as an alternative oxygen-carrying solution until the autoimmune hemolytic anemia abated. Additional approval for compassionate use of this product was obtained from our institutional review board, the U.S. Army Medical Command, and the Food and Drug Administration.\n\n【10】Methods\n-------\n\n【11】Table 2. Physical Properties of Polymerized Bovine Hemoglobin and Human Whole Blood.\n\n【12】HBOC-201 is a sterile solution of glutaraldehyde-polymerized bovine hemoglobin buffered in lactated Ringer's solution. Each unit contains 30 g of polymerized hemoglobin, equivalent to approximately half the hemoglobin contained in 1 unit of human packed red cells.  Table 2 lists the physical properties of HBOC-201. Since HBOC-201 is a solution, it does not contribute to the measured hematocrit. The level of hemoglobin resulting from the administration of HBOC-201 is estimated as the total hemoglobin level minus one third of the hematocrit.\n\n【13】We administered HBOC-201 if there was clinical evidence of end-organ ischemia (acidosis or base excess) or hemodynamic decline or if the whole-blood hemoglobin level decreased to 4 g per deciliter or less. The first unit was administered at a rate of 0.25 g per minute to assess tolerance. Subsequent units were administered at 0.50 g per minute, a rate previously tolerated by patients with sickle cell disease.  The toxicity of HBOC-201 was assessed by monitoring the patient's vital signs, the results of laboratory tests, and symptoms. Certain laboratory tests were not performed, because HBOC-201 interferes with the colorimetric assays on which those tests are based  . Hemodynamic monitoring included measurements of blood pressure by radial-artery catheter and, during periods of hypotension, measurements of cardiac output, central venous pressure, and pulmonary-artery pressure with use of a thermodilution pulmonary-artery catheter. Urine output was measured hourly.\n\n【14】Results\n-------\n\n【15】Figure 2. Hematocrit, Hemoglobin Levels, and Calculated HBOC-201 Levels during HBOC-201 Therapy.\n\n【16】Hour 0 indicates the initiation of HBOC-201 therapy. Each small arrow indicates the transfusion of 1 unit of HBOC-201. To convert values for hemoglobin and HBOC-201 to millimoles per liter, multiply by 0.6206.\n\n【17】A total of 11 units of HBOC-201 (330 g \\[4.9 g per kilogram\\]) were administered as one 90-g, two 60-g, and four 30-g doses over a seven-day period. A peak plasma HBOC-201 level of 3.36 g per deciliter (2.1 mmol per liter) was attained after the administration of the ninth unit. No adverse effects attributable to HBOC-201 were identified. Five units were administered in response to clinical evidence of ischemia (units 1, 2, 7, 10, and 11), three as part of volume resuscitation during an episode of septic shock (units 4, 5, and 6), and three (units 3, 8, and 9) to maintain the total hemoglobin level above 4 g per deciliter. The average total hemoglobin level during the course of HBOC-201 therapy was 5.5 g per deciliter (3.4 mmol per liter), with a corresponding average hematocrit of 9.5 percent. In some instances the hemoglobin level and the hematocrit were nearly equal , suggesting that most of the oxygen-carrying capacity of the blood was attributable to soluble hemoglobin.\n\n【18】Relief of Ischemia\n------------------\n\n【19】The initial 60-g dose of HBOC-201 (units 1 and 2) was administered in response to accelerated hemolysis, 75 days after the patient's initial presentation. The hematocrit had fallen from 22 percent to 13.8 percent over the course of 36 hours, with resultant tachycardia (heart rate, 130 beats per minute) and elevation of the serum lactic acid level to 2.2 mmol per liter. During this four-hour HBOC-201 infusion, the hematocrit declined further, to 6.4 percent, and the total hemoglobin level fell to 3.7 g per deciliter (2.3 mmol per liter), of which approximately 1.6 g per deciliter (1.0 mmol per liter) was HBOC-201. Despite this, the patient's heart rate decreased to 70 beats per minute and subsequently ranged between 70 and 90 beats per minute, she remained hemodynamically stable, and there was no electrocardiographic evidence of ischemia.\n\n【20】Units 4, 5, and 6 of HBOC-201 were administered 48 hours after the initial dose as part of volume expansion for profound hypotension (mean arterial pressure, 40 mm Hg) during an episode of neutropenic septic shock. A norepinephrine infusion was also begun. Unit 7 was administered 16 hours later in response to a drop in the arterial pH from 7.45 to 7.22, with an accompanying decrease in base excess from –5.1 to –17.8 mmol per liter. Improvement in the pH to 7.31 and in the base excess to –13.2 mmol per liter occurred within 10 minutes after the HBOC-201 infusion was started, with subsequent improvement in the pH to 7.37 and in the base excess to –11.8 mmol per liter during the first hour. There was no change in the rate of norepinephrine infusion during this interval.\n\n【21】Unit 10 of HBOC-201 was administered on day 6 after the initial dose in response to declines in the arterial pH from 7.35 to 7.20 and in base excess from –8.2 to –10.8 mmol per liter over a six-hour period. Increases in the arterial pH to 7.34 and in base excess to –9.2 were noted over the course of the one-hour infusion.\n\n【22】Figure 3. Representative Portions of Recordings from Electrocardiographic Leads V <sub>3 </sub> , V <sub>4 </sub> , and V <sub>5 </sub> before and during HBOC-201 Therapy.\n\n【23】The left-hand panels show recordings from leads V <sub>3 </sub> , V <sub>4 </sub> , and V <sub>5 </sub> of the patient's electrocardiogram while her hematocrit was 7.5 percent before HBOC-201 therapy. The right-hand panels show recordings from these electrocardiographic leads while her hematocrit was 4.4 percent with a calculated HBOC-201 level of 2.03 g per deciliter (1.3 mmol per liter).\n\n【24】The last unit of HBOC-201 was administered the next day in response to a stable base excess of –3.7 mmol per liter, with improvement noted to 1.0 mmol per liter within the first hour of the infusion. The minimal hematocrit supported during HBOC-201 therapy was 4.4 percent (total hemoglobin level, 3.5 g per deciliter \\[2.2 mmol per liter\\], of which 2.03 g per deciliter \\[1.3 mmol per liter\\] was HBOC-201), measured on the second day after the start of therapy. An electrocardiogram obtained at this time showed no important abnormalities .\n\n【25】Hemodynamic Response\n--------------------\n\n【26】Hemoglobin-based solutions have been reported to raise both systemic and pulmonary arterial pressures.  In this patient, there was no immediate pressor effect, although there was an overall trend toward higher blood pressures at the end of therapy. The patient's average mean arterial pressure during the five days before the initiation of HBOC-201 therapy was 93.6 mm Hg, and the average during the five days after the completion of therapy was 119.7 mm Hg. The average mean arterial pressure during the course of HBOC-201 therapy was 104.7 mm Hg, when values measured during volume expansion in response to septic shock are excluded. The mean arterial pressure did not change during or immediately after the administration of any of the units of HBOC-201. Invasive hemodynamic monitoring showed an initial decrease in the cardiac index during the period of septic shock; this index later improved in parallel with the improvement in mean arterial pressure as the shock resolved. Pulmonary arterial systolic and diastolic pressures increased only slightly with HBOC-201 therapy.\n\n【27】Clinical Outcome\n----------------\n\n【28】While receiving HBOC-201 during the period of profound neutropenia (absolute neutrophil count, 78 per cubic millimeter) caused by cyclophosphamide, the patient had gram-negative septic shock and, later, gram-negative pelvic osteomyelitis. Treatment required two surgical débridements of the right anterior ilium and long-term administration of antibiotics. Although the cyclophosphamide induced a brief remission in hemolysis in the patient, further treatment with this drug was not attempted, because of the complications. A second trial of plasmapheresis and intravenous immune globulin again failed to induce a sustained response, so immunosuppressive therapy with cyclosporine was initiated. There was a sustained response to cyclosporine, with no further need for transfusions. The patient was discharged to her home in good condition 100 days after the completion of HBOC-201 therapy. Eight months after discharge, the patient remained well, with a hematocrit consistently greater than 35 percent.\n\n【29】Discussion\n----------\n\n【30】Interest in the development of a safe, effective substitute for human erythrocytes as a transfusible medium for oxygen transport has increased substantially in the past decade. A number of products are under investigation.  Polymerized forms of bovine hemoglobin, such as HBOC-201, show particular promise. They have a molecular structure similar to that of human hemoglobin but have lower concentrations of organic phosphates, resulting in more pronounced oxygen unloading in ischemic tissue (the acid Bohr effect) and increased hemoglobin binding of carbon dioxide in the deoxygenated state (the Haldane effect).  The affinity of bovine hemoglobin for oxygen is also partially regulated by serum chloride ions, whereas the affinity of human hemoglobin for oxygen is influenced by 2,3-diphosphoglycerate.  These features result in excellent oxygen-transport properties.\n\n【31】Bovine hemoglobin has been shown to maintain tissue oxygenation  and to permit survival for more than one month with hematocrits as low as 2.4 percent in an ovine model.  HBOC-201 has been found to be safe and well tolerated in normal adults  and in patients with sickle cell disease  and has been studied in patients undergoing elective abdominal aortic surgery.  To our knowledge, this is the first report of the use of HBOC-201 to support oxygen delivery in a patient with severe autoimmune hemolytic anemia. Our patient received a larger dose (330 g) of HBOC-201 than previously administered to a human subject and also attained a higher plasma HBOC-201 level (3.36 g per deciliter) than any reported previously.\n\n【32】A vasoconstrictive response manifested by elevations in systemic and pulmonary arterial pressures typically occurs with the administration of hemoglobin-based solutions, an effect that has been attributed to the binding of nitric oxide by the hemoglobin moiety. This response is associated with a decreased cardiac output and, in several studies, has been associated with impaired oxygen delivery.  We did not perform invasive hemodynamic monitoring at the time therapy was initiated, but we did not observe a substantial vasoconstrictive response to HBOC-201. The absence of a hypertensive response has likewise been noted with administration of HBOC-201 to patients with sickle cell disease.  In addition, concurrent sepsis may have blunted any hypertensive effect, as has been demonstrated in an ovine model,  or higher doses of HBOC-201 may cause less vasoconstriction, as has been observed in patients undergoing abdominal aortic surgery.  In addition, the cardiac index, once measured, varied in parallel with rather than inversely with the mean arterial pressure, and metabolic acidosis as a reflection of ischemia improved predictably with the administration of HBOC-201.\n\n【33】Our patient had an episode of life-threatening gram-negative sepsis during HBOC-201 therapy and had profound ill effects from gram-negative osteomyelitis. It has been speculated that cell-free hemoglobin substances may support bacterial virulence by offering a ready supply of iron, thus sustaining bacterial replication and inhibiting neutrophil function.  There is additional evidence that increased hemolysis itself increases the risk of infection.  It is unclear what role, if any, HBOC-201 may have had in promoting our patient's infectious complications, given her neutropenia and preexisting hemolytic anemia.\n\n【34】In summary, the use of HBOC-201 as an alternative medium for oxygen delivery appears to have been a lifesaving intervention in a patient with refractory autoimmune hemolytic anemia. HBOC-201 supported the patient at a hematocrit of 4.4 percent without immediate or long-term evidence of ischemic injury. The absence of cell-surface antigens in HBOC-201 may make it a useful agent to support oxygen delivery in patients with severe autoimmune hemolytic anemia.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 18:37:19", "endTime": "2024/08/13 18:37:46", "cost": 27.368}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 02:37:47", "grab_time": "2024-08-13 02:37:19"}
{"id": 2234307, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "d4ff4700-fd60-404f-9c6f-e75678dd6eb4", "title": "Case 6-2019: A 29-Year-Old Woman with Nausea, Vomiting, and Diarrhea", "text": "【0】Case 6-2019: A 29-Year-Old Woman with Nausea, Vomiting, and Diarrhea\nPresentation of Case\n--------------------\n\n【1】_Dr. John A. Weems_ (Medicine): A 29-year-old woman was evaluated at a primary care clinic affiliated with this hospital because of nausea, vomiting, and diarrhea.\n\n【2】The patient had been in her usual state of good health until the day before presentation, when nausea, vomiting, diarrhea, fever, muscle aches, and a mild nonproductive cough developed suddenly. She had no sinus congestion, sore throat, shortness of breath, or abdominal pain. Over the telephone on the morning before presentation, she reported that her symptoms were severe and had prevented her from attending work. However, when she was evaluated later in the day by a provider at her primary care clinic, she reported that she had had spontaneous improvement in the morning and felt well on arrival at the clinic.\n\n【3】The patient had a history of exercise-induced asthma, gastroesophageal reflux disease, vitiligo, and genital warts. Two years before presentation, she had had negative screening tests for hepatitis C virus and human immunodeficiency virus. Fifteen months before presentation, she had received a diagnosis of influenza. During the months that followed, she had reported persistent bouts of fatigue and excessive sleepiness that had resulted in two motor vehicle accidents.\n\n【4】During the first event, which had occurred 13 months before presentation, the patient fell asleep while driving and her car crossed into the other lane, over the curb, and into an open space beside the road. She did not collide with any other vehicles or structures and had no trauma. During the second event, which had occurred 7 months before presentation, the patient collided with a turning vehicle. She did not lose consciousness, and the airbags did not deploy. After the crash, she had intermittent painful episodes of muscle spasms in her neck and low back that limited her range of motion. She was too fatigued to seek medical attention until the day after the collision.\n\n【5】The patient subsequently underwent evaluation at her primary care clinic. Her score on the Epworth Sleepiness Scale was 20, with scores ranging from 0 (low-normal daytime sleepiness) to 24 (excessive daytime sleepiness). She was referred for a formal sleep study. In addition, she received prescriptions for naproxen and cyclobenzaprine and completed outpatient physical therapy, and her muscle spasms diminished.\n\n【6】The patient had not undergone any surgical procedures. Medications included omeprazole, varenicline, naproxen, and cyclobenzaprine. Hydrocodone–acetaminophen had caused nausea. The patient was adopted, and her family history was unknown. She lived in an urban neighborhood in New England with her daughter, brother, and sister. She worked two full-time jobs, as a school counselor and a bartender. She smoked one pack of cigarettes weekly and had done so for 17 years, and she reportedly drank two to three alcoholic beverages weekly.\n\n【7】On physical examination, the temperature was 36.8°C, the pulse 106 beats per minute, and the blood pressure 117/91 mm Hg. The weight was 63.5 kg, the height 170 cm, and the body-mass index (the weight in kilograms divided by the square of the height in meters) 21.9. The patient appeared to be well. She had no diaphoresis or rashes, needle marks, or scars. The pupils were equal and reactive, the mucous membranes were moist, and the abdomen was soft, with no tenderness on palpation. Results of liver-function tests were normal, and testing for urinary human chorionic gonadotropin was negative.\n\n【8】Just before the conclusion of the office visit, the patient reported a history of use of nonprescribed oxycodone–acetaminophen tablets and requested initiation of therapy with injectable intramuscular naltrexone. Urine toxicology screening was ordered, and oral naltrexone was prescribed. A follow-up visit was planned for 6 days later, but the patient did not complete the urine toxicology screening or return to the clinic for her scheduled follow-up. However, 2 months later, she requested a referral for psychotherapy because of increased symptoms of stress.\n\n【9】Four months after she requested the referral and 6 months after presentation, the patient was seen in the outpatient psychology clinic of this hospital, where additional history was obtained. She reported poor sleep, low energy, loss of interest in enjoyable activities, feelings of guilt, increased appetite, and a sensation that her legs were heavy and difficult to move. She also reported intermittent episodes of heightened energy, pressured speech, racing thoughts, and excessive spending. She had no history of hallucinations or thoughts of harming herself or others.\n\n【10】At the psychology clinic, the patient reported that she had begun to use illicit drugs — including marijuana, oral opioids, cocaine, and 3,4-methylenedioxymethamphetamine — when she was in middle school. She had continued to use multiple substances for 5 years but had abruptly discontinued when she became pregnant, at 19 years of age. She did not use illicit drugs for 8 years after the birth of her daughter but then resumed regular use of oral opioids 3 years before presentation, when she began to work at a bar where drugs were frequently available. Since then, she had used escalating amounts of oral oxycodone to satisfy increased cravings and prevent withdrawal symptoms.\n\n【11】The patient reported that she used 120 mg of oxycodone per day and spent approximately $3000 per month on oxycodone. She had missed work because of withdrawal symptoms, and she worried that she would lose custody of her daughter because of her drug use. She had never been hospitalized for opioid use or had an overdose. On several occasions, she had used nonprescribed buprenorphine, which had alleviated her withdrawal symptoms and cravings, but she had never tried buprenorphine treatment that had been prescribed by a health care provider. In addition, on several occasions, she had tried to initiate treatment with injectable intramuscular naltrexone but had been unable to abstain from opioid use long enough to receive the treatment. A plan was made for the patient to continue with outpatient cognitive behavioral therapy and mindfulness exercises, and a follow-up visit with her primary care physician was scheduled.\n\n【12】One month later, the patient was seen by her primary care physician. Oral-fluid toxicology screening was positive for oxycodone, buprenorphine, benzoylecgonine, and cocaine; testing of the saliva was negative for fentanyl. A diagnosis and management decisions were made.\n\n【13】Diagnosis and Management\n------------------------\n\n【14】Table 1. Diagnostic Criteria for Opioid Use Disorder.\n\n【15】_Dr. Alexander Y. Walley:_ I am aware of the diagnosis in this case. This 29-year-old woman presented to her primary care clinic after she had symptoms consistent with opioid withdrawal syndrome, which had spontaneously resolved in less than 1 day. At the end of the visit, she requested injectable intramuscular naltrexone, and she later described a history that fulfilled criteria for severe opioid use disorder .  The patient reportedly used approximately $100 worth of nonprescribed oxycodone per day and thus was at high risk for use of heroin and illicitly manufactured fentanyl, which are more potent, widely accessible, and less expensive. However, according to the history and results of urine toxicology screening, her opioid use disorder was limited to use of illicit oxycodone. Although the patient requested naltrexone treatment, she did not complete the urine toxicology screening or return to the clinic for 6 months. I suspect that the patient had some ambivalence about treatment, which is common among patients with substance use disorder. Despite any ambivalence, the high mortality associated with opioid use disorder makes it imperative to find an effective treatment for this patient.\n\n【16】Treatment for Opioid Use Disorder\n---------------------------------\n\n【17】First-line treatment for this patient would be one of the three medications approved by the Food and Drug Administration (FDA) for the treatment of opioid use disorder: naltrexone, methadone, or buprenorphine. These medications lead to longer retention in treatment and decreased opioid use and opioid cravings. In a meta-analysis, methadone and buprenorphine were strongly associated with decreased rates of overdose and death from any cause.  In choosing the best medication for this patient, it would be necessary to have an understanding of not only the treatment-program requirements for each medication but also the patient’s preferences and previous experience with these medications.\n\n【18】### _Naltrexone_\n\n【19】This patient indicated a preference for naltrexone (an opioid antagonist). Oral naltrexone is available in generic form and is administered once daily as a tablet. However, meta-analyses have shown that oral naltrexone is no more effective than placebo in lowering the rate of opioid use or increasing the rate of retention in treatment.  Injectable intramuscular naltrexone is administered every 28 days by a health care provider and is effective in reducing opioid cravings and illicit opioid use. Prescribing naltrexone does not require special training or licensing, although prescribing injectable intramuscular naltrexone often requires prior authorization from an insurance company or collaboration with a specialty pharmacy.\n\n【20】The initiation of either injectable or oral naltrexone treatment precipitates withdrawal symptoms if the patient has not abstained from opioid use for several days before initiation. Of course, abstinence also causes withdrawal symptoms, which are a potent driver of continued substance use. Achieving the abstinence that is necessary to initiate naltrexone therapy is a major challenge; this explains the patient’s unsuccessful attempts at treatment with naltrexone. If she again attempts to undergo treatment with naltrexone, how can she and her provider work together to increase the likelihood that she will continue to take the medication? Before the initiation of naltrexone treatment, the patient’s withdrawal symptoms should be treated either in an inpatient detoxification unit or at home on an outpatient basis, with comfort medications, social support, and close follow-up.\n\n【21】### _Methadone_\n\n【22】In contrast with naltrexone, methadone (a full opioid agonist) is not associated with a risk of precipitated withdrawal, so abstinence before the initiation of methadone treatment is not necessary. However, because methadone has a relatively long and unpredictable half-life, the treatment must be initiated carefully. An initial low dose and slow approach helps to ensure that the patient is not oversedated during the first several weeks. As a treatment for pain, methadone can be prescribed and dispensed in a manner similar to any other opioid pain medication, but as a treatment for opioid use disorder, methadone can be administered to patients outside the hospital only through an opioid treatment program that is licensed and regulated at the federal and state levels .\n\n【23】If this patient were hospitalized for a reason other than addiction, she could be treated with methadone for opioid withdrawal, and if on discharge from the hospital she were linked to an opioid treatment program, she could be treated with methadone for opioid use disorder.  Regulations for opioid treatment programs require patients to receive methadone daily at the clinic and to undergo weekly counseling, random toxicology testing, and medical and psychiatric assessment. Patients may earn “take home” doses after 60 days of documented abstinence and with perfect attendance of dosing and counseling appointments. Methadone treatment through an opioid treatment program is one potential option for this patient to consider.\n\n【24】### _Buprenorphine_\n\n【25】Buprenorphine (a partial opioid agonist) can precipitate withdrawal if the patient has not abstained from opioid use for several hours before the first dose and has not begun to have withdrawal symptoms. Like naltrexone, buprenorphine can be prescribed in any clinical setting, although to prescribe buprenorphine in an outpatient setting, a waiver must be obtained from the Drug Enforcement Agency after completion of additional training (8 hours for physicians and 24 hours for nurse practitioners and physician assistants). Buprenorphine is typically combined with naloxone in a sublingual or buccal formulation to reduce the potential for injection or diversion. A long-acting injectable buprenorphine formulation was approved by the FDA in 2018.\n\n【26】This patient had some experience with use of buprenorphine that had been obtained by illicit means. I would ask the patient whether she had any withdrawal symptoms, sedation, or dysphoria when she took buprenorphine; whether it was helpful in reducing her oxycodone use; and how well she functioned while she took it. If buprenorphine had worked well for her, then I would ask why she requested naltrexone rather than buprenorphine during her primary care visit. As agonist treatments, buprenorphine and methadone are often stigmatized as “trading one drug for another.” This stigma undermines the clear evidence from multiple clinical trials that buprenorphine and methadone therapies can break the addiction cycle of compulsive use.\n\n【27】Risk for Relapse\n----------------\n\n【28】Adherence to treatment is a major challenge for patients who receive any of these three medications. It is worth noting that patients who take methadone may have longer retention in treatment than those who take buprenorphine,  and patients who take buprenorphine have longer retention than those who take naltrexone.  In the first 4 weeks after discontinuation of these medications, there is a surge in overdose mortality,  which is driven by the high likelihood of relapse coupled with reduced tolerance. Before the initiation of naltrexone, methadone, or buprenorphine treatment in this patient, it would be crucial to explain to her that she is at very high risk for relapse and overdose if she discontinues the medication.\n\n【29】Regardless of the treatment that is chosen, this patient will need a strategy to reduce the risk of overdose in the event of relapse. Key elements of an overdose risk-reduction plan include use of opioids in the presence of others who are equipped with naloxone and can respond if overdose occurs; avoidance of additional sedative substances, such as benzodiazepines and alcohol; and administration of the opioid at the lowest possible dose and slowly to test its potency. In accordance with guidance from the Department of Health and Human Services, a naloxone rescue kit should be prescribed to this patient so that she can be prepared to respond to any overdose that she witnesses and can ensure that naloxone is available to anyone who is with her if she relapses. \n\n【30】Opportunities for Improving Care\n--------------------------------\n\n【31】This case shows several ways in which the care of patients with opioid use disorder can be improved. During the patient’s previous encounters with the health care system, there were missed opportunities to discuss and diagnose her opioid use disorder. Although the U.S. Preventive Services Task Force has found insufficient evidence to support universal screening for substance use disorder,  screening was warranted in this patient on the basis of her history, which included multiple risk factors for substance use disorder, such as tobacco use disorder, underlying mood disorder, fatigue and daytime drowsiness, and motor vehicle accidents. Although overdose has replaced motor vehicle crashes as the leading cause of injury-related death in the United States, this case reminds us that a substantial proportion of motor vehicle crashes involve the use of substances — most commonly alcohol but increasingly other substances, such as marijuana and opioids. \n\n【32】Effective screening can be accomplished with one question: “How many times in the past year have you used an illegal drug or used a prescription medication for nonmedical reasons?”  In this patient, the answer to this question, followed by further exploration of the frequency of her substance use and the quantity that she used each time as well as exploration of the consequences of her use, could have allowed her providers to address her substance use disorder at an earlier stage. When the patient requested medication for opioid use disorder, she most likely had already met criteria for this diagnosis. However, it is useful to review the diagnostic criteria with the patient to confirm the diagnosis and its severity . The criteria will continue to be useful for monitoring this patient. As her condition improves, the number of criteria she meets will decrease, indicating reduced severity.\n\n【33】Next Steps\n----------\n\n【34】This patient has at least two promising prognostic characteristics. First, she is seeking treatment and has sought treatment in the past. It is normal for patients with substance use disorder to have multiple episodes of attempted treatment and relapse, but over time, the relapse periods should shorten and the remission periods should lengthen. Second, she abstained from drug use for years after the birth of her daughter, which is a sign that she may be able to abstain in the future.\n\n【35】The patient is receiving care from primary care and mental health care providers. Who would best treat her opioid use disorder? Does she need specialty treatment? If she and her providers decide that methadone is the best option, then she will need to enroll in an opioid treatment program, which is typically separate from primary care and mental health care. If they choose naltrexone or buprenorphine, either treatment can be delivered effectively in the primary care or community mental health care setting. The patient should receive care in the setting in which she is least likely to discontinue treatment, thus minimizing her risk of relapse and overdose.\n\n【36】Dr. Alexander Y. Walley’s Diagnosis\n-----------------------------------\n\n【37】Severe opioid use disorder.\n\n【38】Pathological Discussion\n-----------------------\n\n【39】_Dr. George Eng:_ In this patient, liquid chromatography–mass spectrometry of oral fluid was positive for oxycodone, buprenorphine, benzoylecgonine, and cocaine. Urine is a more commonly tested specimen type than oral fluid, since it can easily be obtained noninvasively, with the additional benefit that drugs of interest or their metabolites are often concentrated in it. However, urine testing for drugs of abuse is potentially complicated by deliberate manipulation of the specimen; adulteration, substitution, and dilution can all affect drug detection. Although an abnormal creatinine level, pH, or osmolality can suggest specimen manipulation, these measures are not entirely sensitive or specific. \n\n【40】In addition, enzyme immunoassays of urine specimens are associated with substantial rates of false positive results. The nonspecificity of enzyme immunoassays can lead to interpretive difficulties when there is a need to distinguish between an opiate-containing treatment regimen and illicit opioid use. Thus, many laboratories use a two-step testing algorithm that consists of initial screening with enzyme immunoassays followed by confirmation with liquid chromatography–mass spectrometry. \n\n【41】The use of oral fluid for drug testing is also a noninvasive technique and may mitigate the potential for specimen manipulation, since collection of the specimen is observed directly. Testing of oral fluid may be particularly useful in clinical practices in which the prevalence of specimen adulteration is high.  Such testing requires a higher degree of technical sophistication, may result in a longer turnaround time, and may not be widely available in local practice settings, but it is offered at reference laboratories.\n\n【42】In this patient, the results of oral-fluid testing confirmed her report of oxycodone use and further revealed evidence of nonprescribed buprenorphine use. In addition, there was evidence of recent cocaine use, including detection of the parent molecule cocaine and the metabolite benzoylecgonine. There was no detection of 6-monoacetylmorphine, a unique metabolite of heroin, or fentanyl, a common heroin adulterant; together, these findings suggest that she was not using heroin.\n\n【43】Follow-up\n---------\n\n【44】_Dr. Sarah E. Wakeman:_ When the patient presented to her primary care clinic for a follow-up visit, she described her history of opioid use and again requested injectable intramuscular naltrexone. In further discussion, it became clear that she preferred naltrexone because of the stigma related to buprenorphine, which she had heard from friends in recovery and observed in meetings of mutual-help organizations.  Despite her initial preference for naltrexone, after she considered her unsuccessful previous attempts to use naltrexone and her successful experience with nonprescribed buprenorphine, she agreed to initiate buprenorphine treatment.\n\n【45】This patient’s history of nonprescribed buprenorphine use is consistent with studies that have shown that the three most commonly reported reasons for use of diverted (nonprescribed) buprenorphine are to prevent withdrawal, to maintain abstinence, and to wean off opioids.  In addition, the outcomes associated with prescribed buprenorphine treatment are better among those who report a history of nonprescribed buprenorphine use than among those who have never taken buprenorphine. \n\n【46】This patient was given instructions to start buprenorphine treatment at home, and close follow-up was arranged. Unobserved initiation of buprenorphine treatment, also called home induction, has been shown to be noninferior to in-office induction and offers more flexibility for patients and providers.  At the patient’s next visit, she was connected to a recovery coach, who offered ongoing peer support. Although there is limited research regarding the effectiveness of recovery coaches in primary care, a qualitative study showed that patients with substance use disorder perceive the coach to play an important role. \n\n【47】Because the patient had ongoing concerns about her ability to continue treatment with buprenorphine, she was initially hesitant to take doses of buprenorphine and naloxone of more than 8 mg and 2 mg, respectively. After initiation of treatment, her toxicology screenings were consistently negative for opioids but she continued to use cocaine intermittently. Eight months after initiation of treatment, she agreed to try increasing her doses of buprenorphine and naloxone to 12 mg and 3 mg, respectively, and her subsequent toxicology screens were negative for cocaine and all opioids. She is now in full, sustained remission. She is working full-time and parenting, and she continues to engage regularly with her medical team and recovery coach.\n\n【48】_A Physician:_ Would you comment on how you determine when to involve child protective services in situations in which a parent has substance use disorder?\n\n【49】_Dr. Wakeman:_ In Massachusetts, the criterion for mandatory reporting by a health care provider is having reasonable cause to believe that a child younger than 18 years of age is suffering from abuse or neglect. I apply this standard to my patients regardless of whether they have a substance use disorder. The parent’s use of substances does not necessarily mean that the child is suffering from abuse or neglect. If I become aware of a circumstance in which a child is suffering from abuse or neglect, then I will report my concern. If I think that it is necessary to report, I disclose to my patients that I am reporting and why, so that they are aware, although this is not required in Massachusetts.\n\n【50】_A Physician:_ At what point do you consider tapering treatment for opioid use disorder?\n\n【51】_Dr. Wakeman:_ The decision to taper treatment should be initiated by the patient and should be based on the clinical scenario. Tapering therapy at less than 1 year typically results in recurrence of active opioid use. One of the longest observational studies of buprenorphine for the treatment of prescription-opioid use disorder, in which patients were followed for up to 42 months, showed that, although many patients elected to taper off buprenorphine during the follow-up period, the strongest predictor of abstinence at 42 months was continued buprenorphine treatment. Long-term treatment with buprenorphine has powerful benefits.  However, if a patient feels strongly about trying to taper treatment and has had a stable condition for years, I suggest beginning a slow taper. If cravings develop, the dose should be increased again. I emphasize to patients that the goal is not to be off the medication but to have what they need to stay alive and healthy.\n\n【52】Final Diagnosis\n---------------\n\n【53】Oxycodone and cocaine use.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-14 00:20:28", "grab_time": "2024-08-13 23:27:13"}
{"id": 2234306, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "2fac4f0e-7048-4f87-a801-8f470d9e1cc7", "title": "Compliance among Pharmacies in California with a Prescription-Drug Discount Program for Medicare Beneficiaries", "text": "【0】Compliance among Pharmacies in California with a Prescription-Drug Discount Program for Medicare Beneficiaries\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Several states have developed prescription-drug discount programs for Medicare beneficiaries. In California, Senate Bill 393, enacted in 1999, requires pharmacies participating in the state Medicaid program (Medi-Cal) to charge customers who present a Medicare card amounts based on Medi-Cal rates. Because Medicare beneficiaries may not be accustomed to presenting their Medicare cards at pharmacies, we assessed the compliance of pharmacies with Senate Bill 393.\n\n【3】Methods\n-------\n\n【4】Fifteen Medicare beneficiaries who received special training and acted as “standardized patients” visited a random sample of pharmacies in the San Francisco Bay area and Los Angeles County in April and May 2001. According to a script, they asked for the prices of three commonly prescribed drugs: rofecoxib, sertraline, and atorvastatin. The script enabled us to determine whether and when, during their interactions with pharmacists or salespeople, the discounts specified in Senate Bill 393 were offered. Pharmacies at which the appropriate discounts were offered were considered compliant.\n\n【5】Results\n-------\n\n【6】The patients completed visits to 494 pharmacies. Seventy-five percent of the pharmacies complied with the prescription-drug discount program; at only 45 percent, however, was the discount offered before it was specifically requested. The discount was offered at 91 percent of pharmacies that were part of a chain, as compared with 58 percent of independent pharmacies (P<0.001). Compliance was higher in the San Francisco Bay area than in Los Angeles County (84 percent vs. 72 percent, P=0.004) and was higher in high-income than low-income neighborhoods (81 percent vs. 69 percent, P=0.002). A Medicare beneficiary taking all three drugs would have saved an average of $55.70 per month as compared with retail prices (a savings of 20 percent).\n\n【7】Conclusions\n-----------\n\n【8】Discounts required under California's prescription-drug discount program for Medicare beneficiaries offer substantial savings. Many patients, however, especially those who use independent pharmacies or who live in low-income neighborhoods, may not receive the discounts.\n\n【9】Introduction\n------------\n\n【10】Expenditures for drugs have grown in parallel with their increasing importance in treating and preventing disease.  In 1998, prescription-drug spending in the United States was estimated to be $91 billion, more than twice the amount spent in 1990.  Elderly Medicare beneficiaries are particularly vulnerable to the high costs of prescription drugs and to the adverse health consequences of missed drug treatments. Thirty-five percent of people over the age of 65 years have three or more chronic conditions; people over 65 account for 34 percent of pharmaceutical expenditures  but make up 13 percent of the population.  However, one third of Medicare beneficiaries have no prescription-drug coverage,  and many of those who do have intermittent coverage.  Medicare beneficiaries who lack prescription-drug coverage, especially those with low incomes, use fewer drugs and have higher out-of-pocket costs than covered beneficiaries. \n\n【11】The federal government is examining ways to make prescription drugs more affordable for Medicare beneficiaries. However, many states have already developed pharmaceutical-assistance programs for persons over the age of 65. Four states (California, Florida, Maine, and Vermont  ) have passed laws to provide Medicare beneficiaries with discounted prescription-drug prices based on prices in the Medicaid program. Eighteen states introduced bills in 2001 that would establish similar policies. \n\n【12】California Senate Bill 393 was enacted in 1999. This law, which applies to all participating pharmacies in the California Medicaid program (Medi-Cal), states that “the pharmacy, upon presentation of a valid prescription for the patient and the patient's Medicare card, shall charge Medicare beneficiaries a price that does not exceed the Medi-Cal reimbursement rate for prescription medicines, and an amount, as set by the California Department of Health Services, to cover electronic transmission charges.”  The California Department of Health Services sent three notices and a Medi-Cal bulletin alerting pharmacies to the enactment of this law, and the sponsoring legislator conducted press conferences about it.\n\n【13】However, the law may not be fully achieving its goal. Because Medicare itself does not cover the cost of prescription drugs, Medicare beneficiaries may be unaccustomed to presenting Medicare cards to pharmacies. The new law included no provisions for educating beneficiaries or monitoring the compliance of pharmacies. This study assessed the compliance of pharmacies with California Senate Bill 393.\n\n【14】Methods\n-------\n\n【15】We trained a group of volunteers, all Medicare beneficiaries, to represent “standardized patients”  and visit a sample of pharmacies participating in the Medi-Cal program in April and May 2001. As standardized patients, they would follow a consistent script that enabled us to determine whether and when, during their interactions with pharmacists or salespeople, the discounts required by Senate Bill 393 were offered. The study protocol was approved by the RAND institutional review board.\n\n【16】Pharmacies\n----------\n\n【17】We obtained a list of all the licensed pharmacies in Los Angeles County and in the San Francisco Bay area counties of Alameda, Contra Costa, Marin, San Francisco, Sonoma, and San Mateo from the Board of Pharmacy of the California Department of Consumer Affairs. We contacted each pharmacy by telephone to determine whether it was independent or part of a chain (defined as three or more outlets with common ownership) and whether it participated in the Medi-Cal program. We used the 2001 Claritas Demographic Update  as a source of data on per capita income and population data according to age, sex, race, and Hispanic or non-Hispanic ethnic background for calendar year 2000 within each ZIP Code in the study counties.\n\n【18】Of the 1689 retail pharmacies that participated in Medi-Cal, we excluded 42 that were located in remote areas of Los Angeles County (those in ZIP Codes 90265, 91350, 91354, 91355, 91381, 91384, 93534, 93535, 93536, 93550, 93551, and 93552) and grouped the remaining 1647 pharmacies into eight strata according to region (Los Angeles County vs. Bay area), type of store (chain vs. independent), and income level (high vs. low) within the neighborhood of the pharmacy, defined according to ZIP Code. We used the population-weighted median income in all the ZIP Codes in the study counties ($21,989) as a cutoff to categorize income levels as high or low.\n\n【19】We drew a stratified, random sample of 500 of the 1647 pharmacies, allocated among the eight strata in proportion to the size of each stratum. The sample size was chosen to provide 90 percent statistical power to detect a 15 percent difference in compliance with Senate Bill 393 between two equal groups of pharmacies.\n\n【20】Prescription Drugs\n------------------\n\n【21】We selected three brand-name prescription drugs used to treat chronic conditions that frequently affect older persons. The drugs, and their legislated Medi-Cal prices for a 30-day supply, were rofecoxib (Vioxx), $64.55; sertraline (Zoloft), $63.11; and atorvastatin (Lipitor), $90.79.  They are among the 50 drugs most requested by Medicare beneficiaries, according to pharmacy-price inquiries since Senate Bill 393 was enacted. \n\n【22】Collection of Data\n------------------\n\n【23】Forty-one Medicare beneficiaries with acting experience underwent a four-hour training session during which they learned a script to use when visiting pharmacies and learned to complete an encounter form after each visit. The scripted encounter was designed to ascertain whether the legally required discounts were offered when older customers initially asked for prices, when they asked for a “senior discount,” when they requested a “Medicare discount,” or not at all. When speaking to the pharmacist or salesperson at each pharmacy, the patient was to begin by saying, “Hi. I left my prescription at home. I just called home and found out what I need. While I'm here, I would like to know how much my medications would cost. Can you help me?” The patient then presented a list of the three study drugs and their doses. After obtaining the prices, the patients asked whether the pharmacy offered a “senior discount” and, if it did, what the discounted prices would be. Finally, the patient presented a Medicare card and asked for a “Medicare discount.”\n\n【24】Answers to common questions that might be asked of patients at a pharmacy were standardized. For example, in response to the question, “Do you have insurance?” the patient was to respond, “Yes, but it doesn't cover my pills.” If pressed for more information or asked directly about Medicare, he or she would respond, “I just have Medicare” and show a Medicare card. The patients were also trained to look for printed signs that indicated the availability of “senior” or “Medicare” discounts.\n\n【25】The training sessions concluded with a test in which two of the investigators acted out five different scenarios. Fifteen of the volunteers (11 men and 4 women) who had previously demonstrated that they knew the script and its variants and who accurately filled out the encounter forms for all five of these scenarios were hired to act as patients and were assigned a set of pharmacies. Once the patients were in the field, the principal investigator reviewed the encounter forms daily for purposes of quality control.\n\n【26】Statistical Analysis\n--------------------\n\n【27】The principal investigator and one additional investigator reviewed all the encounter forms to assess whether and when each pharmacy had offered the required discount. Pharmacies were considered to have complied with Senate Bill 393 if the pharmacist had quoted the Medi-Cal prices for the study drugs or if he or she had stated that a Medicare discount was offered but could not provide prices without “checking the computer” (i.e., checking the state's data base of Medi-Cal prices, a process that incurred a charge). Pharmacies were also considered to have complied with the law if at any point during the interaction the pharmacist quoted prices lower than the Medi-Cal prices. Conversely, if the pharmacist claimed that a Medicare discount was offered but quoted prices higher than the Medi-Cal prices, the pharmacy was considered noncompliant. The principal investigator and the additional investigator agreed on all but four of the encounter forms, which were then adjudicated by the entire project team.\n\n【28】We used chi-square tests  to assess the statistical significance of differences in compliance between pharmacies in Los Angeles County and those in the Bay area, pharmacies that were part of a chain and those that were independent, and pharmacies in high-income and low-income neighborhoods. We used multiple logistic-regression analysis  to assess the independent effects of region, type of pharmacy, and characteristics of the population in the neighborhood on compliance with the law. Adjusted odds ratios obtained from the logistic-regression analysis were converted to relative risks.  A P value of less than 0.05 (by two-tailed testing) was considered to indicate statistical significance. \n\n【29】Results\n-------\n\n【30】Table 1. Study Sample of 500 Pharmacies.\n\n【31】The distribution of the 500 study pharmacies among the eight sampling strata is shown in Table 1 . Of these 500 pharmacies, 3 were closed at the time of the visit, and 2 did not have the study drugs; one visit could not be completed. Thus, the 15 patients completed visits to 494 pharmacies. Table 1 also shows that overall, independent pharmacies were disproportionately located in low-income neighborhoods.\n\n【32】Compliance of Pharmacies\n------------------------\n\n【33】Of the 494 study pharmacies to which visits were completed, 372 (75 percent) offered the required discount. Of the pharmacists at these stores, 22 quoted Medi-Cal prices, 5 quoted prices lower than Medi-Cal prices, and 345 stated that the discounted prices were available but did not provide them, stating that they could not check the prices in the computer without a prescription or sale.\n\n【34】Of the 122 pharmacies where the discount was not offered, pharmacists at 86 stated that there was no Medicare discount; 24 said that their prices reflected the Medicare discount, when in fact their prices were higher than Medi-Cal prices; 8 said that their prices were lower than the Medicare-discount prices, when in fact their prices were higher; and 4 would not quote any prices. Only 71 of the 494 pharmacies (14 percent) had signs indicating the availability of a “senior” or “Medicare” discount, and at only 67 of these stores was the discount offered.\n\n【35】Table 2. Compliance of 494 Pharmacies with Senate Bill 393, According to Geographic Region, Type of Pharmacy, and Income Level of the Neighborhood.\n\n【36】As Table 2 shows, compliance with Senate Bill 393 was higher in the San Francisco Bay area than in Los Angeles County (84 percent vs. 72 percent, P=0.004); higher among pharmacies that were part of a chain than among independent pharmacies (91 percent vs. 58 percent, P<0.001); and higher among pharmacies located in high-income neighborhoods than pharmacies located in low-income neighborhoods (81 percent vs. 69 percent, P=0.002). At 11 of the noncompliant independent pharmacies, the pharmacist told the patient to go to a “big chain” store for discounts.\n\n【37】At only 45 percent of the pharmacies did pharmacists offer the mandated discount before being specifically asked about it. At these pharmacies the discount was offered either when the patient initially asked for prices (7 percent of the pharmacies) or when the patient asked for a senior discount (38 percent). At 30 percent of the pharmacies the discount was offered only after the patient presented a Medicare card and specifically asked for a Medicare discount.\n\n【38】Figure 1. Pharmacies' Compliance with Senate Bill 393 during Standardized Patients' Visits, According to Geographic Region, Type of Pharmacy, and Income Level of the Neighborhood.\n\n【39】The bars depict the percentages of pharmacies at which the required discount was offered when trained volunteers acting as patients initially asked for prices, asked for a “senior discount,” or (finally) asked for a “Medicare discount,” according to a script, or at which the discount was not offered at all. Compliance before the Medicare discount was specifically requested was higher among pharmacies in the San Francisco Bay area than among those in Los Angeles County (P<0.001 by the chi-square test), higher among chain-store pharmacies than among independent pharmacies (P<0.001), and higher among pharmacies in high-income neighborhoods than among those in low-income neighborhoods (P<0.001). Neighborhoods were defined according to ZIP Codes, and income level was defined according to a cutoff value of $21,989 (the population-weighted median income in the study regions).\n\n【40】As Figure 1 illustrates, pharmacists at 63 percent of the pharmacies in the San Francisco Bay area, as compared with 36 percent of the pharmacies in Los Angeles County, offered the Medicare discount before being specifically asked about it (P<0.001). Most strikingly, pharmacists at 67 percent of chain-store pharmacies actively offered the Medicare discount before being asked, as compared with pharmacists at 21 percent of independent pharmacies (P<0.001). Finally, the Medicare discount was actively offered at 52 percent of the pharmacies in high-income neighborhoods as compared with 36 percent of those in low-income neighborhoods (P<0.001).\n\n【41】According to multiple logistic-regression analysis, the type of pharmacy (chain or independent) was the only significant independent predictor of compliance with Senate Bill 393. Pharmacists at chain pharmacies were 1.58 times (95 percent confidence interval, 1.49 to 1.64) as likely as those at independent pharmacies to offer the discount (P<0.001). The geographic region (P=0.95), income level of the neighborhood (P=0.06), and proportions of blacks (P=0.39), Hispanics (P=0.57), and Asians or Pacific Islanders (P=0.71) in the neighborhood were not associated with compliance or noncompliance.\n\n【42】To test for differences among the patients in the responses they elicited while speaking with pharmacists and to test for possible confounding, we repeated the logistic-regression analysis after adding indicator variables for the identity of the actors representing standardized patients. The relative risk of compliance among chain pharmacies as compared with independent pharmacies remained unchanged, and the indicator variables were neither singly nor jointly associated with compliance or noncompliance (P=0.61 for the test of joint association).\n\n【43】Potential Savings to Medicare Beneficiaries\n-------------------------------------------\n\n【44】Table 3. Retail Prices of a 30-Day Supply of the Three Study Drugs, as Compared with the Medi-Cal Prices, at 459 Pharmacies.\n\n【45】We obtained retail prices for the three study drugs at 459 pharmacies . Under Senate Bill 393, Medicare beneficiaries who take all three drugs would save an average of $55.70 per month as compared with the mean retail prices (a savings of 20 percent). The total cost of a 30-day prescription for all three drugs at Medi-Cal prices was $218.45.\n\n【46】Discussion\n----------\n\n【47】We found that the prescription-drug discounts required under California Senate Bill 393 offer substantial potential savings to Medicare beneficiaries but that many beneficiaries may not receive these discounts. Pharmacists at one fourth of the pharmacies in our study failed to offer the mandated discounts, even after patients explicitly requested them.\n\n【48】The independent pharmacies in our study were much less likely than chain-store pharmacies to comply with Senate Bill 393. Independent pharmacists may be unaware of the law; however, multiple notifications about it were sent to all pharmacies by the California Department of Health Services, and at 11 independent pharmacies patients were referred to “big chain” stores — factors that suggest these pharmacists' awareness of the law. Alternatively, independent pharmacies, which do not benefit from economies of scale or from the sale of nonpharmaceutical merchandise, may find it more difficult than chain-store pharmacies to comply with Senate Bill 393. Because independent pharmacies are disproportionately located in low-income neighborhoods, the potential savings from discounts under Senate Bill 393 may be least likely to reach the people who need them the most.\n\n【49】At only 45 percent of the study pharmacies was the Medicare discount offered when patients initially requested prices or when they asked for a senior discount; at the remaining compliant pharmacies the required discount was not offered until it was specifically requested. Few pharmacies had signs advertising senior or Medicare discounts. These findings indicate that, in most cases, Medicare beneficiaries needed to know about Senate Bill 393 in order to take advantage of it. As was true with respect to overall compliance, there was a large discrepancy between chain-store and independent pharmacies with respect to pharmacists' readiness to offer the discounts.\n\n【50】Our study has several limitations. The patients did not present prescriptions at the pharmacies they visited. However, Title 16 of the California Code of Regulations  and California Business and Professions Code 4122 <sup><a>24 </a></sup> stipulate that pharmacies must provide prescription-drug prices when asked, whether or not the customer presents a prescription. The lack of a prescription may have suggested to the salesperson or pharmacist that the patient was shopping for the lowest prices, but that circumstance would probably increase the likelihood of the pharmacist's offering a discount. In addition, our data were collected from the two major metropolitan areas in California; pharmacies in other areas of the state may have different patterns of compliance with the bill.\n\n【51】California's experience with a prescription-drug discount program for Medicare beneficiaries has implications for the design of similar state programs and federal programs. Most important, such programs must include procedures to educate beneficiaries — for example, by mailing information directly to them and by requiring pharmacies to post signs advertising the discounts. Our data suggest that Medicare beneficiaries in California who are aware of Senate Bill 393 are much more likely to receive the legally mandated discounts than those who are not aware of it. Nonetheless, of the 18 states that introduced bills in 2001 providing prescription-drug discounts for Medicare beneficiaries,  only 8 states call for an outreach plan to educate consumers about the discounts. Requiring Medicare beneficiaries to enroll in the discount program and providing beneficiaries with special discount cards to present at pharmacies would probably reinforce their awareness of the program. Eight of the states that introduced bills establishing prescription-drug discounts in 2001 would issue such a discount card.\n\n【52】Finally, states should also consider developing procedures to monitor the compliance of pharmacies with prescription-drug discount laws. Many pharmacies in our study failed to comply with Senate Bill 393, even when patients specifically requested a Medicare discount. However, of the 18 states that introduced prescription-drug discount bills in 2001, only 2 required monitoring of compliance. Within political constraints, policy makers may wish to focus monitoring efforts on independent pharmacies.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 00:59:16", "grab_time": "2024-08-13 00:46:18"}
{"id": 2234305, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "ca852bcd-7a6f-4dfd-b8e4-9e485157a343", "title": "Epidemiology of Long-Term Survival with Acute Leukemia", "text": "【0】Epidemiology of Long-Term Survival with Acute Leukemia\nAbstract\n--------\n\n【1】To define factors distinguishing long-term from short-term survivors among children with acute leukemia, 59 who survived for at least five years were compared with 59 who survived for two years or less. The two groups were matched for age, sex, histology and time and physician of treatment. Seven traits characterized the patient with the highest likelihood of short-term survival. Short-term survivors differed from the long-term in having had a high initial white-cell count; their mothers were less likely to have had complications during their pregnancies with the subjects, were more likely to have had a history of disease, viral and other, in the five-year period before the subject's birth, were more likely to have had irradiation when pregnant with the subject, and were more apt to have been older at their first live birth; the subject was more likely to have been a product of a third or later pregnancy. Thus, of the characteristics examined, those relating to the mother's pregnancy and disease history appeared most cogent.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:49:41", "endTime": "2024/08/14 14:49:48", "cost": 7.173}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 22:49:48", "grab_time": "2024-08-13 22:49:40"}
{"id": 2234304, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "7eba7aa3-88be-4f3c-95e8-f7c40e45b99d", "title": "Studies on the Mechanism of Increased Plasma Triglyceride Levels Induced by Oral Contraceptives", "text": "【0】Studies on the Mechanism of Increased Plasma Triglyceride Levels Induced by Oral Contraceptives\nAbstract\n--------\n\n【1】Increases in plasma triglyceride levels were observed in normal young women treated for two weeks with an oral contraceptive containing ethinyl estradiol and medroxyprogesterone. The mechanism of this phenomenon may be related to an observed decrease in postheparin lipolytic activity and impaired plasma triglyceride removal. At the same time serum insulin levels increased, perhaps stimulating endogenous hepatic triglyceride synthesis and secretion into plasma.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:28:22", "endTime": "2024/08/14 15:29:42", "cost": 79.519}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:28", "update_time": "2024-08-13 23:29:42", "grab_time": "2024-08-13 23:28:22"}
{"id": 2234303, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "6c03ae3b-0b55-45da-b2cb-44e1dca908a0", "title": "Oxygen Toxicity in Man — A Prospective Study in Patients with Irreversible Brain Damage", "text": "【0】Oxygen Toxicity in Man — A Prospective Study in Patients with Irreversible Brain Damage\nAbstract\n--------\n\n【1】To investigate possible pulmonary oxygen toxicity in man, 10 patients who had suffered irreversible brain damage received ventilation with air (five patients) or pure oxygen (five patients) until death. Measurements of arterial-blood gases, cardiac output, intrapulmonary shunt, ratio of dead space to tidal volume and lung-thorax compliance were made periodically. At autopsy, gross condition and total weight of the lungs were noted. The oxygen group demonstrated significantly greater impairment of lung function than the air group. The most sensitive indicator of impaired lung function was a decrease in arterial oxygen tension during breathing of pure oxygen. After 30 hours' ventilation this value declined more sharply in the oxygen group than the air group. After 50 hours it averaged above 400 torr in the air group but only 120 torr in the oxygen group. Intrapulmonary shunt and ratio of dead space to tidal volume also became significantly greater in the oxygen group. Radiographic changes and total lung weight supported these physiologic findings. Microscopical examination of lung tissue failed to reveal noteworthy differences between the two groups.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:00:41", "endTime": "2024/08/14 15:01:24", "cost": 42.51}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 23:01:24", "grab_time": "2024-08-13 23:00:41"}
{"id": 2234302, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "c74acd5f-7c9f-4af7-97ed-a9ac1dec0d88", "title": "Ustekinumab as Induction and Maintenance Therapy for Ulcerative Colitis", "text": "【0】Ustekinumab as Induction and Maintenance Therapy for Ulcerative Colitis\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】The efficacy of ustekinumab, an antagonist of the p40 subunit of interleukin-12 and interleukin-23, as induction and maintenance therapy in patients with ulcerative colitis is unknown.\n\n【3】Methods\n-------\n\n【4】We evaluated ustekinumab as 8-week induction therapy and 44-week maintenance therapy in patients with moderate-to-severe ulcerative colitis. A total of 961 patients were randomly assigned to receive an intravenous induction dose of ustekinumab (either 130 mg \\[320 patients\\] or a weight-range–based dose that approximated 6 mg per kilogram of body weight \\[322\\]) or placebo (319). Patients who had a response to induction therapy 8 weeks after administration of intravenous ustekinumab were randomly assigned again to receive subcutaneous maintenance injections of 90 mg of ustekinumab (either every 12 weeks \\[172 patients\\] or every 8 weeks \\[176\\]) or placebo (175). The primary end point in the induction trial (week 8) and the maintenance trial (week 44) was clinical remission (defined as a total score of ≤2 on the Mayo scale \\[range, 0 to 12, with higher scores indicating more severe disease\\] and no subscore >1 \\[range, 0 to 3\\] on any of the four Mayo scale components).\n\n【5】Results\n-------\n\n【6】The percentage of patients who had clinical remission at week 8 among patients who received intravenous ustekinumab at a dose of 130 mg (15.6%) or 6 mg per kilogram (15.5%) was significantly higher than that among patients who received placebo (5.3%) (P<0.001 for both comparisons). Among patients who had a response to induction therapy with ustekinumab and underwent a second randomization, the percentage of patients who had clinical remission at week 44 was significantly higher among patients assigned to 90 mg of subcutaneous ustekinumab every 12 weeks (38.4%) or every 8 weeks (43.8%) than among those assigned to placebo (24.0%) (P=0.002 and P<0.001, respectively). The incidence of serious adverse events with ustekinumab was similar to that with placebo. Through 52 weeks of exposure, there were two deaths (one each from acute respiratory distress syndrome and hemorrhage from esophageal varices) and seven cases of cancer (one each of prostate, colon, renal papillary, and rectal cancer and three nonmelanoma skin cancers) among 825 patients who received ustekinumab and no deaths and one case of cancer (testicular cancer) among 319 patients who received placebo.\n\n【7】Conclusions\n-----------\n\n【8】Ustekinumab was more effective than placebo for inducing and maintaining remission in patients with moderate-to-severe ulcerative colitis. \n\n【9】Introduction\n------------\n\n【10】 VISUAL ABSTRACT  \nUstekinumab for Ulcerative Colitis\n\n【11】Ulcerative colitis is a chronic inflammatory disease of the large intestine.  Current therapies are limited by increased risks of infection  or cancer  or by loss of clinical benefit. \n\n【12】Ustekinumab (Stelara, Janssen Biotech) is a monoclonal antibody to the p40 subunit of interleukin-12 and interleukin-23 and has been approved for the treatment of psoriasis, psoriatic arthritis, and Crohn’s disease.  In a phase 3 program for the treatment of Crohn’s disease, ustekinumab induced a response at 8 weeks and maintained clinical benefit through 52 weeks of treatment in patients who had had treatment failure with or unacceptable side effects from corticosteroids, immunomodulators, or tumor necrosis factor (TNF) antagonists.  We conducted a phase 3 trial (UNIFI) of ustekinumab that involved patients with moderate-to-severe ulcerative colitis, using doses identical to those in the phase 3 program involving patients with Crohn’s disease.\n\n【13】Methods\n-------\n\n【14】Trial Design and Oversight\n--------------------------\n\n【15】The UNIFI trial included an 8-week randomized induction trial and a 44-week randomized-withdrawal maintenance trial (representing 52 weeks of treatment). Both were double-blind, placebo-controlled trials conducted from August 2015 through August 2018 under one protocol at 244 sites worldwide. Institutional review boards approved the protocol ; all patients provided written informed consent. A steering committee of academic investigators and Janssen scientists designed the trials, analyzed and interpreted the data, and contributed to the manuscript. The first author wrote the first draft of the manuscript; all authors vouch for the veracity and completeness of the data and for the fidelity of the trials to the protocol. Editorial support was provided by Janssen.\n\n【16】Patients\n--------\n\n【17】Adult patients (≥18 years of age) were eligible if they had received a diagnosis of ulcerative colitis at least 3 months before screening and had moderate-to-severe ulcerative colitis, defined as a total score of 6 to 12 on the Mayo scale (range, 0 to 12, with higher scores indicating more severe disease) and a subscore of 2 or 3 on the endoscopic component of the Mayo scale, as determined during central review of videoendoscopy.  Subscores on each of the four components of the Mayo scale range from 0 to 3. Eligible patients were required to have had an inadequate response to or unacceptable side effects from TNF antagonists, vedolizumab, or conventional (i.e., nonbiologic) therapy. \n\n【18】Stable doses of aminosalicylates and immunomodulators were maintained from baseline of induction therapy through week 44 of maintenance therapy. Oral corticosteroids were maintained at a stable dose during the induction trial and tapered when patients entered the maintenance trial.\n\n【19】Previous treatment with interleukin-12 or interleukin-23 antagonists was prohibited. Previous TNF antagonist therapy was discontinued at least 8 weeks before trial entry, and vedolizumab was discontinued at least 4 months before trial entry; other conventional therapies were discontinued at least 2 to 4 weeks before trial entry. Among the exclusion criteria were imminent colectomy, gastrointestinal conditions that would result in surgery or confound disease-activity assessment, cancer, and active infections (including tuberculosis).\n\n【20】Randomization\n-------------\n\n【21】At week 0 in the induction trial, patients were randomly assigned, in a :1 ratio, to receive a single intravenous infusion of 130 mg of ustekinumab, a weight-range–based dose that approximated 6 mg of ustekinumab per kilogram of body weight, or placebo. Randomization was performed with the use of permuted blocks, with stratification according to status with respect to previous treatment failure with biologic agents (yes or no) and geographic region (eastern Europe, Asia, or rest of world).\n\n【22】Figure 1. Overall Trial Flow.\n\n【23】In the induction trial, status with respect to response or nonresponse was determined by means of an interactive Web response system and by the subscore on the endoscopic component of the Mayo scale as assessed by the local endoscopist. The patients who had a response to intravenous ustekinumab (UST) at week 8, as well as those who did not have a response to intravenous placebo and who then received an induction dose of intravenous ustekinumab (6 mg per kilogram of body weight) at week 8 and had a response at week 16, made up the randomized primary analysis population in the maintenance trial. One patient who had a response to intravenous ustekinumab (6 mg per kilogram) at week 8 and three patients who had a response to intravenous placebo did not enter the maintenance trial. Patients who had a delayed response to induction therapy with ustekinumab (i.e., those who did not have a response to intravenous ustekinumab and who then received ustekinumab subcutaneously at week 8 and had a response at week 16) entered the maintenance trial but did not undergo randomization. Patients who had a response to intravenous placebo in the induction trial entered the maintenance trial but did not undergo randomization. Baseline (week 0) in the maintenance trial is the same as week 8 or week 16 in the induction trial, depending on when patients entered maintenance (week 8 or week 16). Patients who had a response to intravenous ustekinumab at week 8 in the induction trial and then completed the maintenance trial through week 44 had 52 weeks of overall exposure; patients who had a response to ustekinumab at week 16 in the induction trial could have up to 60 weeks of overall exposure. SFU denotes safety follow-up (lasting 20 weeks after the last dose of ustekinumab or placebo).\n\n【24】Patients who had a clinical response to intravenous ustekinumab at week 8 (defined as a decrease in the total Mayo score of ≥30% and of ≥3 points from baseline, with an accompanying decrease of ≥1 point on the rectal bleeding component of the Mayo scale or a rectal bleeding subscore of 0 or 1) entered the maintenance trial, as did those who did not have a response to intravenous placebo and who then received an induction dose of intravenous ustekinumab (6 mg per kilogram) at week 8 and had a response at week 16. At week 0 in the maintenance trial, patients were randomly assigned, in a :1 ratio, to receive subcutaneous injections of 90 mg of ustekinumab every 12 weeks, 90 mg of ustekinumab every 8 weeks, or placebo through week 40 . Randomization was performed with the use of permuted blocks, with stratification according to intravenous induction treatment (130 mg of ustekinumab, 6 mg of ustekinumab per kilogram, or placebo followed by 6 mg of ustekinumab per kilogram), status with respect to clinical remission (yes or no) at baseline in the maintenance trial, and oral corticosteroid use (yes or no). These patients comprised the randomized maintenance population (primary analysis population).\n\n【25】Patients who did not have a response to intravenous ustekinumab at week 8 received 90 mg of subcutaneous ustekinumab in a blinded manner and were reevaluated at week 16; those who had a response entered the maintenance trial and received 90 mg of subcutaneous ustekinumab every 8 weeks (i.e., patients with a delayed response to ustekinumab). Patients who had a response to intravenous placebo at week 8 received subcutaneous placebo; these patients and those who had a delayed response to ustekinumab comprised the nonrandomized maintenance population .\n\n【26】During maintenance therapy, patients were monitored for clinical flares. Endoscopy was performed to confirm loss of response. \n\n【27】Assessments and End Points\n--------------------------\n\n【28】The total Mayo score  and the score on the Inflammatory Bowel Disease Questionnaire (IBDQ, with scores ranging from 32 to 224 and higher scores indicating better quality of life)  were assessed at weeks 0, 8, and 16 (in patients who did not have a response to induction therapy at week 8) in the induction trial and at week 20 (IBDQ score only) and week 44 in the maintenance trial. The partial Mayo score (i.e., the total Mayo score excluding the endoscopic subscore, with scores ranging from 0 to 9 and higher scores indicating more severe disease) was evaluated at weeks 2 and 4 during induction and every 4 weeks during maintenance. Concentrations of fecal biomarkers (calprotectin and lactoferrin) and serum C-reactive protein (CRP) were evaluated at all visits during induction and at weeks 8, 24, and 44 during maintenance. Mucosal biopsy samples that were obtained from patients who underwent endoscopy at week 8 during induction and at week 44 during maintenance were assessed for histologic improvement.\n\n【29】The primary end point in the induction trial was clinical remission (defined as a total Mayo score of ≤2 and no subscore >1) at week 8. Major secondary end points at week 8 were endoscopic improvement (defined as a Mayo endoscopic subscore of 0 or 1), clinical response, and change from baseline in the IBDQ score. The IBDQ score was a major secondary end point included in the protocol but was not included as a prespecified major secondary end point in the statistical analysis plan submitted to the Food and Drug Administration (FDA). Histo-endoscopic mucosal healing (which required both histologic improvement \\[defined as neutrophil infiltration in <5% of crypts, no crypt destruction, and no erosions, ulcerations, or granulation tissue\\]  and endoscopic improvement) was an additional end point that was controlled for multiple comparisons at week 8. In the maintenance trial, the primary end point was clinical remission at week 44; major secondary end points were maintenance of clinical response through week 44, endoscopic improvement at week 44, corticosteroid-free clinical remission at week 44, and maintenance of clinical remission through week 44 among patients in clinical remission at baseline in the maintenance trial.\n\n【30】An alternative primary end point of clinical remission that excluded the subscore on the physician’s global assessment component of the Mayo scale was also prespecified to support the FDA submission. This definition required an absolute stool number of 3 or fewer (average daily stool number during 3 days before a visit), a Mayo rectal bleeding subscore of 0, and a Mayo endoscopic subscore of 0 or 1.\n\n【31】Histologic improvement, histo-endoscopic mucosal healing, and changes in the partial Mayo score, IBDQ score, serum CRP concentration, and concentrations of fecal biomarkers were assessed separately in the induction and maintenance trials. Safety follow-up assessment (concomitant medications, adverse events, serious adverse events, and ulcerative colitis–related hospitalizations and surgical procedures) occurred during the induction trial through week 8 or week 16 when patients entered the maintenance trial or 20 weeks after the final induction dose for those discontinuing the trial and during the maintenance trial through week 44 (i.e., 52 weeks of treatment).\n\n【32】Pharmacokinetics and Immunogenicity\n-----------------------------------\n\n【33】Serum ustekinumab concentrations were evaluated at all visits during induction and every 4 weeks during maintenance. Antidrug antibodies were evaluated by means of a drug-tolerant electrochemiluminescence assay at weeks 0, 4, 8, and 16 (in patients who did not have a response to induction therapy at week 8) during induction and at weeks 4, 12, 24, 36, and 44 during maintenance. The relationship between exposure and response was assessed on the basis of quartiles of serum ustekinumab concentration at week 8 during induction (for efficacy end points in the induction trial) and at week 24 during maintenance (for efficacy end points in the maintenance trial).\n\n【34】Statistical Analysis\n--------------------\n\n【35】The primary and major secondary end points in the induction trial (including histo-endoscopic mucosal healing) and the maintenance trial were controlled for multiple comparisons. The type I error rate in each trial was controlled at an alpha level of 0.05 over the end points that were controlled for multiple comparisons with the use of a prespecified multiple-testing procedure. A different prespecified multiple-testing procedure was used to support the FDA submission. (For details on multiple-testing procedures and prespecified subgroups, see the Supplementary Appendix .)\n\n【36】Dichotomous end points were compared between each ustekinumab group and the placebo group with the use of a two-sided, Cochran–Mantel–Haenszel chi-square test with adjustment for stratification variables. Continuous end points were analyzed by means of analysis of covariance or analysis of covariance on van der Waerden normal scores with adjustment for baseline value and stratification variables.\n\n【37】Analyses of other end points were not adjusted for multiple comparisons, and results are reported with 95% confidence intervals not adjusted for multiple comparisons, without P values; inferences drawn from these results may not be reproducible. \n\n【38】Unless otherwise specified, all efficacy analyses were based on the intention-to-treat principle. Data sets for the primary efficacy analyses comprise the patients who underwent randomization in the induction trial or maintenance trial. Prespecified efficacy analyses were also conducted for patients who entered the maintenance trial after having a delayed response to ustekinumab. To evaluate the consistency of the treatment effect for the primary end point, clinical remission was analyzed in prespecified subgroups.\n\n【39】Patients were considered not to have reached dichotomous end points if they had a prohibited change in concomitant medication for ulcerative colitis, had undergone an ostomy or colectomy before week 8 (during induction) or week 44 (during maintenance), had used a rescue medication after a clinical flare (during maintenance), or had discontinued ustekinumab or placebo owing to lack of efficacy or an adverse event of worsening disease during maintenance. For continuous end points, patients who had a treatment failure had their value at baseline in the induction trial carried forward from the time of the event onward (i.e., consistent with nonresponse for dichotomous end points).\n\n【40】For dichotomous end points, including all end points that were controlled for multiple comparisons, patients with missing data were considered not to have reached the end points. Prespecified sensitivity analyses including methods to account for missing data were conducted to test the robustness of the primary end point analyses for both definitions of clinical remission. (For more information on the handling of missing data, see the Supplementary Appendix .)\n\n【41】Assuming an incidence of clinical remission of 7% in the placebo group and 19% in each ustekinumab group, we calculated that 317 patients per induction group would provide more than 90% power for the primary end point at week 8 using a step-up Hochberg testing procedure at a two-sided alpha level of 0.05. This sample size would also provide enough patients for the primary population of the maintenance trial. Assuming an incidence of clinical remission of 20% in the group receiving placebo and 40% in the group receiving 90 mg of subcutaneous ustekinumab every 8 weeks, 109 patients per maintenance group would provide 90% power for the primary end point at week 44 at a two-sided significance level of 0.05 on the basis of the fixed-sequence testing procedure, starting with the high-dose ustekinumab group (every 8 weeks).\n\n【42】In the safety analyses, data for patients who received at least one dose of ustekinumab or placebo in the induction trial were analyzed according to the substance received, and data for patients who received at least one dose of ustekinumab or placebo in the maintenance trial were analyzed according to the assigned trial group. The frequency and types of adverse events were summarized. Immunogenicity analyses included patients who had at least one blood sample obtained after ustekinumab administration.\n\n【43】Results\n-------\n\n【44】Patients\n--------\n\n【45】Of 961 patients who underwent randomization, 912 (94.9%) completed the induction trial: 783 (81.5%) who entered the maintenance trial and 129 (13.4%) who did not enter the maintenance trial completed the final safety visit. In the maintenance trial, 523 patients underwent randomization (primary population) and 260 did not. Most patients (494 of 523, 94.5%) who underwent randomization in the maintenance trial completed the trial. \n\n【46】Table 1. Demographic and Clinical Characteristics at Baseline in the Induction Trial (Randomly Assigned Patients).\n\n【47】At baseline in the induction trial, patients were randomly assigned to receive a single intravenous infusion of placebo (319 patients), ustekinumab at a dose of 130 mg (320), or ustekinumab at a dose approximating 6 mg per kilogram (322). Patient characteristics were generally similar across trial groups in the induction and maintenance trials .\n\n【48】Among 51.1% of randomly assigned patients who had previous treatment failure with biologic agents (491 of 961), a total of 98.8% (485 of 491) had had treatment failure with at least one TNF antagonist, 32.6% (160 of 491) had had treatment failure with both a TNF antagonist and vedolizumab, and 1.2% (6 of 491) had had treatment failure with vedolizumab only. Among patients who did not have previous treatment failure with biologics, 94.3% (443 of 470) had not received biologics and 5.7% (27 of 470) had received biologics but did not have documented treatment failure .\n\n【49】Induction Therapy\n-----------------\n\n【50】Figure 2. Patients with Clinical Remission, Endoscopic Improvement, Clinical Response, or Histo-Endoscopic Mucosal Healing at Week 8 in the Induction Trial.\n\n【51】Weight-range–based doses of ustekinumab approximating 6 mg per kilogram were as follows: 260 mg (weight, ≤55 kg), 390 mg (weight, >55 kg and ≤85 kg), and 520 mg (weight, >85 kg). Patients who had a prohibited change in concomitant medication for ulcerative colitis or who had undergone an ostomy or colectomy before week 8 were considered not to have met the end point. Clinical remission was defined as a total score of 2 or less on the Mayo scale (range, 0 to 12, with higher scores indicating more severe disease) and no subscore greater than 1 (range, 0 to 3) on any of the four Mayo scale components. Endoscopic improvement was defined as a Mayo endoscopic subscore of 0 or 1. Clinical response was defined as a decrease in the total Mayo score of at least 30% and of at least 3 points from baseline, with an accompanying decrease of at least 1 point on the Mayo rectal bleeding subscore or a rectal bleeding subscore of 0 or 1. Histo-endoscopic mucosal healing required both histologic improvement (defined as neutrophil infiltration in <5% of crypts, no crypt destruction, and no erosions, ulcerations, or granulation tissue) and endoscopic improvement. Patients with missing data on all four Mayo subscores at week 8 were considered not to be in clinical remission or not to have a clinical response at week 8. Patients who had a missing Mayo endoscopic subscore at week 8 were considered not to have endoscopic improvement. Patients who were missing any Geboes score components pertaining to histologic improvement at week 8 were considered not to have histologic improvement. The analyses for histologic improvement and histo-endoscopic mucosal healing excluded data from patients whose status with respect to these end points could not be determined at week 8 owing to a biopsy sample that could not be evaluated (i.e., a biopsy sample was obtained but could not be assessed owing to technical issues, such as errors during sample collection, preparation, or both).\n\n【52】At week 8, the percentages of patients in clinical remission were higher in the groups that received ustekinumab at a dose of either 130 mg (15.6% \\[50 of 320 patients\\]) or 6 mg per kilogram (15.5% \\[50 of 322\\]) than in the placebo group (5.3% \\[17 of 319\\]) (P<0.001 for both comparisons with placebo) . The results were similar for the alternative primary end point of clinical remission that excluded the subscore on the physician’s global assessment component of the Mayo scale: 16.6% (53 of 320 patients) and 18.9% (61 of 322) in the respective ustekinumab groups and 6.3% (20 of 319) in the placebo group (P<0.001 for both comparisons with placebo) .\n\n【53】The efficacy observed in prespecified subgroups for both ustekinumab groups was consistent with that in the overall trial population. Results of analyses according to treatments received before the trial suggest benefits of ustekinumab across subgroups. For both definitions of clinical remission, the results of sensitivity analyses were consistent. (For details, see Fig. S3A through S3H and Tables S4 and S5 in the Supplementary Appendix .)\n\n【54】The percentages of patients who met major secondary end points or had histo-endoscopic mucosal healing were significantly higher in both ustekinumab groups than in the placebo group . Through week 8, the median changes from baseline in the IBDQ score were significantly greater in both ustekinumab groups than in the placebo group. The percentage of patients who had histologic improvement at week 8 was higher in both ustekinumab groups than in the placebo group. Improvements from baseline that were observed in the partial Mayo scores and in concentrations of fecal calprotectin and lactoferrin and serum CRP support the clinical outcomes. \n\n【55】Among patients who did not have a clinical response to intravenous ustekinumab and who received 90 mg of subcutaneous ustekinumab at week 8, a total of 59.7% (139 of 233) had a delayed clinical response at week 16. Among all patients in the induction trial who were initially assigned to ustekinumab, 77.6% (498 of 642) had a clinical response within 16 weeks. In addition, among patients who did not have a clinical response to intravenous placebo and who then received intravenous ustekinumab at a dose of 6 mg per kilogram, 67.9% (125 of 184) had a clinical response at week 16.\n\n【56】Maintenance Therapy\n-------------------\n\n【57】Figure 3. Patients’ Responses to Maintenance Therapy.\n\n【58】Patients who had a clinical response to intravenous ustekinumab during the induction trial were randomly assigned to receive subcutaneous injections of placebo or one of two doses of ustekinumab on entry to the maintenance trial. Patients who had a prohibited change in medication for ulcerative colitis, had undergone an ostomy or colectomy, or had used a rescue medication after a clinical flare or who had discontinued ustekinumab or placebo owing to lack of therapeutic effect or owing to an adverse event of worsening of ulcerative colitis before the week 44 visit were considered not to have met the dichotomous end points or had their value at baseline in the induction trial carried forward from the time of the event onward for continuous end points. Patients with missing data on all four Mayo subscores at week 44 were considered not to have clinical remission, clinical response, or corticosteroid-free clinical remission at week 44. Patients who did not have clinical remission or clinical response at any time before week 44 were considered not to be in clinical remission among patients in clinical remission at week 0 in the maintenance trial or not to have maintenance of clinical response through week 44. Patients who had a missing value for corticosteroid use at week 44 had their last value carried forward. Patients who had a missing Mayo endoscopic subscore at week 44 were considered not to have endoscopic improvement.\n\n【59】Among patients who had a clinical response to induction treatment with ustekinumab, the percentages of patients who had clinical remission at week 44 (52 weeks after intravenous induction) were significantly higher in the groups that received 90 mg of ustekinumab every 12 weeks (38.4% \\[66 of 172 patients\\]) or every 8 weeks (43.8% \\[77 of 176\\]) than in the placebo group (24.0% \\[42 of 175\\]) (P=0.002 and P<0.001, respectively, for the comparison with placebo) . The results were similar for the alternative definition of clinical remission: 39.5% (68 of 172 patients) and 42.6% (75 of 176) in the respective ustekinumab groups and 24.6% (43 of 175) in the placebo group (P=0.002 and P<0.001, respectively, for the comparison with placebo). Efficacy among prespecified subgroups was consistent with that in the overall randomized population. For both definitions of clinical remission, the results of sensitivity analyses were consistent. \n\n【60】The percentages of patients with maintenance of clinical response through week 44, endoscopic improvement at week 44, or corticosteroid-free clinical remission (with either definition of clinical remission) at week 44 were significantly higher in both ustekinumab groups than in the placebo group . Among patients in clinical remission at baseline in the maintenance trial, the percentage who had maintenance of clinical remission through week 44 was not significantly higher among those receiving 90 mg of ustekinumab every 8 weeks than among those receiving placebo; when the alternative definition of clinical remission was used, the percentage was significantly higher in both ustekinumab groups than in the placebo group. Results of analyses according to treatments received before the trial suggest benefits of ustekinumab across subgroups for all end points except maintenance of clinical remission. \n\n【61】Among patients receiving corticosteroids at baseline, the percentages of those who discontinued corticosteroid use at least 90 days before week 44 were higher in the groups that received 90 mg of ustekinumab every 12 weeks (67% \\[55 of 82 patients\\]) or every 8 weeks (77% \\[71 of 92\\]) than in the placebo group (44% \\[40 of 91\\]); 97.2% of patients in clinical remission at week 44 (both definitions) (139 of 143) were corticosteroid-free at week 44. Corticosteroids were discontinued sooner by patients receiving ustekinumab (median, 7 weeks in each group) than by those receiving placebo (median, 16 weeks) .\n\n【62】The percentage of patients who had histologic improvement was higher in both ustekinumab groups than in the placebo group, as was the percentage of patients who had histo-endoscopic mucosal healing. Through week 44, median IBDQ scores were maintained or improved with ustekinumab every 12 weeks and every 8 weeks but worsened with placebo. Improvements in partial Mayo scores and concentrations of CRP, lactoferrin, and calprotectin that were observed at baseline in the maintenance trial were maintained in both ustekinumab groups, whereas results for these measures worsened in the placebo group. \n\n【63】Among patients who had a delayed response to ustekinumab and received 90 mg every 8 weeks, 62.4% (98 of 157) had maintenance of clinical response through week 44. The percentages of patients who met this end point or other efficacy measures at week 44 were lower than those among patients who had a response to intravenous ustekinumab and were randomly assigned to 90 mg of subcutaneous ustekinumab every 8 weeks during maintenance .\n\n【64】The percentage of patients who had an ulcerative colitis–related hospitalization was lower in both ustekinumab groups than in the placebo group through week 8 in the induction trial and remained lower through week 44 in the maintenance trial. \n\n【65】Safety\n------\n\n【66】Table 2. Safety Results through the Final Safety Visit in the Induction Trial and through Week 44 in the Maintenance Trial.\n\n【67】Through the final safety visit in the induction trial, the percentages of patients who reported at least one adverse event in the groups receiving 130 mg of ustekinumab, 6 mg of ustekinumab per kilogram, and placebo were 41.4%, 50.6%, and 48.0%, respectively. The percentages of patients in these groups with at least one serious adverse event were 3.7%, 3.4%, and 6.9%, respectively. Through week 44 in the maintenance trial, the percentages of randomly assigned patients who reported at least one adverse event in the groups receiving 90 mg of ustekinumab every 12 weeks, 90 mg of ustekinumab every 8 weeks, and placebo were 69.2%, 77.3%, and 78.9%, respectively. The percentages of patients with at least one serious adverse event were 7.6%, 8.5%, and 9.7%, respectively; the percentages of patients with a serious infection were 3.5%, 1.7%, and 2.3%, respectively. Findings in the nonrandomized population were consistent with those in the randomized population .\n\n【68】Adverse events of interest that occurred among patients receiving ustekinumab or placebo through 52 weeks of treatment are summarized below and in the Supplementary Appendix . Two deaths before week 44 (sudden death attributed to hemorrhage from esophageal varices and death from acute respiratory distress syndrome \\[ARDS\\]) and one death after week 44 (a patient with failure to thrive had a cardiac arrest) occurred among patients receiving ustekinumab. Cancer occurred in 7 of 825 patients who received ustekinumab (1 each of prostate, colon, renal papillary, and rectal cancer and 3 nonmelanoma skin cancers) and 1 of 319 patients who received placebo (testicular cancer). Four patients who received ustekinumab presented with potential opportunistic infections: cytomegalovirus colitis (in 2 patients during maintenance), legionella pneumonia (in 1 patient during induction), and concurrent ophthalmic and oral herpes simplex infections (in 1 patient during maintenance). Three major cardiovascular events occurred: a nonfatal cardiac arrest (in a patient who received ustekinumab during induction and placebo during maintenance), an acute myocardial infarction (in a patient who received ustekinumab and died of ARDS complications), and a nonfatal stroke (in a patient who received placebo during induction).\n\n【69】Pharmacokinetics and Immunogenicity\n-----------------------------------\n\n【70】Positive associations were observed between serum ustekinumab concentrations at week 8 and clinical response at week 8 and between serum ustekinumab concentrations at week 24 and clinical remission at week 44. Among 505 patients who received ustekinumab during both induction and maintenance, antidrug antibodies developed in 4.6% (23 of 505). Among the 23 patients, 22% (5 of 23) had neutralizing antibodies, and 39% (9 of 23) had transient antibodies. \n\n【71】Discussion\n----------\n\n【72】In this phase 3 trial of an antagonist of interleukin-12 and interleukin-23 involving patients with moderate-to-severe ulcerative colitis, ustekinumab was more effective than placebo in achieving induction of clinical remission at 8 weeks. This effect was observed in patients with or without previous treatment failure with biologic agents, including those who had not received biologics. Among patients who had a response to induction therapy with intravenous ustekinumab and who underwent a second randomization, those assigned to either regimen of subcutaneous ustekinumab were more likely to be in clinical remission at 44 weeks than those assigned to placebo. For all prespecified major secondary end points in the induction and maintenance trials, the percentages of patients were significantly higher in the ustekinumab groups than in the placebo group, except for the major secondary end point of maintenance of clinical remission through week 44 among patients in clinical remission at baseline. For that end point, the percentage of patients in the group receiving ustekinumab every 12 weeks was higher than in the placebo group for both remission definitions, but the percentage in the group receiving ustekinumab every 8 weeks was higher than in the placebo group only for the alternative definition of clinical remission that was used to support the FDA submission.\n\n【73】Because this program had a randomized-withdrawal design, the percentages of patients in clinical remission reported at week 44 should be interpreted in the context of the trial design. Only those patients who had a response to induction therapy with intravenous ustekinumab underwent a second randomization in the maintenance trial; therefore, the proportion of patients who had clinical remission with ustekinumab treatment would be different if all patients entered the maintenance trial regardless of the clinical outcome in the induction trial.\n\n【74】The therapeutic goal in patients with ulcerative colitis is to induce and maintain long-term remission, because the disease often has a relapsing and remitting course.  Endoscopic improvement in mucosal appearance is associated with better subsequent long-term outcomes in patients with ulcerative colitis.  Histologic improvement has also been associated with better long-term outcomes, including reductions in corticosteroid use and relapse.  The combination of endoscopic and histologic improvement has been suggested by the research community and regulatory bodies  as the most complete method of assessing mucosal healing. \n\n【75】In this trial, we combined macroscopic and microscopic evidence of mucosal improvement to define histo-endoscopic mucosal healing. Because there was no accepted definition of histologic improvement, criteria were developed with the use of data from completed prospective clinical trials involving patients with ulcerative colitis.  Histo-endoscopic mucosal healing, an end point that was controlled for multiple comparisons in the induction trial, was induced by both intravenous doses of ustekinumab and maintained by both subcutaneous doses. The association of this end point with long-term clinical outcomes and prevention of colon cancer requires further exploration.\n\n【76】In analyses of other end points, improvements in partial Mayo scores and reductions in serum and fecal concentrations of inflammatory biomarkers that were observed with induction were sustained through maintenance. Although our findings suggest that ustekinumab was effective in patients with or without previous treatment failure with biologics for both induction and maintenance therapy, the percentages of patients in whom each end point was achieved were lower across groups with previous treatment failure with biologics.\n\n【77】Some possible differences in dose were observed for several end points. At week 8, a higher percentage of patients who had a clinical response, larger decreases in the partial Mayo score, and greater reductions in fecal lactoferrin and calprotectin concentrations were observed with approximately 6 mg of ustekinumab per kilogram than with 130 mg of ustekinumab. At week 44, for the more objective and stringent end points (e.g., endoscopic improvement, histo-endoscopic mucosal healing, corticosteroid-free remission, and elimination of corticosteroids ≥90 days before week 44 among patients receiving corticosteroids at baseline in the maintenance trial), greater clinical benefit was observed with ustekinumab every 8 weeks than with ustekinumab every 12 weeks.\n\n【78】Cancers developed in seven patients who received ustekinumab (including three cases of nonmelanoma skin cancer) and in one patient who received placebo. Potential opportunistic infections developed in four patients who received ustekinumab. There were no cases of anaphylaxis or serious hypersensitivity reactions in patients who received ustekinumab.\n\n【79】In conclusion, in this trial involving patients with moderate-to-severe ulcerative colitis despite current or previous treatment with conventional or biologic therapy, ustekinumab was more effective than placebo for inducing and maintaining remission.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-14 00:13:25", "grab_time": "2024-08-13 23:17:19"}
{"id": 2234301, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "68e2fe47-7cf6-4fe5-a567-265233e557d7", "title": "Application of Endonuclease Mapping to the Analysis and Prenatal Diagnosis of Thalassemias Caused by Globin-Gene Deletion", "text": "【0】Application of Endonuclease Mapping to the Analysis and Prenatal Diagnosis of Thalassemias Caused by Globin-Gene Deletion\nAbstract\n--------\n\n【1】We applied a recently developed and more direct technic to diagnose thalassemia syndromes associated with deletion of particular globin structural genes and to assess a fetus at risk for one of those conditions, δβ-thalassemia. The method allows assessment of the globin genes present in total cellular DNA and is applicable to amniotic-fluid cell DNA. Cellular DNA fragments produced by cleavage using two specific restriction endonucleases are separated on the basis of size by agarose-gel electrophoresis, and the distribution of specific sequences among the DNA fragments determined by molecular hybridization.\n\n【2】We observed the total deletion of α-globin genes in homozygous α-thalassemia (hydrops fetalis with hemoglobin Bart's) and the deletion of particular β and β-like sequences in cases homozygous for hereditary persistence of fetal hemoglobin and δβ-thalassemia. Analysis of amniotic-fluid cell DNA from a fetus at risk for δβ-thalassemia demonstrated the feasibility of these improved methods for antenatal diagnosis. The molecular studies confirmed the diagnosis predicted by analysis of fetal blood and established at birth.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:47:30", "endTime": "2024/08/14 15:49:02", "cost": 91.878}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 23:49:02", "grab_time": "2024-08-13 23:47:30"}
{"id": 2234300, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "68d6a76e-7bdb-4f56-a7ab-5d1c73917c1f", "title": "Molecular Genetic Anatomy and Risk Profile of Hirschsprung’s Disease", "text": "【0】Molecular Genetic Anatomy and Risk Profile of Hirschsprung’s Disease\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Hirschsprung’s disease, or congenital aganglionosis, is a developmental disorder of the enteric nervous system and is the most common cause of intestinal obstruction in neonates and infants. The disease has more than 80% heritability, including significant associations with rare and common sequence variants in genes related to the enteric nervous system, as well as with monogenic and chromosomal syndromes.\n\n【3】Methods\n-------\n\n【4】We genotyped and exome-sequenced samples from 190 patients with Hirschsprung’s disease to quantify the genetic burden in patients with this condition. DNA sequence variants, large copy-number variants, and karyotype variants in probands were considered to be pathogenic when they were significantly associated with Hirschsprung’s disease or another neurodevelopmental disorder. Novel genes were confirmed by functional studies in the mouse and human embryonic gut and in zebrafish embryos.\n\n【5】Results\n-------\n\n【6】The presence of five or more variants in four noncoding elements defined a widespread risk of Hirschsprung’s disease (48.4% of patients and 17.1% of controls; odds ratio, 4.54; 95% confidence interval \\[CI\\], 3.19 to 6.46). Rare coding variants in 24 genes that play roles in enteric neural-crest cell fate, 7 of which were novel, were also common (34.7% of patients and 5.0% of controls) and conferred a much greater risk than noncoding variants (odds ratio, 10.02; 95% CI, 6.45 to 15.58). Large copy-number variants, which were present in fewer patients (11.4%, as compared with 0.2% of controls), conferred the highest risk (odds ratio, 63.07; 95% CI, 36.75 to 108.25). At least one identifiable genetic risk factor was found in 72.1% of the patients, and at least 48.4% of patients had a structural or regulatory deficiency in the gene encoding receptor tyrosine kinase ( _RET_ ). For individual patients, the estimated risk of Hirschsprung’s disease ranged from 5.33 cases per 100,000 live births (approximately 1 per 18,800) to 8.38 per 1000 live births (approximately 1 per 120).\n\n【7】Conclusions\n-----------\n\n【8】Among the patients in our study, Hirschsprung’s disease arose from common noncoding variants, rare coding variants, and copy-number variants affecting genes involved in enteric neural-crest cell fate that exacerbate the widespread genetic susceptibility associated with _RET_ . For individual patients, the genotype-specific odds ratios varied by a factor of approximately 67, which provides a basis for risk stratification and genetic counseling. \n\n【9】Introduction\n------------\n\n【10】Hirschsprung’s disease is characterized by the lack of ganglia in the myenteric and submucosal plexuses of the gut. It is a “model” complex disorder because it exemplifies multifactorial inheritance and yet has been molecularly tractable.  The disease (with an incidence of 15 cases per 100,000 live births) is characterized by high heritability (>80%) and marked sex differences (male:female ratio\\.  Patients have aganglionosis affecting bowel segments of variable length, as a result of incomplete rostral-to-caudal enteric neuronal colonization; on the basis of these segment lengths, the condition is classified as short, long, or total colonic aganglionosis . Approximately 18% of patients have multiple anomalies, some with specific syndromes; approximately 12% have major chromosomal variants.  Features of Hirschsprung’s disease include its high (3 to 17%) sibling recurrence risk (i.e., the risk of being born with the disease, given that one full sibling is affected) and the variation in risk according to sex, segment length, and familiality. \n\n【11】Hirschsprung’s disease has multifactorial causes, although no environmental causes are known.  Complex segregation analyses have refined this view by showing genetic heterogeneity according to the extent of aganglionosis. The long form is characterized by autosomal dominant inheritance and the short form by recessive or multifactorial inheritance, and the variants associated with both forms have incomplete penetrance.  This finding led to the discovery of 17 genes with approximately 500 rare disease-associated coding variants, chiefly the genes encoding the receptor tyrosine kinase RET and the G-protein–coupled receptor EDNRB .  Four noncoding variants, individually conferring moderate risks (odds ratio, 1.6 to 3.9) but together conferring risk that can vary by as much as a factor of 30 with increasing risk-allele dosage,  are genetic modifiers of Hirschsprung’s disease.  These data suggest widespread and variable genetic susceptibility to the disease from multiple genes, reflected in the differing presentations and recurrence risks among relatives.\n\n【12】We suspected that, in contrast to the genetic risk factors for other complex diseases, many genetic risk factors make individually large contributions to the risk of Hirschsprung’s disease. We undertook genotyping, exome-sequencing, and functional assays to study pathogenic alleles in a set of patients with Hirschsprung’s disease with representative phenotypes. Beyond studying known genes and identifying new ones, we investigated the variation in risk according to the type of pathogenic allele, the contribution of each type of allele to Hirschsprung’s disease in the general population, and the distribution of these types of alleles across phenotypes. Our primary goal was to enable genetic stratification of patients in order to determine how genetic susceptibility manifests in clinical disease and its penetrance. Such genetic stratification could be used to determine whether postsurgical outcome — for example, continued bowel dysfunction and enterocolitis, which is reported in 30 to 50% of patients  — is related to genotype.\n\n【13】Methods\n-------\n\n【14】Participants and Genomewide Analyses\n------------------------------------\n\n【15】We conducted exome sequencing of samples from 190 patients of European ancestry and 47 of their affected relatives (7 parents, 12 children, 17 siblings, and 11 second-degree relatives) with diverse phenotypes. The control sample used in exome sequencing consisted of publicly available, ancestry-matched exome data on 740 samples from the 1000 Genomes Project and the National Institute of Mental Health Repository. For the analysis of common noncoding variant studies, we used a different set of 627 control samples that were genotyped in our laboratory: 404 from the 1000 Genomes Project and an additional 223 “pseudo-controls” (generated from the chromosomes not transmitted to the affected child in 254 parent–child trios  ). For the analysis of copy-number variants, we used a third control set of 19,584 adults of European ancestry. \n\n【16】Sequence variants, genotypes and their frequencies at single-nucleotide variants, small (<50 bp) insertions or deletions, and copy-number variants were identified and annotated.  Single-nucleotide polymorphism (SNP) arrays were used to validate copy-number variant calls. Genotype calls at transcription-enhancer variants were from our previous studies involving the same study population.  The sample ascertainment and analysis methods are described in detail in the Methods section, Tables S1 through S5, and Figures S1 through S3 in the Supplementary Appendix .\n\n【17】Pathogenic Alleles, Genes, and Loci\n-----------------------------------\n\n【18】For assessing the effect of common noncoding variants, we used four disease-associated SNPs — rs2435357, rs7069590, and rs2506030 in _RET_ and rs11766001 in the SEMA3 gene cluster.  We have previously shown that the _RET_ noncoding variants are located within transcription enhancers bound by the transcription factors RARB, GATA2, and SOX10; these variants lead to reduced _RET_ expression and an elevated risk of Hirschsprung’s disease.  Although the causality of the rs11766001 polymorphism in the SEMA3 locus is unproven, considerable data support causality or a strong association with a causal variant in _SEMA3C_ or _SEMA3D_ , which have been shown to be necessary for gut innervation.  Coding pathogenic alleles at each gene were defined as nonsense or missense changes in codons encoding amino acids that are conserved (with respect to their position in the oligopeptide) across species, splice-site single-nucleotide variants, and all coding insertion–deletion variants with a frequency of 5% or less. These definitions gave acceptable levels of true and false positives at known Hirschsprung’s disease genes .  Disease-associated coding variants can have incomplete penetrance and be present in controls; therefore, we identified Hirschsprung’s disease–associated genes as those that had a greater number of unique pathogenic alleles in patients than in controls . We assessed large copy-number variants (deletions of more than 500 kb and duplications of more than 1 Mb) with a frequency of less than 1% among controls to determine whether they were significantly enriched among patients or had previously been found to be associated with a developmental disorder .  Additional details are provided in the Methods section in the Supplementary Appendix .\n\n【19】To assess the role of a gene in Hirschsprung’s disease, we first used reverse-transcriptase polymerase chain reaction (RT-PCR) to assess its RNA expression in the human embryonic gut at Carnegie stage 22, by which time gut neurogenesis is complete . Second, we tested gene expression by RNA sequencing and RT-PCR in the developing mouse gut during the equivalent developmental period (embryonic day 10.5) . Third, we used morpholinos (antisense oligonucleotides) to knock down gene expression in zebrafish embryos at 6 days after fertilization and enumerated the enteric neurons colonizing the gut relative to controls . \n\n【20】The sequence data generated as part of this study are available in the National Center for Biotechnology Information (NCBI) database of Genotypes and Phenotypes (dbGaP) under accession number phs000497. The RNA sequencing data used in this study are accessible under NCBI Gene Expression Omnibus (GEO) accession number GSE99232.\n\n【21】Statistical Analysis\n--------------------\n\n【22】Population-level risks were estimated for groups of pathogenic alleles, genes, or loci with the use of odds ratios with significance thresholds (corrected for multiple testing) and 95% confidence intervals.  The odds ratios were converted to estimated population penetrance (equivalent to the population incidence or risk) with Bayes’ theorem, under the assumption of an incidence of 15 cases per 100,000 European-ancestry live births.  Allele frequencies among controls were obtained from a variety of public resources  to estimate the population attributable risk. Additional details are provided in the Methods section in the Supplementary Appendix .\n\n【23】Results\n-------\n\n【24】Common Regulatory Variants and Risk\n-----------------------------------\n\n【25】Table 1. Population Risk of Hirschsprung’s Disease as a Function of _RET_ and _SEMA3_ Noncoding Risk-Allele Dosage. Table 2.  Table 2. Distribution of Hirschsprung’s Disease Risk According to the Molecular Class of Risk Alleles.\n\n【26】Four common transcription-enhancer variants were associated with a moderate risk of Hirschsprung’s disease in our sample of 190 patients and 627 controls .  The frequency of these variants allowed us to estimate their total effect according to dosage in reference to persons with one allele (none had zero alleles): a risk of Hirschsprung’s disease (odds ratio >1) is evident only with three or more alleles , but, in view of multiple comparisons, the risk was considered significant only when at least five risk alleles were present (odds ratio, 4.54; 95% confidence interval \\[CI\\], 3.19 to 6.46; P=1.22×10 <sup>−16 </sup> ) . Thus, the population risk of Hirschsprung’s disease varies by a factor of 24, from approximately 1 case per 19,100 live births (0 or 1 risk allele) to 1 case per 710 live births (seven or eight risk alleles) according to enhancer risk-allele dosage, which shows the wide differences in basal susceptibility to Hirschsprung’s disease.\n\n【27】Risk Associated with Rare Coding Variants\n-----------------------------------------\n\n【28】We first tested whether coding pathogenic alleles, as we defined them, for the 17 known Hirschsprung’s disease genes statistically discriminated patients from controls . As compared with the 29 pathogenic alleles found in 71 (9.6%) of 740 controls, 36 pathogenic alleles were found in 41 (21.6%) of 190 patients, a percentage 2.25 times as high (P=5.97×10 <sup>−6 </sup> ) , which indicates a higher burden of pathogenic alleles in patients. Furthermore, the pathogenic alleles that were found in patients had a significantly lower mean frequency in an external reference population, the Exome Aggregation Consortium database  (ExAC), than did the pathogenic alleles found in controls (5.58×10 <sup>−4 </sup> vs. 1.11×10 <sup>−3 </sup> , P=2.14×10 <sup>−5 </sup> ) , which indicates that the rare coding changes observed in patients have been subject to greater purifying selection than those observed in controls. That is, even though pathogenic alleles in both patients and controls met our definition of pathogenicity, when we compared the frequency of each set (variants in the patients being one set and variants in the controls the other) with the frequency of the specific variants of each set in persons in the ExAC database, those of the patient set were less frequent in the ExAC database than were those in the control set.\n\n【29】Table 3. Genes with an Excess of Rare Coding Pathogenic Alleles in Hirschsprung’s Disease.\n\n【30】To assess the enrichment of pathogenic alleles for each gene, we estimated the probability (P value) of finding as many or a greater number of distinct pathogenic alleles in patients, restricting our analysis to 15,963 single-nucleotide variants in 4027 genes for which there was at least one identified pathogenic allele in both patients and controls. We identified 3 genes, _EDNRB_ , _ADAMTS17_ , and _ACSS2_ , that exceeded the significance threshold of 1.24×10 <sup>−5 </sup> (5% significance across 4027 genes) . More broadly, at a P value threshold of 0.001, we found 10 genes instead of the expected 4 (P=1.3×10 <sup>−3 </sup> ) . We performed functional tests on these 10 genes to distinguish false from true candidates.\n\n【31】The top 10 genes had a minimum of 4 pathogenic alleles each and included both of the major genes, _RET_ and _EDNRB_ . We also found evidence of 7 novel Hirschsprung’s disease genes — _ACSS2_ , _ADAMTS17_ , _ENO3_ , _FAM213A_ , _SH3PXD2A_ , _SLC27A4_ , and _UBR4_ — on the basis of both an excess of pathogenic alleles and enteric nervous system gene expression in humans and mice during enterogenesis; assays in zebrafish further confirmed _ACSS2_ , _ENO3_ , _SH3PXD2A_ , and _UBR4_ . The 7 novel genes harbored 39 distinct pathogenic alleles occurring in 40 patients (21.1%), as compared with 23 distinct pathogenic alleles occurring in 28 controls (3.8%) (P=3.46×10 <sup>−16 </sup> ). Of the 39 pathogenic alleles in patients, only 6 were identified in 8 controls (1.1%). When all 24 Hirschsprung’s disease genes were considered, we identified 75 unique pathogenic alleles occurring in 34.7% of patients (66 of 190), a percentage significantly higher than the 5.0% observed among controls (37 of 740; odds ratio, 10.02; 95% CI, 6.45 to 15.58; P=3.41×10 <sup>−25 </sup> ) . The mean allele frequencies of the pathogenic alleles in patients and controls in the ExAC database are 4.22×10 <sup>−4 </sup> and 8.26×10 <sup>−4 </sup> , respectively, a difference similar in magnitude to the difference we observed for alleles in the 17 previously known Hirschsprung’s disease genes. The causality of these variants is further confirmed by higher-than-expected genotype concordance between probands with coding pathogenic alleles and their affected relatives (P=0.005) .\n\n【32】Pathways and Functional Groups\n------------------------------\n\n【33】Owing to genetic heterogeneity and chance fluctuations, the overall contribution of pathways to Hirschsprung’s disease can be estimated more accurately than that of individual genes . In Hirschsprung’s disease, the RET and EDNRB signaling pathways play major roles with strong epistatic interactions.  Thus, we considered members of the RET ( _GDNF_ , _NRTN_ , _GFRA1_ , and _RET_ ) and EDNRB ( _ECE1_ , _EDN3_ , and _EDNRB_ ) signaling modules for burden analysis. A third pathway, also epistatic to RET, involves the class 3 semaphorins and their receptors: here we consider only _SEMA3C_ and _SEMA3D_ because of their association with Hirschsprung’s disease.  A fourth class consists of the transcription-factor genes ( _SOX10_ , _ZEB2_ , _PHOX2B_ , and _TCF4_ ) that are critical to the early development of the enteric nervous system and harbor rare coding variants that cause Hirschsprung’s disease–associated syndromes . We considered two additional categories: other known genes ( _KIF1BP_ , _L1CAM_ , _IKBKAP_ , and _NRG1_ )  and the seven novel genes identified in this study.\n\n【34】We compared the total numbers of pathogenic-allele genotypes in each of these six classes or pathways among the 66 variant-positive patients with their corresponding frequencies among controls . Genes encoding members of the EDNRB pathway (odds ratio, 69.03; 95% CI, 8.68 to 547.92), transcription-factor genes (odds ratio, 35.73; 95% CI, 4.15 to 307.72), and novel genes (odds ratio, 23.2; 95% CI, 11.04 to 48.72) had the largest risk effects, followed by genes encoding members of the RET pathway (odds ratio, 16.03; 95% CI, 5.21 to 49.28) and _SEMA3C_ and _SEMA3D_ (odds ratio, 2.65; 95% CI, 1.25 to 5.60). Other known genes (odds ratio, 3.15; 95% CI, 1.22 to 8.09) also made measurable risk contributions, but with an order of magnitude smaller effect. These risk rankings were reflected in the inverse contributions of these classes to the total risk of Hirschsprung’s disease. Pathogenic alleles causing greater risk probably have higher penetrance and are therefore selected against with greater intensity. If so, the abundant coding variants in genes of the RET pathway have lower penetrance than coding variants in the genes of the EDNRB pathway, the genes encoding transcription factors, and the novel genes.\n\n【35】These data also indicate that _RET_ has a smaller coding-variant risk burden than previously believed: 6.3% of the patients (12 patients) had _RET_ coding pathogenic alleles, in contrast to approximately 50% from the older data.  This difference could arise from differing definitions of pathogenicity or from the preponderance of familial and severe cases in earlier studies. Nevertheless, _RET_ regulatory pathogenic alleles, which have even lower penetrance than coding pathogenic alleles,  were prevalent and, together with _RET_ coding variants, conferred substantial risk in 92 of 190 patients (48.4%); this finding highlights the fact that reduced _RET_ expression is the predominant cause of Hirschsprung’s disease. Moreover, coding or noncoding (in the case of _RET_ transcription-enhancer variants) pathogenic alleles in affecting genes that encode members of the RET regulatory network,  which is made up of RET, its transcription factors (RARB, GATA2, and SOX10), its ligands (GDNF and NRTN), and its coreceptor (GFRA1), were found in 120 of our patients (63.2%). In contrast, genes of the EDNRB pathway contributed to only 8 cases (4.2%).\n\n【36】Frequency of Copy-Number Variants in Hirschsprung’s Disease\n-----------------------------------------------------------\n\n【37】Table 4. Karyotypes and Large CNVs in Hirschsprung’s Disease.\n\n【38】Of the 190 patients, 17 (8.9%) had syndromic presentations or known major chromosomal variants . To detect subkaryotypic changes, we examined the exome data to identify large copy-number variants. In total, we identified 16 distinct copy-number variants; 14 of these variants (and their loci) were not previously known to be associated with Hirschsprung’s disease . We assessed the pathogenicity of each variant on the basis of its enrichment in patients or their association with a known developmental disorder to identify 9 chromosomal variants and copy-number variants in 11.4% of patients (21 of 185), with a corresponding frequency of 0.2% (40 of 19,584) in controls, a highly significant effect (odds ratio, 63.07; 95% CI, 36.75 to 108.25; P=4.19×10 <sup>−51 </sup> ) . \n\n【39】Of the 21 instances of pathogenic chromosomal variants in patients, 18 (86%) were recurrent and 3 were nonrecurrent, and 18 were in patients with syndromic presentations . The most frequent (11 variants, 52%) recurrent finding was trisomy 21, but the other 7 occurred at well-known loci for other genomic disorders. The elevated frequency of trisomy 21 among patients with Hirschsprung’s disease (odds ratio, 73.69; 95% CI, 34.97 to 155.29; P=1.23×10 <sup>−29 </sup> )  is not surprising, given previous observations.  However, the 16p11.2del copy-number variant, which is usually associated with autism,  is also significantly enriched (odds ratio, 30.03; 95% CI, 9.70 to 92.97; P=3.62×10 <sup>−9 </sup> ). Overall, the 9.7% frequency of patients with Hirschsprung’s disease who have recurrent chromosomal variants is significantly higher than the expected frequency (odds ratio, 53.30; 95% CI, 30.30 to 93.76; P=2.60×10 <sup>−43 </sup> ). These recurrent chromosomal changes are known to be associated with intellectual disability, autism, neurodevelopmental delay, epilepsy, and Charcot–Marie–Tooth disease type 1A,  perhaps owing to pathways common to the enteric and central nervous systems. The three nonrecurrent variants, one of which deletes _EDNRB_ , were unique, and all occurred in patients with syndromic presentations .\n\n【40】Distribution of Diverse Pathogenic Alleles\n------------------------------------------\n\n【41】Pathogenic alleles in at least 32 genes and loci contribute to Hirschsprung’s disease: rare coding variants in 24 genes, common noncoding variants at four sites within 2 loci, and large copy-number variants and chromosomal anomalies in at least 8 additional loci (not including 13q21.33-q31.1del, which overlaps _EDNRB_ ). The common noncoding risk genotypes (five or more risk alleles), rare coding variants, and copy-number variants occur at decreasing (by orders of magnitude) frequencies in the general population — 17.1%, 5.0%, and 0.2% — but with increasing odds ratios of 4.54, 10.02, and 63.07, respectively . In consequence, all three variant classes make major contributions to the risk of Hirschsprung’s disease, with population attributable risks of 37.7%, 31.1%, and 11.3%, respectively, and a total attributable fraction of 61.9%. In addition, although the differences are not significant, the odds ratios among males are consistently higher than those among females . Thus, the sex effect in Hirschsprung’s disease is not caused by a specific gene or variant but is a property of the disorder. We conclude that, first, even in this rare disorder, common variants are responsible for the majority of cases of Hirschsprung’s disease, despite their individually lower risks, because of their high population prevalence. Second, the total risk from all rare coding pathogenic alleles (which have a much higher penetrance) is also high but is differentially spread over 24 genes. Third, the population risk from copy-number variants is the lowest, spread over the effects of 9 loci but with a majority contribution from trisomy 21. These risks from both known and novel genes and loci are almost certainly overestimates owing to the “winner’s curse.” Consequently, we reestimated the risks, taking into consideration only the well-established risk factors and genes known before this study, and we found the same pattern: these variant classes occur at frequencies of 17.1%, 3.9%, and 0.1% in the general population, but with increasing risks — odds ratios of 4.54, 6.70, and 73.69, respectively . These three categories contribute to the population attributable risks of 37.7%, 18.2%, and 9.1%, respectively, or a total attributable fraction of 53.7%.\n\n【42】Table 5. Distribution of Hirschsprung’s Disease Cases by Genetic Risk Profile and Population Effects.\n\n【43】Finally, we quantified the risk associated with combinations of pathogenic alleles .  We classified each patient’s total burden of pathogenic alleles according to sex, segment length, familiality, and the presence or absence of additional anomalies; we pooled all patients with copy-number variants into one class, given the low frequency of this type of variant. The results showed three cardinal features . First, genetic risk factors of any type were identifiable in 72.1% of patients, and patients harbored various combinations of different types of pathogenic alleles, all in significant excess relative to controls. Second, each of the three variant classes (five or more common noncoding variants, rare coding variants, and copy-number variants) were present in substantial percentages of diagnoses (48.4%, 34.7%, and 11.4%, respectively) . One, two, or three different classes of molecular lesion were present in 51.9%, 18.4%, and 1.7% of patients, respectively — roughly their expected frequencies — with no evidence of interaction, a finding consistent with multifactorial expectations, although the statistical power for such detection is probably low . Third, the genotype-specific odds ratios for Hirschsprung’s disease, estimated in reference to the class with no identifiable genetic risk factor, vary by a factor of 67 and increase with the pathogenic allele burden. These data allow us to estimate the absolute risk of Hirschsprung’s disease, given a person’s genotype. Persons with no identifiable risk factors have an estimated population risk of 5.33 per 100,000 (approximately 1 per 18,800), a low risk of disease. At the other extreme, persons with both common enhancer risk genotypes and rare coding variants and those with copy-number variants have substantial estimated risks of 2.85 per 1000 (approximately 1 per 350) and 8.38 per 1000 (approximately 1 per 120), respectively.\n\n【44】We did not detect any significant genotype–phenotype associations with respect to sex, segment length, familiality, or syndromic status. However, patients with a copy-number variant and patients with both a common transcription-enhancer risk genotype and a rare coding variant — the two classes with the highest relative risks — are characterized by an excess representation of males and of nonfamilial cases. The sex ratio in classes with no evident pathogenic alleles or those with rare coding single-nucleotide variants only is approximately 1. This latter class is most often seen in persons with an affected relative (familial disease), which suggests that most segregating pathogenic alleles in affected families are rare coding variants. There was also a greater tendency for Hirschsprung’s disease to be syndromic among patients in higher risk classes than among those in lower risk classes.\n\n【45】Discussion\n----------\n\n【46】Hirschsprung’s disease can arise both from low-penetrance genetic disorders  and from high-penetrance monogenic syndromes.  Risk prediction and genetic counseling therefore depend on family history, risk factors (sex and segment length), and targeted assessment for syndromic features.  Thus, in a small subset of patients, classical genetic testing of _RET_ , _EDNRB_ , and genes that are associated with syndromes may be informative. The results reported here, however, suggest that widespread genomic analyses may be useful for clinical research and improved risk stratification.\n\n【47】Hirschsprung’s disease is usually an isolated condition and unassociated with family history. However, genetic causal factors can be identified in approximately 72% of cases, for which molecular class, frequency, and disease risk can be quantified on the basis of sequence data alone, explaining between 53.7% and 61.9% of population attributable risk. Approximately 21% of patients have multiple risk factors, with the genotype-specific incidence increasing by a factor of more than 100 (risk ranging from approximately 1 in 18,800 to 1 in 120) as the number of genotypic risk factors increases from zero to three. Therefore, we have sufficient quantification of disease risk according to genotype to address questions of underlying causes and genetic architecture and to provide genetic counseling for the highest-risk 21% of patients and their relatives.\n\n【48】We have made considerable strides in understanding the functional basis of Hirschsprung’s disease. The majority of the 32 genes and loci are known to have roles in the development of the enteric nervous system. In contrast, the majority of patients (63.2%) have identifiable pathogenic alleles only within the known RET regulatory network, which lead to decreased RET signaling. The RET effect is potentially even larger, affecting 78.9% of patients, because an additional 5.8% of patients harbor pathogenic alleles in _UBR4_ , a novel E3 ligase gene identified in this study and a candidate for RET signal termination; 5.9% of patients have trisomy 21, which results in an elevated dosage of _SOD1_ , encoding a negative regulator of RET  ; and 4.2% of cases involve _EDNRB_ , which is SOX10-regulated.  Thus, genetic testing of at least the RET regulatory network is warranted for risk stratification.\n\n【49】In order to understand the biology of enteric nervous system cell proliferation, migration, colonization, and neuronal specialization, it is important to understand the steps subsequent to the transition and differentiation of enteric nervous system cells, such as the likely axonal guidance functions of _SEMA3C_ and _SEMA3D_ .  The seven novel genes identified here, all of which are expressed in the human gut at the appropriate developmental stages, probably control some aspects of axonal guidance, cell proliferation, and local inflammation . We hypothesize that screening the genes regulating these processes in early gut development will further resolve the remaining approximately 40% of Hirschsprung’s disease risk.\n\n【50】A continuing challenge in the study of Hirschsprung’s disease is to understand the cellular mechanisms underlying the disease. Whether we consider the persons with the highest (1 in 120) or lowest (1 in 18,800) risk, the absolute risk of disease is still small. What are the cellular events that trigger or prevent aganglionosis, given a particular genotype? A part of the answer is the existence of very rare de novo gene mutations affecting the enteric nervous system,  which require larger cohorts of trios for the detection of an association. However, the incomplete penetrance of most Hirschsprung’s disease variants implies that stochastic, environmental, or epigenetic factors must be important.\n\n【51】In our study, we found that the risk of the complex phenotype that is Hirschsprung’s disease stemmed from a combination of variants in numerous genes and different classes of genetic variants: noncoding variants, single-nucleotide variants and copy-number variants, and both rare and common variants. Despite the current thinking in human medical genetics, most of the risk of Hirschsprung’s disease arose from a common widespread genetic susceptibility, on top of which rare coding and rarer copy-number variants exacerbated the risk. Despite this molecular diversity, the implicated genes clustered, on the basis of their known function, into gene regulatory networks (which, in Hirschsprung’s disease, regulate the transition from enteric neural-crest cells to enteric neuroblasts, axonal guidance, and neuroblast proliferation), a model that may be relevant to the understanding of other complex disorders.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-14 00:21:48", "grab_time": "2024-08-13 23:24:15"}
{"id": 2234299, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "c7698a83-7d7b-46f4-a64c-eba3fb2ed479", "title": "A Half-Century of Progress in Health: The National Academy of Medicine at 50: Health in Aging — Past, Present, and Future", "text": "【0】A Half-Century of Progress in Health: The National Academy of Medicine at 50: Health in Aging — Past, Present, and Future\n### Audio Interview\n\n【1】 Interview with Dr. Linda Fried on advances in research on aging and ongoing efforts to provide older Americans with high-quality prevention and care. \n\n【2】Increases in life expectancy necessitate new scientific understanding of how to both extend and enhance health over the course of our longer lives. Accumulated evidence has laid the groundwork for a new era of prevention and health promotion for an extended health span.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:00:09", "endTime": "2024/08/14 15:00:19", "cost": 10.302}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 23:00:19", "grab_time": "2024-08-13 23:00:07"}
{"id": 2234298, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "e0eeb1db-31b7-4436-97ec-4a13798f631f", "title": "The Effect of High Doses of Calcium-Channel Blockers on Survival in Primary Pulmonary Hypertension", "text": "【0】The Effect of High Doses of Calcium-Channel Blockers on Survival in Primary Pulmonary Hypertension\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】Primary pulmonary hypertension is a progressive, fatal disease of unknown cause. Vasodilator drugs have been used as a treatment, but their efficacy is uncertain.\n\n【3】Methods.\n--------\n\n【4】We treated 64 patients with primary pulmonary hypertension with high doses of calcium-channel blockers. Patients who responded to treatment (defined as those whose pulmonary-artery pressure and pulmonary vascular resistance immediately fell by more than 20 percent after challenge) were treated for up to five years. Their survival was compared with that of the patients who did not respond and with patients enrolled in the National Institutes of Health (NIH) Registry on Primary Pulmonary Hypertension. Warfarin was given to 55 percent of the patients as concurrent therapy, on the basis of a lung scan showing nonuniformity of pulmonary blood flow (47 percent of patients who responded and 57 percent of those who did not respond).\n\n【5】Results.\n--------\n\n【6】Seventeen patients (26 percent) responded to treatment, as indicated by a 39 percent fall in pulmonary-artery pressure and a 53 percent fall in the pulmonary-vascular-resistance index (P<0.001). Nifedipine (mean \\[±SD\\] daily dose, 172±41 mg) was given to 13 patients, and diltiazem (mean daily dose, 720±208 mg) was given to 4 patients. After five years, 94 percent of the patients who responded (16 of 17) were alive, as compared with 55 percent of the patients who did not respond (26 of 47, P = 0.003). The survival of the patients who responded was also significantly better than that of the NIH registry cohort (P = 0.002) and patients from the NIH registry who were treated at the University of Illinois (P = 0.001). The use of warfarin was associated with improved survival (P = 0.025), particularly in the patients who did not respond.\n\n【7】Conclusions.\n------------\n\n【8】This study suggests that high doses of calcium-channel blockers in patients with primary pulmonary hypertension who respond with reductions in pulmonary-artery pressure and pulmonary vascular resistance may improve survival over a five-year period. \n\n【9】Introduction\n------------\n\n【10】PRIMARY pulmonary hypertension is an uncommon disease that is progressive and incurable.  <sup>, </sup>  The recent National Institutes of Health (NIH) Registry on Primary Pulmonary Hypertension documented a median survival of 2.8 years after the diagnosis.  In the 1980s interest in the treatment of primary pulmonary hypertension focused on vasodilator drugs and anticoagulant therapy.  <sup>, </sup>  Although there are numerous descriptions of the short-term hemodynamic effects of many vasodilator drugs, reports documenting long-term effectiveness have been scarce. Anticoagulants have been recommended, but their long-term effectiveness also remains in question.  <sup><a>7 </a></sup> \n\n【11】In 1987 Rich and Brundage conducted a preliminary study of the use of high doses of calcium-channel—blocking drugs in patients with primary pulmonary hypertension  and found that when the drugs were titrated to produce maximal physiologic effects, there were substantial reductions in pulmonary-artery pressure and pulmonary vascular resistance. When followed for one year, patients who had favorable responses had improvement in symptoms as well as regression of right ventricular hypertrophy, documented by electrocardiography and echocardiography. That initial experience has served as the basis for this prospective evaluation of calcium-channel blockers for patients with primary pulmonary hypertension.\n\n【12】Methods\n-------\n\n【13】Treatment Protocol\n------------------\n\n【14】Patients who were enrolled were referred to the University of Illinois between July 1, 1985, and March 31, 1991, and fulfilled the diagnostic criteria for primary pulmonary hypertension.  Informed consent for the study, approved by the University of Illinois Institutional Review Board, was obtained from patients fulfilling the criteria for primary pulmonary hypertension. The patients' response to the regimen for calcium-channel blockers was then evaluated, as previously described in detail.  <sup>, </sup>  In brief, a balloon flotation catheter was placed in the pulmonary artery and a short Teflon cannula in the femoral artery, after which the patients were monitored in the coronary care unit. All pressures and the cardiac output were recorded hourly, and the systemic and pulmonary resistances were calculated according to standard formulas. Patients were given oral doses of nifedipine (20 mg) or diltiazem (60 mg) if they had a resting tachycardia, and the doses were repeated every hour until a favorable response was achieved (defined as a more than 20 percent decrease in pulmonary-artery pressure and pulmonary vascular resistance), unless systemic hypotension or other intolerable side effects precluded further drug testing. The daily dose was then determined for the patients who responded to treatment by halving the initially effective dose and readministering it every six to eight hours. This dosing regimen remained constant throughout the follow-up period. The vital status of all patients evaluated from July 1985 through March 1991 was last determined in October 1991.\n\n【15】Additional therapy for primary pulmonary hypertension and right ventricular failure was prescribed and administered by the attending physicians. Digoxin was prescribed for all patients taking calcium-channel blockers. Diuretics were recommended if the patient had any history of peripheral edema or if the right atrial pressure exceeded 8 mm Hg. Anticoagulant therapy was advised if the lung scan revealed nonuniformity of pulmonary blood flow.  Forty-seven percent of the patients who responded and 57 percent of those who did not respond received anticoagulant therapy.\n\n【16】Comparison Groups\n-----------------\n\n【17】To assess the survival of the patients who were considered to have responded to the regimen of calcium-channel blockers, we compared them with the patients who did not respond and who were evaluated at the University of Illinois from 1985 until 1991 and followed concurrently. We also compared them with the 22 patients who were referred to and followed prospectively at the University of Illinois from 1981 until 1987 as part of the study conducted by the NIH Registry on Primary Pulmonary Hypertension, as well as 166 other patients from the NIH registry who were seen during the same period. Mortality from all causes was used as the primary end point. Patients who responded were grouped according to an intention-to-treat basis.\n\n【18】Statistical Analysis\n--------------------\n\n【19】Differences between base-line and follow-up values for hemodynamic variables in the patients who responded to treatment were evaluated by paired Student's t-test. Differences among the four groups of patients (patients who responded, patients who did not respond, the portion of the NIH registry cohort treated at the University of Illinois, and the NIH registry cohort) in base-line hemodynamic and other variables were evaluated by one-way analysis of variance.  All P values are based on two-sided tests of significance. Most values are expressed as means ±SD.\n\n【20】Kaplan–Meier curves were constructed for each of the four groups of patients, and median survival as well as the probability of survival at one year, three years, and five years was estimated.  Differences in survival among the groups were examined with the log-rank test  and by proportional-hazards regression analysis.  The covariates assessed for possible inclusion in the regression analysis were age, sex, mean pulmonary-artery pressure, mean right atrial pressure, cardiac index, pulmonary vascular resistance, and treatment with warfarin. An algorithm developed by Mickey and Greenland  was used to determine which of these covariates would be included in the regression. The effect of concurrent warfarin therapy on survival was examined in a similar manner by proportional-hazards regression analysis.\n\n【21】The data from the NIH registry were used to develop and validate an equation to predict survival at one, three, and five years on the basis of three hemodynamic variables: mean pulmonary-artery pressure, mean right atrial pressure, and cardiac index.  Differences between the actual survival at one, three, and five years and that predicted on the basis of this equation were determined for the patients who responded, the patients who did not respond, and historical controls. One-way analysis of variance was used to test for differences among these groups with respect to the expected and observed lengths of survival.\n\n【22】Results\n-------\n\n【23】Short-Term Response to Calcium-Channel Blockers\n-----------------------------------------------\n\n【24】Table 1. Base-Line Values and Early and Late Effects of Calcium-Channel Blockers on Mean Hemodynamic Variables in Patients Who Responded to Treatment.\\*\n\n【25】Of the 71 patients given a diagnosis of primary pulmonary hypertension between July 1, 1985, and March 31, 1991, 7 were not tested because they were considered to be too ill at the time of catheterization. They were not included in the analyses. (Similar patients were excluded from the NIH registry cohort.) Of the remaining 64 patients, 17 responded to drug testing with a 39 percent reduction in mean-pulmonary artery pressure, from 58.3±14.2 to 35.5±9.5 mm Hg (P<0.001), and a 53 percent reduction in the pulmonary-vascular-resistance index, from 23.6±11.0 to 11.6±6.4 units (P<0.001) . This was significantly greater (P<0.001 for pulmonary pressure, and P = 0.04 for pulmonary resistance) than the response of the remaining 47 patients, who had only a slight decrease in mean pulmonary-artery pressure (from 60.7±15.4 to 56.8±14.3 mm Hg; 6.4 percent; P = 0.2) and the pulmonary-vascular-resistance index (from 26.5±13.3 to 22.1±12.7 units; 16.6 percent; P = 0.05).\n\n【26】Among the 17 patients who responded to treatment, 13 received a mean daily dose of 172±41 mg of nifedipine (range, 120 to 240) and 4 (Patients 1,7, 11, and 12) received a mean daily dose of 720±208 mg of diltiazem (range, 540 to 900). Thirteen of the 47 patients who did not respond to treatment had more than 20 percent reductions in pulmonary vascular resistance without a reduction in pulmonary-artery pressure and were sent home while receiving calcium-channel blockers. The daily doses used, however, were considerably lower (60 mg of nifedipine in eight patients and 120 mg of diltiazem in five patients).\n\n【27】Long-Term Response to Calcium-Channel Blockers\n----------------------------------------------\n\n【28】All 17 patients who responded were asked to return annually for follow-up testing. Thirteen patients agreed to at least one follow-up catheterization study. One patient declined to return for financial reasons (Patient 17), one patient died before the annual visit (Patient 14), and at the time of the most recent follow-up two patients had been followed for less than 12 months. The patient who died did so after therapy was stopped abruptly, after being treated successfully with 240 mg of nifedipine per day for four months.\n\n【29】Clinical improvement was noted in all patients who returned for follow-up. Functional capacity was judged to be significantly improved as characterized by a change in the New York Heart Association functional class from 2.39±0.5 to 1.45±0.5 (P = 0.02). In addition, regression of right ventricular hypertrophy was documented by a leftward shift in the mean QRS axis (from 106±21 to 83±28 degrees, P = 0.05) and a reduction in the R-wave voltage in precordial Lead V <sub>1 </sub> (from 4.3±2.7 to 2.2±2.2 mm, P = 0.05).\n\n【30】Figure 1. Mean Pulmonary-Artery Pressure and Pulmonary-Vascular-Resistance Index in the Patients Who Had Favorable Responses.\n\n【31】Values shown were measured at base line, after the initial assessment of the effectiveness of the drug, and then periodically for up to five years.\n\n【32】Serial hemodynamic studies also documented the sustained effectiveness of calcium-channel blockers ; the mean pulmonary-artery pressure and pulmonary vascular resistance at follow-up were similar to the values obtained after the initial drug challenge in all but two patients. In contrast, none of the patients who had only a reduction in pulmonary resistance were judged to have had improvements after three months on the basis of a reduction in the severity of dyspnea and fatigue.\n\n【33】Group Comparisons\n-----------------\n\n【34】Table 2. Demographic and Hemodynamic Characteristics of the Four Groups of Patients.\\*\n\n【35】To test whether the base-line demographic or hemodynamic characteristics of the patients who responded differed significantly from those of the patients who did not respond or the two historical control groups, we compared age, sex, and selected baseline hemodynamic variables in the four groups . Mean pulmonary-artery pressure, right atrial pressure, and cardiac index were chosen because they have been shown in previous studies to be most closely associated with survival.  <sup>, </sup>  <sup>, </sup>  There was no significant difference in any of these variables among the groups, although the patients who responded to treatment tended to have lower right atrial pressures and higher cardiac indexes than the other three groups of patients. There also tended to be a greater proportion of women than men in the subgroup of patients enrolled in the NIH registry and treated at the University of Illinois (4.1 to 1), as compared with the patients in the NIH registry cohort who were treated at other centers (1.7 to 1).\n\n【36】Survival\n--------\n\n【37】Of the 64 patients tested with calcium-channel blockers, 73 percent (17 patients who responded and 30 patients who did not respond) were followed one or more years, 34 percent (10 patients who responded and 12 patients who did not respond) three or more years, and 13 percent (2 patients who responded and 6 patients who did not respond) more than five years. As of October 1991, 42 were alive and 22 were dead. Sixteen of the 17 patients who responded (94 percent) were alive, as compared with only 26 of the 47 patients who did not respond to treatment (55 percent). Overall survival among patients who responded to treatment with the calcium-channel blockers was significantly better than that among the patients who did not respond (P = 0.003).\n\n【38】Figure 2. Kaplan–Meier Estimates of Survival among Patients Who Responded to Treatment (Open Circles), Those Who Did Not Respond (Solid Line), Patients Enrolled in the NIH Registry Who Were Treated at the University of Illinois (Solid Circles), and the NIH Registry Cohort (Triangles).\n\n【39】The percentages were calculated every 6 months for 5 1/2 years. The rate of survival was significantly better in the patients who responded (P = 0.003) than in the other groups.\n\n【40】Survival data were tabulated for the 22 University of Illinois patients enrolled in the NIH Registry on Primary Pulmonary Hypertension from 1981 to 1985 and for the remainder of the NIH registry cohort. Kaplan–Meier estimates were made to examine survival in the four groups . Patients who responded to treatment had significantly better survival rates than the patients who did not respond (P = 0.003), the patients enrolled in the NIH registry and treated at the University of Illinois — considered historical controls—(P = 0.001), or the remainder of the NIH registry cohort (P = 0.002). The survival rate among the patients who responded was 94 percent at one, three, and five years, as compared with a one-year survival of 68 percent, a three-year survival of 47 percent, and a five-year survival of 38 percent among the patients in the NIH registry cohort.\n\n【41】Table 3. Projected and Observed Survival in the Four Groups at One, Three, and Five Years.\n\n【42】To test whether the patients who responded reflected a group with a greater likelihood of survival because they had less advanced disease, their prognosis at one, three, and five years was computed from a formula that incorporates mean pulmonary-artery pressure, right atrial pressure, and cardiac index.  Using this equation, we projected that the three-year survival for the patients who responded would be 55 percent, a rate that was significantly less than the observed survival of 94 percent (P<0.001). The projected rates of survival for the patients who did not respond, the University of Illinois historical controls, and the NIH registry cohort were all similar to the actual rates .\n\n【43】Concurrent Therapy\n------------------\n\n【44】Figure 3. Kaplan–Meier Estimates of Survival, According to the Presence or Absence of a Response to Calcium-Channel Blockers and to the Use of Concurrent Therapy with Warfarin.\n\n【45】Overall survival was significantly improved by warfarin therapy (P = 0.025).\n\n【46】To test the possibility that concurrent therapy might confound the assessment of outcome, the 64 study patients were also analyzed with respect to the influence on survival of the concurrent administration of digoxin, diuretics, and warfarin. Digoxin and diuretics were given to more than 90 percent of the patients, and no significant influences were found. Warfarin was administered to 55 percent of the study group (47 percent of the patients who responded and 57 percent of the patients who did not respond). Survival was significantly better among those given anticoagulants than among those not given anticoagulants (P = 0.025) after the analysis was controlled for both base-line hemodynamic variables and the response to calcium-channel blockers . The improvement in survival with anticoagulation was apparent primarily in the patients who did not respond to treatment with calcium-channel blockers, with a one-year survival of 91 percent, three-year survival of 62 percent, and five-year survival of 47 percent, as compared with rates of 52 percent, 31 percent, and 31 percent, respectively, in patients who did not respond who were not treated with anticoagulation.\n\n【47】Discussion\n----------\n\n【48】Primary pulmonary hypertension has always been characterized as a progressive, incurable disease.  Previous reports have often described mean survival as less than four years.  <sup>, </sup>  The recent NIH Registry on Primary Pulmonary Hypertension has documented a median survival of 2.8 years in a large cohort followed prospectively for 7 years. \n\n【49】Over the past decade there has been considerable interest in the use of vasodilator agents in the treatment of patients with primary pulmonary hypertension.  <sup>, </sup>  Observations that pulmonary-artery pressure and pulmonary vascular resistance could be lowered rapidly by a variety of vasodilator agents led to the speculation that vasoconstriction was a feature of the disease.  However, despite numerous case reports describing marked reductions in pulmonary-artery pressure, pulmonary vascular resistance, or both after treatment with a variety of vasodilator drugs, the long-term effectiveness of these drugs had not been demonstrated.\n\n【50】Our initial observation that treatment with calcium-channel blockers titrated to produce maximal physiologic effects was associated with sustained improvement in clinical symptoms and regression of right ventricular hypertrophy  led us to conduct this prospective study so that patients could be followed for five years. A response to treatment was defined as a reduction of more than 20 percent in pulmonary-artery pressure and pulmonary vascular resistance, since it had been previously shown that a reduction in pulmonary vascular resistance alone did not alter the clinical course or survival of patients treated with vasodilator agents. \n\n【51】The overall survival of the 64 patients entered in this study since 1985 was similar to the survival of those followed in the NIH Registry on Primary Pulmonary Hypertension. However, the subgroup of patients who responded to the calcium-channel blockers had markedly better survival during the five-year follow-up than the patients who did not respond, the NIH registry cohort, and the University of Illinois patients enrolled in the NIH registry. To address the possibility that the patients who responded to treatment had less advanced disease than the other three groups, we calculated the expected survival in this group with a formula derived from the data base of the NIH registry.  When these corrections were made, it was still apparent that the patients who responded to treatment had a better-than-expected rate of survival.\n\n【52】Because all patients who responded initially were treated, it remains possible that the ability to respond to high doses of calcium-channel blockers identifies a subgroup of patients with primary pulmonary hypertension who have a better prognosis. This may relate to the nature of the histologic changes or to the severity of vascular changes at the time. Although the information obtained from open-lung biopsies could provide great insight into these possibilities, such information was not available in this study.  In addition, the optimal dose of calcium-channel blockers for primary pulmonary hypertension remains unknown, since this study did not examine whether lower, traditional doses would have been equally effective in our patients.\n\n【53】The patients who responded to treatment had a better quality of life than the patients who did not respond, as reflected by the presence of fewer symptoms, better exercise tolerance, and evidence of the regression of right ventricular hypertrophy. It remains unknown, however, whether this response will persist indefinitely. In addition, we did not examine whether withdrawing the medication or reducing the dose influences long-term survival. It also remains unknown whether calcium-channel blockers taken in high doses for long periods might produce adverse effects.\n\n【54】In two of the patients who responded, the level of hemodynamic improvement was not maintained after long-term treatment. They did not differ from the other patients with respect to any of the base-line variables, which suggests that even in the face of short-term drug effectiveness, other undefined factors may be involved in determining long-term effectiveness or survival. It is interesting, however, that in the other patients, in whom the hemodynamic effects were maintained for the first year, further reductions in pulmonary vascular resistance were noted at serial follow-up studies. The symptoms of the patients who had reductions in pulmonary vascular resistance but who did not have a short-term decrease in mean pulmonary-artery pressure did not appear to be reduced by long-term therapy. It should also be emphasized that calcium-channel blockers may worsen right ventricular function and need to be administered with caution. \n\n【55】Our interest in the effects of anticoagulation in these patients resulted from the observation that long-term warfarin therapy might be associated with improved survival.  In the light of the recent report that thrombosis occurs in the pulmonary vascular bed in patients with primary pulmonary hypertension,  we thought that it was important to assess whether anticoagulation also affected the outcome. When the analysis was corrected for all other variables, the use of anticoagulation was associated with improved survival. This was noted primarily in the patients who did not respond, since the patients who responded had excellent survival rates regardless of whether they were treated concomitantly with warfarin. Since this study was not designed to test the influence of anticoagulation, the results need to be interpreted with caution. They may reflect a bias, in that anticoagulation was generally recommended when the perfusion lung scan was abnormal, and they might thus pertain to a subgroup of patients with a greater likelihood of survival in any case. Nevertheless, we recommend anticoagulant therapy for patients with primary pulmonary hypertension unless the presence of other underlying conditions increases the risk inordinately.\n\n【56】This study demonstrates that primary pulmonary hypertension may not be uniformly fatal as previously believed. Our data suggest that it is important to evaluate the response of all patients with primary pulmonary hypertension to calcium-channel blocking drugs given in appropriate doses. Patients who have a favorable response should continue drug therapy. In the patients who do not respond, long-term anticoagulation may be warranted. Current alternative strategies include the use of the investigational drug prostacyclin,  often as a means of readying the patient for a heart—lung or lung transplantation. Recent reports of the transplantation of a single lung for the treatment of primary pulmonary hypertension suggest that patients who do not respond to therapy with calcium-channel blockers be considered for this procedure.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "7 ", "content": "【0】The Effect of High Doses of Calcium-Channel Blockers on Survival in Primary Pulmonary Hypertension\nAbstract\n--------\n\n【1】Background.\n-----------\n\n【2】Primary pulmonary hypertension is a progressive, fatal disease of unknown cause. Vasodilator drugs have been used as a treatment, but their efficacy is uncertain.\n\n【3】Methods.\n--------\n\n【4】We treated 64 patients with primary pulmonary hypertension with high doses of calcium-channel blockers. Patients who responded to treatment (defined as those whose pulmonary-artery pressure and pulmonary vascular resistance immediately fell by more than 20 percent after challenge) were treated for up to five years. Their survival was compared with that of the patients who did not respond and with patients enrolled in the National Institutes of Health (NIH) Registry on Primary Pulmonary Hypertension. Warfarin was given to 55 percent of the patients as concurrent therapy, on the basis of a lung scan showing nonuniformity of pulmonary blood flow (47 percent of patients who responded and 57 percent of those who did not respond).\n\n【5】Results.\n--------\n\n【6】Seventeen patients (26 percent) responded to treatment, as indicated by a 39 percent fall in pulmonary-artery pressure and a 53 percent fall in the pulmonary-vascular-resistance index (P<0.001). Nifedipine (mean \\[±SD\\] daily dose, 172±41 mg) was given to 13 patients, and diltiazem (mean daily dose, 720±208 mg) was given to 4 patients. After five years, 94 percent of the patients who responded (16 of 17) were alive, as compared with 55 percent of the patients who did not respond (26 of 47, P = 0.003). The survival of the patients who responded was also significantly better than that of the NIH registry cohort (P = 0.002) and patients from the NIH registry who were treated at the University of Illinois (P = 0.001). The use of warfarin was associated with improved survival (P = 0.025), particularly in the patients who did not respond.\n\n【7】Conclusions.\n------------\n\n【8】This study suggests that high doses of calcium-channel blockers in patients with primary pulmonary hypertension who respond with reductions in pulmonary-artery pressure and pulmonary vascular resistance may improve survival over a five-year period. \n\n【9】Introduction\n------------\n\n【10】PRIMARY pulmonary hypertension is an uncommon disease that is progressive and incurable.  <sup>, </sup>  The recent National Institutes of Health (NIH) Registry on Primary Pulmonary Hypertension documented a median survival of 2.8 years after the diagnosis.  In the 1980s interest in the treatment of primary pulmonary hypertension focused on vasodilator drugs and anticoagulant therapy.  <sup>, </sup>  Although there are numerous descriptions of the short-term hemodynamic effects of many vasodilator drugs, reports documenting long-term effectiveness have been scarce. Anticoagulants have been recommended, but their long-term effectiveness also remains in question.  <sup><a>7 </a></sup> \n\n【11】In 1987 Rich and Brundage conducted a preliminary study of the use of high doses of calcium-channel—blocking drugs in patients with primary pulmonary hypertension  and found that when the drugs were titrated to produce maximal physiologic effects, there were substantial reductions in pulmonary-artery pressure and pulmonary vascular resistance. When followed for one year, patients who had favorable responses had improvement in symptoms as well as regression of right ventricular hypertrophy, documented by electrocardiography and echocardiography. That initial experience has served as the basis for this prospective evaluation of calcium-channel blockers for patients with primary pulmonary hypertension.\n\n【12】Methods\n-------\n\n【13】Treatment Protocol\n------------------\n\n【14】Patients who were enrolled were referred to the University of Illinois between July 1, 1985, and March 31, 1991, and fulfilled the diagnostic criteria for primary pulmonary hypertension.  Informed consent for the study, approved by the University of Illinois Institutional Review Board, was obtained from patients fulfilling the criteria for primary pulmonary hypertension. The patients' response to the regimen for calcium-channel blockers was then evaluated, as previously described in detail.  <sup>, </sup>  In brief, a balloon flotation catheter was placed in the pulmonary artery and a short Teflon cannula in the femoral artery, after which the patients were monitored in the coronary care unit. All pressures and the cardiac output were recorded hourly, and the systemic and pulmonary resistances were calculated according to standard formulas. Patients were given oral doses of nifedipine (20 mg) or diltiazem (60 mg) if they had a resting tachycardia, and the doses were repeated every hour until a favorable response was achieved (defined as a more than 20 percent decrease in pulmonary-artery pressure and pulmonary vascular resistance), unless systemic hypotension or other intolerable side effects precluded further drug testing. The daily dose was then determined for the patients who responded to treatment by halving the initially effective dose and readministering it every six to eight hours. This dosing regimen remained constant throughout the follow-up period. The vital status of all patients evaluated from July 1985 through March 1991 was last determined in October 1991.\n\n【15】Additional therapy for primary pulmonary hypertension and right ventricular failure was prescribed and administered by the attending physicians. Digoxin was prescribed for all patients taking calcium-channel blockers. Diuretics were recommended if the patient had any history of peripheral edema or if the right atrial pressure exceeded 8 mm Hg. Anticoagulant therapy was advised if the lung scan revealed nonuniformity of pulmonary blood flow.  Forty-seven percent of the patients who responded and 57 percent of those who did not respond received anticoagulant therapy.\n\n【16】Comparison Groups\n-----------------\n\n【17】To assess the survival of the patients who were considered to have responded to the regimen of calcium-channel blockers, we compared them with the patients who did not respond and who were evaluated at the University of Illinois from 1985 until 1991 and followed concurrently. We also compared them with the 22 patients who were referred to and followed prospectively at the University of Illinois from 1981 until 1987 as part of the study conducted by the NIH Registry on Primary Pulmonary Hypertension, as well as 166 other patients from the NIH registry who were seen during the same period. Mortality from all causes was used as the primary end point. Patients who responded were grouped according to an intention-to-treat basis.\n\n【18】Statistical Analysis\n--------------------\n\n【19】Differences between base-line and follow-up values for hemodynamic variables in the patients who responded to treatment were evaluated by paired Student's t-test. Differences among the four groups of patients (patients who responded, patients who did not respond, the portion of the NIH registry cohort treated at the University of Illinois, and the NIH registry cohort) in base-line hemodynamic and other variables were evaluated by one-way analysis of variance.  All P values are based on two-sided tests of significance. Most values are expressed as means ±SD.\n\n【20】Kaplan–Meier curves were constructed for each of the four groups of patients, and median survival as well as the probability of survival at one year, three years, and five years was estimated.  Differences in survival among the groups were examined with the log-rank test  and by proportional-hazards regression analysis.  The covariates assessed for possible inclusion in the regression analysis were age, sex, mean pulmonary-artery pressure, mean right atrial pressure, cardiac index, pulmonary vascular resistance, and treatment with warfarin. An algorithm developed by Mickey and Greenland  was used to determine which of these covariates would be included in the regression. The effect of concurrent warfarin therapy on survival was examined in a similar manner by proportional-hazards regression analysis.\n\n【21】The data from the NIH registry were used to develop and validate an equation to predict survival at one, three, and five years on the basis of three hemodynamic variables: mean pulmonary-artery pressure, mean right atrial pressure, and cardiac index.  Differences between the actual survival at one, three, and five years and that predicted on the basis of this equation were determined for the patients who responded, the patients who did not respond, and historical controls. One-way analysis of variance was used to test for differences among these groups with respect to the expected and observed lengths of survival.\n\n【22】Results\n-------\n\n【23】Short-Term Response to Calcium-Channel Blockers\n-----------------------------------------------\n\n【24】Table 1. Base-Line Values and Early and Late Effects of Calcium-Channel Blockers on Mean Hemodynamic Variables in Patients Who Responded to Treatment.\\*\n\n【25】Of the 71 patients given a diagnosis of primary pulmonary hypertension between July 1, 1985, and March 31, 1991, 7 were not tested because they were considered to be too ill at the time of catheterization. They were not included in the analyses. (Similar patients were excluded from the NIH registry cohort.) Of the remaining 64 patients, 17 responded to drug testing with a 39 percent reduction in mean-pulmonary artery pressure, from 58.3±14.2 to 35.5±9.5 mm Hg (P<0.001), and a 53 percent reduction in the pulmonary-vascular-resistance index, from 23.6±11.0 to 11.6±6.4 units (P<0.001) . This was significantly greater (P<0.001 for pulmonary pressure, and P = 0.04 for pulmonary resistance) than the response of the remaining 47 patients, who had only a slight decrease in mean pulmonary-artery pressure (from 60.7±15.4 to 56.8±14.3 mm Hg; 6.4 percent; P = 0.2) and the pulmonary-vascular-resistance index (from 26.5±13.3 to 22.1±12.7 units; 16.6 percent; P = 0.05).\n\n【26】Among the 17 patients who responded to treatment, 13 received a mean daily dose of 172±41 mg of nifedipine (range, 120 to 240) and 4 (Patients 1,7, 11, and 12) received a mean daily dose of 720±208 mg of diltiazem (range, 540 to 900). Thirteen of the 47 patients who did not respond to treatment had more than 20 percent reductions in pulmonary vascular resistance without a reduction in pulmonary-artery pressure and were sent home while receiving calcium-channel blockers. The daily doses used, however, were considerably lower (60 mg of nifedipine in eight patients and 120 mg of diltiazem in five patients).\n\n【27】Long-Term Response to Calcium-Channel Blockers\n----------------------------------------------\n\n【28】All 17 patients who responded were asked to return annually for follow-up testing. Thirteen patients agreed to at least one follow-up catheterization study. One patient declined to return for financial reasons (Patient 17), one patient died before the annual visit (Patient 14), and at the time of the most recent follow-up two patients had been followed for less than 12 months. The patient who died did so after therapy was stopped abruptly, after being treated successfully with 240 mg of nifedipine per day for four months.\n\n【29】Clinical improvement was noted in all patients who returned for follow-up. Functional capacity was judged to be significantly improved as characterized by a change in the New York Heart Association functional class from 2.39±0.5 to 1.45±0.5 (P = 0.02). In addition, regression of right ventricular hypertrophy was documented by a leftward shift in the mean QRS axis (from 106±21 to 83±28 degrees, P = 0.05) and a reduction in the R-wave voltage in precordial Lead V <sub>1 </sub> (from 4.3±2.7 to 2.2±2.2 mm, P = 0.05).\n\n【30】Figure 1. Mean Pulmonary-Artery Pressure and Pulmonary-Vascular-Resistance Index in the Patients Who Had Favorable Responses.\n\n【31】Values shown were measured at base line, after the initial assessment of the effectiveness of the drug, and then periodically for up to five years.\n\n【32】Serial hemodynamic studies also documented the sustained effectiveness of calcium-channel blockers ; the mean pulmonary-artery pressure and pulmonary vascular resistance at follow-up were similar to the values obtained after the initial drug challenge in all but two patients. In contrast, none of the patients who had only a reduction in pulmonary resistance were judged to have had improvements after three months on the basis of a reduction in the severity of dyspnea and fatigue.\n\n【33】Group Comparisons\n-----------------\n\n【34】Table 2. Demographic and Hemodynamic Characteristics of the Four Groups of Patients.\\*\n\n【35】To test whether the base-line demographic or hemodynamic characteristics of the patients who responded differed significantly from those of the patients who did not respond or the two historical control groups, we compared age, sex, and selected baseline hemodynamic variables in the four groups . Mean pulmonary-artery pressure, right atrial pressure, and cardiac index were chosen because they have been shown in previous studies to be most closely associated with survival.  <sup>, </sup>  <sup>, </sup>  There was no significant difference in any of these variables among the groups, although the patients who responded to treatment tended to have lower right atrial pressures and higher cardiac indexes than the other three groups of patients. There also tended to be a greater proportion of women than men in the subgroup of patients enrolled in the NIH registry and treated at the University of Illinois (4.1 to 1), as compared with the patients in the NIH registry cohort who were treated at other centers (1.7 to 1).\n\n【36】Survival\n--------\n\n【37】Of the 64 patients tested with calcium-channel blockers, 73 percent (17 patients who responded and 30 patients who did not respond) were followed one or more years, 34 percent (10 patients who responded and 12 patients who did not respond) three or more years, and 13 percent (2 patients who responded and 6 patients who did not respond) more than five years. As of October 1991, 42 were alive and 22 were dead. Sixteen of the 17 patients who responded (94 percent) were alive, as compared with only 26 of the 47 patients who did not respond to treatment (55 percent). Overall survival among patients who responded to treatment with the calcium-channel blockers was significantly better than that among the patients who did not respond (P = 0.003).\n\n【38】Figure 2. Kaplan–Meier Estimates of Survival among Patients Who Responded to Treatment (Open Circles), Those Who Did Not Respond (Solid Line), Patients Enrolled in the NIH Registry Who Were Treated at the University of Illinois (Solid Circles), and the NIH Registry Cohort (Triangles).\n\n【39】The percentages were calculated every 6 months for 5 1/2 years. The rate of survival was significantly better in the patients who responded (P = 0.003) than in the other groups.\n\n【40】Survival data were tabulated for the 22 University of Illinois patients enrolled in the NIH Registry on Primary Pulmonary Hypertension from 1981 to 1985 and for the remainder of the NIH registry cohort. Kaplan–Meier estimates were made to examine survival in the four groups . Patients who responded to treatment had significantly better survival rates than the patients who did not respond (P = 0.003), the patients enrolled in the NIH registry and treated at the University of Illinois — considered historical controls—(P = 0.001), or the remainder of the NIH registry cohort (P = 0.002). The survival rate among the patients who responded was 94 percent at one, three, and five years, as compared with a one-year survival of 68 percent, a three-year survival of 47 percent, and a five-year survival of 38 percent among the patients in the NIH registry cohort.\n\n【41】Table 3. Projected and Observed Survival in the Four Groups at One, Three, and Five Years.\n\n【42】To test whether the patients who responded reflected a group with a greater likelihood of survival because they had less advanced disease, their prognosis at one, three, and five years was computed from a formula that incorporates mean pulmonary-artery pressure, right atrial pressure, and cardiac index.  Using this equation, we projected that the three-year survival for the patients who responded would be 55 percent, a rate that was significantly less than the observed survival of 94 percent (P<0.001). The projected rates of survival for the patients who did not respond, the University of Illinois historical controls, and the NIH registry cohort were all similar to the actual rates .\n\n【43】Concurrent Therapy\n------------------\n\n【44】Figure 3. Kaplan–Meier Estimates of Survival, According to the Presence or Absence of a Response to Calcium-Channel Blockers and to the Use of Concurrent Therapy with Warfarin.\n\n【45】Overall survival was significantly improved by warfarin therapy (P = 0.025).\n\n【46】To test the possibility that concurrent therapy might confound the assessment of outcome, the 64 study patients were also analyzed with respect to the influence on survival of the concurrent administration of digoxin, diuretics, and warfarin. Digoxin and diuretics were given to more than 90 percent of the patients, and no significant influences were found. Warfarin was administered to 55 percent of the study group (47 percent of the patients who responded and 57 percent of the patients who did not respond). Survival was significantly better among those given anticoagulants than among those not given anticoagulants (P = 0.025) after the analysis was controlled for both base-line hemodynamic variables and the response to calcium-channel blockers . The improvement in survival with anticoagulation was apparent primarily in the patients who did not respond to treatment with calcium-channel blockers, with a one-year survival of 91 percent, three-year survival of 62 percent, and five-year survival of 47 percent, as compared with rates of 52 percent, 31 percent, and 31 percent, respectively, in patients who did not respond who were not treated with anticoagulation.\n\n【47】Discussion\n----------\n\n【48】Primary pulmonary hypertension has always been characterized as a progressive, incurable disease.  Previous reports have often described mean survival as less than four years.  <sup>, </sup>  The recent NIH Registry on Primary Pulmonary Hypertension has documented a median survival of 2.8 years in a large cohort followed prospectively for 7 years. \n\n【49】Over the past decade there has been considerable interest in the use of vasodilator agents in the treatment of patients with primary pulmonary hypertension.  <sup>, </sup>  Observations that pulmonary-artery pressure and pulmonary vascular resistance could be lowered rapidly by a variety of vasodilator agents led to the speculation that vasoconstriction was a feature of the disease.  However, despite numerous case reports describing marked reductions in pulmonary-artery pressure, pulmonary vascular resistance, or both after treatment with a variety of vasodilator drugs, the long-term effectiveness of these drugs had not been demonstrated.\n\n【50】Our initial observation that treatment with calcium-channel blockers titrated to produce maximal physiologic effects was associated with sustained improvement in clinical symptoms and regression of right ventricular hypertrophy  led us to conduct this prospective study so that patients could be followed for five years. A response to treatment was defined as a reduction of more than 20 percent in pulmonary-artery pressure and pulmonary vascular resistance, since it had been previously shown that a reduction in pulmonary vascular resistance alone did not alter the clinical course or survival of patients treated with vasodilator agents. \n\n【51】The overall survival of the 64 patients entered in this study since 1985 was similar to the survival of those followed in the NIH Registry on Primary Pulmonary Hypertension. However, the subgroup of patients who responded to the calcium-channel blockers had markedly better survival during the five-year follow-up than the patients who did not respond, the NIH registry cohort, and the University of Illinois patients enrolled in the NIH registry. To address the possibility that the patients who responded to treatment had less advanced disease than the other three groups, we calculated the expected survival in this group with a formula derived from the data base of the NIH registry.  When these corrections were made, it was still apparent that the patients who responded to treatment had a better-than-expected rate of survival.\n\n【52】Because all patients who responded initially were treated, it remains possible that the ability to respond to high doses of calcium-channel blockers identifies a subgroup of patients with primary pulmonary hypertension who have a better prognosis. This may relate to the nature of the histologic changes or to the severity of vascular changes at the time. Although the information obtained from open-lung biopsies could provide great insight into these possibilities, such information was not available in this study.  In addition, the optimal dose of calcium-channel blockers for primary pulmonary hypertension remains unknown, since this study did not examine whether lower, traditional doses would have been equally effective in our patients.\n\n【53】The patients who responded to treatment had a better quality of life than the patients who did not respond, as reflected by the presence of fewer symptoms, better exercise tolerance, and evidence of the regression of right ventricular hypertrophy. It remains unknown, however, whether this response will persist indefinitely. In addition, we did not examine whether withdrawing the medication or reducing the dose influences long-term survival. It also remains unknown whether calcium-channel blockers taken in high doses for long periods might produce adverse effects.\n\n【54】In two of the patients who responded, the level of hemodynamic improvement was not maintained after long-term treatment. They did not differ from the other patients with respect to any of the base-line variables, which suggests that even in the face of short-term drug effectiveness, other undefined factors may be involved in determining long-term effectiveness or survival. It is interesting, however, that in the other patients, in whom the hemodynamic effects were maintained for the first year, further reductions in pulmonary vascular resistance were noted at serial follow-up studies. The symptoms of the patients who had reductions in pulmonary vascular resistance but who did not have a short-term decrease in mean pulmonary-artery pressure did not appear to be reduced by long-term therapy. It should also be emphasized that calcium-channel blockers may worsen right ventricular function and need to be administered with caution. \n\n【55】Our interest in the effects of anticoagulation in these patients resulted from the observation that long-term warfarin therapy might be associated with improved survival.  In the light of the recent report that thrombosis occurs in the pulmonary vascular bed in patients with primary pulmonary hypertension,  we thought that it was important to assess whether anticoagulation also affected the outcome. When the analysis was corrected for all other variables, the use of anticoagulation was associated with improved survival. This was noted primarily in the patients who did not respond, since the patients who responded had excellent survival rates regardless of whether they were treated concomitantly with warfarin. Since this study was not designed to test the influence of anticoagulation, the results need to be interpreted with caution. They may reflect a bias, in that anticoagulation was generally recommended when the perfusion lung scan was abnormal, and they might thus pertain to a subgroup of patients with a greater likelihood of survival in any case. Nevertheless, we recommend anticoagulant therapy for patients with primary pulmonary hypertension unless the presence of other underlying conditions increases the risk inordinately.\n\n【56】This study demonstrates that primary pulmonary hypertension may not be uniformly fatal as previously believed. Our data suggest that it is important to evaluate the response of all patients with primary pulmonary hypertension to calcium-channel blocking drugs given in appropriate doses. Patients who have a favorable response should continue drug therapy. In the patients who do not respond, long-term anticoagulation may be warranted. Current alternative strategies include the use of the investigational drug prostacyclin,  often as a means of readying the patient for a heart—lung or lung transplantation. Recent reports of the transplantation of a single lung for the treatment of primary pulmonary hypertension suggest that patients who do not respond to therapy with calcium-channel blockers be considered for this procedure.", "index": 2945, "show": true, "start": 2945, "end": 2947, "province": ["文本干净度", "页码/数字"], "isEdit": false, "comment": "全文"}]}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-14 00:20:16", "grab_time": "2024-08-13 23:24:48"}
{"id": 2234297, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "757cc431-59a5-4136-a484-82cf2323f62f", "title": "Reducing LDL with PCSK9 Inhibitors — The Clinical Benefit of Lipid Drugs", "text": "【0】Reducing LDL with PCSK9 Inhibitors — The Clinical Benefit of Lipid Drugs\n### Audio Interview\n\n【1】 Interview with Dr. Kevin Schulman on the recent approval of two PCSK9 inhibitors and what their prices could mean for insurance premiums. \n\n【2】Despite limitations in the data on the two new PCSK9 inhibitors, an FDA advisory committee has voted to approve alirocumab and evolocumab. But committee members emphatically stated that LDL cholesterol levels are not a reliable surrogate for cardiovascular benefit.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:00:23", "endTime": "2024/08/14 15:00:32", "cost": 9.031}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 23:00:31", "grab_time": "2024-08-13 23:00:22"}
{"id": 2234296, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "d64205cb-ec63-4c1f-a776-f1088d9d4a26", "title": "Rapid Prenatal Diagnosis of Sickle Cell Anemia by a New Method of DNA Analysis", "text": "【0】Rapid Prenatal Diagnosis of Sickle Cell Anemia by a New Method of DNA Analysis\nAbstract\n--------\n\n【1】We have used a new method of DNA analysis for the rapid prenatal diagnosis of sickle cell anemia in two fetuses at risk for this disease. This method of detecting the sickle gene is a modification of standard restriction-enzyme techniques and requires only a small amount of DNA.\n\n【2】The first step involves a 200,000-fold enzymatic amplification of the specific β-globin DNA sequences that may carry the sickle mutation. This provides a sufficient quantity of DNA for the analysis. Next, a short Radio-labeled synthetic DNA sequence homologous to normal β-globin gene sequences is hybridized to the amplified target sequences. The hybrid \"duplexes\" are then digested sequentially with two restriction endonucleases. The presence of β <sup>A </sup> \\- or β <sup>s </sup> \\-globin gene sequences in the amplified target DNA from the patient determines whether the β <sup>A </sup> hybridization probe anneals perfectly or with a single nucleotide mismatch. This difference affects the restriction-enzyme digestion of the DNA and the size of the resulting Radio-labeled digestion products, which can be distinguished by electrophoresis followed by autoradiography.\n\n【3】This method is sufficiently sensitive and rapid that the prenatal diagnosis of sickle cell anemia can be made on the same day that the fetal DNA is made available. It can also be applied to the diagnosis of hemoglobin C disease.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:08:39", "endTime": "2024/08/14 15:08:47", "cost": 8.341}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 23:08:47", "grab_time": "2024-08-13 23:08:39"}
{"id": 2234295, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "d373c0ca-80a4-414b-8753-19743ffcafb1", "title": "Acute Pancreatitis", "text": "【0】Acute Pancreatitis\nA 56-year-old woman presents with severe epigastric abdominal pain and vomiting of 14 hours' duration, symptoms that developed shortly after dinner the previous evening. She has no history of alcohol use, takes no medications, and has no family history of pancreatitis. On physical examination, she has a heart rate of 110 beats per minute and moderate epigastric abdominal tenderness without peritoneal signs. The white-cell count is 16,500 per cubic millimeter, and the hematocrit is 49 percent. Amylase, lipase, alanine aminotransferase, and lactate dehydrogenase levels are elevated. Calcium, albumin, triglyceride, and electrolyte values are normal. How should this patient be further evaluated and treated?", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:19:26", "endTime": "2024/08/14 15:19:40", "cost": 14.498}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 23:19:40", "grab_time": "2024-08-13 23:19:25"}
{"id": 2234294, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "d3729264-a12b-476a-acb2-f359468922be", "title": "Long-Term Total Parenteral Nutrition in Infants", "text": "【0】Long-Term Total Parenteral Nutrition in Infants\nAbstract\n--------\n\n【1】An intravenous amino acid, hypertonic glucose, electrolyte and vitamin solution was used in 14 infants under two months of age in whom oral intake was completely withheld for as long as 60 days. Included were infants with complicated intestinal obstruction, bowel fistulas, intraperitoneal sepsis and chronic diarrhea, as well as three with prenatal rupture of an omphalocele. In the past, a high mortality has been observed in such critically ill infants. In this series, all infants survived. Studies of metabolic balance revealed that the intravenous mixture was capable of maintaining satisfactory nutrition in spite of repeated surgical procedures, sepsis and enteric losses. No serious glycosuria, osmotic diuresis or adverse side effects were detected.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:58:01", "endTime": "2024/08/14 14:58:28", "cost": 27.129}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 22:58:29", "grab_time": "2024-08-13 22:58:01"}
{"id": 2234293, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "9927fa02-dc92-428d-aeea-bbacde704d6c", "title": "Should We Practice What We Profess? Care near the End of Life", "text": "【0】Should We Practice What We Profess? Care near the End of Life\nVast majorities of U.S. physicians and other Americans say they'd like to avoid high-intensity care at the end of life, but these wishes are frequently overridden. An Institute of Medicine committee has concluded that major changes in the health care system are needed.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:41:19", "endTime": "2024/08/14 14:43:06", "cost": 107.258}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 22:43:06", "grab_time": "2024-08-13 22:41:19"}
{"id": 2234292, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "f87d1640-7dd6-4a25-adb2-382e810f733b", "title": "Early versus Standard Antiretroviral Therapy for HIV-Infected Adults in Haiti", "text": "【0】Early versus Standard Antiretroviral Therapy for HIV-Infected Adults in Haiti\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】For adults with human immunodeficiency virus (HIV) infection who have CD4+ T-cell counts that are greater than 200 and less than 350 per cubic millimeter and who live in areas with limited resources, the optimal time to initiate antiretroviral therapy remains uncertain.\n\n【3】Methods\n-------\n\n【4】We conducted a randomized, open-label trial of early initiation of antiretroviral therapy, as compared with the standard timing for initiation of therapy, among HIV-infected adults in Haiti who had a confirmed CD4+ T-cell count that was greater than 200 and less than 350 per cubic millimeter at baseline and no history of an acquired immunodeficiency syndrome (AIDS) illness. The primary study end point was survival. The early-treatment group began taking zidovudine, lamivudine, and efavirenz therapy within 2 weeks after enrollment. The standard-treatment group started the same regimen of antiretroviral therapy when their CD4+ T-cell count fell to 200 per cubic millimeter or less or when clinical AIDS developed. Participants in both groups underwent monthly follow-up assessments and received isoniazid and trimethoprim–sulfamethoxazole prophylaxis with nutritional support.\n\n【5】Results\n-------\n\n【6】Between 2005 and 2008, a total of 816 participants — 408 per group — were enrolled and were followed for a median of 21 months. The CD4+ T-cell count at enrollment was approximately 280 per cubic millimeter in both groups. There were 23 deaths in the standard-treatment group, as compared with 6 in the early-treatment group (hazard ratio with standard treatment, 4.0; 95% confidence interval \\[CI\\], 1.6 to 9.8; P=0.001). There were 36 incident cases of tuberculosis in the standard-treatment group, as compared with 18 in the early-treatment group (hazard ratio, 2.0; 95% CI, 1.2 to 3.6; P=0.01).\n\n【7】Conclusions\n-----------\n\n【8】Early initiation of antiretroviral therapy decreased the rates of death and incident tuberculosis. Access to antiretroviral therapy should be expanded to include all HIV-infected adults who have CD4+ T-cell counts of less than 350 per cubic millimeter, including those who live in areas with limited resources. \n\n【9】Introduction\n------------\n\n【10】The optimal time to initiate antiretroviral therapy in adults who are infected with human immunodeficiency virus (HIV) remains uncertain. There have been no randomized trials to determine the optimal time to start antiretroviral therapy in adults who have CD4+ T-cell counts that are greater than 200 and less than 350 per cubic millimeter. Furthermore, there are few data on the optimal time to start antiretroviral therapy in persons who live in locations with limited resources, where high rates of tuberculosis, malnutrition, and coinfection with tropical diseases may alter the natural history of HIV disease and the optimal time to initiate therapy. Therefore, international guidelines differ on when to start antiretroviral therapy. \n\n【11】In Haiti, following World Health Organization (WHO) guidelines, the first-line regimen of antiretroviral therapy, which consists of zidovudine, lamivudine, and efavirenz, is initiated when the CD4+ T-cell count in a patient with HIV type 1 (HIV-1) infection is 200 per cubic millimeter or less or when clinical acquired immunodeficiency syndrome (AIDS) develops.  Among patients who are treated according to this standard strategy for the initiation of antiretroviral therapy, approximately 80% are alive at 5 years.  We conducted a randomized clinical trial in Haiti to determine whether early initiation of antiretroviral therapy, as compared with the standard timing for the initiation of therapy, improves survival.\n\n【12】Methods\n-------\n\n【13】Study Design and Setting\n------------------------\n\n【14】We conducted a randomized, open-label, controlled trial of early initiation of antiretroviral therapy, as compared with the standard timing for initiation of therapy, among HIV-infected adults with a CD4+ T-cell count that was greater than 200 and less than 350 per cubic millimeter and no history of an AIDS illness. The primary study end point was survival. The study was conducted at the center of the Haitian Group for the Study of Kaposi's Sarcoma and Opportunistic Infections (GHESKIO) in Port au Prince, Haiti.  The study was approved by the institutional review boards at Weill Cornell Medical College and GHESKIO. Two of the antiretroviral medications, zidovudine and lamivudine, were donated by GlaxoSmithKline, and one, lopinavir boosted by ritonavir, was donated by Abbott. (The other antiretroviral medications were donated by the Global Fund to Fight AIDS, Tuberculosis, and Malaria.) Neither GlaxoSmithKline nor Abbott had a role in the design of the study, the accrual or analysis of the data, or the preparation of the manuscript.\n\n【15】Inclusion and Exclusion Criteria\n--------------------------------\n\n【16】Subjects could be included in the study if they were infected with HIV, were at least 18 years of age, and had a confirmed CD4+ T-cell count that was greater than 200 and less than 350 per cubic millimeter within 45 days before enrollment. Subjects were excluded if they had a history of an AIDS-defining illness (stage 4 in the WHO staging system)  or had received antiretroviral therapy previously.\n\n【17】Recruitment and Randomization\n-----------------------------\n\n【18】Subjects were recruited at GHESKIO from August 2005 through July 2008. After the subjects had provided written informed consent,  the study team performed a screening evaluation, and eligible subjects were enrolled. Participants were randomly assigned with the use of a computer-generated random-numbers list, in a  ratio, to either early initiation of treatment (early-treatment group) or the standard timing for initiation of treatment (standard-treatment group).\n\n【19】Study Intervention\n------------------\n\n【20】Subjects in both groups were seen monthly by a clinician and received the package of services provided to all HIV-1–infected patients at GHESKIO. Prophylactic treatment with trimethoprim–sulfamethoxazole was administered in all participants,  and isoniazid was given to those who had a positive purified protein derivative (PPD) skin test.  Participants received nutritional support that consisted of daily multivitamins and a monthly food basket containing rice, beans, oil, and meat.  To encourage participants to continue medical follow-up and remain in the study, field workers visited their residences at the time of enrollment and in the case of a missed visit. Participants were counseled about adherence to therapy and about the importance of returning to the clinic whenever they had symptoms.\n\n【21】If a participant had a cough or symptoms that were suggestive of tuberculosis at any time during the study, a chest radiograph was obtained; in addition, three sputum smears were examined for acid-fast bacilli with the use of Ziehl–Neelsen staining and were cultured for _Mycobacterium tuberculosis_ on Löwenstein–Jensen medium.  Subjects with active tuberculosis received directly observed therapy consisting of daily administration of four drugs (isoniazid, rifampin, ethambutol, and pyrazinamide) for a 2-month initiation phase, followed by daily administration of two drugs (isoniazid and rifampin) for a 4-month continuation phase.  Subjects with drug-resistant tuberculosis were treated according to WHO guidelines. \n\n【22】The early-treatment group began treatment within 2 weeks after enrollment. Treatment consisted of lamivudine (150 mg every 12 hours) and zidovudine (300 mg every 12 hours), in a fixed-dose combination, and efavirenz (600 mg every 24 hours, at bedtime). For the first 2 months, antiretroviral therapy was provided under modified direct observation: receipt of the morning dose was observed at the study participant's home by a GHESKIO field worker; the evening dose was left with the participant and the participant was not observed while taking the medication.\n\n【23】If a drug caused toxic effects in a subject, the following drug substitution could be made: stavudine as a substitute for zidovudine and nevirapine or lopinavir, boosted by ritonavir, as a substitute for efavirenz. Among participants who were receiving rifampin for the treatment of active tuberculosis, the dose of efavirenz was increased from 600 mg every 24 hours to 800 mg every 24 hours. The failure of antiretroviral therapy was defined according to the WHO criteria: a confirmed decrease in the CD4+ T-cell count to a level that was 50% below the peak count or to a level below the baseline count, or a new AIDS illness during receipt of antiretroviral therapy.  Participants in whom first-line therapy failed were switched to the second-line regimen of abacavir, didanosine, and lopinavir boosted by ritonavir.\n\n【24】Participants in the standard-treatment group started therapy when they had a single CD4+ T-cell count of 200 per cubic millimeter or less or when an AIDS-defining illness developed. The treatment consisted of the same first-line regimen of antiretroviral therapy as that used for the early-treatment group (lamivudine, zidovudine, and efavirenz). In addition, for women in the standard-treatment group who became pregnant, antiretroviral therapy was initiated to prevent transmission of HIV to the fetus and was continued throughout the study, but nevirapine was substituted for efavirenz. Other drug substitutions and the second-line regimen were the same as those for the early-treatment group.\n\n【25】Study End Points\n----------------\n\n【26】The primary study end point was survival. Death was documented in one of the following ways: an obituary notice, an autopsy report, a hospital death certificate, or a report from a contact documenting oral communication with the subject's health care provider or family member. Incident tuberculosis was a secondary study end point. We used the case definition of the American Thoracic Society, as described previously. \n\n【27】Clinical and Laboratory Measurements\n------------------------------------\n\n【28】Adherence to antiretroviral medications was measured with the use of a questionnaire about medication adherence, described previously, that was translated into Haitian Creole. The questionnaire was administered every 6 months. \n\n【29】Serious adverse events and their relationship to antiretroviral medications were assessed, were graded according to the grading system in the National Institutes of Health, Division of AIDS, manual for the grading of adverse events, and were reported at the standard level of reporting.  We report all severe (grade 3) and life-threatening (grade 4) suspected drug reactions.\n\n【30】Laboratory tests that were performed included a baseline CD4+ T-cell count, a complete blood count, and measurements of aspartate aminotransferase, alanine aminotransferase, and creatinine. A complete blood count, liver-function tests, and serum chemical tests were repeated every 3 months for participants who were taking antiretroviral drugs. The CD4+ T-cell count was repeated for all participants every 6 months or more frequently, if requested by the primary care clinician.\n\n【31】Statistical Analysis\n--------------------\n\n【32】Information from clinical and laboratory case-report forms was entered electronically in Haiti through an Internet interface, and the data were managed by Frontier Science and Technology Research Foundation in New York. Data were exported into SAS software (SAS Institute) for analysis.\n\n【33】The study was designed to accumulate a fixed number of end points. We estimated that with a sample of 794 participants (397 per group), the study would have 80% power to show a hazard ratio for survival with early treatment of 2.0 after 65 deaths had occurred, with a two-sided type I error rate of 5%. Three interim analyses were scheduled, after 16, 32, and 48 deaths had occurred. The interim analyses, which were performed by investigators who were unaware of the treatment assignments, were reviewed by members of the data and safety monitoring board of the National Institutes of Health, Division of AIDS. Prespecified stopping rules were based on the O'Brien–Fleming boundary for significance, with Lan–DeMets flexible spending functions. \n\n【34】We hypothesized that early initiation of antiretroviral therapy, as compared with the standard timing for initiation of therapy, would improve survival. All analyses were based on the intention-to-treat principle. The primary study end point, survival, was analyzed with the use of standard Kaplan–Meier methods, and differences between the two survival curves were evaluated with the use of the log-rank test, as specified in the protocol.  Cox proportional-hazards regression analysis was used to estimate the hazard ratio with 95% confidence intervals. We used the same methods in the analysis of the secondary outcome of incident tuberculosis. For comparison of other proportions, we used Fisher's exact test. Two-sided hypotheses and tests were adopted for all statistical inferences.\n\n【35】Results\n-------\n\n【36】Recruitment and Baseline Characteristics\n----------------------------------------\n\n【37】Figure 1. Screening, Randomization, and Follow-up.\n\n【38】ART denotes antiretroviral therapy.Table 1.  Table 1. Baseline Characteristics of the Study Participants.\n\n【39】A total of 1066 subjects were screened between August 2005 and July 2008, and 816 were enrolled in the study . The median age of enrolled subjects was 40 years, and 470 (58%) were women. The median CD4+ T-cell count was 281 per cubic millimeter. The baseline characteristics were similar between the two groups .\n\n【40】Status at the Time of Analysis\n------------------------------\n\n【41】The data and safety monitoring board reviewed the second interim analysis, which included data accumulated up to May 1, 2009; there were 29 deaths at that point. The trial crossed the prespecified stopping boundary for a difference in survival between the groups, and the data and safety monitoring board recommended that the trial be stopped and that all participants in the standard-treatment group be given antiretroviral therapy.\n\n【42】The median length of follow-up was 21 months (range, 1 to 44). Of the 408 participants in the early-treatment group, 383 (94%) continued in follow-up to the end of the study, 6 (1%) died, and 19 (5%) were lost to follow-up. Of the 408 participants in the standard-treatment group, 367 (90%) were included in the follow-up assessments, 23 (6%) died, and 18 (4%) were lost to follow-up.\n\n【43】Of the 408 participants in the standard-treatment group, 160 (39%) met the criteria for initiation of antiretroviral therapy and began receiving antiretroviral drugs during the course of the study. Of the 408 participants in the standard-treatment group, 118 (29%) received isoniazid prophylaxis because of a positive tuberculin skin test and 400 (98%) received trimethoprim–sulfamethoxazole prophylaxis. Of the 408 participants in the early-treatment group, 99 (24%) received isoniazid prophylaxis and 388 (95%) received trimethoprim–sulfamethoxazole prophylaxis. Of the 327 participants in the early-treatment group who had at least 12 months of follow-up, 294 (90%) were adherent to antiretroviral therapy (i.e., received more than 95% of antiretroviral medications in the first year of antiretroviral therapy); of the 60 participants in the standard-treatment group who received antiretroviral therapy for at least 12 months, 57 (95%) were adherent to the therapy.\n\n【44】Survival\n--------\n\n【45】Figure 2. Kaplan–Meier Estimates of Survival in the Early-Treatment and Standard-Treatment Groups.\n\n【46】There were 29 deaths during the course of the study — 23 in the standard-treatment group and 6 in the early-treatment group (P=0.001 by the log-rank test). In the Kaplan–Meier analysis, 98% of the participants in the early-treatment group and 93% in the standard-treatment group were alive at 36 months . The unadjusted hazard ratio for the risk of death with standard treatment as compared with early treatment was 4.0 (95% confidence interval \\[CI\\], 1.6 to 9.8).\n\n【47】The causes of death among the 23 participants in the standard-treatment group who died were gastroenteritis (7 participants), tuberculosis (5), pneumonia (4), homicide (2), cancer (1), cardiomyopathy (1), cholangitis with sepsis (1), stroke (1), and suicide (1). The causes of death among the 6 participants in the early-treatment group who died were burn injury (1), gastroenteritis (1), myocardial infarction (1), pulmonary embolism after gynecologic surgery (1), stroke (1), and gastrointestinal bleeding (1). There was only 1 death from an infectious disease in the early-treatment group, as compared with 17 deaths in the standard-treatment group.\n\n【48】Antiretroviral therapy had been initiated in 7 of the 23 participants in the standard-treatment group who died. These seven participants died a median of 2 months after starting therapy.\n\n【49】Incident Tuberculosis\n---------------------\n\n【50】Figure 3. Kaplan–Meier Estimates of the Probability of Remaining Free from Active Tuberculosis in the Early-Treatment and Standard-Treatment Groups.\n\n【51】Among the 773 participants who did not have tuberculosis at enrollment, 54 received a diagnosis of tuberculosis during the follow-up period. There were 36 cases of incident tuberculosis in the standard-treatment group and 18 in the early-treatment group (P=0.01 by the log-rank test). In the Kaplan–Meier analysis of survival, tuberculosis developed by 36 months in 6% of the participants in the early-treatment group, as compared with 14% in the standard-treatment group . The hazard ratio for the risk of incident tuberculosis with standard treatment as compared with early treatment was 2.0 (95% CI, 1.2 to 3.6). Tuberculosis developed in 31 participants in the standard-treatment group before antiretroviral therapy was initiated and in 5 participants in the standard-treatment group a median of 6 months after the initiation of antiretroviral therapy. None of the participants in the early-treatment group, as compared with five of the participants in the standard-treatment group, died as a result of incident tuberculosis.\n\n【52】CD4+ T-Cell Count\n-----------------\n\n【53】The median CD4+ T-cell count in the early-treatment group increased from 280 per cubic millimeter at enrollment to 520 per cubic millimeter at month 36. The median CD4+ T-cell count in the standard-treatment group declined from 282 per cubic millimeter at baseline to 270 per cubic millimeter at month 36.\n\n【54】Initiation of Antiretroviral Therapy in the Standard-Treatment Group\n--------------------------------------------------------------------\n\n【55】Antiretroviral therapy was initiated in 160 of the 408 participants in the standard-treatment group (39%). In 147 of these participants, the CD4+ T-cell count fell to 200 per cubic millimeter or less; in 7 participants, an AIDS-defining illness developed; and in 3 participants, both an AIDS-defining illness developed and the CD4+ T-cell count fell to 200 per cubic millimeter or less. In addition, antiretroviral therapy was initiated in three pregnant women to prevent transmission of HIV infection to their offspring. Among the 160 participants in the standard-treatment group in whom antiretroviral therapy was initiated, the median CD4+ T-cell count at the start of antiretroviral therapy was 166 per cubic millimeter (interquartile range, 130 to 190).\n\n【56】Figure 4. Kaplan–Meier Estimates of Survival without Antiretroviral Therapy (ART) among the 408 Participants in the Standard-Treatment Group.\n\n【57】An additional 16 participants in the standard-treatment group died before antiretroviral therapy could be initiated. In the Kaplan–Meier analysis, the estimated median survival without antiretroviral therapy in the standard-treatment group was 24 months .\n\n【58】Drug Reactions\n--------------\n\n【59】Of the 408 participants in the early-treatment group, 32 (8%) had a severe or life-threatening drug reaction. Of the 160 participants in the standard-treatment group who received antiretroviral therapy, 18 (11%) had a severe or life-threatening drug reaction. Details of these drug reactions are provided in Table 2 in the Supplementary Appendix . Anemia associated with zidovudine therapy was the most common adverse drug reaction, occurring in 13 (8%) of the 160 participants in the standard-treatment group who received antiretroviral therapy and in 14 (3%) of the 408 participants in the early-treatment group.\n\n【60】Discussion\n----------\n\n【61】The results of this randomized, controlled trial show that among HIV-1–infected adults who live in resource-poor areas, antiretroviral therapy that is initiated when the CD4+ T-cell count is greater than 200 and less than 350 per cubic millimeter, as compared with antiretroviral therapy that is deferred until the CD4+ T-cell count falls to 200 per cubic millimeter or less or an AIDS-defining illness develops, results in a 75% reduction in the rate of death and a 50% decrease in the incidence of tuberculosis\n\n【62】Our finding that early antiretroviral therapy improves the rate of survival is consistent with data from observational studies.  The When To Start Consortium examined outcomes for more than 24,000 HIV-infected patients in 15 cohorts in Europe and North America. This study showed that with initiation of antiretroviral therapy when the CD4+ T-cell count was lower than 350 per cubic millimeter, as compared with initiation when the CD4+ T-cell count was 350 or higher, the hazard ratio for death was 1.4 to 2.0.  Our prospective study validates these observational findings in a randomized, controlled trial. Furthermore, the effect size in our trial, with a hazard ratio of 4.0, was larger than the effect size seen in the observational cohorts. One possible reason for the large effect size in our study is that it was conducted in a resource-poor setting, where high rates of tuberculosis, malnutrition, and coinfections with tropical diseases may exacerbate the effect of deferred therapy.\n\n【63】Early antiretroviral therapy also decreased the incidence of tuberculosis by 50% in our study. This finding is consistent with observational studies from Africa showing a decrease in the incidence of tuberculosis after antiretroviral therapy is started.  Tuberculosis is a leading cause of death among HIV-1–infected patients in developing countries,  and the effect of early antiretroviral therapy on the incidence of tuberculosis explains in part the decreased rate of death seen in our trial. Furthermore, the HIV epidemic has dramatically increased the incidence of active tuberculosis in countries with limited resources and is overwhelming tuberculosis-control programs.  Provision of early antiretroviral therapy on a large scale in areas with limited resources has the potential to decrease the incidence of active tuberculosis in the general population.\n\n【64】The WHO has promoted a public health approach in its guidelines to antiretroviral therapy, emphasizing feasibility, cost-effectiveness, and large-scale implementation.  Earlier initiation of antiretroviral therapy — when the CD4+ T-cell count is less than 350 per cubic millimeter — is likely to be consistent with this approach.  The median time to the initiation of antiretroviral therapy in our standard-treatment group was 2 years. At current pricing, 2 years of antiretroviral drugs will cost approximately $400 per person. Thus, for a cost of approximately $400 per person, the rate of death can be decreased by 75%, and the incidence of active tuberculosis by 50%. Furthermore, the standard-treatment group had higher rates of infectious diseases and of treatment-limiting drug reactions than did the early-treatment group and required frequent monitoring of CD4+ T-cell counts. This complex medical care consumed resources and the time of highly trained health care workers, factors that may in part offset the cost of starting antiretroviral therapy earlier.\n\n【65】Our study was not blinded. This would not affect the primary study end point of survival, but we cannot exclude the possibility that detection bias influenced the secondary end points. However, the rates at which participants remained in the study for follow-up assessments were high, and the fact that the rates were similar in the two groups suggests that the intensity of follow-up was similar.\n\n【66】In conclusion, early antiretroviral therapy decreased the rate of death by 75% in HIV-infected adults who had a CD4+ T-cell count that was greater than 200 and less than 350 per cubic millimeter. Access to antiretroviral therapy should be expanded to all HIV-infected adults who have a CD4+ T-cell count of less than 350 per cubic millimeter, including those who live in locations with limited resources.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-14 00:19:25", "grab_time": "2024-08-13 23:09:25"}
{"id": 2234291, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "26f88216-0bee-48ee-81a9-615ac4bdbd69", "title": "p53 Antigen Loss in Stored Paraffin Slides", "text": "【0】p53 Antigen Loss in Stored Paraffin Slides\nTo the Editor:\n--------------\n\n【1】Immunohistochemical techniques are commonly used to detect antigens of therapeutic or prognostic importance in patients with cancer. Some technical problems in their use are well recognized, such as antigen masking by fixatives.  We recently encountered another potential problem — antigen loss in slides stored at room temperature.\n\n【2】While studying p53 gene expression in breast cancers using immunohistochemical analysis of formalin-fixed, paraffin-embedded sections, we observed diminished reactivity over time on our p53-positive control slides. These slides had been cut from a paraffin block containing a p53-positive breast cancer and stored at room temperature for up to two months.\n\n【3】Figure 1. Specimens of Ductal Carcinoma in Situ of the Breast Immunostained for p53 Antigen with Monoclonal Antibody PAb 1801.\n\n【4】In Panel A, a freshly cut paraffin section shows numerous tumor-cell nuclei positive for p53, some with intense staining. In Panel B, a paraffin section that had been cut from the same block but stored at room temperature for two months shows a striking loss of antigen reactivity and only a few faintly staining nuclei (arrows).\n\n【5】To investigate this problem, we studied 10 cases of mammary ductal carcinoma in situ previously shown in our laboratory to be p53-positive. For each case, slides stored at room temperature for two months and freshly cut slides from the same paraffin blocks were stained simultaneously for p53 on an automated immunostainer (Ventana Medical Systems, Tucson, Ariz.) with two anti-p53 monoclonal antibodies (PAb 1801, Zeneca, London, and D07, Dako, Carpinteria, Calif.). The immunostains were reviewed blindly and evaluated for the distribution and intensity of staining. In every case, immunoreactivity was weaker on the stored slides than on the slides that had been freshly cut from the same paraffin block . In three cases, immunoreactivity for p53 was present on the freshly cut slides, but absent on the corresponding stored slides. Similar results were obtained with both antibodies.\n\n【6】The range of markers for which antigen loss on stored paraffin slides is a problem is not known. We and others have also noticed this problem with estrogen receptor as well as with the _bcl-_ 2 oncoprotein  (and Battifora H, City of Hope National Medical Center, Duarte, Calif.: personal communication). The precise time course of antigen loss is also not known.\n\n【7】Our observations indicate that immunohistochemical analysis of slides stored at room temperature can produce spuriously negative results for some antigens. Researchers who have performed or plan to perform such analyses on paraffin sections stored at room temperature should be aware of this potential pitfall.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [{"text": "(Ventana Medical Systems, Tucson, Ariz.) ", "content": "【0】p53 Antigen Loss in Stored Paraffin Slides\nTo the Editor:\n--------------\n\n【1】Immunohistochemical techniques are commonly used to detect antigens of therapeutic or prognostic importance in patients with cancer. Some technical problems in their use are well recognized, such as antigen masking by fixatives.  We recently encountered another potential problem — antigen loss in slides stored at room temperature.\n\n【2】While studying p53 gene expression in breast cancers using immunohistochemical analysis of formalin-fixed, paraffin-embedded sections, we observed diminished reactivity over time on our p53-positive control slides. These slides had been cut from a paraffin block containing a p53-positive breast cancer and stored at room temperature for up to two months.\n\n<mark>【3】Figure 1. </mark>Specimens of Ductal Carcinoma in Situ of the Breast Immunostained for p53 Antigen with Monoclonal Antibody PAb 1801.\n\n【4】In Panel A, a freshly cut paraffin section shows numerous tumor-cell nuclei positive for p53, some with intense staining. In Panel B, a paraffin section that had been cut from the same block but stored at room temperature for two months shows a striking loss of antigen reactivity and only a few faintly staining nuclei (arrows).\n\n【5】To investigate this problem, we studied 10 cases of mammary ductal carcinoma in situ previously shown in our laboratory to be p53-positive. For each case, slides stored at room temperature for two months and freshly cut slides from the same paraffin blocks were stained simultaneously for p53 on an automated immunostainer (Ventana Medical Systems, Tucson, Ariz.) with two anti-p53 monoclonal antibodies (PAb 1801, Zeneca, London, and D07, Dako, Carpinteria, Calif.). The immunostains were reviewed blindly and evaluated for the distribution and intensity of staining. In every case, immunoreactivity was weaker on the stored slides than on the slides that had been freshly cut from the same paraffin block . In three cases, immunoreactivity for p53 was present on the freshly cut slides, but absent on the corresponding stored slides. Similar results were obtained with both antibodies.\n\n【6】The range of markers for which antigen loss on stored paraffin slides is a problem is not known. We and others have also noticed this problem with estrogen receptor as well as with the _bcl-_ 2 oncoprotein  (and Battifora H, City of Hope National Medical Center, Duarte, Calif.: personal communication). The precise time course of antigen loss is also not known.\n\n【7】Our observations indicate that immunohistochemical analysis of slides stored at room temperature can produce spuriously negative results for some antigens. Researchers who have performed or plan to perform such analyses on paraffin sections stored at room temperature should be aware of this potential pitfall.", "index": 1578, "show": true, "start": 1565, "end": 1606, "province": ["文本干净度", "无关文本"], "isEdit": false}, {"text": " (PAb 1801, Zeneca, London, and D07, Dako, Carpinteria, Calif.). ", "content": "【0】p53 Antigen Loss in Stored Paraffin Slides\nTo the Editor:\n--------------\n\n【1】Immunohistochemical techniques are commonly used to detect antigens of therapeutic or prognostic importance in patients with cancer. Some technical problems in their use are well recognized, such as antigen masking by fixatives.  We recently encountered another potential problem — antigen loss in slides stored at room temperature.\n\n【2】While studying p53 gene expression in breast cancers using immunohistochemical analysis of formalin-fixed, paraffin-embedded sections, we observed diminished reactivity over time on our p53-positive control slides. These slides had been cut from a paraffin block containing a p53-positive breast cancer and stored at room temperature for up to two months.\n\n<mark>【3】Figure 1. </mark>Specimens of Ductal Carcinoma in Situ of the Breast Immunostained for p53 Antigen with Monoclonal Antibody PAb 1801.\n\n【4】In Panel A, a freshly cut paraffin section shows numerous tumor-cell nuclei positive for p53, some with intense staining. In Panel B, a paraffin section that had been cut from the same block but stored at room temperature for two months shows a striking loss of antigen reactivity and only a few faintly staining nuclei (arrows).\n\n【5】To investigate this problem, we studied 10 cases of mammary ductal carcinoma in situ previously shown in our laboratory to be p53-positive. For each case, slides stored at room temperature for two months and freshly cut slides from the same paraffin blocks were stained simultaneously for p53 on an automated immunostainer <mark>(Ventana Medical Systems, Tucson, Ariz.) </mark>with two anti-p53 monoclonal antibodies (PAb 1801, Zeneca, London, and D07, Dako, Carpinteria, Calif.). The immunostains were reviewed blindly and evaluated for the distribution and intensity of staining. In every case, immunoreactivity was weaker on the stored slides than on the slides that had been freshly cut from the same paraffin block . In three cases, immunoreactivity for p53 was present on the freshly cut slides, but absent on the corresponding stored slides. Similar results were obtained with both antibodies.\n\n【6】The range of markers for which antigen loss on stored paraffin slides is a problem is not known. We and others have also noticed this problem with estrogen receptor as well as with the _bcl-_ 2 oncoprotein  (and Battifora H, City of Hope National Medical Center, Duarte, Calif.: personal communication). The precise time course of antigen loss is also not known.\n\n【7】Our observations indicate that immunohistochemical analysis of slides stored at room temperature can produce spuriously negative results for some antigens. Researchers who have performed or plan to perform such analyses on paraffin sections stored at room temperature should be aware of this potential pitfall.", "index": 1671, "show": true, "start": 1645, "end": 1710, "province": ["文本干净度", "无关文本"], "isEdit": false}, {"text": "  (and Battifora H, City of Hope National Medical Center, Duarte, Calif.: personal communication)", "content": "【0】p53 Antigen Loss in Stored Paraffin Slides\nTo the Editor:\n--------------\n\n【1】Immunohistochemical techniques are commonly used to detect antigens of therapeutic or prognostic importance in patients with cancer. Some technical problems in their use are well recognized, such as antigen masking by fixatives.  We recently encountered another potential problem — antigen loss in slides stored at room temperature.\n\n【2】While studying p53 gene expression in breast cancers using immunohistochemical analysis of formalin-fixed, paraffin-embedded sections, we observed diminished reactivity over time on our p53-positive control slides. These slides had been cut from a paraffin block containing a p53-positive breast cancer and stored at room temperature for up to two months.\n\n<mark>【3】Figure 1. </mark>Specimens of Ductal Carcinoma in Situ of the Breast Immunostained for p53 Antigen with Monoclonal Antibody PAb 1801.\n\n【4】In Panel A, a freshly cut paraffin section shows numerous tumor-cell nuclei positive for p53, some with intense staining. In Panel B, a paraffin section that had been cut from the same block but stored at room temperature for two months shows a striking loss of antigen reactivity and only a few faintly staining nuclei (arrows).\n\n【5】To investigate this problem, we studied 10 cases of mammary ductal carcinoma in situ previously shown in our laboratory to be p53-positive. For each case, slides stored at room temperature for two months and freshly cut slides from the same paraffin blocks were stained simultaneously for p53 on an automated immunostainer <mark>(Ventana Medical Systems, Tucson, Ariz.) </mark>with two anti-p53 monoclonal antibodies<mark> (PAb 1801, Zeneca, London, and D07, Dako, Carpinteria, Calif.). </mark>The immunostains were reviewed blindly and evaluated for the distribution and intensity of staining. In every case, immunoreactivity was weaker on the stored slides than on the slides that had been freshly cut from the same paraffin block . In three cases, immunoreactivity for p53 was present on the freshly cut slides, but absent on the corresponding stored slides. Similar results were obtained with both antibodies.\n\n【6】The range of markers for which antigen loss on stored paraffin slides is a problem is not known. We and others have also noticed this problem with estrogen receptor as well as with the _bcl-_ 2 oncoprotein  (and Battifora H, City of Hope National Medical Center, Duarte, Calif.: personal communication). The precise time course of antigen loss is also not known.\n\n【7】Our observations indicate that immunohistochemical analysis of slides stored at room temperature can produce spuriously negative results for some antigens. Researchers who have performed or plan to perform such analyses on paraffin sections stored at room temperature should be aware of this potential pitfall.", "index": 2378, "show": true, "start": 2339, "end": 2436, "province": ["文本干净度", "无关文本"], "isEdit": false}]}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-14 00:20:08", "grab_time": "2024-08-13 23:03:31"}
{"id": 2234290, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "10cb4d65-1638-4b25-9cdc-47de0e86798d", "title": "South Korea’s Thyroid-Cancer “Epidemic” — Turning the Tide", "text": "【0】South Korea’s Thyroid-Cancer “Epidemic” — Turning the Tide\nTo the Editor:\n--------------\n\n【1】In 2014, we reported on the rate of thyroid-cancer diagnoses in South Korea that was 15 times as high in 2011 as the rate in 1993.  This increase resulted when fee-for-service providers added thyroid screening with ultrasonography to other cancer-screening tests paid for by the government. Here, we report on an increased awareness of overdiagnosis of thyroid cancer among South Koreans and the effect of this awareness on the number of surgical operations for thyroid cancer.\n\n【2】In March 2014, eight physicians from South Korea formed the Physician Coalition for Prevention of Overdiagnosis of Thyroid Cancer and wrote an open letter to the public highlighting the extraordinarily high incidence of thyroid cancer in South Korea and proposing that screening with ultrasonography be discouraged. Broadcasters ran hour-long investigative reports on television, and major newspapers ran headlines such as “What Caused Jump in Thyroid Cancer Cases?” \n\n【3】Figure 1. Trend in the Number of Operations for Thyroid Cancer in South Korea, 2001–2015.\n\n【4】Data are from the Health Insurance Review and Assessment Service, South Korea.\n\n【5】Subsequently, there has been a marked decrease in thyroid operations in South Korea after a decade of explosive growth. Whereas more than 43,000 operations for thyroid cancer were performed from the second quarter of 2013 through the first quarter of 2014, approximately 28,000 operations were performed from the second quarter of 2014 through the first quarter of 2015 — a 35% reduction . Preliminary estimates from insurance claims suggest a 30% reduction in the incidence of thyroid cancer (the lag time in the availability of incidence data from the Korean Central Cancer Registry is 2 to 3 years). Thus, the decrease in the number of surgical operations was not primarily the result of more conservative surgical practice (e.g., opting for active surveillance instead); rather, it resulted from less screening — and less diagnosis.\n\n【6】Of course, it is possible that less diagnosis and fewer surgical operations may ultimately mean more deaths from thyroid cancer in Korea. We consider that extraordinarily unlikely for two reasons: the dramatic increase in diagnosis and surgery had no effect on lowering thyroid-cancer mortality; and the additional diagnoses from screening were all papillary thyroid cancer — a histologic finding that is so prevalent in the general population that it is better considered a normal variant than a deadly disease.\n\n【7】There are indications that the changes mainly reflect patients’ choices, not physicians’ recommendations. Thyroid-cancer screening and treatment have become big business in South Korea. Over the past decade, hospitals have expanded thyroid clinics, hiring surgeons and fueling an industry of robot-assisted thyroid surgery. The Korean Thyroid Association, a professional society of endocrinologists and thyroid surgeons, expressed a strong negative reaction to the concerns expressed by the physician coalition, saying that screening and treatment should not be banned because they are “basic human rights.” \n\n【8】Our findings suggest that a small group of physicians can change the direction of medical care through public discourse. Whether this course correction will continue or be reversed, however, remains to be seen. The incidence of thyroid cancer in South Korea is still extraordinarily high, and the challenges are substantial. Because it is more intuitive and appealing, the case for early detection is much easier to make than is the case against it. Nonetheless, there is some reason for optimism: the Korean Guideline for Thyroid Cancer Screening, which was developed by the Korean Committee for National Cancer Screening Guidelines in April, concluded that “thyroid ultrasonography is not routinely recommended for healthy subjects.”  We hope this example will encourage other doctors to find their voice when medical trends run counter to their patients’ interests.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-14 00:19:55", "grab_time": "2024-08-13 23:01:55"}
{"id": 2234289, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "92306ac7-a77a-47ba-b6f3-b2dfde721661", "title": "Extracorporeal Membrane Oxygenation for Severe Acute Respiratory Distress Syndrome", "text": "【0】Extracorporeal Membrane Oxygenation for Severe Acute Respiratory Distress Syndrome\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】The efficacy of venovenous extracorporeal membrane oxygenation (ECMO) in patients with severe acute respiratory distress syndrome (ARDS) remains controversial.\n\n【3】Methods\n-------\n\n【4】In an international clinical trial, we randomly assigned patients with very severe ARDS, as indicated by one of three criteria — a ratio of partial pressure of arterial oxygen (Pa o <sub>2 </sub> ) to the fraction of inspired oxygen (F io <sub>2 </sub> ) of less than 50 mm Hg for more than 3 hours; a Pa o <sub>2 </sub> :F io <sub>2 </sub> of less than 80 mm Hg for more than 6 hours; or an arterial blood pH of less than 7.25 with a partial pressure of arterial carbon dioxide of at least 60 mm Hg for more than 6 hours — to receive immediate venovenous ECMO (ECMO group) or continued conventional treatment (control group). Crossover to ECMO was possible for patients in the control group who had refractory hypoxemia. The primary end point was mortality at 60 days.\n\n【5】Results\n-------\n\n【6】At 60 days, 44 of 124 patients (35%) in the ECMO group and 57 of 125 (46%) in the control group had died (relative risk, 0.76; 95% confidence interval \\[CI\\], 0.55 to 1.04; P=0.09). Crossover to ECMO occurred a mean (±SD) of 6.5±9.7 days after randomization in 35 patients (28%) in the control group, with 20 of these patients (57%) dying. The frequency of complications did not differ significantly between groups, except that there were more bleeding events leading to transfusion in the ECMO group than in the control group (in 46% vs. 28% of patients; absolute risk difference, 18 percentage points; 95% CI, 6 to 30) as well as more cases of severe thrombocytopenia (in 27% vs. 16%; absolute risk difference, 11 percentage points; 95% CI, 0 to 21) and fewer cases of ischemic stroke (in no patients vs. 5%; absolute risk difference, −5 percentage points; 95% CI, −10 to −2).\n\n【7】Conclusions\n-----------\n\n【8】Among patients with very severe ARDS, 60-day mortality was not significantly lower with ECMO than with a strategy of conventional mechanical ventilation that included ECMO as rescue therapy. \n\n【9】Introduction\n------------\n\n【10】The acute respiratory distress syndrome (ARDS) is associated with high mortality despite the use of low-volume, low-pressure ventilation strategies that are aimed at reducing ventilator-induced lung injury.  The most severe forms of ARDS may be associated with mortality exceeding 60%.  In these situations, some centers will use venovenous extracorporeal membrane oxygenation (ECMO).  There have been major advances in the past few years regarding the technology of ECMO circuits.  In this context, patients who received ECMO therapy during the influenza A (H1N1) pandemic in 2009 appeared to benefit, but the studies in which they were examined were not randomized.  Around the same time, a randomized trial that assigned patients with ARDS to an expert center for consideration of ECMO as part of a treatment protocol yielded promising results, although methodologic issues limited the conclusions that could be drawn from the trial.  We designed the ECMO to Rescue Lung Injury in Severe ARDS (EOLIA) trial to determine the effect of early initiation of ECMO in patients with the most severe forms of ARDS.\n\n【11】Methods\n-------\n\n【12】Trial Design and Oversight\n--------------------------\n\n【13】We conducted an international, randomized trial. The trial was sponsored and conducted largely in France by the Direction de la Recherche Clinique et du Développement, Assistance Publique–Hôpitaux de Paris, with a grant from the French Ministry of Health. International centers that enrolled patients outside France were the legal sponsor for the trial in their own country. An independent data and safety monitoring committee periodically reviewed trial outcomes. The members of the writing committee wrote all drafts of the manuscript. All the authors approved the final version of the manuscript and made the decision to submit it for publication. They also verified the data and vouch for the completeness of the data, the accuracy of the analyses, and the fidelity of the trial to the protocol.\n\n【14】Maquet-Getinge provided HLS ECMO cannulas, the CardioHelp device, and circuits (HLS Set Advanced 7.0). Neither Maquet-Getinge nor the trial sponsors participated in the trial design; the data collection, analysis, or interpretation; or the writing or submission of the manuscript.\n\n【15】Patients\n--------\n\n【16】Patients were eligible for enrollment if their condition fulfilled the American–European Consensus Conference definition for ARDS,  if they had undergone endotracheal intubation and had been receiving ventilation for less than 7 days, and if they met disease-severity criteria as outlined in Section II.1 of the Supplementary Appendix (including a ratio of partial pressure of arterial oxygen \\[Pa o <sub>2 </sub> \\] to the fraction of inspired oxygen \\[F io <sub>2 </sub> \\] of <50 mm Hg for >3 hours, a Pa o <sub>2 </sub> :F io <sub>2 </sub> of <80 mm Hg for >6 hours, or an arterial blood pH of <7.25 with a partial pressure of arterial carbon dioxide \\[Pa co <sub>2 </sub> \\] of ≥60 mm Hg for >6 hours, with the respiratory rate increased to 35 breaths per minute and mechanical-ventilation settings adjusted to keep a plateau pressure of ≤32 cm of water) despite ventilator optimization (defined as a fraction of inspired oxygen \\[F io <sub>2 </sub> \\] of ≥0.80, a tidal volume of 6 ml per kilogram of predicted body weight, and a positive end-expiratory pressure \\[PEEP\\] of ≥10 cm of water). Physicians were encouraged to use neuromuscular blocking agents and prone positioning before randomization. Other adjunctive therapies, such as inhaled nitric oxide, recruitment maneuvers (i.e., procedures that are used to reinflate collapsed lung units and that involve sustained application of an airway pressure of >35 cm of water),  high-frequency oscillatory ventilation, or almitrine infusion, were allowed at the discretion of the responsible clinicians.\n\n【17】Exclusion criteria were an age of less than 18 years; receipt of mechanical ventilation for 7 days or longer; pregnancy; a weight of more than 1 kg per centimeter of height or a body-mass index (the weight in kilograms divided by the square of the height in meters) of more than 45; long-term chronic respiratory insufficiency treated with oxygen therapy or noninvasive ventilation; cardiac failure resulting in venoarterial ECMO; a history of heparin-induced thrombocytopenia; cancer with a life expectancy of less than 5 years; a moribund condition or a Simplified Acute Physiology Score (SAPS-II) value of more than 90 (on a scale from 0 to 163, with higher scores indicating greater severity of illness) on the day of randomization; a current non–drug-induced coma after cardiac arrest; irreversible neurologic injury; a decision to withhold or withdraw life-sustaining therapies; an expected difficulty in obtaining vascular access for ECMO in the femoral or jugular vein; or a situation in which the ECMO device was not immediately available.\n\n【18】Trial Procedures\n----------------\n\n【19】Randomization was stratified according to center and the duration of ventilation before randomization (<72 hours vs. ≥72 hours). Concealment of the randomized assignment was ensured by means of a centralized, secure, Web-based randomization system. Non-ECMO centers that had extensive expertise in treating patients with ARDS could enter patients if an ECMO retrieval team could establish ECMO within 2 hours after randomization and transfer the patient to the ECMO center. A prespecified protocol was used to treat patients in the control group who had undergone randomization at ECMO centers and at non-ECMO centers .\n\n【20】Patients assigned to the ECMO group underwent percutaneous venovenous cannulation. Anticoagulation was achieved with unfractionated heparin that was adjusted to a target activated partial-thromboplastin time of 40 to 55 seconds or anti-Xa activity between 0.2 and 0.3 IU per milliliter.\n\n【21】Patients in the control group received ventilatory treatment according to the increased recruitment strategy from the Express trial.  Neuromuscular blocking agents  and prolonged periods of prone positioning  were strongly encouraged. Recruitment maneuvers, inhaled nitric oxide, inhaled prostacyclin, or intravenous almitrine could be used when oxygenation objectives were not met. Crossover to ECMO for patients in the control group was allowed if they had refractory hypoxemia (oxygen saturation \\[Sa o <sub>2 </sub> \\] of <80% for >6 hours, despite the use of available and feasible adjunctive therapies) and if the treating physician thought that the patient had no irreversible multiorgan failure and that ECMO might change the outcome. For patients who were treated at non-ECMO centers, the mobile ECMO retrieval team was alerted.\n\n【22】End Points\n----------\n\n【23】The primary end point was mortality at 60 days. The key secondary end point was treatment failure, which was defined as crossover to ECMO or death in patients in the control group and as death in patients in the ECMO group. Other end points included mortality at other time points, the time to death until day 60, and a per-treatment analysis in which mortality was compared among patients who received ECMO and those who did not. Safety end points included the rates of pneumothorax, stroke, infection at the site of ECMO cannula insertion, cannula thrombosis, ECMO circuit change, intravascular hemolysis, ventilator-associated pneumonia, severe hemorrhagic complications, and red-cell transfusion. Other secondary end points are listed in the Supplementary Appendix . Deaths were directly attributed to the ECMO procedure if they occurred in the context of failure of the ECMO device, massive gas emboli, cardiac arrest due to massive circuit clotting, septic shock due to infection at the ECMO cannulation site, intracranial hemorrhage, pneumothorax during cannula insertion, or massive bleeding that led to the transfusion of at least 10 units of packed red cells.\n\n【24】Statistical Analysis\n--------------------\n\n【25】The expected mortality at 60 days was 60% in the group receiving conventional ventilation  and was estimated at 40% among those receiving early ECMO support.  We calculated that, in order for the trial to have 80% power, at an alpha level of 5% and with a group-sequential analysis occurring after the randomization of every 60 participants, the maximum sample would need to be 331 participants. For the primary end point, a sequential-design method with stopping rules that were defined according to the two-sided triangular test  was applied. The two-sided triangular design allowed for early stopping for evidence of superiority of ECMO, a predicted lack of a significant difference, or evidence of harm. More details about the design are given in Section II.2 of the Supplementary Appendix .\n\n【26】The characteristics of the patients at baseline are reported as percentages for categorical variables and as means (with standard deviations) or medians (with interquartile ranges) for continuous variables, as appropriate. Primary analyses were conducted according to the intention-to-treat principle and did not use a stratified test statistic. Categorical variables were compared with chi-square or Fisher’s exact tests, and continuous variables were compared with Student’s t-test or a Wilcoxon test, as appropriate. Kaplan–Meier survival curves until 60 days after randomization were compared with a log-rank test. Friedman’s tests and other nonparametric tests were used to compare repeated measurements over time. A planned sensitivity analysis was performed with the use of a Cox regression model to adjust for prespecified baseline variables: cause of ARDS, coexisting conditions, age of the patient, duration of mechanical ventilation before randomization, disease severity at inclusion, and center. We conducted post hoc exploratory analyses of the primary end point in subgroups of interest. Given the number of crossover procedures that occurred in patients in the control group, we performed a post hoc rank-preserving structural-failure time analysis to adjust for crossover in the estimation of survival . \n\n【27】All the analyses were conducted at a two-sided alpha level of 5%. All the analyses were performed with the use of R software, version 3.3.3 (R Foundation), except for the sequential analysis of the primary end point, for which we used SAS software, version 9.2 (SAS Institute), and PEST (model-independent parameter estimation and uncertainty analysis) software, version 4 .\n\n【28】Results\n-------\n\n【29】Patients\n--------\n\n【30】Figure 1. Enrollment, Randomization, and Follow-up of the Trial Participants.\n\n【31】The Simplified Acute Physiology Score (SAPS-II) is assessed on a scale ranging from 0 to 163, with higher scores indicating greater severity of illness. The body-mass index (BMI) is the weight in kilograms divided by the square of the height in meters. ARDS denotes the acute respiratory distress syndrome, ECMO extracorporeal membrane oxygenation, and ICU intensive care unit.\n\n【32】After the inclusion of 240 patients, the fourth planned sequential interim analysis (in April 2017) showed that the lower boundary of the stopping-rule triangle had been crossed . Because no significant between-group difference in mortality at 60 days had been found, trial recruitment was stopped, in accordance with the prespecified rules. Among 1015 patients who were eligible for inclusion, 249 patients underwent randomization: 124 were assigned to the ECMO group and 125 to the control group . A total of 3 patients in the ECMO group did not receive ECMO (1 patient had rapid clinical improvement and 2 died soon after randomization), and 35 patients (28%) in the control group crossed over to ECMO because of refractory hypoxemia at a mean (±SD) of 6.5±9.7 days after randomization.\n\n【33】Table 1. Characteristics of the Patients at Randomization.\n\n【34】The characteristics of the patients at baseline (randomization) were similar in the two groups . The main causes of ARDS were bacterial pneumonia (in 45% of the patients) and viral pneumonia (in 18%), and 78% of the patients had severe sepsis or septic shock. Before randomization, 59% of the patients had undergone prone positioning, and 74% had received vasopressors.\n\n【35】Trial Treatment\n---------------\n\n【36】Of the 121 patients in the ECMO group who received ECMO at a mean of 3.3±2.8 hours after randomization, insertion of the cannula was performed in the femoral and jugular veins in 116 (96%). A total of 48 of 124 patients (39%) were retrieved from non-ECMO centers by the mobile ECMO rescue team . ECMO support lasted a mean of 15±13 days .\n\n【37】Table 2. End Points.\n\n【38】Patients in the ECMO group had tidal volumes, plateau pressures, driving pressures (the difference between the plateau pressure and PEEP), and respiratory rates that decreased from baseline to a greater extent than the respective values in the control group, whereas levels of arterial blood gases in the ECMO group normalized in the immediate days after randomization . Patients in the control group, regardless of whether they were treated at ECMO centers or non-ECMO centers, received low-volume, low-pressure ventilation according to the current standard of care . In the control group, 113 patients (90%) were placed prone, 104 (83%) received inhaled nitric oxide or inhaled prostacyclin, and 100% received neuromuscular blocking agents after randomization .\n\n【39】Primary End Point\n-----------------\n\n【40】Figure 2. Kaplan–Meier Survival Estimates in the Intention-to-Treat Population during the First 60 Days of the Trial.\n\n【41】At 60 days, 44 patients (35%) in the ECMO group and 57 (46%) in the control group had died (relative risk, 0.76; 95% confidence interval \\[CI\\], 0.55 to 1.04; P=0.09) . The hazard ratio for death within 60 days after randomization in the ECMO group, as compared with the control group, was 0.70 (95% CI, 0.47 to 1.04; P=0.07) . Adjustment for important prognostic factors did not change the results.\n\n【42】Secondary End Points\n--------------------\n\n【43】The relative risk of treatment failure, defined as death by day 60 in patients in the ECMO group and as crossover to ECMO or death in patients in the control group, was 0.62 (95% CI, 0.47 to 0.82; P<0.001) . At 60 days, patients in the ECMO group had significantly more days than those in the control group without prone positioning (59 vs. 46 days; median difference, 13 days; 95% CI, 5 to 59) and without renal-replacement therapy (50 vs. 32 days; median difference, 18 days; 95% CI, 0 to 51) . At 60 days, patients in the ECMO group also had significantly more days than those in the control group that were free from renal failure (46 vs. 21 days; median difference, 25 days; 95% CI, 6 to 53) and cardiac failure (48 vs. 41 days; median difference, 7 days; 95% CI, 0 to 51), according to score-specific organ subcomponents of the Sequential Organ Failure Assessment . Multiorgan failure, respiratory failure, and septic shock were the main causes of death in the two groups. Subgroup analyses showed no significant interaction of 60-day mortality with baseline demographic characteristics, ARDS severity, or randomization at ECMO centers versus non-ECMO centers .\n\n【44】Crossover to ECMO\n-----------------\n\n【45】A total of 35 patients (28%) in the control group received ECMO for refractory hypoxemia at a mean of 6.5±9.7 days after randomization (median, 4 days; interquartile range, 1 to 7; range, 0 to 50). These patients had significantly higher values than other patients in the control group with regard to the mean baseline plateau pressure (31.7±5.5 vs. 28.5±4.1 cm of water; mean difference, 3.2 cm of water; 95% CI, 1.2 to 5.2), and driving pressure (20.2±6.1 vs. 16.6±5.3 cm of water; mean difference, 3.6 cm of water; 95% CI, 1.2 to 6.0), had lower respiratory-system compliance (21.3±9.2 vs. 27.1±11.0 ml per centimeter of water; mean difference, −5.8 ml per centimeter of water; 95% CI, −10.4 to −1.1), and had more quadrants with infiltrate in the chest radiograph (3.7±0.6 vs. 3.3±0.9 quadrants; mean difference, 0.5 quadrants; 95% CI, 0.1 to 0.8) — all findings that indicate more severe ARDS in the patients who received rescue ECMO . At the time that they received ECMO, the median Pa o <sub>2 </sub> :F io <sub>2 </sub> in these patients was 51 mm Hg (interquartile range, 46 to 61), and the median Sa o <sub>2 </sub> was 77% (interquartile range, 74 to 87). During the 24 hours preceding crossover to ECMO, the Pa o <sub>2 </sub> :F io <sub>2 </sub> , Sa o <sub>2 </sub> , and pH values in these patients decreased significantly, and the Pa co <sub>2 </sub> increased significantly .\n\n【46】These patients also had signs of rapidly evolving cardiovascular failure, as indicated by the significant increase in the 24 hours before crossover in the median serum lactate level, from 1.7 mmol per liter (interquartile range, 1.3 to 2.2) to 3.2 mmol per liter (interquartile range, 1.5 to 6.2), and in the inotropic score, from 10 μg per kilogram of body weight per minute (interquartile range, 0 to 55) to 90 μg per kilogram per minute (interquartile range, 45 to 215) . Before crossover, 9 patients had cardiac arrest, 7 had severe right heart failure, and 11 had renal failure leading to dialysis. Venoarterial ECMO was applied in 7 patients, including 6 who received ECMO while undergoing cardiopulmonary resuscitation. Mortality at 60 days was 57% (20 of 35 patients) among patients in the control group who crossed over to ECMO versus 41% (37 of 90 patients) among the other patients in the control group (relative risk 1.39; 95% CI, 0.95 to 2.03). The results of the rank-preserving structural-failure time analysis with adjustment for selective crossover are provided in the Supplementary Appendix .\n\n【47】Adverse Events\n--------------\n\n【48】Table 3. Adverse Events as Defined by the Trial Protocol in the Intention-to-Treat Population.\n\n【49】One patient in each group died from complications related to ECMO cannulation. Patients in the ECMO group had significantly higher rates than those in the control group of severe thrombocytopenia (<20,000 platelets per cubic millimeter; 27% vs. 16%; absolute risk difference, 11 percentage points; 95% CI, 0 to 21) and bleeding events leading to packed red-cell transfusion (46% vs. 28%; absolute risk difference, 18 percentage points; 95% CI, 6 to 30). The rate of ischemic stroke was lower in the ECMO group than in the control group (no patients vs. 5%; absolute risk difference, −5 percentage points; 95% CI, −10 to −2), but the rate of hemorrhagic stroke was similar in the two groups . Rates of pneumothorax, ventilator-associated pneumonia, and massive bleeding were similar in the two groups. Among all the patients who were treated with ECMO, the rate of bleeding was 53%, the rate of hematoma at the cannula-insertion site was 6%, the rate of infection at the cannula-insertion site was 14%, and the rate of intravascular hemolysis was 5%.\n\n【50】Discussion\n----------\n\n【51】In this randomized trial involving patients with very severe ARDS, early application of ECMO was not associated with mortality at 60 days (primary end point) that was significantly lower than that in the control group. Although the use of ECMO for severe respiratory failure has increased substantially over the past decade,  its use remains controversial.  The results of the first two randomized trials of ECMO were disappointing,  but the trials were conducted decades ago. The results of the most recent trial (Conventional Ventilatory Support versus Extracorporeal Membrane Oxygenation for Severe Adult Respiratory Failure \\[CESAR\\]) were encouraging,  but not all patients in the ECMO group received ECMO, and the use of mechanical ventilation in the control group lacked standardization. In the present trial, 98% of the patients in the ECMO group received ECMO and were transported during receipt of ECMO to the referral center if needed. Moreover, 90% of the patients in the control group underwent prolonged prone positioning  and all of them received neuromuscular blocking agents. \n\n【52】Despite the use of these strategies, which have been shown to improve outcomes,  28% of the patients in the control group in our trial crossed over to ECMO for refractory hypoxemia. This crossover rate makes it difficult to draw definitive conclusions regarding the usefulness of ECMO for severe forms of ARDS. We were aware of this potential problem when we started the trial, but many investigators felt that it would have been unethical to prohibit crossover to ECMO in patients with very severe hypoxemia. The prespecified secondary composite end point of death (in both groups) plus crossover to ECMO (in the control group) showed a benefit in favor of the ECMO group, but this is difficult to interpret in light of the negative results for the primary end point. This secondary analysis clearly represents a bias against the control group, but it is important to point out that the patients who crossed over to ECMO were extremely ill (Sa o <sub>2 </sub> of <80% for >6 hours, despite recruitment maneuvers, inhaled nitric oxide or prostacyclin, and prone positioning; some patients received ECMO during cardiopulmonary resuscitation or received venoarterial ECMO support because of severe cardiac failure). In a sensitivity analysis, results regarding this secondary end point remained significant even under the assumption that one third of these extremely sick patients would have survived without ECMO .\n\n【53】Our trial has several limitations. First, it was stopped per protocol after 75% of the maximum calculated sample size had been achieved. Second, the 28% rate of crossover among patients with refractory hypoxemia in the control group may have diluted the potential effect of ECMO. Third, we included patients at ECMO centers and non-ECMO referral centers. However, treatments were strictly defined according to the protocol in each group, and patients who underwent randomization at non-ECMO centers were rapidly transported to a local ECMO center while they were receiving ECMO. Furthermore, ventilatory strategies that were applied in the ECMO centers and non-ECMO centers did not differ among patients in the control group. The inclusion of patients at ECMO centers and non-ECMO referral centers may also be viewed as a strength, since most patients in countries where ECMO is available will be treated initially at non-ECMO centers. Fourth, the trial was probably underpowered to detect mortality that was 20 percentage points lower in the ECMO group than in the control group (in which crossover to ECMO for refractory hypoxemia was allowed).\n\n【54】In conclusion, the analysis of the primary end point (mortality at 60 days) in our trial involving patients with very severe ARDS showed no significant benefit of early ECMO, as compared with a strategy of conventional mechanical ventilation, which included crossover to ECMO (used by 28% of the patients in the control group).", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-14 00:24:21", "grab_time": "2024-08-13 23:52:27"}
{"id": 2234288, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "7de5e58a-5235-4651-94af-c10a68b7e32e", "title": "Monoclonal B-Cell Lymphocytosis and Chronic Lymphocytic Leukemia", "text": "【0】Monoclonal B-Cell Lymphocytosis and Chronic Lymphocytic Leukemia\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】A diagnosis of chronic lymphocytic leukemia (CLL) requires a count of over 5000 circulating CLL-phenotype cells per cubic millimeter. Asymptomatic persons with fewer CLL-phenotype cells have monoclonal B-cell lymphocytosis (MBL). The goal of this study was to investigate the relation between MBL and CLL.\n\n【3】Methods\n-------\n\n【4】We investigated 1520 subjects who were 62 to 80 years of age with a normal blood count and 2228 subjects with lymphocytosis (>4000 lymphocytes per cubic millimeter) for the presence of MBL, using flow cytometry. Monoclonal B cells were further characterized by means of cytogenetic and molecular analyses. A representative cohort of 185 subjects with CLL-phenotype MBL and lymphocytosis were monitored for a median of 6.7 years (range, 0.2 to 11.8).\n\n【5】Results\n-------\n\n【6】Monoclonal CLL-phenotype B cells were detected in 5.1% of subjects (78 of 1520) with a normal blood count and 13.9% (309 of 2228) with lymphocytosis. CLL-phenotype MBL had a frequency of 13q14 deletion and trisomy 12 similar to that of CLL and showed a skewed repertoire of the immunoglobulin heavy variable group ( _IGHV_ ) genes. Among 185 subjects presenting with lymphocytosis, progressive lymphocytosis occurred in 51 (28%), progressive CLL developed in 28 (15%), and chemotherapy was required in 13 (7%). The absolute B-cell count was the only independent prognostic factor associated with progressive lymphocytosis. During follow-up over a median of 6.7 years, 34% of subjects (62 of 185) died, but only 4 of these deaths were due to CLL. Age above 68 years and hemoglobin level below 12.5 g per deciliter were the only independent prognostic factors for death.\n\n【7】Conclusions\n-----------\n\n【8】The CLL-phenotype cells found in the general population and in subjects with lymphocytosis have features in common with CLL cells. CLL requiring treatment develops in subjects with CLL-phenotype MBL and with lymphocytosis at the rate of 1.1% per year.\n\n【9】Introduction\n------------\n\n【10】The incidence of chronic lymphocytic leukemia (CLL) is approximately 6 per 100,000 persons per year in North America.  The National Cancer Institute–sponsored Working Group guidelines for the diagnosis of CLL require a lymphocyte count of 5000 or more per cubic millimeter and a characteristic cell-surface phenotype of B cells: the presence of CD19, CD5, and CD23, weak expression of CD20 and CD79b, and either kappa or lambda immunoglobulin light chains.  High-sensitivity flow cytometry allows for the detection of B cells with a CLL phenotype in numbers as low as 1 per 10,000 normal leukocytes.  With this method, CLL-phenotype cells have been found in over 3% of adults with otherwise normal blood counts. \n\n【11】The term monoclonal B-cell lymphocytosis (MBL) indicates the presence in the blood of monoclonal B cells in numbers below 5000 per cubic millimeter with no other features of a B-cell lymphoproliferative disorder. The term has been used to designate an expansion of monoclonal B cells of uncertain clinical significance. In subjects with MBL, the B cells usually have a CLL-phenotype, although MBL without a CLL phenotype has been noted. \n\n【12】The International Workshop on Chronic Lymphocytic Leukemia has revised the diagnostic criteria for CLL to require 5000 or more CLL-phenotype B cells per cubic millimeter because the National Cancer Institute Working Group guidelines could permit a diagnosis of CLL in a subject with a reactive T-cell lymphocytosis.  Lymphocytosis with fewer than 5000 CLL-phenotype B cells per cubic millimeter and an absence of symptoms of CLL is defined as CLL-phenotype MBL. It is not known whether CLL-phenotype MBL is associated with any of the characteristic abnormalities of CLL, such as the 13q14 deletion  or biased usage of specific immunoglobulin heavy variable group ( _IGHV_ ) genes. \n\n【13】We investigated two cohorts with CLL-phenotype MBL. The first consisted of subjects with entirely normal blood counts who were screened for CLL-phenotype MBL. The second consisted of subjects who were shown to have CLL-phenotype MBL after referral for the investigation of lymphocytosis between 1995 and 2000 and for whom long-term follow-up data were available. The aim of the study was to determine whether chromosomal abnormalities of CLL also occur in CLL-phenotype MBL and to estimate the probability that CLL requiring treatment will develop in someone with CLL-phenotype MBL.\n\n【14】Methods\n-------\n\n【15】Selection of Subjects\n---------------------\n\n【16】Table 1. Characteristics and Outcomes of Subjects with CLL-Phenotype MBL, According to Cohort.\n\n【17】Table 1 lists the characteristics of the two cohorts. The first cohort comprised 890 women and 630 men, all outpatients who met the following criteria: age between 60 and 80 years, normal leukocyte and differential counts, a normal platelet count, and a normal hemoglobin level; a blood sample less than 24 hours old; and visiting a general-practice, ophthalmology, gynecology, cardiology, dermatology, or orthopedic preoperative clinic or the emergency department. Subjects were excluded if they had been visiting a hematology, oncology, or transplantation clinic or had had a sample sent for investigation of a cancer in the past. All subjects meeting these criteria during the study period were investigated for the presence of MBL.\n\n【18】The second cohort comprised 2228 subjects who were referred for investigation of a current or previous lymphocytosis between April 18, 1995, and December 12, 2000. The normal range for lymphocytes at our institution is 1000 to 4500 cells per cubic millimeter, but the upper limit of the normal range varies at referring centers, from 4000 to 4800 cells per cubic millimeter. In some subjects, the lymphocytosis had resolved by the time a sample from a referring institution was analyzed.\n\n【19】Oral informed consent was provided for blood analysis. Approval was granted by the Leeds Teaching Hospitals Research Ethics Committee to perform biologic studies on discarded blood specimens from anonymous patients and to review the outcomes of subjects presenting with lymphocytosis. Subjects from centers that performed follow-up or blood counts only on selected subjects were excluded from the outcome review. There were no significant differences in age, sex, B-cell count, or other blood-count values between the 185 subjects studied in the outcome review and all 309 subjects with CLL-phenotype MBL and lymphocytosis (P>0.10 for all values by the Wilcoxon–Mann–Whitney U test).\n\n【20】Flow Cytometry and Cell Purification\n------------------------------------\n\n【21】Leukocytes were prepared using ammonium chloride as reported previously.  To screen for MBL in samples with a normal blood count, 5×10 <sup>5 </sup> cells were incubated for 30 minutes with 5 μl each of anti-CD19 phycoerythrin–cyanin 5.5, anti-CD5 allophyocyanin, anti-kappa fluorescein isothiocyanate, and anti-lambda phycoerythrin. Subjects with a clonal B-cell excess (kappa:lambda ratio < or >2. were assessed with the use of an extended panel .\n\n【22】B cells were purified from separated leukocytes obtained from subjects with CLL-phenotype MBL, with the use of anti-CD19–coated magnetic beads and a cell separator (autoMACS, Miltenyi Biotec). In samples with more than 95% CD19 expression on selected cells, cytospin slides were prepared, air-dried overnight, and stored at −20°C; if a sufficient sample was available, genomic DNA was isolated (QIAamp DNA blood mini kit, Qiagen).\n\n【23】Fluorescence In Situ Hybridization (FISH)\n-----------------------------------------\n\n【24】Cytospin slides were fixed in methanol acetic acid and glacial acetic acid  and pretreated in 2× saline sodium citrate (SSC) and 0.1% Nonidet P-40 and dehydrated in an ethanol series. Five microliters of probe in 50% formamide hybridization buffer was applied. Probes were either a mixture of 13q14 and 13q34 or a set of CLL multicolor probes (05J81-001, 05J80-001, and 05J83-001; Abbott Molecular). Cells and probe were codenatured at 73°C for 3 minutes and hybridized overnight at 37°C. Post-hybridization stringency washing was carried out at 69°C during two 2-minute cycles in 0.4× SSC and 0.3% Nonidet P-40, followed by 2 minutes in 2× SSC and 1% Nonidet P-40. Cells counterstained with 4′,6-diamidine-2-phenylidole dihydrochloride were examined under a fluorescence microscope (Axioplan 2, Zeiss); images were captured by a camera (IMAC-CCD S30, Sony) and processed with the use of ISIS3 software (MetaSystems).\n\n【25】_IGHV_ Gene Analysis\n--------------------\n\n【26】DNA was amplified with the use of BIOMED-2 _IGHV_ 5-carboxyfluorescein–labeled primers for fragment analysis, as described previously,  by means of an ABI 377 sequencer and GENESCAN software (Applied Biosystems). Monoclonal samples were reamplified with the use of nonfluorescent primers, the products were purified on 2% agarose gels (Qiaquick Gel Extraction kit, Qiagen), and direct sequencing was performed by means of a BigDye Terminator cycle sequencing kit on an ABI 377 sequencer (Applied Biosystems). Rearranged _IGHV_ segments were identified by comparison with the germ-line sequences by means of IgBlast  and IMGT/V-QUEST . The percent mutation from the closest germ-line _IGHV_ sequence was calculated from the number of nucleotide differences between the 5′ end of framework 1 and the 3′ end of framework 3, as a percentage of total nucleotides.\n\n【27】Statistical Analysis\n--------------------\n\n【28】We determined the degree of association between the presence of chromosomal abnormalities and _IGHV_ gene usage using Fisher's exact test and the likelihood-ratio chi-square analysis. Univariate log-rank outcome analysis was performed on groups with the use of cutoff points defined by the highest Youden's J value (a measure of the receiver-operating-characteristic curve that enables the selection of an optimal cutoff point) for predicting the development of progressive lymphocytosis or death. Progressive lymphocytosis was defined as a lymphocyte count that was more than twice the count at presentation and remained at this level or increased at subsequent assessments. Multivariate analysis was performed with the use of the Cox proportional-hazards model, and assumptions were tested on the basis of Schoenfeld residuals. All variables were tested for intercorrelation (by Spearman's rank test with Bonferroni correction) and those that generated interference in the multivariate analysis were excluded; CD38 expression by B cells was also excluded from multivariate analysis because it was not significant in the univariate analysis and because data were not available for all subjects. All P values were two-sided and calculated with the use of Stata 9.0 software (Statacorp); P values less than 0.05 were considered to indicate statistical significance.\n\n【29】Results\n-------\n\n【30】Prevalence of CLL-Phenotype MBL\n-------------------------------\n\n【31】Among the 1520 subjects who were 62 to 80 years of age and had normal blood counts and no history of cancer, CLL-phenotype MBL was detected in 78 (5.1%) and non–CLL-phenotype MBL (i.e., light-chain–restricted CD19+ B cells with no CD5 expression and strong CD20 expression) was identified in 27 (1.8%). In most subjects, the absolute B-cell count was within the normal range of 25 to 490 per cubic millimeter. Of the 2228 subjects referred for review for lymphocytosis who had a current or previous lymphocyte count above 4000 per cubic millimeter, CLL-phenotype MBL was detected in 309 (13.9%). CLL was diagnosed in 1031 of the 2228 subjects (46.3%), and a non-CLL B-cell abnormality or reactive lymphocytosis in 888 (39.9%).\n\n【32】Chromosomal Abnormalities\n-------------------------\n\n【33】Table 2. Chromosomal Abnormalities and _IGHV_ Gene Usage and Mutation in Subjects with CLL-Phenotype MBL.\n\n【34】Interphase FISH analysis was performed in 71 subjects with CLL-phenotype MBL in either cohort . The proportion of subjects with a 13q14 deletion or trisomy 12 was similar to that seen among the subjects with CLL described by Döhner et al.  ; 13q14 deletion was detected in 48% of our subjects and trisomy 12 in 20% (vs. 55% and 16%, respectively, in the study by Döhner et al.). Markers associated with poor prognosis (deletion of the ataxia–telangiectasia mutated gene _ATM_ or the tumor protein p53 gene _TP53_ ) were detected in none of the subjects with CLL-phenotype MBL and a normal blood count and in only 3 of the 33 subjects (9%) with CLL-phenotype MBL and lymphocytosis.\n\n【35】_IGHV_ Gene Repertoire and Mutation Status\n------------------------------------------\n\n【36】Direct _IGHV_ sequencing was performed in 40 subjects with CLL-phenotype MBL . The presence of more than 2% mutation from the germ-line sequence in the _IGHV_ gene is a good prognostic factor for CLL, occurring in 55% (796 of 1447) of reported subjects with CLL (range, 47 to 58).  A total of 88% (35 of 40) subjects with CLL-phenotype MBL had more than 2% _IGHV_ mutation. The _IGHV_ repertoire was skewed, with over half the 40 subjects having rearranged _IGHV3-07, IGHV3-23,_ or _IGHV4-34_ segments, which account for less than one quarter of rearranged _IGHV_ genes in normal B cells.  There was no significant difference in the _IGHV_ repertoire between subjects with a normal blood count and those with lymphocytosis (P=0.46 by the likelihood-ratio chi-square analysis). In comparison with previously reported subjects with CLL,  the _IGHV_ repertoire in all subjects with CLL-phenotype MBL was similar to that seen in subjects with CLL associated with a favorable prognosis, as defined by the presence of more than 2% _IGHV_ mutation from the germ-line sequence (P=0.14 by the likelihood-ratio chi-square analysis) but significantly different from the _IGHV_ repertoire seen in subjects with CLL associated with a poor prognosis, as defined by the presence of _IGHV_ mutation of less than or equal to 2% (P<0.001 by the likelihood-ratio chi-square analysis).\n\n【37】Outcomes in Subjects Presenting with Lymphocytosis\n--------------------------------------------------\n\n【38】Figure 1. Kaplan–Meier Estimates of Outcomes among Subjects with CLL-Phenotype MBL and Lymphocytosis.\n\n【39】Panel A shows the proportion of subjects remaining alive and the proportion who were alive and remained free from treatment for CLL. Panel B shows the proportion of subjects with stable CLL-phenotype MBL, defined as the absence of symptoms or features of CLL and the maintenance of a stable lymphocyte count (a count less than twice that at presentation).Table 3.  Table 3. Risks of Progressive Lymphocytosis and Death among Subjects with CLL-Phenotype MBL and Lymphocytosis, According to Feature at Presentation.\n\n【40】Sequential monitoring with a median follow-up of 6.7 years (range, 0.2 to 11.8) was performed in 185 subjects with CLL-phenotype MBL referred for investigation of a current or previous lymphocyte count above 4000 per cubic millimeter. Figure 1 shows their Kaplan–Meier estimates of outcome, Table 1 lists their outcome data, and Table 3 lists the risk factors for progressive lymphocytosis and for death.\n\n【41】Progressive lymphocytosis was observed in 51 of the 185 subjects (28%) during the follow-up period, with a lymphocyte count above 30,000 per cubic millimeter occurring in 31 of the 51 subjects. The total lymphocyte count at presentation was a significant risk factor for progressive lymphocytosis in the univariate analysis but not the multivariate analysis. The previously used cutoff point of 5000 lymphocytes per cubic millimeter was not predictive of progressive lymphocytosis or the development of CLL. The B-cell count at presentation was the only significant independent factor that predicted progressive lymphocytosis, whether assessed using cutoff points or as a continuous variable. After a median of 6.9 years of follow-up (range, 0.2 to 11.5), there was little or no change in the total lymphocyte count in subjects with a B-cell count below 1900 per cubic millimeter at presentation. The hazard ratio for the development of progressive lymphocytosis was 1.46 (95% confidence interval \\[CI\\], 1.12 to 1.91) for each increase of 1000 B cells per cubic millimeter at presentation (P=0.005 by Cox proportional-hazards model).\n\n【42】Of the 51 subjects with progressive lymphocytosis, further evidence of progressive CLL, predominantly lymphadenopathy, developed in 28 (55%), and 13 of these 51 subjects eventually required chemotherapy . Treatment was initiated at a median of 4.0 years (range, 1.1 to 10.1) after initial diagnosis. The estimated rate of progression to CLL requiring treatment among subjects with CLL-phenotype MBL presenting with lymphocytosis was 1.1% per year (95% CI, 0.7 to 1.9). None of the factors assessed — including age, sex, hemoglobin level, total lymphocyte count, T-cell count, B-cell count, and B-cell CD38 expression — predicted an increased risk of disease progression or the requirement for treatment. Of the 13 treated subjects, 7 are alive, with a median of 1.9 years (range, 0.0 to 8.6) of follow-up since the initiation of treatment.\n\n【43】There were 62 deaths among the subjects with CLL-phenotype MBL and lymphocytosis during follow-up. The age and hemoglobin level at diagnosis of CLL-phenotype MBL were the only independent factors associated with overall survival. By definition, anemia at the time of diagnosis of CLL-phenotype MBL was not autoimmune or due to bone marrow infiltration by CLL. Of the 62 subjects who died, 13 had progressive CLL, but this was noted as a cause of death in only 4.\n\n【44】Discussion\n----------\n\n【45】MBL is a relatively new diagnostic category, which reflects the ability of high-sensitivity flow cytometry to detect CLL-phenotype cells at low levels during routine investigations for unrelated disorders or health screening. Separating CLL-phenotype MBL from CLL is important, because CLL-phenotype MBL does not necessarily evolve into CLL.\n\n【46】CLL-phenotype cells are detectable in over 3% of adults  and in over 10% of persons with more than two first-degree relatives affected by CLL.  The CLL phenotype is always associated with monoclonal surface immunoglobulin.  Preliminary reports indicate that proteins such as CD81 and messenger RNA such as lymphoid enhancer-binding factor 1, which are aberrantly expressed in CLL, show a similar pattern in CLL-phenotype MBL.  Our study found that CLL-phenotype cells can have chromosomal abnormalities, most notably the deletion of 13q14, which occurs at similar frequencies in CLL-phenotype MBL and in CLL. _IGHV_ gene usage in CLL-phenotype MBL is skewed, with more than 87% of subjects having mutated _IGHV_ genes. Therefore, even at the lowest levels of detection in persons with a normal blood count, CLL-phenotype B cells are, according to the currently available methods, biologically indistinguishable from CLL B cells.\n\n【47】Outcome data for persons with CLL-phenotype MBL have been limited to two studies involving fewer than 50 subjects and less than 5 years of follow-up.  In our study, during a median follow-up of 6.7 years, progressive CLL (characterized by lymphadenopathy, splenomegaly, anemia, thrombocytopenia, lymphocyte doubling time <6 months, persistent infection, or drenching night sweats) developed in 15% (28 of 185) of subjects with CLL-phenotype MBL with an initial lymphocyte count of more than 4000 per cubic millimeter. The annual risk of developing CLL requiring chemotherapy among subjects with CLL-phenotype MBL presenting with lymphocytosis was 1 to 2%, which is similar to the rate of progression to myeloma seen in patients with monoclonal gammopathy of undetermined significance (MGUS).  A further similarity to MGUS is that the majority of deaths of subjects with CLL-phenotype MBL are not due to CLL but to unrelated causes. Age and hemoglobin level were the only independent factors predicting death in our series. Anemia was not caused by the CLL-phenotype cells, because such a cause would exclude a diagnosis of MBL. The B-cell and T-cell counts at presentation were of borderline significance, and the relevance of these factors may become apparent in larger series.\n\n【48】Predicting outcome in subjects with CLL-phenotype MBL is difficult, because few subjects express markers associated with an adverse outcome in CLL, such as unmutated _IGHV_ genes.  Moreover, progression can occur in subjects with CLL-phenotype MBL in whom B cells express markers associated with a good outcome in CLL. Lymphocyte doubling time is uninformative, because CLL-phenotype cells usually do not represent the majority of lymphocytes. Kaplan–Meier curves of disease progression showed no plateau over time, indicating that, as with MGUS, indefinite periodic monitoring is indicated for subjects with CLL-phenotype MBL presenting with a lymphocytosis.\n\n【49】Our data support the use of the B-cell count rather than lymphocyte count for the diagnosis of CLL or MBL. The cutoff point of 5000 lymphocytes per cubic millimeter does not predict outcome and allows for a diagnosis of CLL in someone with a reactive T-cell lymphocytosis. The age-standardized incidence rate in our region, since the diagnosis of CLL-phenotype MBL was introduced in 2005, is 2.4 cases per 100,000 per year, as compared with 5.8 cases of CLL. The incidence rate for CLL-phenotype MBL with a B-cell count above 1900 cells per cubic millimeter is 2 cases per 100,000 per year. The incidence rate is less than 1 case per 100,000 per year among persons younger than 40 years of age, rising steadily to 30 cases per 100,000 per year among adults over 70 years of age. \n\n【50】In summary, we have found a biologic relation between CLL-phenotype MBL and CLL. The majority of deaths in persons with CLL-phenotype MBL are due to unrelated causes, but progressive CLL requiring chemotherapy will develop in a clinically significant proportion of subjects presenting with lymphocytosis.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 18:16:08", "endTime": "2024/08/13 18:16:57", "cost": 48.427}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 02:16:57", "grab_time": "2024-08-13 02:16:08"}
{"id": 2234287, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "3a52a020-2690-4c36-abca-46ced083e789", "title": "Tumor-Infiltrating Lymphocyte Therapy or Ipilimumab in Advanced Melanoma", "text": "【0】Tumor-Infiltrating Lymphocyte Therapy or Ipilimumab in Advanced Melanoma\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Immune checkpoint inhibitors and targeted therapies have dramatically improved outcomes in patients with advanced melanoma, but approximately half these patients will not have a durable benefit. Phase 1–2 trials of adoptive cell therapy with tumor-infiltrating lymphocytes (TILs) have shown promising responses, but data from phase 3 trials are lacking to determine the role of TILs in treating advanced melanoma.\n\n【3】Methods\n-------\n\n【4】Download a PDF of the Research Summary .\n\n【5】In this phase 3, multicenter, open-label trial, we randomly assigned patients with unresectable stage IIIC or IV melanoma in a  ratio to receive TIL or anti–cytotoxic T-lymphocyte antigen 4 therapy (ipilimumab at 3 mg per kilogram of body weight). Infusion of at least 5×10 <sup>9 </sup> TILs was preceded by nonmyeloablative, lymphodepleting chemotherapy (cyclophosphamide plus fludarabine) and followed by high-dose interleukin-2. The primary end point was progression-free survival.\n\n【6】Results\n-------\n\n【7】A total of 168 patients (86% with disease refractory to anti–programmed death 1 treatment) were assigned to receive TILs (84 patients) or ipilimumab (84 patients). In the intention-to-treat population, median progression-free survival was 7.2 months (95% confidence interval \\[CI\\], 4.2 to 13.1) in the TIL group and 3.1 months (95% CI, 3.0 to 4.3) in the ipilimumab group (hazard ratio for progression or death, 0.50; 95% CI, 0.35 to 0.72; P<0.001); 49% (95% CI, 38 to 60) and 21% (95% CI, 13 to 32) of the patients, respectively, had an objective response. Median overall survival was 25.8 months (95% CI, 18.2 to not reached) in the TIL group and 18.9 months (95% CI, 13.8 to 32.6) in the ipilimumab group. Treatment-related adverse events of grade 3 or higher occurred in all patients who received TILs and in 57% of those who received ipilimumab; in the TIL group, these events were mainly chemotherapy-related myelosuppression.\n\n【8】Conclusions\n-----------\n\n【9】In patients with advanced melanoma, progression-free survival was significantly longer among those who received TIL therapy than among those who received ipilimumab. \n\n【10】Introduction\n------------\n\n【11】 QUICK TAKE  \nTumor-Infiltrating Lymphocytes in Advanced Melanoma  \n\n【12】Programmed death 1 (PD-1) protein blockade with nivolumab or pembrolizumab is a frequently used first-line treatment in patients with metastatic melanoma.  Combination immunotherapy with ipilimumab (an anti–cytotoxic T-lymphocyte antigen 4 antibody) and nivolumab induces responses in a higher percentage of patients (58% vs. 45%)  but is associated with a high incidence of severe adverse events and is currently recommended primarily for a subgroup of patients with poor prognostic factors such as a high serum lactate dehydrogenase (LDH) level or liver or brain metastases.\n\n【13】Approximately 50% of melanomas harbor a mutation in _BRAF_ ; thus, an additional treatment option is combined BRAF and MEK inhibition. Although this therapy is associated with a high response, resistance develops in most patients over time.  Ipilimumab (with or without nivolumab) has become a second-line treatment option, but objective responses and durable benefits occur in only 15 to 30% of patients.  Combination treatment with nivolumab and anti–lymphocyte-activation gene 3 (LAG-3) has also been associated with objective responses in 16% of patients with disease that was refractory to anti–PD-1 therapy, but data on progression-free survival are lacking.  Although these new treatment options have substantially improved the prognosis in patients with metastatic melanoma, approximately 50% still die from the disease within 5 years after the diagnosis of stage IV disease. \n\n【14】Adoptive cell therapy with tumor-infiltrating lymphocytes (TILs) is a personalized autologous treatment that involves the ex vivo outgrowth and expansion of tumor-resident T cells and subsequent intravenous adoptive transfer of the cells after preparative lymphodepleting chemotherapy, which is supported by the administration of interleukin-2 to enhance the in vivo expansion of the cells and augment antitumor responses.  Evidence of clinical activity of TIL therapy in patients with advanced melanoma was reported by Rosenberg and colleagues in the 1990s.  Subsequent phase 1–2 trials showed responses in 36% and 70% of patients, with durable complete responses in up to 20% of patients.  More recently, objective responses were observed in 36% of patients who received LN-144 TIL therapy, even among those who had disease progression while receiving anti–PD-1 treatment, findings that illustrate the potential of this treatment after failure of previous immune checkpoint inhibition.  Despite these promising results, the role of TILs in the current treatment landscape remains undefined because data on a direct comparison of TILs with standard treatment are lacking. In this multicenter, open-label, phase 3, randomized trial, we compared TILs with ipilimumab as first- or second-line treatment in patients with advanced melanoma.\n\n【15】Methods\n-------\n\n【16】Patients\n--------\n\n【17】Patients were eligible for inclusion in the trial if they were 18 to 75 years of age and had histologically confirmed, unresectable or metastatic stage IIIC or IV cutaneous melanoma (hereafter “advanced melanoma”) (as defined in the seventh edition of the _Cancer Staging Manual_ of the American Joint Committee on Cancer) with one or more lesions (collectively 2 to 3 cm in diameter) that could be surgically removed for generation of TILs. In addition, patients were required to have residual measurable disease after resection as defined by the following: Response Evaluation Criteria in Solid Tumors (RECIST), version 1.1 <sup><a>28 </a></sup> ; a World Health Organization performance-status score of 0 or 1 (on a scale of 0 to 5, with higher numbers indicating greater disability); and a serum LDH level that was less than or equal to 2 times the upper limit of the normal range. One previous line of systemic treatment for this disease stage, excluding ipilimumab, was allowed. A full overview of eligibility criteria is provided in the Supplementary Methods section in the Supplementary Appendix , available with the full text of this article at NEJM.\n\n【18】Trial Design and Treatment\n--------------------------\n\n【19】In this multicenter, open-label, phase 3 trial, patients were randomly assigned in a  ratio to receive either TILs or ipilimumab. Randomization was stratified according to _BRAF_ V600–mutation status, line of treatment, and treatment center. Patients who were assigned to receive TILs underwent a metastasectomy for the retrieval and expansion of TILs, followed by hospital admission for administration of nonmyeloablative, lymphodepleting chemotherapy (cyclophosphamide at a dose of 60 mg per kilogram of body weight per day for 2 days intravenously and fludarabine at a dose of 25 mg per square meter of body-surface area per day for 5 days intravenously), single intravenous adoptive transfer of 5×10 <sup>9 </sup> to 2×10 <sup>11 </sup> TILs, and subsequent high-dose interleukin-2 (600,000 IU per kilogram per dose) every 8 hours, for a maximum of 15 doses per protocol . Patients in the ipilimumab group received 3 mg of ipilimumab per kilogram intravenously every 3 weeks, for a maximum of 4 doses. Administration of ipilimumab could be delayed or discontinued if adverse events occurred, in accordance with the protocol. No dose reductions were allowed.\n\n【20】End Points and Assessments\n--------------------------\n\n【21】The primary end point was progression-free survival assessed by the investigator with the use of RECIST, version 1.1. Progression-free survival was defined as the time from randomization to first disease progression (either radiologic progression or subsequent anticancer therapy, including systemic therapy, radiotherapy, or surgery) or death. The secondary end points were the following: progression-free survival assessed according to immune-related response criteria  ; objective response assessed according to RECIST, version 1.1, and immune-related response criteria; complete response; overall survival; health-related quality of life; and safety.\n\n【22】Health-related quality of life was measured with the use of the European Organization for Research and Treatment of Cancer Quality-of-Life Questionnaire Core 15 palliative care, a 15-item questionnaire on which higher scores on the global quality-of-life and functioning scales indicate better functioning and higher scores on the symptom scales indicate higher levels of symptom burden.  Adverse events were evaluated by the treating physician in accordance with the National Cancer Institute Common Terminology Criteria for Adverse Events, version 4.03. Efficacy analyses included all patients who underwent randomization (the intention-to-treat population), and safety analyses included all patients who had received chemotherapy and TIL or at least one dose of ipilimumab. Additional information on end-point assessment is provided in the Supplementary Methods section of the Supplementary Appendix .\n\n【23】Trial Oversight\n---------------\n\n【24】The trial was designed at one of the two participating clinical sites (the Netherlands Cancer Institute, Amsterdam) and was approved by the Central Committee on Research Involving Human Subjects in the Netherlands and the institutional review board and independent ethics committee at each trial center. The other participating clinical site was the National Center for Cancer Immune Therapy, Copenhagen University Hospital, Herlev, Denmark. The trial was conducted in accordance with the principles of the Declaration of Helsinki, the Harmonized Tripartite Guideline for Good Clinical Practice from the International Council for Harmonisation, and the ethical principles underlying European Union Directive 2001/20/EC. All the patients provided written informed consent and received treatment at one of the two primary clinical sites. An independent data and safety monitoring board reviewed progress and safety.\n\n【25】Data were collected at each participating site, and raw data were seen only by the trial team from each participating site in accordance with the clinical trial agreement; a master data and sample transfer contract was signed by both sites. The data were analyzed at the Netherlands Cancer Institute. Authors who were not employees of the two participating clinical sites did not have access to the raw data. The authors agreed to maintain confidentiality of the data until publication and vouch for the accuracy and completeness of the data and for the fidelity of the trial to the protocol. All the authors contributed to drafting the manuscript, provided critical revision, or did both, and all approved the decision to submit the final manuscript for publication. No one who is not an author contributed to writing the manuscript.\n\n【26】Generation of Tumor-Infiltrating Lymphocytes\n--------------------------------------------\n\n【27】The manufacturing of TILs was based on established techniques.  TILs were manufactured at each trial center with the use of harmonized standard operating procedures according to the Good Manufacturing Practice guidelines of the European Union and EudraLex volume 4, which is specific to advanced therapy medicinal products. The TILs were classified as advanced therapy medicinal products under European Commission regulation 1394/2007. Further details are provided in the Supplementary Methods section of the Supplementary Appendix .\n\n【28】Statistical Analysis\n--------------------\n\n【29】The sample size was calculated on the basis of a comparison of the percentage of patients with progression-free survival at 6 months. On the basis of a study by Hodi et al.,  it was expected that the percentage of patients with progression-free survival at 6 months in the ipilimumab group would be 20 to 25%. We estimated that at least 80 patients would have to undergo randomization in each group (160 patients in total) for the trial to have 90% power to detect an increase in progression-free survival at 6 months from 20% in the ipilimumab group to 45% in the TIL group (odds ratio, 3.27), using a two-group continuity corrected chi-square test with a two-sided significance level of 0.05. With this level of accrual, an absolute increase from 25 percentage points with ipilimumab to 50 percentage points with TIL therapy (odds ratio, 3.0) in progression-free survival could be detected with 88% power. Considering the possibility that 5 to 10% of the patients randomly assigned to the TIL group would not receive the intended treatment, the required sample size was calculated to be 168 to 176 patients. Although the trial was powered to compare progression-free survival at 6 months, during the course of the trial it was considered statistically more efficient to analyze the entire progression-free survival curve with the use of survival methods, and this was included in a protocol amendment. Considering that the power calculation reflected a conservative approach, analysis of complete progression-free survival would yield sufficient power.\n\n【30】Progression-free and overall survival curves were constructed with the use of the Kaplan–Meier method, and treatment groups were compared with the use of the stratified (unweighted) log-rank test and the stratified Cox regression model. The trial was considered to be positive if the progression-free survival among patients who received TILs was significantly longer than that among those who received ipilimumab, on the basis of the log-rank test with a two-sided P value below 0.05. In addition, a prespecified per-protocol analysis of the primary end point with the use of a landmark approach was performed, including patients who received the trial treatment without rapid clinical progression within 5 weeks after randomization. As exploratory post hoc analyses, comparisons of progression-free and overall survival across subgroups of interest were performed. Data are presented in a forest plot, and survival curves were constructed with the use of the Kaplan–Meier method.\n\n【31】Responses after TIL and ipilimumab treatment were reported with their associated 95% binomial confidence intervals. Health-related quality-of-life outcomes were evaluated with the use of a generalized-estimating-equations model for longitudinal data.  The widths of the confidence intervals for the secondary end points and exploratory post hoc analyses have not been adjusted for multiplicity and cannot be used in place of a hypothesis test. Details are provided in the Statistical Analyses section of the Supplementary Appendix , protocol, and statistical analysis plan.\n\n【32】Results\n-------\n\n【33】Patients and Treatment\n----------------------\n\n【34】Table 1. Baseline Characteristics of the Patients.\n\n【35】Between September 2014 and March 2022, a total of 168 patients were randomly assigned to receive either TILs (84 patients) or ipilimumab (84 patients) (the intention-to-treat population) . Baseline characteristics were balanced between the two treatment groups . A total of 149 of 168 patients (89%) had disease progression after receiving previous systemic therapy — mostly adjuvant anti–PD-1 therapy (40 patients \\[24%\\]) or first-line anti–PD-1 therapy (105 patients \\[62%\\]). Details regarding these systemic therapies are provided in Table S1.\n\n【36】At the time of the data cutoff on June 9, 2022, the overall median follow-up was 33.0 months. A total of 80 patients had received TILs and 82 patients had received at least one infusion of ipilimumab. The reasons for nonreceipt of TILs were patient decision (in 1 patient), late response to previous therapy (in 1 patient), insufficient TIL outgrowth (in 1 patient), and rapid clinical progression (in 1 patient). Patients who received TILs received a median of 40.9×10 <sup>9 </sup> cells (range, 4.9 to 110.4) and a median of 4 doses of high-dose interleukin-2 (range, 0 to 10). The median duration of hospital admission was 17 days (range, 12 to 38). Two patients did not receive ipilimumab owing to patients’ decision or rapidly progressive disease that warranted the immediate initiation of combined BRAF and MEK inhibition. Patients who received ipilimumab received a median of 3 infusions (range, 1 to 4), and 26 of the 42 patients (62%) who discontinued treatment prematurely did so because of adverse events .\n\n【37】Efficacy\n--------\n\n【38】Figure 1. Progression-free Survival.\n\n【39】Progression-free survival assessed according to the Response Evaluation Criteria in Solid Tumors (RECIST), version 1.1, is shown for all patients who were randomly assigned to receive tumor-infiltrating lymphocyte (TIL) therapy or ipilimumab (the intention-to-treat population). The patients were stratified according to _BRAF_ V600–mutation status, line of treatment, and treatment center. Hazard ratios were estimated with the use of the stratified Cox regression model. The P value was calculated with the use of the stratified log-rank test with a two-sided 95% confidence interval. Tick marks indicate censored data..\n\n【40】In the intention-to-treat population, TILs were associated with a significant benefit with respect to progression-free survival assessed according to RECIST, version 1.1, with a median progression-free survival of 7.2 months (95% confidence interval \\[CI\\], 4.2 to 13.1), as compared with 3.1 months (95% CI, 3.0 to 4.3) with ipilimumab (hazard ratio for progression or death, 0.50; 95% CI, 0.35 to 0.72; P<0.001 by an unweighted stratified log-rank test) . The percentage of patients with progression-free survival at 6 months was 52.7% (95% CI, 42.9 to 64.7) in the TIL group and 21.4% (95% CI, 14.2 to 32.2) in the ipilimumab group. This benefit of TILs over ipilimumab was confirmed in a prespecified per-protocol analysis . With assessment according to immune-related response criteria, median progression-free survival was 6.0 months (95% CI, 4.6 to 12.0) in the TIL group, as compared with 3.2 months (95% CI, 3.0 to 4.4) in the ipilimumab group (hazard ratio, 0.56; 95% CI, 0.39 to 0.79) . Results of a post hoc analysis of progression-free survival in key subgroups are shown in Figures S5 and S6.\n\n【41】Table 2. Best Response. Figure 2.  Figure 2. Clinical Activity of Treatment.\n\n【42】The waterfall plot shows the maximum percentage change in tumor size from baseline (on computed tomographic imaging closest to the start of treatment in both groups) in the intention-to-treat population in patients who were assigned to receive TIL therapy  or ipilimumab . The tumor size was calculated as the sum of the diameters of all target lesions in each patient. In 14 patients (3 patients \\[4%\\] in the TIL group and 11 \\[13%\\] in the ipilimumab group), the best radiologic change in tumor size could not be evaluated or evaluation was not performed because of an event (death or rapid clinical progression for which the initiation of subsequent anticancer therapy was warranted) that occurred before the first response evaluation. Data from these patients were excluded from this figure. In 6 patients (3 patients \\[4%\\] in the TIL group and 3 \\[4%\\] in the ipilimumab group), the best change in tumor size from baseline was 0.0%. Each bar represents 1 patient, and bar colors indicate the best objective response category according to RECIST, version 1.1, in evaluable patients. The change in tumor size was calculated as the maximum percentage change in the size of target lesions from baseline to the time of progression. Patients who had a complete response without a 100% decrease in tumor size had residual lymph nodes smaller than 10 mm in the shortest diameter or residual lesions smaller than 5 mm in diameter.\n\n【43】The percentage of patients with an objective response according to RECIST, version 1.1, was 49% (95% CI, 38 to 60) in the TIL group and 21% (95% CI, 13 to 32) in the ipilimumab group. Complete responses were observed in 20% (95% CI, 12 to 30) of the patients in the TIL group and 7% (95% CI, 3 to 15) of those in the ipilimumab group , with durable complete responses in both treatment groups . With assessment according to immune-related response criteria, objective responses were seen in 50% (95% CI, 39 to 61) of patients in the TIL group and 20% (95% CI, 12 to 30) of those in the ipilimumab group. Table S3, which shows an overview of systemic treatments administered after disease progression, indicates that more patients in the TIL group who had not had a response received ipilimumab or the combination of ipilimumab and nivolumab than those in the ipilimumab group who had not had a response.\n\n【44】Overall Survival\n----------------\n\n【45】Median overall survival among patients in the TIL group was 25.8 months (95% CI, 18.2 to not reached), as compared with 18.9 months (95% CI, 13.8 to 32.6) among those in the ipilimumab group (hazard ratio for death, 0.83; 95% CI, 0.54 to 1.27). The 2-year overall survival was 54.3% (95% CI, 43.9 to 67.2) in the TIL group and 44.1% (95% CI, 33.6 to 57.8) in the ipilimumab group . Overall survival in key subgroups is shown in Figures S9 through S11.\n\n【46】Safety\n------\n\n【47】Table 3. Most Common Treatment-Related Adverse Events.\n\n【48】Adverse events that were assessed by the investigators as being related to treatment occurred in all patients in the TIL group and in 96% of those in the ipilimumab group. The most common adverse events of any grade related to TILs and ipilimumab are presented in Table 3 . All patients in the TIL group had grade 3 or 4 neutropenia owing to preparative lymphodepleting chemotherapy, with a median duration of neutropenia of 7 days (range, 2 to 58 days). Capillary leak syndrome (of any grade) associated with interleukin-2 occurred in 30% of the patients who received TILs and interleukin-2 . In the TIL group, autoimmune toxic effects leading to skin hypopigmentation occurred in 9 patients (11%) ; uveitis occurred in 6 patients (8%), and hearing impairment occurred in 3 patients (4%) .\n\n【49】Treatment-related adverse events of grade 3 or higher occurred in all patients in the TIL group and in 57% of those in the ipilimumab group. Treatment-related serious adverse events occurred in 15% of the patients in the TIL group and 27% of those in the ipilimumab group . All treatment-related serious adverse events are shown in Table S6. New TIL-related adverse events of grade 3 or higher occurred typically during hospital admission (in 99% of cases) and were handled according to protocol on the oncology ward; short-term stabilization in an intensive care unit was warranted in eight patients (10%). One patient in the TIL group died from an arterial thromboembolism on day 22 after treatment; this death was not considered by the investigators to be related to treatment.\n\n【50】Health-Related Quality of Life\n------------------------------\n\n【51】Table 4. Health-Related Quality-of-Life Scores at 6 Months.\n\n【52】Patients in the TIL group had higher mean scores on the global health-related quality-of-life, physical functioning, and emotional functioning domains after treatment than those in the ipilimumab group . Patients in the TIL group reported a lower symptom burden of fatigue, pain, and insomnia than those in the ipilimumab group, with differences still observed at week 60 . However, patients in the TIL group reported a higher symptom burden of nausea and vomiting than those in the ipilimumab group, with a mean difference in symptom scores of 1.6 at week 24.\n\n【53】Discussion\n----------\n\n【54】This multicenter, phase 3, randomized trial involving patients with advanced melanoma compared TIL T-cell therapy as first- or second-line treatment with ipilimumab, which has previously been used as a second-line option in metastatic melanoma.  Progression-free survival was more than twice as long in the TIL group as in the ipilimumab group, and the hazard of disease progression or death was 50% lower. Separation of the progression-free survival curves occurred within 6 months after randomization, with a 30 percentage-point difference between the groups at 6 months and a continued benefit for patients in the TIL group.\n\n【55】Previous phase 1–2 trials have shown the potential clinical benefit of TILs in patients with metastatic melanoma, although most involved patients who had not received anti–PD-1 therapy.  In the current trial, although 86% of the patients had had disease progression after they received previous anti–PD-1 treatment either as adjuvant or first-line agents, 49% of the patients in the TIL group had an objective response, and of these patients, 20% had a complete response. These percentages are higher than those seen in a recent trial of LN-144 TIL therapy,  possibly because most patients who received LN-144 TIL therapy had had disease progression after multiple previous lines of systemic treatment, including anti–PD-1 therapy, ipilimumab, and — in patients with _BRAF_ V600–mutated melanoma — BRAF and MEK inhibition. In our trial, no major differences in progression-free survival were observed according to the stratification factors of _BRAF_ mutation status, line of treatment, or treatment center.\n\n【56】First-line treatment options for advanced melanoma have rapidly evolved over the past 5 years. In addition to anti–PD-1 therapy, currently approved treatment options are the following: combination therapy with ipilimumab and nivolumab, combined BRAF and MEK inhibitors, and relatlimab (an anti–LAG-3 antibody) plus nivolumab.  In our trial, nine patients (11%) received TILs as first-line treatment, and no major difference was seen in progression-free survival among patients who had received no previous therapy, those who had received adjuvant therapy, and those who had received previous first-line anti–PD-1 therapy. This finding suggests that TIL therapy can also be effective as first-line treatment; however, patient and disease characteristics (e.g., brain metastases, a high serum LDH level, or poor performance status), potential toxic effects, and the availability of the treatment play important roles in the choice of treatment. Our trial primarily included patients who had received previous adjuvant or first-line anti–PD-1 monotherapy. For these patients, TIL therapy could be a possible first- or second-line treatment option for metastatic disease, as shown in this trial, whereas the data on LN-144 TIL therapy in patients with more refractory disease clearly suggest a broader indication for TILs.\n\n【57】The antitumor activity of ipilimumab monotherapy after failure of anti–PD-1 inhibition is well known, with objective responses in 4 to 56% of patients,  results that were confirmed in this trial. In a retrospective, multicenter, cohort trial involving 355 patients with advanced melanoma that was refractory to anti–PD-1 therapy, 31% of the patients who received a combination of ipilimumab plus nivolumab had an objective response, as compared with 13% of those who received ipilimumab alone.  Similar objective responses were observed in a recent prospective trial involving patients with advanced melanoma that was refractory to anti–PD-1 therapy. That trial showed objective responses in 19 of 69 patients (28%) who received a second-line combination of ipilimumab and nivolumab and in 2 of 23 patients (9%) who received second-line ipilimumab monotherapy.  The estimates of 6-month progression-free survival were 34% (90% CI, 25 to 44) in the combination-treatment group and 13% (90% CI, 4 to 27) in the ipilimumab-monotherapy group. In our trial, the percentage of patients with progression-free survival at 6 months was 52.7% (95% CI, 42.9 to 64.7) in the TIL group and 21.4% (95% CI, 14.2 to 32.2) in the ipilimumab group. The results of these two trials cannot be directly compared, but they suggest a benefit of TILs over the combination of ipilimumab plus nivolumab. The difference between the two ipilimumab groups could be explained by differences in the baseline characteristics of the patients, especially the serum LDH level. In addition to immunotherapies, combined BRAF and MEK inhibition remains a second-line treatment option for patients with _BRAF_ V600–mutated melanoma. Although this treatment has been associated with high objective responses in up to 57% of patients,  treatment resistance remains a problem in the majority of patients.\n\n【58】In our trial, treatment-related adverse events were more frequently seen with TILs than with ipilimumab, owing predominantly to chemotherapy, interleukin-2, or both, and these events were in line with those in previous studies.  Despite the increased frequency of adverse events, the global health-related quality-of-life scores were higher in patients who received TILs. In this trial, treatment with ipilimumab resulted in a high incidence of adverse events of grade 3 or higher (57%).\n\n【59】This phase 3, multicenter, open-label, randomized trial involving patients with advanced melanoma (the majority of whom had disease that was refractory to anti–PD-1 therapy) showed that TILs can be successfully generated from resected melanoma metastases in patients with advanced melanoma. Treatment with TILs was associated with significantly longer progression-free survival than treatment with ipilimumab.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 11:07:14", "endTime": "2024/08/14 11:11:31", "cost": 256.106}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 19:11:30", "grab_time": "2024-08-13 19:07:14"}
{"id": 2234286, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "e6dbfaf8-4629-4e33-a22f-ab7c8a62056a", "title": "Prophylactic Sclerotherapy of Large Esophageal Varices", "text": "【0】Prophylactic Sclerotherapy of Large Esophageal Varices\nAbstract\n--------\n\n【1】We randomly assigned 95 patients with large esophageal varices (Grade 3 or 4) who had not previously had upper gastrointestinal tract bleeding to two groups: 49 received intravariceal sclerotherapy, and 46 were followed as controls. Over a mean follow-up of 13 months there was no difference between the sclerotherapy group and the control group in mortality (24.4 percent) or any significant difference in average hospital stay per month (3.0 vs. 2.6 days). Sclerotherapy was associated with significantly more episodes of upper gastrointestinal bleeding (26 vs. 10 episodes, P<0.05); 75 percent of deaths in the sclerotherapy group were related to bleeding, as compared with 18 percent in the control group.\n\n【2】An additional 54 patients with cirrhosis who did not qualify for the study were also followed — 20 with small varices and 34 with none. Mortality was 20 and 15 percent, respectively; no deaths were due to bleeding.\n\n【3】We conclude that prophylactic sclerotherapy does not provide clinical benefit to patients with large esophageal varices.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:13:33", "endTime": "2024/08/14 15:13:39", "cost": 6.486}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 23:13:40", "grab_time": "2024-08-13 23:13:33"}
{"id": 2234285, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "e4d19291-b705-4941-8382-d29c422c10df", "title": "The Role of the Plasma from Platelet Concentrates in Transfusion Reactions", "text": "【0】The Role of the Plasma from Platelet Concentrates in Transfusion Reactions\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Febrile, nonhemolytic transfusion reactions are the most frequent adverse reactions to platelets. A number of observations argue against the widely held view that these reactions result from the interaction between antileukocyte antibodies in the recipient and leukocytes in the platelet product. We sought to determine whether substances in the plasma or the cells in the product cause reactions to transfused platelets.\n\n【3】Methods\n-------\n\n【4】We separated standard platelet concentrates into their plasma and cellular components and then transfused both portions in random order. Patients were monitored for reactions during all transfusions. Before each transfusion, the concentration of cytokines (interleukin-1β and interleukin-6) was measured in the platelet products. Studies were also performed on the platelet products to determine the effect of storage on the concentration of cytokines.\n\n【5】Results\n-------\n\n【6】Sixty-four pairs of platelet-product components (the plasma supernatant and the cells) were administered to 12 patients. There were 20 reactions to the plasma supernatant and 6 reactions to the cells (chi-square = 6.50, P = 0.009). Eight transfusions were associated with reactions to both products. The plasma component was more likely to cause severe reactions than the cells (chi-square = 9.6, P<0.01). A strong positive correlation was observed between the reactions and the concentration of interleukin-1β and interleukin-6 in the plasma supernatant (P<0.001 and P = 0.034, respectively). In vitro studies demonstrated that interleukin-1β and interleukin-6 concentrations rise progressively in stored platelets and that these concentrations are related to the leukocyte count in the platelet product.\n\n【7】Conclusions\n-----------\n\n【8】Bioreactive substances in the plasma supernatant of the platelet product cause most febrile reactions associated with platelet transfusions. Removing the plasma supernatant before transfusion can minimize or prevent these reactions.\n\n【9】Introduction\n------------\n\n【10】Febrile, nonhemolytic transfusion reactions are the most frequent adverse reactions to blood products. The risk of these reactions is highest with platelets; they occur in 5 to 30 percent of platelet transfusions, depending on the type of product  . Most of the reactions are mild, but some are life-threatening. The widespread practice of premedication with antipyretic agents often prevents fever, but not the other unpleasant side effects of the reactions  .\n\n【11】The mechanism of reactions to transfused platelets is not well understood. It is generally assumed that they are caused by the interaction of antileukocyte alloantibodies in the recipient's plasma and white cells in the platelet product  . Consistent with this view are reports that removing leukocytes from the platelet product can prevent some febrile reactions  . Yet, febrile transfusion reactions are more frequent with platelet transfusions than with red-cell transfusions, even though red-cell products contain more leukocytes  . Febrile reactions can occur in male patients who have never received a previous transfusion, which also argues against antileukocyte alloantibodies as the cause of the reactions  . Moreover, febrile transfusion reactions are more likely with platelets that have been stored than with relatively fresh platelets  . These observations suggest that a bioreactive substance or substances produced in the platelet concentrate during storage could mediate reactions caused by platelet transfusions.\n\n【12】To test this hypothesis, we gave patients with thrombocytopenia two fractions of platelet concentrates: the plasma supernatant and the cellular component (platelets and leukocytes). We found that the plasma supernatant was significantly more likely to produce adverse reactions than the cells. Reactions to the plasma component of the platelet product correlated with the concentrations of interleukin-1β and interleukin-6 in the supernatant. Parallel studies showed that the concentrations of interleukin-1β and interleukin-6 increased in the supernatant during storage of the platelet product.\n\n【13】Methods\n-------\n\n【14】Clinical Protocol\n-----------------\n\n【15】Patients were eligible for the study if they were over 17 years of age, had thrombocytopenia, and were expected to require a minimum of six platelet transfusions over a one-to-two-month period. Since our hypothesis stated that the plasma supernatant, rather than a factor in the recipient (i.e., antileukocyte alloantibodies) was responsible for these reactions, a previous platelet-associated reaction was not a criterion for entry. Each platelet transfusion consisted of a pool of concentrates prepared from whole blood from five random donors that had been collected in bags containing CP2D anticoagulant (Miles Laboratories, Berkeley, Calif.). Whenever possible, four- or five-day-old platelets were transfused to increase the likelihood of a reaction  . The pooled platelet concentrate was centrifuged at 2000 × g for 10 minutes, and 150 to 180 ml of the plasma supernatant was removed to a sterile transfer bag. The plasma supernatant contained low numbers of platelets and leukocytes (less than 10 <sup>6 </sup> per product)  . Approximately 180 ml of previously prepared fresh-frozen plasma from one of the platelet donors was added to the pellet of platelets and leukocytes remaining in the bag, and the product was allowed to rest at room temperature for 40 to 60 minutes before resuspension.\n\n【16】Plasma samples taken from the supernatant and from the product after resuspension of the cellular component were assayed to determine the leukocyte count, platelet count, interleukin-1β concentration, and interleukin-6 concentration. The age of the platelet product was also recorded. The components of the platelet product (plasma supernatant and cells) were transfused in random order, with a two-hour interval between infusions. The two-hour interval was selected as a washout period because our previous results indicated that most reactions occur during or just after transfusion and that symptoms subside within two hours  . Neither the patients nor the nursing staff were told which component was being transfused.\n\n【17】Before each transfusion, a questionnaire was administered to the patient to document base-line evidence of chills, cold, or discomfort on a seven-point Likert scale on which 1 indicated “no symptoms” and 7 “severe symptoms”  . Scores of 2 and 3 were considered to indicate mild symptoms, 4 and 5 moderate symptoms, and 6 and 7 severe symptoms. The questionnaire was readministered immediately after the transfusion and again one hour later. A reaction was defined as an increase in the severity of symptoms over the base-line level. The patient's temperature was also recorded each time. Standardized pretransfusion medication consisted of 25 mg of intravenous diphenhydramine hydrochloride (Benadryl, Parke-Davis, Scarborough, Ont.) and two 325-mg acetaminophen tablets (Tylenol, McNeil, Guelph, Ont.). Some patients also received 50 mg of meperidine hydrochloride (Demerol, Sanofi Winthrop, Markham, Ont.). Serum from the patients was tested for lymphocytotoxic antibodies (GenTrak, Plymouth Meeting, Pa.). The study was approved by the institutional ethics committee, and informed consent was obtained from each eligible patient before enrollment.\n\n【18】Laboratory Studies\n------------------\n\n【19】Ten platelet concentrates were prepared from blood from random donors that had been collected in bags containing CP2D anticoagulant. Each concentrate was separated into two equal portions, one of which was filtered (Pall PL50, Pall Biomedical Products, Toronto) to remove contaminating leukocytes. The concentrates were then stored at 22 °C with horizontal agitation for 10 days. Samples were taken from each concentrate (filtered and unfiltered) on days 1 through 5, day 7, and day 10 for cytokine measurement and bacterial culture. In the unfiltered portion of the concentrates, leukocyte and platelet counts were performed with a Coulter counter (Coulter Electronics, Hialeah, Fla.). In the filtered platelets, leukocyte counts were performed manually with a Hausser counting chamber  . The threshold of detection with this method is 10 <sup>6 </sup> leukocytes per product. Interleukin-1β was measured with an enzyme-linked immunosorbent assay (R and D Systems, Minneapolis). Interleukin-6 was measured with a standard bioassay. Proliferation of the interleukin-6-dependent B9 hybridoma cell line was used to assay samples, with recombinant human interleukin-6 used as a standard  .\n\n【20】Statistical Analysis\n--------------------\n\n【21】We analyzed the association between characteristics of the platelet concentrate (age, leukocyte count, and cytokine concentrations) and the likelihood of reaction using the Wilcoxon test. We compared rates of reaction and the severity of reactions associated with the plasma and cellular components of the platelet products using McNemar's chi-square test. The correlation of interleukin-1β and interleukin-6 concentrations with the leukocyte count during storage was determined with the Spearman rank-correlation coefficient.\n\n【22】Results\n-------\n\n【23】Clinical Study\n--------------\n\n【24】Twelve patients received a total of 64 pairs of transfusion components (range, 3 to 10) according to the protocol described. Seven of the patients had newly diagnosed acute myelogenous leukemia (AML) and were receiving induction chemotherapy. The remaining five patients had AML (relapsed or in remission), myelodysplastic syndrome, chronic myelogenous leukemia, or chronic idiopathic thrombocytopenic purpura with gastrointestinal hemorrhage. For 32 transfusion pairs, the plasma was administered first, and the cellular component two hours later. For the remaining 32 pairs, the cellular component was administered first.\n\n【25】Table 1. Number of Adverse Reactions, According to the Type of Product.\n\n【26】The frequency of adverse reactions to the plasma supernatant, the cellular component, and both products is shown in Table 1 . There were 28 reactions to the plasma supernatant and 14 reactions to the cellular component. In 20 transfusion pairs there were reactions to the plasma supernatant but not to the cellular component, and in 6 transfusion pairs there were reactions to the cellular component but not to the supernatant (chi-square = 6.50, P = 0.009).\n\n【27】Nine patients had more than one adverse reaction: seven had more reactions to the plasma supernatant than to the cellular component, one had more reactions to the cellular component, and one had an equal number of reactions to both components. With eight transfusion pairs, there were reactions to both the plasma and the cellular component. Two patients, who received three and four pairs of transfusion components, had no reactions. Six of the seven platelet products these two patients received were stored for four days or less, had leukocyte counts of less than 600 per cubic millimeter, and had low concentrations of interleukin-1β (≤ 12 pg per milliliter) and interleukin-6 (≤ 373 pg per milliliter). One five-day-old platelet concentrate had an absolute leukocyte count of 1800 per cubic millimeter and interleukin concentrations of 36 and 475 pg per milliliter, respectively.\n\n【28】The severity of reactions to the plasma supernatant was significantly greater than the severity of reactions to the cellular component. Forty-three percent of the reactions to the plasma (12 of 28) were graded severe. Thirty-two percent (9 of 28) were mild, and 25 percent (7 of 28) were moderate. In contrast, only 21 percent of the reactions to the cellular component (3 of 14) were severe, 21 percent (3 of 14) were moderate, and 57 percent (8 of 14) were mild. Thus, for the 34 pairs of transfusion components that were associated with reactions, severity was greater with the plasma supernatant in 24 cases, was greater with the cellular component in 6, and did not differ between components in 4 (chi-square = 9.6, P<0.01). An increase in temperature of more than 1 degree C was observed with only 7 of the 34 transfusion pairs associated with reactions. For all seven transfusions that produced a febrile reaction, the reaction was caused by the plasma alone.\n\n【29】The order of infusion did not have any effect on the likelihood or severity of reaction. The plasma supernatant was transfused first in 9 of 20 cases of reactions associated with the plasma alone, 4 of 6 associated with the cellular component alone, and 4 of 8 associated with both products.\n\n【30】Table 2. Correlation of the Likelihood of a Reaction with the Age, Leukocyte Count, and Cytokine Concentrations of the Platelet Product.\n\n【31】Reactions to the plasma supernatant were associated with higher concentrations of interleukin-1β (P<0.001 by the Wilcoxon test) and interleukin-6 (P = 0.034 by the Wilcoxon test) . Reactions to the plasma supernatant were also associated with older platelet concentrates (P = 0.007) and higher leukocyte counts in the original platelet pool (P = 0.03). The likelihood of a reaction to the cellular component of the platelet concentrate was not associated with the age of the product (P = 0.87), the leukocyte count (P = 0.32), the interleukin-1β concentration (P = 0.18), or the interleukin-6 concentration (P = 0.16) . The mean (±SD) leukocyte count in the cellular component was 1760 ±1710 per cubic millimeter. The mean leukocyte count in the plasma supernatant was 30 ±20 per cubic millimeter.\n\n【32】Serum from nine of the patients was available for testing for lymphocytotoxic anti-HLA antibodies. Five of these patients had reactions to the cellular component of the product, but only one of the five had detectable lymphocytotoxic anti-HLA antibodies. This patient, who had idiopathic thrombocytopenic purpura, had two reactions to the plasma supernatant, one reaction to the cellular component, and two reactions to both components. Lymphocytotoxic antibodies were not detected in the serum of four patients who did not have reactions to the cellular component of the platelet product.\n\n【33】In Vitro Studies\n----------------\n\n【34】Table 3. Concentration of Cytokines in Platelet Concentrates during Storage, According to Whether They Had Been Depleted of Leukocytes.\n\n【35】The concentrations of both interleukin-1β and interleukin-6 rose progressively during storage of the platelet concentrates that had not been depleted of leukocytes . Interleukin-1β, which was undetectable (<0.3 pg per milliliter) in all platelet concentrates on day 1, was detected in 9 of 10 concentrates by day 5 and in all concentrates by day 10. Interleukin-6 was detectable in 9 of 10 platelet concentrates by day 5 and in all concentrates by day 10. The correlation of cytokine concentrations with the duration of storage was 0.94 for interleukin-1β and 0.95 for interleukin-6 (P<0.01). When the platelet concentrates were depleted of white cells before storage, the concentrations of interleukin-1β and interleukin-6 remained undetectable or very low throughout the period of storage. The concentrations of interleukin-1β and interleukin-6 in the plasma correlated positively with the leukocyte count in the platelet product (r = 0.73 and r = 0.71, respectively). Bacterial cultures of the platelet concentrates showed no growth on day 10 of sampling.\n\n【36】Discussion\n----------\n\n【37】We found that patients reacted significantly more often and more severely to the plasma from the platelet concentrate than to the cells (platelets and leukocytes). As in our previous study,  reactions to the plasma supernatant were most frequent with supernatants from older platelet products and from those with higher leukocyte counts. In contrast, adverse reactions to the cells, which were resuspended in fresh-frozen plasma, did not correlate with the age of the product or the leukocyte count. Our study supports the hypothesis that bioreactive substances released into the supernatant plasma during storage cause platelet-associated transfusion reactions  .\n\n【38】Since interleukins (particularly interleukin-1β and interleukin-6) are potent pyrogens, we measured the concentrations of interleukin-1β and interleukin-6 in samples taken from the platelet products just before infusion. Only with plasma supernatant was a strong correlation observed between the cytokine concentrations and transfusion reactions.\n\n【39】As in previous studies,  interleukin-1β and interleukin-6 were undetectable in the platelet product at the time of its collection but increased progressively during storage . An important determinant of the concentration of these cytokines was the leukocyte count in the platelet product during storage. However, cytokines may not be the only mediators of platelet-associated reactions. It has recently been reported that lipid compounds that increase the activity of neutrophil oxidase also accumulate in platelet concentrates during storage, and these agents may have a role in acute transfusion-associated lung injury  .\n\n【40】The outcome measured in this study was subjective, and the clinical relevance of mild reactions, which were usually characterized by a cold feeling or discomfort, can be questioned. However, the severe reactions, which included rigors, chills, and nausea, could be documented objectively by the nursing staff. They were also significantly more likely to be caused by plasma than by cells.\n\n【41】Several of our patients reacted only to the cellular component of the platelet product, suggesting that in some patients mechanisms other than cytokines may contribute to or be responsible for these reactions. It is possible that these reactions involve an immune-mediated event  ; however, only one of these patients had detectable lymphocytotoxic anti-HLA antibodies .\n\n【42】The generalizability of these results is limited, since we studied only 12 patients; however, a significant statistical and clinical difference was observed in spite of the small number of patients. The overall frequency of reactions in this study was higher than previously reported  . This was not unexpected, because four- and five-day-old platelets were selected for transfusion whenever possible, since we had previously identified the age of the platelet concentrate as the most significant predictor of a reaction  .\n\n【43】Our observations could explain why removing leukocytes from the platelet product just before transfusion may not prevent reactions in some patients. However, our study does suggest that depleting platelet concentrates of leukocytes before storage may be an effective way of preventing febrile, nonhemolytic transfusion reactions. Although removing the plasma supernatant just before infusion was efficacious in preventing reactions to the platelet product in this small group of patients, investigations in a more diverse population are needed to determine the overall effectiveness of this approach.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-14 00:23:57", "grab_time": "2024-08-13 23:49:27"}
{"id": 2234284, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "7f65f16f-7a5e-4c1e-a8b9-c0e5d555e97d", "title": "Case 17-2011 — A 49-Year-Old Woman with a Mass in the Breast and Overlying Skin Changes", "text": "【0】Case 17-2011 — A 49-Year-Old Woman with a Mass in the Breast and Overlying Skin Changes\nA 49-year-old woman presented with a 12-cm mass in the right breast, fixed to the chest wall. The overlying skin was erythematous and edematous. A core-biopsy specimen showed infiltrating ductal carcinoma.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:43:45", "endTime": "2024/08/14 14:44:00", "cost": 15.441}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 22:44:01", "grab_time": "2024-08-13 22:43:44"}
{"id": 2234283, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "f301ff3f-9764-4472-874f-55cf8eaea685", "title": "Rate Control versus Rhythm Control for Atrial Fibrillation after Cardiac Surgery", "text": "【0】Rate Control versus Rhythm Control for Atrial Fibrillation after Cardiac Surgery\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Atrial fibrillation after cardiac surgery is associated with increased rates of death, complications, and hospitalizations. In patients with postoperative atrial fibrillation who are in stable condition, the best initial treatment strategy — heart-rate control or rhythm control — remains controversial.\n\n【3】Methods\n-------\n\n【4】Patients with new-onset postoperative atrial fibrillation were randomly assigned to undergo either rate control or rhythm control. The primary end point was the total number of days of hospitalization within 60 days after randomization, as assessed by the Wilcoxon rank-sum test.\n\n【5】Results\n-------\n\n【6】Postoperative atrial fibrillation occurred in 695 of the 2109 patients (33.0%) who were enrolled preoperatively; of these patients, 523 underwent randomization. The total numbers of hospital days in the rate-control group and the rhythm-control group were similar (median, 5.1 days and 5.0 days, respectively; P=0.76). There were no significant between-group differences in the rates of death (P=0.64) or overall serious adverse events (24.8 per 100 patient-months in the rate-control group and 26.4 per 100 patient-months in the rhythm-control group, P=0.61), including thromboembolic and bleeding events. About 25% of the patients in each group deviated from the assigned therapy, mainly because of drug ineffectiveness (in the rate-control group) or amiodarone side effects or adverse drug reactions (in the rhythm-control group). At 60 days, 93.8% of the patients in the rate-control group and 97.9% of those in the rhythm-control group had had a stable heart rhythm without atrial fibrillation for the previous 30 days (P=0.02), and 84.2% and 86.9%, respectively, had been free from atrial fibrillation from discharge to 60 days (P=0.41).\n\n【7】Conclusions\n-----------\n\n【8】Strategies for rate control and rhythm control to treat postoperative atrial fibrillation were associated with equal numbers of days of hospitalization, similar complication rates, and similarly low rates of persistent atrial fibrillation 60 days after onset. Neither treatment strategy showed a net clinical advantage over the other. \n\n【9】Introduction\n------------\n\n【10】In recent years, much research has focused on the prevention of atrial fibrillation after cardiac surgery, but highly effective interventions are lacking. Thus, postoperative atrial fibrillation remains the most common complication after cardiac surgery, with an incidence of 20 to 50%.  This complication has major adverse consequences for patients and the health care system, including increased rates of death, complications, and hospitalizations and inflated costs.  Therefore, efforts to determine the most effective preventive strategies and management practices are important. There are two general approaches to managing postoperative atrial fibrillation: heart-rate control (hereafter “rate control”) and rhythm control with the use of antiarrhythmic drugs, direct-current cardioversion, or both.\n\n【11】In the Atrial Fibrillation Follow-up Investigation of Rhythm Management (AFFIRM) trial, in which investigators studied the use of rate control versus rhythm control in nonsurgical patients with atrial fibrillation, the use of rhythm control was shown to offer no survival advantage but was associated with more frequent hospitalizations and adverse drug effects.  However, some studies involving patients with postoperative atrial fibrillation after cardiac surgery have suggested that rhythm control may offer advantages over rate control, although the evidence is inconclusive. \n\n【12】The lack of consensus regarding best practices for the management of atrial fibrillation after cardiac surgery has led to major variations in practice patterns.  Treatment approaches aim to reduce the severity of associated symptoms, limit adverse hemodynamic effects, decrease the length of hospital stay, prevent readmissions, and improve survival. Advocates of a rhythm-control strategy contend that a more rapid conversion to sinus rhythm might reduce thromboembolic risk, minimize exposure to anticoagulation, and restore functional capacity more quickly than rate control. Proponents of rate control counter that this approach averts the potential adverse effects of antiarrhythmic drugs and complications associated with cardioversion.\n\n【13】Determining the risks and benefits of rate control versus rhythm control for postoperative atrial fibrillation may provide information to improve clinical decision making and resource utilization for this highly prevalent condition. The Cardiothoracic Surgical Trials Network (CTSN), therefore, conducted a randomized trial to evaluate the effectiveness and safety of rate control versus rhythm control for new-onset atrial fibrillation or atrial flutter after cardiac surgery.\n\n【14】Methods\n-------\n\n【15】Trial Design and Oversight\n--------------------------\n\n【16】This trial was conducted at 23 sites in the United States and Canada; the institutional review board at each site approved the protocol. A coordinating center, independent adjudication committee, and data and safety monitoring board oversaw the progress of the trial.\n\n【17】Patients and Interventions\n--------------------------\n\n【18】The trial enrolled adult patients in hemodynamically stable condition who were undergoing elective cardiac surgery to treat coronary artery disease or heart-valve disease; none of the patients had a history of atrial fibrillation . All the patients provided written informed consent.\n\n【19】The patients were enrolled in the study and underwent randomization if they had postoperative atrial fibrillation that persisted for more than 60 minutes or recurrent episodes of atrial fibrillation during the index hospitalization (≤7 days after surgery). Patients with a history of atrial fibrillation were excluded to avoid making changes to their established preoperative medication regimen for atrial fibrillation and anticoagulation.\n\n【20】Patients in the rate-control group received medications to slow the heart rate, with a goal of achieving a resting heart rate of less than 100 beats per minute. Patients in whom sinus rhythm did not return after an initial strategy of rate control could be switched to rhythm control if their provider thought that such treatment was necessary to improve their hemodynamic status or alleviate symptoms.\n\n【21】Patients in the rhythm-control group were treated with amiodarone with or without a rate-slowing agent. If atrial fibrillation persisted for 24 to 48 hours after randomization, direct-current cardioversion was recommended. The recommended dose of amiodarone was the equivalent of 3 g of oral amiodarone before hospital discharge, with a maintenance dose of 200 mg per day or less if direct-current cardioversion was successful. It was recommended that the use of amiodarone be extended for 60 days, but discontinuation was allowed for amiodarone-related adverse events (e.g., symptomatic bradycardia, a corrected QT interval of >480 msec, or neuropathy).\n\n【22】If patients remained in atrial fibrillation or had recurrent atrial fibrillation 48 hours after randomization, anticoagulation with warfarin (target international normalized ratio, 2 to 3) was recommended, and bridging with low-molecular-weight heparin was allowed. Anticoagulation was recommended to be continued for 60 days, unless complications occurred.\n\n【23】To control for noncardiovascular reasons for hospitalization, we defined readiness for discharge from an atrial fibrillation perspective. For patients in the rate-control group with continuing atrial fibrillation, the readiness-for-discharge criteria included a target resting heart rate of less than 100 beats per minute. Patients in the rhythm-control group met the discharge criteria if they received a full amiodarone loading dose and were either free of atrial fibrillation for more than 24 hours and had no atrial fibrillation at the time of discharge or remained in atrial fibrillation after treatment with amiodarone for at least 48 hours or received direct-current cardioversion with adequate control of rate.\n\n【24】Trial End Points\n----------------\n\n【25】The primary end point was the total number of days in the hospital (including emergency department visits) within 60 days after randomization. Secondary end points included the duration of the hospital stay from randomization to the time of eligibility for discharge on the basis of criteria regarding atrial fibrillation, the length of the index hospitalization, the need for readmission, heart rhythm and time to conversion to a sustained stable rhythm without atrial fibrillation, the need for permanent placement of a pacemaker, and the rates of death and adverse events. The status of patients with respect to atrial fibrillation was determined by means of telemetry during the first 7 days and by means of electrocardiography at the time of hospital discharge and at 30 days and 60 days.  Follow-up assessments were performed 30 days and 60 days after randomization.\n\n【26】Statistical Analysis\n--------------------\n\n【27】The primary null hypothesis of the trial was that there would be no between-group difference in the total number of days of hospitalization at 60 days after randomization. The sample size was based on estimates of the length of hospital stay and rate of rehospitalization,  in addition to a blinded reestimation of sample size. Using a conservative estimate of a standard deviation of 6.3 days for the primary end point, we determined that enrollment of 520 patients assigned in a  ratio to one of the two groups would give the study 90% power to detect a difference of 2.0 days between the groups. We tested the primary end point in an intention-to-treat analysis using a two-tailed Wilcoxon rank-sum test with an alpha level of 0.05. The test accommodated nonignorable missing outcomes because of death by assigning such patients the worst ranks on the basis of the date of death. We used Poisson regression to analyze rates of adverse events and Kaplan–Meier analysis and the log-rank test to assess the time until conversion to a sustained, stable heart rhythm without atrial fibrillation. Sensitivity analyses to determine the influence of treatment nonadherence were performed with the use of an instrumental variable approach with the randomization assignment as the instrument.\n\n【28】Results\n-------\n\n【29】Patients\n--------\n\n【30】Table 1. Characteristics of the Patients and Procedures at Baseline.\n\n【31】From May 2014 through May 2015, a total of 2109 patients met the eligibility criteria and were enrolled preoperatively . Among these patients, postoperative atrial fibrillation developed in 695 (33.0%); 523 of these patients underwent randomization. The characteristics of the two groups were similar at baseline . The mean age was 68.8±9.1 years, and 24% of the patients were women. Isolated coronary-artery bypass grafting (CABG) was performed in approximately 40%, isolated valve surgery in 40%, and both procedures in 20%. The proportion of patients in whom postoperative atrial fibrillation developed was 28.1% among those who had undergone isolated CABG, 33.7% among those who had undergone isolated valve surgery, and 47.3% among those who had undergone combined procedures.\n\n【32】Table 2. Reasons for and Timing of Nonadherence to Treatment Assignment.\n\n【33】Approximately 24% of the patients in the rhythm-control group did not complete the full course of amiodarone and received beta-blockers, calcium-channel blockers, or both . Among the patients in the rate-control group, 26.7% received amiodarone or direct-current cardioversion. The majority of patients who discontinued or switched therapy did so for protocol-specified clinical reasons (80.0% in the rate-control group and 64.5% in the rhythm-control group). The timing of such changes in therapy differed between the groups, with more patients in the rate-control group than in the rhythm-control group changing therapy during the index hospitalization (83% vs. 48%). Overall, 60 patients (11.5%) received direct-current cardioversion (9.2% in the rate-control group and 13.8% in the rhythm-control group).\n\n【34】Hospitalization Days\n--------------------\n\n【35】Table 3. Hospitalization and Readmission.\n\n【36】The primary outcome, the number of hospital days from randomization until 60 days, did not differ significantly between the rate-control group and the rhythm-control group (mean, 6.4 days and 7.0 days, respectively; median, 5.1 days and 5.0 days, respectively; P=0.76) . The mean length of stay for the index hospitalization after randomization was 5.5 days in the rate-control group and 5.8 days in the rhythm-control group (median, 4.3 in each group; P=0.88). A sensitivity analysis to determine the influence of treatment nonadherence confirmed the results of the intention-to-treat analysis (P=0.51 for the total hospital stay, P=0.72 for the index hospital stay).  When the length of stay for the index hospitalization was adjusted for discharge readiness on the basis of status regarding atrial fibrillation, the mean length of stay was 5.0 days in the rate-control group and 5.2 in the rhythm-control group, with a median of 4.0 days in each group (P=0.99).\n\n【37】During the study period, there were 159 hospital readmissions, including emergency department visits, with no significant between-group difference in the rate per 100 patient-months . Rates of readmission for cardiovascular causes were 6.8 per 100 patient-months in the rate-control group and 8.1 per 100 patient-months in the rhythm-control group (P=0.48); readmission rates for the treatment of atrial fibrillation were 2.6 and 3.9 per 100 patient-months, respectively (P=0.27). The proportion of patients who were readmitted within 30 days after hospital discharge was 22.8% in the rate-control group and 21.4% in the rhythm-control group (P=0.71).\n\n【38】Timing of Onset and Resolution of Atrial Fibrillation\n-----------------------------------------------------\n\n【39】The average time to the onset of postoperative atrial fibrillation was 2.4 days (range, 0 to 7) after surgery. A total of 46.2% of the patients in the rate-control group and 31.8% of those in the rhythm-control group met the protocol-specified indications for the initiation of anticoagulation. At the time of hospital discharge, warfarin had been prescribed for 42.7% of the patients in the rate-control group and for 43.3% of those in the rhythm-control group, with an average duration of anticoagulation of 44.8 days and 44.9 days, respectively.\n\n【40】Figure 1. Patients with No Atrial Fibrillation at 7 Days and Status at 30 Days and 60 Days.\n\n【41】Panel A shows the proportion of patients undergoing cardiac surgery who had a stable heart rhythm without atrial fibrillation during the first week after randomization in the rate-control group and the rhythm-control group. Panel B shows the status with respect to atrial fibrillation at the time of discharge from the index hospitalization, at 30 days, and at 60 days, according to treatment group. The pink boxes denote patients in atrial fibrillation, and the blue boxes denote patients with a stable heart rhythm without atrial fibrillation. The patients’ status with respect to atrial fibrillation was determined by means of electrocardiography at the time of hospital discharge and at 30 days and 60 days. The accounting for atrial fibrillation included patients who had recurrent atrial fibrillation (as adjudicated by the clinical events committee) or who were readmitted to the hospital for recurrent atrial fibrillation during the interval periods. Overall, 11.5% of patients underwent direct-current cardioversion (9.2% in the rate-control group and 13.8% in the rhythm-control group). Of the direct-current cardioversions, 85% occurred during the index hospitalization. Among the patients who were discharged from the hospital with atrial fibrillation, direct-current cardioversion was performed during the index hospitalization in 3 of 26 patients (12%) in the rate-control group and in 7 of 17 patients (41%) in the rhythm-control group.\n\n【42】A total of 89.9% of the patients in the rate-control group and 93.5% of those in the rhythm-control group had a stable, sustained heart rhythm without atrial fibrillation at hospital discharge (P=0.14). At 60 days, a stable heart rhythm without atrial fibrillation had been achieved for the previous 30 days in 93.8% of the patients in the rate-control group and in 97.9% of those in the rhythm-control group (P=0.02); from discharge to 60 days, the percentages were 84.2% in the rate-control group and 86.9% in the rhythm-control group (P=0.41) .\n\n【43】Death and Adverse Events\n------------------------\n\n【44】Table 4. Serious and Protocol-Defined Adverse Events.\n\n【45】At 60 days, five patients had died: three in the rate-control group and two in the rhythm-control group (P=0.64). There were no significant differences in the overall rates of serious adverse events between the rate-control group and the rhythm-control group (24.8 per 100 patient-months and 26.4 per 100 patient-months, respectively; P=0.61) . The overall rates of cerebrovascular thromboembolism (0.8 per 100 patient-months in the rate-control group and 0.4 per 100 patient-months in the rhythm-control group) and noncerebral thromboembolism (0.6 per 100 patient-months and 0.2 per 100 patient-months) were low and did not differ significantly between the two groups (P=0.40 for the cerebrovascular thromboembolism comparison and P=0.31 for the noncerebral thromboembolism comparison). The rates of serious bleeding (a score of ≥3 on the Bleeding Academic Research Consortium scale, with scores ranging from 0 \\[no bleeding\\] to 5 \\[fatal bleeding\\]) were 2.2 per 100 patient-months in the rate-control group and 1.2 per 100 patient-months in the rhythm-control group (P=0.21). The most common protocol-defined adverse events (either serious or nonserious) were major infections (9.3 per 100 patient-months in the rate-control group and 6.6 per 100 patient-months in the rhythm-control group, P=0.13), cardiac arrhythmias (4.7 and 6.2 per 100 patient-months, respectively; P=0.30), and pleural effusions (3.0 and 4.8 per 100 patient-months, respectively; P=0.16).\n\n【46】Discussion\n----------\n\n【47】Our findings confirm that new-onset atrial fibrillation remains a common complication after cardiac surgery. More than 30% of the patients who underwent cardiac surgery in our trial had either sustained or recurrent postoperative atrial fibrillation. These rates approached 50% among patients who underwent combined CABG and valve surgery. Postoperative atrial fibrillation is associated with several adverse consequences and independently predicts increased rates of death and complications, including stroke, heart failure, and infection.  Moreover, postoperative atrial fibrillation after cardiac surgery significantly increases the length of hospital stay, readmission risk, and resource utilization. Estimates of the average annual cost of treatment of postoperative atrial fibrillation and its sequelae approach $1 billion in the United States. \n\n【48】Despite the importance of postoperative atrial fibrillation, the most effective management strategy for this common surgical complication remains uncertain, a factor that had led to a substantial variation in treatments. The joint guidelines of the American College of Cardiology, American Heart Association, and Heart Rhythm Society, which were published when our trial was far along in enrollment, recommend rate control with beta-blockers as the first-line therapy in patients whose condition is hemodynamically stable (i.e., class I, level of evidence A).  These recommendations are based partly on studies regarding the prevention of atrial fibrillation after cardiac surgery and extrapolation from the AFFIRM trial, which compared rate control with rhythm control in nonsurgical patients with atrial fibrillation. The AFFIRM trial showed that management of nonsurgical atrial fibrillation with rhythm control offered no survival advantage over rate control and that patients who were treated with a rhythm-control strategy were more likely to require hospitalization and have adverse drug effects than were those who were treated with a rate-control strategy.  By comparison, rigorous evidence in the cardiac surgical setting is sparse and limited to several retrospective, observational studies and one pilot randomized trial comparing rate control with rhythm control in 50 patients. \n\n【49】In our trial, in which the number of patients enrolled was 10 times that in the previous studies, we discovered important insights into the benefits and risks of rate control versus rhythm control for the treatment of postoperative atrial fibrillation after cardiac surgery. We found no significant difference between treatment strategies with respect to the primary end point, the total number of hospital days, including the primary admission and any subsequent readmissions occurring within 60 days after randomization. Postoperative atrial fibrillation is usually a transient condition that resolves spontaneously but that may have hemodynamic consequences and result in treatment-related adverse events, such as bleeding, thromboembolic complications, drug-related toxic effects, and complications related to the use of direct-current cardioversion, events that may in turn lead to prolonged hospitalizations and repeat admissions. The primary end point that we used in this trial captures the short-term effect of a very diverse set of adverse events. Moreover, further insight into the trade-offs between rate control and rhythm control can help improve clinical decision making and resource utilization. The importance of this end point is reflected in the finding that the rate of hospital readmission at 30 days was more than 28%, with nearly one fifth of such readmissions resulting from recurrent atrial fibrillation.\n\n【50】Patients in the rhythm-control group achieved a stable heart rhythm without atrial fibrillation earlier than those in the rate-control group. In addition, the proportion of patients who were free of atrial fibrillation between day 30 and day 60 was significantly lower in the rhythm-control group than in the rate-control group. However, the overall proportion of patients who were free of atrial fibrillation between hospital discharge and 60 days was much lower than the proportion who were free of atrial fibrillation between 30 days and 60 days, but the between-group difference was not significant. Although we did not compare strategies for anticoagulation in patients with postoperative atrial fibrillation, the results provide data that may inform clinical decision making. The protocol specified that anticoagulation therapy should be initiated in patients who had atrial fibrillation for more than 48 hours and those who had more than a single episode of atrial fibrillation during the index hospitalization. More patients in the rate-control group than in the rhythm-control group met this indication (46.2% vs. 31.8%). However, the proportions of patients who were prescribed warfarin at discharge were similar in the two groups, which may reflect additional considerations regarding the need for anticoagulation. The median duration of anticoagulation was approximately 45 days in each group.\n\n【51】With the anticoagulation strategy used in this trial, the incidence of serious thromboembolic events (2%) was low overall and did not differ significantly between the two groups. The overall percentage of patients with serious bleeding was approximately 3%, a frequency that did not differ significantly between the two groups. Nearly 90% of the bleeding events occurred in patients who were receiving anticoagulation. Thus, the relatively low incidence of thromboembolic events came at the expense of serious bleeding, which suggests the need to further study the trade-off between the risks and benefits of anticoagulation for atrial fibrillation after cardiac surgery.\n\n【52】In this comparative effectiveness trial, we evaluated an initial strategy of rate control versus rhythm control in a clinical context in which changes in the status of patients can prompt alterations in the treatment regimen. Approximately 25% of the patients could not adhere to the assigned treatment strategy. Among the patients in the rate-control group, 26.7% received amiodarone or direct-current cardioversion, and 23.8% of the patients in the rhythm-control group did not complete the full course of amiodarone. The majority of treatment nonadherence occurred for prespecified clinical indications. Deviation from rate control was largely a result of drug ineffectiveness, whereas amiodarone was discontinued mostly due to drug-related toxic effects. In the AFFIRM trial, investigators noted crossover rates of 15 to 38% during the course of the trial in nonsurgical patients who were not as acutely ill as those in our trial. \n\n【53】Our study has several limitations. First, the primary end point was a proxy for important clinical outcomes, such as stroke and serious bleeding. A randomized trial with the power to detect differences in these end points would have required the enrollment of thousands of patients. Second, the results of our trial pertain only to patients with new-onset postoperative atrial fibrillation. Third, there was a relatively high rate of treatment discontinuation, but in sensitivity analyses we confirmed the results of the intention-to-treat analysis. Fourth, we did not include quality-of-life measures because of the short duration of the trial and the likelihood that the effects of surgery would overshadow the effects of postoperative atrial fibrillation on quality of life. However, the inclusion of such measures might have provided insights into the burden of treatment and its trade-offs. Finally, we did not assess postoperative atrial fibrillation by means of continuous home monitoring, an approach that might have led to an underestimation of its prevalence.\n\n【54】Postoperative atrial fibrillation is common after cardiac surgery and amenable to either a rate-control or rhythm-control strategy. Approximately 85% of the patients in our trial had a stable heart rhythm without atrial fibrillation from the time of hospital discharge onward, and about 95% were free of atrial fibrillation by the end of the study. Anticipating this result, we chose an end point that was related to resource utilization and the experience of patients: days in the hospital after randomization. The study-group assignments did not influence this end point. However, we did observe clinical differences between the two approaches. An initial strategy of rate control averted much of the toxic effects and side effects associated with amiodarone but was associated with a slower resolution of atrial fibrillation, thereby leading to a greater need for anticoagulation (with its attendant risks) and a slightly higher prevalence of atrial fibrillation during follow-up. The faster resolution of atrial fibrillation in the rhythm-control group came at the price of amiodarone-related side effects in many patients, often necessitating discontinuation of amiodarone after hospital discharge. In patients with postoperative atrial fibrillation who are in hemodynamically stable condition, one strategy does not appear to have a net clinical advantage over the other. In such cases, the preferences of patients and physicians should dictate whether a rhythm-control approach that uses amiodarone with or without direct-current cardioversion is worth the benefit over a rate-control approach.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 17:00:24", "endTime": "2024/08/13 17:00:48", "cost": 23.97}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 01:00:48", "grab_time": "2024-08-13 01:00:24"}
{"id": 2234282, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "0e50b246-3858-4840-8a2d-309018724804", "title": "Case 28-2015 — A 32-Year-Old Man with Fever, Headache, and Myalgias after Traveling from Liberia", "text": "【0】Case 28-2015 — A 32-Year-Old Man with Fever, Headache, and Myalgias after Traveling from Liberia\nA public health authority contacted the hospital about a 32-year-old man with fever, headache, and myalgias that had developed 8 days after he had traveled from Liberia during an epidemic of Ebola virus disease. Management decisions were made.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:32:45", "endTime": "2024/08/14 14:33:00", "cost": 14.576}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 22:33:00", "grab_time": "2024-08-13 22:32:45"}
{"id": 2234281, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "1402c5ed-7e67-4063-816b-a490eb3b45d6", "title": "Thrombotic Microangiopathy Associated with Interferon Beta", "text": "【0】Thrombotic Microangiopathy Associated with Interferon Beta\nTo the Editor:\n--------------\n\n【1】Figure 1. Cases of Thrombotic Microangiopathy Associated with a Common Manufacturing Source of Interferon Beta.\n\n【2】Shown are renal-biopsy specimens obtained from four patients receiving recombinant interferon beta therapy in South Scotland in whom thrombotic microangiopathy was diagnosed during an 18-month period . All four specimens show arteriolar luminal obliteration with swollen endothelium and fibrin (arrows; hematoxylin and eosin and silver staining \\[Panels A, B, and D\\] and Martius scarlet blue \\[MSB\\] staining \\[Panel C\\]). All four patients were treated with recombinant interferon beta from the same manufacturer, as confirmed by tracing of drug batches. The Venn diagram shows the overlap of 10 batches prescribed to patients in the year before the presentation of the index case .\n\n【3】Interferon beta is a widely prescribed recombinant-protein therapy with a well-established favorable safety profile.  Here, we describe an unexpectedly high number of cases of thrombotic microangiopathy associated with severe or malignant hypertension in four patients with multiple sclerosis who were receiving therapy with recombinant interferon beta in South Scotland. A detailed review of the case histories of these patients, including a genetic analysis, did not identify any other causal factor for this condition, and an analysis of pharmacy records revealed a significant association with a common manufacturing source of interferon beta (Rebif, Merck) .\n\n【4】The regulatory authorities in the United Kingdom received six additional spontaneous reports of disorders related to thrombotic microangiopathy and interferon beta, all associated with the same manufacturer (for details, see the Supplementary Appendix ). In December 2013, the Medicines and Healthcare Products Regulatory Agency (MHRA) issued a drug-safety update regarding a possible link between interferon beta and thrombotic microangiopathy.  In April 2009, the manufacturer of Rebif added a warning to the package insert about a possible association with thrombotic microangiopathy, which was specifically defined as the hemolytic–uremic syndrome and thrombotic thrombocytopenic purpura (HUS/TTP).\n\n【5】We requested details regarding the geographical and temporal distribution of the HUS/TTP reports. Consistent with our observations in the United Kingdom, very few cases were reported globally in the first 9 years of safety monitoring. However, there has been a recent increase in reports from countries that share the same formulation as that used in the United Kingdom.  Substantial caution is required in the interpretation of spontaneous reports of adverse drug reactions, since such reports are voluntary, are potentially subject to underreporting, and may be influenced by many factors, including the severity of the drug reaction, the diagnostic classification, and the degree of publicity. However, we did not detect such patterns or trends in the safety data from a similar recombinant interferon beta product, suggesting that further investigation of the association with changes in manufacturing may be worthwhile. We have raised these concerns with the manufacturer and regulatory authorities.\n\n【6】The patients in our analysis share important clinical features (for details, see the Supplementary Appendix ). First, all the patients presented after years of well-tolerated treatment with interferon beta, making an association difficult to recognize. Second, fulminant presentation was associated with severe hypertension. Third, despite the emergency presentation, retrospective review identified chronic changes in all renal-biopsy specimens and a prodrome in three of the four patients with features that included newly diagnosed hypertension, hematologic abnormalities, and renal impairment in the months before diagnosis. We subsequently identified a similar prodrome in a recent fatal case in the United Kingdom. Thrombotic microangiopathy is therefore a serious and potentially fatal complication that has emerged late in the lifetime of recombinant interferon beta therapy. Early manifestations of this complication may be recognizable with increased vigilance, with the potential to mitigate severity.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-14 00:11:36", "grab_time": "2024-08-13 22:38:29"}
{"id": 2234280, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "6e732f56-e78e-41c8-8d15-bd0e046d87b7", "title": "Timing of Initiation of Antiretroviral Drugs during Tuberculosis Therapy", "text": "【0】Timing of Initiation of Antiretroviral Drugs during Tuberculosis Therapy\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】The rates of death are high among patients with coinfection with tuberculosis and the human immunodeficiency virus (HIV). The optimal timing for the initiation of antiretroviral therapy in relation to tuberculosis therapy remains controversial.\n\n【3】Methods\n-------\n\n【4】In an open-label, randomized, controlled trial in Durban, South Africa, we assigned 642 patients with both tuberculosis and HIV infection to start antiretroviral therapy either during tuberculosis therapy (in two integrated-therapy groups) or after the completion of such treatment (in one sequential-therapy group). The diagnosis of tuberculosis was based on a positive sputum smear for acid-fast bacilli. Only patients with HIV infection and a CD4+ cell count of less than 500 per cubic millimeter were included. All patients received standard tuberculosis therapy, prophylaxis with trimethoprim–sulfamethoxazole, and a once-daily antiretroviral regimen of didanosine, lamivudine, and efavirenz. The primary end point was death from any cause.\n\n【5】Results\n-------\n\n【6】This analysis compares data from the sequential-therapy group and the combined integrated-therapy groups up to September 1, 2008, when the data and safety monitoring committee recommended that all patients receive integrated antiretroviral therapy. There was a reduction in the rate of death among the 429 patients in the combined integrated-therapy groups (5.4 deaths per 100 person-years, or 25 deaths), as compared with the 213 patients in the sequential-therapy group (12.1 per 100 person-years, or 27 deaths); a relative reduction of 56% (hazard ratio in the combined integrated-therapy groups, 0.44; 95% confidence interval, 0.25 to 0.79; P=0.003). Mortality was lower in the combined integrated-therapy groups in all CD4+ count strata. Rates of adverse events during follow-up were similar in the two study groups.\n\n【7】Conclusions\n-----------\n\n【8】The initiation of antiretroviral therapy during tuberculosis therapy significantly improved survival and provides further impetus for the integration of tuberculosis and HIV services. \n\n【9】Introduction\n------------\n\n【10】In 2007, it was estimated that there were about 33 million persons living with human immunodeficiency virus (HIV) infection  and 9.2 million persons with newly diagnosed tuberculosis worldwide.  The two diseases are closely intertwined, and the number of patients with coinfection continues to grow rapidly.  Tuberculosis is the most common opportunistic disease  and the most common cause of death in patients with HIV infection in developing countries.  Notwithstanding effective tuberculosis chemotherapy, in the presence of HIV infection, tuberculosis is associated with substantially increased case fatality rates  and is also the most commonly reported cause of death in South Africa.  In 2007 in South Africa, an estimated 5.3 million people were infected with HIV and 341,165 with tuberculosis, of whom approximately 73% were coinfected with HIV. \n\n【11】The optimal timing for the initiation of antiretroviral therapy in patients with HIV and tuberculosis coinfection remains unclear. Current guidelines are based on observational studies and expert opinion.  Despite World Health Organization (WHO) guidelines supporting concomitant treatment of the two diseases and urging more aggressive management,  the initiation of antiretroviral therapy is often deferred until completion of tuberculosis therapy because of concern about potential drug interactions between rifampin and some classes of antiretroviral drugs,  the immune reconstitution inflammatory syndrome,  overlapping side effects,  a high pill burden, and programmatic challenges.  This study, called the Starting Antiretroviral Therapy at Three Points in Tuberculosis (SAPIT) trial, was designed to determine the optimal time to initiate antiretroviral therapy in patients with HIV and tuberculosis coinfection who were receiving tuberculosis therapy.\n\n【12】Methods\n-------\n\n【13】Study Design\n------------\n\n【14】The study was an open-label, randomized, controlled trial conducted at the eThekwini HIV–tuberculosis clinic, which is operated by the Centre for the AIDS Programme of Research in South Africa (CAPRISA) in Durban, South Africa. This clinic adjoins one of the largest outpatient tuberculosis facilities in South Africa, the Prince Cyril Zulu Communicable Disease Centre.\n\n【15】Guidelines of the South African National Tuberculosis Control Programme  stipulate that a first episode of tuberculosis be treated with a 2-month intensive combination-drug regimen of rifampin, isoniazid, ethambutol, and pyrazinamide, with doses determined according to pretreatment weight. Thereafter, patients receive a 4-month continuation regimen of isoniazid and rifampin. Patients with a history of tuberculosis receive a 3-month intensive regimen (including the addition of streptomycin for the first 2 months), followed by a 5-month continuation phase. In our study, patients were routinely offered therapy that was directly observed by clinic-based nurses. Some patients selected community-based supervisors, heads of households, and treatment supporters in workplaces who supervised and recorded the taking of medication.\n\n【16】Patients\n--------\n\n【17】From June 28, 2005, to July 11, 2008, we recruited patients who were at least 18 years of age and who had confirmed HIV infection (on the basis of two rapid HIV tests) and a positive smear for tuberculosis acid-fast bacilli (with the use of auramine and Ziehl–Neelsen staining methods). Inclusion in the study required independent confirmation of positive tuberculosis status at the Department of Medical Microbiology at the Nelson R. Mandela School of Medicine, initiation of treatment with the standard tuberculosis regimen at the Communicable Disease Centre, a CD4+ cell count of less than 500 per cubic millimeter at screening, and an absence of clinical contraindications to the initiation of antiretroviral therapy. Female patients were required to agree to use contraception while receiving efavirenz.\n\n【18】Study Procedures\n----------------\n\n【19】After providing written informed consent, patients with confirmed HIV and tuberculosis coinfection were randomly assigned in a :1 ratio (with the use of sealed envelopes) to one of three study groups in permuted blocks of six or nine with no stratification. In the first group, antiretroviral therapy was to be initiated within 4 weeks after the start of tuberculosis therapy (early integrated-therapy group). In the second group, antiretroviral therapy was to be initiated within 4 weeks after the completion of the intensive phase of tuberculosis therapy (late integrated-therapy group). In the third group, antiretroviral therapy was to be initiated within 4 weeks after the completion of tuberculosis therapy (sequential-therapy group).\n\n【20】All patients received adherence counseling, prophylaxis with trimethoprim–sulfamethoxazole against HIV-related opportunistic infections, and the same once-daily three-drug antiretroviral therapy regimen, consisting of didanosine (250 mg for a body weight of <60 kg and 400 mg for a weight ≥60 kg), lamivudine (300 mg), and efavirenz (600 mg). Adherence to the antiretroviral regimen was assessed monthly according to pill counts (pills issued minus pills returned as a percentage of anticipated pill consumption). Regardless of the study-group assignment, patients could be started on antiretroviral therapy at any time by clinicians at the Communicable Disease Centre, by study clinicians, or by personal physicians at their discretion.\n\n【21】Follow-up visits for the monitoring of safety and clinical status were scheduled monthly for 24 months. Adverse events were graded with the use of the Division of AIDS Table for Grading the Severity of Adult and Pediatric Adverse Events, version 1.0, as recommended by the National Institute of Allergy and Infectious Diseases (December 28, 2004). Measurements of CD4+ cell counts with the use of flow cytometry (FACSCalibur, Becton Dickinson) and HIV RNA  were performed at the time of screening, at randomization, and every 6 months thereafter. Monitoring for radiologic changes and sputum conversion was performed at the time of screening, at the end of the intensive phase of tuberculosis therapy, 1 month before the end of tuberculosis therapy, and whenever clinically indicated.\n\n【22】End Points\n----------\n\n【23】The primary end point was death from any cause. Secondary end points included discontinuation because of side effects, toxic effects, HIV RNA levels, tuberculosis outcomes, and the occurrence of the immune reconstitution inflammatory syndrome. Discontinuation because of side effects was documented as study-initiated treatment interruptions in the pharmacy records. Toxic effects were assessed by means of a clinical checklist and standard laboratory tests for hematologic, hepatic, and renal abnormalities. The immune reconstitution inflammatory syndrome was defined as a paradoxical deterioration in clinical status or laboratory findings after the initiation of antiretroviral or antituberculosis therapy without another attributable cause.\n\n【24】Interim Monitoring\n------------------\n\n【25】After a planned interim analysis, on September 1, 2008, almost 2 months after completion of enrollment, the data and safety monitoring committee recommended that all patients in the sequential-therapy group be started on antiretroviral therapy as soon as possible but continue in follow-up until study completion. The committee also recommended continuation of the two integrated-therapy groups with no changes. The patients in the sequential-therapy group were contacted within a week after the committee's meeting, and almost all of them started antiretroviral therapy within a month. We present data up to September 1, 2008, comparing the sequential-therapy group with the combined early and late integrated-therapy groups, which are hereafter referred to as the integrated-therapy group.\n\n【26】Study Oversight\n---------------\n\n【27】The trial was approved by the Biomedical Research Ethics Committee at the University of KwaZulu-Natal and the South African government's Medicines Control Council.\n\n【28】Statistical Analysis\n--------------------\n\n【29】We estimated that we would need to enroll 649 patients (factoring in an anticipated loss to follow-up) in order to have a power of 80% and an alpha level of 0.05 to detect a 60% reduction in mortality on the basis of a predicted death rate of 10% in the study group with the worst outcome. All analyses were performed according to the intention-to-treat principle. The primary outcome was analyzed with the use of Kaplan–Meier curves and the log-rank test. The duration of time in the study was calculated as the time from randomization to death, withdrawal from the study, or the cutoff date of September 1, 2008, whichever occurred first. Poisson approximations were used to calculate confidence intervals for the rate of death. Proportional-hazards regression models were used to adjust for confounding variables. Fisher's exact test was used for the analysis of categorical data, and unpaired t-tests or the Wilcoxon two-sample test for the analysis of continuous data.\n\n【30】Results\n-------\n\n【31】Patients\n--------\n\n【32】Figure 1. Enrollment and Outcomes. Table 1.  Table 1. Baseline Characteristics of the Patients.\n\n【33】A total of 642 patients with HIV and tuberculosis coinfection were enrolled: 429 in the combined integrated-therapy group and 213 in the sequential-therapy group . At baseline, patients in the two groups had similar demographic and clinical characteristics, including age, CD4+ cell counts, and HIV RNA levels .\n\n【34】Follow-up\n---------\n\n【35】At the time of the data cutoff, on September 1, 2008, a total of 338 of the 642 patients (52.6%) were still in active follow-up, 52 (8.1%) had died during follow-up, 134 (20.9%) had completed follow-up, and 56 (8.7%) had withdrawn before study completion. Of the 62 patients (9.7%) who were regarded as lost to follow-up (9.6% in the integrated-therapy group and 9.9% in the sequential-therapy group), 35 were known to be alive, and the clinical status of the remaining 27 was unknown. (Patients were considered to be lost to follow-up if they went 4 months without a visit.) The median duration of follow-up in the trial was 12.1 months (interquartile range, 6.1 to 21.6).\n\n【36】Initiation of Antiretroviral Therapy\n------------------------------------\n\n【37】The median duration of tuberculosis therapy was similar among patients who completed such therapy: 210 days for 271 patients in the integrated-therapy group and 207 days for 137 patients in the sequential-therapy group. At the time of this analysis, 102 patients in the integrated-therapy group and 48 patients in the sequential-therapy group were still receiving tuberculosis therapy.\n\n【38】Of the 350 patients in the integrated-therapy group who started antiretroviral therapy, 338 did so while they were receiving tuberculosis therapy. Patients in this group started antiretroviral therapy at a mean (±SD) of 70±72 days after the start of tuberculosis therapy. Of the 100 patients in the sequential-therapy group who started antiretroviral therapy, 7 did so while they were receiving tuberculosis therapy. In this group, antiretroviral therapy was initiated a mean of 260±71 days after the initiation of tuberculosis therapy. Thus, patients in the sequential-therapy group started antiretroviral therapy, on average, 190 days later than those in the integrated-therapy group.\n\n【39】Primary End Point\n-----------------\n\n【40】Table 2. Death Rates and Hazard Ratios, Stratified According to CD4+ Cell Count. Figure 2.  Figure 2. Kaplan–Meier Survival Curves.\n\n【41】TB denotes tuberculosis.\n\n【42】There were 25 deaths in the integrated-therapy group, for a death rate of 5.4 per 100 person-years, as compared with 27 deaths in the sequential-therapy group, for a death rate of 12.1 per 100 person-years (hazard ratio in the integrated-therapy group, 0.44; 95% confidence interval \\[CI\\], 0.25 to 0.79; P=0.003) . After adjustment for baseline WHO status of HIV infection (stage 4 vs. stage 3), CD4+ cell count, age, sex, the presence or absence of a history of tuberculosis, the presence or absence of extrapulmonary tuberculosis, and baseline HIV RNA level, the hazard ratio was 0.43 (95% CI, 0.25 to 0.77; P=0.004).\n\n【43】Information on the 52 deaths was based on hospital chart notes for 28 patients, a death certificate for 1 patient, and two independent oral reports of death for 23 patients. On the basis of the chart notes and death certificate for 29 patients, causes of death in the integrated-therapy group were tuberculosis (including tuberculous meningitis) for 2 patients, respiratory distress or _Pneumocystis jiroveci_ pneumonia for 6 patients, and metabolic acidosis, cardiomyopathy, and a motor-vehicle accident for 1 patient each; causes of death in the sequential-therapy group were tuberculosis (including tuberculous meningitis) for 6 patients, respiratory distress or _P. jiroveci_ pneumonia for 3 patients, and nontuberculous meningitis, gastroenteritis, renal failure, hepatic failure, and glioma for 1 patient each. The cause of death was unclear in the chart notes of four patients.\n\n【44】The baseline CD4+ cell count independently predicted mortality in the two study groups. Mortality was lower in the integrated-therapy group in all CD4+ count strata . The median baseline CD4+ count was similar in the two study groups. There was no interaction between the CD4+ count and the study groups (P=0.57).\n\n【45】Treatment Outcomes\n------------------\n\n【46】Table 3. Clinical Outcomes of Tuberculosis Therapy. Table 4.  Table 4. Clinical Outcomes of HIV Therapy.\n\n【47】The rate of adherence to antiretroviral therapy according to pill counts was 97.2% in the integrated-therapy group and 97.6% in the sequential-therapy group. Outcomes with respect to tuberculosis therapy were similar in the two study groups, regardless of whether patients were receiving first-episode therapy or repeated therapy . At 12 months after randomization, the proportion of patients with a suppressed HIV RNA level was higher in the integrated-therapy group than in the sequential-therapy group (90.0% vs. 77.8%, P=0.006). However, the proportion of patients with a suppressed HIV RNA level 6 months after the initiation of antiretroviral therapy was similar in the two groups .\n\n【48】Adverse Events\n--------------\n\n【49】The immune reconstitution inflammatory syndrome was diagnosed in 53 of 429 patients (12.4%; 95% CI, 9.5 to 15.9) in the integrated-therapy group and in 8 of 213 patients (3.8%; 95% CI, 1.8 to 7.5) in the sequential-therapy group (P<0.001). Six patients required the use of corticosteroids (five in the integrated-therapy group and one in the sequential-therapy group). No changes in the antiretroviral regimen were needed because of immune-reconstitution events. None of the deaths were determined to be related to the immune reconstitution inflammatory syndrome. Among grade 3 or 4 adverse events that were not regarded as immune reconstitution, 140 occurred in the integrated-therapy group (30 per 100 person-years) and 71 in the sequential-therapy group (32 per 100 person-years) (P=0.69) .\n\n【50】Discussion\n----------\n\n【51】This trial showed that the initiation of antiretroviral therapy during tuberculosis therapy in patients with confirmed tuberculosis and HIV coinfection reduced mortality by 56% (95% CI, 21 to 75). The death rate rose from 5.4 per 100 person-years to 12.1 per 100 person-years when initiation of antiretroviral therapy was delayed until the completion of tuberculosis therapy. The interval between the completion of tuberculosis therapy and the initiation of antiretroviral therapy is important; a considerable number of deaths in the sequential-therapy group occurred during this time . Once antiretroviral therapy was initiated, however, it was associated with similarly high levels of viral suppression in the two study groups, findings that are similar to those observed in other HIV treatment programs in South Africa. \n\n【52】Mortality among patients with HIV and tuberculosis coinfection is known to be high despite the use of effective tuberculosis therapy.  Observational studies have indicated that the initiation of antiretroviral therapy during tuberculosis therapy improves treatment outcomes in such patients. A meta-analysis of studies involving 6934 patients at five hospitals in Madrid showed a significant improvement in survival (63% increase) among patients who began antiretroviral therapy while they were receiving tuberculosis therapy.  In Thailand, an analysis of 1003 patients showed an increase by a factor of 20 in the rate of death among patients who did not receive simultaneous antiretroviral and tuberculosis therapies, as compared with those who did receive the two therapies.  A Thai review of studies involving 626 patients showed a hazard ratio for death of 0.17 for patients who started antiretroviral therapy during tuberculosis treatment, as compared with patients who did not receive antiretroviral therapy.  Although the selection of patients for integrated treatment by clinicians may have led to bias in these studies, the trials show a consistent association between antiretroviral therapy and survival in coinfected patients. The randomized design of our trial validates and extends the findings from these retrospective observational data.\n\n【53】Among patients with CD4+ counts of less than 200 cells per cubic millimeter, the rate of death was 46% lower in the integrated-therapy group than in the sequential-therapy group (P=0.04). Although the number of deaths was small in the subgroup of patients who had CD4+ counts between 200 and 500 cells per cubic millimeter, there was a trend toward lower mortality in the integrated-therapy group. This finding has implications for treatment guidelines and policies. Current WHO guidelines for the treatment of patients with HIV and tuberculosis coinfection recommend the deferment of antiretroviral therapy until the completion of tuberculosis therapy in patients with WHO stage 3 HIV infection and CD4+ counts of more than 200 cells per cubic millimeter.  Our findings suggest that this guideline should be expanded to include cotreatment of HIV infection and tuberculosis in patients with CD4+ counts of less than 500 cells per cubic millimeter.\n\n【54】There is increasing evidence that even among patients with HIV infection who do not have tuberculosis, earlier initiation of antiretroviral therapy is associated with improved outcomes.  In a study involving 8362 asymptomatic patients with HIV infection in the United States and Canada,  mortality was 69% lower among patients in whom antiretroviral therapy was initiated when the CD4+ count was between 350 and 500 cells per cubic millimeter than in those in whom such therapy was deferred until the CD4+ count was less than 350 cells per cubic millimeter. Similarly, data from 18 prospective cohort studies have shown that deferring antiretroviral therapy was associated with higher rates of the acquired immunodeficiency syndrome (AIDS) and death than starting therapy when the CD4+ count was more than 350 cells per cubic millimeter. \n\n【55】However, there are major concerns regarding the early initiation of antiretroviral therapy during tuberculosis treatment, including the increased risk of the immune reconstitution inflammatory syndrome, additive toxic effects, and the potential adverse effect on outcomes of tuberculosis therapy. We found similar rates of grade 3 and 4 adverse events in the two study groups and similar outcomes of tuberculosis therapy. Since many of the deaths occurred after the completion of tuberculosis therapy, the providers of such therapy were unaware of the benefits of cotherapy of tuberculosis and HIV infection. Although the incidence of immune-reconstitution events was significantly higher in the integrated-therapy group, this finding was not unexpected, since such events have been associated with the early initiation of antiretroviral therapy in patients with tuberculosis.  The incidence of such events in the integrated-therapy group was similar to that observed in studies of other cohorts in developing countries,  including a retrospective analysis of hospitalized Thai patients receiving both antiretroviral and tuberculosis therapies, which showed that 21 of 167 patients (12.6%) had an immune-reconstitution event.  However, none of the deaths in our trial, in which data regarding the cause of death were available, were considered attributable to the immune reconstitution inflammatory syndrome. It is reassuring that recent studies of tuberculosis-associated immune reconstitution inflammatory syndrome indicate that this complication is rarely fatal and that severe episodes can be successfully managed with corticosteroids.  Thus, the concern about increasing the likelihood of such episodes must be tempered by the survival benefit shown in our study. Nevertheless, the paradoxical deterioration in the clinical status is sufficiently common to warrant close clinical monitoring in the first few months after the initiation of antiretroviral therapy in patients coinfected with tuberculosis.\n\n【56】We acknowledge several limitations of our study. The use of death from any cause as the primary end point might underestimate the potential effect of integrated HIV–tuberculosis treatment on the rates of death specifically from tuberculosis or HIV infection. Since we were not able to obtain reliable information on the causes of all deaths in the trial, we were not able to estimate the effect on the rate of deaths that were related only to tuberculosis or HIV infection. Since our trial included only patients who had a positive sputum smear for acid-fast bacilli and whose disease was diagnosed and treated in an outpatient tuberculosis clinic, the results may not be directly generalizable to all forms and severity levels of tuberculosis. Since a retrospective analysis of 549 patients with AIDS and extrapulmonary tuberculosis showed that the introduction of highly active antiretroviral therapy significantly improved survival,  the early initiation of antiretroviral therapy may have similar benefits in patients with extrapulmonary tuberculosis. Although we have no reason to believe that our findings do not apply to sputum-smear–negative tuberculosis, our findings require empirical confirmation in this group. It should be noted that the judgment of study and nonstudy care providers took precedence over protocol-defined timing of the initiation of antiretroviral therapy, which led to early initiation of such therapy in some patients in the sequential-therapy group and delayed initiation in some patients in the integrated-therapy group. Another limitation was the delay in the initiation of antiretroviral therapy after the completion of tuberculosis therapy in the sequential-therapy group because of clinical issues (e.g., elevated levels of liver enzymes) or missed visits. Furthermore, the question of when antiretroviral therapy should be initiated during tuberculosis therapy awaits completion of the study.\n\n【57】In summary, our findings provide compelling evidence of the benefit of initiating antiretroviral therapy during tuberculosis therapy in patients with HIV coinfection. The findings also support recommendations by the WHO and others for the integration of tuberculosis and HIV care.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-14 00:19:57", "grab_time": "2024-08-13 23:20:57"}
{"id": 2234279, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "6f41bb03-258d-4df5-9e46-a6c2e4b87c53", "title": "Abnormalities of the Central Visual Pathways in Prader–Willi Syndrome Associated with Hypopigmentation", "text": "【0】Abnormalities of the Central Visual Pathways in Prader–Willi Syndrome Associated with Hypopigmentation\nAbstract\n--------\n\n【1】Patients with oculocutaneous or ocular albinism have misrouting of optic fibers, with fibers from 20 degrees or more of the temporal retina crossing at the chiasm Instead of projecting to the ipsilateral hemisphere. Misrouting can result in strabismus and nystagmus. Because patients with the Prader–Willi syndrome may also have hypopigmentation and strabismus, we wondered whether they too might have misrouting of optic fibers. We therefore studied six patients with Prader–Willi syndrome selected for a history of strabismus, using pattern-onset visually evoked potentials with binocular and monocular Stimulation to look for evidence of misrouted retinal-ganglion fibers. Four had hypopigmentation, and three of these four had abnormal evoked potentials indistinguishable from those recorded in human albinos. The two with normal pigmentation had normal responses. These findings indicate that patients with Prader–Willi syndrome who have hypopigmentation have a brain abnormality characterized by mlsrouting of retinal-ganglion fibers at the optic chiasm — a finding previously reported only in forms of albinism.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:30:51", "endTime": "2024/08/14 14:31:12", "cost": 20.232}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 22:31:11", "grab_time": "2024-08-13 22:30:50"}
{"id": 2234278, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "8c7eda21-26a2-4da3-92f9-d8c9157a3f5d", "title": "Idarucizumab for Dabigatran Reversal — Full Cohort Analysis", "text": "【0】Idarucizumab for Dabigatran Reversal — Full Cohort Analysis\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Idarucizumab, a monoclonal antibody fragment, was developed to reverse the anticoagulant effect of dabigatran.\n\n【3】Methods\n-------\n\n【4】We performed a multicenter, prospective, open-label study to determine whether 5 g of intravenous idarucizumab would be able to reverse the anticoagulant effect of dabigatran in patients who had uncontrolled bleeding (group A) or were about to undergo an urgent procedure (group B). The primary end point was the maximum percentage reversal of the anticoagulant effect of dabigatran within 4 hours after the administration of idarucizumab, on the basis of the diluted thrombin time or ecarin clotting time. Secondary end points included the restoration of hemostasis and safety measures.\n\n【5】Results\n-------\n\n【6】A total of 503 patients were enrolled: 301 in group A, and 202 in group B. The median maximum percentage reversal of dabigatran was 100% (95% confidence interval, 100 to 100), on the basis of either the diluted thrombin time or the ecarin clotting time. In group A, 137 patients (45.5%) presented with gastrointestinal bleeding and 98 (32.6%) presented with intracranial hemorrhage; among the patients who could be assessed, the median time to the cessation of bleeding was 2.5 hours. In group B, the median time to the initiation of the intended procedure was 1.6 hours; periprocedural hemostasis was assessed as normal in 93.4% of the patients, mildly abnormal in 5.1%, and moderately abnormal in 1.5%. At 90 days, thrombotic events had occurred in 6.3% of the patients in group A and in 7.4% in group B, and the mortality rate was 18.8% and 18.9%, respectively. There were no serious adverse safety signals.\n\n【7】Conclusions\n-----------\n\n【8】In emergency situations, idarucizumab rapidly, durably, and safely reversed the anticoagulant effect of dabigatran. \n\n【9】Introduction\n------------\n\n【10】Patients who are receiving oral anticoagulant therapy for the prevention or treatment of thrombosis may benefit from anticoagulant reversal if they present with life-threatening bleeding or if they will be undergoing urgent surgery or intervention. Therefore, the availability of specific reversal agents has the potential to improve the benefit–risk profile of long-term anticoagulant therapy and to increase patient and physician acceptance of such treatment. Idarucizumab is a humanized monoclonal antibody fragment that binds dabigatran with high affinity and specificity and rapidly reverses its anticoagulant activity.  Idarucizumab has been licensed in many countries, in part on the basis of the results of an interim analysis of data on the first 90 patients enrolled in the Reversal Effects of Idarucizumab on Active Dabigatran (RE-VERSE AD) study.  This report provides data on the entire cohort of 503 patients included in that study and validates the results of the interim analysis.\n\n【11】Methods\n-------\n\n【12】Study Design and Oversight\n--------------------------\n\n【13】We conducted a multicenter, prospective, single-cohort study.  The rationale for not including a control group has been described previously.  A steering committee composed of representatives from academia and the sponsor (Boehringer Ingelheim) assumes final responsibility for the design and conduct of the study. The study protocol , which is available with the full text of this article at NEJM.org, was approved by all the relevant institutional review boards. All the authors contributed to the drafting of the manuscript, made the decision to submit the manuscript for publication, and vouch for the completeness and accuracy of the data, the accuracy of the analyses, and the fidelity of the study to the protocol. No one who is not an author contributed to the writing of the manuscript.\n\n【14】Patients\n--------\n\n【15】The study included two groups of adults, 18 years of age or older, who were receiving dabigatran. The patients in group A were those with uncontrollable or life-threatening bleeding that was judged by the treating clinician to require rapid anticoagulant reversal. The patients in group B were those who were about to undergo surgery or other invasive procedures that could not be delayed for at least 8 hours and for which normal hemostasis was required. All the patients or their authorized representative provided written informed consent.\n\n【16】Study Treatment\n---------------\n\n【17】All patients were to receive 5 g of intravenous idarucizumab, which was administered as two 50-ml bolus infusions, each containing 2.5 g of idarucizumab, no more than 15 minutes apart. The 5-g dose was calculated to reverse the total body load of dabigatran that was associated with the 99th percentile of the dabigatran levels measured in the Randomized Evaluation of Long-Term Anticoagulation Therapy (RE-LY) trial. \n\n【18】Assessments and Study End Points\n--------------------------------\n\n【19】The primary efficacy end point was the maximum percentage reversal of the anticoagulant effect of dabigatran, determined at any point from the end of the first idarucizumab infusion until 4 hours after the end of the second infusion, with the percentage reversal assessed on the basis of the diluted thrombin time or the ecarin clotting time. These measurements were chosen because they correlate linearly with dabigatran concentrations measured with the use of mass spectroscopy.  Blood samples for pharmacokinetic and pharmacodynamic assessments were obtained at baseline, after the first infusion of idarucizumab, and between 10 and 30 minutes and at 1, 2, 4, 12, and 24 hours after the second infusion. Diluted thrombin time, ecarin clotting time, activated partial-thromboplastin time, and concentrations of unbound dabigatran were measured at a central laboratory, as described previously.  Reasons that an assessment could not be performed at any given time point included death, a missing sample, a small-volume sample, and technical difficulties. Treating clinicians were unaware of the results at the central laboratory. In parallel, the activated partial-thromboplastin time was assessed locally at baseline, after the first infusion of idarucizumab, and between 10 and 30 minutes and at 12 hours after the second infusion of idarucizumab. Complete reversal was defined as a decrease in the diluted thrombin time or ecarin clotting time to a normal level. A second 5-g dose of idarucizumab was permitted if there was recurrent or continued bleeding and objective evidence of a residual anticoagulant effect of dabigatran or if a second surgical procedure was necessary and residual anticoagulant activity was suspected or confirmed.\n\n【20】Clinical outcomes, as assessed by the treating clinician, were secondary end points. In group A, the extent of bleeding and hemodynamic stability were assessed between 10 and 30 minutes and at 1, 2, 4, 12, and 24 hours after the second idarucizumab infusion or when deemed clinically appropriate. The severity of bleeding was classified with the use of the International Society on Thrombosis and Haemostasis criteria .  In group B, periprocedural hemostasis was classified by the clinician as normal or as mildly, moderately, or severely abnormal. Adverse events were coded according to the _Medical Dictionary for Regulatory Activities,_ version 18.0.  Adverse events occurring within 5 days after the administration of idarucizumab were considered to have occurred during treatment. The severity of bleeding at presentation (in group A) and any suspected thrombotic events or deaths occurring from the time of idarucizumab infusion to 90 days after the infusion were to be adjudicated by an independent committee. Deaths were classified as vascular (including bleeding) or nonvascular in origin.\n\n【21】Statistical Analysis\n--------------------\n\n【22】The primary efficacy end point of maximum percentage reversal of dabigatran was calculated for patients in whom pretreatment diluted thrombin times or ecarin clotting times were above the upper limit of the normal range as assessed at a central laboratory; descriptive statistics with confidence intervals or percentiles were used as appropriate. Clotting-time measurements that exceeded the maximum measurable range were imputed with the use of the maximum measurable clotting time of 500 seconds only if the imputation was consistent with the concomitant results of other coagulation tests and unbound-dabigatran concentrations. \n\n【23】The sample size was based on regulatory feedback and practical considerations, including recruitment rates and the frequency of serious bleeding complications and emergency surgery among patients receiving dabigatran. On the basis of data from the RE-LY trial, the annual rates of life-threatening bleeding among patients receiving dabigatran at a dose of 150 mg and 110 mg are 1.5% and 1.25%, respectively, and the annual rate of emergency surgery among patients receiving dabigatran is 1.5%. \n\n【24】Results\n-------\n\n【25】Characteristics of the Patients\n-------------------------------\n\n【26】Table 1. Baseline Characteristics of the Patients.\n\n【27】From June 2014 through July 2016, a total of 503 patients (301 in group A and 202 in group B) were enrolled at 173 sites (of 369 initiated sites) in 39 countries. More than 95% of the patients were receiving dabigatran for stroke prevention in the context of atrial fibrillation, and the median age was 78 years. The median patient-reported time from the last dose of dabigatran to the first infusion of idarucizumab was 14.6 hours in group A and 18.0 hours in group B. Of the enrolled patients, 43.3% had a creatinine clearance, calculated with the use of the Cockcroft–Gault equation, that was less than 50 ml per minute. Many patients had coexisting conditions at the time of enrollment .\n\n【28】Table 2. Indications for Dabigatran Reversal.\n\n【29】Of the 301 patients in group A, 137 (45.5%) had gastrointestinal bleeding, 98 (32.6%) had intracranial hemorrhage, and 78 (25.9%) had trauma as the cause of bleeding . Bleeding was adjudicated as major or life-threatening in 265 patients (88.0%) and resulted in surgical intervention in 61 (20.3%); 114 patients (37.9%) had hemodynamic instability at presentation.\n\n【30】Of the 202 patients in group B, 197 (97.5%) underwent the intended surgery or intervention. The median time from the first infusion of idarucizumab to the initiation of the procedure was 1.6 hours. The indications for urgent surgery or intervention are listed in Table 2 .\n\n【31】Reversal of Anticoagulation\n---------------------------\n\n【32】Figure 1. Key Measurements before and after the Administration of Idarucizumab.\n\n【33】The diluted thrombin time in 293 patients who had uncontrolled bleeding and in 195 patients who were about to undergo urgent surgery or intervention are shown in Panels A and B, respectively. Panel C shows the plasma concentration of unbound dabigatran in the 485 patients in groups A and B who could be assessed. Panel D shows the activated partial-thromboplastin time in the 486 patients in groups A and B who could be assessed. The arrows show the timing of the two infusions of idarucizumab. Blood samples were obtained at baseline, after the first infusion, and between 10 and 30 minutes and at 1, 2, 4, 12, and 24 hours after the second infusion. Data are presented as box-and-whisker plots, in which the top and bottom of the rectangles indicate the 75th and 25th percentiles, respectively; the horizontal lines within the rectangles indicate the 50th percentile; the lines above and below the rectangles indicate the 90th and 10th percentiles, respectively; and the dots above and below the lines indicate the 95th and 5th percentiles, respectively. The shaded areas show the normal ranges for each of the measures, which are based on data from 208 volunteers. The upper limits of the normal range for diluted thrombin time and activated partial-thromboplastin time are 35.5 seconds and 39.8 seconds, respectively.\n\n【34】At study entry, 461 of the 503 patients (91.7%; 276 in group A and 185 in group B) had a prolonged diluted thrombin time or ecarin clotting time and were included in the primary efficacy analysis . The median maximum percentage reversal within 4 hours after the administration of idarucizumab was 100% (95% confidence interval \\[CI\\], 100 to 100), as assessed on the basis of either the diluted thrombin time  or the ecarin clotting time . Reversal was rapid and occurred independently of age, sex, renal function, and dabigatran concentration at baseline. Reversal based on the activated partial-thromboplastin time  and reversal based on the thrombin time , as measured at the central laboratory, were similar to that based on the diluted thrombin time; the activated partial-thromboplastin time was prolonged at baseline in 373 of the 503 patients (232 in group A and 141 in group B).\n\n【35】Dabigatran and Idarucizumab Concentrations\n------------------------------------------\n\n【36】Only one patient, who was subsequently found to be receiving apixaban, had no measurable plasma concentration of dabigatran at study entry. Unbound-dabigatran concentrations for all other patients correlated with the results of the clotting assays. The median baseline concentration of unbound dabigatran was 110 ng per milliliter in group A and 73.6 ng per milliliter in group B; after the administration of idarucizumab, the concentration was 20 ng per milliliter or less in all but three patients who could be assessed . With these low concentrations of unbound dabigatran, impairment of hemostasis is unlikely, because corresponding clotting times are at or below the upper limit of the normal range.\n\n【37】Unbound-dabigatran concentrations remained below 20 ng per milliliter for 24 hours in the majority of patients; however, reappearance of levels above 20 ng per milliliter was observed in 114 of 497 patients (23.0%), mainly after 12 hours, with 67 patients having elevated levels only at the 24-hour measurement. These recurrent elevations were associated with recurrent or continued bleeding in 10 patients in group A and in no patients in group B; of the 10 patients, 3 received an additional dose of idarucizumab. At 24 hours, the median idarucizumab concentration had decreased to less than 1% of the peak median, a finding consistent with the short half-life of idarucizumab . \n\n【38】Table 3. Patients Who Received More Than One Dose of Idarucizumab.\n\n【39】Only 9 of the 503 patients (1.8%) received more than 5 g of idarucizumab, including the 3 in group A who had recurrent bleeding; 7 received a second dose of idarucizumab and 1 received two additional doses because they had recurrent bleeding or were undergoing a second urgent surgical procedure . One patient received a second dose in error.\n\n【40】Clinical Outcomes\n-----------------\n\n【41】The time to the cessation of bleeding could not be assessed in the 98 patients with intracranial bleeding, because there is dissociation between the clinical course and the extent of bleeding. Although hematoma expansion on early follow-up imaging studies of the head can be used as a surrogate for the determination of the time to bleeding cessation, such imaging studies were not mandated. Of the remaining 203 patients in group A, 134 (67.7%) had confirmed bleeding cessation within 24 hours; among those 134 patients, the median time to hemostasis after the administration of idarucizumab was 2.5 hours (95% CI, 2.2 to 3.9). In the remaining 69 patients, bleeding stopped before treatment in 2 patients and could not be determined in 67 patients. Because bleeding could not be visualized (either directly or with imaging), it was not possible to know at a given time point whether bleeding had stopped or was still ongoing.\n\n【42】Among the 197 patients in group B who underwent surgery or an intervention, periprocedural hemostasis was assessed as normal in 184 patients (93.4%), mildly abnormal in 10 (5.1%), and moderately abnormal in 3 (1.5%); no patients had severely abnormal hemostasis. Many patients received transfusions and other blood products. The use of blood products and volume expanders is described in Table S2 in the Supplementary Appendix .\n\n【43】The 30-day mortality rate was 13.5% in group A and 12.6% in group B, and the corresponding 90-day mortality rate, as estimated by the Kaplan–Meier method, was 18.8% and 18.9%, respectively. The number of deaths that occurred within 5 days after treatment was 19 (6.3%) in group A and 16 (7.9%) in group B . The 30-day mortality rate was 16.4% among patients with intracranial hemorrhage, 11.1% among patients with gastrointestinal bleeding, and 12.7% among patients with bleeding at other sites.\n\n【44】Thrombotic Events\n-----------------\n\n【45】Figure 2. Adjudicated Thrombotic Events within 30 Days after the Administration of Idarucizumab.\n\n【46】Panels A and B list the thrombotic events that occurred among patients in group A and group B, respectively. Patient age, sex, and type of index event are listed in parentheses after the type of thrombotic event. The light gray portion of the bar indicates the time before the event, and the dark gray portion the time after the event. Red diamonds indicate the initiation of parenteral or oral anticoagulant therapy, and blue circles the initiation of antiplatelet therapy. AA denotes aortic aneurysm, DVT deep-vein thrombosis, GI gastrointestinal, and ICH intracranial hemorrhage.\n\n【47】Thrombotic events occurred in 24 of the 503 patients (4.8%; 14 in group A and 10 in group B) within 30 days after treatment and in 34 patients (6.8%; 19 in group A and 15 in group B) within 90 days. Details of the 30-day events are provided in Figure 2 . During the 90-day follow-up, antithrombotic therapy (including treatment with prophylactic or therapeutic doses of an anticoagulant or with an antiplatelet drug) was restarted in 72.8% of the patients in group A and in 90.1% in group B, at a mean of 13.2 days and 3.5 days, respectively, after the administration of idarucizumab. By 72 hours after the administration of idarucizumab, antithrombotic therapy was restarted in 69 of the 301 patients in group A (22.9%), with 10.1% of those patients receiving dabigatran, and in 135 of the 202 patients in group B (66.8%), with 25.9% receiving dabigatran.\n\n【48】Immunogenicity and Hypersensitivity\n-----------------------------------\n\n【49】Anti-idarucizumab antibodies were detected in 28 of the 501 patients who could be assessed (5.6%). Of those 28 patients, 19 tested positive for preexisting antibodies that were cross-reactive with idarucizumab before its administration, and 9 had antibodies that developed during treatment. The antibody titers were generally low (median, 4; interquartile range, 2 to 8), and the preexisting antibodies had no detectable effect on idarucizumab activity.\n\n【50】Three potential hypersensitivity events, each of which occurred within 5 days after the administration of idarucizumab, were reported by the investigator as being drug-related. These included a rash that lasted 1 day in a patient in whom therapy with ondansetron and tramadol had been initiated 2 days previously, vomiting and loss of consciousness in a patient who had a large intracranial hemorrhage at study entry, and hypotension during the infusion of idarucizumab that was reported as an anaphylactic reaction. An additional case of anaphylaxis, which was characterized by rash, vomiting, respiratory distress, and loss of consciousness, was reported in a patient who was receiving amoxicillin.\n\n【51】Other Safety Outcomes\n---------------------\n\n【52】Serious adverse events that occurred within 5 days after the administration of idarucizumab were reported in 117 patients (23.3%): 66 in group A (21.9%) and 51 in group B (25.2%). Events that occurred at a frequency of at least 1% in either group are listed in Table S3 in the Supplementary Appendix . Most of the events appeared to be a worsening of the index event or a coexisting condition. No other consistent pattern emerged. In group A, the most frequent event was delirium (which occurred in 2.3% of the patients); in group B, the most frequent events were cardiac arrest and septic shock (which occurred in 3.5% and 3.0% of the patients, respectively).\n\n【53】Discussion\n----------\n\n【54】The results of the RE-VERSE AD study show that, among 503 patients who were receiving dabigatran, had uncontrolled bleeding or were about to undergo an urgent procedure, and had a prolonged diluted thrombin time at baseline, idarucizumab reversed anticoagulation rapidly and completely (to a median maximum percentage of 100%) in more than 98% of the patients. A single 5-g dose of idarucizumab was sufficient in 98% of the patients, and reversal was maintained for 24 hours in most patients. The robust, rapid, and durable reversal observed in this study is consistent with the results of an interim analysis in this study and with the results of studies of the use of idarucizumab in healthy volunteers. \n\n【55】The study protocol, which was designed to mimic routine emergency care and to avoid delay in treatment, did not mandate that the results of baseline coagulation tests had to be available before idarucizumab was administered. Therefore, some patients had normal clotting times at entry. The safety of idarucizumab observed in this study supports its urgent use even if patients later prove to have had little or no circulating dabigatran.\n\n【56】Among patients with overt bleeding who could be evaluated in the first 24 hours, the median time to the cessation of bleeding was 2.5 hours. The administration of idarucizumab enabled surgery or an intervention in 197 of the 202 patients in group B; the median time to the initiation of the procedure was 1.6 hours, and 95% had normal or mildly abnormal hemostasis during the procedure. Therefore, the use of idarucizumab permitted rapid and safe intervention in the majority of patients.\n\n【57】The most likely explanation for a recurrent elevation in clotting time, which was seen mainly between 12 and 24 hours after treatment in 114 patients, is redistribution of unbound dabigatran from the extravascular to the intravascular compartment. However, recurrent elevation was associated with bleeding in only 10 patients. Therefore, among patients with a recurrent elevation in clotting time, only those with new-onset or recurrent bleeding should be considered for a second dose of idarucizumab.\n\n【58】The 30-day mortality rate was similar in group A and group B (13.5% and 12.6%, respectively), as was the 90-day mortality rate (18.8% and 18.9%, respectively). Patients enrolled in this study were elderly, had numerous coexisting conditions, and presented with serious index events, such as intracranial hemorrhage, multiple trauma, sepsis, acute abdomen, or open fracture. Most of the deaths that occurred within 5 days after enrollment appeared to be related to the severity of the index event or to coexisting conditions (e.g., respiratory failure or multiple organ failure), whereas deaths that occurred after 30 days were more likely to be independent events or related to coexisting conditions. The 30-day mortality rate observed in this study is lower than the 30-day mortality rate of 50% observed among patients who were receiving warfarin and presented with intracranial hemorrhage and than the 30-day mortality rate of 30% observed among patients who were receiving warfarin and were about to undergo emergency intervention.  However, it is similar to the 30-day mortality rate of 15% observed among the first 67 patients enrolled in a study of andexanet for the reversal of factor Xa inhibitors in patients with serious bleeding. \n\n【59】The rate of thrombotic events was 4.8% at 30 days and 6.8% at 90 days, and the 30-day rate was similar in group A and group B (5.0% and 4.6%, respectively). These rates are consistent with those reported after major surgical procedures or hospitalization for uncontrolled bleeding.  The low rate of reinitiation of anticoagulation, particularly in group A, may have contributed to the thrombotic events. Idarucizumab has a half-life of approximately 45 minutes,  and all the thrombotic events that occurred within 72 hours after its administration occurred in patients in whom anticoagulation had not been restarted. Subsequent thrombotic events are more likely to reflect the underlying prothrombotic state than to be a direct effect of reversal, because idarucizumab had no procoagulant activity when it was given to animals and healthy human volunteers. \n\n【60】Rates of thrombosis after the administration of idarucizumab are lower than those reported in studies evaluating prothrombin complex concentrate for the reversal of vitamin K antagonists.  For example, in one such study, the 30-day rate of thrombotic events was 7.8%.  The 30-day rate of thrombotic events in this study was lower than the rates of 18% and 12% that were observed among the first 67 and 102 patients, respectively, who received andexanet in the ANNEXA-4 (Andexanet Alfa, a Novel Antidote to the Anticoagulation Effects of FXA Inhibitors) study. \n\n【61】The strengths of this study include the broad inclusion criteria and the pragmatic study design, which reflects usual clinical practice. With this pragmatic design, patients with uncontrolled bleeding due to trauma could be enrolled in group A or group B at the discretion of the treating physician, depending on the urgency of any planned surgery. The major limitation of this study is the lack of a control group. Although guidelines recommend prothrombin complex concentrate for dabigatran reversal if idarucizumab is unavailable,  high-quality evidence of its effectiveness is limited.\n\n【62】In summary, idarucizumab is effective for dabigatran reversal among patients who have uncontrolled bleeding or will be undergoing urgent surgery. Although case reports suggest that thrombolysis and thrombectomy can be performed safely after dabigatran reversal with idarucizumab,  postmarketing surveillance would be helpful to monitor the effectiveness of idarucizumab for this and other indications and to further assess its safety.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-14 00:18:25", "grab_time": "2024-08-13 22:40:54"}
{"id": 2234277, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "0bd15f4f-a95f-40d8-95a1-496bf31189bc", "title": "Teamwork — Part 2: Cursed by Knowledge — Building a Culture of Psychological Safety", "text": "【0】Teamwork — Part 2: Cursed by Knowledge — Building a Culture of Psychological Safety\n### Audio Interview\n\n【1】 Audio roundtable discussion on learning to foster better teams. \n\n【2】Because physicians often set the cultural tone of the hospital, it’s worth considering barriers to health care professionals’ “psychological safety” for which we’re largely responsible. Why doesn’t it always feel like everyone caring for a patient is on the same team?", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:52:19", "endTime": "2024/08/14 14:52:43", "cost": 24.26}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 22:52:43", "grab_time": "2024-08-13 22:52:19"}
{"id": 2234276, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "26152cb2-bc45-4a58-ba0f-e8ccd42e8398", "title": "Physical Activity and Employment Status of Patients on Maintenance Dialysis", "text": "【0】Physical Activity and Employment Status of Patients on Maintenance Dialysis\nAbstract\n--------\n\n【1】Existing data on the clinical outcome of maintenance dialysis for end-stage kidney disease focus mainly on the duration of life. We surveyed 18 dialysis centers to gain a broader overview of the current status of 2481 patients on dialysis, irrespective of the type or location of dialysis. The results suggest that 12 per cent of dialysis patients are diabetics and that 53 per cent are 50 years of age or older. There was considerable variation among centers in the degree of rehabilitation; nevertheless, only 60 per cent of the nondiabetic patients and 23 per cent of the diabetic patients were capable of a level of physical activity beyond that of caring for themselves. Only one quarter of the patients worked outside the home, whereas one third worked at home. These results suggest that a larger proportion of dialysis patients than previously suspected are severely debilitated. There is a need for improved data on the quality and length of life of patients on maintenance dialysis.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:40:30", "endTime": "2024/08/14 14:40:52", "cost": 21.193}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 22:40:52", "grab_time": "2024-08-13 22:40:30"}
{"id": 2234275, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "31e7ad40-661a-48ca-885f-e3434dd7fdc9", "title": "Political Tug-of-War and Pediatric Residency Funding", "text": "【0】Political Tug-of-War and Pediatric Residency Funding\nThe recent government shutdown led to effective defunding of the Children's Hospitals Graduate Medical Education (CHGME) Payment Program. The funding lapse highlights the danger of subjecting GME funding to a politicized process.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:31:11", "endTime": "2024/08/14 15:31:51", "cost": 40.342}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 23:31:51", "grab_time": "2024-08-13 23:31:10"}
{"id": 2234274, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "f10ab9cb-0f34-48c6-8c5a-e0f16e7c725e", "title": "Brief Report: Thermocoagulation for the Early Treatment of Pregnancy with an Acardiac Twin", "text": "【0】Brief Report: Thermocoagulation for the Early Treatment of Pregnancy with an Acardiac Twin\nIntroduction\n------------\n\n【1】In twin pregnancy with acardia, which occurs in about 1 in 35,000 deliveries, the heart and usually other organs fail to develop in one twin.  The acardiac (“recipient”) twin receives blood from the normal (“pump”) twin, and the blood is then returned to the normal twin.  The natural history is variable, and some pregnancies proceed to term. Commonly, the acardiac twin becomes grossly edematous, and its size may exceed that of the pump twin. Hydramnios may occur in either sac. The perinatal mortality rate for pump twins is around 55 percent, with death due mainly to congestive cardiac failure or prematurity.  Acardia is discovered by routine ultrasonography in early pregnancy or when a clinical finding later in pregnancy, such as polyhydramnios, leads to ultrasonography.\n\n【2】Various therapeutic options have been proposed, including control of amniotic-fluid volume by repeated amniocentesis or indomethacin therapy in the mother,  administration of digoxin to the mother to treat heart failure in the pump twin, and selective preterm delivery of the acardiac twin by hysterotomy.  These interventions are usually feasible only after 24 weeks of gestation, and they are hazardous for both the mother and the normal fetus. Another approach is to stop the perfusion of the acardiac twin by the pump twin, which has been done with varying degrees of success by percutaneous injection of thrombogenic coils  or sclerosing agents to occlude the umbilical cord of the acardiac twin  ; by cord ligation performed at hysterotomy  or with endoscopic  or ultrasound  guidance; and by fetoscopic laser coagulation. \n\n【3】We report here on a new technique of thermocoagulation used in four women with pregnancies in which there was one acardiac twin. The technique was used to stop the perfusion of the acardiac twin, with the subsequent delivery of the healthy twin.\n\n【4】Methods\n-------\n\n【5】Thermocoagulation was performed with a wire electrode, 1 mm in diameter, that could be passed through an 18-gauge needle and that was insulated with polytetrafluoroethylene along most of its length, with 3 mm of the wire left bare at the tip. The electrode, which was made in the medical-physics workshop at our institution, was connected to a standard monopolar diathermy machine and activated by a foot switch.\n\n【6】Figure 1. Placement of 18-Gauge Needle and Monopolar Insulated Wire Electrode for Thermocoagulation of a Major Vessel in the Body of an Acardiac Acephalic Fetus.\n\n【7】The arrows show the direction of circulation from and to the normal (pump) twin.\n\n【8】After deciding on the basis of color-flow mapping which vessel was to be coagulated, an 18-gauge needle was introduced transabdominally with the use of local anesthesia and with ultrasound guidance (128XP/10 system, Acuson, Mountain View, Calif.). The tip of the needle was guided into the lumen of the fetal aorta if the vessel was of sufficient size; if it was too small, the tip was placed near the vessel. The wire electrode was inserted so that its bare tip lay in or just outside the vessel wall, with care taken to ensure that the tip was beyond the needle and no longer in contact with it . Power was delivered for periods of 5 to 15 seconds, with 10 W delivered initially and the amount increased in increments of 5 to 10 W, until a white echodense area of thermocoagulation surrounded the electrode tip and the vessel. The procedure was judged to be successful when the cessation of blood flow to the acardiac twin was confirmed by color Doppler ultrasonography. Before 20 weeks of gestation, the maximal power required for thermocoagulation was 20 to 35 W. Ultrasound imaging and Doppler ultrasonography were also used to demonstrate that the circulation of the pump twin remained normal during and after thermocoagulation. The procedure took 5 to 10 minutes, and the women were allowed to go home 1 hour afterward.\n\n【9】Results\n-------\n\n【10】The four cases presented here were consecutive and unselected. Use of the procedure was approved by the institutional review committee at our hospital, and all the women gave written informed consent.\n\n【11】Table 1. Characteristics and Outcomes of Four Pregnancies with an Acardiac Twin That Were Treated by Thermocoagulation.\n\n【12】Patient 1 was first seen when she was 24 weeks pregnant. The acardiac twin was enormously edematous with no amniotic fluid, and it compressed the pump twin and its amniotic sac . The pump twin had cardiac failure, with an enlarged heart, reversed flow in the ductus venosus, and oligohydramnios. The target of first choice for thermocoagulation in the acardiac twin was the point of insertion of the umbilical cord into the placenta, but this site was obscured. The needle and electrode tip were therefore inserted into the fetal end of the umbilical cord. The cord was so large and edematous that thermocoagulation with up to 60 W of power did not cause an immediate cessation of flow. Color Doppler ultrasonography did demonstrate a reduction of flow, however, and in the next two weeks, the acardiac twin stopped growing, and the hydrops decreased. The pump twin continued to grow, the volume of amniotic fluid became normal, and no abnormalities of the brain or cerebral ventricles were seen with ultrasonography.\n\n【13】At 32 weeks, severe preeclampsia developed, and the pump twin was delivered by emergency cesarean section. The twin weighed 1265 g and had hyaline membrane disease and intraventricular hemorrhage, resulting in developmental delay. The acardiac twin was mummified, and an autopsy confirmed the absence of the heart and other viscera.\n\n【14】Patient 2 underwent the procedure at 18 weeks' gestation because the acardiac twin had gross hydrops and was bigger than the pump twin .\n\n【15】Patient 3 was referred at 16 weeks' gestation; the acardiac twin was edematous but smaller than the pump twin. Ultrasonography was performed weekly; by 19 weeks, the acardiac twin was larger than the pump twin, which had some myocardial hypertrophy and polyhydramnios. The procedure was therefore performed at this time.\n\n【16】Patient 4 was referred at 12 weeks' gestation, at which time the acardiac twin did not have hydrops and was smaller than the pump twin. Serial ultrasonography showed a dramatic increase in hydrops and oligohydramnios in the acardiac twin and mild polyhydramnios around the pump twin by 16 weeks, when the procedure was performed.\n\n【17】Acardiac fetuses have small, often short umbilical cords, usually with two vessels. Before 20 weeks' gestation, it is difficult to place an 18-gauge needle in an umbilical vessel. Therefore, in Patients 2, 3, and 4, we positioned the needle near the major vessel in the acardiac twin under color Doppler ultrasonographic guidance, and the electrode tip was then advanced into the vessel or placed next to it. The exact placement was not critical in the small fetuses, since the zone of thermocoagulation was large enough to include the vessel and hence to occlude it .\n\n【18】In Patients 2, 3, and 4, perfusion of the acardiac twin stopped immediately, as demonstrated by color flow mapping. Growth ceased and hydrops disappeared in the three acardiac fetuses. All three pregnancies continued without further complications, and in each case, a healthy baby was delivered vaginally at term, together with a mummified acardiac fetus.\n\n【19】Discussion\n----------\n\n【20】In pregnancies involving an acardiac twin, conservative management results in a high rate of loss of the normal twin. In the largest reported series, involving 49 cases, congestive cardiac failure, polyhydramnios, and preterm delivery were strongly related to the ratio of the weight of the acardiac twin to that of the pump twin, with a ratio above 70 percent correlated with an adverse outcome. Some acardiac twins become smaller in the absence of intervention; nonetheless, when ultrasonography reveals features of cardiac compromise in the pump twin, edema in the acardiac twin, or polyhydramnios in either sac, vascular occlusion should be performed in the acardiac twin to correct the excessive cardiovascular demands on the normal twin. In our series, cardiac compromise in the pump twin was apparent as early as 16 weeks' gestation.\n\n【21】Thermocoagulation has several advantages over alternative therapies for this condition. It is simple and quick and does not require expensive equipment. Thermocoagulation is guided by ultrasonography in a manner similar to that of fetal-blood sampling and does not require the instruments and skills necessary for intrauterine surgery under endoscopic guidance. Whereas thermocoagulation is performed with the use of local anesthesia, other methods of selective occlusion of the umbilical cord are more invasive and carry greater risks of fetal and maternal morbidity and of fetal mortality.\n\n【22】The cord of the acardiac twin is often very short and thin, and it may be difficult to identify clearly, even when visualized directly, or it may be markedly edematous, in which case endoscopic ligation or laser coagulation may be hazardous. Occlusion of the cord is also difficult in the presence of polyhydramnios or oligohydramnios. These problems are avoided by identifying the main intraabdominal vessel in the body of the acardiac twin and ablating it by thermocoagulation, thus arresting the circulation of the acardiac twin. Finally, thermocoagulation can be used earlier in pregnancy than most of the alternative procedures.\n\n【23】We conclude that thermocoagulation offers a safe and effective method to occlude the circulation of the acardiac twin and should become the treatment of choice for pregnancy with an acardiac twin.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-14 00:22:39", "grab_time": "2024-08-13 23:35:58"}
{"id": 2234273, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "98d64c05-e429-4c65-940b-6864cfe06f00", "title": "Banning Genetic Discrimination in Life Insurance — Time to Follow Florida’s Lead", "text": "【0】Banning Genetic Discrimination in Life Insurance — Time to Follow Florida’s Lead\nFear of discrimination by life insurance companies has been an obstacle to progress in the use of genetic technologies in medicine and research. A new Florida law will allow residents to undergo genetic testing without fear of the financial consequences of results.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:37:04", "endTime": "2024/08/14 14:37:39", "cost": 35.847}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 22:37:39", "grab_time": "2024-08-13 22:37:03"}
{"id": 2234272, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "4889a978-1cb6-4006-b3ad-dce117e593ff", "title": "MRI-Targeted or Standard Biopsy for Prostate-Cancer Diagnosis", "text": "【0】MRI-Targeted or Standard Biopsy for Prostate-Cancer Diagnosis\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Multiparametric magnetic resonance imaging (MRI), with or without targeted biopsy, is an alternative to standard transrectal ultrasonography–guided biopsy for prostate-cancer detection in men with a raised prostate-specific antigen level who have not undergone biopsy. However, comparative evidence is limited.\n\n【3】Methods\n-------\n\n【4】In a multicenter, randomized, noninferiority trial, we assigned men with a clinical suspicion of prostate cancer who had not undergone biopsy previously to undergo MRI, with or without targeted biopsy, or standard transrectal ultrasonography–guided biopsy. Men in the MRI-targeted biopsy group underwent a targeted biopsy (without standard biopsy cores) if the MRI was suggestive of prostate cancer; men whose MRI results were not suggestive of prostate cancer were not offered biopsy. Standard biopsy was a 10-to-12–core, transrectal ultrasonography–guided biopsy. The primary outcome was the proportion of men who received a diagnosis of clinically significant cancer. Secondary outcomes included the proportion of men who received a diagnosis of clinically insignificant cancer.\n\n【5】Results\n-------\n\n【6】A total of 500 men underwent randomization. In the MRI-targeted biopsy group, 71 of 252 men (28%) had MRI results that were not suggestive of prostate cancer, so they did not undergo biopsy. Clinically significant cancer was detected in 95 men (38%) in the MRI-targeted biopsy group, as compared with 64 of 248 (26%) in the standard-biopsy group (adjusted difference, 12 percentage points; 95% confidence interval \\[CI\\], 4 to 20; P=0.005). MRI, with or without targeted biopsy, was noninferior to standard biopsy, and the 95% confidence interval indicated the superiority of this strategy over standard biopsy. Fewer men in the MRI-targeted biopsy group than in the standard-biopsy group received a diagnosis of clinically insignificant cancer (adjusted difference, −13 percentage points; 95% CI, −19 to −7; P<0.001).\n\n【7】Conclusions\n-----------\n\n【8】The use of risk assessment with MRI before biopsy and MRI-targeted biopsy was superior to standard transrectal ultrasonography–guided biopsy in men at clinical risk for prostate cancer who had not undergone biopsy previously. \n\n【9】Introduction\n------------\n\n【10】Men with a clinical suspicion of prostate cancer on the basis of an elevated prostate-specific antigen (PSA) level or an abnormal digital rectal examination are typically offered a standard transrectal ultrasonography–guided biopsy of the prostate during which 10 to 12 cores are obtained. This approach is associated with the underdetection of higher-grade (clinically significant) prostate cancers and the overdetection of low-grade (clinically insignificant) cancers.  Despite randomized trials showing that men with clinically insignificant cancer do not benefit from treatment,  its identification still results in the overtreatment of some men. Some men will receive radical treatment that has side effects,  and others will undergo active surveillance with repeated assessment over time that has costs for patients and health care systems. \n\n【11】An alternative diagnostic pathway in men with a clinical suspicion of prostate cancer involves multiparametric magnetic resonance imaging (MRI). With better standardization of the conduct and reporting of multiparametric MRI, the ability to detect clinically significant cancer and to rule it out has improved over the past decade.  Multiparametric MRI could be used as a triage test to avoid a biopsy if the results were negative,  whereas positive results could be used for targeting abnormal areas in the prostate during biopsy. \n\n【12】In single-center studies, the approach of obtaining MRI-targeted biopsy cores alone, without performing standard biopsies, has shown similar or higher rates of detection of clinically significant cancer  and lower rates of detection of clinically insignificant cancer  than standard biopsy. We compared MRI-targeted biopsy with standard transrectal ultrasonography–guided biopsy in a pragmatic, multicenter, randomized trial. The PRECISION (Prostate Evaluation for Clinically Important Disease: Sampling Using Image Guidance or Not?) trial aimed to evaluate prospectively whether multiparametric MRI, with targeted biopsy in the presence of an abnormal lesion, was noninferior to standard transrectal ultrasonography–guided biopsy in the detection of clinically significant prostate cancer in men with a clinical suspicion of prostate cancer who had not undergone biopsy of the prostate previously.\n\n【13】Methods\n-------\n\n【14】Trial Design\n------------\n\n【15】We conducted this multicenter, randomized, noninferiority trial at 25 centers in 11 countries . Men who provided written informed consent were randomly assigned in a  ratio to either the MRI-targeted biopsy group or the standard-biopsy group . The assignment sequence used computer-generated, randomly permuted blocks of unequal size, stratified according to center. Group assignments were revealed by the Web-based system once a participant had been assessed as eligible and had provided written informed consent.\n\n【16】The full trial protocol , available at NEJM.org, has been published previously  and was approved by the ethics review board at each participating institution. The trial was monitored by an independent trial steering committee and data and safety monitoring committee. The trial was designed by the Standards of Reporting for MRI-Targeted Biopsy Studies (START) working group,  and final decisions were made by the first author and the last two authors. Data were gathered by the trial team members who are listed in Section S1 in the Supplementary Appendix . One author analyzed the data, and the analysis was independently verified by another author. The authors assume responsibility for the accuracy and completeness of the data and analyses and for the adherence of the trial to the protocol. The first draft of the manuscript was written by the first author.\n\n【17】No commercial entity was involved in the trial. The trial was funded by the National Institute for Health Research and the European Association of Urology Research Foundation, with trial governance from University College London. The funders had no role in the protocol development, data analysis or interpretation, or manuscript preparation.\n\n【18】Participants\n------------\n\n【19】Participants were recruited in outpatient clinics and were eligible for enrollment if they had not undergone biopsy of the prostate previously and had been referred with a clinical suspicion of prostate cancer on the basis of an elevated PSA level, an abnormal digital rectal examination, or both . Participants were required to have a PSA level of 20 ng per milliliter or less, to have results on digital rectal examination that did not suggest extracapsular disease, and to be suitable candidates for biopsy of the prostate and for MRI.\n\n【20】MRI and MRI-Targeted Biopsy\n---------------------------\n\n【21】Multiparametric MRI was performed with the use of a 1.5-T or 3.0-T scanner with a pelvic phased-array coil, with or without an endorectal coil . T <sub>2 </sub> \\-weighted, diffusion-weighted, and dynamic contrast-enhanced sequences were acquired according to minimum standards that have been set by consensus guidelines.  Areas on the multiparametric MRI that were suggestive of prostate cancer were categorized by a local radiologist according to the Prostate Imaging–Reporting and Data System, version 2 (PI-RADS v2),  on a scale from 1 to 5, with higher numbers indicating a greater likelihood of clinically significant cancer. Table S4 in the Supplementary Appendix provides details regarding the experience of the clinicians who took part in the trial.\n\n【22】Men who had a positive result on the multiparametric MRI — that is, in whom an area with a score of 3 (equivocal regarding the likelihood of prostate cancer), 4 (likely to be prostate cancer), or 5 (highly likely to be prostate cancer) was identified — underwent MRI-targeted biopsy with the use of real-time ultrasonographic guidance. A maximum of three areas that were suggestive of prostate cancer were permitted to be chosen for targeted biopsy, with a maximum of 4 biopsy cores obtained per area, resulting in a maximum of 12 biopsy cores obtained per participant. MRI-targeted biopsy registration (i.e., matching of the image of the target on MRI with the real-time image of the prostate during biopsy) could be performed by means of visual registration or software-assisted registration (also known as MRI–ultrasonographic fusion)  and could be carried out through the transrectal or transperineal route, according to local expertise . In the absence of abnormal areas on the multiparametric MRI (i.e., a negative result, with a score of 1 or 2), the participant was not offered a protocol biopsy.\n\n【23】Standard Transrectal Ultrasonography–Guided Biopsy\n--------------------------------------------------\n\n【24】Biopsy was carried out by experienced operators who used a standard transrectal technique. A total of 10 to 12 biopsy cores were obtained from the peripheral zone of the prostate at the base, mid gland, and apex. \n\n【25】Participant-Reported Outcome Measures\n-------------------------------------\n\n【26】Participant-reported questionnaires were used to collect data about intervention-specific side effects immediately and at 30 days after biopsy and after MRI.  Health-related quality of life was assessed with the use of the EuroQol–5 Dimension Self-Report Questionnaire at baseline, 24 hours after the intervention, and 30 days after the intervention. \n\n【27】Outcomes\n--------\n\n【28】The primary outcome was the proportion of men with clinically significant cancer, defined as the presence of a single biopsy core indicating disease of Gleason score 3+4 (Gleason sum of 7) or greater (the Gleason score is composed of a primary \\[most predominant\\] grade plus a secondary \\[highest nonpredominant\\] grade; the range for a primary or secondary grade is from 3 to 5, with the Gleason sum ranging from 6 to 10, and with higher scores indicating a more aggressive form of prostate cancer). Secondary outcomes included the proportion of men with clinically insignificant cancer (Gleason score 3+3), the proportion of men in the MRI-targeted biopsy group who did not undergo biopsy, and the proportion of men with adverse events after the intervention. All the secondary outcomes are listed in Table S6 in the Supplementary Appendix . Outcomes were reported according to the START guidelines,  which are the consensus criteria for reporting studies of MRI-targeted prostate biopsies.\n\n【29】Follow-up\n---------\n\n【30】Participants were followed until the visit at which their treatment decisions were made or until their 30-day postintervention questionnaires were completed, whichever was later. Participants who underwent further diagnostic tests as a result of the outcome of the treatment-decision visit were additionally followed until after the results of the further investigation were made available and recorded. These participants included men who had negative test results in either the standard-biopsy group or the MRI-targeted biopsy group and underwent additional testing. Participants who had negative test results in either group at the end of the trial period returned to standard-care monitoring at each center, which typically involved surveillance of the PSA level. Participants who underwent radical prostatectomy on the basis of their treatment decision were also followed until the pathological testing results of their radical prostatectomy were available. Participants provided written informed consent for long-term follow-up as part of future studies involving additional contact from the trial center and linkage to national databases.\n\n【31】Quality Control\n---------------\n\n【32】Uroradiologists and pathologists at the coordinating center, who were unaware of the results of the original reports, reviewed 25% of the multiparametric MRIs and 15% of the original pathological specimens. These MRIs and specimens had been chosen at random from participants at every site.\n\n【33】Statistical Analysis\n--------------------\n\n【34】Using a noninferiority margin of 5 percentage points that was agreed on at an expert consensus group meeting  and a one-sided alpha level of 2.5%, we calculated that the randomization of 422 men would provide the trial with 90% power to show the noninferiority of MRI, with or without targeted biopsy, to standard biopsy, assuming a detection rate of clinically significant cancer of 40% in the group that underwent MRI, with or without targeted biopsy, and 30% in the standard-biopsy group. This sample size was increased to 470 to allow for a 10% rate of withdrawal and loss to follow-up. Detailed justification of the sample size is provided in the protocol. \n\n【35】The statistical analysis plan was prespecified and approved by the data and safety monitoring committee before the analysis of any data. For the primary outcome, if the lower boundary of the two-sided 95% confidence interval for the difference in the rates of detection of clinically significant cancer in the MRI-targeted biopsy group relative to the standard-biopsy group was greater than −5 percentage points, then MRI, with or without targeted biopsy, would be deemed to be noninferior. Furthermore, if the lower boundary was greater than zero, superiority would be claimed. The difference was estimated with the use of a generalized linear mixed model (with the use of an identity link function with a binomial distribution) that included trial center as a random effect.\n\n【36】All the participants who underwent randomization were included in the primary intention-to-treat analysis. Analyses were repeated in the modified intention-to-treat population and the per-protocol population as sensitivity analyses . The modified intention-to-treat analysis excluded participants who did not complete a diagnostic test strategy; this analysis was carried out to prevent unequal withdrawal in the two groups from contributing to a difference between the groups. The per-protocol analysis included only men who underwent the randomly assigned testing procedure as specified in the protocol; this analysis was carried out because this was a noninferiority trial, so a per-protocol analysis would reduce the chance of biasing the result toward the null. If, after participants had undergone the trial test procedures, further tests provided different information about the presence of cancer, no adjustment was made to the analyses of the primary and secondary outcomes. A post hoc Bonferroni correction was used to adjust for three secondary outcomes (proportion of men with clinically insignificant cancer, maximum cancer core length, and health-related quality of life), with a two-sided P value of less than 0.017 considered to indicate statistical significance. The methods of analysis of the other outcomes are described in Section S2 in the Supplementary Appendix .\n\n【37】Results\n-------\n\n【38】Trial Population\n----------------\n\n【39】Figure 1. Enrollment, Randomization, and Follow-up of the Participants.\n\n【40】Men who were randomly assigned to the magnetic resonance imaging (MRI)–targeted biopsy group underwent MRI. If the MRI revealed results that were suggestive of prostate cancer, the participant underwent a targeted biopsy; men whose MRI results were not suggestive of prostate cancer were not offered biopsy. Men who were assigned to the standard-biopsy group underwent standard transrectal ultrasonography–guided biopsy. PSA denotes prostate-specific antigen.Table 1.  Table 1. Characteristics of the Participants at Baseline.\n\n【41】From February 2016 through August 2017, a total of 500 participants underwent randomization at 23 of the 25 sites, with 252 participants being assigned to the MRI-targeted biopsy group and 248 to the standard-biopsy group . The characteristics of the participants at baseline were similar in the two groups .\n\n【42】A total of 71 of 252 participants (28%) in the MRI-targeted biopsy group had a result on multiparametric MRI that was not suggestive of prostate cancer (PI-RADS v2 score, ≤2), and so they did not undergo biopsy. Among the participants with a positive result on multiparametric MRI, 51 of 175 (29%) had a PI-RADS v2 score of 3, 70 (40%) had a score of 4, and 54 (31%) had a score of 5 . The remaining 6 men did not complete the MRI assessment . Among the participants who underwent biopsy, a median of 4 biopsy cores were obtained in the MRI-targeted biopsy group, as compared with a median of 12 cores in the standard-biopsy group .\n\n【43】Outcomes\n--------\n\n【44】Table 2. Comparison of Cancer Detection between Groups. Figure 2.  Figure 2. Intention-to-Treat, Modified Intention-to-Treat, and Per-Protocol Analyses of the Primary Outcome for the Detection of Clinically Significant Prostate Cancer.\n\n【45】Shown are the absolute differences between the MRI-targeted biopsy group and the standard-biopsy group in the rates of detection of clinically significant cancer. The intention-to-treat analysis included all the participants who underwent randomization, the modified intention-to-treat analysis excluded participants who did not complete a diagnostic test strategy, and the per-protocol analysis included only participants who underwent the randomly assigned testing procedure as specified in the protocol. If the lower boundary of the two-sided 95% confidence interval for the difference (MRI-targeted biopsy group minus standard-biopsy group) was greater than −5 percentage points (dashed line), then MRI, with or without targeted biopsy, would be deemed to be noninferior. If the lower boundary was greater than zero (solid line), superiority would be claimed.\n\n【46】Clinically significant cancer was detected in 95 men (38%) in the MRI-targeted biopsy group, as compared with 64 (26%) in the standard-biopsy group (adjusted difference, 12 percentage points; 95% confidence interval \\[CI\\], 4 to 20; P=0.005) . The lower boundary of the 95% confidence interval for the difference was greater than −5 percentage points, so MRI, with or without targeted biopsy, was deemed to be noninferior to standard transrectal ultrasonography–guided biopsy in the detection of clinically significant cancer. Furthermore, the 95% confidence interval showed the superiority of MRI, with or without targeted biopsy, over transrectal ultrasonography–guided biopsy. The results were consistent in the modified intention-to-treat and per-protocol populations .\n\n【47】Fewer participants received a diagnosis of clinically insignificant cancer in the MRI-targeted biopsy group than in the standard-biopsy group (23 men \\[9%\\] vs. 55 \\[22%\\]; adjusted difference, −13 percentage points; 95% CI, −19 to −7; P<0.001). In men with cancer, the mean maximum cancer core length was 7.8 mm in the MRI-targeted biopsy group and 6.5 mm in the standard-biopsy group (adjusted mean difference, 1.0 mm; 95% CI, 0.0 to 2.1; P=0.053). Interpretations of the results for these secondary outcomes were unchanged by post hoc Bonferroni correction .\n\n【48】Figure 3. Percentages of Men with Clinically Significant, Clinically Insignificant, and No Cancer, Identified According to PI-RADS v2 Score.\n\n【49】For men randomly assigned to the MRI-targeted biopsy group, the areas of the prostate were scored with the use of the Prostate Imaging–Reporting and Data System, version 2 (PI-RADS v2). Scores range from 1 to 5, with higher numbers indicating a greater likelihood of clinically significant cancer; a score of 3 indicates equivocal results, 4 results that are likely to be prostate cancer, and 5 results that are highly likely to be prostate cancer. Men who had a score of 3 or higher underwent MRI-targeted biopsy. Clinically significant cancer was defined as the presence of a single biopsy core indicating disease of Gleason score 3+4 (Gleason sum of 7) or greater, and clinically insignificant cancer as a biopsy sample with a Gleason score of 3+3 (Gleason sum of 6). The Gleason score is composed of a primary (most predominant) grade plus a secondary (highest nonpredominant) grade; the range for a primary or secondary grade is from 3 to 5, with the Gleason sum ranging from 6 to 10, and with higher scores indicating a more aggressive form of prostate cancer. Percentages may not total 100 because of rounding.\n\n【50】A greater percentage of cores were positive for cancer in the MRI-targeted biopsy group (422 of 967 cores \\[44%\\]) than in the standard-biopsy group (515 of 2788 \\[18%\\]). Among men with a positive result on MRI, the percentage of men with clinically significant cancer was highest among participants with a PI-RADS v2 score of 5 (83%), followed by those with a score of 4 (60%) and those with a score of 3 (12%). Conversely, the percentage of men without cancer was highest among participants with a PI-RADS v2 score of 3 (67%), followed by those with a score of 4 (31%) and those with a score of 5 (6%) .\n\n【51】Quality of Life and Safety\n--------------------------\n\n【52】Health-related quality of life at 24 hours and at 30 days after the intervention did not differ significantly between the MRI-targeted biopsy group and the standard-biopsy group. The intervention was associated with similar results regarding immediate postintervention discomfort and pain in the two groups. The participant-reported complications at 30 days were less frequent in the MRI-targeted biopsy group than in the standard-biopsy group, including events of blood in the urine (30% vs. 63%), blood in the semen (32% vs. 60%), pain at the site of the procedure (13% vs. 23%), rectal bleeding (14% vs. 22%), and erectile dysfunction (11% vs. 16%). These findings reflected the lower percentage of men undergoing biopsy and fewer biopsy cores obtained in the MRI-targeted biopsy group than in the standard-biopsy group. A total of 2% of the men in the MRI-targeted biopsy group and 2% in the standard-biopsy group had serious adverse events. Details regarding health-related quality-of-life scores, participant-reported complications, and adverse events are provided in Tables S10 through S12 in the Supplementary Appendix .\n\n【53】Further Diagnostic Testing\n--------------------------\n\n【54】After the discussion of the test results with each participant, more men in the standard-biopsy group (39 men \\[16%\\]) than in the MRI-targeted biopsy group (7 \\[3%\\]) underwent further diagnostic tests. Of the 39 further diagnostic tests that were performed in the standard-biopsy group, 38 (in 15% of the participants in the group) were diagnostic multiparametric MRIs that were carried out in men with negative results on the transrectal ultrasonography–guided biopsy. In the MRI-targeted biopsy group, only 3 participants (1%) with negative results on MRI subsequently underwent standard transrectal ultrasonography–guided biopsy. More men who underwent MRI-targeted biopsy (104 men \\[41%\\]) than men who underwent standard transrectal ultrasonography–guided biopsy (74 \\[30%\\]) adopted a strategy of monitoring of the PSA level, although the percentage of men undergoing active surveillance or radical treatment was similar in the two groups.\n\n【55】Among the participants who underwent further biopsy, clinically significant cancer was detected in none of the 4 men in the MRI-targeted biopsy group and in 3 of 9 men (33%) in the standard-biopsy group. Of the 71 men with negative results on MRI and no biopsy, 3 (4%) were discharged, 62 (87%) were referred for monitoring of the PSA level, 3 (4%) underwent further prostate biopsy (all had negative results), 1 (1%) underwent an additional multiparametric MRI, and 2 (3%) had missing information. The percentage of men whose Gleason score was upgraded (i.e., found to be higher) after radical prostatectomy was similar in the MRI-targeted biopsy group (5 of 30 men \\[17%\\]) and the standard-biopsy group (4 of 27 \\[15%\\]). Details are provided in Tables S13 through S15 in the Supplementary Appendix .\n\n【56】Quality Control\n---------------\n\n【57】Results of the quality-control review of multiparametric MRI showed that the percentage of cases that were scored with agreement for concordant biopsy decision by the central radiology team and the site radiologist was 78% (50 of 64 cases). The percentage of cases that were scored with agreement on the Gleason score by the central pathologists and the site pathologist was 88% (53 of 60 cases). Details are provided in Table S16A, S16B, and S16C in the Supplementary Appendix .\n\n【58】Discussion\n----------\n\n【59】The ideal test for prostate cancer would be minimally invasive, have few side effects, identify a high proportion of men who would benefit from treatment, and minimize the identification of men with clinically insignificant cancer in order to prevent overtreatment. In men with a clinical suspicion of prostate cancer who had not undergone biopsy of the prostate previously, the PRECISION trial showed that MRI, with or without targeted biopsy, appeared to achieve these goals better than the traditional standard of care, transrectal ultrasonography–guided biopsy. MRI, with or without targeted biopsy, led to fewer men undergoing biopsy, more clinically significant cancers being identified, less overdetection of clinically insignificant cancer, and fewer biopsy cores being obtained than did standard transrectal ultrasonography–guided biopsy. Slightly more than one quarter of the men avoided a biopsy altogether, and the 30-day participant-reported side-effect profile appeared to be more favorable in the MRI-targeted biopsy group than in the standard-biopsy group. The MRI-targeted biopsy approach was also well adhered to by the participants and clinicians, with only 7 of 252 men (3%) not completing the diagnostic test strategy .\n\n【60】The results of single-center studies have been mixed. Some studies have not shown the superiority of an MRI-based pathway over transrectal ultrasonography–guided biopsy, although these comparisons were likely to have been underpowered.  Other single-center studies have shown advantages of an MRI-based diagnostic pathway over transrectal ultrasonography–guided biopsy,  and a meta-analysis of published studies had findings concordant with those of our trial.  These single-center studies have limitations in their lack of generalizability, and the majority of the studies were small and nonrandomized.\n\n【61】The PRECISION trial was an international trial, and key strengths included its size and pragmatism.  We did not limit the performance of MRI-targeted biopsy to highly experienced operators, and most of the participating investigators had modest experience with MRI-targeted biopsy, particularly as compared with standard transrectal ultrasonography–guided biopsy. We also allowed nonacademic centers outside the original expert group to take part. In addition, either 1.5-T or 3.0-T MRI machines were permitted, and the use of an endorectal coil was permitted but not required. Also, various techniques of MRI-targeted biopsy, with visual registration or software-assisted registration with either transrectal or transperineal access routes, were permitted. This approach is supported by a meta-analysis of studies that showed a lack of superiority of any one registration approach.  We believed that the results would be more generalizable if we permitted centers to use their local expertise and resources than if we required that they use a particular operating system or access route that may not have been available to all centers outside of the trial. We observed differences among centers in the detection of clinically significant cancers. However, on average, MRI with or without targeted biopsy was conclusively superior to standard transrectal ultrasonography–guided biopsy.\n\n【62】Our trial has limitations. First, despite the use of standardized reporting of MRI results,  the central quality-control review of multiparametric MRIs  showed moderate agreement (78%) between the site and the central radiologist reading, a finding that highlights that there is still room for improvement in attaining consistency in the reporting of the results of multiparametric MRI. Regardless, the degree of agreement with central interpretation was similar to the interrater agreement that has been seen in other studies involving expert readers of multiparametric MRIs.  This finding highlights the need for further research regarding improvements to the standardization, reproducibility, and reporting of multiparametric MRIs.\n\n【63】Second, a small proportion of the pathological test results were upgraded or downgraded on central pathological review. However, the differences were not substantial between groups, and the agreement that was seen on central review was consistent with that seen in the literature. \n\n【64】Third, there are concerns about the men with negative results on multiparametric MRI who do not undergo biopsy. It has been shown that these men have a low risk of clinically significant cancer,  but nonetheless, follow-up with monitoring of the PSA level is routine, reasonable, and safe. Participants provided consent for long-term follow-up in national registries. Moreover, this trial showed that, among men with negative results on initial tests, a far greater proportion of the participants in the standard-biopsy group underwent further diagnostic tests than did those in the MRI-targeted biopsy group, a finding that confirms that a negative result on multiparametric MRI was more reassuring to the participants and clinicians than a negative result on standard transrectal ultrasonography–guided biopsy.\n\n【65】Fourth, it is possible that clinically significant cancers may have been missed by the omission of standard biopsy cores in men in the MRI-targeted biopsy group. Previous well-designed studies have highlighted that the percentage of cases of clinically significant cancer that are missed by MRI-targeted biopsy but detected by standard transrectal ultrasonography–guided biopsy is low, between 0% and 10%.  Despite more than one quarter of the men avoiding a biopsy, this trial showed that when clinicians limited themselves to the use of MRI-targeted biopsies only, the rates of detection of clinically significant cancer were higher than those seen with the standard of care. Furthermore, because systematic biopsy was avoided, clinically insignificant cancer was detected in fewer men, which may have a substantial benefit in reducing the overtreatment of men with prostate cancer. If both systematic biopsy and MRI-targeted biopsy were carried out in the same man at the same time, the performance of one test could be influenced by the other, which would make it difficult to evaluate the unbiased performance of each test individually.\n\n【66】We acknowledge that the acquisition and reporting of MRI of the prostate are specialist skills with a learning curve and that the radiologists involved in this trial were reporting a high volume of MRIs per year (median, 300 MRIs per year). We suggest that those who report MRIs of the prostate report a high volume of scans under the supervision of a radiologist who is experienced in MRI of the prostate. We acknowledge that a change in the standard of care for prostate-cancer diagnosis would entail changes in health care systems to accommodate appropriate MRI capacity and to meet the training needs of radiologists and urologists. From a health economics perspective, the cost savings with MRI, with or without targeted biopsy, over standard transrectal ultrasonography–guided biopsy may emerge from the earlier detection of clinically significant cancers, fewer cases of insignificant cancer diagnosed, and fewer repeat biopsies. Reports from other studies and in different contexts suggest that this pathway may be cost-effective in the long term. \n\n【67】In conclusion, in men with a clinical suspicion of prostate cancer, we found that a diagnostic pathway including risk assessment with MRI before biopsy and MRI-targeted biopsy in the presence of a lesion suggestive of cancer was superior to the diagnostic pathway of standard transrectal ultrasonography–guided biopsy.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-14 00:18:31", "grab_time": "2024-08-13 22:56:28"}
{"id": 2234271, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "b228aca9-d448-4750-93de-2b03ada72e73", "title": "Case 21-1998: Rabies", "text": "【0】Case 21-1998: Rabies\nTo the Editor\n-------------\n\n【1】The death of a 32-year-old American traveler from rabies after a dog bite in Nepal, described in Case 21-1998 (July 9 issue),  is a sobering reminder that fatal encephalitis can occur when postexposure prophylaxis is not used. Dr. Basgoz, the attending physician and case discussant, commented that the patient had “considerable knowledge about the risk of rabies, as well as relatively ready access to medical care,” yet provided no details regarding her failure to receive prophylaxis. In an earlier description of the case, it was reported that despite three attempts to obtain postexposure prophylaxis before returning home, the patient was either unable to obtain it or unsure of its necessity.  Sadly, it appears she did not know that the Western-run Canadian International Water and Energy Consultants Clinic Travel Medicine Center in Katmandu has counseled travelers and administered rabies immune globulin and postexposure rabies vaccine for the past 15 years.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 18:03:35", "endTime": "2024/08/13 18:03:50", "cost": 15.064}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 02:03:50", "grab_time": "2024-08-13 02:03:35"}
{"id": 2234270, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "ade89687-b816-4952-aace-11e6db0c73df", "title": "A New Genetic Basis for Hemoglobin-H Disease", "text": "【0】A New Genetic Basis for Hemoglobin-H Disease\nAbstract\n--------\n\n【1】We studied 11 families with α-thalassemia from the Qatif oasis population of eastern Saudi Arabia to determine the genetic and molecular basis of hemoglobin-H disease, which is being encountered in this area with increasing frequency. The results show that there are two common α-thalassemia haplotypes, a deletion (–α/) determinant and a nondeletion (αα <sup>T </sup> /) determinant, which interact to produce a series of overlapping phenotypes. The most severe, hemoglobin-H disease, results from the homozygous state for the nondeletion determinant — a pattern of inheritance not previously recognized for this condition. Its molecular and genetic properties are thus different from those that produce the condition in Oriental or Mediterranean populations.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:41:13", "endTime": "2024/08/14 15:41:23", "cost": 9.779}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 23:41:23", "grab_time": "2024-08-13 23:41:13"}
{"id": 2234269, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "cedaebdd-319c-476c-ae30-a2335b1ad7be", "title": "In Vivo Biomechanical Measurements of a Football Player's C6 Spine Fracture", "text": "【0】In Vivo Biomechanical Measurements of a Football Player's C6 Spine Fracture\nTo the Editor:\n--------------\n\n【1】### Video\n\n【2】 Football Tackle Resulting in Cervical Spine Fracture \n\n【3】During an investigation of concussion in American football players, we captured in vivo biomechanical data on a cervical spine fracture as it occurred in a male athlete (age, 18 years; height, 189.0 cm; weight, 79.4 kg) who was performing a head-down tackling maneuver. The cornerback's helmet was equipped with the Head Impact Telemetry System (Simbex), a six-accelerometer array that measures the location and magnitude of an impact. The impact magnitude was quantified by measuring peak linear and rotational acceleration of the head with the use of the Gadd Severity Index (GSI) and Head Injury Criteria (HIC).  The GSI and HIC are mathematically weighted measures of head acceleration and the duration of impact, with higher scores representing increased likelihood of injury.\n\n【4】After being transported to the emergency department, the athlete reported having pain in the head, neck, and lower back (severity between 3 and 5 on a scale of 0 through 10, with 0 indicating no pain and 10 indicating most severe pain) and losing consciousness for less than 10 seconds at the time of injury. A computed tomographic (CT) scan of the brain was normal, but a CT scan of the cervical spine revealed a fracture of the left facet of C6 at the inferior articulating process that extended into the laminar junction. There were no other misalignments or injuries. A scan obtained with the use of magnetic resonance imaging showed left-sided joint effusion and muscle edema at C6 and C7, but no other abnormalities were detected. The on-call neurosurgeon confirmed a diagnosis of concussion and a stable left C6 facet fracture with no neurologic sequelae. The athlete was discharged within 48 hours with instructions to wear a hard collar. He was disqualified from any further participation in football, but a CT scan obtained at a 12-week follow-up assessment revealed complete healing, and the patient was cleared to participate in basketball.\n\n【5】Figure 1. Profile of the Impact Resulting in a C6 Fracture.\n\n【6】The linear acceleration data, expressed in _g_ (g-force), were collected over the course of 40 msec.\n\n【7】Examination of video footage  confirmed that the impact occurred at the top right side of the helmet (162 degrees of azimuth and 76 degrees of elevation), producing a peak linear acceleration of 114× _g_ ( _g_ is g-force, or 9.8 m per second squared) and a rotational acceleration of 3318 rad (radians) per second squared. In 16 other athletes for whom we have recorded similar types of impact, the mean values were 98× _g_ and 6548 rad per second squared. However, the impact resulting in cervical fracture produced a GSI score of 812 and an HIC score of 487, both of which are substantially higher than the scores recorded for other athletes in similar circumstances (289.1 and 187.4, respectively). The higher scores for this athlete are probably a result of the longer duration of the impact (approximately 20 msec) . The mechanism of injury is consistent with sports-related spine injuries produced by an axial loading of the neck that results from the combined force of the head impact and the inertial loading from the torso. \n\n【8】Sporting and recreational activities are the second most common cause of cervical spine injury for persons younger than 30 years of age.  These injuries have an average lifetime cost of more than $3 million.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-14 00:18:46", "grab_time": "2024-08-13 23:02:07"}
{"id": 2234268, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "e5ddaa15-aa0e-47d1-891c-81f782361808", "title": "Seven-Year Efficacy of RTS,S/AS01 Malaria Vaccine among Young African Children", "text": "【0】Seven-Year Efficacy of RTS,S/AS01 Malaria Vaccine among Young African Children\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】The candidate malaria vaccine RTS,S/AS01 is being evaluated in order to inform a decision regarding its inclusion in routine vaccination schedules.\n\n【3】Methods\n-------\n\n【4】We conducted 7 years of follow-up in children who had been randomly assigned, at 5 to 17 months of age, to receive three doses of either the RTS,S/AS01 vaccine or a rabies (control) vaccine. The end point was clinical malaria (temperature of ≥37.5°C and infection with _Plasmodium falciparum_ of >2500 parasites per cubic millimeter). In an analysis that was not prespecified, the malaria exposure of each child was estimated with the use of information on the prevalence of malaria among residents within a 1-km radius of the child’s home. Vaccine efficacy was defined as 1 minus the hazard ratio or the incidence-rate ratio, multiplied by 100, in the RTS,S/AS01 group versus the control group.\n\n【5】Results\n-------\n\n【6】Over 7 years of follow-up, we identified 1002 episodes of clinical malaria among 223 children randomly assigned to the RTS,S/AS01 group and 992 episodes among 224 children randomly assigned to the control group. The vaccine efficacy, as assessed by negative binomial regression, was 4.4% (95% confidence interval \\[CI\\], −17.0 to 21.9; P=0.66) in the intention-to-treat analysis and 7.0% (95% CI, −14.5 to 24.6; P=0.52) in the per-protocol analysis. Vaccine efficacy waned over time (P=0.006 for the interaction between vaccination and time), including negative efficacy during the fifth year among children with higher-than-average exposure to malaria parasites (intention-to-treat analysis: −43.5%; 95% CI, −100.3 to −2.8 \\[P=0.03\\]; per-protocol analysis: −56.8%; 95% CI, −118.7 to −12.3 \\[P=0.008\\]).\n\n【7】Conclusions\n-----------\n\n【8】A three-dose vaccination with RTS,S/AS01 was initially protective against clinical malaria, but this result was offset by rebound in later years in areas with higher-than-average exposure to malaria parasites. \n\n【9】Introduction\n------------\n\n【10】 QUICK TAKE  \nMalaria Vaccine in Young African Children  \n\n【11】RTS,S/AS01 is a malaria vaccine candidate that has undergone phase 3 evaluation across several sites in Africa that have varying intensities of malaria transmission. During more than 48 months of follow-up, immunization with the RTS,S/AS01 vaccine was estimated to be associated with rates of protection against clinical malaria of 36.3% (95% confidence interval \\[CI\\], 31.8 to 40.5) among children 5 to 17 months of age who had received a fourth dose and 28.3% (95% CI, 23.3 to 32.9) among those who had not received a fourth dose.  The rates among young infants (6 to 12 weeks of age at the time of first vaccination) with more than 38 months of follow-up were 25.9% (95% CI, 19.9 to 31.5) among those who had received a fourth dose and 18.3% (95% CI, 11.7 to 24.4) among those who had not received a fourth dose.\n\n【12】The efficacy of vaccination with RTS,S/AS01 wanes over time.  The potential for rebound in malaria cases (also referred to as “age shift”) as immunity wanes may lessen the public health usefulness of malaria vaccines. We present data from 7 years of follow-up to assess the possibility of a rebound.\n\n【13】Methods\n-------\n\n【14】Trial Design\n------------\n\n【15】We conducted this trial as part of a double-blind, randomized, controlled, phase 2 trial of the RTS,S/AS01 vaccine in children who were 5 to 17 months of age at the time of the first vaccination and who lived in Kilifi, Kenya, or in Korogwe, Tanzania.  The original two-site trial was initiated in March 2007 and was completed in August 2008 in Korogwe and, after a site-specific extension, in November 2008 in Kilifi. Additional follow-up was then conducted in Kilifi until April 2011 (4-year efficacy results were published in 2013).  A further extension trial was conducted until November 2014, at which time follow-up was discontinued. The data reported here are from the Kilifi site only.\n\n【16】The trial extension was designed by the academic authors, and employees of GlaxoSmithKline Biologicals provided review of the protocol . Until November 1, 2008, the sponsorship, monitoring, and data management were the responsibility of GlaxoSmithKline Biologicals; after that date, these aspects of the trial were the responsibility of the Kenya Medical Research Institute–Wellcome Trust Research Programme. Data were gathered by the academic team, and the analysis was conducted by the first, second, and last authors. The first draft of the manuscript was written by the first author and revised by the last author, with comments from all the authors. Safety reporting to the regulatory authorities was undertaken by GlaxoSmithKline Biologicals.\n\n【17】Participants\n------------\n\n【18】In early 2007, we recruited 447 healthy children who were 5 to 17 months of age. We conducted three extensions: from the end of 12 months of follow-up until November 2008, then until April 2011, and then finally for an additional 3 years. Written informed consent for the extension was obtained from the parents or guardians of all the children with the use of approved consent forms provided in Swahili or Giriama. Nonliterate parents indicated consent by using a thumbprint, and a signature was obtained from an independent literate witness. The original trial and its extensions were approved by the Kenya Medical Research Institute National Ethics Committee, the Western Institutional Review Board, and the Oxford Tropical Research Ethics Committee. This article is published with the permission of the Director of Kenya Medical Research Institute.\n\n【19】Procedures\n----------\n\n【20】In the initial trial, three doses of the RTS,S/AS01 vaccine or rabies (control) vaccine were administered, at baseline and at 1 and 2 months. No vaccines were administered during the extended follow-up phase. Participants were followed up by means of both weekly active surveillance and passive surveillance to identify clinical malaria cases. We obtained blood samples for the assessment of asymptomatic parasitemia at 8, 12, 15, 25, 38, and 49 months (as reported previously  ) and at 65, 78, and 91 months after vaccination. The participants and clinicians who were involved in the follow-up were unaware of the trial-group assignments. The principal investigators became aware of the trial-group assignments after the end of the initial phase of the trial but did not take part in the clinical evaluation of participants.\n\n【21】Malaria-Parasite Exposure\n-------------------------\n\n【22】Malaria transmission shows fine-scale geographic heterogeneity.  We previously found that fine-scale variations in exposure could be predicted by estimation of the prevalence of malaria infection among children who reside within a 1-km radius of each participant as an exposure index. Furthermore, the accuracy of this exposure index is refined by weighting according to the inverse of the distance between homes within the 1-km radius and the index child. Hence, homes that are near to the index child contribute more important information than do those on the edge of the 1-km radius.  In an analysis that was not prespecified, we used data from 870 children who were under active surveillance in the same trial area to determine exposure indexes and categorized the participants into low-exposure and high-exposure groups according to whether they were at or below the cohort mean or above the cohort mean, respectively.\n\n【23】Statistical Analysis\n--------------------\n\n【24】The primary end point was clinical malaria caused by _Plasmodium falciparum_ (temperature of ≥37.5°C and _P. falciparum_ parasitemia density of >2500 parasites per cubic millimeter). The intention-to-treat cohort included all the children who had undergone randomization. The per-protocol cohort included children who received three doses of vaccine according to the trial protocol and for whom surveillance data were available at any time from 2 weeks after receipt of the third dose. We censored data from children at 7 years of follow-up.\n\n【25】We used Cox proportional-hazard regression for analysis of the first malarial episode. Multiple episodes were analyzed by means of negative binomial regression and the Andersen–Gill extension of Cox regression, with clustering by participant. The first-episode analysis was used as the primary analysis after 8 months of follow-up,  but longer-term follow-up showed lower efficacy when all episodes were considered.  Vaccine efficacy was defined as 1 minus the hazard ratio or the incidence-rate ratio multiplied by 100 in the RTS,S/AS01 group versus the control group.\n\n【26】Adjustments were made for age, bed-net use, and malaria exposure. We plotted the incidence-rate ratios over time by first aggregating the data into 4-month groups and then calculating the incidence rates in each trial group; we then divided the incidence in the RTS,S/AS01 group by the incidence in the control group. A quadratic equation was then fitted to these values.\n\n【27】As previously reported,  we calculated the cases averted in each year of follow-up by subtracting the measured incidence per person-year among participants in the RTS,S/AS01 group from the incidence per person-year among participants in the control group and then multiplying by 1000 to express the result as the number of cases averted per 1000 children vaccinated with RTS,S/AS01. We calculated cumulative cases by summing the cases averted up to and including each given year. We used bootstrapping methods to obtain 95% confidence intervals by taking the 2.5th and 97.5th percentiles of 1000 iterations. All the analyses were performed with the use of Stata software, version 13 (StataCorp).\n\n【28】Results\n-------\n\n【29】Trial Participants\n------------------\n\n【30】Figure 1. Randomization and Follow-up of Trial Participants.\n\n【31】We conducted three extensions: from the end of 12 months of follow-up until November 2008, from then until April 2011, and finally for an additional 3 years. Other reasons for withdrawal included children missing vaccinations because of hospital admission (with contraindications to further vaccination), medical conditions not permitted by the protocol , and incomplete documentation regarding concomitant vaccinations.\n\n【32】Of the 447 children enrolled in the original trial, 312 completed all three extensions of follow-up (164 participants in the RTS,S/AS01 group and 148 in the control group) . We included all enrolled children in our analysis (i.e., 447 participants in the intention-to-treat cohort and 415 in the per-protocol cohort). All the participants who underwent randomization received at least one dose of vaccine. The characteristics of the RTS,S/AS01 group and the control group were similar at baseline . Participants who were lost to follow-up were significantly less likely to have bed nets and more likely to live farther away from the dispensary than were other participants. In addition, a nonsignificantly greater number of participants in the control group than in the RTS,S/AS01 group were lost to follow-up, and participants who were lost to follow-up had a nonsignificantly lower incidence of malaria .\n\n【33】Efficacy against First Episode\n------------------------------\n\n【34】Table 1. Vaccine Efficacy.\n\n【35】In the intention-to-treat cohort, there were 150 cases of first episodes of clinical malaria among 223 participants in the RTS,S/AS01 group and 157 cases among 224 participants in the control group. In a Cox regression analysis, after adjustment for person-years of follow-up but no covariates, the vaccine efficacy against the first episode of clinical malaria was 27.0% (95% CI, 8.5 to 41.8; P=0.006) . Consistent results were seen in the per-protocol analysis.\n\n【36】Efficacy against All Episodes\n-----------------------------\n\n【37】In the intention-to-treat cohort, 1002 episodes of malaria occurred in the RTS,S/AS01 group and 992 in the control group. The rate of loss to follow-up was higher in the control group than in the RTS,S/AS01 group, and after the inclusion of person-years of observation in the negative binomial model, the estimate of vaccine efficacy was 4.4% (95% CI, −17.0 to 21.9; P=0.66) . Similar results were seen in the per-protocol analysis.\n\n【38】Table 2. Vaccine Efficacy against All Episodes, According to Malaria-Parasite Exposure and Year of Follow-up.\n\n【39】Efficacy was consistently lower in the cohort with high exposure to malaria parasites than in the cohort with low exposure . Efficacy against all episodes of clinical malaria was 16.6% (95% CI, −24.6 to 44.2) in the low-exposure cohort (P=0.38) and −2.4% (95% CI, −26.1 to 16.8) in the high-exposure cohort (P=0.82).\n\n【40】Waning in Vaccine Efficacy\n--------------------------\n\n【41】Figure 2. Malaria Incidence and Vaccine Efficacy, According to Malaria Exposure and Trial Group in the Intention-to-Treat Cohort.\n\n【42】Panel A shows the incidence of malaria in the cohort with a low exposure index (distance-weighted local prevalence of malaria at or below the cohort mean), and Panel B the incidence in the cohort with a high exposure index (distance-weighted local prevalence of malaria above the cohort mean). The top graphs show the incidence of malaria in the RTS,S/AS01 group and the control group according to year of follow-up. The bottom graphs show the estimates of vaccine efficacy, aggregated in 4-month windows, on the basis of the calculation of 1 minus the incidence-rate ratio times 100, with the incidence-rate ratio calculated as the incidence of malaria in the RTS,S/AS01 group divided by the incidence in the control group. The orange line indicates 0% efficacy, and the blue line indicates smoothed estimates of efficacy over time. The dashed lines indicate 95% confidence intervals, and green dots point estimates of efficacy.\n\n【43】There was a significant interaction between receipt of the RTS,S/AS01 vaccine and follow-up time in the adjusted negative binomial regression model (incidence-rate ratio, 1.07; 95% CI, 1.02 to 1.14; P=0.006) and in the Andersen–Gill extension of the Cox regression analysis (hazard ratio, 1.22; 95% CI, 1.02 to 1.45; P=0.03). These interaction terms indicate that the efficacy of vaccination changed significantly over time. This finding can be quantified further by an examination of efficacy in individual years. In the intention-to-treat analysis, vaccine efficacy declined from 35.9% (95% CI, 8.1 to 55.3; P=0.02) in the first year to 3.6% (95% CI, −29.5 to 28.2; P=0.81) in the seventh year . In year 5, negative efficacy was observed. This finding was of marginal significance overall (−34.4%; 95% CI, −83.9 to 1.8; P=0.06) in the per-protocol analysis, but most of the negative efficacy was seen in the high-exposure cohort. At year 5, negative efficacy was not significant in the low-exposure cohort (−0.8%; 95% CI, −100.7 to 49.3; P=0.98) but was significant in the high-exposure cohort (−56.8%; 95% CI, −118.7 to −12.3, P=0.008).\n\n【44】Waning of vaccine efficacy was more rapid in the cohort with high exposure to malaria parasites than in the cohort with low exposure. A three-way interaction among vaccination, time, and malaria-parasite exposure resulted in an incidence-rate ratio of 1.23 (95% CI, 1.07 to 1.42; P=0.004) in the negative binomial analysis. This three-way interaction indicated significant variation in the rate of decline, with more rapidly declining efficacy observed with increasing exposure index.\n\n【45】Estimated Cases of Malaria Averted\n----------------------------------\n\n【46】Figure 3. Malaria Cases Averted during Follow-up in the Intention-to-Treat Population.\n\n【47】Shown are the cumulative numbers of malaria cases averted, according to year of follow-up and exposure index of the cohort. We calculated cases averted in each year by subtracting the measured incidence per person-year among participants in the RTS,S/AS01 group from the incidence per person-year among participants in the control group and then multiplying by 1000 to express the result as the number of cases averted per 1000 children vaccinated with RTS,S/AS01. We calculated cumulative cases by summing the cases averted up to and including the year under consideration.\n\n【48】In the intention-to-treat analysis, the overall estimated number of clinical malaria cases averted over a period of 7 years was 317 cases (95% CI, −357 to 973) per 1000 children vaccinated with RTS,S/AS01, with wide confidence intervals that overlapped zero. In the low-exposure cohort, cases continued to be averted throughout the follow-up period, to a total of 718 cases (95% CI, 4 to 1404) per 1000 participants in the RTS,S/AS01 group. However, in the high-exposure cohort, there were negative cases averted in later years (i.e., there were more cumulative cases among participants in the RTS,S/AS01 group than among those in the control group), which more than offset the cases that were averted in earlier years, leading to −141 cases (95% CI, −1210 to 906) averted per 1000 participants . The findings regarding averted cases were based on incidence rates rather than absolute numbers of cases per participant and hence were adjusted for person-years at risk .\n\n【49】Cross-Sectional Analysis\n------------------------\n\n【50】The prevalence of asymptomatic _P. falciparum_ parasitemia was lower in the RTS,S/AS01 group than in the control group at all cross-sectional surveys before the fourth year. Thereafter, the prevalences were similar in the two groups .\n\n【51】Safety\n------\n\n【52】There were no significant differences between the RTS,S/AS01 group and the control group in the percentage of children reporting one or more serious adverse events (17.9% \\[95% CI, 13.1 to 23.6\\] and 25.4% \\[95% CI, 19.9 to 31.7\\], respectively) . No cases of meningitis were reported. A total of 15 cases of severe malaria were identified during follow-up: 5 cases in the RTS,S/AS01 group and 10 in the control group. In the control group, all the episodes of severe malaria occurred before 2.7 years of follow-up, whereas in the RTS,S/AS01 group, all the cases of severe malaria were observed after 2.7 years of follow-up . All cases of severe malaria resolved without long-term sequelae.\n\n【53】Discussion\n----------\n\n【54】We found that RTS,S/AS01 provided protective efficacy in the first year after vaccination but that the efficacy subsequently waned. Efficacy was close to zero in the fourth year and may have been negative in the fifth year. The larger phase 3 trial of the RTS,S/AS01 vaccine showed efficacy estimates of 28.3% (95% CI, 23.3 to 32.9) against all malaria episodes over a median of 4 years of follow-up in the group that received three doses of the RTS,S/AS01 vaccine, as compared with the control group.  The data set from the phase 2 trial presented here includes fewer participants than the phase 3 trial did (447 vs. 8923 participants) with a longer duration of follow up (7 years vs. 4 years).\n\n【55】There was a trend toward negative efficacy in the fifth year in the whole cohort, with a significant result in the subgroup of children who had a high malaria-exposure index, as compared with those with a low exposure index . Only 312 of the 447 participants who underwent randomization completed follow-up, which may have introduced a risk of bias. There were indications that participants who were lost to follow-up lived farther from the dispensary and were less likely to have bed nets than participants who completed the trial . Participants who were lost to follow-up were also more likely to be in the control group and to have a lower risk of malaria episodes, but these findings were not significant, which suggests a low risk of bias in the primary analysis.  Furthermore, our analysis was exploratory among the two subgroup cohorts and hence is prone to type I error because of multiple comparisons. However, the negative efficacy during the fifth year fits an overall trend , and the variation in efficacy over time and according to malaria-parasite exposure is supported by a significant interaction between time and exposure in the determination of vaccine efficacy.\n\n【56】The summation of the described variation in efficacy over time since vaccination and according to malaria exposure led to undetectable efficacy over a period of 7 years in the cohort we studied (i.e., the confidence intervals for the estimates of efficacy and numbers of cases averted included zero). We note that the absolute number of malaria cases was in fact slightly higher in the RTS,S/AS01 group than in the control group . The calculated vaccine efficacies and cases averted were marginally (and nonsignificantly) positive after correction for fewer person-years of observation among persons who received the control vaccine than among those who received RTS,S/AS01. The confidence intervals for cases averted are wide in our analysis. This uncertainty reflects the limited sample size in our trial, combined with high frequencies of clinical episodes: any uncertainty in estimates of relative efficacy therefore translates to greater uncertainty in the estimates of absolute numbers of cases averted.\n\n【57】We recorded a clinical malaria rate of 0.76 cases per person-year of observation among participants in the control group who were under conditions of active surveillance. In the phase 3 trial, at the site where the highest transmission was recorded (Siaya in western Kenya), a clinical malaria rate of 3.31 cases per person-year was recorded under conditions of passive surveillance.  Therefore, our “higher-than-average transmission” cohort within the Junju geographic area in Kilifi may be equivalent to a moderate intensity of transmission in the wider African context,  and hence our results may not be generalizable to areas with higher intensities of transmission.\n\n【58】The potential for malaria rebound has been suggested before as a possibility after pre-erythrocytic vaccination  and may also be a concern with regard to insecticide-treated bed nets in the context of insecticide resistance.  Malaria rebound has been observed in randomized trials involving children after the withdrawal of weekly malaria chemoprophylaxis.  In contrast, studies of intermittent preventive treatment with antimalarial agents have not shown a rebound. \n\n【59】Malaria rebound may occur because the RTS,S/AS01 vaccine protects against malaria sporozoites but does not induce clinical immunity against blood-stage parasites. We and others have previously found lower levels of antibodies against blood-stage parasites in children who have been immunized with the RTS,S/AS01 vaccine than in those given the control vaccine.  The reduced exposure to blood-stage parasites among persons who have received the RTS,S/AS01 vaccine may lead to a slower acquisition of immunity to blood-stage parasites, leading to an increase in episodes of clinical malaria in later life. This effect may be less marked in geographic regions where children are only occasionally exposed to parasites, in which immunity is more slowly acquired, and hence we did not see any evidence of rebound in our low-exposure cohort.\n\n【60】A large phase 3 trial of RTS,S/AS01 showed an efficacy estimate of 28% against all malaria episodes over a median of 4 years of follow-up in the group that received three doses of the RTS,S/AS01 vaccine, as compared with the control group.  Efficacy against clinical malaria was higher among children who received a fourth dose than among those who did not (36% vs. 28%).  Extended follow-up is currently being undertaken at three sites from the phase 3 trial and includes some participants who are receiving a fourth dose, which will provide further information on outcomes in year 5 and beyond.\n\n【61】In conclusion, RTS,S/AS01 vaccination showed evidence of 35.9% efficacy in the first year after vaccination, but efficacy fell to 2.5% in the fourth year. The cohort with a high exposure index had a partial rebound in clinical malaria cases during the fifth year. This result eroded the benefits that were seen in early years, such that over a period of 7 years, vaccine efficacy was estimated at 4.4%, a rate that was substantially lower than that seen over short-term follow up.  In areas with a high intensity of malaria-parasite transmission, some of the early gains in averting the malaria burden can be lost in later years owing to a waning in vaccine efficacy. A larger phase 3 trial has been conducted across a range of transmission conditions and with additional vaccine doses. It will be essential to monitor efficacy in longer-term follow-up for year 5 and beyond to accurately measure the benefit and potential risk of vaccination with the RTS,S/AS01 vaccine.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-14 00:23:42", "grab_time": "2024-08-13 23:45:59"}
{"id": 2234267, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "f75b1370-3073-4c40-965c-ea75e8c9955c", "title": "Undernutrition and Child Development", "text": "【0】Undernutrition and Child Development\nAbstract\n--------\n\n【1】### Abstract\n\n【2】When 19 children who had been hospitalized with undernutrition in the first year of life were compared with a control group three to four years later, the test group was found to be lower in height, weight, head circumference and developmental quotient. Impairment of physical and mental development appeared to correlate with the duration of undernutrition in the first year of life. Nine children admitted to the hospital with undernutrition but treated in the first four months of life now have a mean developmental quotient of 95, which is similar to the mean of 99 for the control children. In 10 with undernutrition after four months of age low indexes for height, weight and head circumference were more frequent, and the mean developmental quotient was 70. Social factors associated with undernutrition included paternal separation, alcohol-related problems, inadequate money and many young siblings.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/13 16:01:41", "endTime": "2024/08/13 16:01:46", "cost": 5.073}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 00:01:46", "grab_time": "2024-08-13 00:01:34"}
{"id": 2234266, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "59650e2f-35fc-4464-ab3a-65c46e880cea", "title": "Bipolar Disorder", "text": "【0】Bipolar Disorder\nTo the Editor:\n--------------\n\n【1】Belmaker (July 29 issue)  reviews the syndrome of bipolar disorder. The lifetime prevalence of bipolar disorders among patients in primary care and general medical settings is considerably higher  than the approximately 1 percent consistently reported in the general population.  Patients with bipolar disorder are much more likely to seek help when they are depressed, and a history of manic or hypomanic symptoms can be easily missed. There is a significant risk of psychiatric complications when an antidepressant drug is prescribed without concurrent use of a mood stabilizer, such as lithium, in a patient with bipolar disorder. Therefore, it is important that primary care physicians ask any patients presenting with depression about a possible history of mood elevation and other manic symptoms  and about a possible family history of bipolar disorder. As Dr. Belmaker points out, no clear personality traits specific to patients with bipolar disorder have been identified. However, a higher index of suspicion is probably justified in the case of patients who have symptoms of borderline personality disorder, such as frequent and sudden mood changes, impulsivity, interpersonal instability, and self-injury, because of the coexistence of the two disorders.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:46:53", "endTime": "2024/08/14 14:47:07", "cost": 13.46}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 22:47:07", "grab_time": "2024-08-13 22:46:53"}
{"id": 2234265, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "fc39b020-c47d-46e3-b92f-71f54ed3c370", "title": "Population and the Environment — Time for Another Contraception Revolution", "text": "【0】Population and the Environment — Time for Another Contraception Revolution\n### Audio Interview\n\n【1】 Interview with Dr. Deborah Anderson on the potential for new contraceptive methods to ease problems associated with population growth. \n\n【2】As the world population continues to grow, pressures on the environment will become more critical. The time seems ripe for another contraception revolution to provide options for the diverse populations that are not currently being served by modern contraception.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:45:50", "endTime": "2024/08/14 15:46:04", "cost": 14.7}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 23:46:05", "grab_time": "2024-08-13 23:45:03"}
{"id": 2234264, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "0bc3eb91-a52b-4c10-b181-aa46aa335cdd", "title": "Asthma in Pregnancy", "text": "【0】Asthma in Pregnancy\nA 23-year-old nonsmoking woman (gravida 1, para 0) presents at 11 weeks' gestation with an 8-year history of asthma, which has worsened over the past year. She reports symptoms requiring albuterol two or three times per day and interfering with sleep. Her forced expiratory volume in 1 second is 75% of the predicted value; it increases to 88% after administration of albuterol. How should her case be managed?", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:04:38", "endTime": "2024/08/14 15:04:51", "cost": 13.956}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 23:04:52", "grab_time": "2024-08-13 23:04:37"}
{"id": 2234263, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "c1c14b0f-4a9b-439a-a87b-a35625f2b35c", "title": "Lack of Effect of Coumarin in Women with Lymphedema after Treatment for Breast Cancer", "text": "【0】Lack of Effect of Coumarin in Women with Lymphedema after Treatment for Breast Cancer\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Lymphedema of the arms can be a serious consequence of local and regional therapy in women with breast cancer. Coumarin has been reported to be effective for the treatment of women with lymphedema; we undertook a study in which we attempted to replicate those findings.\n\n【3】Methods\n-------\n\n【4】We studied 140 women with chronic lymphedema of the ipsilateral arm after treatment for breast cancer. The women received 200 mg of oral coumarin or placebo twice daily for six months and then the other treatment for the following six months. The end points of the study consisted of the volume of the arm (calculated from measurements of hand and arm circumference) and the answers on a questionnaire completed by the patient about symptoms potentially related to lymphedema.\n\n【5】Results\n-------\n\n【6】The volumes of the arms at 6 and 12 months were virtually identical, regardless of whether coumarin or placebo was given first. After six months, the average volume of the affected arm increased by 21 ml during placebo treatment and 58 ml during coumarin treatment (P=0.80). In addition, answers on the patients' questionnaires were similar in the two treatment groups. After six months, only 15 percent of the women in the coumarin group and 10 percent of those in the placebo group reported that the study medication had helped a moderate or large amount (P=0.19). Coumarin was well tolerated, except that it resulted in serologic evidence of liver toxicity in 6 percent of the women.\n\n【7】Conclusions\n-----------\n\n【8】Coumarin is not effective therapy for women who have lymphedema of the arm after treatment for breast cancer.\n\n【9】Introduction\n------------\n\n【10】Lymphedema is an important long-term complication of local and regional therapy in women with breast cancer. It can result in cosmetic deformity, loss of functional ability, physical discomfort, and recurrent episodes of cellulitis and lymphangitis. It is more common in women who are obese  and in women over the age of 60 years, presumably because of the loss of connections between lymph vessels and veins.  Physical therapy can be effective in reducing the lymphedema but requires special training that is not widely available. \n\n【11】Coumarin (5,6-benzo-\\[α\\]-pyrone, or 1,2-benzopyrone) and related drugs have been reported to reduce lymphedema,  possibly through stimulation of proteolysis by tissue macrophages. In addition to findings that it decreases the pain and discomfort caused by lymphedema, coumarin has been reported to reduce the incidence of cellulitis or lymphangitis and to soften slowly the brawny edema that is often found in conjunction with lymphedema. In 1993, Casley-Smith et al. reported in the _Journal_ the results of a double-blind, crossover trial of coumarin in 31 women with postmastectomy lymphedema and 21 men and women with lymphedema of the leg of various causes.  Coumarin was reported to be more effective than placebo in reducing the volume of edema fluid in the arm, in reducing skin temperature, and in increasing the softness of the limb tissue. We undertook the current study in an attempt to confirm these results in women who had lymphedema after treatment for breast cancer.\n\n【12】Methods\n-------\n\n【13】Subjects\n--------\n\n【14】The subjects of the study were 140 women 33 to 84 years old with unilateral lymphedema of the arm attributed to earlier local or regional treatment of breast cancer (surgery or radiation therapy). In each case, both the woman and her physician had determined that the lymphedema was sufficiently severe to warrant treatment. The lymphedema had to have been present for at least one year and was not immediately reversible by elevation or compression of the arm. All the women were ambulatory. Women were not eligible for the study if they had taken coumarin previously, were currently undergoing radiation therapy or chemotherapy (with the exception of tamoxifen given as an adjuvant to local or regional treatment), had changed their regimen of physical therapy for lymphedema during the preceding month, or had an indwelling venous device; if they had an infection of either arm, had evidence of residual active cancer, had a life expectancy of less than 2 years, or had bilateral edema of the arms; if they were pregnant or nursing; or if they had a history of hepatitis or evidence of liver dysfunction (i.e., serum aminotransferase or conjugated bilirubin concentrations >50 percent above the upper limit of normal), a history of alcohol abuse, or a history of venous thrombosis in the preceding 12 months.\n\n【15】At the time of enrollment, a complete history was obtained from each woman, and a physical examination and liver-function tests were performed. In addition, the women completed a questionnaire designed to assess swelling, pressure, tightness, heaviness, and loss of mobility of the arms, which they graded from 0 to 3 according to the following scale: 0, none; 1, mild; 2, moderate; and 3, severe. These questionnaires also inquired about any infection in the affected arm. Measurements were taken of the circumference of each hand just distal to the thumb, of each wrist at its narrowest point, and of each arm 30, 40, and 50 cm proximal to the tip of the middle finger, as far as possible before the axilla was reached. The volume of each arm was calculated from these measurements as described by Casley-Smith  and according to the formula for the volume of a cylinder. The women were also given written instructions that provided details about the planned study procedures and educational information about lymphedema. The study was approved by the appropriate institutional review committees, and all the women gave written informed consent.\n\n【16】Study Design\n------------\n\n【17】The women were stratified according to six characteristics (age, therapy for breast cancer, history of cellulitis in the involved arm, duration of lymphedema, time since surgery or radiation therapy, and tamoxifen therapy) and then randomly assigned to receive coumarin (two 100-mg tablets twice daily) or placebo (two identical lactose tablets twice daily) for six months, followed by the other treatment for six months. The coumarin and placebo tablets were provided by Drossapharm Pharmaceuticals (Basel, Switzerland).\n\n【18】The women were examined monthly, and on each occasion they were asked to complete questionnaires that included the items on the prestudy questionnaire as well as questions about whether they thought that the study medication was helpful, how often they took the study medication, and whether they had nausea, vomiting, diarrhea, or other symptoms that might be related to the medication. At the end of each six-month treatment period, the circumference of the hands and arms was measured in the same way as before the study.\n\n【19】Initially, we planned to measure serum aminotransferase concentrations at the end of each treatment period. However, as we have reported previously,  two women had abnormal values three or four months after treatment started (the measurement was performed in one woman in whom jaundice developed and in another at the discretion of the attending physician). We therefore measured serum aminotransferase concentrations in the other women after three to four months of the initial treatment and then one and three months after crossover to the opposite treatment. Treatment was stopped if serum aminotransferase concentrations were two or more times the upper limit of normal.\n\n【20】The efficacy of treatment was judged according to changes in arm volume, which was calculated from measurements of circumference by the method of Casley-Smith,  and according to the women's answers on the questionnaires.\n\n【21】Statistical Analysis\n--------------------\n\n【22】At the end of each treatment period, Student's t-tests and Wilcoxon's rank-sum tests were used to compare the average circumference of the affected arm at each measurement site, after normality had been established or refuted by Shapiro–Wilk testing.  The average ratio of the circumference of the affected arm to that of the normal arm was compared in the same way at each site. The arm-circumference measurements were then combined into volumetric data for each arm at each time point according to the method of Casley-Smith  and by application of the formula for the volume of a cylinder.\n\n【23】We evaluated the volumetric data using the geometric relations for arm measurements and the SAS Data Step Graphics Interface program.  According to this method, the circumference measured at each site was used to construct ellipses with the geometric formula relating the circumference of an ellipse to its area. A second equation was formed by relating the relative length of the major and minor axes of each ellipse. The two equations, each with two unknown variables, were then solved to obtain the equation for an ellipse that represented the shape of the arm at each site. These ellipses were then joined by straight lines of the appropriate lengths, and a representation of the curvature of the hand was constructed with an additional ellipse. For each woman, the representation of the normal arm was then overlaid with the representation of the affected arm. Simulations demonstrated that the resulting image accurately reflected changes in arm volume.\n\n【24】The incidence scores for responses to the questionnaires were compared between the groups at the end of each treatment period by simple tests for the equality of binomial proportions. Ordinal responses were analyzed by standard Wilcoxon's rank-sum tests. All the statistical tests were two-sided.\n\n【25】Results\n-------\n\n【26】Of the 140 women enrolled in the study, 1 was found to be ineligible (she had a history of hepatitis) and 1 withdrew from the study (she never took any study medication after randomization). For analyses of toxicity, data from all 139 women who took any study medication (including the ineligible woman) were included. For the evaluation of efficacy, data were obtained on 130 of the 138 remaining women (94 percent) at 6 months and 113 (82 percent) at 12 months. Six women discontinued treatment before the evaluation at 6 months, and 12 more stopped before the 12-month evaluation. One woman was reportedly murdered after her six-month evaluation. Arm-volume data were not obtained in several additional cases in which women did not return for arm measurements; data were available for 120 at 6 months and 93 at 12 months.\n\n【27】Table 1. Base-Line Characteristics of Women with Breast Cancer and Lymphedema According to Stratification Factors.\n\n【28】The characteristics of the women in the two study groups were similar , as were their answers to questions on the base-line questionnaire about arm pressure, tightness, heaviness, swelling, and loss of mobility.\n\n【29】Figure 1. Mean Volumes of the Arms in the Women Receiving Coumarin and Placebo in a 12-Month Crossover Study.\n\n【30】The affected arm (dashed line) and normal arm (solid line) are shown; circles represent sites at which the circumference was measured. The sizes of the involved arms and of the contralateral control arms remained remarkably similar despite treatment.\n\n【31】Results of a crossover analysis demonstrated that there was no evidence of a carryover effect, and therefore results for each treatment were combined. After the administration of coumarin or placebo for six months, there were no significant differences from base line in total or distal edema; volume of the affected arm; ratio of the volume of the affected arm to that of the normal arm; or circumference of the hand, wrist, or arm at points 30, 40, and 50 cm from the tip of the middle finger. The average volume of the affected arm increased by 21 ml with placebo and 58 ml with coumarin. The volumes of both the affected and the normal arms were similar in the two groups at all times . Our assessment of the influence of evaluation on the results included analyses of the effects of variability between patients, treatment period, treatment sequence, base-line scores, severity of lymphedema, duration of lymphedema, age, handedness, use of tamoxifen, and history of cellulitis. Regardless of the covariates included in the analysis, coumarin had no effect that differed from that of placebo on any of the end points related to efficacy.\n\n【32】Figure 2. Grading of Arm Symptoms on Questionnaires by Women in the Two Treatment Groups.\n\n【33】Arm symptoms assessed by the women were swelling, pressure, tightness, heaviness, and loss of mobility. Symptoms were graded according to the following scale: 0, none; 1, mild; 2, moderate; and 3, severe.\n\n【34】Analysis of the data provided by the monthly questionnaires also supported this finding. The women's responses to questions about arm swelling, pressure, tightness, heaviness, and loss of mobility were similar for coumarin and placebo during both periods and demonstrated some positive changes with time but no differential effects associated with treatment . The frequency of infections of the arm was similar during the coumarin and placebo periods.\n\n【35】Table 2. Benefit Perceived by the Women while Receiving Coumarin or Placebo.\n\n【36】After each six-month period the women were asked whether they thought that the study medication was helping them. Their responses did not suggest that coumarin had benefit during either period . After 12 months the women were asked which of the two treatment periods (the first or the second) they preferred. Of the 87 women who answered this question, 51 percent did not prefer one period over the other, 24 percent preferred the coumarin period, and 25 percent preferred the placebo period.\n\n【37】The results of the monthly questionnaires with respect to compliance revealed that 88 percent of the women took at least 90 percent of their study medication during the first six months, and 81 percent did so during the second six months. There were no differences between treatments in compliance.\n\n【38】With regard to side effects, the information obtained from the questionnaires and by history taking at 6 and 12 months did not suggest any differences in the incidence of nausea, vomiting, or diarrhea between coumarin treatment and placebo. However, as we have previously reported,  the incidence of hepatotoxic effects was substantially higher with coumarin than with placebo. In none of the women did serum aminotransferase concentrations reach 2.5 times the upper limit of normal during the placebo period, whereas in nine women (6 percent) the concentrations became high during treatment with coumarin (P=0.006). The most prominent instance of hepatotoxicity occurred in a woman in whom jaundice developed and the serum bilirubin concentration rose to 19.3 mg per deciliter (330 μmol per liter) while she was receiving coumarin. In these nine women the test results became normal after coumarin treatment was stopped (treatment was stopped when the elevated values were recorded).\n\n【39】Discussion\n----------\n\n【40】In our study we found that coumarin did not alleviate lymphedema and that coumarin-related hepatotoxic effects were more common than has been previously reported. We designed our protocol to duplicate that of a study by Casley-Smith et al., who reported that coumarin alleviated lymphedema.  We are unable to explain the difference between the results of the two studies. The previous trial involved 31 women with lymphedema of an arm, whereas we studied 140 women. All the women had lymphedema after treatment for breast cancer, and review of the base-line characteristics of the women in the two studies suggests that they were similar. The circumferences of the arms were measured similarly in both studies.\n\n【41】Previous studies suggested that coumarin caused hepatotoxic effects in fewer than 1 percent of patients, and indeed it was claimed that hepatotoxicity was not clearly associated with this drug.  Thus, our finding of hepatotoxic effects in 6 percent of the women in our study was unexpected. We were unable to identify any predisposing factors, such as therapy with tamoxifen or high body weight. During our trial, the deaths of patients receiving coumarin in other countries led to the removal of the drug from the market in at least two countries.\n\n【42】In conclusion, we found that coumarin was ineffective for ameliorating lymphedema of the arm in women who had undergone local or regional therapy for breast cancer.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-14 00:22:02", "grab_time": "2024-08-13 23:27:41"}
{"id": 2234262, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "fb9efabb-8715-4496-ba03-970efb195691", "title": "Protecting Research Subjects — The Crisis at Johns Hopkins", "text": "【0】Protecting Research Subjects — The Crisis at Johns Hopkins\nIn June 2001, Ellen Roche, a healthy young technician at the Johns Hopkins Asthma and Allergy Center, died during an asthma study. The tragedy prompted several intensive investigations of research oversight at Johns Hopkins and led to the temporary suspension of all federally funded research projects at the institution. In this Health Policy Report, Steinbrook provides a detailed discussion of the outcome of the investigations, the response from Johns Hopkins, and the wider lessons for all involved in clinical investigation.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:40:20", "endTime": "2024/08/14 14:40:41", "cost": 20.926}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 22:40:41", "grab_time": "2024-08-13 22:40:19"}
{"id": 2234261, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "824a11e9-af76-4ff3-809f-e004e2136c78", "title": "Effects of a Circulating Factor in Patients with Essential Hypertension on Intracellular Free Calcium in Normal Platelets", "text": "【0】Effects of a Circulating Factor in Patients with Essential Hypertension on Intracellular Free Calcium in Normal Platelets\nAbstract\n--------\n\n【1】Intracellular free (cytosolic) calcium has been reported to be increased in the platelets of patients with essential hypertension. We investigated the possibility that the high cytosolic calcium concentration may be caused by a circulating plasma factor, by incubating platelets from normotensive subjects with plasma ultrafiltrates from patients with essential hypertension. The cytosolic calcium concentration in normal platelets increased after incubation with plasma from patients with untreated hypertension (80±15 percent \\[±SEM\\]) or from patients in whom hypertension was well controlled by calcium-influx blockers (129±33 percent). In contrast, the cytosolic calcium concentration was unchanged after incubation with plasma from normotensive subjects. When platelets from the patients were incubated with plasma from the controls, cytosolic calcium in platelets decreased by more than 30 percent, into the normal range (P<0.01).\n\n【2】These data demonstrate that plasma from patients with essential hypertension contains a substance that increases the cytosolic calcium concentration in platelets. Cytosolic calcium is a trigger for vascular smooth-muscle-cell contraction, and if the plasma factor acts on these cells as it acts on platelets, it may be responsible for the increased peripheral vascular resistance associated with hypertension.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:48:21", "endTime": "2024/08/14 14:48:38", "cost": 16.419}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:27", "update_time": "2024-08-13 22:48:38", "grab_time": "2024-08-13 22:48:14"}
{"id": 2234260, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "2e8caf08-c829-43dd-9261-ae221e52811a", "title": "#WhiteCoatsForBlackLives — Addressing Physicians’ Complicity in Criminalizing Communities", "text": "【0】#WhiteCoatsForBlackLives — Addressing Physicians’ Complicity in Criminalizing Communities\nArticle\n-------\n\n【1】As uprisings continue around the United States in response to police violence against Black people, we have reached a moment of reckoning for many Americans. As a nation, we are struggling to find a way forward. Many organizations have issued statements of solidarity and made promises of support, as first steps. Individual clinicians and physicians’ organizations have joined the efforts, speaking out against police violence and naming racism as a public health issue or crisis. Organizations including the American Academy of Pediatrics, the American Medical Association, and the American College of Physicians have issued statements denouncing police brutality, condemning violence against protestors, and calling for inquiries into cases of police violence against Black people.\n\n【2】This is new territory for most medical organizations, which have traditionally been conservative, are often self-described as nonpartisan, and have historically shied away from public advocacy efforts focused on social justice. The medical profession has long prided itself on its espoused values of objectivity and impartiality. But as a Black woman and a physician, I know these portrayals have never been accurate. In fact, all of medicine, including my chosen field of obstetrics and gynecology, has deeply racist and exploitative roots. The notion that medical providers are unbiased and objective, practicing within a profession free from the legacies of racism, genocide, and White supremacy, is fictitious.\n\n【3】This ahistorical view has caused tremendous harm. In addition to preventing us from identifying and exposing racist beliefs and inherent bias in medical systems, it has allowed us to continue to quietly funnel our patients and their families into the criminal legal system that our statements of solidarity purport to combat. It is not simply interactions between Black people and law enforcement outside the hospital that put our patients at risk, it is also the criminalization of patients within the health care system. This criminalization can be particularly harmful in the context of pregnancy, childbearing, and reproductive health.\n\n【4】Legislative and policy concerns regarding substance use during pregnancy have been debated since the 1980s. State policies mandating the reporting of mothers who use drugs and alcohol during pregnancy became increasingly racialized in the 1990s, during the “crack” cocaine epidemic. Black mothers were particularly targeted with punitive action for substance use during pregnancy. Their children were villainized as “superpredators,” and despite the lack of medical evidence to support the “crack baby syndrome,” they were written off as criminals destined to fail. As Black women became the face of substance use during pregnancy, calls for a carceral response were amplified, and families and communities were torn apart.\n\n【5】The racialized misrepresentation of substance use in pregnancy has continued to have far-reaching negative effects. Black and Indigenous women seeking pregnancy care are more likely to be screened for illicit substance use.  Such testing — often undisclosed and performed without explicit consent — has resulted in parents losing their children or being incarcerated. Even policies implementing universal testing as a solution do not eliminate bias in reporting or address underlying racism. Despite similar rates of substance use during pregnancy by Black and White women, racial disparities exist at all levels, including initiation of testing, referral to drug treatment programs, and reporting to child protective services (CPS). Health care providers are often the first point of contact between families and the criminal legal system, creating an avenue for entry into a system of state surveillance.\n\n【6】The overarching justification for reporting someone to CPS for investigation is linked to mandatory state reporting policies. Most mandated reporters, such as physicians, have been taught that the child welfare system is an unbiased legal system that ensures children’s safety and well-being. In reality, indications for reporting, reasons for removal of children, and subsequent monitoring and surveillance are racially biased, subjective, and paternalistic. Black families are more likely to be reported and investigated for child abuse and neglect, to have their cases substantiated, and to have their children removed from their custody or care.  Moreover, many clinicians are disconnected from the consequences for families after referral to CPS. Once in foster care, Black children remain in custody longer than White children and generally receive inferior services. \n\n【7】Visits to an obstetrician-gynecologist to seek pregnancy care or for delivery can be entry points into the criminal legal system for parents and into state custody for children. These referrals occur in myriad ways: clinicians call CPS when a patient refuses to consent to a medical procedure during prenatal care or childbirth, when the patient herself is in foster care, when the patient has a child who has prior foster-system involvement, when the patient is incarcerated, or when the patient has a disability. Such referrals increase the likelihood that children will be taken from families at the time of delivery, and they become a pathway for increased state surveillance. Social workers, state agents, and the police are given access to these families’ homes, relationships, and lives. Families are subject to investigation, interrogation, separation, and punishment for many years after a report is made.\n\n【8】Criminalization may also occur when a pregnancy doesn’t end in a live birth. For someone having a miscarriage or fetal loss, seeking emergency care can result in bedside interrogations, arrest, and jail time. Whether out of malice or simply ignorance of reporting requirements, clinicians have caused substantial harm to patients by calling law enforcement after the loss of a pregnancy because they suspect the miscarriage was intentionally induced. Women of color, those with low incomes, young people, and immigrants are disproportionately criminalized under these circumstances. The legal network If/When/How: Lawyering for Reproductive Justice has identified more than 19 states that have conducted criminal investigations of people suspected of ending their own pregnancy or helping someone else to do so. Most of these investigations were initiated by health care providers after someone sought care. The investigations cause far-reaching harm whether or not they lead to incarceration. Arrest records and even misdemeanor charges can result in job loss and stigma, even if no formal charge is filed. These charges can be difficult or impossible to remove from state records.\n\n【9】Even when people attempt to induce their own abortion or seek medical care afterward, physicians have an ethical and legal responsibility to safeguard our patients’ health information.  Instead of sending someone to jail or exposing them to humiliating interrogations, we are obliged to ensure that however they decide to end a pregnancy, they can do so safely, effectively, and with dignity and respect. Punitive approaches deter people from seeking health care, have discriminatory effects on marginalized people, and effectively criminalize pregnancy for certain communities.\n\n【10】Medical professionals and the care we provide are not uniquely beyond the reach of racism. Nor are Ob/Gyns the only clinicians putting our patients at risk for criminalization. From undocumented immigrants being deported after seeking care for themselves or their children to Black men being disproportionately criminalized and incarcerated for nondisclosure of their HIV status, medical providers often participate in or orchestrate these efforts. So after we have put away our #WhiteCoatsForBlackLives signs, we should not simply return to participating in systems grounded in the same racist practices and polices we seek to change in law enforcement.\n\n【11】As we continue to object to police violence against Black communities and work with our institutions to issue statements supporting Black lives, we should also interrogate our own active and passive complicity. We should seek ways to reduce our collusion with the carceral system. This effort includes using the goals and techniques of harm reduction for patients with substance use disorder, including advocating for eliminating universal or mandated drug testing in pregnant and postpartum people. It means supporting primary prevention of substance use disorder, improved access to treatment, and family unification, which improves outcomes for families.\n\n【12】The effort should include opposing policies that criminalize patients for seeking health care, including reporting suspicion of self-managed abortion, pregnancy loss, and substance use during pregnancy. And we should educate ourselves, our colleagues, and trainees about the harms of mandatory reporting, its racist history, and its uneven and discriminatory implementation. \n\n【13】As more Americans call for the destruction or reformation of the criminal legal system, we should voice full-throated objections to policies and practices that increase the likelihood of entry into the carceral system through health care institutions. As physicians, we have a critical role to play in this movement.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:44:01", "endTime": "2024/08/14 14:46:14", "cost": 132.707}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:26", "update_time": "2024-08-13 22:46:14", "grab_time": "2024-08-13 22:44:01"}
{"id": 2234259, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "e543a6ce-4c4f-46d5-a12a-c8ac730d2588", "title": "Effect of Artesunate–Amodiaquine on Mortality Related to Ebola Virus Disease", "text": "【0】Effect of Artesunate–Amodiaquine on Mortality Related to Ebola Virus Disease\nAbstract\n--------\n\n【1】Background\n----------\n\n【2】Malaria treatment is recommended for patients with suspected Ebola virus disease (EVD) in West Africa, whether systematically or based on confirmed malaria diagnosis. At the Ebola treatment center in Foya, Lofa County, Liberia, the supply of artemether–lumefantrine, a first-line antimalarial combination drug, ran out for a 12-day period in August 2014. During this time, patients received the combination drug artesunate–amodiaquine; amodiaquine is a compound with anti–Ebola virus activity in vitro. No other obvious change in the care of patients occurred during this period.\n\n【3】Methods\n-------\n\n【4】We fit unadjusted and adjusted regression models to standardized patient-level data to estimate the risk ratio for death among patients with confirmed EVD who were prescribed artesunate–amodiaquine (artesunate–amodiaquine group), as compared with those who were prescribed artemether–lumefantrine (artemether–lumefantrine group) and those who were not prescribed any antimalarial drug (no-antimalarial group).\n\n【5】Results\n-------\n\n【6】Between June 5 and October 24, 2014, a total of 382 patients with confirmed EVD were admitted to the Ebola treatment center in Foya. At admission, 194 patients were prescribed artemether–lumefantrine and 71 were prescribed artesunate–amodiaquine. The characteristics of the patients in the artesunate–amodiaquine group were similar to those in the artemether–lumefantrine group and those in the no-antimalarial group. A total of 125 of the 194 patients in the artemether–lumefantrine group (64.4%) died, as compared with 36 of the 71 patients in the artesunate–amodiaquine group (50.7%). In adjusted analyses, the artesunate–amodiaquine group had a 31% lower risk of death than the artemether–lumefantrine group (risk ratio, 0.69; 95% confidence interval, 0.54 to 0.89), with a stronger effect observed among patients without malaria.\n\n【7】Conclusions\n-----------\n\n【8】Patients who were prescribed artesunate–amodiaquine had a lower risk of death from EVD than did patients who were prescribed artemether–lumefantrine. However, our analyses cannot exclude the possibility that artemether–lumefantrine is associated with an increased risk of death or that the use of artesunate–amodiaquine was associated with unmeasured patient characteristics that directly altered the risk of death.\n\n【9】Introduction\n------------\n\n【10】The outbreak of Ebola virus disease (EVD) in West Africa has led to more than 28,000 cases and has claimed more than 11,000 lives since the outbreak was first declared in March 2014, with most of the burden of disease observed in Guinea, Sierra Leone, and Liberia.  Few treatment practices or therapeutics are known to significantly reduce the risk of death. Recent in vitro assessments of drugs that have been approved by the U.S. Food and Drug Administration for anti-EVD activity have identified a number of candidates among compounds that are used to treat other diseases, including malaria.  However, little to no evidence exists on the clinical efficacy of any of these compounds against EVD.\n\n【11】Guidelines for the management of EVD recommend treatment for malaria in patients with suspected EVD, either for those patients in whom malaria has been confirmed by a positive laboratory or rapid diagnostic test or for all patients with suspected EVD regardless of malaria diagnosis.  The latter option (systematic treatment regardless of malaria confirmation) is often preferred in settings with a high malaria burden because of the prophylactic effect of malaria drugs, even in the absence of current infection. Some guidelines recommend an artemisinin-based combination of artemether and lumefantrine as the first choice of therapy because of concerns about potential liver-related toxic effects of amodiaquine in the primary alternative combination, artesunate–amodiaquine. \n\n【12】Figure 1. Patients Admitted to the Ebola Treatment Center in Foya, Liberia, June 5 to October 24, 2014.\n\n【13】The number of new cases admitted per day to the Ebola treatment center in Foya, Lofa County, Liberia, are shown, according to Ebola virus disease (EVD) status (confirmed EVD, probable EVD, or no EVD). The gray-shaded region represents the period during which artemether–lumefantrine was out of stock and artesunate–amodiaquine was the only antimalarial drug prescribed to patients.\n\n【14】In August 2014, the Ebola treatment center in Foya, Lofa County, Liberia, which was supported by Médecins sans Frontières, ran out of its supply of artemether–lumefantrine after a sudden spike in admissions to the center . During a 12-day period, artesunate–amodiaquine was supposed to be prescribed systematically for all patients with suspected EVD who were admitted to the Ebola treatment center, with no other known systematic changes in care. Although this situation was unplanned, it provided the conditions to explore the possible differential effects of these two antimalarial therapies on survival among patients with confirmed EVD. Our interest in making these comparisons was driven by in vitro results that showed the efficacy of amodiaquine in inhibiting Ebola virus activity.  In the current study, we estimated the effectiveness of artesunate–amodiaquine, as compared with artemether–lumefantrine or no antimalarial treatment, in reducing mortality among patients with confirmed EVD who were admitted to the Ebola treatment center in Foya.\n\n【15】Methods\n-------\n\n【16】Study Setting\n-------------\n\n【17】The first cases of EVD in Lofa County were reported in March 2014. The Ebola treatment center in Foya, which was initially a 10-bed isolation unit in a former refugee transit center, had no additional confirmed cases until a subsequent wave started in early June 2014. Bed and staff capacity increased as the number of patients increased; the bed capacity reached 100 beds in August 2014, at which time more than 100 new confirmed cases were being admitted each week.\n\n【18】According to protocol, all patients with suspected EVD who were admitted to the Ebola treatment center were supposed to be prescribed standard treatment consisting of prophylactic antibiotics and a 3-day course of the antimalarial combination therapy artemether–lumefantrine, with the dose determined according to the age of the patient.  Prepackaged standard treatment was supposed to be provided to each patient on admission and included a full course of antibiotics and antimalarial drugs. In addition, supportive treatment, including fluid replacement, was given according to the needs of the patients, although fluids were often provided only orally during the peak of the epidemic . However, on August 19, 2014, the supply of artemether–lumefantrine ran out, and during the subsequent 12-day “stock-out” period, patients who would have normally been prescribed artemether–lumefantrine were prescribed a 3-day course of another artemisinin-based combination, coformulated artesunate–amodiaquine, with the dose determined according to the age of the patient. No other systematic changes in patient care occurred during this period.\n\n【19】Clinical Data\n-------------\n\n【20】On admission, a venous blood sample was obtained from each patient for laboratory testing, including confirmation of EVD and malaria. The confirmation of EVD was based on the results of a reverse-transcriptase–polymerase-chain-reaction (RT-PCR) assay (RealStar Filovirus Screen RT-PCR Kit 1.0, Altona Diagnostics). Patients with positive results on RT-PCR were considered to have confirmed EVD, and those with negative RT-PCR results after at least 72 hours from the onset of symptoms were considered to be negative for EVD. Patients classified as negative for EVD and those without available RT-PCR results were excluded from this analysis. Malaria was confirmed according to the results of a rapid antigen-detection test that detects the four primary species causing human malaria (BinaxNOW Malaria, Alere).\n\n【21】The laboratory confirmation of EVD and malaria was performed by the European Mobile Laboratory Consortium. Whole venous blood samples were shipped in accordance with the World Health Organization criteria for shipping and handling infectious substances  to Guéckédou, Guinea, the closest available laboratory, for laboratory confirmation during most of the study period, until September 12, 2014, when on-site laboratory services became available.\n\n【22】Epidemiologic Surveillance\n--------------------------\n\n【23】The current analyses are based on individual patient-level data that were compiled by a staff epidemiologist from case-investigation forms, clinical files, and laboratory results from June 5 through October 24, 2014, for patients at the Ebola treatment center. Case-investigation forms were used by trained staff at the Ebola treatment center to record patient characteristics, including demographic and epidemiologic information, time of onset of symptoms, and clinical signs and symptoms at admission. Clinical files, which were kept in a low-risk zone of the center, were used to record each patient’s prescribed treatments, with no indication of whether the drug was provided to and taken by the patient.\n\n【24】We used standard case definitions for suspected, probable, and confirmed cases of EVD that were established by the World Health Organization and Liberian Ministry of Health.  The time to admission was defined as the number of days between the onset of symptoms and admission to the Ebola treatment center. Viral load was expressed as a cycle-threshold value (i.e., the number of RT-PCR cycles needed to detect Ebola virus RNA). The total number of inpatients with suspected, probable, or confirmed EVD who were receiving care at the Ebola treatment center at the time a patient was admitted was used as a measure of workload at the facility.\n\n【25】Study Oversight\n---------------\n\n【26】These analyses, which were performed in collaboration with the Liberian Ministry of Health, were based on retrospectively collected data without patient identifiers and were exempt from review by the ethical review board of the Médecins sans Frontières. All the authors vouch for the completeness and accuracy of the analyses presented.\n\n【27】Statistical Analysis\n--------------------\n\n【28】The distribution of key potential confounders in the relationship between antimalarial treatment and Ebola mortality was compared with the use of summary statistics, such as the mean or median for continuous variables and proportions for binary or categorical variables. To test for significant differences in distributions of the variables among the groups categorized by antimalarial prescription status, we used the Kruskal–Wallis test for continuous covariates and the chi-square or Fisher’s exact test for categorical variables.  Two-sided P values less than 0.05 were considered to indicate statistical significance for all statistical tests. To explore the effect of malaria treatment on EVD-related mortality, we used Poisson regression models with robust error variance.  In adjusted analyses, we included risk factors for death from EVD that had been identified in previous studies or by an expert in the field  and compared their effects using alternative models according to Akaike’s information criterion.  All adjusted analyses included only patients with complete data on the variables of interest, including clinical outcome, malaria treatment prescribed (including no prescription), and potential confounders. We also considered alternative models with different covariates and covering different time windows during the study period. The main analyses were performed with the use of the R statistical package (the R Foundation for Statistical Computing) and STATA statistical software, version 12 (StataCorp); source code for the main analyses is available on request.\n\n【29】Results\n-------\n\n【30】Patients\n--------\n\n【31】A total of 382 patients with confirmed EVD were admitted to the Ebola treatment center in Foya from June 5 through October 24, 2014; of these patients, 381 were included in our analysis and 1 patient was excluded because of missing outcome data. We categorized the patients according to their antimalarial drug prescription status into one of four groups: a group that included 194 of 288 patients (67.4%) with confirmed EVD who were hospitalized between June 6 and August 18, 2014, and after August 30, 2014, and who received artemether–lumefantrine as part of the recommended treatment for patients with suspected EVD  (artemether–lumefantrine group) ; a group that included 71 of 93 patients (76.3%) who received artesunate–amodiaquine from August 19 through 30, 2014, when artemether–lumefantrine was not available in the facility (artesunate–amodiaquine group); a group that included 63 of the 381 patients (16.5%) with confirmed EVD who did not receive antimalarial therapy, possibly because they tested negative for malaria or because of rationing of artemether–lumefantrine during the period of limited supply just before the stock ran out (no-antimalarial group); and a group that included 53 of the 381 patients (13.9%) with confirmed EVD for whom information on prescription of antimalarial treatment was missing (missing-data group; this group was assessed to understand patterns of missing data). The occurrence of missing prescription data was not associated with any clinical variables that we assessed, including EVD severity or discharge status; however, it was associated with increased case load at the Ebola treatment center and with being admitted early in the course of the epidemic .\n\n【32】Most of the patients (87.3%) with confirmed EVD were between 5 and 59 years of age, and 6.9% of the patients were younger than 5 years of age. The median PCR cycle-threshold value at admission was 19.4 (interquartile range, 17.1 to 22.8), and the median time between symptom onset and admission was 3.5 days (interquartile range, 2 to 6). Rapid tests for malaria were positive in 19.3% of the patients. Overall, 32.6% of the patients received intravenous fluids, and the average proportion of patients receiving intravenous fluids increased over time, except for a sharp decline in early August when admissions to the Ebola treatment center increased substantially .\n\n【33】Table 1. Characteristics of Patients with Confirmed Ebola Virus Disease Admitted to the Ebola Treatment Center in Foya, Liberia, According to Antimalarial Prescription Status.\n\n【34】The characteristics of the patients in the artesunate–amodiaquine group were generally similar to those of patients in the artemether–lumefantrine group and the no-antimalarial group, except that patients in the artesunate–amodiaquine group had lower cycle-threshold values on admission, were prescribed antibiotics less often, and were admitted at times when the Ebola treatment center was busier . The patients in the artesunate–amodiaquine group were less geographically clustered than were those in the artemether-lumefantrine group (3.9 cases per village vs. 4.6 cases per village).\n\n【35】Mortality\n---------\n\n【36】Table 2. Relative Risk of Death Among Patients with Confirmed Ebola Virus Disease, According to Antimalarial Prescription Status.\n\n【37】A total of 64.4% of the patients in the artemether–lumefantrine group died, as compared with 50.7% of the patients in the artesunate–amodiaquine group. In unadjusted analyses, the artesunate–amodiaquine group had a 21% lower risk of death than did those in the artemether–lumefantrine group (risk ratio, 0.79; 95% confidence interval \\[CI\\], 0.61 to 1.01). After adjustment for potential confounders (age, sex, cycle-threshold value, time from symptom onset to admission, malaria test result, receipt or no receipt of intravenous fluids, and number of inpatients at the Ebola treatment center on the day of patient admission), the artesunate–amodiaquine group had a 31% lower risk of death than did the artemether–lumefantrine group (risk ratio, 0.69; 95% CI, 0.54 to 0.89) . Alternative adjusted models led to similar qualitative results .\n\n【38】Table 3. Multivariate Analysis of Risk Factors for Death Among Patients with Confirmed Ebola Virus Disease.\n\n【39】The final model, which included 282 patients with complete data, was adjusted for demographic characteristics (age and sex), the time from symptom onset to admission, cycle-threshold value at admission, malaria rapid-test result, receipt or no receipt of intravenous fluids, and the estimated number of other patients being treated at the Ebola treatment center on the day a patient was admitted. In this model, as in the other models, we found a protective effect of artesunate–amodiaquine; in addition, we found that an age older than 60 years, a lower cycle-threshold value at admission, admission at a time during which there were more patients in the Ebola treatment center, and receipt of intravenous fluids were all associated with a significantly higher risk of death .\n\n【40】Table 4. Risk Ratio of Death among Patients with Confirmed Ebola Virus Disease, According to Malaria and Prescription Status.\n\n【41】In stratified analyses, among the 272 patients who tested negative for malaria, those who were prescribed artesunate–amodiaquine had a 36% lower risk of death than did those who were prescribed artemether–lumefantrine (risk ratio, 0.64; 95% CI, 0.49 to 0.85) . However, among the 65 patients who tested positive for malaria, we found no protective effect of the prescription of artesunate–amodiaquine (risk ratio, 1.00; 95% CI, 0.54 to 1.85).\n\n【42】To account for the possibility that unmeasured trends during this dynamic epidemic could have confounded our estimates of the relationship between prescribed antimalarial treatment and mortality among patients with confirmed EVD, we assessed this effect during the period in which artesunate–amodiaquine was prescribed and also during the following three distinct time windows during which artemether–lumefantrine was prescribed: the week before and the week after the period during which artesunate–amodiaquine was prescribed (first window); the 10 days before the period during which artesunate–amodiaquine was prescribed (second window); and 10 days after the period during which artesunate–amodiaquine was prescribed (third window). Across all these subanalyses, our data still showed that artesunate–amodiaquine was associated with a significantly lower risk of death than was artemether–lumefantrine, with consistent (unadjusted) risk ratios of 0.66 during the first window, 0.64 during the second window, and 0.68 during the third window .\n\n【43】Discussion\n----------\n\n【44】Our analyses of this natural experiment that was triggered by a stock-out of the standard antimalarial drugs at the Ebola treatment center in Foya showed that among patients with EVD, those who were prescribed artesunate–amodiaquine had a 31% lower risk of death than did those who were prescribed artemether–lumefantrine (risk ratio, 0.69; 95% CI, 0.0.54 to 0.89). The biologic plausibility of our findings is based on in vitro experiments that showed the efficacy of amodiaquine in inhibiting Ebola virus activity.  Chloroquine, another 4-aminoquinolone compound, has shown mixed efficacy in in vivo studies.  In humans, the therapeutic dose of amodiaquine against malaria is 7.5 to 15.0 mg per kilogram of body weight,  and toxic effects (e.g., agranulocytosis and liver damage) have been reported only when amodiaquine was used for long-term prophylaxis.  Artesunate–amodiaquine has also been used in children with uncomplicated malaria, and to date, no obvious safety concerns have been identified.  Desethyl-amodiaquine, the active metabolite of amodiaquine, has a long half-life; in humans, the mean elimination half-life is 211 hours. The peak concentration of desethyl-amodiaquine is reached after the last dose of a standard 3-day course of treatment. It is possible that the effects of this antimalarial agent on the virus can be seen only at the time of peak concentration, which could explain the observed divergence in the survival curves of those prescribed artesunate–amodiaquine and those prescribed artemether–lumefantrine at approximately 5 days after admission .\n\n【45】Although we found that artesunate–amodiaquine was associated with a lower risk of death than was artemether–lumefantrine in the full study population, when we restricted the population to those with a positive malaria test, this association was attenuated. However, prescription of any antimalarial agent was associated with a lower risk of death than the risk with no antimalarial agent . The potential interaction between malaria status and type of antimalarial agent prescribed warrants further investigation.\n\n【46】As has been seen in previous studies of risk factors associated with death from EVD,  patients with a higher viral load at admission, as measured by PCR cycle-threshold value, and those who were older than 60 years of age had a higher risk of death. In addition, patients admitted during busy periods (i.e., days on which more patients were in the center) and patients who were prescribed parenteral treatment had a higher risk of death.\n\n【47】The stock-out of artemether–lumefantrine described in this article led to a natural experiment in which the exposure (i.e., the antimalarial treatment prescribed) was, in theory, unrelated to individual patient characteristics, which should reduce the confounding that limits inferences from observational studies. However, because the situation changed rapidly during this dynamic EVD epidemic, the characteristics of the patients who were admitted to the Ebola treatment center during the 12 days when artemether–lumefantrine was out of stock may have differed in undetected ways from those admitted at other times. To assess the potential effect of unobserved confounding factors, we analyzed several restricted time windows before and after the stock-out separately, and the findings remained consistent . Still, there could be other confounding factors that we were unable to measure and account for in our analyses.\n\n【48】This analysis has numerous limitations. The patient files contained information only about prescription of an antimalarial drug; no information was included on whether the patient completed the full course of the regimen. Because both drugs evaluated are taken orally, severely ill patients may not have been able to swallow the pills from either regimen. Because artesunate–amodiaquine causes gastrointestinal side effects more often than other artemisinin-based antimalarial drugs,  it is possible that patients who were prescribed artesunate–amodiaquine were less likely than patients who were prescribed artemether–lumefantrine to complete the full course. If this was the case, our results would underestimate the relative risk of death among patients in the artesunate–amodiaquine group. Among our study population, 63 patients were not prescribed antimalarial treatment for various possible reasons, including the rationing of artemether–lumefantrine that occurred in early August just before the stock-out. If these reasons were related to unmeasured patient characteristics that directly alter the risk of death, our results could be confounded.\n\n【49】Although artesunate–amodiaquine and artemether–lumefantrine are generally considered to be safe drugs,  an alternative hypothesis is that artemether–lumefantrine increases the risk of death. This hypothesis is supported by our estimates of a protective, though nonsignificant, effect observed among patients who received no antimalarial prescription as compared with those who were prescribed artemether–lumefantrine  and by the fact that this effect persisted in most adjusted sensitivity analyses . However, the biologic plausibility of this hypothesis is uncertain.\n\n【50】Artemether–lumefantrine is contraindicated in patients with known hypokalemia or hypomagnesemia because it can increase the risk of QT-interval prolongation and lead to potentially fatal arrhythmias.  Diarrhea and vomiting are common in patients with EVD, and hypokalemia has been reported anecdotally.  One study in which the post-treatment electrocardiograms of children with uncomplicated malaria who received artemether–lumefantrine were compared with the post-treatment electrocardiograms of those who received artesunate–amodiaquine showed no significant difference in the QT-interval prolongation.  Artemether–lumefantrine is also contraindicated in patients who are receiving drugs associated with QT-interval prolongation,  including quinolone antibiotics. Five patients in the artemether–lumefantrine group were prescribed ciprofloxacin, although only one died (case fatality rate, 20%). None of the other drugs for which we have information are contraindicated in patients receiving artemether–lumefantrine. However, some case reports suggest that metoclopramide, an antiemetic agent that was commonly used in Foya, is associated with a range of cardiac effects,  although data on metoclopramide use were not recorded. Fatal arrhythmias associated with the use of artemether–lumefantrine might be expected to occur during the first days of administration; however, an excess of early deaths with artemether–lumefantrine did not occur in our study, as evidenced by the fact that the survival curves for the groups in our study started to diverge 5 days after admission .\n\n【51】The natural experiment described here provided an excellent opportunity to assess the potential effect of antimalarial regimens on mortality among patients with confirmed EVD. Although questions about the mechanism remain, the results suggest that artesunate–amodiaquine may be preferable to artemether–lumefantrine in patients with confirmed EVD. We urge health care providers in countries affected by EVD to try to confirm these findings, including analyses of the effect of mass drug administration of artesunate–amodiaquine on EVD transmission in Sierra Leone and Liberia.  Centers that used artemether–lumefantrine and have access to results of laboratory and cardiac monitoring of patients with EVD might be able to affirm or disprove the potential association between artemether–lumefantrine and fatal arrhythmias. More research is needed to independently test this apparent association, and if it is confirmed, to estimate the safest and most effective therapeutic dose against Ebola virus.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": []}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:26", "update_time": "2024-08-14 00:20:54", "grab_time": "2024-08-13 23:37:23"}
{"id": 2234258, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "cbe2a007-1c19-427c-9c9c-b796d03bc209", "title": "Anabolic Therapies for Osteoporosis", "text": "【0】Anabolic Therapies for Osteoporosis\nTo the Editor:\n--------------\n\n【1】In their review of anabolic therapies for osteoporosis, Canalis et al. (Aug. 30 issue)  mention contraindications to teriparatide use, including skeletal malignant conditions. We wish to add an additional caution concerning the use of this drug in patients with a history of cancer. Patients with non–small-cell lung cancer, breast cancer, and other cancers have been shown to have micrometastatic tumor cells in the bone marrow that are associated with poor outcomes.  It is not known whether patients without evidence of disease for many years have “micrometastases” in the bone marrow as well. The high-bone-turnover state (sequential osteoblastic activity followed by osteoclastic activity) created by teriparatide might fuel occult micrometastases through liberation of bone-matrix–derived growth factor and cytokine release in the microenvironment. An additional concern regarding patients with hematologic cancers is the stimulatory effect of teriparatide on hematopoietic stem cells through osteoblastic cells situated within the bone marrow “niche.”  In patients with severe osteoporosis and a history of cancer, the benefits of teriparatide in preventing fractures should be weighed against these theoretical risks.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:58:30", "endTime": "2024/08/14 14:58:46", "cost": 15.693}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:26", "update_time": "2024-08-13 22:58:46", "grab_time": "2024-08-13 22:58:30"}
{"id": 2234257, "user_id": "65e7dd68e6dc6a3a8618a668", "user_name": "王磊", "task_id": 1579, "source_info": {"seq_id": "1f8d58ea-2821-4094-a9dd-31dbb5ebeec8", "title": "The Infant Seat as Treatment for Gastroesophageal Reflux", "text": "【0】The Infant Seat as Treatment for Gastroesophageal Reflux\nAbstract\n--------\n\n【1】Positioning in the infant seat (\"chalasia chair\") for treatment of infants with gastroesophageal reflux is presumed to have a beneficial effect. We undertook a controlled, prospective study of such positioning to evaluate this purported benefit. Nine infants with documented gastroesophageal reflux participated in 18 paired two-hour postprandial trials in an infant seat and in the horizontal prone position. Distal esophageal pH monitoring demonstrated longer exposure to gastroesophageal reflux while infants were in the seat than when they were prone (28.2±6.4 per cent vs. 12.8±3.7 per cent of total time with pH <4.0, P = 0.023), a difference due largely to more episodes (16.0±2.4 vs. 10.1±2.3 per two-hour postprandial period, P = 0.002). We conclude that the infant seat, rather than being therapeutic in gastroesophageal reflux in children under six months of age, is actually detrimental, when compared with simply placing an infant prone.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:53:58", "endTime": "2024/08/14 14:54:16", "cost": 17.198}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:26", "update_time": "2024-08-13 22:54:16", "grab_time": "2024-08-13 22:53:58"}
{"id": 2234256, "user_id": "65dea7050c9e908864e3bcde", "user_name": "焦瀚远", "task_id": 1579, "source_info": {"seq_id": "13d91389-0af9-46ad-bdad-ad9a2a4dbf4b", "title": "The Nontherapeutic Use of Psychoactive Drugs — A Modern Epidemic", "text": "【0】The Nontherapeutic Use of Psychoactive Drugs — A Modern Epidemic\nAbstract\n\n【1】The current widespread nontherapeutic use of psychoactive drugs began among a small group of college students in the early 1960s. It spread with explosive force into an epidemic of extraordinary scope involving all regions of the country, all socioeconomic classes, and all age groups. This article reviews the drugs currently used and identifies those who use them. It discusses the complex, rapidly changing patterns of use and the consequences of this epidemic for both the individual and the society.\n\n【2】The inhalants, phencyclidine, cocaine, heroin, the psychotherapeutics (methaqualone and amphetamine), and marijuana are the most widely used drugs. Recent clinical and laboratory research indicates that these drugs pose serious hazards to physical and mental health.\n\n【3】Marijuana is the most widely used illicit drug; one quarter of the entire U.S. population have used the drug, and 20 million people use it daily. The short-term and long-term adverse effects of marijuana have important social implications.\n\n【4】Recent data suggest that drug users possess limited inner resources to cope with psychological stress and that they take drugs to fill a moral and spiritual void and to meet intense emotional needs. It is proposed that these character traits and emotional conflicts of drug users may reflect recent changes in child rearing and family stability.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 14:59:12", "endTime": "2024/08/14 15:00:02", "cost": 49.802}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:26", "update_time": "2024-08-13 23:00:02", "grab_time": "2024-08-13 22:59:12"}
{"id": 2234255, "user_id": "6576f559fffcb026c0088587", "user_name": "周煜霖", "task_id": 1579, "source_info": {"seq_id": "fc58e38d-f60c-4daa-89b8-f89e1f77a72d", "title": "Painful Purple Toes", "text": "【0】Painful Purple Toes\nA 57-year-old man presented to the emergency department with painful purple discoloration of three toes on his left foot. He had also had intermittent blurry vision, intermittent chest pain, fatigue, anorexia, drenching night sweats, and a weight loss of 7 kg (15 lb) over the previous 3 weeks. His roommate commented that the patient had been slightly confused.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 11:04:42", "endTime": "2024/08/14 11:06:49", "cost": 127.419}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:26", "update_time": "2024-08-13 19:06:49", "grab_time": "2024-08-13 19:04:41"}
{"id": 2234254, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "9dfa2784-f259-424b-9ccd-1fbbd35f5ccf", "title": "A Randomized Trial of Chemotherapy and Hormonal Therapy in Advanced Breast Cancer", "text": "【0】A Randomized Trial of Chemotherapy and Hormonal Therapy in Advanced Breast Cancer\nAbstract\n--------\n\n【1】We randomized 81 postmenopausal women with advanced breast cancer, whose tumors were rich in estrogen receptors or of unknown estrogen-receptor status, to receive either estrogen therapy alone or estrogen therapy combined with chemotherapy. An additional 31 patients, whose tumors were poor in estrogen receptors, were randomized to receive either chemotherapy alone or estrogen combined with chemotherapy. The median duration of follow-up was 87 months. In the receptor-rich group, the survival of the 21 patients receiving combined therapy was significantly longer than that of 19 patients receiving estrogen as initial therapy (followed by chemotherapy after failure or relapse). The median survivals were 72 and 29 months, respectively (P = 0.05 by the generalized Wilcoxon method). Among 41 patients with tumors of unknown receptor status, a survival advantage from combined therapy over chemotherapy was seen in the first two years and then disappeared. The survival in 31 patients with receptor-poor tumors was uniformly short regardless of the therapeutic method. We conclude that combined therapy offers a survival advantage in postmenopausal patients with receptor-rich tumors.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:12:22", "endTime": "2024/08/14 15:12:29", "cost": 7.796}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:26", "update_time": "2024-08-13 23:12:29", "grab_time": "2024-08-13 23:12:21"}
{"id": 2234253, "user_id": "65e7dd234a08e7753ad36f9f", "user_name": "黄艳玲", "task_id": 1579, "source_info": {"seq_id": "9f5f4c25-b064-4b03-98be-88a14b52535a", "title": "Seroepidemiology of Human Sarcoma Antigen (S", "text": "【0】Seroepidemiology of Human Sarcoma Antigen (S\nAbstract\n--------\n\n【1】A previously identified tumor-associated antigen of human sarcomas, S <sub>1 </sub> , has been studied to characterize further its association with neoplasia. We used an immunofluorescence test on 166 serum specimens from normal persons and 295 from patients with neoplasia to determine the distribution of S <sub>1 </sub> antibody. The prevalence of antibody to S <sub>1 </sub> in the normal population varies considerably with age. Thirty-nine (91 per cent) of 43 persons between five and 20 years of age had serum antiS <sub>1 </sub> activity, whereas of 39 above the age of 41 only 13 (33 per cent) were similarly reactive.\n\n【2】Neoplasia may induce the reappearance of S <sub>1 </sub> antibody. Significant antibody levels were found in more than 80 per cent of patients with carcinoma of the breast, lung and melanoma 41 years of age or older. An inverse relation of antibody prevalence to extent of disease was noted in persons with Hodgkin's disease. Available data suggest that S <sub>1 </sub> is a \"heterophil\" type of antigen. Although not tumor-specific, S <sub>1 </sub> may prove useful both for the detection of neoplasia and for the evaluation of response to anti-tumor therapy.", "tags": {}, "lang": "en", "attr": {}, "ext": null, "dataset": "nejm", "batch_name": "20230925", "version": "version0"}, "result_info": {"text": [], "startTime": "2024/08/14 15:07:23", "endTime": "2024/08/14 15:07:37", "cost": 13.112}, "finished": true, "dropped": false, "create_time": "2024-08-12 23:58:26", "update_time": "2024-08-13 23:07:36", "grab_time": "2024-08-13 23:07:23"}