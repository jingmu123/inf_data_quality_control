# -*- coding: utf-8 -*-
import json
type1={'药理学': 0.445, '内科': 0.389, '儿科': 0.031, '生物化学': 0.028, '妇产科': 0.028, '微生物学': 0.02, '病理学': 0.013, '解剖学': 0.01, '医学伦理学': 0.01, '皮肤性病科': 0.008, '生理学': 0.005, '营养学': 0.003, '外科': 0.003, '预防医学': 0.003, '耳鼻咽喉头颈外科学': 0.003, '医学物理学': 0.003}
type2={'药理学@临床药理学': 0.336, '内科@感染病学': 0.125, '药理学@分子药理学': 0.122, '内科@心血管内科': 0.046, '内科@消化内科': 0.035, '内科@神经内科': 0.035, '内科@风湿病学': 0.029, '内科@老年病学': 0.029, '生物化学@临床生物化学': 0.026, '内科@肾脏内科': 0.02, '内科@内分泌内科': 0.02, '微生物学@医学细菌学': 0.02, '内科@呼吸内科': 0.017, '内科@传染病学': 0.014, '儿科@新生儿科': 0.014, '内科@血液内科': 0.014, '内科@肿瘤学': 0.014, '妇产科@产科': 0.012, '医学伦理学@医患沟通': 0.012, '病理学@临床病理学': 0.009, '解剖学@局部解剖学': 0.006, '外科@泌尿外科': 0.006, '解剖学@系统解剖学': 0.006, '妇产科@生殖医学': 0.006, '生理学@人体生理学': 0.006, '麻醉学@疼痛医学': 0.003, '病理学@系统病理学': 0.003, '微生物学@医学病毒学': 0.003, '生物化学@分子生物化学': 0.003, '营养学': 0.003, '妇产科@妇科': 0.003, '生物化学@细胞生物化学': 0.003}

file="drug_detail_zh"
save_file = f"../../../../full_data/{file}/{file}.jsonl"
fw = open(save_file, 'w',encoding="utf-8")


from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained("../../../basic_tools/tokenizer")
def tokenizer_lens(context):
    ids = tokenizer.encode(context)
    return len(ids)
sum_lens = 0
class_ratio_token= {'level1': {'药理学': '96.702%', '内科': '80.833%', '生物化学': '8.763%', '儿科': '9.171%', '妇产科': '5.135%', '皮肤性病科': '1.367%', '营养学': '0.292%', '微生物学': '10.679%', '病理学': '8.146%', '解剖学': '2.603%', '外科': '0.352%', '医学伦理学': '2.643%', '预防医学': '0.487%', '耳鼻咽喉头颈外科学': '0.212%', '医学物理学': '0.265%', '生理学': '1.392%'}, 'level2': {'药理学@临床药理学': '96.223%', '内科@心血管内科': '18.11%', '内科@肾脏内科': '8.815%', '药理学@分子药理学': '37.821%', '生物化学@临床生物化学': '6.746%', '内科@感染病学': '42.481%', '妇产科@产科': '4.638%', '内科@传染病学': '7.38%', '内科@内分泌内科': '6.161%', '内科@风湿病学': '7.923%', '麻醉学@疼痛医学': '0.424%', '内科@消化内科': '5.572%', '微生物学@医学细菌学': '9.797%', '儿科@新生儿科': '4.435%', '内科@血液内科': '3.105%', '内科@老年病学': '8.176%', '内科@肿瘤学': '4.182%', '内科@神经内科': '8.241%', '病理学@系统病理学': '4.191%', '微生物学@医学病毒学': '0.881%', '解剖学@局部解剖学': '1.748%', '病理学@临床病理学': '3.026%', '内科@呼吸内科': '1.747%', '生物化学@分子生物化学': '1.789%', '外科@泌尿外科': '0.544%', '医学伦理学@医患沟通': '2.291%', '解剖学@系统解剖学': '1.858%', '妇产科@生殖医学': '2.362%', '生理学@人体生理学': '1.392%', '营养学': '0.314%', '妇产科@妇科': '0.241%', '生物化学@细胞生物化学': '0.228%'}, 'all_sample_tokens': 106110}
class_ratio_doc= {'level1': {'生物化学': '8.8%', '内科': '76.8%', '微生物学': '6.4%', '解剖学': '2.4%', '医学伦理学': '2.4%', '药理学': '100.0%', '皮肤性病科': '1.6%', '妇产科': '1.6%', '生理学': '1.6%', '儿科': '0.8%', '外科': '0.8%', '病理学': '0.8%', '耳鼻咽喉头颈外科学': '0.8%'}, 'level2': {'药理学@临床药理学': '91.2%', '内科@消化内科': '9.6%', '内科@神经内科': '9.6%', '内科@风湿病学': '8.0%', '生物化学@临床生物化学': '7.2%', '内科@肾脏内科': '5.6%', '内科@内分泌内科': '5.6%', '微生物学@医学细菌学': '5.6%', '内科@老年病学': '5.6%', '内科@传染病学': '4.0%', '儿科@新生儿科': '4.0%', '内科@血液内科': '4.0%', '内科@肿瘤学': '4.0%', '内科@呼吸内科': '4.0%', '药理学@分子药理学': '33.6%', '内科@感染病学': '33.6%', '妇产科@产科': '3.2%', '医学伦理学@医患沟通': '3.2%', '病理学@临床病理学': '2.4%', '内科@心血管内科': '11.2%', '解剖学@局部解剖学': '1.6%', '外科@泌尿外科': '1.6%', '妇产科@生殖医学': '1.6%', '生理学@人体生理学': '1.6%', '麻醉学@疼痛医学': '0.8%', '病理学@系统病理学': '0.8%', '微生物学@医学病毒学': '0.8%', '生物化学@分子生物化学': '0.8%', '解剖学@系统解剖学': '0.8%', '营养学': '0.8%', '妇产科@妇科': '0.8%', '生物化学@细胞生物化学': '0.8%'}}

with open(f"../../../../full_data/{file}/{file}_clean.jsonl", "r",encoding="utf-8") as fs:
    for item in fs.readlines():
        item = json.loads(item)
        context = item["text"]
        lens = tokenizer_lens(context)
        sum_lens += lens

with open(f"../../../../full_data/{file}/{file}_clean.jsonl", "r",encoding="utf-8") as fs:
    for item in fs.readlines():
        item = json.loads(item)
        item["tags"] = {
                        "id": item["seq_id"],
                        "clean_iters":"2",
                        "quality_score":"96.8%",
                        "note":"部分条目缺少药品有效期信息",
                        "class_ratio_doc": class_ratio_doc,
                        "class_ratio_tokenize": class_ratio_token,
                        "item_tokens": tokenizer_lens(item["text"]),
                        "dataset_tokens": sum_lens,
                        "bia_class": "药品说明书"
                        }

        item = json.dumps(item,ensure_ascii=False)
        fw.write(item+"\n")
