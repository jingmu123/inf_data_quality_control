# -*- coding: utf-8 -*-
import json
type1={'药理学': 0.331, '内科': 0.299, '生物化学': 0.059, '妇产科': 0.047, '外科': 0.038, '微生物学': 0.032, '皮肤性病科': 0.023, '病理学': 0.023, '生理学': 0.017, '儿科': 0.016, '遗传学': 0.016, '医学伦理学': 0.015, '医学免疫学': 0.011, '麻醉学': 0.009, '眼科': 0.008, '预防医学': 0.008, '全科医学概论': 0.008, '病理生理学': 0.007, '口腔科学': 0.005, '解剖学': 0.005, '急诊医学': 0.004, '流行病学和循证医学': 0.003, '耳鼻咽喉头颈外科学': 0.003, '放射科': 0.003, '营养学': 0.002, '组织学与胚胎学': 0.002, '康复医学': 0.002, '医学心理学': 0.002, '医学统计学': 0.002, '卫生政策与管理': 0.001, '精神病学': 0.001}
type2={'药理学@临床药理学': 0.321, '内科@心血管内科': 0.081, '内科@感染病学': 0.049, '内科@肿瘤学': 0.039, '内科@神经内科': 0.034, '内科@消化内科': 0.032, '内科@呼吸内科': 0.032, '妇产科@妇科': 0.028, '内科@内分泌内科': 0.026, '药理学@分子药理学': 0.025, '医学伦理学@医患沟通': 0.021, '生物化学@分子生物化学': 0.02, '生物化学@有机化学': 0.018, '内科@肾脏内科': 0.018, '病理学@临床病理学': 0.016, '内科@传染病学': 0.014, '妇产科@产科': 0.013, '外科@普通外科': 0.013, '微生物学@医学病毒学': 0.012, '麻醉学@疼痛医学': 0.012, '微生物学@医学真菌学': 0.012, '内科@风湿病学': 0.011, '妇产科@生殖医学': 0.011, '儿科@新生儿科': 0.011, '内科@血液内科': 0.011, '生物化学@临床生物化学': 0.011, '外科@骨科': 0.011, '遗传学@人类遗传学': 0.008, '生物化学@细胞生物化学': 0.008, '微生物学@人体寄生虫学': 0.008, '遗传学@分子遗传学': 0.007, '微生物学@医学细菌学': 0.007, '病理学@系统病理学': 0.007, '外科@神经外科': 0.007, '生理学@人体生理学': 0.007, '生理学@系统生理学': 0.005, '内科@老年病学': 0.004, '外科@烧伤与整形外科': 0.004, '放射科@影像诊断': 0.004, '儿科@儿内科': 0.004, '解剖学@系统解剖学': 0.004, '口腔科学@口腔外科': 0.004, '外科@肝胆外科': 0.003, '眼科': 0.003, '病理学@分子病理学': 0.003, '外科@泌尿外科': 0.003, '精神病学': 0.001, '生理学@细胞生理学': 0.001, '病理学@细胞病理学': 0.001, '皮肤性病科': 0.001}

file="baiduyidian"
save_file = f"../../../../full_data/{file}/{file}.jsonl"
fw = open(save_file, 'w',encoding="utf-8")

from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained("../../../basic_tools/tokenizer")
def tokenizer_lens(context):
    ids = tokenizer.encode(context)
    return len(ids)
sum_lens = 0
class_ratio_token= {'level1': {'外科': '31.597%', '微生物学': '14.871%', '病理学': '34.664%', '内科': '48.32%', '药理学': '17.72%', '遗传学': '11.927%', '预防医学': '7.248%', '生物化学': '3.067%', '生理学': '13.676%', '解剖学': '3.333%', '急诊医学': '5.464%', '医学伦理学': '1.854%', '妇产科': '9.33%', '医学免疫学': '2.316%', '麻醉学': '0.465%', '皮肤性病科': '12.103%', '儿科': '6.586%', '全科医学概论': '9.399%', '康复医学': '0.365%', '流行病学和循证医学': '6.202%', '放射科': '3.778%', '医学心理学': '2.837%', '口腔科学': '4.099%', '职业卫生学': '0.334%', '病理生理学': '2.381%', '眼科': '3.714%', '环境卫生学': '0.327%', '耳鼻咽喉头颈外科学': '1.908%', '医学统计学': '0.959%', '医学物理学': '0.493%', '精神病学': '1.473%', '营养学': '0.215%'}, 'level2': {'病理学@临床病理学': '15.352%', '微生物学@医学病毒学': '2.408%', '内科@感染病学': '8.585%', '药理学@临床药理学': '23.264%', '外科@泌尿外科': '3.252%', '内科@神经内科': '9.479%', '遗传学@人类遗传学': '8.649%', '外科@神经外科': '3.483%', '外科@骨科': '3.599%', '内科@肾脏内科': '2.401%', '内科@消化内科': '8.704%', '儿科@儿内科': '3.501%', '内科@心血管内科': '8.768%', '医学伦理学@医患沟通': '4.182%', '病理学@系统病理学': '14.44%', '内科@呼吸内科': '2.257%', '妇产科@产科': '2.543%', '外科@普通外科': '7.087%', '内科@风湿病学': '3.078%', '解剖学@系统解剖学': '3.543%', '微生物学@医学细菌学': '4.514%', '微生物学@医学真菌学': '2.188%', '病理学@细胞病理学': '1.218%', '病理学@分子病理学': '1.116%', '放射科@影像诊断': '4.857%', '麻醉学@疼痛医学': '0.914%', '内科@血液内科': '4.816%', '儿科@新生儿科': '2.857%', '生理学@人体生理学': '4.96%', '妇产科@妇科': '4.505%', '内科@内分泌内科': '5.689%', '微生物学@人体寄生虫学': '1.791%', '内科@肿瘤学': '5.993%', '外科@肝胆外科': '1.348%', '内科@传染病学': '3.141%', '妇产科@生殖医学': '1.252%', '外科@胸心外科': '0.761%', '生理学@系统生理学': '3.162%', '口腔科学@口腔外科': '2.835%', '儿科': '0.533%', '内科@老年病学': '1.414%', '解剖学@局部解剖学': '1.718%', '生物化学@有机化学': '0.215%', '生理学@细胞生理学': '0.825%', '预防医学': '0.19%', '病理学': '0.19%', '遗传学@分子遗传学': '0.999%', '生物化学@临床生物化学': '2.018%', '病理生理学': '0.153%', '耳鼻咽喉头颈外科学': '0.231%', '全科医学概论': '0.207%', '外科': '0.178%', '流行病学和循证医学': '0.178%', '药理学': '0.178%', '医学心理学': '0.178%', '放射科': '0.178%', '急诊医学': '0.292%', '外科@烧伤与整形外科': '0.292%', '儿科@儿童保健': '0.52%'}, 'all_sample_tokens': 1158176}
class_ratio_doc= {'level1': {'遗传学': '8.75%', '生理学': '8.25%', '妇产科': '8.0%', '儿科': '6.75%', '内科': '58.5%', '解剖学': '4.75%', '全科医学概论': '4.25%', '眼科': '4.25%', '急诊医学': '4.0%', '口腔科学': '4.0%', '病理学': '29.0%', '外科': '26.25%', '放射科': '2.5%', '精神病学': '2.25%', '药理学': '14.5%', '皮肤性病科': '12.0%', '流行病学和循证医学': '10.5%', '微生物学': '10.25%', '预防医学': '1.75%', '病理生理学': '1.75%', '耳鼻咽喉头颈外科学': '1.75%', '医学心理学': '1.75%', '医学免疫学': '1.25%', '麻醉学': '1.25%', '医学伦理学': '1.25%', '生物化学': '0.75%', '医学统计学': '0.5%', '康复医学': '0.25%', '职业卫生学': '0.25%', '医学物理学': '0.25%', '营养学': '0.25%'}, 'level2': {'内科@神经内科': '9.75%', '内科@消化内科': '8.75%', '内科@感染病学': '8.5%', '遗传学@人类遗传学': '7.25%', '内科@心血管内科': '7.25%', '外科@普通外科': '6.75%', '内科@内分泌内科': '6.0%', '放射科@影像诊断': '5.5%', '内科@肿瘤学': '4.75%', '医学伦理学@医患沟通': '4.25%', '妇产科@妇科': '4.0%', '外科@骨科': '4.0%', '外科@泌尿外科': '3.75%', '内科@血液内科': '3.75%', '微生物学@医学细菌学': '3.5%', '生理学@人体生理学': '3.25%', '外科@神经外科': '3.0%', '儿科@儿内科': '3.0%', '解剖学@系统解剖学': '3.0%', '口腔科学@口腔外科': '3.0%', '药理学@临床药理学': '20.0%', '内科@传染病学': '2.75%', '内科@风湿病学': '2.5%', '微生物学@医学病毒学': '2.5%', '内科@肾脏内科': '2.25%', '妇产科@产科': '2.25%', '儿科@新生儿科': '2.25%', '内科@呼吸内科': '2.0%', '微生物学@医学真菌学': '2.0%', '病理学@临床病理学': '13.0%', '病理学@系统病理学': '12.0%', '微生物学@人体寄生虫学': '1.75%', '生理学@系统生理学': '1.75%', '解剖学@局部解剖学': '1.5%', '麻醉学@疼痛医学': '1.25%', '外科@肝胆外科': '1.25%', '内科@老年病学': '1.25%', '生物化学@临床生物化学': '1.25%', '病理学@分子病理学': '1.0%', '病理学@细胞病理学': '1.0%', '妇产科@生殖医学': '1.0%', '遗传学@分子遗传学': '1.0%', '外科@胸心外科': '0.75%', '生理学@细胞生理学': '0.5%', '儿科': '0.25%', '生物化学@有机化学': '0.25%', '预防医学': '0.25%', '病理学': '0.25%', '病理生理学': '0.25%', '耳鼻咽喉头颈外科学': '0.25%', '全科医学概论': '0.25%', '外科': '0.25%', '流行病学和循证医学': '0.25%', '放射科': '0.25%', '药理学': '0.25%', '医学心理学': '0.25%', '急诊医学': '0.25%', '外科@烧伤与整形外科': '0.25%', '儿科@儿童保健': '0.25%'}}

with open(f"../../../../full_data/{file}/{file}_preformat.jsonl", "r",encoding="utf-8") as fs:
    for item in fs.readlines():
        item = json.loads(item)
        context = item["text"]
        lens = tokenizer_lens(context)
        sum_lens += lens

with open(f"../../../../full_data/{file}/{file}_preformat.jsonl", "r",encoding="utf-8") as fs:
    for item in fs.readlines():
        item = json.loads(item)
        item["tags"] = {
                        "id": item["seq_id"],
                        "clean_iters":"0",
                        "quality_score":"95%",
                        "class_ratio_doc": class_ratio_doc,
                        "class_ratio_tokenize": class_ratio_token,
                        "item_tokens": tokenizer_lens(item["text"]),
                        "dataset_tokens": sum_lens,
                        "bia_class": "百科科普"
        }

        item = json.dumps(item,ensure_ascii=False)
        fw.write(item+"\n")
